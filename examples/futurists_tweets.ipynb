{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook demonstrates the use of `snscrape` social-media scrapper to efficiently (with parallelization) retrieve tweets from multiple accounts.\n",
    "\n",
    "As an example, we will retrieve recent tweets of well-known futurists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scrapping:kevin2kelly\n",
      "INFO:scrapping:michiokaku\n",
      "INFO:scrapping:michellzappa\n",
      "INFO:scrapping:PeterDiamandis\n",
      "INFO:scrapping:janlgordon\n",
      "INFO:scrapping:rossdawson\n",
      "INFO:scrapping:GeniusWorks\n",
      "INFO:scrapping:briansolis\n",
      "INFO:scrapping:Richard_Florida\n",
      "WARNING:snscrape.modules.twitter:Stopping after 20 empty pages\n",
      "INFO:scrapping:RetailProphet\n",
      "INFO:scrapping:avantgame\n",
      "INFO:scrapping:gleonhard\n",
      "INFO:scrapping:ayeletb\n",
      "INFO:scrapping:mgorbis\n",
      "INFO:scrapping:zephoria\n",
      "INFO:scrapping:rushkoff\n",
      "INFO:scrapping:futuristufuk\n",
      "INFO:scrapping:fhioxford\n",
      "INFO:scrapping:KurzweilAINews\n",
      "INFO:scrapping:Joi\n",
      "INFO:scrapping:ramez\n",
      "INFO:scrapping:aubreydegrey\n",
      "INFO:scrapping:jhagel\n",
      "INFO:scrapping:GreatDismal\n",
      "INFO:scrapping:GlenHiemstra\n",
      "INFO:scrapping:alphanmanas\n",
      "INFO:scrapping:FaithPopcorn\n",
      "INFO:scrapping:nd_kane\n",
      "INFO:scrapping:ThomasFrey\n",
      "INFO:scrapping:frankdiana\n",
      "INFO:scrapping:rodfalcon\n",
      "INFO:scrapping:DavidSmithGFF\n",
      "INFO:scrapping:jesse\n",
      "INFO:scrapping:DanielBurrus\n",
      "INFO:scrapping:jcmeister\n",
      "INFO:scrapping:cshirky\n",
      "INFO:scrapping:Anabjain\n",
      "INFO:scrapping:dunagan23\n",
      "INFO:scrapping:webmasterdave\n",
      "INFO:scrapping:bookofthefuture\n",
      "INFO:scrapping:busynessgirl\n",
      "INFO:scrapping:cityofsound\n",
      "INFO:scrapping:jeremygutsche\n",
      "INFO:scrapping:nicolasnova\n",
      "INFO:scrapping:bradtem\n",
      "INFO:scrapping:jimcarroll\n",
      "INFO:scrapping:ericgarland\n",
      "INFO:scrapping:brettking\n",
      "INFO:scrapping:LisaBodell\n",
      "INFO:scrapping:rachelbotsman\n",
      "INFO:scrapping:mariansalzman\n",
      "INFO:scrapping:stratnews\n",
      "INFO:scrapping:mpesce\n",
      "INFO:scrapping:futurist_Ahines\n",
      "INFO:scrapping:tprstly\n",
      "INFO:scrapping:mattwardio\n",
      "INFO:scrapping:LiselotteLyngso\n",
      "INFO:scrapping:novaspivack\n",
      "INFO:scrapping:larrybrilliant\n",
      "INFO:scrapping:edelkoort\n",
      "INFO:scrapping:mikewalsh\n",
      "INFO:scrapping:Millennia2015\n",
      "INFO:scrapping:cascio\n",
      "INFO:scrapping:localrat\n",
      "INFO:scrapping:petervan\n",
      "INFO:scrapping:servicesphere\n",
      "INFO:scrapping:felixbbopp\n",
      "INFO:scrapping:kjaerglobal\n",
      "INFO:scrapping:puruesh\n",
      "INFO:scrapping:pickover\n",
      "INFO:scrapping:dw2\n",
      "INFO:scrapping:patrickdixon\n",
      "INFO:scrapping:Blazing_Science\n",
      "INFO:scrapping:jape\n",
      "INFO:scrapping:montymetzger\n",
      "INFO:scrapping:cecilysommers\n",
      "INFO:scrapping:davidorban\n",
      "INFO:scrapping:grayscott\n",
      "INFO:scrapping:nilofer\n",
      "INFO:scrapping:wendyinfutures\n",
      "INFO:scrapping:heathervescent\n",
      "INFO:scrapping:melissasterry\n",
      "INFO:scrapping:noreenahertz\n",
      "INFO:scrapping:jtwinsor\n",
      "INFO:scrapping:stoweboyd\n",
      "WARNING:snscrape.modules.twitter:Stopping after 20 empty pages\n",
      "INFO:scrapping:timeguide\n",
      "INFO:scrapping:gregverdino\n",
      "INFO:scrapping:scobleizer\n",
      "INFO:scrapping:afromusing\n",
      "INFO:scrapping:MFordFuture\n",
      "INFO:scrapping:DavidBrin\n",
      "INFO:scrapping:KarenSands\n",
      "INFO:scrapping:jerrymichalski\n",
      "INFO:scrapping:sahtouris\n",
      "INFO:scrapping:psaffo\n",
      "INFO:scrapping:Trendmeister\n",
      "INFO:scrapping:HLavoix\n",
      "INFO:scrapping:garrygolden\n",
      "INFO:scrapping:dtapscott\n",
      "INFO:scrapping:horizonwatching\n",
      "INFO:scrapping:MadelineAshby\n",
      "INFO:scrapping:KristinaDryza\n",
      "INFO:scrapping:meedabyte\n",
      "INFO:scrapping:elinafuturist\n",
      "INFO:scrapping:nraford\n",
      "INFO:scrapping:shapingtomorrow\n",
      "INFO:scrapping:JenniferSertl\n",
      "INFO:scrapping:TanjaHichert\n",
      "INFO:scrapping:Urbanverse\n",
      "INFO:scrapping:jonWturney\n",
      "INFO:scrapping:technoshaman\n",
      "INFO:scrapping:COTFtransform\n",
      "INFO:scrapping:ethicalmarkets\n",
      "INFO:scrapping:fastfuture\n",
      "INFO:scrapping:johnmsmart\n",
      "INFO:scrapping:prospective\n",
      "INFO:scrapping:Cekent\n",
      "INFO:scrapping:nextwavefutures\n",
      "INFO:scrapping:KarlSchroeder\n",
      "INFO:scrapping:Futur1st\n",
      "INFO:scrapping:StephaniePride\n",
      "INFO:scrapping:adamjorlen\n",
      "INFO:scrapping:EmilyK_Dalton\n",
      "INFO:scrapping:Competia\n",
      "INFO:scrapping:ehooge\n",
      "INFO:scrapping:Mandarapte108\n",
      "INFO:scrapping:skeevestevens\n",
      "WARNING:snscrape.modules.twitter:Tweet 1453417036642664454 contains an app icon medium key '4_1626211314443120642' on app 'android_app'/'com.mcdonalds.app', but the corresponding medium is missing; dropping\n",
      "INFO:scrapping:redesign\n",
      "INFO:scrapping:Geofutures\n",
      "INFO:scrapping:RielM\n",
      "INFO:scrapping:futurecheck\n",
      "INFO:scrapping:tracey_lou\n",
      "INFO:scrapping:futureguru\n",
      "INFO:scrapping:MGBarbato\n",
      "INFO:scrapping:ayeshakhanna1\n",
      "INFO:scrapping:salimismail\n",
      "INFO:scrapping:KevinABarnes\n",
      "INFO:scrapping:ErOrange\n",
      "INFO:scrapping:kristinalford\n",
      "INFO:scrapping:bronwynwilliams\n",
      "INFO:scrapping:byronreese\n",
      "INFO:scrapping:proGective\n",
      "INFO:scrapping:jimmath\n",
      "INFO:scrapping:brendacooper\n",
      "INFO:scrapping:ajitjaokar\n",
      "WARNING:snscrape.modules.twitter:Stopping after 20 empty pages\n",
      "INFO:scrapping:MareeConway\n",
      "INFO:scrapping:aftermillennial\n",
      "INFO:scrapping:futuramb\n",
      "INFO:scrapping:jackuldrich\n",
      "INFO:scrapping:moravec\n",
      "INFO:scrapping:JackieKothbauer\n",
      "INFO:scrapping:ngcrebecca\n",
      "INFO:scrapping:superplex\n",
      "WARNING:snscrape.modules.twitter:Stopping after 20 empty pages\n",
      "INFO:scrapping:DaveTheFuturist\n",
      "INFO:scrapping:mtrends\n",
      "INFO:scrapping:deanitla\n",
      "INFO:scrapping:thimon\n",
      "INFO:scrapping:troed\n",
      "INFO:scrapping:DiBariTweets\n",
      "INFO:scrapping:Garf\n",
      "INFO:scrapping:Bob_Richards\n",
      "INFO:scrapping:schfrrn\n",
      "INFO:scrapping:frankspencer\n",
      "INFO:scrapping:webbmedia\n",
      "INFO:scrapping:missmetaverse\n",
      "INFO:scrapping:VenessaMiemis\n",
      "INFO:scrapping:wdeggers\n",
      "INFO:scrapping:morgainegaye\n",
      "INFO:scrapping:CultureofFuture\n",
      "INFO:scrapping:dcoplin\n",
      "INFO:scrapping:jenjarratt\n",
      "INFO:scrapping:mkonovalenko\n",
      "INFO:scrapping:herx\n",
      "INFO:scrapping:jseelybrown\n",
      "INFO:scrapping:roboshrink\n",
      "INFO:scrapping:dvorsky\n",
      "INFO:scrapping:StratNarrative\n",
      "INFO:scrapping:MrFuture\n",
      "INFO:scrapping:_trendspotter\n",
      "INFO:scrapping:brianvellmure\n",
      "INFO:scrapping:urfuturist\n",
      "INFO:scrapping:tonybosma\n",
      "INFO:scrapping:jmacdonald\n",
      "INFO:scrapping:FuturistGraeme\n",
      "INFO:scrapping:digitalfemme\n",
      "INFO:scrapping:rebeccacosta\n",
      "INFO:scrapping:FutureInstitute\n",
      "INFO:scrapping:GregoryJRader\n",
      "INFO:scrapping:JeanHouston\n",
      "INFO:scrapping:lxlightman\n",
      "INFO:scrapping:TimLonghurst\n",
      "INFO:scrapping:futurprospicere\n",
      "INFO:scrapping:shara\n",
      "INFO:scrapping:drjaygary\n",
      "INFO:scrapping:DomenicoZungri\n",
      "INFO:scrapping:craigrispin\n",
      "INFO:scrapping:nancy\n",
      "INFO:scrapping:BizTrends\n",
      "INFO:scrapping:mlrhea\n",
      "INFO:scrapping:j9j\n",
      "INFO:scrapping:meds888\n",
      "INFO:scrapping:weiterdenker\n",
      "INFO:scrapping:dojau\n",
      "INFO:scrapping:TamarKasriel\n",
      "INFO:scrapping:laladeheinzelin\n",
      "INFO:scrapping:WEBfuturetrends\n",
      "INFO:scrapping:FreijavanDuijne\n",
      "INFO:scrapping:LaBlogga\n",
      "INFO:scrapping:htibbs\n",
      "INFO:scrapping:francescoeam\n",
      "INFO:scrapping:realfuturist\n",
      "INFO:scrapping:JeremyRifkin\n",
      "INFO:scrapping:Janelle_Marr\n",
      "INFO:scrapping:Fstyles\n",
      "INFO:scrapping:JoyceGioia\n",
      "INFO:scrapping:Louise\n",
      "INFO:scrapping:trendssoul\n",
      "INFO:scrapping:lcleries\n",
      "INFO:scrapping:vicdelr\n",
      "INFO:scrapping:foodfuturist\n",
      "INFO:scrapping:futuristpaul\n",
      "INFO:scrapping:Tiffani_Bova\n"
     ]
    }
   ],
   "source": [
    "# install social media scrapper: !pip3 install snscrape\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# configure logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('scrapping')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# twits ranges\n",
    "start_date = datetime.datetime(2021,1,1,tzinfo=datetime.timezone.utc)\n",
    "attributes = ('date','url','rawContent')\n",
    "\n",
    "\n",
    "def get_tweets(username,n_tweets=None,attributes=attributes):\n",
    "    tweets = sntwitter.TwitterSearchScraper(f'from:{username}').get_items() # invoke the scrapper\n",
    "    tweets = itertools.islice(tweets,n_tweets) # stopped when the count reached\n",
    "    tweets = itertools.takewhile(lambda t:t.date>=start_date, tweets) # stop when date passed\n",
    "    tweets = map(lambda t: (username,)+tuple(getattr(t,a) for a in attributes),tweets) # keep only attributes needed\n",
    "    pd.DataFrame(tweets).to_csv(f'../data/futurists_tweets/{username}.csv')\n",
    "    logger.info(username)\n",
    "    return tweets\n",
    "\n",
    "\n",
    "# a list of accounts to scrape\n",
    "user_names = pd.read_csv('../data/futurists.csv')['Twitter'].to_list()\n",
    "\n",
    "# parallelise queries for speed ! \n",
    "with mp.Pool(4) as p:\n",
    "    results = p.imap(get_tweets, user_names)\n",
    "    p.close()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mmax_colwidth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m800\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data\u001b[39m=\u001b[39;49mresults,columns\u001b[39m=\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m'\u001b[39;49m,)\u001b[39m+\u001b[39;49mattributes)\n\u001b[1;32m      4\u001b[0m itertools\u001b[39m.\u001b[39mislice([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anticipate/anticipatio/.venv/lib/python3.10/site-packages/pandas/core/frame.py:781\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[39m# For data is scalar\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 781\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataFrame constructor not properly called!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    783\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[1;32m    784\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(columns)\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 800)\n",
    "df = pd.DataFrame(data=results,columns=('user',)+attributes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e97d664ee103394b0533f1ee531435373195263bf8c5b5c10c43c63457b8b388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
