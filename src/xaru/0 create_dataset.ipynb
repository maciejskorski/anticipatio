{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import itertools\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "repo_path = Path('/home/krajda/anticipatio/')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Unique users:400\n",
                        "Unique texts:1200003\n",
                        "Unique posts (timestamp+text): 1458018\n"
                    ]
                }
            ],
            "source": [
                "def open_fn(f):\n",
                "    try:\n",
                "        return pd.read_csv(f, engine='python')\n",
                "    except:\n",
                "        return pd.DataFrame()\n",
                "\n",
                "files = list(\n",
                "    itertools.chain(\n",
                "            Path(repo_path/'data/futurists_kol/data').rglob('*csv'),\n",
                "            Path(repo_path/'data/futurists_rossdawson/data').rglob('*csv')\n",
                "        )\n",
                "    )\n",
                "\n",
                "with open(repo_path / 'data/model_input_files_order.txt','tr') as f:\n",
                "    fpaths = f.readlines()\n",
                "    fpaths = [line.strip() for line in fpaths]\n",
                "\n",
                "files_shuffled = pd.Series(index=[f.name for f in files], data=files)\n",
                "files = files_shuffled.loc[fpaths].to_list()\n",
                "\n",
                "tweets = pd.concat(map(open_fn, files))\n",
                "\n",
                "tweets.columns = ['index','user','timestamp','url','txt']\n",
                "tweets.reset_index(drop=True,inplace=True)\n",
                "\n",
                "tweets['txt'] = tweets['txt'].astype(str)\n",
                "tweets['user']=tweets['user'].str.replace('@','').str.strip().str.lower()\n",
                "tweets['timestamp'] = pd.to_datetime(tweets['timestamp'])\n",
                "\n",
                "tweets = tweets.drop(columns=['index'])\n",
                "\n",
                "tweets.drop_duplicates(inplace=True,subset=['timestamp','txt'])\n",
                "tweets.reset_index(inplace=True,drop=True)\n",
                "\n",
                "print('Unique users:{}\\nUnique texts:{}'.format(tweets['user'].nunique(),tweets['txt'].nunique()))\n",
                "docs = tweets['txt'].tolist()\n",
                "\n",
                "print('Unique posts (timestamp+text): {}'.format(len(docs)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TEXT CLEANING"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cleaning tweets... html unescape\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/1458018 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1458018/1458018 [00:00<00:00, 1489959.58it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cleaning tweets... removing regex # 0\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1458018/1458018 [00:04<00:00, 304415.50it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cleaning tweets... removing regex # 1\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1458018/1458018 [00:15<00:00, 96110.76it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cleaning tweets... removing regex # 2\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1458018/1458018 [00:13<00:00, 106689.20it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Cleaning tweets... removing RTs\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1458018/1458018 [00:00<00:00, 1999878.59it/s]\n"
                    ]
                }
            ],
            "source": [
                "import html\n",
                "import re\n",
                "from tqdm import tqdm\n",
                "\n",
                "regexes = [\n",
                "    re.compile(\n",
                "        r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,\"\n",
                "        r\"}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(\"\n",
                "        r\"?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\"\n",
                "    ), # URLS\n",
                "    re.compile(r\"\\S*@\\S*\\..\\S*\"), # EMAILS\n",
                "    re.compile(r\"(?<=\\s)(@[\\w\\-\\.]+)(?=[\\:\\,\\.\\!\\?\\s]?)|^(@[\\w\\-\\.]+)(?=[\\:\\,\\.\\!\\?\\s]?)\"), # HANDLES\n",
                "]\n",
                "\n",
                "docs = tweets['txt'].tolist()\n",
                "\n",
                "print('Cleaning tweets... html unescape')\n",
                "docs = [html.unescape(t) for t in tqdm(docs)]\n",
                "\n",
                "for regex in regexes:\n",
                "    print('Cleaning tweets... removing regex #', regexes.index(regex))\n",
                "    docs = [regex.sub('', t) for t in tqdm(docs)]\n",
                "\n",
                "print('Cleaning tweets... removing RTs')\n",
                "docs = [t[4:] if t.startswith('RT :') else t for t in tqdm(docs)]\n",
                "\n",
                "tweets['original_text'] = tweets['txt']\n",
                "tweets['txt'] = docs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.to_pickle(tweets,repo_path / 'data/final.pkl')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "3.9.16",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
