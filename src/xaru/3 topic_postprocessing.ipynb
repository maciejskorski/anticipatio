{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "repo_path = Path('/home/krajda/anticipatio/')\n",
    "\n",
    "topic_model = BERTopic.load(repo_path / 'models/pca10_kmeans200_cv.pkl')\n",
    "tweets = pd.read_pickle(repo_path / 'data/final.pkl')\n",
    "docs = tweets['txt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "\n",
    "representative_docs = topic_model.representative_docs_\n",
    "\n",
    "representative_words = []\n",
    "\n",
    "for _, x in topic_model.topic_representations_.items():\n",
    "    inner = []\n",
    "    for w, _ in x:\n",
    "        inner.append(w)\n",
    "    representative_words.append(inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info['Share [%]'] = topic_info['Count'] / topic_info['Count'].sum()*100\n",
    "topic_info['Share [%]'] = topic_info['Share [%]'].round(2)\n",
    "topic_info['Share [%]']\n",
    "\n",
    "topic_info['Relevant words'] = representative_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def get_gpt4_answer(question: str, model_name:str = \"gpt-4-1106-preview\"):\n",
    "    prompt = \"{{ question }}\"\n",
    "    template = ChatPromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        messages=[\n",
    "            SystemMessage(content=\"\"),\n",
    "            HumanMessagePromptTemplate(\n",
    "                prompt=PromptTemplate(\n",
    "                    template=prompt, template_format=\"jinja2\", input_variables=[\"question\"]\n",
    "                )\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(model_name=model_name, temperature=0.1)\n",
    "    llm_chain = LLMChain(llm=llm, prompt=template)\n",
    "    output = llm_chain({\"question\": question})\n",
    "    \n",
    "    return output[\"text\"]\n",
    "\n",
    "\n",
    "answers = {}\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    prompt = f\"\"\"You are an Data Analyst within Social Media Department of analitycal company. You analyze internet discussion about coherent topic and provide meaningful descriptions and labels to the topic.\n",
    "\n",
    "        The topic is described by the following keywords: {representative_words[i]}\n",
    "\n",
    "        This topic has also 3 most representative documents:\n",
    "        - {representative_docs[i][0]}\n",
    "        - {representative_docs[i][1]}\n",
    "        - {representative_docs[i][2]}\n",
    "\n",
    "        Based on the information above, extract a short topic description and a topic label.\n",
    "        Return results as a JSON array with two fields:\n",
    "        {{\n",
    "        'topic_description': '...',\n",
    "        'topic_label': '...'\n",
    "        }}\n",
    "        \"\"\"\n",
    "    \n",
    "    try:\n",
    "            \n",
    "        raw_answer = get_gpt4_answer(prompt)\n",
    "        answers[i] = {'raw': raw_answer}\n",
    "        answer = json.loads(raw_answer)\n",
    "        \n",
    "        answers[i]['desc'] = answer['topic_description']\n",
    "        answers[i]['label'] = answer['topic_label']\n",
    "    \n",
    "    except:\n",
    "        print(i)\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(answers, open(repo_path / 'data/labels.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = []\n",
    "errors = {}\n",
    "for i, x in answers.items():\n",
    "    iss = x['raw'].index('```json\\n')\n",
    "    ie = x['raw'].index('\\n```', iss)\n",
    "    \n",
    "    try:\n",
    "        formatted.append(json.loads(x['raw'][iss+8:ie].replace('\\n', '').replace('    ', '')))\n",
    "    except:\n",
    "        formatted.append({'topic_description': '', 'topic_label': ''})\n",
    "        errors[i] = x['raw'][iss+8:ie].replace('\\n', '').replace('    ', '')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted[56]['topic_description']= 'Discussion surrounding emerging blockchain technologies, focusing on Web3 innovations, NFTs, and potential updates or versions indicated by the numbers.'\n",
    "formatted[56]['topic_label']= 'Blockchain Technology & Web3'\n",
    "\n",
    "formatted[69]['topic_description']= 'Online social media interactions and expressions of gratitude or requests for information, characterized by the use of internet shorthand and conversational phrases.'\n",
    "formatted[69]['topic_label']= 'Social Media Communication'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(formatted)\n",
    "\n",
    "topic_info['Label'] = df['topic_label']\n",
    "topic_info['Description'] = df['topic_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info.to_csv(repo_path / 'data/topic_info.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
