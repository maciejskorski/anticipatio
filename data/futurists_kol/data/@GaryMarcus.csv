,0,1,2,3
0,@GaryMarcus,2023-02-16 15:02:28+00:00,https://twitter.com/GaryMarcus/status/1626235569717268486,"@Nabil_Alouani_ @bworley @nytimes it is totally overattribution and at same time scary, because some people will harm themselves or others as a result. 

see this that I just posted

https://t.co/HZYJYaxQuK"
1,@GaryMarcus,2023-02-16 15:01:05+00:00,https://twitter.com/GaryMarcus/status/1626235222953185282,"I‚Äôm scared.  You should  be, too. #GPT3 #Bing #TheNewAI

https://t.co/HZYJYaxQuK"
2,@GaryMarcus,2023-02-16 14:20:46+00:00,https://twitter.com/GaryMarcus/status/1626225073689620483,@ChrSzegedy @ylecun not as hard it used to be? ü§£
3,@GaryMarcus,2023-02-16 07:26:58+00:00,https://twitter.com/GaryMarcus/status/1626120937660899328,Similar conclusions from LessWrong: https://t.co/S17AsNTs63
4,@GaryMarcus,2023-02-16 07:07:12+00:00,https://twitter.com/GaryMarcus/status/1626115965779066880,Bigger models are more fluent but not more truthful: the dinosaur civilization edition
5,@GaryMarcus,2023-02-16 02:47:13+00:00,https://twitter.com/GaryMarcus/status/1626050539279745024,"Bing‚Äôs terrible, horrible, no good week
https://t.co/CWpdhebbk9"
6,@GaryMarcus,2023-02-16 02:07:43+00:00,https://twitter.com/GaryMarcus/status/1626040595696459776,"Holy crap - at this rate Bing might not make it to a truss of lettuce:

https://t.co/jyoRTNNSqM"
7,@GaryMarcus,2023-02-16 02:05:40+00:00,https://twitter.com/GaryMarcus/status/1626040080161976320,"Bing lied about me, but that doesn‚Äôt seem to be the worst of its recent sins."
8,@GaryMarcus,2023-02-16 01:03:32+00:00,https://twitter.com/GaryMarcus/status/1626024444224499712,"What I actually said, Bing, is quite the opposite

(2/2) https://t.co/jiHlgDrehb"
9,@GaryMarcus,2023-02-16 01:03:30+00:00,https://twitter.com/GaryMarcus/status/1626024438876737536,"Nice try, Bing, but I never said you were more accurate and reliable than Bard.   

With or without references, you made that up.  

(1/2)"
10,@GaryMarcus,2023-02-15 21:58:33+00:00,https://twitter.com/GaryMarcus/status/1625977894630555660,If only someone could have seen this coming üôÑ
11,@GaryMarcus,2023-02-15 21:47:38+00:00,https://twitter.com/GaryMarcus/status/1625975145675517953,Having a great day in LA! https://t.co/W68z2YYZyU
12,@GaryMarcus,2023-02-15 17:52:44+00:00,https://twitter.com/GaryMarcus/status/1625916031733747713,the fabulous Missy Cummings @nytimes!
13,@GaryMarcus,2023-02-15 07:53:24+00:00,https://twitter.com/GaryMarcus/status/1625765204712894464,No
14,@GaryMarcus,2023-02-15 01:50:18+00:00,https://twitter.com/GaryMarcus/status/1625673825454272514,@AnnijaBolton stay tuned for answers to at least some of them :)
15,@GaryMarcus,2023-02-14 18:30:19+00:00,https://twitter.com/GaryMarcus/status/1625563101465837568,Also üíØ
16,@GaryMarcus,2023-02-14 16:00:24+00:00,https://twitter.com/GaryMarcus/status/1625525375135809536,"Oh how I love thee, ChatGPT
Let me count the ways https://t.co/ZkAYZ9peCe"
17,@GaryMarcus,2023-02-14 04:15:03+00:00,https://twitter.com/GaryMarcus/status/1625347864913403904,"@RitaJKing @Grady_Booch No words, only sympathy"
18,@GaryMarcus,2023-02-14 04:13:06+00:00,https://twitter.com/GaryMarcus/status/1625347374444068865,Nobody should ever have to get a text like this.
19,@GaryMarcus,2023-02-14 04:09:26+00:00,https://twitter.com/GaryMarcus/status/1625346452749946881,@RitaJKing @Grady_Booch Hope everything turns out ok.
20,@GaryMarcus,2023-02-14 02:41:25+00:00,https://twitter.com/GaryMarcus/status/1625324303511326720,Loving the questions people are asking here. üôè
21,@GaryMarcus,2023-02-14 02:26:06+00:00,https://twitter.com/GaryMarcus/status/1625320448388112384,"A sample of what other people are saying about you, @ylecun. Just today. 

It‚Äôs fine to change your mind, but not to rewrite the past. https://t.co/t6pqYT7Gof"
22,@GaryMarcus,2023-02-14 02:09:01+00:00,https://twitter.com/GaryMarcus/status/1625316150677745665,about that Microsoft demo
23,@GaryMarcus,2023-02-14 01:17:45+00:00,https://twitter.com/GaryMarcus/status/1625303245450264576,ask me anything about AI and the human mind; I will use some of your questions in something I am recording.
24,@GaryMarcus,2023-02-13 23:07:28+00:00,https://twitter.com/GaryMarcus/status/1625270461004414976,What will really count in AI in the end? w @ProfNoahGian @TIME https://t.co/12KfZjH21m
25,@GaryMarcus,2023-02-13 22:51:39+00:00,https://twitter.com/GaryMarcus/status/1625266478709899264,@ihorgowda @pomeranian99
26,@GaryMarcus,2023-02-13 18:32:18+00:00,https://twitter.com/GaryMarcus/status/1625201211933880322,"@DrJimFan @chrisdonahuey Wii Music did something similar, probably without ML in 2008, https://t.co/suw9TSIrDN, and algorithmic composition has a long history. Pat Metheny built a whole tour around it : https://t.co/ONLkfJb648"
27,@GaryMarcus,2023-02-13 18:15:00+00:00,https://twitter.com/GaryMarcus/status/1625196860183875593,@sentientist @Aella_Girl And it‚Äôs how you motivate that the study you are doing moves beyond the prior literature in important ways.
28,@GaryMarcus,2023-02-13 18:03:15+00:00,https://twitter.com/GaryMarcus/status/1625193902126018560,"@Zergylord Likely true for LLMs, possibly irrelevant for AGI."
29,@GaryMarcus,2023-02-13 18:01:15+00:00,https://twitter.com/GaryMarcus/status/1625193399736483840,"@postdiscipline @MelMitchell1 @wooldridgemike At a technical level @ch402‚Äôs work is fascinating. At an intuitive level, several of my recent substack essays are very relevant."
30,@GaryMarcus,2023-02-13 15:31:59+00:00,https://twitter.com/GaryMarcus/status/1625155836078325762,"I promise to stop writing so much! But I‚Äôve got one more for you later today. This time, @TIME, with @ProfNoahGian :)"
31,@GaryMarcus,2023-02-13 15:02:03+00:00,https://twitter.com/GaryMarcus/status/1625148302043000832,"@atomless prebuttal, since I wrote it earlier anticipating the historical revisionism"
32,@GaryMarcus,2023-02-13 14:12:12+00:00,https://twitter.com/GaryMarcus/status/1625135754149040130,"@ylecun This thread is a lie. In 2019, you sang a very different tune, and repeatedly attacked me for saying similar things. 

I have provided receipts: https://t.co/vwjyX7NRI8

You have not responded.

You are rewriting history."
33,@GaryMarcus,2023-02-13 13:56:28+00:00,https://twitter.com/GaryMarcus/status/1625131794952761349,"From Turing Award winner (2018) to A-list gaslighter in five years. 

What a fall from grace."
34,@GaryMarcus,2023-02-13 13:52:34+00:00,https://twitter.com/GaryMarcus/status/1625130816673140736,"‚ÄúLeCun doing some A-list gaslighting here‚Äù. 

Congrats @ylecun, at least you are doing something right. https://t.co/eMe2LRr25N"
35,@GaryMarcus,2023-02-13 13:44:43+00:00,https://twitter.com/GaryMarcus/status/1625128839151067136,"As I said, everybody sees what you are doing, @ylecun."
36,@GaryMarcus,2023-02-13 04:35:37+00:00,https://twitter.com/GaryMarcus/status/1624990655989837824,"@oFFMetaSweat @sama @Grady_Booch @ylecun hey look who just joined our team, @Grady_Booch ü§£"
37,@GaryMarcus,2023-02-13 04:29:16+00:00,https://twitter.com/GaryMarcus/status/1624989058001944576,"From the dude who unfollowed @ylecun for sounding like me, after tweeting ‚ÄúChatGPT is incredibly limited, but good enough at some things to create a misleading impression of greatness‚Ä¶.we have lots of work to do on robustness and truthfulness.‚Äù 

Game on."
38,@GaryMarcus,2023-02-13 04:22:25+00:00,https://twitter.com/GaryMarcus/status/1624987333522239489,"@repligate @reality__gamer are you sure it never made illegal moves? did you add additional constraint? tbh I am skeptical, given what i have seen."
39,@GaryMarcus,2023-02-13 03:26:41+00:00,https://twitter.com/GaryMarcus/status/1624973308063272960,@RichardSocher @IAmSamFin Safe to assume there is some hybrid AI there? A pure LLM presumably isn‚Äôt uptodate enough‚Ä¶
40,@GaryMarcus,2023-02-13 02:54:19+00:00,https://twitter.com/GaryMarcus/status/1624965159776288768,@JeffSpies @ylecun Or both?
41,@GaryMarcus,2023-02-13 02:52:03+00:00,https://twitter.com/GaryMarcus/status/1624964590458277889,Source: https://t.co/7uZsIUAdXX
42,@GaryMarcus,2023-02-13 02:52:02+00:00,https://twitter.com/GaryMarcus/status/1624964586045833219,Literally the most prescient prediction I ever made. https://t.co/cSbQFy7CPu
43,@GaryMarcus,2023-02-13 02:34:58+00:00,https://twitter.com/GaryMarcus/status/1624960291187589120,"In case you forgot the intellectual history, @ylecun, it is all summed up here:

https://t.co/4sYsA83JdF"
44,@GaryMarcus,2023-02-13 02:34:57+00:00,https://twitter.com/GaryMarcus/status/1624960286385111042,"Everybody else sees it, @ylecun.  

Do you entirely lack the courage and grace to acknowledge the ideas of others? https://t.co/buoV2hi7ux"
45,@GaryMarcus,2023-02-13 02:34:55+00:00,https://twitter.com/GaryMarcus/status/1624960277107343362,"ü§ØAre you joking, @ylecun? People are starting to agree with *your* statements about LLMs? 

Would it kill you to acknowledge that I was making the same arguments for years? 

To show the tiniest fiber of integrity? To not pretend that you invented ideas you once mocked?

1/3"
46,@GaryMarcus,2023-02-13 02:19:20+00:00,https://twitter.com/GaryMarcus/status/1624956357718970368,An honor to be channeled by @pomeranian99!
47,@GaryMarcus,2023-02-13 01:46:24+00:00,https://twitter.com/GaryMarcus/status/1624948068318871552,"@AAlmeidaAuthor Not so much, if the cases they tested appear many times in the training set"
48,@GaryMarcus,2023-02-13 01:28:12+00:00,https://twitter.com/GaryMarcus/status/1624943490873577472,Exactly so. This is the core of why people shouldn‚Äôt take that new LLM / Theory of Mind paper seriously.
49,@GaryMarcus,2023-02-12 23:04:26+00:00,https://twitter.com/GaryMarcus/status/1624907310177959937,"@shiraeis I will discuss,  next week perhaps. It is not persuasive."
50,@GaryMarcus,2023-02-12 20:45:56+00:00,https://twitter.com/GaryMarcus/status/1624872452550705152,@jeremys @noUpside @matthewstoller eg https://t.co/lqo1spYPBl
51,@GaryMarcus,2023-02-12 18:32:23+00:00,https://twitter.com/GaryMarcus/status/1624838846629421056,@denny_zhou Or at least to AGI
52,@GaryMarcus,2023-02-12 18:29:11+00:00,https://twitter.com/GaryMarcus/status/1624838038286385152,@wavyphd @SashaMTL @Kdawg5000 I was so torn between that one and Sasha‚Äôs and hers won by a hair because I though the prompt worked better with the text. thanks so much to you both!
53,@GaryMarcus,2023-02-12 17:46:01+00:00,https://twitter.com/GaryMarcus/status/1624827178998431744,thanks for your help @apage43 @noUpside @SashaMTL @CriticalAI
54,@GaryMarcus,2023-02-12 17:37:08+00:00,https://twitter.com/GaryMarcus/status/1624824942692016129,"Gross! How sewers of lies could spell the end of web search.

https://t.co/p8HXTXde1i"
55,@GaryMarcus,2023-02-12 15:51:13+00:00,https://twitter.com/GaryMarcus/status/1624798286115917824,"Talking truth, bullshit, and AI ‚Äî with VC legend and all around polymath @wolfejosh and @DannyCrichton @LuxCapitol"
56,@GaryMarcus,2023-02-12 15:33:41+00:00,https://twitter.com/GaryMarcus/status/1624793875037708289,"@ChristinaBehme4 @noUpside @ProfNoahGian @DG_Rand @sinanaral @erikbryn @chafkin Could be any of these, but eg stuff just to get eyeballs to sell ads to"
57,@GaryMarcus,2023-02-12 15:32:48+00:00,https://twitter.com/GaryMarcus/status/1624793651523235840,@apage43 @ChristinaBehme4 @noUpside @ProfNoahGian @DG_Rand @sinanaral @erikbryn @chafkin This is exactly what I have in mind - has anybody written about this?
58,@GaryMarcus,2023-02-12 15:31:20+00:00,https://twitter.com/GaryMarcus/status/1624793284051873794,"Or ‚Äúsewer of lies‚Äù, ‚Äúsea of lies‚Äù etc"
59,@GaryMarcus,2023-02-12 15:28:55+00:00,https://twitter.com/GaryMarcus/status/1624792674355261440,"Hivemind cc @Kdawg5000 @SashaMTL, revised art request: how about ‚Äúgoogle drowning in a cesspool of lies‚Äù?"
60,@GaryMarcus,2023-02-12 15:00:17+00:00,https://twitter.com/GaryMarcus/status/1624785466909425664,"dear hivemind,  
- is there a term for a bunch of fake websites that mutually reinforce each other in order to increase their search ranking?
- are there any studies or articles about this? 
@noUpside @ProfNoahGian @DG_Rand @sinanaral @erikbryn @chafkin @lorakolodny"
61,@GaryMarcus,2023-02-12 14:43:33+00:00,https://twitter.com/GaryMarcus/status/1624781256964833281,Why Lex (‚Äúwe should listen to people who disagree‚Äù) Fridman blocked me üôÑ
62,@GaryMarcus,2023-02-12 14:40:13+00:00,https://twitter.com/GaryMarcus/status/1624780419760803841,üíØ
63,@GaryMarcus,2023-02-12 06:01:52+00:00,https://twitter.com/GaryMarcus/status/1624649972586258433,LLMs will never solve the alignment problem by themselves.
64,@GaryMarcus,2023-02-12 05:59:38+00:00,https://twitter.com/GaryMarcus/status/1624649410234974208,"@DrTBehrens About two years ago I questioned Lex‚Äôs assertion that Austin was about to become the AI capital of the world. 

It hasn‚Äôt."
65,@GaryMarcus,2023-02-12 03:50:56+00:00,https://twitter.com/GaryMarcus/status/1624617022494752768,@CastPush That‚Äôs interesting! How did you make it? (Prompt? System?)
66,@GaryMarcus,2023-02-12 00:46:59+00:00,https://twitter.com/GaryMarcus/status/1624570729349124096,Good question: If you can‚Äôt keep ChatGPT from cheating at chess why the heck do you think scaling LLM is going to solve the alignment problem?
67,@GaryMarcus,2023-02-12 00:11:34+00:00,https://twitter.com/GaryMarcus/status/1624561814003683333,"@eazy_boris @MeghanEMurphy @lexfridman Well, no. He had me on his show, Sep 2019, and then he blocked me, for a totally trivial reason. And showed zero interest in discussing it.  

He doesn‚Äôt have intelligent discussions with people who disagree them (I do, all the time). He blocks them, by the bushel."
68,@GaryMarcus,2023-02-11 23:50:18+00:00,https://twitter.com/GaryMarcus/status/1624556465896976384,most definitely https://t.co/0uoBHk2h7h
69,@GaryMarcus,2023-02-11 23:30:50+00:00,https://twitter.com/GaryMarcus/status/1624551566874411008,"Hive mind, would love a generative illustration for my next essay, capturing the theme ‚ÄúGoogle crushed by lies‚Äù"
70,@GaryMarcus,2023-02-11 23:13:42+00:00,https://twitter.com/GaryMarcus/status/1624547251438903303,"Fitting coda to this morning‚Äôs essay?

ChatGPT brazenly ignoring the rules of chess, h/t @annieduke https://t.co/WEyWr2n2nc"
71,@GaryMarcus,2023-02-11 19:52:28+00:00,https://twitter.com/GaryMarcus/status/1624496610800721920,"Hive mind: What are the most recent analyses on the costs of compute, in terms $ and energy, for SOTA LLMs, during training and at inference time?"
72,@GaryMarcus,2023-02-11 17:40:02+00:00,https://twitter.com/GaryMarcus/status/1624463283217649664,"Nightmare on LLM Street!

Why I am scared of how ChatGPT might be misused, and why maybe you should be, too.

https://t.co/soT4otoDnF

üëá https://t.co/qDsB1qAOi7"
73,@GaryMarcus,2023-02-11 13:08:39+00:00,https://twitter.com/GaryMarcus/status/1624394988485513217,@RemivanTrijp Hmm fair point. Maybe: https://t.co/pqEVmfZHvS
74,@GaryMarcus,2023-02-11 07:03:20+00:00,https://twitter.com/GaryMarcus/status/1624303052525297664,@tweeterholmes I think is the winner but that just might be the runner-up: https://t.co/7v6OAAX4vG
75,@GaryMarcus,2023-02-11 06:53:50+00:00,https://twitter.com/GaryMarcus/status/1624300660912193538,@teh_aimee but it‚Äôs so dark and it almost needs a bit of cute and catchy to balance things out..
76,@GaryMarcus,2023-02-11 06:52:28+00:00,https://twitter.com/GaryMarcus/status/1624300317876813825,@teh_aimee it‚Äôs pretty bad..
77,@GaryMarcus,2023-02-11 06:49:13+00:00,https://twitter.com/GaryMarcus/status/1624299502063742977,Can anyone beat this? https://t.co/T3OaI274Xe
78,@GaryMarcus,2023-02-11 06:47:22+00:00,https://twitter.com/GaryMarcus/status/1624299034071662592,"@JeffSpies @said_mitch leaning this way, thanks to your collective help: https://t.co/RPhmPjg5du"
79,@GaryMarcus,2023-02-11 06:32:53+00:00,https://twitter.com/GaryMarcus/status/1624295387984166913,"@flabaster If you really want an answer to your question about why I am so concerned by GPT, read my Substack in the morning. 

Am in shock at what ChatGPT is still capable of, even after feedback from almost 100 million users. Almost every example I include is from this week."
80,@GaryMarcus,2023-02-11 06:05:38+00:00,https://twitter.com/GaryMarcus/status/1624288532968935425,"Hivemind, I‚Äôve uncovered some really bad stuff, and need a sticky title to help get the word out. 

Please help with a title:

Little Shop of ChatGPT Horrors

Inside the Heart of ChatGPT‚Äôs Darkness

[Essays posts 8am PT at https://t.co/8ir1xKenr6]"
81,@GaryMarcus,2023-02-11 01:15:40+00:00,https://twitter.com/GaryMarcus/status/1624215560882987011,"Saturday at 8am PT, at https://t.co/8ir1xKdPBy: Inside ChatGPT‚Äôs Heart of Darkness"
82,@GaryMarcus,2023-02-10 04:57:49+00:00,https://twitter.com/GaryMarcus/status/1623909075808563200,"I am sorry, Sydney, I am afraid I can do that."
83,@GaryMarcus,2023-02-10 02:44:08+00:00,https://twitter.com/GaryMarcus/status/1623875435233792000,"@j_bindra @dioscuri If Big Tech does address the problem, it will be neurosymbolicly, not through pure LLMs. Already MSFT is heading that way, to include recent news without constant retraining.

note that pure focus on AI didn‚Äôt solve driverless cars, this far, after $100B and many years invested"
84,@GaryMarcus,2023-02-10 02:40:40+00:00,https://twitter.com/GaryMarcus/status/1623874562311225347,@jackclarkSF @Miles_Brundage @YejinChoinka @_dieuwke_ @Zergylord @VeredShwartz
85,@GaryMarcus,2023-02-10 02:35:51+00:00,https://twitter.com/GaryMarcus/status/1623873348362174464,"üÜïMaking benchmarks to measure #commonsense is hard. Really hard. Few are truly satisfactory, which is perhaps why there more than 100 of them.

Important and deep dive into the challenges, by @ErnestSDavis 

https://t.co/VRx4pmNe3T"
86,@GaryMarcus,2023-02-09 20:11:46+00:00,https://twitter.com/GaryMarcus/status/1623776691276636160,"@rgblong They solved the exam but not common sense, not even close. I will have a paper about this soon."
87,@GaryMarcus,2023-02-09 19:40:56+00:00,https://twitter.com/GaryMarcus/status/1623768931927474176,"@rgblong The problem is not the training objective, it‚Äôs the lack of internal cognitive models that they can reason over. But it is lot of expect that such models would emerge simply from sequence prediction."
88,@GaryMarcus,2023-02-09 16:30:46+00:00,https://twitter.com/GaryMarcus/status/1623721074700726277,"I wanted AGI, I got 140 plagiarized characters."
89,@GaryMarcus,2023-02-09 16:25:23+00:00,https://twitter.com/GaryMarcus/status/1623719719634341889,"‚Äúon the @garymarcus @ylecun wagon‚Äù. 

Life sure is full of surprises!"
90,@GaryMarcus,2023-02-09 14:03:14+00:00,https://twitter.com/GaryMarcus/status/1623683946553946114,Overheard https://t.co/wshBqmeDKT
91,@GaryMarcus,2023-02-09 05:33:11+00:00,https://twitter.com/GaryMarcus/status/1623555588209926144,B won:
92,@GaryMarcus,2023-02-09 05:31:34+00:00,https://twitter.com/GaryMarcus/status/1623555182486519814,"@yoavgo Ha! good point! Maybe the narrative is supposed to be: MSFT is the underdog, vs Slow Titan? 

(of course the allegedly slow titan got out a knockoff lickety-split)

At least I noted the asymmetry ü§£"
93,@GaryMarcus,2023-02-09 05:10:44+00:00,https://twitter.com/GaryMarcus/status/1623549939388403712,"Oops! How Google bombed, while doing pretty much exactly the same thing as Microsoft did, with similar results

https://t.co/aVO13uL6i4 https://t.co/CUK7LAc5HH"
94,@GaryMarcus,2023-02-09 04:29:18+00:00,https://twitter.com/GaryMarcus/status/1623539511606284289,"Pick a title for my next Substack:
A: A Day that will Live in AI Infamy
B: Oops! How Google bombed, while doing pretty much exactly the same thing as Microsoft did, with similar results"
95,@GaryMarcus,2023-02-08 20:42:53+00:00,https://twitter.com/GaryMarcus/status/1623422134709108736,Taking a birthday break! https://t.co/o34YOwr727
96,@GaryMarcus,2023-02-08 20:42:02+00:00,https://twitter.com/GaryMarcus/status/1623421922586378247,"I call bullshit. It totally depends on the task. pretty graphics, tho."
97,@GaryMarcus,2023-02-08 17:04:57+00:00,https://twitter.com/GaryMarcus/status/1623367290661089281,A fitting welcome gift from our new machine overlords.
98,@GaryMarcus,2023-02-08 16:31:21+00:00,https://twitter.com/GaryMarcus/status/1623358834613039104,"@kelseyhightower Good question! In brief: symbolic just means applying functions that are defined to work algebraically over variables, as opposed to tuning network weights. 

No commitment to hand-wiring, though it often is, but eg Inductive Logic Programming is symbolic w learning."
99,@GaryMarcus,2023-02-08 14:48:37+00:00,https://twitter.com/GaryMarcus/status/1623332980445052930,"speculation: when Bing‚Äôs new search engine answers current questions (eg re today‚Äôs news), it hasn‚Äôt retrained the LLM, it has supplement the neural network with (neuro)symbolic techniques.

Nobody is saying it, but neurosymbolic AI is about to be deployed at massive scale."
100,@GaryMarcus,2023-02-08 14:02:17+00:00,https://twitter.com/GaryMarcus/status/1623321320896491521,ü§£ https://t.co/Iy2NJ2kjUx
101,@GaryMarcus,2023-02-08 01:27:51+00:00,https://twitter.com/GaryMarcus/status/1623131462286606337,https://t.co/FdlbN6WFrq
102,@GaryMarcus,2023-02-08 01:15:04+00:00,https://twitter.com/GaryMarcus/status/1623128243254751232,@Yonatan_Jaku @pmddomingos Today‚Äôs news: https://t.co/PpEXUdvou5
103,@GaryMarcus,2023-02-08 01:13:23+00:00,https://twitter.com/GaryMarcus/status/1623127821211287555,"Read the news, Pedro. The flood has just begun: https://t.co/gPlHXSqoaB"
104,@GaryMarcus,2023-02-07 20:53:20+00:00,https://twitter.com/GaryMarcus/status/1623062377104289795,"Oh dear, @twitter ‚ÄúNo. He‚Äù ain‚Äôt a legit trend, just a string of characters with a zillion unrelated referents. Your AI needs work.

OTOH, @paulbloomatyale, *Big He ü§£ https://t.co/KHcygOg5oq"
105,@GaryMarcus,2023-02-07 20:23:15+00:00,https://twitter.com/GaryMarcus/status/1623054806716940290,@hackylawyER please dm or followback @hackylawyER
106,@GaryMarcus,2023-02-07 19:24:07+00:00,https://twitter.com/GaryMarcus/status/1623039925636730880,@Nabil_Alouani_ indeed; @nntaleb please DM; we have multiple things to talk about
107,@GaryMarcus,2023-02-07 19:13:04+00:00,https://twitter.com/GaryMarcus/status/1623037143219322880,"@hackylawyER exactly, the cost of bullshit is going to zero. double plus ungood."
108,@GaryMarcus,2023-02-07 17:34:26+00:00,https://twitter.com/GaryMarcus/status/1623012323962286081,Thanks; some LLM policy suggestions here: https://t.co/QCAInsodQy
109,@GaryMarcus,2023-02-07 17:12:35+00:00,https://twitter.com/GaryMarcus/status/1623006825066143744,"Clearly worth the risks to trust, democracy, education, and public health, then."
110,@GaryMarcus,2023-02-07 15:50:00+00:00,https://twitter.com/GaryMarcus/status/1622986039639031808,"GPT didn‚Äôt invent the art of bullshit, it just scaled it"
111,@GaryMarcus,2023-02-07 15:10:34+00:00,https://twitter.com/GaryMarcus/status/1622976118977597440,@HiFromMichaelV not so confident myself tbh; seems like a very volatile moment.
112,@GaryMarcus,2023-02-07 15:09:56+00:00,https://twitter.com/GaryMarcus/status/1622975958021193729,"üÜïPNAS study: ‚Äúsmall perturbations to vignette-based tasks can lead GPT-3 vastly astray,.. it shows no signatures of directed exploration, and‚Ä¶fails miserably in a causal reasoning task‚Äù‚Äîconfirming what @yudapearl &amp; I have been saying for years.

https://t.co/znEWLeWIpi"
113,@GaryMarcus,2023-02-07 14:27:47+00:00,https://twitter.com/GaryMarcus/status/1622965351184232448,@Franksntra3 @erikengheim i have also been saying this for a while and fully agree
114,@GaryMarcus,2023-02-07 14:12:12+00:00,https://twitter.com/GaryMarcus/status/1622961428973101057,"Fabulous. This is exactly what schools should be doing right now! (Tech bros should also take note.)
https://t.co/AJtW9Sjbzv"
115,@GaryMarcus,2023-02-07 14:08:54+00:00,https://twitter.com/GaryMarcus/status/1622960597943078912,"The amount of misinformation being spread around Bill Gates is mindblowing.

He‚Äôs not a perfect human being, nor above criticism, but in the last decade done a hell of a lot for humanity, *far* more than most. 

Almost none of what I read about him here is true."
116,@GaryMarcus,2023-02-07 13:39:42+00:00,https://twitter.com/GaryMarcus/status/1622953248385810439,"@kaalam_ai i noticed all that, too, (and the lack of social media) and remain impressed. what would be the analog for the future from here?"
117,@GaryMarcus,2023-02-07 13:32:40+00:00,https://twitter.com/GaryMarcus/status/1622951479144480770,"@IntuitMachine major miss, yes, but still pretty darn impressive. they also missed the toxicity and polarization that went with the social media."
118,@GaryMarcus,2023-02-07 05:09:07+00:00,https://twitter.com/GaryMarcus/status/1622824759376613377,Amazing. Strikingly good predictions from 1993; doubt anyone today will do as well for 2053.
119,@GaryMarcus,2023-02-07 02:40:46+00:00,https://twitter.com/GaryMarcus/status/1622787426166120448,"üôã‚Äç‚ôÇÔ∏èSerious question, @ylecun: we both agreed on a lot in 2017 and both agree now in 2023 that LLMs are an off-ramp on the road AGI, yet you gave me a hard time in between, saying I was ""mostly wrong"", ""fighting a rearguard action"", etc.

What is it that I was wrong about? https://t.co/6PR5rNwocm"
120,@GaryMarcus,2023-02-07 01:03:44+00:00,https://twitter.com/GaryMarcus/status/1622763006487830528,The people have spoken https://t.co/h8AGLEgfLT
121,@GaryMarcus,2023-02-06 20:39:43+00:00,https://twitter.com/GaryMarcus/status/1622696562936918016,"@jeremys @moskov Fun fact: @tmorello, who started later than many, told me that while he was building his guitar chops, and before he developed his unique voice, he practiced 6-8 hours a day as an adult (while doing an honors degree at Harvard)."
122,@GaryMarcus,2023-02-06 15:03:37+00:00,https://twitter.com/GaryMarcus/status/1622611979209965568,"So much for guardrails

https://t.co/5bdfcewJ5t"
123,@GaryMarcus,2023-02-06 14:22:52+00:00,https://twitter.com/GaryMarcus/status/1622601724459622402,Ha ha. I wrote a whole book about that actually :) [Kluge]
124,@GaryMarcus,2023-02-06 02:47:09+00:00,https://twitter.com/GaryMarcus/status/1622426641631944705,"@guicho271828 @ylecun agree, he‚Äôs been very unclear and possibly inconsistent on those issues"
125,@GaryMarcus,2023-02-06 01:42:28+00:00,https://twitter.com/GaryMarcus/status/1622410365626892289,@guicho271828 @ylecun And even now although he would prefer model based RL to model free he is not all that big a booster of any kind of RL. He has stuck by his cherry on top metaphor for years.
126,@GaryMarcus,2023-02-06 01:39:18+00:00,https://twitter.com/GaryMarcus/status/1622409567941582848,@guicho271828 @ylecun When did he say that? I don‚Äôt remember him ever being keen on model-free RL.
127,@GaryMarcus,2023-02-06 00:53:41+00:00,https://twitter.com/GaryMarcus/status/1622398089553399810,Best explanation of recent @ylecun tweets
128,@GaryMarcus,2023-02-05 23:06:01+00:00,https://twitter.com/GaryMarcus/status/1622370991228997632,I have often made same argument; agree with @ylecun that excessive focus on LLMs may delay HLAI/AGI
129,@GaryMarcus,2023-02-05 20:45:52+00:00,https://twitter.com/GaryMarcus/status/1622335722979233792,"Hey, @youknowwho, we gotta keep our fans happy https://t.co/RGPIOFgpiE"
130,@GaryMarcus,2023-02-05 20:24:19+00:00,https://twitter.com/GaryMarcus/status/1622330299836399616,@ChrSzegedy @ESYudkowsky Whereas many any unreasonable scientist tries to silence anyone engaged in potential refutation
131,@GaryMarcus,2023-02-05 20:07:46+00:00,https://twitter.com/GaryMarcus/status/1622326132766019584,"2023 AAAI Tutorial: Advances in Neuro Symbolic Reasoning, Tuesday Feb 7 by ‚Å¶@PauloShakASU‚Å©  https://t.co/dxkGYJpAAB"
132,@GaryMarcus,2023-02-05 20:04:46+00:00,https://twitter.com/GaryMarcus/status/1622325377988427776,@mlittmancs @mkearnsupenn it‚Äôs for a specific event that has an established format with two well-known speakers.
133,@GaryMarcus,2023-02-05 19:31:51+00:00,https://twitter.com/GaryMarcus/status/1622317094628126720,"@ncooper57 Can you spell that out? my immediate concerns are mainly around text and audio, though definitely fake video w public figures etc surely has risks."
134,@GaryMarcus,2023-02-05 19:17:03+00:00,https://twitter.com/GaryMarcus/status/1622313370128109569,@bennywu45 @elonmusk @teslaownersSV And the harder to debug
135,@GaryMarcus,2023-02-05 19:07:51+00:00,https://twitter.com/GaryMarcus/status/1622311054629036033,"Amazing how many people believe this, even when I have written extensively (even this week!) about agreements going back several  years.  Eg see here 2017 slide https://t.co/KtUH2CKp2E and see long essay on 2022 https://t.co/Odg2QIt39X"
136,@GaryMarcus,2023-02-05 18:38:53+00:00,https://twitter.com/GaryMarcus/status/1622303765033553920,@guysnovelutumba @ylecun @CriticalAI Hardly. I have written plenty about our points of agreement. See eg my last substack piece (@garymarcus is in title) and the one with paradigm shift in the title.
137,@GaryMarcus,2023-02-05 18:37:34+00:00,https://twitter.com/GaryMarcus/status/1622303435537416192,@Inframethod @CriticalAI ü§£ü§£ social media have no effective way of dealing w likely increase in scale
138,@GaryMarcus,2023-02-05 18:33:06+00:00,https://twitter.com/GaryMarcus/status/1622302312332169224,@ylecun @CriticalAI Fully 100% agree.
139,@GaryMarcus,2023-02-05 18:32:47+00:00,https://twitter.com/GaryMarcus/status/1622302231109451776,üíØ
140,@GaryMarcus,2023-02-05 18:30:05+00:00,https://twitter.com/GaryMarcus/status/1622301550118064128,"@CriticalAI @Inframethod @safiyanoble Sent her a note, thanks!"
141,@GaryMarcus,2023-02-05 18:28:46+00:00,https://twitter.com/GaryMarcus/status/1622301222144462848,@IrenaCronin We have become vastly more polarized in last 20 years; not great adaptation
142,@GaryMarcus,2023-02-05 18:24:48+00:00,https://twitter.com/GaryMarcus/status/1622300221287038977,@CriticalAI @Inframethod It may happen but we certainly aren‚Äôt yet prepared
143,@GaryMarcus,2023-02-05 18:23:52+00:00,https://twitter.com/GaryMarcus/status/1622299985575546880,"@IrenaCronin That‚Äôs an empty argument, basically an assertion, without any specifics about how we will adapt and without recognizing or disputing the critical increase in volume"
144,@GaryMarcus,2023-02-05 18:16:18+00:00,https://twitter.com/GaryMarcus/status/1622298083525799937,@IrenaCronin https://t.co/QCAInsodQy
145,@GaryMarcus,2023-02-05 18:03:26+00:00,https://twitter.com/GaryMarcus/status/1622294844722008064,"Resolved #2: Large language models pose a significant potential threat to democracy. 

Question: would anyone eminent in AI care to debate against?"
146,@GaryMarcus,2023-02-05 17:12:25+00:00,https://twitter.com/GaryMarcus/status/1622282004900487168,@ianbicking Mainly just medical malpractice and potential destruction of democracy
147,@GaryMarcus,2023-02-05 17:09:02+00:00,https://twitter.com/GaryMarcus/status/1622281155537158144,"@HiFromMichaelV Significant harm (multiple deaths, spread of fascism, decline of democracy etc). Net is a separate question."
148,@GaryMarcus,2023-02-05 15:38:08+00:00,https://twitter.com/GaryMarcus/status/1622258278440005633,"@vijayasankarv you literally can‚Äôt calculate the net unless you assess the harm; that‚Äôs part of the equation, hence a prerequisite"
149,@GaryMarcus,2023-02-05 15:14:03+00:00,https://twitter.com/GaryMarcus/status/1622252219155496960,"@jim_rutt doubt it. but there is of course the question of net benefits.

@ylecun, before he pivoted to lambasting LLMs, did argue at length in November here on Twitter that he saw no real harm. I don‚Äôt know if he still holds that position."
150,@GaryMarcus,2023-02-05 15:11:17+00:00,https://twitter.com/GaryMarcus/status/1622251521282048003,@garrygolden to save humanity
151,@GaryMarcus,2023-02-05 15:08:21+00:00,https://twitter.com/GaryMarcus/status/1622250782220509184,"Resolved: Large language models are going to cause significant harm.

Question: would anyone eminent in AI care to debate against?"
152,@GaryMarcus,2023-02-05 14:16:33+00:00,https://twitter.com/GaryMarcus/status/1622237747586162688,"@ylecun @yoavgo HL (human level) AI &amp; AGI are two different terms that partly overlap. We don‚Äôt want machines to inherent the worst of human intelligence (confirmation bias, lousy memory, poor arithmetic, etc) but we do want them to have a flexibility &amp; adaptivity that thus far our machines lack"
153,@GaryMarcus,2023-02-05 08:34:13+00:00,https://twitter.com/GaryMarcus/status/1622151596120612866,@pmddomingos https://t.co/AlhtubvOqP
154,@GaryMarcus,2023-02-05 05:18:25+00:00,https://twitter.com/GaryMarcus/status/1622102322481614851,@Kdawg5000 @ylecun!
155,@GaryMarcus,2023-02-05 04:24:57+00:00,https://twitter.com/GaryMarcus/status/1622088868370726913,"A brave, honest, sincere, and thoughtful video about a toxic mix of money, power and gender dynamics in (but presumably not limited to) in the Bay Area tech scene.

If you read the @time article you should watch it. If you didn‚Äôt read the @time article you should watch it."
156,@GaryMarcus,2023-02-05 04:09:00+00:00,https://twitter.com/GaryMarcus/status/1622084854560215041,@adityasood @RepJoeWilson https://t.co/yGUgRNPIoU
157,@GaryMarcus,2023-02-05 04:03:20+00:00,https://twitter.com/GaryMarcus/status/1622083426760421376,@neo4reo Bargaining?
158,@GaryMarcus,2023-02-05 02:47:27+00:00,https://twitter.com/GaryMarcus/status/1622064330744410112,@kareem_carr Conspiracy theories are not the same thing as random errors of binding stuff together that doesn‚Äôt belong. That sort of random confused binding is not something that normally functioning humans typically do. That is not our own (unimpaired) pattern of functioning.
159,@GaryMarcus,2023-02-05 01:56:40+00:00,https://twitter.com/GaryMarcus/status/1622051550062579712,"@kareem_carr hard disagree. Eg when Galactica says that Elon Musk died in a car crash in 2018, in contradiction to its own database, it is making a kind of confabulation that humans do not make. Some of its garbage comes from humans, some does not."
160,@GaryMarcus,2023-02-04 22:14:14+00:00,https://twitter.com/GaryMarcus/status/1621995572432629761,"My Twitter mentions, DMs, and emails all look like this today."
161,@GaryMarcus,2023-02-04 18:41:05+00:00,https://twitter.com/GaryMarcus/status/1621941932992917504,@Grady_Booch @srchvrs See
162,@GaryMarcus,2023-02-04 18:08:51+00:00,https://twitter.com/GaryMarcus/status/1621933818507821056,why wait? I‚Äôm buying!
163,@GaryMarcus,2023-02-04 17:56:36+00:00,https://twitter.com/GaryMarcus/status/1621930738525536256,Who knew this is how the war would end?
164,@GaryMarcus,2023-02-04 17:46:25+00:00,https://twitter.com/GaryMarcus/status/1621928172869799936,@pretendsmarts @jingle__belle Used this here:
165,@GaryMarcus,2023-02-04 17:44:26+00:00,https://twitter.com/GaryMarcus/status/1621927677442797568,Signed book for whoever comes up with the best illustrated version of this meme :)
166,@GaryMarcus,2023-02-04 17:43:31+00:00,https://twitter.com/GaryMarcus/status/1621927443455164417,@YiTayML And see the blog length version!
167,@GaryMarcus,2023-02-04 17:35:14+00:00,https://twitter.com/GaryMarcus/status/1621925361096466433,@srchvrs See also
168,@GaryMarcus,2023-02-04 17:34:03+00:00,https://twitter.com/GaryMarcus/status/1621925064118784008,@alexjc Essay inspired partly by this tweet:
169,@GaryMarcus,2023-02-04 17:15:23+00:00,https://twitter.com/GaryMarcus/status/1621920365214851074,"history and humor, in one morning essay that is all but co-written by @ylecun"
170,@GaryMarcus,2023-02-04 17:10:16+00:00,https://twitter.com/GaryMarcus/status/1621919078930878464,now posted:
171,@GaryMarcus,2023-02-04 17:06:34+00:00,https://twitter.com/GaryMarcus/status/1621918144691597312,"Most people think of @GaryMarcus and @YLeCun as matter and anti-matter (or perhaps the other way around). But that wasn‚Äôt always the case.

This essay was not written by ChatGPT.

https://t.co/KtUH2CKp2E"
172,@GaryMarcus,2023-02-04 15:50:52+00:00,https://twitter.com/GaryMarcus/status/1621899093676269568,"@labenz @ylecun (indeed that‚Äôs the working subtitle: No, this article was not written by ChatGPT)"
173,@GaryMarcus,2023-02-04 15:47:48+00:00,https://twitter.com/GaryMarcus/status/1621898324344475648,"@labenz @ylecun well that‚Äôs part of what‚Äôs funny about the essay; LeCun has outdone ChatGPT, in channelling me."
174,@GaryMarcus,2023-02-04 15:44:07+00:00,https://twitter.com/GaryMarcus/status/1621897397629759488,"Wanted: someone with a good sense of comic tone to edit @garymarcus essay that was accidentally written @ylecun

(seriously! DM if you can help!)"
175,@GaryMarcus,2023-02-04 14:42:46+00:00,https://twitter.com/GaryMarcus/status/1621881956689657856,Who had this on their 2023 bingo card?
176,@GaryMarcus,2023-02-04 00:29:31+00:00,https://twitter.com/GaryMarcus/status/1621667228763713536,"LLMs will help coders, but it won‚Äôt replace them. here‚Äôs a big part of why:"
177,@GaryMarcus,2023-02-04 00:26:03+00:00,https://twitter.com/GaryMarcus/status/1621666356038086656,"Clear thinking about the brain, from @Nancy_Kanwisher. We can all agree that many aspects of brain function require ensembles of neural circuitry, but that doesn‚Äôt mean that individual circuits inherently lack specificity."
178,@GaryMarcus,2023-02-03 22:48:18+00:00,https://twitter.com/GaryMarcus/status/1621641756638052352,"#ChatGPT, if you were a Congress person, which one would you be?"
179,@GaryMarcus,2023-02-03 22:29:48+00:00,https://twitter.com/GaryMarcus/status/1621637104555151360,@kareem_carr Ha. Real statisticians test hypotheses; ML engineers just make shit up ü§£
180,@GaryMarcus,2023-02-03 21:49:30+00:00,https://twitter.com/GaryMarcus/status/1621626961968893952,"What if @nealstephenson‚Äô Diamond Age tutor was suddenly available now, to all, for $20/month, but also regularly made mistakes, all presented with an air of absolute authority?"
181,@GaryMarcus,2023-02-03 21:43:10+00:00,https://twitter.com/GaryMarcus/status/1621625369022562304,"@DrTechlash @zacharylipton @sissicao And (I didn‚Äôt see theirs, same title more or less) https://t.co/P8CmXsGCBW"
182,@GaryMarcus,2023-02-03 15:53:35+00:00,https://twitter.com/GaryMarcus/status/1621537393424891905,@pretendsmarts @jingle__belle i forgot the cropped version that had circulated widely - a preview of later efforts to rewrite history!
183,@GaryMarcus,2023-02-03 15:00:49+00:00,https://twitter.com/GaryMarcus/status/1621524113876750336,Receipts: https://t.co/4sYsA83JdF
184,@GaryMarcus,2023-02-03 14:53:13+00:00,https://twitter.com/GaryMarcus/status/1621522200217157647,@jingle__belle YouTube debate 2017 might be last in person meeting
185,@GaryMarcus,2023-02-03 14:44:46+00:00,https://twitter.com/GaryMarcus/status/1621520073927307265,I am not the only one who has noticed what‚Äôs up here. https://t.co/Eam4OwSelG
186,@GaryMarcus,2023-02-03 04:51:18+00:00,https://twitter.com/GaryMarcus/status/1621370720419975169,What would Bill Murray make of ChatGPT?
187,@GaryMarcus,2023-02-03 04:42:57+00:00,https://twitter.com/GaryMarcus/status/1621368622559141888,"Happy Groundhog Day ‚Äì the AI edition!

https://t.co/llvCuy9MRH"
188,@GaryMarcus,2023-02-02 20:32:04+00:00,https://twitter.com/GaryMarcus/status/1621245087664701440,"@heatherldawe @troutgirl @SashaMTL I‚Äôm saying that women were probably *even more* disproportionately affected by the layoffs than 56% suggests, since women aren‚Äôt 50% of the tech force. (I actually see a few different estimates, in poking around the web, so not confident of any of the exact numbers here.)"
189,@GaryMarcus,2023-02-02 14:31:52+00:00,https://twitter.com/GaryMarcus/status/1621154439188062213,"@troutgirl @SashaMTL that‚Äôs probably worse than it sounds, because the base rates are probably that women are noticeably less than half of the tech work force. anybody have a figure there?"
190,@GaryMarcus,2023-02-02 14:15:00+00:00,https://twitter.com/GaryMarcus/status/1621150195340943361,Ouch: https://t.co/KAfuH4QGaa
191,@GaryMarcus,2023-02-02 14:14:58+00:00,https://twitter.com/GaryMarcus/status/1621150186805542914,"ChatGPT ain‚Äôt rocket science!

Brilliant @NPR story by @gbrumfiel. Listen &amp; be sure also to see the amazing yet flawed AI-generated schematics online. With quotes from me, @emilymbender @SashaMTL @YejinChoinka Tierra Guinn Fletcher and (tellingly) no comment from OpenAI. https://t.co/i8FBv6WOUQ"
192,@GaryMarcus,2023-02-02 12:35:19+00:00,https://twitter.com/GaryMarcus/status/1621125106981568514,@TandooriElvis https://t.co/gbUJdgDqEY
193,@GaryMarcus,2023-02-02 12:20:01+00:00,https://twitter.com/GaryMarcus/status/1621121256618856455,"terrifying that someone can just put up a medical AI advice system with so little friction, given the current state of the tech"
194,@GaryMarcus,2023-02-02 12:13:37+00:00,https://twitter.com/GaryMarcus/status/1621119646404612097,@sapinker the miles in the graph pertain largely to highway (city driving is harder for autonomous vehicles) &amp; only to miles driven with humans-in-the-loop; they do not establish that current tech could drive as well as people outside highways or without human support.
195,@GaryMarcus,2023-02-02 11:51:51+00:00,https://twitter.com/GaryMarcus/status/1621114170946252800,"@vaishakbelle I took a poll, here :) on the day I wrote  my alt intelligence piece. Also because i didn‚Äôt want anything to be paywalled. (Not sure if medium still does.)"
196,@GaryMarcus,2023-02-02 02:51:15+00:00,https://twitter.com/GaryMarcus/status/1620978124363296769,"I have to assume this a joke, but am more than happy to give 4:1 odds, in the criteria I laid out here: https://t.co/yfXycYXxb9"
197,@GaryMarcus,2023-02-02 01:54:57+00:00,https://twitter.com/GaryMarcus/status/1620963954750259204,"1980s: AI companies spend vast amounts of $ hiring humans to write rules to patch brittle symbolic systems. 

2020s: AI companies spend vast amounts of $ hiring humans to to patch brittle neural systems."
198,@GaryMarcus,2023-02-02 01:51:19+00:00,https://twitter.com/GaryMarcus/status/1620963038257119232,"Seriously, is this what we want, folks?"
199,@GaryMarcus,2023-02-02 00:20:41+00:00,https://twitter.com/GaryMarcus/status/1620940230600826881,"Gaslighting and reality in AI: Three years of epic @Ylecun and @garymarcus battles, summed up in a single convenient blog post. 

 https://t.co/7p3TCVIlVf"
200,@GaryMarcus,2023-02-01 19:20:30+00:00,https://twitter.com/GaryMarcus/status/1620864689684254721,"So pleased to see that #ChatGPT has finally solved the problems with basic math word problems that I first pointed in Fall of 2019. Such progress!  Oh, wait ‚Ä¶ um."
201,@GaryMarcus,2023-02-01 18:56:53+00:00,https://twitter.com/GaryMarcus/status/1620858743624990720,ü§£ü§£
202,@GaryMarcus,2023-02-01 18:18:44+00:00,https://twitter.com/GaryMarcus/status/1620849142435307521,"@Grady_Booch Yann? Why? I don‚Äôt get it.

ü§£ü§£ü§£"
203,@GaryMarcus,2023-02-01 13:44:54+00:00,https://twitter.com/GaryMarcus/status/1620780230939127808,Omg this thread is BRUTAL!
204,@GaryMarcus,2023-02-01 04:37:13+00:00,https://twitter.com/GaryMarcus/status/1620642403815415808,"CNET‚Äôs Fake New Fiasco, Autopilot, and a mysterious paper by Lex Fridman

https://t.co/gbUJdgDqEY"
205,@GaryMarcus,2023-01-31 14:42:35+00:00,https://twitter.com/GaryMarcus/status/1620432358326562816,And yet that critical functionality is missing from LLMs and hardly any seems to care üôÑ
206,@GaryMarcus,2023-01-31 04:33:38+00:00,https://twitter.com/GaryMarcus/status/1620279114719707136,"I didn‚Äôt realize tbh that Newsweek was still in business, but, wow, the linked oped is a profound mixture of truth, terrible argument, and utter bullshit."
207,@GaryMarcus,2023-01-30 17:52:17+00:00,https://twitter.com/GaryMarcus/status/1620117712503721984,"Gandhi, one of the greatest leaders in history, was assassinated 75 years ago today. 

It is *always* worth reflecting on his teachings.

https://t.co/iWBJswkhEN"
208,@GaryMarcus,2023-01-29 18:37:09+00:00,https://twitter.com/GaryMarcus/status/1619766614798532610,@CFGeek ü§£ü§£ü§£ true
209,@GaryMarcus,2023-01-29 16:30:29+00:00,https://twitter.com/GaryMarcus/status/1619734736834002947,"@mkirschenbaum @CriticalAI @EnglishOER @markcmarino yes, at least in last a new form of tech is introduced. probably by 6 years there will be; but pure LLMs will continue to make these mistakes even then. i already am on public record predicting such errors for GPT-4."
210,@GaryMarcus,2023-01-29 16:28:44+00:00,https://twitter.com/GaryMarcus/status/1619734298126598144,"@CriticalAI @EnglishOER @markcmarino there‚Äôs this Musk car crash from galactica, via @MNWH: https://t.co/ePFV7PTsCR"
211,@GaryMarcus,2023-01-29 16:23:28+00:00,https://twitter.com/GaryMarcus/status/1619732971707338752,"@CriticalAI @EnglishOER @markcmarino you might be referring to something someone sent to me about Noam Chomsky (alive and well as of an email he sent me a couple days ago) allegedly dying in 2020, generated by ChatGPT‚Äôs sibling davinci, complete with fake URLs. At least it got Hillary Clinton‚Äôs status correct üôÑ https://t.co/IDumam9Ygb"
212,@GaryMarcus,2023-01-29 01:06:33+00:00,https://twitter.com/GaryMarcus/status/1619502221821083651,"@benedictevans @MMikeMMa And better at spelling my first name. But it never looks at the actual evidence, as I do."
213,@GaryMarcus,2023-01-28 19:01:05+00:00,https://twitter.com/GaryMarcus/status/1619410250146394112,avoidance + imitation truly is the most sincere form of flattery.
214,@GaryMarcus,2023-01-28 18:43:39+00:00,https://twitter.com/GaryMarcus/status/1619405863407722496,"Hmm, didn‚Äôt a few other people post same thing earlier? ü§î"
215,@GaryMarcus,2023-01-28 18:05:35+00:00,https://twitter.com/GaryMarcus/status/1619396283386716160,Should have known that the man with the biggest vocabulary I have ever met would figure out the word I was looking for.
216,@GaryMarcus,2023-01-28 18:03:13+00:00,https://twitter.com/GaryMarcus/status/1619395689167081475,Orwell in the tech world.
217,@GaryMarcus,2023-01-28 00:15:15+00:00,https://twitter.com/GaryMarcus/status/1619126924571205633,"what actually happened with Paul Pelosi. 

And why I hope the proprietor of this establishment will have a really hard think about how he wants to be remembered‚Äîas a leader, or as a purveyor of unfounded lies. https://t.co/XzwjO95J5z"
218,@GaryMarcus,2023-01-27 21:57:20+00:00,https://twitter.com/GaryMarcus/status/1619092217351782414,harshest insult of 2023
219,@GaryMarcus,2023-01-27 21:56:40+00:00,https://twitter.com/GaryMarcus/status/1619092049109860357,"Serious question: is there a word for when you say ‚ÄúI cannot do X‚Äù while doing  *exactly* X? 

Like ‚Äúrealtime hypocrisy‚Äù but maybe a little more concise?"
220,@GaryMarcus,2023-01-27 21:54:06+00:00,https://twitter.com/GaryMarcus/status/1619091403187044353,@WillOremus ü§£ ‚ÄúI apologize‚Äù
221,@GaryMarcus,2023-01-27 21:53:07+00:00,https://twitter.com/GaryMarcus/status/1619091155320455173,"‚ÄúI cannot put partisan loyalty ahead of national security‚Äù, said he. ü§£ü§£üò¢"
222,@GaryMarcus,2023-01-27 20:44:46+00:00,https://twitter.com/GaryMarcus/status/1619073953842208768,@MelMitchell1 Indeed a VC mentioned this very idea to me in the last few days.
223,@GaryMarcus,2023-01-27 20:20:15+00:00,https://twitter.com/GaryMarcus/status/1619067785921073152,This was soooo good. Stay tuned; cooking up something very special.
224,@GaryMarcus,2023-01-27 18:44:22+00:00,https://twitter.com/GaryMarcus/status/1619043657184874496,"How cool is that? Chatting with @KenJennings about AI and Jeopardy, in a few minutes!"
225,@GaryMarcus,2023-01-27 18:19:01+00:00,https://twitter.com/GaryMarcus/status/1619037275102547969,@soboleffspaces passing a bar exam quasi open book isn‚Äôt necessarily a measure of genuine competence to practice law.
226,@GaryMarcus,2023-01-27 16:51:07+00:00,https://twitter.com/GaryMarcus/status/1619015153772789760,this offer expires in 90 minutes.
227,@GaryMarcus,2023-01-27 16:12:51+00:00,https://twitter.com/GaryMarcus/status/1619005524615495684,"There may be a day when AI chatbots aren‚Äôt bullshit artists. But that day has not come. 

I‚Äôm with the courts, at least for now, in shutting this down. https://t.co/aXrif6ErdR"
228,@GaryMarcus,2023-01-27 13:57:13+00:00,https://twitter.com/GaryMarcus/status/1618971392216829956,"If you could ask Ken Jennings one question, what would it be?"
229,@GaryMarcus,2023-01-26 19:52:08+00:00,https://twitter.com/GaryMarcus/status/1618698323396796432,"Sex, Lies and Plagiarism.

(Ok, kidding about the first) https://t.co/gvW4ZBNRsN"
230,@GaryMarcus,2023-01-24 20:25:02+00:00,https://twitter.com/GaryMarcus/status/1617981825422610432,hardcore coding meets AGI  - live
231,@GaryMarcus,2023-01-24 20:05:25+00:00,https://twitter.com/GaryMarcus/status/1617976887762116608,Live now @kelseyhightower and @Grady_Booch on Twitter spaces
232,@GaryMarcus,2023-01-24 04:37:06+00:00,https://twitter.com/GaryMarcus/status/1617743270653882371,"@kelseyhightower @mmitchell_ai @cherthedev @timnitGebru @Grady_Booch (my own presence wasn‚Äôt initially planned; it was supposed to be Grady, but then Grady and I did a dialog over the weekend that was well-received, so I was added in just yesterday.)"
233,@GaryMarcus,2023-01-24 04:30:14+00:00,https://twitter.com/GaryMarcus/status/1617741542151843841,"@mmitchell_ai @cherthedev @timnitGebru @kelseyhightower @Grady_Booch things are not always as they seem, or as people believe them to be. a number of women of color were actually already invited (3 by me, the only 3 people I invited)."
234,@GaryMarcus,2023-01-24 03:47:25+00:00,https://twitter.com/GaryMarcus/status/1617730769115545600,@kelseyhightower @cherthedev @Grady_Booch @timnitGebru @mmitchell_ai @timnitGebru would be great if you wanted to join
235,@GaryMarcus,2023-01-24 00:54:16+00:00,https://twitter.com/GaryMarcus/status/1617687191307841536,100% agree.
236,@GaryMarcus,2023-01-24 00:02:27+00:00,https://twitter.com/GaryMarcus/status/1617674154102370306,"@Nick_Davidov @sama don‚Äôt read it that way at all; ‚Äúextending our¬†partnership.
This multi-year, multi-billion dollar investment from Microsoft follows their previous investments in 2019 and 2021‚Äù sounds like a new deal has been signed for further multi-billion dollars."
237,@GaryMarcus,2023-01-23 23:04:30+00:00,https://twitter.com/GaryMarcus/status/1617659566795415552,"@witbrock @CriticalAI @elonmusk https://t.co/yfXycYXxb9?, plus one mechanism has to do 3+/5"
238,@GaryMarcus,2023-01-23 22:39:44+00:00,https://twitter.com/GaryMarcus/status/1617653334630109184,"@Abel_TorresM @elonmusk no, that‚Äôs not *general* intelligence, if that‚Äôs all it does"
239,@GaryMarcus,2023-01-23 22:38:58+00:00,https://twitter.com/GaryMarcus/status/1617653141885030400,"@CriticalAI @elonmusk he agreed to mine, if you read the thread"
240,@GaryMarcus,2023-01-23 21:52:48+00:00,https://twitter.com/GaryMarcus/status/1617641525672050690,"AGI in 2023? Game on! Brave man, braver than @elonmusk, who refused to take a less ambitious version of this same bet."
241,@GaryMarcus,2023-01-23 21:46:17+00:00,https://twitter.com/GaryMarcus/status/1617639886126997504,"@PaulYacoubian It would be kind of lame,  not really a general intelligence, but I would pay off the bet, not wanting to be seen as a welcher :)"
242,@GaryMarcus,2023-01-23 21:42:44+00:00,https://twitter.com/GaryMarcus/status/1617638990999588864,@PaulYacoubian Game on with small clarification - a single system has to do at least three of the criteria (3 separate narrow AIs wouldn‚Äôt count as a general AI). Ok?
243,@GaryMarcus,2023-01-23 20:31:58+00:00,https://twitter.com/GaryMarcus/status/1617621181473120258,"@PaulYacoubian how much are you betting, and how much of that action may I take? (and what are your criteria? see my proposed bet with Elon Musk for my mine.)"
244,@GaryMarcus,2023-01-23 04:58:09+00:00,https://twitter.com/GaryMarcus/status/1617386178134540288,"Empire State Building, shrouded in clouds https://t.co/17Ajgt6MSt"
245,@GaryMarcus,2023-01-22 23:52:06+00:00,https://twitter.com/GaryMarcus/status/1617309159669612544,@NathanpmYoung . @Abebab has the roots of an argument that I would like to see her develop
246,@GaryMarcus,2023-01-22 23:20:05+00:00,https://twitter.com/GaryMarcus/status/1617301104227930112,"3pm Tuesday ET @TwitterSpaces, w @kelseyhightower &amp; @Grady_Booch"
247,@GaryMarcus,2023-01-22 23:15:36+00:00,https://twitter.com/GaryMarcus/status/1617299975909822465,@DrTechlash @AI21Labs Nice direction. Still not AGI but ahead of what some other chat style search engines have been trying to do
248,@GaryMarcus,2023-01-22 22:59:22+00:00,https://twitter.com/GaryMarcus/status/1617295888678023168,@DrTechlash @AI21Labs I tweeted about it when it came out and often mention it :)
249,@GaryMarcus,2023-01-22 22:41:20+00:00,https://twitter.com/GaryMarcus/status/1617291351141371904,when two top journals reject an idea that spawned one of the greatest advances in neuroscience ever.
250,@GaryMarcus,2023-01-22 22:35:58+00:00,https://twitter.com/GaryMarcus/status/1617289998906134529,"@PessoaBrain ‚ÄúPan and Dizhoor wrote a paper about their work and submitted it to Nature on November 25, 2004‚Ä¶  The editors at Nature suggested they send it on to a more specialized journal called Nature Neuroscience, which rejected it‚Äù ü§¶‚Äç‚ôÇÔ∏è"
251,@GaryMarcus,2023-01-22 22:08:52+00:00,https://twitter.com/GaryMarcus/status/1617283180632891396,nice to be back! https://t.co/RbmJfHXg4a
252,@GaryMarcus,2023-01-22 21:33:48+00:00,https://twitter.com/GaryMarcus/status/1617274353464348672,"@ruimcosta @shenoystanford So sad to hear this. Krishna wrote a brilliant essay for Jeremy Freeman and me in 2015, in The Future of the Brain."
253,@GaryMarcus,2023-01-22 21:08:23+00:00,https://twitter.com/GaryMarcus/status/1617267959763800064,everyday this guy starts to sound a little more like me ü§£
254,@GaryMarcus,2023-01-22 21:04:00+00:00,https://twitter.com/GaryMarcus/status/1617266856439746561,#2 in a series of tweets that have aged well.
255,@GaryMarcus,2023-01-22 16:01:36+00:00,https://twitter.com/GaryMarcus/status/1617190753859506197,"AGI will not happen in your lifetime! Or will it?

@Grady_Booch and I discuss.

https://t.co/lQr3tmLzR0"
256,@GaryMarcus,2023-01-22 14:19:28+00:00,https://twitter.com/GaryMarcus/status/1617165051021885440,"@hughes_meister Needs more explanation than I can likely write on twitter or in next few days, but I plan to reply. And no, I don‚Äôt agree.

@gradientpub might I write a reply? very important issue."
257,@GaryMarcus,2023-01-22 13:33:12+00:00,https://twitter.com/GaryMarcus/status/1617153409450213377,"the original large-scale model, emphasis on large!

https://t.co/y7GJWQo268 https://t.co/2aCpoxfCvw"
258,@GaryMarcus,2023-01-22 03:11:04+00:00,https://twitter.com/GaryMarcus/status/1616996843912585216,"@alok_damle @Machine01776819 it would still generate misinfo, because it loses track of the relations between properties. (as I discussed in my Substack on why ChatGPT can appear both brilliant and stupid)"
259,@GaryMarcus,2023-01-22 03:09:04+00:00,https://twitter.com/GaryMarcus/status/1616996339501473793,"@UrsulaBrinkmann @alok_damle don‚Äôt think LLMs actually have intention; they are just trying to predict things. so though don‚Äôt try to deceive, but they sure do say a lot of stuff that simply ain‚Äôt true."
260,@GaryMarcus,2023-01-21 22:32:02+00:00,https://twitter.com/GaryMarcus/status/1616926623206449153,This tweet aged extremely well.
261,@GaryMarcus,2023-01-21 16:03:53+00:00,https://twitter.com/GaryMarcus/status/1616828940903149571,"@pmddomingos Silliness above &amp; below, inasmuch as *many* people share my views about current inadequacy, eg @MelMitchell1 @ErnestSDavis @swarat @Grady_Booch @dmonett  @PMinervini @emilymbender @AI4Code @maier_ak @HochreiterSepp @demishassabis &amp; even @ylecun  @pmddomingos &amp; @geoffreyhinton"
262,@GaryMarcus,2023-01-21 15:53:37+00:00,https://twitter.com/GaryMarcus/status/1616826358700838912,The Marcus Corollary: AI will not be achieved until people recognize that rampant hallucination is a bug rather than a feature.
263,@GaryMarcus,2023-01-20 23:45:09+00:00,https://twitter.com/GaryMarcus/status/1616582634607644673,The word ‚Äúarguably‚Äù died on this day in 2023.
264,@GaryMarcus,2023-01-20 23:16:08+00:00,https://twitter.com/GaryMarcus/status/1616575332634722306,"@NickRMorgan And what if (a) LLMs fail ever to become reliable and do a lot of damage and/or (b) turn out to be a detour with a large opportunity cost?

Scientists wasted 30 years thinking genes were made of protein. 

Sometimes the dominant way is not the right way."
265,@GaryMarcus,2023-01-20 19:17:12+00:00,https://twitter.com/GaryMarcus/status/1616515202715103234,"@MaFavelli @siobhansolberg actually the book is already out (https://t.co/C6XodPcoZW), but might be time for a sequel‚Ä¶"
266,@GaryMarcus,2023-01-20 19:00:20+00:00,https://twitter.com/GaryMarcus/status/1616510958742175745,@togelius @alberto_tonda @mitpress I‚Äôm here for you :)
267,@GaryMarcus,2023-01-20 18:48:41+00:00,https://twitter.com/GaryMarcus/status/1616508027619926016,"@ihorgowda @ianbremmer we clearly need to talk; see my recent Ezra Klein podcast, and https://t.co/QCAInsodQy"
268,@GaryMarcus,2023-01-20 18:44:55+00:00,https://twitter.com/GaryMarcus/status/1616507078725754880,"This is a hell of a statement, and not necessarily wrong: ‚ÄúThese advances represent a step-change in AI's potential to manipulate people and sow political chaos‚Äù; generative AI as a major geopolitical risk: https://t.co/KAZHFZGePD by @ianbremmer and Cliff Kupchan"
269,@GaryMarcus,2023-01-20 16:50:34+00:00,https://twitter.com/GaryMarcus/status/1616478301417267201,"@YiTayML key question, for you: what can‚Äôt be solved by scaling, so we know what we need to work on :)"
270,@GaryMarcus,2023-01-20 16:40:02+00:00,https://twitter.com/GaryMarcus/status/1616475650797469696,"@YiTayML in the future! not on sale anywhere just yet, alas."
271,@GaryMarcus,2023-01-20 04:41:49+00:00,https://twitter.com/GaryMarcus/status/1616294907286814721,@TheodoreGalanos Goes by *query* content
272,@GaryMarcus,2023-01-20 04:39:58+00:00,https://twitter.com/GaryMarcus/status/1616294438258737152,"@TheodoreGalanos 3. Not well, but there has been some work. RLHF mostly goes by surety, not internal knowledge; best work I know there is by Anthropic in 2022.

You are missing the point on 1. My kids learn new concepts when they read books; LLMs don‚Äôt really."
273,@GaryMarcus,2023-01-20 04:21:57+00:00,https://twitter.com/GaryMarcus/status/1616289907147935745,@ChristinaBehme4 Should we declare victory when we have made George Santos level AI?
274,@GaryMarcus,2023-01-20 03:54:07+00:00,https://twitter.com/GaryMarcus/status/1616282902802862086,Not before 2030 @metaculus @MatthewJBar
275,@GaryMarcus,2023-01-20 03:53:01+00:00,https://twitter.com/GaryMarcus/status/1616282625072852992,@MoodyHikmet @Tweetermeyer Tesla is giving him a lot of material to talk about!
276,@GaryMarcus,2023-01-20 03:48:23+00:00,https://twitter.com/GaryMarcus/status/1616281457802240000,interesting set of criteria; no current AI meets them in a general way
277,@GaryMarcus,2023-01-20 03:47:07+00:00,https://twitter.com/GaryMarcus/status/1616281138351464451,"@NaveenGRao @danahull @sokane1 @GrahamStarr @chafkin @business Nope, those were Elon‚Äôs words, and a bit of an exaggeration.  But it might possibly lead to them to be valued like a first-rate luxury car company rather than like a tech company."
278,@GaryMarcus,2023-01-19 23:41:21+00:00,https://twitter.com/GaryMarcus/status/1616219288993681408,"@kmvanh @danahull @sokane1 @GrahamStarr @chafkin @business by all means feel free to unfollow. or read eg my post on Cicero, which I actually thought was a (rare) step in the right direction."
279,@GaryMarcus,2023-01-19 23:26:24+00:00,https://twitter.com/GaryMarcus/status/1616215528535904263,"Will Tesla ever ‚ÄúSolve‚Äù Full Self Driving? - by Gary Marcus

From June 2022 and worth rereading, in light of recent news broken by ‚Å¶@danahull‚Å© ‚Å¶@sokane1‚Å© ‚Å¶@GrahamStarr‚Å© ‚Å¶ @chafkin @business‚Å©

Esp the Musk quote at top https://t.co/udbUPHK4gD"
280,@GaryMarcus,2023-01-19 20:16:40+00:00,https://twitter.com/GaryMarcus/status/1616167782487576577,"‚ÄúNine days later, after Tesla staffers shared a fourth version of the video, Musk replied that there were still too many jump cuts, and that the demo footage ‚Äúneeds to feel like one continuous take.‚Äù‚Äù @JohnCarreyrou"
281,@GaryMarcus,2023-01-19 19:48:55+00:00,https://twitter.com/GaryMarcus/status/1616160797134290944,"Doubt that @OpenAI will like this episode of @profgalloway‚Äôs podcast. 

But I thought it was a pretty stimulating conversation, at the intersection of AI and unusual business models‚Ä¶"
282,@GaryMarcus,2023-01-19 04:14:23+00:00,https://twitter.com/GaryMarcus/status/1615925613566783489,@CriticalAI @emilymbender @timnitGebru @mmitchell_ai ü§£
283,@GaryMarcus,2023-01-19 03:46:41+00:00,https://twitter.com/GaryMarcus/status/1615918644269289475,"@rasbt @tdietterich @billyperrigo 1. we haven‚Äôt a clue how to do that, other than via sweathshop style filtering, which doesn‚Äôt work all that well
2. Even if we did, LLMs would still fabricate all kinds of stuff, because they, sort of a la lossy compression, forget which bits do and don‚Äôt go together."
284,@GaryMarcus,2023-01-19 02:39:10+00:00,https://twitter.com/GaryMarcus/status/1615901653814902784,"@pmddomingos definitely not, but i never said it needed to be."
285,@GaryMarcus,2023-01-19 02:38:22+00:00,https://twitter.com/GaryMarcus/status/1615901449111891968,"Bingo! @tdietterich totally nailing what‚Äôs wrong both with current AI and the OpenAI sweatshops documented by @billyperrigo.

Hint: it‚Äôs not about the salary. https://t.co/ouscqjFUlf"
286,@GaryMarcus,2023-01-19 01:47:31+00:00,https://twitter.com/GaryMarcus/status/1615888653443821570,@nirsd With right innate basis you can make sense of data very quickly. That‚Äôs what a baby ibex does to calibrate so fast
287,@GaryMarcus,2023-01-19 00:28:42+00:00,https://twitter.com/GaryMarcus/status/1615868819339182088,More like #heartbreaking. surely one of the best leaders we have seen in a long time.
288,@GaryMarcus,2023-01-19 00:26:21+00:00,https://twitter.com/GaryMarcus/status/1615868228462419975,@MikellTaylor Oh no!!!
289,@GaryMarcus,2023-01-19 00:03:23+00:00,https://twitter.com/GaryMarcus/status/1615862447646064640,Absolutely; pleas do read The Next Decade in AI and The Algebraic Mind for specific claims about core requirements
290,@GaryMarcus,2023-01-19 00:02:12+00:00,https://twitter.com/GaryMarcus/status/1615862152060960768,@PaulTopping @StefanFSchubert @nickcave @billyperrigo @goodside @chafkin Pity ‚Äúpride comes before the fall‚Äù was taken ü§£
291,@GaryMarcus,2023-01-18 23:24:30+00:00,https://twitter.com/GaryMarcus/status/1615852660510580737,@KerbalFPV @vadimberman @benedictevans Just add AI that knows how to search from natural language strings and you will be all set! ü§£
292,@GaryMarcus,2023-01-18 23:20:06+00:00,https://twitter.com/GaryMarcus/status/1615851556007743489,@neuranna But what about ‚Ä¶ semantics?
293,@GaryMarcus,2023-01-18 23:19:35+00:00,https://twitter.com/GaryMarcus/status/1615851427255177216,"Totally (in advance of a close look) disagree with conclusion (1), totally agree with conclusion (2), and look forward to reading this!"
294,@GaryMarcus,2023-01-18 22:18:56+00:00,https://twitter.com/GaryMarcus/status/1615836163616669697,"@StefanFSchubert @nickcave @billyperrigo @goodside @chafkin the common threads are perhaps deception, hubris, overhype, and exploitation. not identical but not without overlap, either."
295,@GaryMarcus,2023-01-18 21:33:07+00:00,https://twitter.com/GaryMarcus/status/1615824630601879552,"24 seriously embarrassing hours for AI, summed up in one blog post

https://t.co/yUdzt5GDdF,  featuring @nickcave @billyperrigo @goodside @chafkin and more."
296,@GaryMarcus,2023-01-18 20:28:11+00:00,https://twitter.com/GaryMarcus/status/1615808290264616961,"The choices we make, around what kind of AI we build, have consequences for society.

We are pursuing the best path we currently know how to build. But is it the best path imaginable?

Sometimes the slower road is the better road. 

How much human cost is too much?

3/3"
297,@GaryMarcus,2023-01-18 20:28:11+00:00,https://twitter.com/GaryMarcus/status/1615808288993726464,"Real AI would learn with the efficiency of human children.

Real AI would be able to reason from first principles, and generalize far more deeply.

AI Sweatshops are the consequence of trying to substitute shallow data for deep understanding.

2/3"
298,@GaryMarcus,2023-01-18 20:28:10+00:00,https://twitter.com/GaryMarcus/status/1615808287194157059,"Real AI wouldn‚Äôt need sweatshops.

Real AI wouldn‚Äôt need vast amounts of data.

ü™° 1/3"
299,@GaryMarcus,2023-01-18 20:16:07+00:00,https://twitter.com/GaryMarcus/status/1615805254481874947,@DrJimFan their stuff tends to be choreographed but at the same time better grippers in this form factor are likely to drive deeper progress in AI and robotics.
300,@GaryMarcus,2023-01-18 19:17:56+00:00,https://twitter.com/GaryMarcus/status/1615790611767902208,@kareem_carr But I see no evidence that this is actually working; esp in non English languages.
301,@GaryMarcus,2023-01-18 17:37:43+00:00,https://twitter.com/GaryMarcus/status/1615765389941538834,"And today, we learned that OpenAI ran a sweatshop in Kenya. AI needs to up its game. and regulators need to up theirs."
302,@GaryMarcus,2023-01-18 17:34:23+00:00,https://twitter.com/GaryMarcus/status/1615764551370145801,@goodside @perplexity_ai Neurosymbolic AI for the win!
303,@GaryMarcus,2023-01-18 17:33:33+00:00,https://twitter.com/GaryMarcus/status/1615764341428453387,@j_bindra @realDonaldTrump Or George Santos?
304,@GaryMarcus,2023-01-18 16:00:57+00:00,https://twitter.com/GaryMarcus/status/1615741040568467456,"@kailuowang @DrJimFan @stephen_wolfram remains to be seen; Codex has been a good application ‚Äòcause programmers are their minding the story, and debugging, and have relevant expertise to understand the output, and have suitably low expectations. 

we expect Wolfram Alpha to just work, like a calculator. higher bar!"
305,@GaryMarcus,2023-01-18 15:44:29+00:00,https://twitter.com/GaryMarcus/status/1615736897367838721,"@DrJimFan @stephen_wolfram Key question for both you &amp; Stephen is how to do so reliably, esp, given that both input &amp; output of LLM‚Äôs are strings, rather than structured objects.

If human language were as unambiguous as Leibniz‚Äô constructed language this would be trivial, but IRL language is hard."
306,@GaryMarcus,2023-01-18 10:22:33+00:00,https://twitter.com/GaryMarcus/status/1615655876345626625,@nferraz AI does not need to replicate humans. But planes have more common with birds than you think: https://t.co/f0uFcdT5mx
307,@GaryMarcus,2023-01-18 10:12:09+00:00,https://twitter.com/GaryMarcus/status/1615653261540986881,"New challenge for #gpt4: the honest, sourced biography challenge

Cc @metaculus @MatthewJBar - I  predict that gpt4 by end of 2023 can do this without error in less than 25% of its attempts"
308,@GaryMarcus,2023-01-18 10:07:54+00:00,https://twitter.com/GaryMarcus/status/1615652192350007296,@RistoUuk https://t.co/27mQtEFZTr
309,@GaryMarcus,2023-01-18 09:57:10+00:00,https://twitter.com/GaryMarcus/status/1615649490240929792,"@vadimberman Here is something you could tell an intern that no extant generative model could follow: write a one page biography of X; don‚Äôt make anything up; give sources for each thing that you say. 

Cc @benedictevans"
310,@GaryMarcus,2023-01-18 06:58:38+00:00,https://twitter.com/GaryMarcus/status/1615604560533520391,"@TaliaRinger If you want to call it the transfer problem I am cool with that. If you want to ignore the problem altogether, we may not have as much common ground as I thought."
311,@GaryMarcus,2023-01-18 06:21:50+00:00,https://twitter.com/GaryMarcus/status/1615595300344692738,@PaulTopping Personally i am shocked-not shocked
312,@GaryMarcus,2023-01-18 05:48:08+00:00,https://twitter.com/GaryMarcus/status/1615586819281940483,"things I learned today
üëâTesla staged its 2016 driverless car demo
üëâCNET‚Äôs ChatGPT-written stories were a mistake-filled mess
üëâThe latest ‚Äúaligned‚Äù chatbot (Claude) hallucinates pretty much same as the last one"
313,@GaryMarcus,2023-01-18 05:24:52+00:00,https://twitter.com/GaryMarcus/status/1615580963664429056,"@TaliaRinger This critique misses the mark. AI is falling short now precisely because it is narrow.  humans clearly have some kind of flexibility and efficiency in acquiring new tasks.

I see little value in denying that reality."
314,@GaryMarcus,2023-01-18 05:16:51+00:00,https://twitter.com/GaryMarcus/status/1615578945377931265,"@TaliaRinger People are WAY more general at this then machines; as noted above &amp; on Klein we are not *perfectly* general but no machine matches the generality of my 8 and 10 year old or even closer. Machines can‚Äôt leverage simple verbal instructions the way kids can, &amp; require way more data."
315,@GaryMarcus,2023-01-18 05:11:26+00:00,https://twitter.com/GaryMarcus/status/1615577581339947010,@TaliaRinger The point is that it should be able to do new tasks beyond some previous list. Gato is multitask but doesn‚Äôt generalize well to new tasks. So IMHO that doesn‚Äôt count eg per the definition of AGI I gave here: https://t.co/ygD2ohxN3V
316,@GaryMarcus,2023-01-18 05:00:14+00:00,https://twitter.com/GaryMarcus/status/1615574763514265602,@mickeysan007 @hylobateslover @chafkin @JohnCarreyrou does this kind of post hoc it will be the next version rationalization ring any bells?
317,@GaryMarcus,2023-01-18 02:55:26+00:00,https://twitter.com/GaryMarcus/status/1615543357819998209,@PaulTopping The screenshot came on pretty strong
318,@GaryMarcus,2023-01-18 02:28:39+00:00,https://twitter.com/GaryMarcus/status/1615536616982081536,"very good technical description of the problem of LLMs that is extremely close to what I said in type/token chapter of The Algebraic Mind (2001).

Nothing has changed - in 20 years"
319,@GaryMarcus,2023-01-18 02:25:37+00:00,https://twitter.com/GaryMarcus/status/1615535853023170560,@PaulTopping Eh? ‚ÄúThe intent of the video was not to accurately portray what was available for customers in 2016. It was to portray what was possible to build into the system.‚Äù¬†And see comment from John
320,@GaryMarcus,2023-01-18 02:18:13+00:00,https://twitter.com/GaryMarcus/status/1615533992555720704,".@labenz, early January: don‚Äôt worry about hallucination, it‚Äôs mostly solved 
CNET, tonight: Oops!
Claude: Hold my beer https://t.co/dOr7x3Mpyh"
321,@GaryMarcus,2023-01-18 02:10:09+00:00,https://twitter.com/GaryMarcus/status/1615531959941500929,In other shocking news.
322,@GaryMarcus,2023-01-18 01:33:44+00:00,https://twitter.com/GaryMarcus/status/1615522795961856000,"Wow! Who could possibly have seen this coming? ‚ÄúCNET Is Reviewing the Accuracy of All Its AI-Written Articles After Multiple Major Corrections‚Äù 

üêµ‚å®Ô∏è‚å®Ô∏è‚å®Ô∏èüôà https://t.co/n7NZMQaFup"
323,@GaryMarcus,2023-01-18 00:17:12+00:00,https://twitter.com/GaryMarcus/status/1615503535021428736,‚ù§Ô∏èüôè
324,@GaryMarcus,2023-01-17 23:42:41+00:00,https://twitter.com/GaryMarcus/status/1615494851046576129,"@TaliaRinger partly in sympathy (as noted in my interview w Ezra Klein), but there‚Äôs certainly a kind of generality that is absent now. eg LLM can‚Äôt even play a passable game of chess, and AlphaZero wouldn‚Äôt be able to beat Cicero in Diplomacy, while Cicero would be lost at Go."
325,@GaryMarcus,2023-01-17 23:40:10+00:00,https://twitter.com/GaryMarcus/status/1615494218373562368,"@Jonparts it‚Äôs a question of science and engineering, not consensus."
326,@GaryMarcus,2023-01-17 23:36:26+00:00,https://twitter.com/GaryMarcus/status/1615493275796008960,"@Jonparts zero chance. too many foundational issues remain unsolved, and the kind of approximation we can do now is too problematic."
327,@GaryMarcus,2023-01-17 23:17:11+00:00,https://twitter.com/GaryMarcus/status/1615488431454556160,"AGI - this century? Or no? Agree with Grady? Disagree? He and are going to have a dialog on the topic (for once I get to play the role of optimist!), which we will post on my Substack. 

Got questions for either of us? Post them here."
328,@GaryMarcus,2023-01-17 20:31:45+00:00,https://twitter.com/GaryMarcus/status/1615446801582292992,"@flabaster @Grady_Booch Most people underestimate themselves, if they think they can replaced by large language models"
329,@GaryMarcus,2023-01-17 20:30:34+00:00,https://twitter.com/GaryMarcus/status/1615446502914260992,@kareem_carr Or be the source of subtle errors that lead to failures to replicate?
330,@GaryMarcus,2023-01-17 19:42:12+00:00,https://twitter.com/GaryMarcus/status/1615434332612743169,"One of the first times I have ever disagreed with @Grady_Booch. I think we see AGI within less than a century; he‚Äôs less sanguine.  

Discussion in the thread."
331,@GaryMarcus,2023-01-17 19:38:29+00:00,https://twitter.com/GaryMarcus/status/1615433394888019968,"@filippie509 @Grady_Booch @vijayasankarv @AngeloDalli agree, ChatGPT is diverting a lot of resources away; was going to make that point in some detail in my FTX essay."
332,@GaryMarcus,2023-01-17 19:36:00+00:00,https://twitter.com/GaryMarcus/status/1615432770041569281,"@Grady_Booch @vijayasankarv @AngeloDalli though i would exempt all the sapience etc stuff, since i don‚Äôt even know what the criteria are. i would say we can solve the semantics and reasoning problems and have machines that have solid models of themselves in 75 years"
333,@GaryMarcus,2023-01-17 19:34:44+00:00,https://twitter.com/GaryMarcus/status/1615432451828092928,"@Grady_Booch @vijayasankarv @AngeloDalli indeed, one of first times i remember disagreeing w you."
334,@GaryMarcus,2023-01-17 19:18:32+00:00,https://twitter.com/GaryMarcus/status/1615428374620672000,"@vijayasankarv @Grady_Booch @AngeloDalli a modest number of decades, maybe 25 - 75 years."
335,@GaryMarcus,2023-01-17 18:59:35+00:00,https://twitter.com/GaryMarcus/status/1615423604266790912,@CASBSStanford @AlisonGopnik @ghadfield but that happens a lot! but ‚ù§Ô∏è
336,@GaryMarcus,2023-01-17 18:14:09+00:00,https://twitter.com/GaryMarcus/status/1615412170870882306,"GPU‚Äôs are trending. If you care about GPUs and the effect they have had in shaping AI
a. I highly recommend watching this short but provocative discussion by Sarah Hooker [@sarahookr]
b. follow up by reading her article The Hardware Lottery"
337,@GaryMarcus,2023-01-17 18:06:01+00:00,https://twitter.com/GaryMarcus/status/1615410127531814917,"@yoavgo @MelMitchell1 @EmreSevinc @emilymbender @MelMitchell1‚Äôs choice of words was spot-on. 

Peoples‚Äô expectation for what MSFT is going to release w OpenAI are unrealistic."
338,@GaryMarcus,2023-01-17 15:54:01+00:00,https://twitter.com/GaryMarcus/status/1615376905733279745,@yoavgo @MelMitchell1 @EmreSevinc @emilymbender the problem is that  nonexperts regularly get fooled by these benchmark names and then misestimate how close robust natural language understanding is. (As I've trying to explain to @labenz)
339,@GaryMarcus,2023-01-17 15:40:22+00:00,https://twitter.com/GaryMarcus/status/1615373470514450432,@EmreSevinc @emilymbender @yoavgo @MelMitchell1 The opening pages of https://t.co/Pt7HZc3RJd dissected a very similar claim that made in 2018 :)
340,@GaryMarcus,2023-01-17 15:08:45+00:00,https://twitter.com/GaryMarcus/status/1615365516016910337,The underlying algorithm doesn't know how many legs a human body can have.
341,@GaryMarcus,2023-01-17 15:07:34+00:00,https://twitter.com/GaryMarcus/status/1615365217436979200,Prove you are not a human. #stablediffusion https://t.co/32RXChF0g5
342,@GaryMarcus,2023-01-17 14:53:26+00:00,https://twitter.com/GaryMarcus/status/1615361662093262848,@fhuszar New to me; here is his bio https://t.co/ahgKhj6NJE
343,@GaryMarcus,2023-01-17 14:34:28+00:00,https://twitter.com/GaryMarcus/status/1615356885645025285,100% agree that all this is *critical* for AGI and lacking in current AI‚Äîjust as much now as when Rebooting AI went to press saying much the same thing 4 years ago üòî
344,@GaryMarcus,2023-01-17 14:30:56+00:00,https://twitter.com/GaryMarcus/status/1615355996192534528,@Grady_Booch @AngeloDalli I agree with 100% of this but don‚Äôt think it follows that we are necessarily several or many decades away.
345,@GaryMarcus,2023-01-16 17:02:53+00:00,https://twitter.com/GaryMarcus/status/1615031851416162306,I‚Äôll give ChatGPT this: its creativity in hallucination is endless
346,@GaryMarcus,2023-01-16 16:59:51+00:00,https://twitter.com/GaryMarcus/status/1615031085863424000,"Invariably, experts are disappointed‚Äîand rightly so‚Äîin ChatGPT, when they look at what says in their own domain.

Jack of all trades, master of none."
347,@GaryMarcus,2023-01-16 15:11:53+00:00,https://twitter.com/GaryMarcus/status/1615003914876882953,"Anyone who thinks there is even the slightest possible substance to what Nick Bostrom was saying needs a history lesson. 

This is a good place to start."
348,@GaryMarcus,2023-01-16 14:56:14+00:00,https://twitter.com/GaryMarcus/status/1614999978522574849,"@labenz @peterwildeford @NathanpmYoung @ezraklein validity versus reliability

validity versus reliability

validity versus reliability

validity versus reliability"
349,@GaryMarcus,2023-01-16 14:50:19+00:00,https://twitter.com/GaryMarcus/status/1614998487296532482,"@labenz @peterwildeford @NathanpmYoung @ezraklein Seems to me like you aren‚Äôt listening to what I am trying to tell you about the inadequacy of benchmarks. Please read something about the distinction between ‚Äúvalidity‚Äù and ‚Äúreliability‚Äù, and stop taking these things are face value."
350,@GaryMarcus,2023-01-16 14:48:18+00:00,https://twitter.com/GaryMarcus/status/1614997979039166464,"History will show Turing Award winner @yudapearl‚Äôs challenges to ‚Äúcurve fitting‚Äù were 100% correct. 

Here is a beauty:"
351,@GaryMarcus,2023-01-16 14:45:49+00:00,https://twitter.com/GaryMarcus/status/1614997353945239552,"@jon_mellon @yudapearl If it slips in and out (as I would expect) it is because it does not actually understand the underlying principle, but rather because is driven by similarity to what is in its massive but undisclosed database. 

Exactly as @yudapearl and I have been trying to explain all along."
352,@GaryMarcus,2023-01-16 05:58:11+00:00,https://twitter.com/GaryMarcus/status/1614864571159949312,"@labenz @NathanpmYoung @ezraklein again you are seeing what you want to see
‚Äì ignoring section of big bench that reports non scaling on some measures
- ignoring problems of validity they are rampant and well-known in ML for years"
353,@GaryMarcus,2023-01-16 05:56:25+00:00,https://twitter.com/GaryMarcus/status/1614864126567907330,"@labenz @NathanpmYoung @ezraklein well aware of them; @ErnestSDavis just reviewed them. They are underwhelming. Eg nearly all are multiple choice, allowing them to be gamed. 

Put differently, results are ‚Äúgood‚Äù on these benchmarks but discomprehension errors remain common. 

Validity remains poor."
354,@GaryMarcus,2023-01-16 05:39:40+00:00,https://twitter.com/GaryMarcus/status/1614859911250477056,@labenz @NathanpmYoung @ezraklein Not sure there any compelling conmonsense benchmarks tbh
355,@GaryMarcus,2023-01-16 04:51:12+00:00,https://twitter.com/GaryMarcus/status/1614847717058170880,"@labenz @NathanpmYoung @ezraklein You seem unaware of an open secret in the field; benchmarks rarely get at what we want them to be. 

If you don‚Äôt believe me, here is a random example from a team at Facebook making same point (as quoted in my 2020 arXiv The Next Decade in AI). https://t.co/FZzd2e1PU8"
356,@GaryMarcus,2023-01-16 04:18:52+00:00,https://twitter.com/GaryMarcus/status/1614839577965105154,"@MoodyHikmet safety is a not a f_ing unidimensional scalar value.

i am still reeling from the main part of your thread, reinventing the wheel and doing such a naive job of it."
357,@GaryMarcus,2023-01-16 04:16:11+00:00,https://twitter.com/GaryMarcus/status/1614838902153674753,@garybasin @labenz @ezraklein retrieval models are apples; LLMs are oranges. putting them together effectively is not nearly as easy as people seem to be thinking.
358,@GaryMarcus,2023-01-16 04:13:34+00:00,https://twitter.com/GaryMarcus/status/1614838246906920960,"holy sh_t. terrifying thread. amateur hour, tested on public roads."
359,@GaryMarcus,2023-01-16 02:49:23+00:00,https://twitter.com/GaryMarcus/status/1614817059824885760,".@meta‚Äôs @ylecun likes to paint himself as a moderate, but LLMs have already started causing real harm
üëâplagiarized at least one journalist (@Kantrowitz)
üëâIndundated StackOverflow w garbage
üëâRegurgitated many artists work w small changes. without compensation
+misinfo to come"
360,@GaryMarcus,2023-01-16 02:43:02+00:00,https://twitter.com/GaryMarcus/status/1614815463577628672,@labenz @NathanpmYoung @ezraklein They don‚Äôt do everything at college level. They do a bunch of benchmarks at college level. College students don‚Äôt hallucinate like this when they pay attention. It tells you more about the benchmarks than it does about intelligence.
361,@GaryMarcus,2023-01-16 02:24:50+00:00,https://twitter.com/GaryMarcus/status/1614810883221520385,"@NathanpmYoung @labenz @ezraklein i just marked up @labenz‚Äôs draft. i daresay that on a few of my predictions, he actually agrees!"
362,@GaryMarcus,2023-01-16 02:11:59+00:00,https://twitter.com/GaryMarcus/status/1614807649283104770,"@NathanpmYoung @ezraklein @labenz yes. I mean, they are powerful at generating bullshit, and useful for programming, but weak at reasoning, factuality, etc. does depend on what you want. i want to understand how AGI could be built and LLMs aren‚Äôt that."
363,@GaryMarcus,2023-01-16 02:10:58+00:00,https://twitter.com/GaryMarcus/status/1614807391081762817,"@labenz @NathanpmYoung @ezraklein and I plan to take the bet! (but need to read through and discuss the details w you, first)"
364,@GaryMarcus,2023-01-16 02:09:47+00:00,https://twitter.com/GaryMarcus/status/1614807095064539136,"@labenz @NathanpmYoung @ezraklein - more powerful than I say in what way? vague!
- fact that they cannot stick to physics, history, math etc is a massive problem, whatever you call it. 
- no real solutions yet to any key problem i pointed out 
- I follow interpretability lit, but black box is far from unlocked"
365,@GaryMarcus,2023-01-16 02:06:44+00:00,https://twitter.com/GaryMarcus/status/1614806327653720065,"@NathanpmYoung @ezraklein @labenz i was careful not to say literal cut * paste; i explain in more detail in two recent posts on substack. but the made up stuff is a massive *ongoing* problem that reflects that the system cannot keep itself consistent with its own training data. 

there‚Äôs nothing 2020 about that."
366,@GaryMarcus,2023-01-16 01:53:14+00:00,https://twitter.com/GaryMarcus/status/1614802928912695296,"Cannot believe this is still circulating when it‚Äôs fundamental empirical claim is so thoroughly wrong, and when none of what I said in reply has even been addressed.

It‚Äôs like politics. Just tells you what people *want* to believe‚Ä¶.

https://t.co/dobWhIibgr"
367,@GaryMarcus,2023-01-16 01:51:14+00:00,https://twitter.com/GaryMarcus/status/1614802427601129475,"@NathanpmYoung @ezraklein @labenz You are kidding right? 
- His foundational claim was the errors that I made have been solved. They haven‚Äôt. There have been 100s of similar examples posted since his thread
- I responded at length and heard no substantive reply:"
368,@GaryMarcus,2023-01-16 00:17:10+00:00,https://twitter.com/GaryMarcus/status/1614778751858114560,"üíØ @DJFreshUK

Too many people take for granted that AI‚Äîin its current incarnation, tech-wise &amp; policywise‚Äîwill necessarily be net positive

Too many overlook its tendency towards misinformation

Too few stand by rights of artists, coders, pedestrians etc. who have not consented."
369,@GaryMarcus,2023-01-15 23:07:59+00:00,https://twitter.com/GaryMarcus/status/1614761343852351489,@mukdal exactly!! that‚Äôs a big part of why I have been arguing for hybrid AI for 30 years :)
370,@GaryMarcus,2023-01-15 20:20:47+00:00,https://twitter.com/GaryMarcus/status/1614719263297740801,"The Smug Archive
üëâcherry-picks
üëâignores nukes &amp; tech that has actually cause major harm (submachine guns, pesticides, etc)
üëâignores importance of regulation (seatbelts, airplane certification etc)
üëâignores tech that failed (full self-driving, Facebook M, dirigibles etc)"
371,@GaryMarcus,2023-01-15 19:49:31+00:00,https://twitter.com/GaryMarcus/status/1614711396586950656,"in older approaches to AI, people applied to bandages, to address the brittleness, but they were embarrassed about it and knew it wasn‚Äôt really working.

In new approaches, people  regularly apply patches, without shame, but the brittleness remains."
372,@GaryMarcus,2023-01-15 19:46:06+00:00,https://twitter.com/GaryMarcus/status/1614710538784612353,"The problem with old-fashioned symbolic AI was that it was brittle.

The problem with modern AI is that it is brittle, and hardly anyone seems to care."
373,@GaryMarcus,2023-01-15 18:15:17+00:00,https://twitter.com/GaryMarcus/status/1614687681723916288,"@davidmanheim @ben_j_todd @ezraklein I do not. But I have grown tired of the discussion; I have made each of these points at length in recent articles in Substack, SciAm, Nautilus, etc, and in technical articles in arXiv and TMLR. 

peace, out."
374,@GaryMarcus,2023-01-15 17:38:54+00:00,https://twitter.com/GaryMarcus/status/1614678525201768448,"@davidmanheim @ben_j_todd @ezraklein with respect to the criteria I laid out, it has. Check the 10 issues I raised. Which have been solved? 1/10? In ten years, people will see LLMs commercially viable (yet problematic) but a detour relative to trustworthy AI.

And even commercial value is still speculative."
375,@GaryMarcus,2023-01-15 17:17:45+00:00,https://twitter.com/GaryMarcus/status/1614673205314355205,"@alexjc Seems to me that there are two orthogonal issues:
- should your architecture be open? 
- where do you get your data from/are contributors justly compensated?

Both are tricky. But virtue in one doesn‚Äôt logically entail virtue in the other."
376,@GaryMarcus,2023-01-15 16:56:12+00:00,https://twitter.com/GaryMarcus/status/1614667781001338881,"@davidmanheim @PaulTopping @ben_j_todd @ezraklein Read https://t.co/C6XodPcoZW; it went to press just before LLMs became popular but lays out many challenges for genuine intelligence. I don‚Äôt see how LLMs resolve any of them. It‚Äôs not compositional and can‚Äôt reason, so it‚Äôs just a giant but superficial statistical approximator"
377,@GaryMarcus,2023-01-15 16:36:33+00:00,https://twitter.com/GaryMarcus/status/1614662835271004161,"@davidmanheim @PaulTopping @ben_j_todd @ezraklein not in the areas that I have emphasized for over two decades. in my view we have tons of superficial progress, but little progress in the deeper problems that would get us to genuine and trustworthy intelligence. 

And are entering a mess of misinformation we are ill prepared for"
378,@GaryMarcus,2023-01-15 16:33:50+00:00,https://twitter.com/GaryMarcus/status/1614662151624622080,"@davidmanheim @PaulTopping @ben_j_todd @ezraklein I predicted driverless cars would be harder than expected, language comprehension would be poor, reasoning would be poor; they still are. 

I based these predictions around distribution shift; importance of that is now recognized.

You put words in my mouth that I did not say"
379,@GaryMarcus,2023-01-15 16:23:15+00:00,https://twitter.com/GaryMarcus/status/1614659486131818497,@coecke Maybe they are using Twitter‚Äôs Named Entity Recognition algorithm
380,@GaryMarcus,2023-01-15 16:18:44+00:00,https://twitter.com/GaryMarcus/status/1614658352700850179,bet we will see a lot of this in the hallucinatory ChatGPT era‚Ä¶
381,@GaryMarcus,2023-01-15 16:12:49+00:00,https://twitter.com/GaryMarcus/status/1614656860707237890,@davidmanheim @PaulTopping @ben_j_todd @ezraklein What are you claiming exactly? I stand by all the concerns there and would go further and note that Yann LeCun ridiculed the paper at the time but now basically makes all the same points in his own talks.
382,@GaryMarcus,2023-01-15 16:07:10+00:00,https://twitter.com/GaryMarcus/status/1614655440046161921,@soboleffspaces @rodgerkibble @kareem_carr all for disclosure - but how about a checkbox rather than authorship?
383,@GaryMarcus,2023-01-15 15:38:53+00:00,https://twitter.com/GaryMarcus/status/1614648324270985222,"@davidmanheim @ben_j_todd @ezraklein come again? I have been exceptionally public about I believe, eg in my predictions that deep learning alone would have trouble with driverless cars, reasoning about the world, and accurate language comprehension. 

Those predictions have held true."
384,@GaryMarcus,2023-01-15 00:51:06+00:00,https://twitter.com/GaryMarcus/status/1614424906720247808,"@ASteckley @PaulTopping sorry, typo: mentioning/including"
385,@GaryMarcus,2023-01-14 19:42:50+00:00,https://twitter.com/GaryMarcus/status/1614347325681565696,"a benefit to mentoring ChatGPT as an author that I hadn‚Äôt considered ü§£ 

(Thanks, @PaulTopping!) https://t.co/GiyrfLRWQS"
386,@GaryMarcus,2023-01-14 19:20:41+00:00,https://twitter.com/GaryMarcus/status/1614341754253357056,@tunguz And yet the paper itself shows that the systems fail to meet that low bar. (Ps scientific prose is lousy but convention but need not be.)
387,@GaryMarcus,2023-01-14 19:19:20+00:00,https://twitter.com/GaryMarcus/status/1614341413013180416,"People gonna believe what they want to believe. 

Here: lot of people liked this tweet, but not many read the actual paper or noticed @miguelisolano‚Äôs correction below, which shows that the tweet got the paper wrong."
388,@GaryMarcus,2023-01-14 19:09:16+00:00,https://twitter.com/GaryMarcus/status/1614338878214922240,"I love @Aella_Girl‚Äôs bold, empirically-driven Kinsey surveys for the modern age. 

But by same token I am worried about people starting to take advice from a chatbot with a very superficial notion of what it is taking about. 

+1 to still asking hive mind on a question like this."
389,@GaryMarcus,2023-01-14 19:02:37+00:00,https://twitter.com/GaryMarcus/status/1614337204813463553,@maier_ak @fabiochiusi Sure but please do not call it a coauthor just because it helped you with some API calls
390,@GaryMarcus,2023-01-14 18:58:18+00:00,https://twitter.com/GaryMarcus/status/1614336119310807040,"@Martin_Heyam @kareem_carr This is absolutely a key goal, as I emphasized on the Ezra Klein.  But we need to rethink how we are spending our research dollars if we want to get there anytime soon,  and to misattribute deep comprehension to systems that lack it."
391,@GaryMarcus,2023-01-14 18:50:46+00:00,https://twitter.com/GaryMarcus/status/1614334222042562560,@ben_j_todd ha ha and totally not the real issues (see my reply)
392,@GaryMarcus,2023-01-14 18:49:56+00:00,https://twitter.com/GaryMarcus/status/1614334014483206145,"@ben_j_todd maybe you have not read the more serious criticisms, yet? 
Top 3:
- fundamental issue with hallucination &amp; factuality 
- misleading authority in false answers
- misuse for purveying misinformation 
See recent articles at https://t.co/8ir1xKenr6 &amp; on @EzraKlein show

#ChatGPT"
393,@GaryMarcus,2023-01-14 17:44:43+00:00,https://twitter.com/GaryMarcus/status/1614317599843844096,@LetThereBeAIML They will be here: https://t.co/JvqoeaXpUR
394,@GaryMarcus,2023-01-14 17:27:33+00:00,https://twitter.com/GaryMarcus/status/1614313282353135616,"Trending this week: adding ChatGPT to scientific papers.

Here‚Äôs why that‚Äôs a terrible idea: https://t.co/vbqfxflNnP

cc @kareem_carr"
395,@GaryMarcus,2023-01-14 12:47:18+00:00,https://twitter.com/GaryMarcus/status/1614242754145705985,Excellent thread on AI utopianism &amp; it‚Äôs challenges
396,@GaryMarcus,2023-01-14 11:43:11+00:00,https://twitter.com/GaryMarcus/status/1614226620335943680,@deliprao Agree! My own take: https://t.co/vbqfxflNnP
397,@GaryMarcus,2023-01-14 04:00:02+00:00,https://twitter.com/GaryMarcus/status/1614110062355836928,@ryankatzrosene https://t.co/vbqfxflNnP
398,@GaryMarcus,2023-01-14 03:14:38+00:00,https://twitter.com/GaryMarcus/status/1614098636329320448,@fialkool Corrected since my tweet earlier in the day? Stochastic?
399,@GaryMarcus,2023-01-14 02:45:40+00:00,https://twitter.com/GaryMarcus/status/1614091350294802433,5 reasons why you shouldn‚Äôt include ChatGPT in your list of coauthors üôè
400,@GaryMarcus,2023-01-14 02:37:18+00:00,https://twitter.com/GaryMarcus/status/1614089244557053954,@CranfordMATTER https://t.co/vbqfxflNnP
401,@GaryMarcus,2023-01-14 02:37:03+00:00,https://twitter.com/GaryMarcus/status/1614089180312899584,"Scientists, please don‚Äôt let your chatbots grow up to be co-authors.

Five reasons why including ChatGPT in your list of authors is a bad idea

https://t.co/C7817jyh7f"
402,@GaryMarcus,2023-01-13 23:12:45+00:00,https://twitter.com/GaryMarcus/status/1614037767524323329,"correct answer, via Google https://t.co/r72fwAC5La"
403,@GaryMarcus,2023-01-13 22:44:32+00:00,https://twitter.com/GaryMarcus/status/1614030666127282177,"@nxthompson runner‚Äôs humor, the ChatGPT edition"
404,@GaryMarcus,2023-01-13 22:42:10+00:00,https://twitter.com/GaryMarcus/status/1614030070947119108,You do the math. ChatGPT didn‚Äôt actually win this round üôÑ
405,@GaryMarcus,2023-01-13 19:32:36+00:00,https://twitter.com/GaryMarcus/status/1613982363817758721,Anyone else feeling this way?
406,@GaryMarcus,2023-01-13 17:42:16+00:00,https://twitter.com/GaryMarcus/status/1613954599303655424,@GMondaSilva @jpwiseuk @charleskfisher A lot lower.
407,@GaryMarcus,2023-01-13 04:21:54+00:00,https://twitter.com/GaryMarcus/status/1613753178205622278,"If and when $SNTA gets that self-driving sleigh thing solved, he is going to totally own logistics."
408,@GaryMarcus,2023-01-13 02:47:59+00:00,https://twitter.com/GaryMarcus/status/1613729544103661568,Hey @ylecun can we switch roles already?  What happened to taking turns?
409,@GaryMarcus,2023-01-13 02:43:30+00:00,https://twitter.com/GaryMarcus/status/1613728413596127233,If only.
410,@GaryMarcus,2023-01-13 02:35:44+00:00,https://twitter.com/GaryMarcus/status/1613726459457343489,"humanity‚Äôs last words, said to GPT 6, in early 2030:

 ‚Äúoh shit! I meant for you to take my request literally‚Äîand I forgot to specify that in the prompt! 

Noooooooooooo!‚Äù"
411,@GaryMarcus,2023-01-13 02:05:40+00:00,https://twitter.com/GaryMarcus/status/1613718896133165057,how can anyone think that we are close to AGI when current systems can‚Äôt even reliably answer queries like ‚Äúwrite a one page biography of X‚Äù without making stuff up?
412,@GaryMarcus,2023-01-12 19:44:02+00:00,https://twitter.com/GaryMarcus/status/1613622854012243968,My friend ChatGPT3 says today was a big day @Twitter https://t.co/0kGhF8tj8d
413,@GaryMarcus,2023-01-12 16:48:40+00:00,https://twitter.com/GaryMarcus/status/1613578721700593664,"@sergia_ch @emilymbender @haleyhaala Because I do not wish to splinter the left, I would be happy to be extremely flexible in virtually all regards, and would welcome @critical_AI‚Äôs leadership, and follow their lead."
414,@GaryMarcus,2023-01-12 16:46:37+00:00,https://twitter.com/GaryMarcus/status/1613578205020971008,"@sergia_ch @marypcbuk @timnitGebru @PsychScientists of course not. But it‚Äôs all I can do, and I am trying to do it. The charges of insincerity are really grating."
415,@GaryMarcus,2023-01-12 16:44:45+00:00,https://twitter.com/GaryMarcus/status/1613577734910869504,"@sergia_ch @emilymbender @HenrySiqueiros @timnitGebru Because (a) how she consistently mistreats me &amp; (b) because in reply she quoted something out of context from Ezra Klein making it clearly her remark targeted me. (she did not respond to my clarification, either)

she has splintered the left based on a profound misreading of me."
416,@GaryMarcus,2023-01-12 16:18:11+00:00,https://twitter.com/GaryMarcus/status/1613571051149209601,"‚ÄúI would advocate *not* moving fast and breaking things,‚Äù

@demishassabis, with important words of caution. I hope that the AI world will take heed."
417,@GaryMarcus,2023-01-12 15:31:06+00:00,https://twitter.com/GaryMarcus/status/1613559199556075520,"Again urging that everybody read Ned Block‚Äôs devastating critique of racist pseudo-science, today. 

Take a few minutes of your day. 

Thank you. Link below."
418,@GaryMarcus,2023-01-12 15:23:46+00:00,https://twitter.com/GaryMarcus/status/1613557354985066497,"So sorry that all those things I said on @ezraklein turn out to be outmoded. Oh, wait‚Ä¶ üôÑ"
419,@GaryMarcus,2023-01-12 06:09:02+00:00,https://twitter.com/GaryMarcus/status/1613417750197866502,"Actually davinci3 was at least the 5th or so large language model that OpenAI has presented; I first pointed out problems of this general type in 2019.

I have already publicly predicted that these kinds of world-tracking errors will remain in GPT-4 &amp; stand by those predictions."
420,@GaryMarcus,2023-01-12 05:47:53+00:00,https://twitter.com/GaryMarcus/status/1613412427957432322,"@ljbuturovic @jpineau1 IMHO you are focusing on wrong things here, eg fussy details (what counts as AI or use).

You are certainly correct that the problem is not unique to AI (I pointed to @jpineau1‚Äôs general checklist, very well aware). 

But in no way is medical AI immune to these problems."
421,@GaryMarcus,2023-01-12 05:43:29+00:00,https://twitter.com/GaryMarcus/status/1613411321697144837,"Best analysis of Bostrom‚Äôs shocking email and inadequate apology I‚Äôve seen is a series of comments by @rajiinio

I would also urge everyone to read @de_dicto‚Äôs classic shredding of whatever half-assed science Bostrom may have had in mind: https://t.co/t18go4JDPX"
422,@GaryMarcus,2023-01-12 05:20:02+00:00,https://twitter.com/GaryMarcus/status/1613405422203068416,@davidmanheim @archstreetllc where were you this morning when I needed you?
423,@GaryMarcus,2023-01-12 03:56:42+00:00,https://twitter.com/GaryMarcus/status/1613384447348584450,"GPT-3 DaVinci‚Äôs capacity for dynamically constructing cognitive models still shows room for improvement, but this new ‚Äúprobability spectrum‚Äù feature is terrific. 

Thank you, @openAI. (Example &amp; h/t from @ErnestSDavis) https://t.co/iVqb4trVjc"
424,@GaryMarcus,2023-01-12 03:51:47+00:00,https://twitter.com/GaryMarcus/status/1613383213514383360,story of my recent life üôÑ
425,@GaryMarcus,2023-01-12 03:34:32+00:00,https://twitter.com/GaryMarcus/status/1613378870300016641,"@_kramki @will_peak If you were me, and did so. would be pilloried for revising history and covering up. #

And many of the points I said remain; only if the company makes more than double Microsoft‚Äôs entire 2022 profits do the extra provisions kick in."
426,@GaryMarcus,2023-01-12 02:39:09+00:00,https://twitter.com/GaryMarcus/status/1613364934251016199,"@ShannonVallor @anderssandberg I am with @ShannonVallor that there is no defense here.  

No person in the last decade of the 20th century should have written that. 

Or thought it."
427,@GaryMarcus,2023-01-12 01:47:29+00:00,https://twitter.com/GaryMarcus/status/1613351928926441472,@YablokoU @jbthinking @MMikeMMa @BethCarey12 It is fast evolving but I don‚Äôt think any particular class of errors has actually been resolved.
428,@GaryMarcus,2023-01-12 01:46:18+00:00,https://twitter.com/GaryMarcus/status/1613351634347909120,@nsaphra @HenrySiqueiros @emilymbender @timnitGebru Also he has listened respectfully to criticism. How many of us can truly say that?
429,@GaryMarcus,2023-01-12 01:44:19+00:00,https://twitter.com/GaryMarcus/status/1613351131765440512,"@nsaphra @HenrySiqueiros @emilymbender @timnitGebru Some is, some isn‚Äôt (as w me), but that point is fair. 

Still, people are being a bit unkind.

Put differently, Timnit &amp; I are beefing over something stupid (I wish we would stop) but it‚Äôs worth asking what the real intellectual issue is, and OP deserves credit for trying."
430,@GaryMarcus,2023-01-12 01:37:53+00:00,https://twitter.com/GaryMarcus/status/1613349514441805824,"@HenrySiqueiros @timnitGebru sorry that Twitter is such a nasty place and that people are piling on; you were well-intentioned and it is worth clarifying the geography of positions. 

I tried to use this both to affirm where I agree w @timnitGebru and to clarify where @emilymbender misunderstands me."
431,@GaryMarcus,2023-01-12 01:32:54+00:00,https://twitter.com/GaryMarcus/status/1613348262194614274,"@davidsancar @WIRED Outmaneuvered maybe but ‚Äúunderdogs‚Äùreally misses all that I mentioned and the billion dollars and internal access they already got from MSFT, before now."
432,@GaryMarcus,2023-01-12 01:23:06+00:00,https://twitter.com/GaryMarcus/status/1613345794626834432,@davidsancar @OpenAI Underdogs? They launched with a pledged billion dollars in funding and big names like Musk and Thiel backing them and connecting them. Altman ran YC. Hoffman is on their board and Microsoft‚Äôs.
433,@GaryMarcus,2023-01-12 01:14:31+00:00,https://twitter.com/GaryMarcus/status/1613343635046793217,"@emilymbender @HenrySiqueiros @timnitGebru Penicillin is a fine drug but not to the answer to all medicine.

Please read my actual work, as I have read yours, beginning with final two pages of Rebooting AI, esp ‚ÄúWhich is not to say all will be good‚Äù &amp; ‚Äúsolving AI won‚Äôt be panacea‚Äù, and our concerns about inequality. https://t.co/3Cio0vLrA6"
434,@GaryMarcus,2023-01-12 00:48:52+00:00,https://twitter.com/GaryMarcus/status/1613337178666594304,@emilymbender @HenrySiqueiros @timnitGebru Excuse me @emilymbender but you have totally strawpersonned me if you think I belong in that bin. I think AI can do a lot note good than it has but I don‚Äôt think eg it can magically solve political problems nor that we should take humans out of the loop or ignore them in design.
435,@GaryMarcus,2023-01-12 00:14:10+00:00,https://twitter.com/GaryMarcus/status/1613328447547269120,"@timnitGebru @HenrySiqueiros 2. I am perhaps more focused on technical issues (eg distribution shift, sample efficiency) but we share technical concerns about LLMs that aren‚Äôt all that different, and you should read her stochastic parrots paper if you haven‚Äôt."
436,@GaryMarcus,2023-01-12 00:12:18+00:00,https://twitter.com/GaryMarcus/status/1613327978397663232,"@timnitGebru @HenrySiqueiros 1.@timnitGebru and I are both deeply concerned about tech‚Äôs near-term impact. 

I fully endorse her concerns about how current tech disproportionately affects minorities (see my pinned tweet).

I am lately focused esp. on risks of automated misinformation.

Both issues are vital."
437,@GaryMarcus,2023-01-11 22:48:21+00:00,https://twitter.com/GaryMarcus/status/1613306850212212736,Brilliant saying from Polish!
438,@GaryMarcus,2023-01-11 22:17:28+00:00,https://twitter.com/GaryMarcus/status/1613299079764901890,"@PaulReiser vancouver BC, please, fan of yours since Diner and ever more."
439,@GaryMarcus,2023-01-11 22:08:02+00:00,https://twitter.com/GaryMarcus/status/1613296703867879424,"@soniajoseph_ Good though that Melinda, Laurene, MacKenzie are making some efforts."
440,@GaryMarcus,2023-01-11 22:04:13+00:00,https://twitter.com/GaryMarcus/status/1613295742298501120,@nlpnyc @bengoertzel This is his third great thread in seven weeks. Good track record.
441,@GaryMarcus,2023-01-11 21:32:29+00:00,https://twitter.com/GaryMarcus/status/1613287755911696384,"Meanwhile, back in the real world, 15% staff cut at Alphabet‚Äôs AI-oriented healthcare company Verily"
442,@GaryMarcus,2023-01-11 21:27:04+00:00,https://twitter.com/GaryMarcus/status/1613286393681448962,@sharongoldman But see my update. semafor misreported!
443,@GaryMarcus,2023-01-11 21:15:07+00:00,https://twitter.com/GaryMarcus/status/1613283386122199040,@chessninja @AF4C_FirstMove @theharryshearer
444,@GaryMarcus,2023-01-11 21:13:07+00:00,https://twitter.com/GaryMarcus/status/1613282885267775488,@cyberandy @fourweekmba Yes I mentioned that in my last pgh.
445,@GaryMarcus,2023-01-11 21:07:38+00:00,https://twitter.com/GaryMarcus/status/1613281504997830656,@DrJimFan @danijarh A bit annoying the author has blocked me such that I can‚Äôt see the work
446,@GaryMarcus,2023-01-11 20:05:25+00:00,https://twitter.com/GaryMarcus/status/1613265846746611713,"As ever, listen @BenGoertzel, one of the clearest thinkers in AGI:"
447,@GaryMarcus,2023-01-11 19:45:12+00:00,https://twitter.com/GaryMarcus/status/1613260759907328000,@tabithagold also Angela Sheffield at Raft.
448,@GaryMarcus,2023-01-11 19:44:38+00:00,https://twitter.com/GaryMarcus/status/1613260617707839488,@stevecrossan @tabithagold @HMRoff i was about to suggest Heather as well. Steve beat me there :)
449,@GaryMarcus,2023-01-11 19:33:18+00:00,https://twitter.com/GaryMarcus/status/1613257764935184385,@ColinHayhurst @OpenAI @noUpside @ylecun @Meta @MetaAI its a quote from the paper (which could use a conventional abstract)
450,@GaryMarcus,2023-01-11 19:28:35+00:00,https://twitter.com/GaryMarcus/status/1613256577871642628,". @OpenAI and @noUpside stand in clear opposition to @ylecun and @meta / @metaAI here:

 ‚Äúnewer generative models have a high probability of being adopted in future influence operations, and that no reasonable mitigations can be expected to fully prevent this.‚Äù"
451,@GaryMarcus,2023-01-11 18:45:05+00:00,https://twitter.com/GaryMarcus/status/1613245628624297984,"You can make Clippy better, or be the first to build AGI. Which do you choose? ü§£"
452,@GaryMarcus,2023-01-11 18:39:44+00:00,https://twitter.com/GaryMarcus/status/1613244283968180224,Nice way of putting the OpenAI equity reversion bar (see below) in perspective
453,@GaryMarcus,2023-01-11 18:37:58+00:00,https://twitter.com/GaryMarcus/status/1613243837773938688,"@jordannovet and openAI something like 10s of M from what i hear, so that does put the upper bar in perspective. thanks!"
454,@GaryMarcus,2023-01-11 18:14:40+00:00,https://twitter.com/GaryMarcus/status/1613237974640263168,@davidmanheim @archstreetllc and i also sent out this fresh tweet (rather than delete history)
455,@GaryMarcus,2023-01-11 18:11:13+00:00,https://twitter.com/GaryMarcus/status/1613237106683572226,"Update!
üëâThe headline of this essay raised interesting questions.
üëâBut OpenAI is getting a much better deal than the initial reports that I relied on suggested. 
üëâI have updated my take at the end.
üëâIt is still a very interesting deal. How it all lands remains fascinating!"
456,@GaryMarcus,2023-01-11 17:59:48+00:00,https://twitter.com/GaryMarcus/status/1613234235565051904,@StefanFSchubert @btnelson just reread your suggestion and like it better; misread it the first time. i will tweet some kind of summary of where things stand
457,@GaryMarcus,2023-01-11 17:34:22+00:00,https://twitter.com/GaryMarcus/status/1613227832179830785,"@StefanFSchubert @btnelson yes but others are; i am getting conflicting advice, all delivered with certainty. like the father the son and the donkey‚Ä¶"
458,@GaryMarcus,2023-01-11 17:33:16+00:00,https://twitter.com/GaryMarcus/status/1613227556886695936,@davidmanheim @archstreetllc we all know that if i deleted it that i would be accused of revising history to make myself look favorable. so i have chosen instead to update the article and post further clarifying tweets
459,@GaryMarcus,2023-01-11 17:32:08+00:00,https://twitter.com/GaryMarcus/status/1613227273104281600,"@StefanFSchubert @btnelson i clarified in the article, on that tweet, on my own tweet. if i delete the tweet as some suggest i guarantee i will be accused of revising my own history to be favorable."
460,@GaryMarcus,2023-01-11 17:30:40+00:00,https://twitter.com/GaryMarcus/status/1613226902839517184,@davidmanheim @archstreetllc in a certain sense it may be both.
461,@GaryMarcus,2023-01-11 17:29:05+00:00,https://twitter.com/GaryMarcus/status/1613226503755694080,"@StefanFSchubert @btnelson I agree with first sentence :) and (already) appended a note about the edit, which changes the situation partly but not entirely."
462,@GaryMarcus,2023-01-11 17:19:27+00:00,https://twitter.com/GaryMarcus/status/1613224080093892614,"@btnelson do see the update though, at end of piece, leading me to less certainty."
463,@GaryMarcus,2023-01-11 17:18:20+00:00,https://twitter.com/GaryMarcus/status/1613223796831580167,"@will_peak the info from Semafor was wrong, but i still think important questions are raised; i revised my own view (and still don‚Äôt know what to believe)."
464,@GaryMarcus,2023-01-11 16:55:16+00:00,https://twitter.com/GaryMarcus/status/1613217992405577728,"@jbsto I wrote that whole essay precisely because the deal terms didn‚Äôt make sense, and it made me scratch my head.

In hindsight, I should have just *assumed* the deal terms were probably misreported. (I did at least allow for the possibility. Sigh.)"
465,@GaryMarcus,2023-01-11 16:49:11+00:00,https://twitter.com/GaryMarcus/status/1613216463263010818,"This thread got interesting! Terrific, open-minded response from APA and a chance for you, hive mind, to add your own thoughts on how academic papers ought cite bot-generated output. 

Other journals should take note of this thread as it evolves, too.

#ChatGPT #LLM #GPT3"
466,@GaryMarcus,2023-01-11 16:46:46+00:00,https://twitter.com/GaryMarcus/status/1613215852987576320,"@APA_Style I like the notion that they are *archived* output of a computer program, but not the notion that they are personal per se. 

thanks for responding! will RT so others can add thoughts."
467,@GaryMarcus,2023-01-11 16:44:13+00:00,https://twitter.com/GaryMarcus/status/1613215213989556224,@self_adjoint absolutely. but metabolic function that all that the 500 different proteins in a synapse are there to do? and how about dendrites @YiotaPoirazi and Larkin Lab have shown they are also far more sophisticated
468,@GaryMarcus,2023-01-11 16:39:58+00:00,https://twitter.com/GaryMarcus/status/1613214145016659969,UPDATE: THe reporting was *not* correct. I gave my updated understanding at the end of this essay https://t.co/nQj0iAzePd
469,@GaryMarcus,2023-01-11 16:35:10+00:00,https://twitter.com/GaryMarcus/status/1613212935635218432,Crucial update; Semafor actually got the deal terms wrong. At 4am @jeremyakahn posted the actual terms; i‚Äôve added a link to his story @fortune and some further analysis: https://t.co/HDKXe5ELaO
470,@GaryMarcus,2023-01-11 16:02:38+00:00,https://twitter.com/GaryMarcus/status/1613204748991365122,"Is Microsoft about to get the deal of the century? Or is Sam Altman unloading OpenAI at just the right time? 

Some thoughts: https://t.co/DCaHdKVdH6"
471,@GaryMarcus,2023-01-11 14:19:58+00:00,https://twitter.com/GaryMarcus/status/1613178909994135553,comparing the ‚Äúsynapses‚Äù involved in GPT to biological synapses may turn out to be like comparing a four year old‚Äôs first sketch to the Mona Lisa.
472,@GaryMarcus,2023-01-11 13:48:28+00:00,https://twitter.com/GaryMarcus/status/1613170983095128066,@grsimari üôÑ
473,@GaryMarcus,2023-01-11 07:03:47+00:00,https://twitter.com/GaryMarcus/status/1613069140583157760,"Meanwhile Founders fund and Thrive are reportedly buying big slugs from the founding team, who apparently want to cash out a bunch now, right before the alleged big thing. Which is usually taken as a bad sign.

How does it all fit together?

2/2"
474,@GaryMarcus,2023-01-11 07:03:46+00:00,https://twitter.com/GaryMarcus/status/1613069137798131712,"IF the reporting is all correct‚Ä¶ Altman is playing high stakes poker. He is burning money fast running Chat. He has only modest revenue. VC is tight. at the same time has a very hot demo, yet he is apparently ready to give up almost all of it to investors and msft. Why?

1/2"
475,@GaryMarcus,2023-01-11 06:13:23+00:00,https://twitter.com/GaryMarcus/status/1613056458098356224,"@AAlmeidaAuthor @emilymbender @timnitGebru Because I actually want peace w Bender and Gebru, because I share some of their values (though they fail to see that), and because I think we could accomplish something together.

You have completely misread both me and the exchange with Domingos."
476,@GaryMarcus,2023-01-11 06:06:09+00:00,https://twitter.com/GaryMarcus/status/1613054638051430400,@ethanCaballero ‚Äòcause that‚Äôs how you roll when your scaling is about to solve AGI
477,@GaryMarcus,2023-01-11 05:54:09+00:00,https://twitter.com/GaryMarcus/status/1613051616218992641,‚ÄúThe reproducibility issues that haunt health-care AI‚Äù / ‚Å¶and let me recommend @jpineau1‚Å©‚Äôs reproducibility checklist yet again! https://t.co/EvbIKergHR
478,@GaryMarcus,2023-01-11 03:44:10+00:00,https://twitter.com/GaryMarcus/status/1613018905488031745,@MMikeMMa some elite investors told me not to short Tesla when it was near 400. sigh.
479,@GaryMarcus,2023-01-11 03:17:00+00:00,https://twitter.com/GaryMarcus/status/1613012068772511748,@FramesImpact agree with all that except the MSFT part which is pending; codex is solid (because programmers understand what they are getting) but reliability is a potential issue for other products
480,@GaryMarcus,2023-01-11 02:55:40+00:00,https://twitter.com/GaryMarcus/status/1613006700055007233,@leonpalafox both would be interesting. but real AGI should do it all :)
481,@GaryMarcus,2023-01-11 02:51:45+00:00,https://twitter.com/GaryMarcus/status/1613005715974819840,@leonpalafox what‚Äôs your actual estimate eg for 2030 annual
482,@GaryMarcus,2023-01-11 02:47:05+00:00,https://twitter.com/GaryMarcus/status/1613004542312087553,"@leonpalafox well, if they were really first and unique to AGI, that would be a huge entree into many many markets. of course i don‚Äôt think they are particularly close; just raising hypotheticals."
483,@GaryMarcus,2023-01-11 02:08:01+00:00,https://twitter.com/GaryMarcus/status/1612994710414725120,@leonpalafox @yudapearl Fully agree with @yudapearl on most of what matters.
484,@GaryMarcus,2023-01-11 02:07:06+00:00,https://twitter.com/GaryMarcus/status/1612994478847201282,"Five days ago in this feed, some people tried to persuade me that the AI market will be worth $15.7 trillion/year; now I am being told that selling 50% of an allegedly imminent shot at that market for a mere $15 billion is perfectly reasonable.

Can‚Äôt be both."
485,@GaryMarcus,2023-01-11 01:52:32+00:00,https://twitter.com/GaryMarcus/status/1612990812316659714,"Good hypothetical question: If you thought you actually had the secret to AGI and putting Google out of business, and a significant chance at major revenue soon, would you give up 49% of what you had for &lt; $15B?"
486,@GaryMarcus,2023-01-11 01:25:03+00:00,https://twitter.com/GaryMarcus/status/1612983896316186624,"@bobjinx Not optimistic, beyond secret watermarks that could probably be defeated."
487,@GaryMarcus,2023-01-11 01:18:39+00:00,https://twitter.com/GaryMarcus/status/1612982286382948353,@bobjinx Hard to see how bad actors won‚Äôt exploit it.
488,@GaryMarcus,2023-01-11 00:11:01+00:00,https://twitter.com/GaryMarcus/status/1612965264416735232,"@StefanFSchubert @Ylecun did; i think his argument is that fake info needs to be distributed by recognized actors to have impact. i didn‚Äôt buy the argument, inasmuch as random people with clever tweets sometimes spread info pretty far."
489,@GaryMarcus,2023-01-10 23:47:26+00:00,https://twitter.com/GaryMarcus/status/1612959332559384577,"And still I am told, don‚Äôt worry, we won‚Äôt see in any increase in misinformation."
490,@GaryMarcus,2023-01-10 23:22:59+00:00,https://twitter.com/GaryMarcus/status/1612953177523118080,"say what? GPTChats to be treated as personal communication? 

APA you can do better."
491,@GaryMarcus,2023-01-10 22:41:15+00:00,https://twitter.com/GaryMarcus/status/1612942674528735232,@kl4sp @neilturkewitz @LeonDerczynski @ezraklein @Abebab @AlisonGopnik @AnjaKasp @MelMitchell1 @mer__edith @mmitchell_ai @frossi_t @YejinChoinka @suchisaria @SColesPorter @soniajoseph_ @vboykis @AnimaAnandkumar @emilymbender @timnitGebru @ruha9 @safiyanoble @ruchowdh @ubiquity75 @dmonett @__TweetinChar__ @DorotheaBaur @CjColclough @MiaD @WomeninAIEthics And don‚Äôt forget the fabulous @AnjaKasp
492,@GaryMarcus,2023-01-10 22:26:53+00:00,https://twitter.com/GaryMarcus/status/1612939061387460608,@pmddomingos @emilymbender @timnitGebru The irony here is that my politics are much closer to theirs than yours.
493,@GaryMarcus,2023-01-10 22:24:30+00:00,https://twitter.com/GaryMarcus/status/1612938461115486213,@marypcbuk @timnitGebru @PsychScientists Agreed. That‚Äôs why I publicly apologized yesterday even though I thought that the details were unfair.
494,@GaryMarcus,2023-01-10 21:09:49+00:00,https://twitter.com/GaryMarcus/status/1612919667529764864,"@IrisVanRooij @timnitGebru @PsychScientists @emilymbender You have that backwards. I got upset when two specific *individuals* were accused without strong evidence of being eugenicists. 

I encouraged Abeba to try to develop a related argument that I thought was more nuanced and less individually inflammatory."
495,@GaryMarcus,2023-01-10 21:07:07+00:00,https://twitter.com/GaryMarcus/status/1612918985707917312,"@IrisVanRooij @timnitGebru @PsychScientists @emilymbender I did apologize yesterday, in a tweet in which I promoted 10 of my favorite women. It was sincere; you then publicly told me I needed to apologize ‚Äúsincerely.‚Äù How is that not questioning my sincerity?  that really does not seem fair to me."
496,@GaryMarcus,2023-01-10 21:02:59+00:00,https://twitter.com/GaryMarcus/status/1612917945721839620,"@IrisVanRooij @timnitGebru @PsychScientists @emilymbender They don‚Äôt.  But I do the think we would all be better off if we were allies; I mean that sincerely, and I will keep pushing for it. 

and I *like* helping minorities represent their views. I was disappointed that an important set of issues wasn‚Äôt represented in the last debate."
497,@GaryMarcus,2023-01-10 20:49:32+00:00,https://twitter.com/GaryMarcus/status/1612914562080337920,"@sirbayes @kenarchersf @emilymbender @timnitGebru I failed to mention enough women in my Ezra interview, which I think is a partly fair note (hence I apologized publicly) &amp; partly unfair, because I didn‚Äôt choose or know the questions or control the agenda and have made many efforts elsewhere to include and promote women."
498,@GaryMarcus,2023-01-10 20:22:40+00:00,https://twitter.com/GaryMarcus/status/1612907797783666688,@satiyum What‚Äôs your gpt-indexes to sideload data mean?
499,@GaryMarcus,2023-01-10 20:15:46+00:00,https://twitter.com/GaryMarcus/status/1612906064659513345,"@emilymbender @haleyhaala I am not sure I understand 3

But I do know this shouldn‚Äôt about money and I am to willing to volunteer my own time for the greater good."
500,@GaryMarcus,2023-01-10 20:14:16+00:00,https://twitter.com/GaryMarcus/status/1612905684424855553,@emilymbender @haleyhaala It doesn‚Äôt have be called that or to be that; it can and should be a collective effort to discuss AI ethics from multiple perspectives.
501,@GaryMarcus,2023-01-10 20:12:24+00:00,https://twitter.com/GaryMarcus/status/1612905216650903552,@IrisVanRooij @timnitGebru @PsychScientists This is actually exactly what I did (twice) and I am being taken as insincere. what would you do if you were taken as insincere when you were sincere?
502,@GaryMarcus,2023-01-10 20:11:25+00:00,https://twitter.com/GaryMarcus/status/1612904967677022209,"@IrisVanRooij @timnitGebru @PsychScientists @emilymbender I offered an olive branch in order to lower temperature &amp; am sincere in thinking it would be better if we allied in common ground.

level of distrust relative to my track record is unfair. People that know me know I am being misrepresented. Nobody wishes to be misrepresented."
503,@GaryMarcus,2023-01-10 20:08:34+00:00,https://twitter.com/GaryMarcus/status/1612904251449303042,"@emilymbender @haleyhaala I do this, or try to. in every forum I control‚Äîwhich should be clear from the strong representation of women in my debates and in my tweets‚Äîbut I don‚Äôt control every forum I am in."
504,@GaryMarcus,2023-01-10 20:02:12+00:00,https://twitter.com/GaryMarcus/status/1612902647404859392,@kenarchersf @emilymbender @timnitGebru I did! And the attacks on me continued.
505,@GaryMarcus,2023-01-10 16:51:37+00:00,https://twitter.com/GaryMarcus/status/1612854686411018240,"@emilymbender @haleyhaala this distorts both the context of the episode and what I was trying to say, but rather than going into that I would rather that you focus on the constructive way of going forward that i suggested, and that you recognize that i did in fact take your note, here:"
506,@GaryMarcus,2023-01-10 16:46:35+00:00,https://twitter.com/GaryMarcus/status/1612853419366305795,@asayeed @emilymbender @timnitGebru here:
507,@GaryMarcus,2023-01-10 16:45:38+00:00,https://twitter.com/GaryMarcus/status/1612853180001583104,"@asayeed @emilymbender @timnitGebru I did that, quite pubilcly. I also made huge efforts in my debates. adding to the distortion is not helping."
508,@GaryMarcus,2023-01-10 16:44:32+00:00,https://twitter.com/GaryMarcus/status/1612852903336902657,"@timnitGebru @PsychScientists meanwhile, in addition to yesterday‚Äôs apology that preceded your messages, reprinted above, i was busy writing this at the same time as you were posting. it‚Äôs up to you whether to choose the path of peace or of a war:"
509,@GaryMarcus,2023-01-10 16:42:57+00:00,https://twitter.com/GaryMarcus/status/1612852505742053376,@timnitGebru @PsychScientists I did apologize. You chose to ignore.
510,@GaryMarcus,2023-01-10 16:42:13+00:00,https://twitter.com/GaryMarcus/status/1612852322484523015,@PsychScientists I actually already did that here:
511,@GaryMarcus,2023-01-10 16:38:10+00:00,https://twitter.com/GaryMarcus/status/1612851304027795456,"I hereby invite you, @timnitGebru, @Abebab, @rajiinio, @jovialjoy, @red_abebe, etc to an event, time of your choosing, co-hosted by https://t.co/ucYKX5thdO &amp; @CriticalAI (if they are willing) to showcase vital ethical issues that I was not able to represent on @ezraKlein

2/2"
512,@GaryMarcus,2023-01-10 16:38:10+00:00,https://twitter.com/GaryMarcus/status/1612851302551416833,"Dear @emilymbender,

I come in peace, and not in war; as I wrote to @TimnitGebru privately (no response) a couple days ago, nothing is to be gained from this battle; and we would make better allies than enemies.  

In good faith‚Ä¶

1/2"
513,@GaryMarcus,2023-01-10 16:01:25+00:00,https://twitter.com/GaryMarcus/status/1612842053951709184,"There is no quick fix for ChatGPT! And there won‚Äôt be. 

For an explanation of why not, and for why ChatGPT is so good inferring at wrong answers, please see ‚ÄúWhat‚Äôs going on here‚Äù in https://t.co/lqo1spYPBl and the earlier essay it cites."
514,@GaryMarcus,2023-01-10 15:58:14+00:00,https://twitter.com/GaryMarcus/status/1612841252734767107,"Not one participant in our debates was paid; we‚Äôve never charged for the event.
Everyone who has participated‚Äîfrom Chomsky to Kahneman to @celestekidd, @YejinChoinka, @frossi_t, @anjakasp, @erikbryn, @Montreal_AI &amp; me has generously contributed their time as a gift to the world."
515,@GaryMarcus,2023-01-10 07:36:38+00:00,https://twitter.com/GaryMarcus/status/1612715020374409216,"In many ways my favorite moment in any interview I have ever done. 

Thank you, @ezraklein. https://t.co/4NNFmXF0f4"
516,@GaryMarcus,2023-01-10 06:10:58+00:00,https://twitter.com/GaryMarcus/status/1612693461379223553,@TaylorOgan ‚ÄúFailure is not fraud‚Äù ü§£
517,@GaryMarcus,2023-01-10 06:08:30+00:00,https://twitter.com/GaryMarcus/status/1612692840920027136,"@dsivakumar Even for that story that probably is in the corpus, it misses the point‚Ä¶"
518,@GaryMarcus,2023-01-10 06:02:27+00:00,https://twitter.com/GaryMarcus/status/1612691320077955072,"Who could have predicted this?

Big Data alone is not the answer to cognition. 

It never has been, and it never will be."
519,@GaryMarcus,2023-01-10 05:48:24+00:00,https://twitter.com/GaryMarcus/status/1612687782421598209,"@dsivakumar I seriously doubt that an unaided LLM of any feasible scale could pass on something with a length like a novel, nonfiction book or a feature movie; maybe on short news article."
520,@GaryMarcus,2023-01-10 05:32:37+00:00,https://twitter.com/GaryMarcus/status/1612683813108453377,@deviparikh As well you should be
521,@GaryMarcus,2023-01-10 05:30:51+00:00,https://twitter.com/GaryMarcus/status/1612683365198725120,So many replications and extensions of the issues that @labenz said were already fixed that I have literally lost track.
522,@GaryMarcus,2023-01-10 05:28:07+00:00,https://twitter.com/GaryMarcus/status/1612682677383200768,@dsivakumar I just gave you a link to a very concrete task; come back when you have solved it?
523,@GaryMarcus,2023-01-10 05:27:26+00:00,https://twitter.com/GaryMarcus/status/1612682508788985856,@dsivakumar If you want a citable reference : https://t.co/j6Sz0Vb3iB
524,@GaryMarcus,2023-01-10 05:25:49+00:00,https://twitter.com/GaryMarcus/status/1612682098057564160,@dsivakumar It is what it is. I don‚Äôt think btw the Turing Test accomplished much of anything; eg what has Eugene Goostman brought to general AI?
525,@GaryMarcus,2023-01-10 05:00:06+00:00,https://twitter.com/GaryMarcus/status/1612675628138102787,"@DrJimFan For sure. But they at Siri know sort of how to match the templates with APIs. And how not to overpromise. 

It‚Äôs a striking reality check that LLMs can‚Äôt simply blow that away."
526,@GaryMarcus,2023-01-10 04:05:32+00:00,https://twitter.com/GaryMarcus/status/1612661897823936513,@ojoshe @goodside @paulg @barneyp imagine that
527,@GaryMarcus,2023-01-10 03:38:52+00:00,https://twitter.com/GaryMarcus/status/1612655186765545472,"@NektariosAI @Grady_Booch No, to @ylecun‚Äôs credit he has not blocked me, nor I him though I am sure he has felt tempted. I respect Yann for that, and think that the honorable thing for us is to keep the dialog open.

I hope that he will unblock @Grady_Booch."
528,@GaryMarcus,2023-01-10 02:32:14+00:00,https://twitter.com/GaryMarcus/status/1612638414968614913,"üôè 80,000 followers. It ain‚Äôt Kim Kardashian, or even close. But it still means something to me. 

My thanks to all who follow for supporting me, even as I speak my skeptical mind and sometimes say unfashionable things."
529,@GaryMarcus,2023-01-10 02:19:56+00:00,https://twitter.com/GaryMarcus/status/1612635319706484737,@banazir @pascalefung @jahendler @witbrock @VeredShwartz @nasrinmmm @MMikeMMa link is broken; please see this essay and links there: https://t.co/V3xDRPfWmy
530,@GaryMarcus,2023-01-10 02:17:33+00:00,https://twitter.com/GaryMarcus/status/1612634720826961920,"The tragic thing is that the correct answers actually *already are* in the training corpus.  

But the learning algorithm isn‚Äôt precise enough to reliably retrain them.

Critically, ChatGPT *lacks the ability to validate whether what it says is consistent with its training*."
531,@GaryMarcus,2023-01-10 02:11:38+00:00,https://twitter.com/GaryMarcus/status/1612633231584813056,"@haleyhaala An overestimate of their own chances at AGI and an underestimate how much women might contribute.

It‚Äôs unfortunate that @emilymbender chose to shoot the messenger when we are actually on the same side on both of the above points."
532,@GaryMarcus,2023-01-10 01:59:45+00:00,https://twitter.com/GaryMarcus/status/1612630243197726720,"@pwlot @daniel_eth @rgblong @chafkin @filippie509 was predicting in 2016 that driverless cars weren‚Äôt likely to succeed anytime soon ‚Äúdangerous nonsense‚Äù? how about predicting in 2001 that neural nets would have trouble w distribution shift?

&amp; what is it exactly that makes a prediction that something is hard *dangerous*?"
533,@GaryMarcus,2023-01-10 01:29:56+00:00,https://twitter.com/GaryMarcus/status/1612622739218759681,"@DrJimFan Step 2 is very hard; I wrote about this here:

https://t.co/OFidJ1B1t6"
534,@GaryMarcus,2023-01-10 01:24:48+00:00,https://twitter.com/GaryMarcus/status/1612621448241381376,"@MLWave And now I am blocking you, same reason"
535,@GaryMarcus,2023-01-10 01:23:36+00:00,https://twitter.com/GaryMarcus/status/1612621144821239809,"@MLWave I am unfollowing you because of your attacks in my integrity. The database is open to the entire community and so are the data; people can do as they please, using what suits them."
536,@GaryMarcus,2023-01-10 01:16:56+00:00,https://twitter.com/GaryMarcus/status/1612619467972018176,"@grbradsk Watch @sama‚Äôs interview with Elad Gil, about 29:50 in."
537,@GaryMarcus,2023-01-10 01:13:59+00:00,https://twitter.com/GaryMarcus/status/1612618722107330563,"@nealkhosla A lot rests on the word *key* there. I certainly don‚Äôt think that (even with scaling) they will suffice, but eg they can be useful for certain important components such as classification and paraphrasing, better than other techniques, though perhaps not irreplaceable."
538,@GaryMarcus,2023-01-10 00:23:58+00:00,https://twitter.com/GaryMarcus/status/1612606137446322176,"@dsivakumar i have in various places been clear that understanding would consist in constructing dynamic, interrogable (API-accessible) world models. people do that in eg parts of robotics all that time; it‚Äôs not that obscure."
539,@GaryMarcus,2023-01-09 23:54:19+00:00,https://twitter.com/GaryMarcus/status/1612598675129401345,"Want to help make large language models like ChatGPT better? Read this. (Even better, please considering sharing).

#citizenscience for #GPT

https://t.co/V3xDRPfWmy"
540,@GaryMarcus,2023-01-09 21:57:50+00:00,https://twitter.com/GaryMarcus/status/1612569363323944960,"ML Fans: Please be super nice to the poor baby search engine

Everyone else: You‚Äôve got be kidding"
541,@GaryMarcus,2023-01-09 21:36:44+00:00,https://twitter.com/GaryMarcus/status/1612564051883864066,üò± Is this really the future of search?
542,@GaryMarcus,2023-01-09 21:34:20+00:00,https://twitter.com/GaryMarcus/status/1612563446217990144,@mmitchell_ai @sergia_ch ‚ù§Ô∏è I‚Äôm not perfect but I really do try.
543,@GaryMarcus,2023-01-09 21:33:26+00:00,https://twitter.com/GaryMarcus/status/1612563221105496064,@mmitchell_ai @sergia_ch my pleasure!!! love those double M Mitchell days :) @MelMitchell1
544,@GaryMarcus,2023-01-09 19:32:21+00:00,https://twitter.com/GaryMarcus/status/1612532751135305728,"1. No, ChatGPT doesn't lie because it that no conception of truth. 
2. No it won't (by itself) be able to tell true from false; that's just not how it is built.
3. Yes, AI can have understanding &amp; knowledge. Your nav system has both, albeit in limited ways. Much more is possible!"
545,@GaryMarcus,2023-01-09 18:47:57+00:00,https://twitter.com/GaryMarcus/status/1612521575168999424,@iproduceresultz @labenz and this reply:
546,@GaryMarcus,2023-01-09 17:57:26+00:00,https://twitter.com/GaryMarcus/status/1612508863030517760,@RamaswmySridhar @ShriramKMurthi @vivek7ue See my riff on Twitter trends listing Elon and Musk separately ü§£
547,@GaryMarcus,2023-01-09 17:56:04+00:00,https://twitter.com/GaryMarcus/status/1612508517721833472,@sirbayes @labenz @ezraklein I hope you will read my reply @sirbayes
548,@GaryMarcus,2023-01-09 17:43:41+00:00,https://twitter.com/GaryMarcus/status/1612505402708721664,"Great question, interesting thread; üî• answer from @rasbt"
549,@GaryMarcus,2023-01-09 17:16:55+00:00,https://twitter.com/GaryMarcus/status/1612498665435983872,"@ravinsharma7 @genologos @leecronin @JakeDFoster @labenz all of those were submitted in last few days, and i don‚Äôt think earlier versions are still available. the system is fundamentally inconsistent, eg https://t.co/MroDKxglgO"
550,@GaryMarcus,2023-01-09 17:14:37+00:00,https://twitter.com/GaryMarcus/status/1612498085816733696,"Honestly, the biggest error wasn‚Äôt in @labenz‚Äôs thread, it was in people accepting his claims uncritically."
551,@GaryMarcus,2023-01-09 16:40:14+00:00,https://twitter.com/GaryMarcus/status/1612489433613500416,@sergia_ch @mmitchell_ai Here:
552,@GaryMarcus,2023-01-09 16:36:04+00:00,https://twitter.com/GaryMarcus/status/1612488387881242626,"@sergia_ch @mmitchell_ai a. don‚Äôt think this is fully fair, given that the interview was focused around OpenAI; and Altman who were in the news
B. I already nonetheless tried to balance a bit with a list that included @mmitchell_ai and regularly promote her and many other women."
553,@GaryMarcus,2023-01-09 16:31:42+00:00,https://twitter.com/GaryMarcus/status/1612487288579305474,"Incredible that 
- @labenz claimed that the hallucination problems that I described on @ezraklein were fixed, when clearly they are not
- that hundreds of people believed him, without trying for themselves 

Sad commentary on a misplaced will to believe in magic."
554,@GaryMarcus,2023-01-09 06:58:19+00:00,https://twitter.com/GaryMarcus/status/1612342990546296834,"@filippie509 @rgblong @daniel_eth @chafkin I am not confident that @filippie509 is right but nor am I sure he is wrong 
- business model on generative AI (aside from codex) isn‚Äôt yet clear; not much moat
- driverless cars have been a bust 
- virtual assistants also a bust; big slowdown in Alexa; Facebook M canceled"
555,@GaryMarcus,2023-01-09 06:52:15+00:00,https://twitter.com/GaryMarcus/status/1612341464985665538,"@jacyanthis @daniel_eth @rgblong @chafkin @filippie509 I am happy to make bets on state of AI, less so on how the community (which often doesn‚Äôt appear rational) will react."
556,@GaryMarcus,2023-01-09 06:41:44+00:00,https://twitter.com/GaryMarcus/status/1612338816987336705,"@rgblong @daniel_eth @chafkin @filippie509 problem with that sort of bet is it partly dependent on facts but partly on mood. Tesla felt overvalued to me in 2020, but I couldn‚Äôt predict *when* there would be a correction. Driverless car valuation seemed high to me in 2019 but I didn‚Äôt know when market would recognize it."
557,@GaryMarcus,2023-01-09 05:23:40+00:00,https://twitter.com/GaryMarcus/status/1612319170712174594,@ChadGracia Oh no!
558,@GaryMarcus,2023-01-09 04:03:35+00:00,https://twitter.com/GaryMarcus/status/1612299019090558976,"Apologies that @EzraKlein interview happened mostly to mention men (partly because focus was on OpenAI).

here are 10 of the many great women in AI I follow:
@Abebab
@AlisonGopnik
@AnjaKasp
@MelMitchell1
@mer__edith
@mmitchell_ai
@frossi_t
@YejinChoinka
@suchisaria 
@SColesPorter"
559,@GaryMarcus,2023-01-09 03:42:16+00:00,https://twitter.com/GaryMarcus/status/1612293651438383104,@yassoma @AlisonGopnik No; and further items with kids (see second tweet I added) and an expanded study with adults rule out all the obvious counter arguments; I look forward to the full paper being published.
560,@GaryMarcus,2023-01-09 03:40:47+00:00,https://twitter.com/GaryMarcus/status/1612293281299460098,"A whole bunch of other scenarios led to similar results, with kids at 80%, GPT at chance. https://t.co/m02frTxH3p"
561,@GaryMarcus,2023-01-09 03:30:32+00:00,https://twitter.com/GaryMarcus/status/1612290701747949571,@MatthewJBar There is loads of stuff in the 60s. The Sussman summer vision project etc
562,@GaryMarcus,2023-01-09 03:27:20+00:00,https://twitter.com/GaryMarcus/status/1612289895707602944,"Awesome example @AlisonGopnik just sent me, from her 2022 NeurIPS talk, comparing 4-7 year old children and #GPT-3. 

A piece of paper rips, and the child/GPT has to figure out how to fix it. There‚Äôs no tape; it‚Äôs McGyver time:

Use a bandage? Or scissors? https://t.co/d37ZutViDt"
563,@GaryMarcus,2023-01-09 03:20:23+00:00,https://twitter.com/GaryMarcus/status/1612288145806225408,@MatthewJBar ‚ÄúWithin a generation the problem of creating ‚Äòartificial intelligence‚Äô will be substantially solved.‚Äù
564,@GaryMarcus,2023-01-09 03:20:10+00:00,https://twitter.com/GaryMarcus/status/1612288090730803200,"@MatthewJBar I am afraid I am with the ‚Äúof course‚Äù sentence. Minsky did eventually change his tune, but that article was a big deal and consistent with the whole story and I see no evidence that he protested it at the time. 1967 he said sth similar:"
565,@GaryMarcus,2023-01-09 03:14:40+00:00,https://twitter.com/GaryMarcus/status/1612286705377378306,"@rgblong the failure is only being recognized now, as @chafkin documents, even though @filippie509 &amp; I anticipated it since 2016, &amp; AI funding has in fact softened outside the latest fad, which may turn out to be short lived.  GM pulled out, Apple delayed its project etc‚Äîbut only in 2022"
566,@GaryMarcus,2023-01-09 03:12:04+00:00,https://twitter.com/GaryMarcus/status/1612286054102601728,@rgblong I have some issues with the thread‚Äôs recounting of history and left some notes
567,@GaryMarcus,2023-01-09 03:11:30+00:00,https://twitter.com/GaryMarcus/status/1612285910867128324,"@MatthewJBar I agree that we can‚Äôt induce directly from past history but not convinced by your history.

I recommend https://t.co/hUMRkGdWHH and references cited there, to start"
568,@GaryMarcus,2023-01-09 03:10:36+00:00,https://twitter.com/GaryMarcus/status/1612285684072710144,"@MatthewJBar Simon worked on General Problem Solver; surely he had something like AGI in mind.

the whole thing about the Lighthill report  (that you don‚Äôt mention) is that it led a deceleration in funding: https://t.co/0o6MxxLZzf"
569,@GaryMarcus,2023-01-09 03:07:52+00:00,https://twitter.com/GaryMarcus/status/1612284994336223233,"@MatthewJBar Threading didn‚Äôt work; the quote from Minsky is real, not sure why doubt it."
570,@GaryMarcus,2023-01-09 03:06:21+00:00,https://twitter.com/GaryMarcus/status/1612284613799604224,"@MatthewJBar It was a quote in Life Magazine, back when fact checking was a thing. https://t.co/oiErrGx4f7 (I once saw a scan of the issue; it‚Äôs probably out there)"
571,@GaryMarcus,2023-01-09 02:53:06+00:00,https://twitter.com/GaryMarcus/status/1612281279264993280,"@NunezKant @PessoaBrain @MelMitchell1 @labenz I really don‚Äôt, as explained here;"
572,@GaryMarcus,2023-01-09 02:17:15+00:00,https://twitter.com/GaryMarcus/status/1612272257468108800,"I am learning so much tonight, from my new tutor."
573,@GaryMarcus,2023-01-09 01:33:45+00:00,https://twitter.com/GaryMarcus/status/1612261308644339713,@DaddyOh hence my joke about alternative geography facts
574,@GaryMarcus,2023-01-09 01:30:59+00:00,https://twitter.com/GaryMarcus/status/1612260613488783360,Brush up your Mexican history! And learn new facts about geography with your incredible new tutor!
575,@GaryMarcus,2023-01-09 01:13:48+00:00,https://twitter.com/GaryMarcus/status/1612256290381918211,@MLWave since these systems are known to regurgitate full bits of text (‚Äúdata leakage‚Äù aka ‚Äúmemorization‚Äù in the technical literature) i beg to differ.
576,@GaryMarcus,2023-01-09 01:12:29+00:00,https://twitter.com/GaryMarcus/status/1612255958956412930,A crappy alternative reality that‚Äôs still infinitely better than actual reality.
577,@GaryMarcus,2023-01-09 00:42:23+00:00,https://twitter.com/GaryMarcus/status/1612248382172721152,"@MLWave yes but since they are so well-known and often repeated they could have been added to the training corpus, which we can‚Äôt search."
578,@GaryMarcus,2023-01-09 00:36:22+00:00,https://twitter.com/GaryMarcus/status/1612246868561645570,"@HiFromMichaelV they were massively massively trained. As it happens Chomsky and I recently discussed both the parrots and the results but we just aren‚Äôt convinced of direct relevance.

i published some work on birdsong in Nature &amp; certainly have interest in the literature."
579,@GaryMarcus,2023-01-09 00:30:20+00:00,https://twitter.com/GaryMarcus/status/1612245351716773888,"@MLWave there are lots of google hits for those specific examples, used by Davis and me in 2015 as illustrations before of common sense reasoning, and we have no idea what the training corpus actually includes. 

at least make up your own."
580,@GaryMarcus,2023-01-09 00:17:48+00:00,https://twitter.com/GaryMarcus/status/1612242195767259136,"@BethCarey12 @ylecun and yet i gather that the pages of facebook are still regularly plagued with misinformation that somehow manages to slip through.

most telling thing is that I repeatedly asked him what data Meta has on what fraction of misinfo is generated by LLMs &amp; he has never responded."
581,@GaryMarcus,2023-01-09 00:11:57+00:00,https://twitter.com/GaryMarcus/status/1612240726955552768,"@fredgrenier12 @mdwelsh @bentossell We are very very long way from eg being able to build a browser, a programming language, or an operating system by training examples alone."
582,@GaryMarcus,2023-01-09 00:02:26+00:00,https://twitter.com/GaryMarcus/status/1612238331001311232,Incredible. @ylecun is *still* on his campaign to suggest that any concerns about the possible side effects of large language models are ‚Äúridiculous knee-jerk prophecies of doom‚Äù‚Äîeven after StackOverflow had to (temporarily?) ban LLM-generated content in order to stay alive.
583,@GaryMarcus,2023-01-08 23:55:08+00:00,https://twitter.com/GaryMarcus/status/1612236491513819136,@librarythingtim not sure what you are trying but there are lots of examples like this that aren‚Äôt very impressive: https://t.co/5dGDT76EGp
584,@GaryMarcus,2023-01-08 23:50:49+00:00,https://twitter.com/GaryMarcus/status/1612235407441416194,"@timnitGebru @emilymbender @ezraklein you called two specific people eugenicists; I asked you to clarify what you meant; you didn‚Äôt. I don‚Äôt know either of the people involved at all well, but the charge did not seem fair to me.

the only evidence i ever got was from a distorted quotation from one of the two people."
585,@GaryMarcus,2023-01-08 23:46:40+00:00,https://twitter.com/GaryMarcus/status/1612234360799006721,"@timnitGebru, if you read my book or pinned tweet, you would see I am not the person you imagine.

I do think you use the word eugenics carelessly, but otherwise am with you on short-term risk; my own focus there is misinfo but literally begged @Abebab to discuss bias at debate."
586,@GaryMarcus,2023-01-08 23:32:04+00:00,https://twitter.com/GaryMarcus/status/1612230686794199042,"@timnitGebru @emilymbender @ezraklein That‚Äôs not so. All I have ever said is that your arguments about EA and eugenics are weak, or at least in need of clarification as to what exactly the argument is. (You refused to answer). 

I have never defended EA as such.  Don‚Äôt make stuff up."
587,@GaryMarcus,2023-01-08 23:13:18+00:00,https://twitter.com/GaryMarcus/status/1612225964771250178,"@KevinIndrebo @conor64 Blind trust in a deeply fallible oracle sounds awful to me; i expect this is going to the way of driverless cars: endless hype, massive investment, slow delivery. more here: https://t.co/lqo1spYPBl"
588,@GaryMarcus,2023-01-08 23:10:39+00:00,https://twitter.com/GaryMarcus/status/1612225297734340608,Extremely well put: ‚ÄúYou should trust [ChatGPT] least when you‚Äôre least able to notice it‚Äôs wrong.‚Äù
589,@GaryMarcus,2023-01-08 22:49:11+00:00,https://twitter.com/GaryMarcus/status/1612219895332343808,"Exactly, all the lessons of the cognitive revolution relative to behaviorism seem to have been lost."
590,@GaryMarcus,2023-01-08 22:33:41+00:00,https://twitter.com/GaryMarcus/status/1612215995187474433,@Aye_Patrick_ @genologos @leecronin @JakeDFoster @labenz I did thanks; i may write about it. tl;dr passing a bar exam based on  a large fraction of the internet doesn‚Äôt mean you actually know how to lawyer
591,@GaryMarcus,2023-01-08 22:24:04+00:00,https://twitter.com/GaryMarcus/status/1612213573702545408,"@emilymbender @ezraklein 1. Emily, you rarely if ever cite my work on hype &amp; and limits of neural nets that precedes yours, and yet I cite yours (as recently as today!). Odd for *you* to complain about citation.

2. I‚Äôve invited you, Timnit, Abeba to my debates, exactly to give you a platform. Take it!"
592,@GaryMarcus,2023-01-08 18:34:55+00:00,https://twitter.com/GaryMarcus/status/1612155908645359616,@labenz @ezraklein I think this thread is deeply misguided. I have summarized my thoughts here:
593,@GaryMarcus,2023-01-08 18:34:15+00:00,https://twitter.com/GaryMarcus/status/1612155742127280134,@Peter_Jacobs7 @labenz @ezraklein I urge you to read my reply first:
594,@GaryMarcus,2023-01-08 18:32:07+00:00,https://twitter.com/GaryMarcus/status/1612155201942847488,"In sum: parroting &amp; paraphrasing text is not‚Äîand never will be‚Äîcomprehension, even though *sometimes* correct. 

(See also arguments from  @emilymbender @mmitchell_ai @timnitGebru; @MelMitchell1; @ylecun &amp; @Jake_Browning00)

For that reason, such systems remain dangerous.

END"
595,@GaryMarcus,2023-01-08 18:32:06+00:00,https://twitter.com/GaryMarcus/status/1612155199749251073,"Pastiches like that are *often* true, because many of the underlying sentences they echo are true.

But they can be false too, because system doesn‚Äôt know which pieces belong together. That‚Äôs what it means to *NOT* understand.

more about that here: https://t.co/bbOXczqzRQ

[5/6]"
596,@GaryMarcus,2023-01-08 18:32:06+00:00,https://twitter.com/GaryMarcus/status/1612155198331580416,"A parrot can repeat something that is true; that doesn‚Äôt mean that the parrot knows (or determines, or cares) whether what it is saying is true.

LLMs aren‚Äôt literal parrots; but they are terrific at pastiching together *paraphrases* of things they have been trained on.

[4/6]"
597,@GaryMarcus,2023-01-08 18:32:05+00:00,https://twitter.com/GaryMarcus/status/1612155196913905665,"More than that, the thread is based on a confusion, conflating output with process.

A system that regurgitates with paraphrases can sometimes output text that is true, but that doesn‚Äôt mean that the system *ever* computes whether what it is saying *is* true. 

It doesn‚Äôt.

[3/6]"
598,@GaryMarcus,2023-01-08 18:32:05+00:00,https://twitter.com/GaryMarcus/status/1612155195533975552,"Everything I described on @ezra klein remains a problem.
üëâChatGPT continues to hallucinate
üëâIt continues to present untruths with (false) authority
üëâIt continues to create fake references to support its claims
üëâAs before, such output can easily fool humans, posing risks
[2/6]"
599,@GaryMarcus,2023-01-08 18:32:04+00:00,https://twitter.com/GaryMarcus/status/1612155191616483329,"This popular defense of #GPT is fundamentally misguided.  

Its main claim is that ChatGPT has substantially solved an earlier set of problems, and that‚Äôs just not true.

Consider examples like these just *from the last 48 hours*, all reinforcing my fundamental points.

[Thread] https://t.co/GKGi8ua9Qm"
600,@GaryMarcus,2023-01-08 17:36:09+00:00,https://twitter.com/GaryMarcus/status/1612141117629427712,"Just yesterday I was told all these problems had been fixed since my @ezraklein interview

Guess not.

Notes:
üëâ this question is NOT a trick question
üëâ likely inconsistent w lots of stuff in training database
üëâ no signal about what is fabricated; all presented authoritatively"
601,@GaryMarcus,2023-01-08 16:23:22+00:00,https://twitter.com/GaryMarcus/status/1612122802483757056,"üí∞How to get rich in AI:

üëâPropose an exciting new technology (driverless cars, virtual assistants, new-fangled search‚Ä¶)
üëâPromise fabulous results
üëâRaise a fortune
üëâStumble, because products ‚â† demos
üëâBlame the Data
üëâGather More Data
üëâStumble some more
üëâRinse &amp; Repeat"
602,@GaryMarcus,2023-01-08 05:41:36+00:00,https://twitter.com/GaryMarcus/status/1611961295821230081,seems like a few investors may have missed this memo ü§∑‚Äç‚ôÇÔ∏è
603,@GaryMarcus,2023-01-08 05:20:50+00:00,https://twitter.com/GaryMarcus/status/1611956070280495105,They ought to! But do they?
604,@GaryMarcus,2023-01-08 05:07:21+00:00,https://twitter.com/GaryMarcus/status/1611952677931618305,@hmac_sha1 @SteamboatLion @tylercowen To a first approximation yes
605,@GaryMarcus,2023-01-08 05:06:56+00:00,https://twitter.com/GaryMarcus/status/1611952572755218437,@MarkusSchacher Good luck using stuff like this as search engine if it is 3/4 correct and always sounds authoritative. https://t.co/NQQr1VbQwB
606,@GaryMarcus,2023-01-08 05:05:36+00:00,https://twitter.com/GaryMarcus/status/1611952234899836930,@andywalters @labenz Numerous replies at end of his thread
607,@GaryMarcus,2023-01-08 04:23:54+00:00,https://twitter.com/GaryMarcus/status/1611941743884394496,@rgblong @BeebsMemes Fair point
608,@GaryMarcus,2023-01-08 03:58:06+00:00,https://twitter.com/GaryMarcus/status/1611935248199344128,"@DVHenkelWallace @BeebsMemes Long term optimistic, short term pessimistic, because confusion about absurd claims is leading to over investment in problematic approaches."
609,@GaryMarcus,2023-01-08 03:46:16+00:00,https://twitter.com/GaryMarcus/status/1611932272965607424,@andywalters @labenz I responded to every (?) point; what remains valid?
610,@GaryMarcus,2023-01-08 02:16:11+00:00,https://twitter.com/GaryMarcus/status/1611909603285139456,"Some notes:
üëâall four queries (3 screenshots) had *tons* of relevant data that could have been used 
üëâno ‚Äúit happened after training‚Äù 2022 excuse here
üëâan intelligent agent could trivially get right answers by invoking web search
For rounds 1 and 2, see https://t.co/rmg5y73aNE"
611,@GaryMarcus,2023-01-08 02:16:11+00:00,https://twitter.com/GaryMarcus/status/1611909600772751360,üîîRound 3 in Google vs ChatGPT!
612,@GaryMarcus,2023-01-08 00:58:12+00:00,https://twitter.com/GaryMarcus/status/1611889976698109952,"@rgblong @tylercowen i would say we have 30-40% chance of getting there by 2030, much less if we relied solely on LLMs/scaling. but i think the drive to make Chat style search will encourage better techniques for hybrid AI that could help."
613,@GaryMarcus,2023-01-08 00:43:53+00:00,https://twitter.com/GaryMarcus/status/1611886372599762947,"@danbri @danielko @ezraklein @NewYorker litmus really means better test of comprehension than the easily gamed turing test, as made clear in the 2014 essay: https://t.co/1N4qeEn6uH and 2016 AI article: https://t.co/j6Sz0Vb3iB"
614,@GaryMarcus,2023-01-08 00:41:09+00:00,https://twitter.com/GaryMarcus/status/1611885684905906177,"@rgblong @tylercowen what should have been clearer in the Elon bet is that for it to be AGI *a single system* ought be able to do more than one of the five. 

but i‚Äôd still be genuinely impressed with any system that really fluidly could solve what I raised in 2014 for a wide range of inputs."
615,@GaryMarcus,2023-01-08 00:38:45+00:00,https://twitter.com/GaryMarcus/status/1611885082704510978,"@DotCSV those were illustrative one-liners; the categories of errors (logical, physical) etc are all still unsolved.

many other examples i have given that are longer to state also remain unsolved, eg the comprehension challenge in TNY 2014, free generalization in 2001, L5 driving 2016"
616,@GaryMarcus,2023-01-08 00:30:24+00:00,https://twitter.com/GaryMarcus/status/1611882978422161408,"@BrandoHablando @ezraklein @NewYorker that‚Äôs best use case so far, agreed. if there are two additions i would have made to what i said in podcast
- i should have made clearer that any given error might be resolved, but that the general challenges remain
- I should have given more credit to use in programming"
617,@GaryMarcus,2023-01-08 00:28:12+00:00,https://twitter.com/GaryMarcus/status/1611882427206758400,"@rgblong @tylercowen also, that very task was part of the bet that I offered Elon that he didn‚Äôt. https://t.co/yfXycYXxb9 

8 years, same goal post."
618,@GaryMarcus,2023-01-08 00:26:03+00:00,https://twitter.com/GaryMarcus/status/1611881885936013313,"@rgblong @tylercowen fine to try, but again that was my goalpost in 2014 and it clearly hasn‚Äôt been met yet and i still think it‚Äôs a goal, that (again) I haven‚Äôt shifted.

considering how much I write and how much scrutiny my writing gets, and the time spans involved, that‚Äôs saying a lot."
619,@GaryMarcus,2023-01-07 23:58:53+00:00,https://twitter.com/GaryMarcus/status/1611875047635050497,"üî•, and a little sad that the last sentence even needs repeating. Yet here we are.

cc @bengoertzel"
620,@GaryMarcus,2023-01-07 23:51:32+00:00,https://twitter.com/GaryMarcus/status/1611873200903950337,brain teaser (cc @goodside) https://t.co/X8SlnBVM5a
621,@GaryMarcus,2023-01-07 23:38:37+00:00,https://twitter.com/GaryMarcus/status/1611869948212842496,"@Clarksterh @tylercowen the clearest in 2001 was that that class of networks would fail to freely generalize universally-quantified one to mappings. that was extended to newer models in math by @yasaman_razeghi in Arxiv in 2022, in logic by @guyvdb arXiv 2022."
622,@GaryMarcus,2023-01-07 23:29:08+00:00,https://twitter.com/GaryMarcus/status/1611867560030658561,@BethCarey12 @soboleffspaces @theharryshearer Harry taught me everything he knew after it was recorded :) Wait til the next one!
623,@GaryMarcus,2023-01-07 23:27:59+00:00,https://twitter.com/GaryMarcus/status/1611867273651957760,"@genologos @WiringTheBrain @mazefire56 @ylecun here‚Äôs the word count/failure in abstraction example I mentioned on @ezraklein, reported to me by Andrew Sundstrom [click to see whole thing]: https://t.co/0S00IgfMjv"
624,@GaryMarcus,2023-01-07 23:01:40+00:00,https://twitter.com/GaryMarcus/status/1611860650522972160,"@goodside @samuelshapley @ezraklein @NewYorker am impressed by that one, and wonder how systematic it is."
625,@GaryMarcus,2023-01-07 22:50:27+00:00,https://twitter.com/GaryMarcus/status/1611857827013996546,"@nferraz @tylercowen a lot of short term increase in programmer productivity, against (a) increased distrust and (b) delay in searching other parts of space of potential AGI solutions, including wherever actual answer lies. automated scientific discovery will be delayed."
626,@GaryMarcus,2023-01-07 22:47:05+00:00,https://twitter.com/GaryMarcus/status/1611856981211648001,@pstAsiatech @ezraklein I defer to @swarat on the unit test stuff; my guess is it probably works fine in many simple cases but would break in more subtle ones.
627,@GaryMarcus,2023-01-07 22:39:19+00:00,https://twitter.com/GaryMarcus/status/1611855026699505665,"@nferraz Nobody is arguing they aren‚Äôt useful. I am arguing they they may be dangerous, that there is an opportunity cost, and that may not be on the critical path to AGI.

Cc @tylercowen"
628,@GaryMarcus,2023-01-07 22:37:43+00:00,https://twitter.com/GaryMarcus/status/1611854621320056832,@BeebsMemes Except that it doesn‚Äôt actually care whether it pleases you; it‚Äôs just optimizing next word prediction
629,@GaryMarcus,2023-01-07 22:36:40+00:00,https://twitter.com/GaryMarcus/status/1611854356546211840,"@nferraz No the AI community did not. They said it Go *one* grand challenge among many. Progress was faster than expected there but not on the core general AI that McCarthy Minsky Simon etc dreamed about in 1950 and 1960s. 

That is still unsolved."
630,@GaryMarcus,2023-01-07 22:21:43+00:00,https://twitter.com/GaryMarcus/status/1611850597841653760,@nferraz Ps empirically as @KukiChatbotDev would tell you chatbots could talk about a very wide range of topics by 2012; you just made up whatever it is you are saying AFAIK.
631,@GaryMarcus,2023-01-07 22:20:29+00:00,https://twitter.com/GaryMarcus/status/1611850284640395265,"@nferraz Again, who the heck are you talking about?  

Certainly not me."
632,@GaryMarcus,2023-01-07 22:19:22+00:00,https://twitter.com/GaryMarcus/status/1611850003726872576,"@WiringTheBrain @mazefire56 @ylecun LLMs just don‚Äôt have what is needed to acquire proper world models. 

Sorta like asking what kind of color *experience* would lead a monochromat to see color. 

Sometimes you need evolution/innate architecture &amp; representation in order to have a bootstrap effective learning."
633,@GaryMarcus,2023-01-07 22:14:13+00:00,https://twitter.com/GaryMarcus/status/1611848708492242945,@stuartbuck1 @labenz @ezraklein Shh don‚Äôt tell ü§£
634,@GaryMarcus,2023-01-07 22:13:29+00:00,https://twitter.com/GaryMarcus/status/1611848524936908800,"Literally the only reply to my query below so far is a pointer to goalposts (closed world board games) that I have argued *against* üôÑ 

cc: @tylercowen"
635,@GaryMarcus,2023-01-07 22:09:38+00:00,https://twitter.com/GaryMarcus/status/1611847556396638208,"@nferraz But Go wasn‚Äôt *my* goalpost.  and I never said they would never crack Go. Go as currently addressed is about narrow intelligence, and I keep stressing general intelligence and that doesn‚Äôt represent progress there.

Maybe you have me confused with someone else?"
636,@GaryMarcus,2023-01-07 21:14:18+00:00,https://twitter.com/GaryMarcus/status/1611833631710015489,"Marcus, 2012: deep learning lack a good way to represent causal relationships

ChatGPT, 2023: Kids‚Äô epigenetic state may affect their parents‚Äô epigenetic state.

Marcus, 2023: Pretty weak causal reasoning there

ML Fans 2023: Marcus keeps shifting his goalposts

Um, how exactly? https://t.co/1MeqoPiMok"
637,@GaryMarcus,2023-01-07 19:21:01+00:00,https://twitter.com/GaryMarcus/status/1611805121133821954,"@garretthonke @FelixHill84 And as Chomsky (who was there) pointed out AI used to be a field that welcomed cognitive science, instead of dismissing it. 

perhaps historians may write about how the late 2020s reunification finally allowed for real progress."
638,@GaryMarcus,2023-01-07 19:16:21+00:00,https://twitter.com/GaryMarcus/status/1611803946435366912,@labenz @harishkgarg @ezraklein @tylercowen https://t.co/XTzyvEP0qi
639,@GaryMarcus,2023-01-07 18:57:43+00:00,https://twitter.com/GaryMarcus/status/1611799256247205889,@loretoparisi Sorry not going to fully agree on that one; anyone of that can break with all manner of edge cases
640,@GaryMarcus,2023-01-07 18:43:35+00:00,https://twitter.com/GaryMarcus/status/1611795699024424960,"@labenz @ezraklein See example I just posted with the unwitting housekeeper, for just one of many examples. I am not just talking about post-training; am talking about what happens over the course of a narrative or exposition."
641,@GaryMarcus,2023-01-07 18:31:22+00:00,https://twitter.com/GaryMarcus/status/1611792627279753216,@samtaecassidy Human fact checkers aren‚Äôt perfect but they don‚Äôt get stuck on the Halting Problem either.
642,@GaryMarcus,2023-01-07 18:25:32+00:00,https://twitter.com/GaryMarcus/status/1611791158132486145,@labenz @ezraklein Apropos:
643,@GaryMarcus,2023-01-07 18:24:30+00:00,https://twitter.com/GaryMarcus/status/1611790900514156545,"Of course system is stochastic, will do well in many (short) cases that are canonical, and closer to trained examples, but get thrown by non canonical edge cases, greater length etc. 

also: BigBench showed that scaling didn‚Äôt work well for longer stories. 

2/2"
644,@GaryMarcus,2023-01-07 18:24:30+00:00,https://twitter.com/GaryMarcus/status/1611790897301323777,"dark but illuminating example I mentioned on @ezraklein: ChatGPT fails to build an accurate internal model of what happens in a discourse. 

In 2014 @newyorker (&amp; in https://t.co/Pt7HZc3RJd) I said story comprehension was a better litmus test. 

We are still are not there. 

1/2 https://t.co/Gbz1SobCpI"
645,@GaryMarcus,2023-01-07 18:14:32+00:00,https://twitter.com/GaryMarcus/status/1611788388306391041,"@labenz @ezraklein Something you could reliably interrogate, eg with an API, about a dynamically evolving state of affairs, about objects, agents, states, beliefs, etc. see my Next Decade in AI essay, and long tradition eg in robotics.

What you see is a charitable overattribution."
646,@GaryMarcus,2023-01-07 17:55:58+00:00,https://twitter.com/GaryMarcus/status/1611783717021941760,"@bhdebayan @ezraklein @theharryshearer It‚Äôs not just ‚Äúthe very edge cases‚Äù (&amp; of course edge cases with respect to health advice etc can be fatal so are critically important).

Here‚Äôs a systematic study just reported; even in best case w related system, best techniques &gt; 30% not trustworthy:
(https://t.co/OsiwuFbYqs)"
647,@GaryMarcus,2023-01-07 17:29:23+00:00,https://twitter.com/GaryMarcus/status/1611777026343702528,"@labenz @harishkgarg @ezraklein @tylercowen it‚Äôs not that hard to get either. and that‚Äôs the problem. 

not saying there is no utility to the systems; i am saying that there are costs to trusting it, and lots ways that bad actors can abuse it."
648,@GaryMarcus,2023-01-07 17:25:27+00:00,https://twitter.com/GaryMarcus/status/1611776038211837952,"@labenz @ezraklein apropos, error from today and place to report/monitor:"
649,@GaryMarcus,2023-01-07 17:22:42+00:00,https://twitter.com/GaryMarcus/status/1611775347435110402,"@labenz @ezraklein the problem is that the errors are *principled*; i have been emphasizing the same types of things for years, and they persist. because there is no world model."
650,@GaryMarcus,2023-01-07 17:21:37+00:00,https://twitter.com/GaryMarcus/status/1611775072477548550,"@harishkgarg @labenz @ezraklein it‚Äôs not, though. the system is stochastic, and any given error may get patched (OpenAI does this regularly), but it‚Äôs very easy induce to qualitatively similar errors."
651,@GaryMarcus,2023-01-07 17:20:07+00:00,https://twitter.com/GaryMarcus/status/1611774694176493568,"@labenz @ezraklein source on that one below, this week.

ultra-woke ones I read on Ezra I prepared Dec 19, 3 days before interview.

i mentioned to Ezra before recording (a) the stochasticity and (b) OpenAI‚Äôs frequent patching, but we got so into things we forgot to mention on the air."
652,@GaryMarcus,2023-01-07 16:32:04+00:00,https://twitter.com/GaryMarcus/status/1611762601930948609,"OpenAI is trending; for a skeptical look at #ChatGPT, you might listen to this discussion on @ezraklein‚Äôs podcast."
653,@GaryMarcus,2023-01-07 16:13:08+00:00,https://twitter.com/GaryMarcus/status/1611757840104042497,"#ChatGPT is swiftly-changing beast, old errors are patched, new ones arise. Please keep your examples coming, and submit errors here: https://t.co/t4EZKBKr9G 

Newer models welcome, too! cc @goodside"
654,@GaryMarcus,2023-01-07 15:31:03+00:00,https://twitter.com/GaryMarcus/status/1611747247057952770,"@pwlot @goodside @RobertLepenies Such a myth that I am never impressed! 

Scaling old techniques may never move me, but I posted a full-on wow two days ago re work from @ChangyangLinghu @eboyden3 @nature on a molecular tape recorder that blew me away! 

Real science is often about inventing new things."
655,@GaryMarcus,2023-01-07 14:57:02+00:00,https://twitter.com/GaryMarcus/status/1611738687406223363,"@labenz @ezraklein I couldn‚Äôt make it to the end here. The examples were from ChatGPT, not earlier models. Here‚Äôs a fresh example from yesterday that I just posted about. appeals to a Wittgenstein aren‚Äôt going to change the fact the system generates complete BS in fully authoritative fashion: https://t.co/N8XRz3sD6R"
656,@GaryMarcus,2023-01-07 12:51:53+00:00,https://twitter.com/GaryMarcus/status/1611707191249219585,Perfect example:
657,@GaryMarcus,2023-01-07 12:35:25+00:00,https://twitter.com/GaryMarcus/status/1611703047855706112,"Related thread by @goodside, which confirms predictions I made in The Algebraic Mind (2002; Chapter 3) and extends work by @yasaman_razeghi/@_sameersingh_ in Arxiv 2022"
658,@GaryMarcus,2023-01-07 12:11:15+00:00,https://twitter.com/GaryMarcus/status/1611696967226372096,@yassoma @ezraklein @theharryshearer @emilymbender
659,@GaryMarcus,2023-01-07 12:06:21+00:00,https://twitter.com/GaryMarcus/status/1611695734793056265,"Wow! *Epic* scientific confabulation!  #ChatGPT invents new, impossible scientific principle and alleges it is ‚Äúcurrently a topic of debate in the scientific community‚Äù

Perfect distillation of what I discussed w @ezraklein and @theharryshearer.  Brilliant example."
660,@GaryMarcus,2023-01-06 23:41:10+00:00,https://twitter.com/GaryMarcus/status/1611508200729350144,@ylecun @_RobToews @gdb exactly!
661,@GaryMarcus,2023-01-06 23:31:28+00:00,https://twitter.com/GaryMarcus/status/1611505761527660546,Fully agree w @ylecun on this re LLMs:
662,@GaryMarcus,2023-01-06 23:02:55+00:00,https://twitter.com/GaryMarcus/status/1611498574726180864,@kevinroose @CaseyNewton Me! we should hash out our different views on AI publicly. Cf my show w Ezra earlier today.
663,@GaryMarcus,2023-01-06 22:16:18+00:00,https://twitter.com/GaryMarcus/status/1611486845065650179,"@RTomMcCoy Expressing concerns about the kind of biological plausibility arguments that eg @ylecun made last week, IIRC"
664,@GaryMarcus,2023-01-06 18:56:31+00:00,https://twitter.com/GaryMarcus/status/1611436568400760832,"Um, what if ChatGPT *isn‚Äôt* as intelligent as it seems? 

@EzraKlein @nytimes and I go deep; if you liked my podcast with Lex Fridman, you‚Äôll love this. 

https://t.co/Cq1K2xZLxV"
665,@GaryMarcus,2023-01-06 11:02:04+00:00,https://twitter.com/GaryMarcus/status/1611317170692325378,"The $29,000,000,000 future of web search! 

Facts not included."
666,@GaryMarcus,2023-01-06 05:05:10+00:00,https://twitter.com/GaryMarcus/status/1611227350355816449,@realPeterMorrow @thealexbanks @leonpalafox @mchui
667,@GaryMarcus,2023-01-06 04:56:06+00:00,https://twitter.com/GaryMarcus/status/1611225072207024128,@MichaelKevinSp2 Yep there is a serious (lack of) moat issue.
668,@GaryMarcus,2023-01-06 04:50:17+00:00,https://twitter.com/GaryMarcus/status/1611223605484089346,H/t @LoganTCollins
669,@GaryMarcus,2023-01-06 04:49:39+00:00,https://twitter.com/GaryMarcus/status/1611223446612242432,"wow. A ‚Äúmolecular tape recorder‚Äù. 

This is awesome."
670,@GaryMarcus,2023-01-06 04:41:34+00:00,https://twitter.com/GaryMarcus/status/1611221414148993024,@MichaelKevinSp2 They have to hope (despite modest revenue) that they are unlike the driverless car industry that thus far has been hobbled by  the ratio of edge cases to actual value delivered.
671,@GaryMarcus,2023-01-06 04:37:51+00:00,https://twitter.com/GaryMarcus/status/1611220476134846466,"@leonpalafox @mchui do you still basically stand by these estimates of economic impact of AI from a few years ago? If not, what is your current thinking?"
672,@GaryMarcus,2023-01-06 04:31:53+00:00,https://twitter.com/GaryMarcus/status/1611218976046223362,@thealexbanks Was it from here? https://t.co/p0JJaDg4Ek
673,@GaryMarcus,2023-01-06 04:31:30+00:00,https://twitter.com/GaryMarcus/status/1611218878289563649,@leonpalafox Just found this from which the number@may have been drawn: https://t.co/p0JJaDg4Ek
674,@GaryMarcus,2023-01-06 04:27:17+00:00,https://twitter.com/GaryMarcus/status/1611217817478795264,@leonpalafox Again I would like to see a complete estimate.
675,@GaryMarcus,2023-01-06 04:23:24+00:00,https://twitter.com/GaryMarcus/status/1611216838951833601,@leonpalafox Would love to see your overall estimate on a spreadsheet.
676,@GaryMarcus,2023-01-06 04:21:26+00:00,https://twitter.com/GaryMarcus/status/1611216344887996418,"@leonpalafox In the country with the largest economy, and assuming that across entire industries, consistently for the duration."
677,@GaryMarcus,2023-01-06 04:17:30+00:00,https://twitter.com/GaryMarcus/status/1611215358131859457,"@leonpalafox Pharmacy is 1T; if you double it with AI, you are 1/16 there. but how? are you going to sell twice as many drugs? If you merely add 50% due to AI to that market (which would be astonishing in 7 years); you are only 1/32 of the way there."
678,@GaryMarcus,2023-01-06 04:13:15+00:00,https://twitter.com/GaryMarcus/status/1611214284696203265,"@imtejas13 @kamalojasv181 LLMs definitely will have neg consequences (eg misinformation); but it‚Äôs the opportunity costs that I worry about most. 

We could be curing cancer or solving climate change but most focus now is on using LLMs to make friendlier (not more accurate) search, presumably to sell ads."
679,@GaryMarcus,2023-01-06 04:09:11+00:00,https://twitter.com/GaryMarcus/status/1611213263743897601,@leonpalafox The estimate is more than 100% of the latter two industries combined.
680,@GaryMarcus,2023-01-06 04:02:11+00:00,https://twitter.com/GaryMarcus/status/1611211499917434883,"@leonpalafox Ok, now explain me another six or seven zeroes? More than the entire Chinese economy?"
681,@GaryMarcus,2023-01-06 03:57:40+00:00,https://twitter.com/GaryMarcus/status/1611210365190443010,@PipFoweraker And then multiplied by 10?
682,@GaryMarcus,2023-01-06 03:53:11+00:00,https://twitter.com/GaryMarcus/status/1611209238671679490,@erikbryn @amcafee @paulkrugman your take on this estimate for AI contributions to global economy in 2030?
683,@GaryMarcus,2023-01-06 03:50:34+00:00,https://twitter.com/GaryMarcus/status/1611208577913606146,@thealexbanks Did you make up this 15.7T number? How did you derive it?
684,@GaryMarcus,2023-01-06 03:49:45+00:00,https://twitter.com/GaryMarcus/status/1611208374686994433,"I think this is a vast overestimate. 

anyone want to try to defend it?"
685,@GaryMarcus,2023-01-06 03:33:47+00:00,https://twitter.com/GaryMarcus/status/1611204356589912065,If only that was all that was involved in linguistics!
686,@GaryMarcus,2023-01-06 02:30:28+00:00,https://twitter.com/GaryMarcus/status/1611188418662510593,"@grbradsk @ylecun 1. Don‚Äôt dude me, please
2. Much of that would count as neural and behavioral but eg would muscle memory or movement or visual segmentation  count as *thought*?  Some would reserve the term for things like reasoning etc. 
3. Mouth is probably a typo; corrections is very vague"
687,@GaryMarcus,2023-01-06 02:16:29+00:00,https://twitter.com/GaryMarcus/status/1611184901025562624,"The chance of getting significant investment for anything that isn‚Äôt  an LLM right now is near zero; if LLMs continue to be untruthful and unreliable and nothing else gets well-funded, will those choices turn out to have been a good thing?"
688,@GaryMarcus,2023-01-06 02:03:18+00:00,https://twitter.com/GaryMarcus/status/1611181582941048832,"@matspike Count me  as a skeptic of Minimalism, but ‚ÄúWith most of its antecedents in place‚Äù sounds like ‚Äúbuilds on top of an extant genome‚Äù not ‚Äúall contained in a tiny mutation‚Äù"
689,@GaryMarcus,2023-01-06 01:25:42+00:00,https://twitter.com/GaryMarcus/status/1611172120700260352,@data_prophet vancouver BC
690,@GaryMarcus,2023-01-06 01:25:13+00:00,https://twitter.com/GaryMarcus/status/1611172000587972608,@matspike I have. Where does he say otherwise? What specifically does he say?
691,@GaryMarcus,2023-01-06 01:19:20+00:00,https://twitter.com/GaryMarcus/status/1611170517951647744,@TrustInAutonomy Mine doesn‚Äôt; always free
692,@GaryMarcus,2023-01-06 01:15:04+00:00,https://twitter.com/GaryMarcus/status/1611169445895933956,@DrMJoyner @ylecun @rogerkmoore Condensation of my 2004 book The Birth of the Mind which goes into much more depth on same issue
693,@GaryMarcus,2023-01-06 01:09:46+00:00,https://twitter.com/GaryMarcus/status/1611168111629066240,@matspike See second point below
694,@GaryMarcus,2023-01-06 01:08:46+00:00,https://twitter.com/GaryMarcus/status/1611167858473504768,"@ylecun @rogerkmoore Again, misleading
üëâanimal communication differs from human language in scope (past, future,  counterfactual),neural basis &amp; rich semantics
üëâa tiny number of mutations *coupled* w  inherited genome ‚â† language is contained in tiny portion of genome, see https://t.co/FC84HxuyLj"
695,@GaryMarcus,2023-01-06 00:46:42+00:00,https://twitter.com/GaryMarcus/status/1611162304653000704,"@reknubed The problems with reliability abstraction and truthfulness stand in contradiction to this claim IMHO.

More directly observed in models like DALL-E 2 where semantics can probed more directly.  see 2022 arxiv by @EvelinaLeivada @ElliotMurphy91 and myself"
696,@GaryMarcus,2023-01-06 00:42:45+00:00,https://twitter.com/GaryMarcus/status/1611161312452648961,@killerstorm @ylecun Recommend you read eg @yasaman_razeghi and @_sameersingh_‚Äôs arxiv from last year to increase your understanding the underlying dynamics
697,@GaryMarcus,2023-01-06 00:30:37+00:00,https://twitter.com/GaryMarcus/status/1611158258936340481,"Another shot of a skyline I have loved for 25 years, since I first visited https://t.co/QegGlCrBQs"
698,@GaryMarcus,2023-01-06 00:24:12+00:00,https://twitter.com/GaryMarcus/status/1611156642447622145,"@Fayeexplore This one, not yet written, and only just conceived, will appear February 2, in honor of https://t.co/4kZLzVw6MX"
699,@GaryMarcus,2023-01-06 00:17:26+00:00,https://twitter.com/GaryMarcus/status/1611154941074149376,@killerstorm @ylecun And yes it is literally just (intricate) statistics on word sequences
700,@GaryMarcus,2023-01-06 00:16:47+00:00,https://twitter.com/GaryMarcus/status/1611154778322620420,"@killerstorm @ylecun 1. You have perhaps underestimated the vastness of the source database
2. Errors are still routine, even on basic things like ‚Äúodd number‚Äù and addition"
701,@GaryMarcus,2023-01-06 00:15:03+00:00,https://twitter.com/GaryMarcus/status/1611154343217995779,"@s_r_constantin Essential readings on why so much in modern ML reminds so many of us of the film Groundhog Day: 

‚Ä¢ Fodor and Pylyshyn 1988 Cognition
‚Ä¢ Pinker and Prince 1988 Cognition
‚Ä¢ Pinker 1999 Words and Rules
‚Ä¢ Marcus et al 1999 Science
‚Ä¢ Marcus 2001 The Algebraic Mind"
702,@GaryMarcus,2023-01-06 00:00:37+00:00,https://twitter.com/GaryMarcus/status/1611150707322667009,"‚ÄúYou‚Äôre a linguist? I took some French in High School!‚Äù

Is it time for a Substack post on the perils of armchair cognitive (neuro)science? Seems to be a lot of that going around."
703,@GaryMarcus,2023-01-05 23:43:06+00:00,https://twitter.com/GaryMarcus/status/1611146299864190976,@killerstorm @ylecun No. It replicates the statistics of word sequences.
704,@GaryMarcus,2023-01-05 22:51:27+00:00,https://twitter.com/GaryMarcus/status/1611133303259791360,"üì£ Report your ChatGPT / LLM Bugs here! And check out the data live, on-line!

Joint project w ‚Å¶@ErnestSDavis‚Å© ‚Å¶@jahendler‚Å© ‚Å¶@EvelinaLeivada‚Å©. Technical implementation by @MMikeMMa‚Å©

[This link replaces yesterday‚Äôs Google Form] https://t.co/dHfsyBrSvX"
705,@GaryMarcus,2023-01-05 22:45:35+00:00,https://twitter.com/GaryMarcus/status/1611131825983979520,"@killerstorm @ylecun it doesn‚Äôt get lucky every time. it often says dumb, discomprehending things; my feed is full of such examples."
706,@GaryMarcus,2023-01-05 22:43:59+00:00,https://twitter.com/GaryMarcus/status/1611131425155354626,"@tdietterich @csabaveres @rgblong @EvelinaLeivada I think that is only approximately correct but very interesting; but as yet not informative about human language understanding. So not a point against Chomsky‚Äôs narrow but important point, unless it can be shown in some way eg to make predictions about human performance."
707,@GaryMarcus,2023-01-05 20:42:42+00:00,https://twitter.com/GaryMarcus/status/1611100902630494209,"This is a good antidote to the overselling of Google‚Äôs (excellent, but limited) new medical result earlier this week. Different model but same conclusions likely apply. Even more so if you tried to replace an actual doctor.

also relates to my https://t.co/lqo1spYPBl"
708,@GaryMarcus,2023-01-05 20:39:10+00:00,https://twitter.com/GaryMarcus/status/1611100011173142529,"@danbri @sir_deenicus @benhammersley @WebSummit No. What Chomsky said is that they don‚Äôt tell us anything about *how human language works*;  he is as far I can tell correct.  You are getting confused by ellipsis.

He and I both acknowledge that LLMs are potentially useful for engineering."
709,@GaryMarcus,2023-01-05 20:27:25+00:00,https://twitter.com/GaryMarcus/status/1611097056558608385,@rgblong @tdietterich @EvelinaLeivada @ChrisGPotts i didn‚Äôt say that they weren‚Äôt interesting. they don‚Äôt solve the problems i keep raising but they are interesting. 15 years ago we didn‚Äôt have a sense of the scale at which they could be built.
710,@GaryMarcus,2023-01-05 20:12:33+00:00,https://twitter.com/GaryMarcus/status/1611093316120240128,"@danbri @sir_deenicus @benhammersley @WebSummit at least read this, already a summary: https://t.co/5menFbK5a0"
711,@GaryMarcus,2023-01-05 19:49:31+00:00,https://twitter.com/GaryMarcus/status/1611087516547055616,"@jeffrey_bowers @rasbt @pgolding not just that paper, but certainly very relevant"
712,@GaryMarcus,2023-01-05 19:48:18+00:00,https://twitter.com/GaryMarcus/status/1611087212216713216,@danbri @sir_deenicus @benhammersley Perhaps you haven‚Äôt yet had time to listen in detail to what he actually said?  I feel that he delineated the scope of his remarks quite carefully and that you are not responding to the claims he made at https://t.co/ObPcxbXMzU &amp; longer discussion with me @websummit (on youtube).
713,@GaryMarcus,2023-01-05 19:14:02+00:00,https://twitter.com/GaryMarcus/status/1611078589495283712,"Seriously, Twitter, your named entity recognition AI is about 30 years out of date."
714,@GaryMarcus,2023-01-05 19:08:47+00:00,https://twitter.com/GaryMarcus/status/1611077267790364673,"@tdietterich @EvelinaLeivada If you wrote a paper with George Miller saying exactly that in the 1960s, you wouldn‚Äôt find that to be very surprising."
715,@GaryMarcus,2023-01-05 18:57:54+00:00,https://twitter.com/GaryMarcus/status/1611074527840342016,"@tdietterich @EvelinaLeivada if they don‚Äôt map onto semantics and world models, I am not all that interested in your revolution, particularly wrt to Chomsky‚Äôs questions about the science of human language as opposed to engineering."
716,@GaryMarcus,2023-01-05 18:57:07+00:00,https://twitter.com/GaryMarcus/status/1611074331198754816,"@tdietterich @EvelinaLeivada if you think learning language is mapping syntax onto semantics and pragmatics and world models (as I do), they don‚Äôt.  

semantically, they don‚Äôt even acquire basics like addition or odd number that are perfectly well-defined."
717,@GaryMarcus,2023-01-05 18:47:12+00:00,https://twitter.com/GaryMarcus/status/1611071834090524673,@tdietterich or by n-grams for large n. so what? and see @EvelinaLeivada‚Äôs reply.
718,@GaryMarcus,2023-01-05 18:42:58+00:00,https://twitter.com/GaryMarcus/status/1611070771077746688,@danbri possibly interesting as engineering. but what insight is giving us into how humans process/represent/understand language?
719,@GaryMarcus,2023-01-05 18:42:02+00:00,https://twitter.com/GaryMarcus/status/1611070536339292160,Two links if you want to know more about *why* Noam Chomsky is down on GPT-3 and large language models.
720,@GaryMarcus,2023-01-05 18:40:57+00:00,https://twitter.com/GaryMarcus/status/1611070262832951296,"@rasbt @pgolding He talks about it at length here: https://t.co/fjJ6WCvIji

and I discuss his thinking here: https://t.co/5menFbK5a0"
721,@GaryMarcus,2023-01-05 18:36:51+00:00,https://twitter.com/GaryMarcus/status/1611069230413414400,Not one serious reply to this. Tells you a lot.
722,@GaryMarcus,2023-01-05 18:34:16+00:00,https://twitter.com/GaryMarcus/status/1611068581923680257,@rasbt @pgolding that doesn‚Äôt address what Chomsky is saying.  He‚Äôs talking about whether LLMs have contributed to the science of understanding how human languages work.
723,@GaryMarcus,2023-01-05 17:46:10+00:00,https://twitter.com/GaryMarcus/status/1611056475820142592,@millvillager I will post when I have it tomorrow (&amp; haven‚Äôt heard it yet)
724,@GaryMarcus,2023-01-05 17:42:46+00:00,https://twitter.com/GaryMarcus/status/1611055619301322753,A very big podcast drops Friday at 5am ET; proud to be part of it.
725,@GaryMarcus,2023-01-05 17:18:36+00:00,https://twitter.com/GaryMarcus/status/1611049538344849409,@TaliaRinger Appreciate the pointer; has anyone else said it? It seems like a crazy view.
726,@GaryMarcus,2023-01-05 16:35:54+00:00,https://twitter.com/GaryMarcus/status/1611038793536253953,@TaliaRinger Really? Examples?
727,@GaryMarcus,2023-01-05 16:24:08+00:00,https://twitter.com/GaryMarcus/status/1611035831602679809,"@mpshanahan @ylecun Even the LLM proponents generally aspire to be multimodal, tho, so it‚Äôs not that they are making an argument per se for language as sufficient for all thought"
728,@GaryMarcus,2023-01-05 16:12:51+00:00,https://twitter.com/GaryMarcus/status/1611032991329058816,"@mpshanahan @ylecun ah. He is a bit all over the place, actually; or so it would seem. he is right that language is not sufficient, but wrong to think that LLMs tell us much about human language or cognition, and more or less said both contradictory things in the space of a few days."
729,@GaryMarcus,2023-01-05 15:55:14+00:00,https://twitter.com/GaryMarcus/status/1611028556855017474,"@untitled01ipynb Not structured enough, but nice backup plan"
730,@GaryMarcus,2023-01-05 15:47:55+00:00,https://twitter.com/GaryMarcus/status/1611026717665263616,"Holy Strawperson. Who ever said language was *sufficient* to explain all human thought? (Maybe Pylyshyn, in the 70s?)

Any serious contemporary cognitive psychologist assumes we have multiple representational formats."
731,@GaryMarcus,2023-01-05 15:37:43+00:00,https://twitter.com/GaryMarcus/status/1611024151397150725,"Hive Mind, is there something like Google Forms that is good for allowing people to uploading screenshots of ChatGPT errors and also for making the repository data automatically available to all?  (prefer that only a limited number of people can edit the overall file)."
732,@GaryMarcus,2023-01-05 15:22:05+00:00,https://twitter.com/GaryMarcus/status/1611020214371745793,"I too was wondering how @yLeCun reached that remarkable conclusion, that *most* human thought was non-verbal."
733,@GaryMarcus,2023-01-05 15:20:12+00:00,https://twitter.com/GaryMarcus/status/1611019742453846016,"@ylecun @NaveenGRao Agree with your comments on airplanes and bird wings, but don‚Äôt see how it rescues your original claim. 

Especially in light of the claims that both you and I have made about why LLMs are misguided/incomplete, and about why paradigm shifts are needed."
734,@GaryMarcus,2023-01-05 03:45:42+00:00,https://twitter.com/GaryMarcus/status/1610844966477262849,@paulg counterpoint: https://t.co/AyKgUNPfko
735,@GaryMarcus,2023-01-05 02:08:49+00:00,https://twitter.com/GaryMarcus/status/1610820582123180034,"@SCR10 If you want to dive deep, it‚Äôs worth it :)"
736,@GaryMarcus,2023-01-05 01:34:29+00:00,https://twitter.com/GaryMarcus/status/1610811943702663170,True in AI and not at all a good thing
737,@GaryMarcus,2023-01-05 01:29:17+00:00,https://twitter.com/GaryMarcus/status/1610810634194817024,@vayuvegula @MMikeMMa @sama @OpenAI They are collecting their own data but not afaik sharing with the community (as we intend)
738,@GaryMarcus,2023-01-05 01:16:35+00:00,https://twitter.com/GaryMarcus/status/1610807437094977537,"@MMikeMMa Yep we won‚Äôt make the emails available, but we will distribute and try to organize in some fashion"
739,@GaryMarcus,2023-01-05 01:03:42+00:00,https://twitter.com/GaryMarcus/status/1610804197536182272,@KWeatherwalks @AdrianoDAlessa3 https://t.co/RPfMQF49mp
740,@GaryMarcus,2023-01-05 01:02:01+00:00,https://twitter.com/GaryMarcus/status/1610803771285864448,"Yes, there is! The time has come! A repository for all your favorite #ChatGPT (#GPT3/#Galactica etc) errors now online! 

Please contribute! https://t.co/RPfMQF49mp

üôè"
741,@GaryMarcus,2023-01-05 00:52:22+00:00,https://twitter.com/GaryMarcus/status/1610801344239239168,@AdrianoDAlessa3 I am about to announce such a thing :)
742,@GaryMarcus,2023-01-05 00:41:10+00:00,https://twitter.com/GaryMarcus/status/1610798525390151681,Paper on this by @ErnestSDavis https://t.co/6su4JlmN0w
743,@GaryMarcus,2023-01-05 00:20:29+00:00,https://twitter.com/GaryMarcus/status/1610793320279863297,Tell me you don‚Äôt understand addition without telling me you don‚Äôt understand addition. https://t.co/MVC67h8CGE
744,@GaryMarcus,2023-01-04 22:04:01+00:00,https://twitter.com/GaryMarcus/status/1610758977423540227,@mmitchell_ai https://t.co/4ebldudEwf
745,@GaryMarcus,2023-01-04 21:12:38+00:00,https://twitter.com/GaryMarcus/status/1610746045696479232,Innateness for the win :)
746,@GaryMarcus,2023-01-04 21:08:32+00:00,https://twitter.com/GaryMarcus/status/1610745015663484929,"@PessoaBrain @NaveenGRao @ylecun Sure, definitely a simplification,  but there is certainly some kind of heavily constrained non-random connectivity"
747,@GaryMarcus,2023-01-04 18:53:00+00:00,https://twitter.com/GaryMarcus/status/1610710905276227585,Just another gorgeous day 45 min outside of Vancouver https://t.co/Ep2d0zEiFS
748,@GaryMarcus,2023-01-04 16:28:44+00:00,https://twitter.com/GaryMarcus/status/1610674599318151170,@nferraz @GillTripat I do think that in principle there is value in brainstorming with Chat but those 5 slogans are as generic and forgettable as the ones above them.
749,@GaryMarcus,2023-01-04 12:44:54+00:00,https://twitter.com/GaryMarcus/status/1610618272197775361,"@npparikh @yoavgo By current approaches I meant LLMs, which weren‚Äôt dominant when that report was written in 2020."
750,@GaryMarcus,2023-01-04 00:53:03+00:00,https://twitter.com/GaryMarcus/status/1610439127715184640,"@sondervorst @GiuseppeVenuto9 it doesn‚Äôt really understand abstractions like math, so on math questions it is hit or miss depending on similarity to training sets. i think they may be integrating a calculator to try to help but I doubt that the integration will be thorough and reliable."
751,@GaryMarcus,2023-01-04 00:31:38+00:00,https://twitter.com/GaryMarcus/status/1610433739599020032,"David Ferrucci on AI, moral responsibility, and the AGI Debate: https://t.co/e7OON8FZsg"
752,@GaryMarcus,2023-01-03 23:56:54+00:00,https://twitter.com/GaryMarcus/status/1610424997390188544,@andywalters ok but eg (cc @mrgreene1977) https://t.co/nrD5bnBzZu
753,@GaryMarcus,2023-01-03 23:18:16+00:00,https://twitter.com/GaryMarcus/status/1610415276893343744,@WickedViper23 @jdwalters85 ü§£ Watson &amp; medicine &amp; any number of driverless cars made unrealizable promises like that. edge cases edge cases edge cases
754,@GaryMarcus,2023-01-03 21:14:35+00:00,https://twitter.com/GaryMarcus/status/1610384151290720256,"@NaveenGRao @ylecun Complexity + prior structure. We have &gt; 150 brain areas &gt; 1000 neuron types, &gt; 500 proteins in a synapse etc; rough draft prior to experience. All that is being totally ignored. Fine for some purposes, but silly in ‚Äúbiological plausibility‚Äù  arguments."
755,@GaryMarcus,2023-01-03 21:07:09+00:00,https://twitter.com/GaryMarcus/status/1610382278869520384,"@leecronin @ylecun some AI (eg ILP) can, but LLMs are pretty limited in that regard; too much else in AI is being ignored at present."
756,@GaryMarcus,2023-01-03 21:06:31+00:00,https://twitter.com/GaryMarcus/status/1610382117908905985,"@NaveenGRao @ylecun *Nobody* doubts that LLMs have some use cases; question (in this thread) is whether they tell us anything about human language. 

LeCun suggested they might, but his argument focuses on a few similarities while ignoring many dissimilarities and just isn‚Äôt  at all compelling."
757,@GaryMarcus,2023-01-03 21:02:44+00:00,https://twitter.com/GaryMarcus/status/1610381166397509633,"@rgblong @ylecun I mean I guess we‚Äôve only know it since Shannon? https://t.co/P4QDDt6XSC with large N can produce text really well. Why is this surprising? 

The real issue is linking semantics to regurgitant. So far that hasn‚Äôt happened."
758,@GaryMarcus,2023-01-03 20:59:28+00:00,https://twitter.com/GaryMarcus/status/1610380343676407808,"@npparikh @yoavgo you won‚Äôt get fairness, reliability, interpretability, etc with current approaches; that‚Äôs why it matters"
759,@GaryMarcus,2023-01-03 20:58:24+00:00,https://twitter.com/GaryMarcus/status/1610380078512476160,"@npparikh @yoavgo by definition they can do with it a human-level accuracy, which was the ask"
760,@GaryMarcus,2023-01-03 20:56:58+00:00,https://twitter.com/GaryMarcus/status/1610379718074957825,"@leecronin @ylecun lots of aspects of human cognition are surely built on evolutionary old systems, but some important innovation happened in last few hundred thousand or million years."
761,@GaryMarcus,2023-01-03 20:55:42+00:00,https://twitter.com/GaryMarcus/status/1610379395822415872,"@NGRColosimo @leecronin @ylecun my book Kluge is actually about these suboptimalities in the evolution of human cognition, as it happens :)"
762,@GaryMarcus,2023-01-03 19:45:27+00:00,https://twitter.com/GaryMarcus/status/1610361719603462144,"@ylecun You are conflating many ideas there, but I don‚Äôt think anybody has made that argument per se in 30 years."
763,@GaryMarcus,2023-01-03 19:05:05+00:00,https://twitter.com/GaryMarcus/status/1610351560621699073,"@ylecun Weak argument. Yes, language evolved to be produced and understood by neural networks. 

But biological neural nets are vastly more complex than artificial neural nets; &amp; only syntax (not semantics) is well-captured by ANNs. 

Brain has
üëâfar more cell types
üëâfar more structure"
764,@GaryMarcus,2023-01-03 18:16:10+00:00,https://twitter.com/GaryMarcus/status/1610339249236381696,"@yoavgo I conclude that you don‚Äôt really care about reliable natural language understanding, as long as at least one task exceeds some modest threshold of utility. 

Clearly, our ambitions differ. I honestly hope you will elevate yours; AI can have so much more to offer."
765,@GaryMarcus,2023-01-03 18:09:17+00:00,https://twitter.com/GaryMarcus/status/1610337517588582401,"@yoavgo You are just assuming your conclusion then, assuming that we can have language without intelligence, and hence assuming eg that theories of language comprehension that require connections to discourse and world models just don‚Äôt matter. 

But you aren‚Äôt showing that."
766,@GaryMarcus,2023-01-03 18:06:50+00:00,https://twitter.com/GaryMarcus/status/1610336901793484801,"@yoavgo That‚Äôs fine insofar it goes (Googlr has been doing that for 20 years with keyword search, and I am glad to have it) but a long way from the ambitious AI has had and should have."
767,@GaryMarcus,2023-01-03 17:58:37+00:00,https://twitter.com/GaryMarcus/status/1610334832957218819,"@yoavgo Do humans need the questions in advance? 

We care because it is a good measure of being able to read in a generalized way, rather just doing glorified retrieval on short texts."
768,@GaryMarcus,2023-01-03 17:54:16+00:00,https://twitter.com/GaryMarcus/status/1610333737551810560,"@yoavgo Read a Pulitzer Prize winning book that was released after training and answer arbitrary questions about it with human-level accuracy.  Or watch a movie, same task."
769,@GaryMarcus,2023-01-03 17:46:36+00:00,https://twitter.com/GaryMarcus/status/1610331808465584129,"@stevenflinn Most of it 2023 will be too unreliable for applications where safety is important, but yes we are moving towards augmentation rather than displacement."
770,@GaryMarcus,2023-01-03 17:40:37+00:00,https://twitter.com/GaryMarcus/status/1610330303591256064,"@yoavgo I am sure you care about reliable natural language understanding. So, question: do you think reliable natural language understanding, at a full discourse level/across a long text, is achievable without reaching AGI? What would that even look like, to have NLU without AGI?"
771,@GaryMarcus,2023-01-03 17:30:06+00:00,https://twitter.com/GaryMarcus/status/1610327655634862080,"Maybe you ought also quote from the many issues raised in Section 6, for balance?"
772,@GaryMarcus,2023-01-03 17:27:31+00:00,https://twitter.com/GaryMarcus/status/1610327006650195968,"Hyped-up tweet: ‚ÄúExtraordinary new paper‚Ä¶‚Äù

Article itself: ‚ÄúThe resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians.‚Äù

Yes, there is progress; no, doctors won‚Äôt be replaced anytime soon."
773,@GaryMarcus,2023-01-02 20:10:18+00:00,https://twitter.com/GaryMarcus/status/1610005583561887744,"@jbrukh @dileeplearning It‚Äôs a technical issue, that will only be solved by moving towards hybrid models; this might be the impetus that makes that happen."
774,@GaryMarcus,2023-01-02 20:09:12+00:00,https://twitter.com/GaryMarcus/status/1610005306595233794,‚ù§Ô∏è
775,@GaryMarcus,2023-01-02 15:50:05+00:00,https://twitter.com/GaryMarcus/status/1609940097322958848,@jbrukh And dude I loved my Nokia 3650
776,@GaryMarcus,2023-01-02 15:49:30+00:00,https://twitter.com/GaryMarcus/status/1609939952791617536,"@jbrukh üôÑOr like me 2016, saying driverless cars are much harder than people think.

Or me saying 2012 that deep learning would have trouble with language comprehension (still true) &amp; causal reasoning.

or, per @dileeplearning, others saying fast-scaling dirigibles weren‚Äôt the way to go"
777,@GaryMarcus,2023-01-02 11:32:26+00:00,https://twitter.com/GaryMarcus/status/1609875260064804869,Priceless
778,@GaryMarcus,2023-01-01 17:25:17+00:00,https://twitter.com/GaryMarcus/status/1609601667682500610,@leecronin üíØ
779,@GaryMarcus,2023-01-01 16:13:39+00:00,https://twitter.com/GaryMarcus/status/1609583642078248960,@MarielzaTalks @EthicsInAI 100%; I tried to hard to get someone to speak to that but didn‚Äôt work out for 2022.
780,@GaryMarcus,2023-01-01 03:37:06+00:00,https://twitter.com/GaryMarcus/status/1609393251462828033,Happy New Year ü•Ç https://t.co/2huRQ9iqxc
781,@GaryMarcus,2022-12-31 18:03:48+00:00,https://twitter.com/GaryMarcus/status/1609248972471926784,"Short-term pessimism, long-term optimism?"
782,@GaryMarcus,2022-12-31 16:54:44+00:00,https://twitter.com/GaryMarcus/status/1609231593830502406,@hughes_meister Maybe you responded without reading the essay? Certainly you haven‚Äôt addressed my arguments for why those things will not be easy to add in reliable ways.
783,@GaryMarcus,2022-12-31 16:48:23+00:00,https://twitter.com/GaryMarcus/status/1609229994001108994,"17 reasons why you should be worried about AI, as we go into 2023

https://t.co/4XmOPGzvop"
784,@GaryMarcus,2022-12-31 13:44:26+00:00,https://twitter.com/GaryMarcus/status/1609183701304512513,@bentossell https://t.co/H2URrzU1qD
785,@GaryMarcus,2022-12-31 05:44:21+00:00,https://twitter.com/GaryMarcus/status/1609062883874246656,"episode 3 in my holiday trilogy on the state of AI drops Saturday morning, pacific time: An epic AI Debate‚Äîand why everyone should be at least a bit worried about AI

subscribe @ https://t.co/8ir1xKdPBy"
786,@GaryMarcus,2022-12-30 23:39:23+00:00,https://twitter.com/GaryMarcus/status/1608971037643014144,@yew_mun But curious for your take on both present and future versions of AlphaFold‚Ä¶
787,@GaryMarcus,2022-12-30 23:38:52+00:00,https://twitter.com/GaryMarcus/status/1608970908634591239,@yew_mun I think AlphaFold‚Äôs successors will have important lasting positive impact on the world; much less certain about ChatGPT‚Äôs
788,@GaryMarcus,2022-12-30 23:28:02+00:00,https://twitter.com/GaryMarcus/status/1608968181586227208,@BlancheMinerva @Abebab?
789,@GaryMarcus,2022-12-30 20:19:27+00:00,https://twitter.com/GaryMarcus/status/1608920723338440704,Together at last!
790,@GaryMarcus,2022-12-30 19:26:24+00:00,https://twitter.com/GaryMarcus/status/1608907374613659649,@iizzy_ not sure what Chat‚Äôs contribution would be in that particular scenario
791,@GaryMarcus,2022-12-30 19:25:41+00:00,https://twitter.com/GaryMarcus/status/1608907193780404224,round 2 now posted:
792,@GaryMarcus,2022-12-30 19:25:24+00:00,https://twitter.com/GaryMarcus/status/1608907122221412355,round 2:
793,@GaryMarcus,2022-12-30 17:45:47+00:00,https://twitter.com/GaryMarcus/status/1608882050697920513,@mrgreene1977 So sorry! I am fan of your hard-hitting analysis. @glichfield you should consider hiring @mrgreene1977.
794,@GaryMarcus,2022-12-30 17:43:29+00:00,https://twitter.com/GaryMarcus/status/1608881475340111873,@billbrown Wow what a prescient quote!
795,@GaryMarcus,2022-12-30 17:42:29+00:00,https://twitter.com/GaryMarcus/status/1608881223304384512,"@soumithchintala Taste can differ as to what is ‚Äúfoundational‚Äù, and I see your point re scaling, but is there any reason to think Google can‚Äôt simply and immediately do comparable scaling of its own? Is there any technical moat there? IMHO there is more @bengoertzel thread than you acknowledge."
796,@GaryMarcus,2022-12-30 17:37:06+00:00,https://twitter.com/GaryMarcus/status/1608879867390734337,@adelegoldberg1 @FelixHill84 I don‚Äôt see this as an argument targeting the validity of the competence and performance distinction; I see it as saying that knowledge is swiftly put to use (which hopefully we can all agree on). @JeffLidz?
797,@GaryMarcus,2022-12-30 17:10:46+00:00,https://twitter.com/GaryMarcus/status/1608873241376092162,@CadeMetz @realGeorgeHotz fyi
798,@GaryMarcus,2022-12-30 17:06:54+00:00,https://twitter.com/GaryMarcus/status/1608872265609019393,"Is ChatGPT Really a ‚ÄúCode Red‚Äù for Google Search? ü§î

https://t.co/lqo1spYPBl"
799,@GaryMarcus,2022-12-30 10:55:11+00:00,https://twitter.com/GaryMarcus/status/1608778721691066369,@Astro_Wakata wow! thank you!
800,@GaryMarcus,2022-12-30 10:52:23+00:00,https://twitter.com/GaryMarcus/status/1608778018352431106,ü§£ü§£
801,@GaryMarcus,2022-12-30 10:10:09+00:00,https://twitter.com/GaryMarcus/status/1608767386941026307,"@sethlazar @tdietterich it is inevitable that some systems will make decisions without humans in the loop, often in real time.  so that‚Äôs not sufficient for all cases."
802,@GaryMarcus,2022-12-30 10:07:31+00:00,https://twitter.com/GaryMarcus/status/1608766726904352768,@stemarO_O discussed in section on history at https://t.co/7WD8XxMEAr
803,@GaryMarcus,2022-12-30 02:57:08+00:00,https://twitter.com/GaryMarcus/status/1608658416536551424,Who‚Äôs ready for Round 2?
804,@GaryMarcus,2022-12-30 02:12:05+00:00,https://twitter.com/GaryMarcus/status/1608647081018937345,@realGeorgeHotz Or just read my 2016 interview for free? https://t.co/eLbmoH7Nfm
805,@GaryMarcus,2022-12-30 02:08:20+00:00,https://twitter.com/GaryMarcus/status/1608646134008000514,@tdietterich @soboleffspaces @sethlazar But one often wants both values and a command of the facts (including everyday knowledge about how the world works)
806,@GaryMarcus,2022-12-29 23:47:55+00:00,https://twitter.com/GaryMarcus/status/1608610800108998657,More fire from Ben Goertzel!
807,@GaryMarcus,2022-12-29 23:31:31+00:00,https://twitter.com/GaryMarcus/status/1608606669579382789,live view of large language models like #ChatGPT trying to be truthful
808,@GaryMarcus,2022-12-29 22:22:08+00:00,https://twitter.com/GaryMarcus/status/1608589208838410245,"@EmanuelSchucha1 One of those two taught some January term classes at MIT; the other, an Institute Professor at MIT (MIT‚Äôs highest honor) launched large, enduring areas of both linguistics and computer science, and is one of the most influential intellectuals of all time. 

Your call."
809,@GaryMarcus,2022-12-29 22:11:08+00:00,https://twitter.com/GaryMarcus/status/1608586441382318080,"two days left in the year, two more essays to come at https://t.co/8ir1xKenr6‚Ä¶"
810,@GaryMarcus,2022-12-29 22:09:08+00:00,https://twitter.com/GaryMarcus/status/1608585939030532098,"@BethCarey12 @prem_k @MMikeMMa @PWengerden @Nick_Davidov @emilymbender @Montreal_IA @jbthinking I like his work; don‚Äôt think that was the place for it tho. might be another occasion at same point, diving deeper into linguistics"
811,@GaryMarcus,2022-12-29 22:08:10+00:00,https://twitter.com/GaryMarcus/status/1608585694015852545,"@EmanuelSchucha1 it‚Äôs totally irrelevant only if you think you can get to AGI without understanding how humans get to language. i doubt you can, so it think it is likely ultimately quite relevant; IMHO your inability to listen through to the end of argument may not serve you well."
812,@GaryMarcus,2022-12-29 22:06:21+00:00,https://twitter.com/GaryMarcus/status/1608585236572692480,@Pehdrew_ source?
813,@GaryMarcus,2022-12-29 22:05:36+00:00,https://twitter.com/GaryMarcus/status/1608585049783554049,original: https://t.co/hwzec7yfU0 which got telephoned into this https://t.co/rJPgZyb0x0 which got telephoned into the above
814,@GaryMarcus,2022-12-29 22:05:35+00:00,https://twitter.com/GaryMarcus/status/1608585046218399745,ü§£ü§£ and the award for most out of context quote of the year goes to this summary of a summary:
815,@GaryMarcus,2022-12-29 17:41:07+00:00,https://twitter.com/GaryMarcus/status/1608518489651965952,"@Nick_Davidov Indeed.

Neurosymbolic AI, because it is not yet well developed &amp; has potential to offer something new, might offer a technical moat to the right startup.

Current generative techniques are too widely understood to offer a technical moat."
816,@GaryMarcus,2022-12-29 17:27:57+00:00,https://twitter.com/GaryMarcus/status/1608515176390864896,How cool is that? In a couple hours I will be getting voiceover lessons from the legendary @theharryshearer (for a Le Show cameo!) https://t.co/gvQUGGmJhf
817,@GaryMarcus,2022-12-29 17:10:10+00:00,https://twitter.com/GaryMarcus/status/1608510700628082689,Hints in my most important recent paper: The Next Decade in AI  https://t.co/rbeWGMenKO
818,@GaryMarcus,2022-12-29 16:55:51+00:00,https://twitter.com/GaryMarcus/status/1608507098341556225,"Have tried to get all three to clarify their positions on this, without success

All three have expressed opposition to symbols, but none have done is so in clear and consistent ways."
819,@GaryMarcus,2022-12-29 16:53:10+00:00,https://twitter.com/GaryMarcus/status/1608506424908193794,perhaps you didn‚Äôt actually hear enough to be well-informed about that which you are dismissing?  that‚Äôs not at all what Chomsky said (your quote is literally a fabrication) and it misses literally all of the nuance of what I said.
820,@GaryMarcus,2022-12-29 16:08:15+00:00,https://twitter.com/GaryMarcus/status/1608495117492436996,@UltraRareAF Follow @hardmaru
821,@GaryMarcus,2022-12-29 15:39:50+00:00,https://twitter.com/GaryMarcus/status/1608487966086946822,"early 2020s: Shortage of radiologists
late 2020s: Shortage of software developers"
822,@GaryMarcus,2022-12-29 13:15:51+00:00,https://twitter.com/GaryMarcus/status/1608451732719427584,Shame that the people who might most benefit from this probably won‚Äôt watch.
823,@GaryMarcus,2022-12-29 13:14:28+00:00,https://twitter.com/GaryMarcus/status/1608451386706128899,"@christofuse @WebSummit @jeremyakahn Perhaps after you have watched you could explain which of his points you think might be addressed and why? 

His concern is about scientific insight l I see literally no reason to think that making a model bigger would address what he says here.

See also https://t.co/xBMZhyzSuh"
824,@GaryMarcus,2022-12-29 01:35:06+00:00,https://twitter.com/GaryMarcus/status/1608275382888710145,"‚ÄúDebunking the Great AI Lie‚Äù

Noam Chomsky and I dive deep on language, science, and AI (&amp; #GPT3)

@WebSummit, interviewed by @jeremyakahn. (Sound gets better after first minute or two)

https://t.co/dadxNxItj1"
825,@GaryMarcus,2022-12-29 01:30:10+00:00,https://twitter.com/GaryMarcus/status/1608274141605466117,Touch√©
826,@GaryMarcus,2022-12-29 01:22:56+00:00,https://twitter.com/GaryMarcus/status/1608272321097207808,@EigenGender dare to question Elon and/or LLMs :)
827,@GaryMarcus,2022-12-29 01:20:21+00:00,https://twitter.com/GaryMarcus/status/1608271670451769348,@cajundiscordian We are in for a rough ride
828,@GaryMarcus,2022-12-29 01:19:26+00:00,https://twitter.com/GaryMarcus/status/1608271443200020480,@ForTheLoveOfTAO Why do people think I would post without checking that sort of thing? üôÑ
829,@GaryMarcus,2022-12-29 00:47:38+00:00,https://twitter.com/GaryMarcus/status/1608263440631726083,@cajundiscordian What is it that they think is a viable target?
830,@GaryMarcus,2022-12-28 21:43:06+00:00,https://twitter.com/GaryMarcus/status/1608216997741101057,"@vijayasankarv even where the values are obvious to humans (eg don‚Äôt make stuff up, which most not all humans follow), it‚Äôs really hard to get machines to follow along."
831,@GaryMarcus,2022-12-28 21:42:30+00:00,https://twitter.com/GaryMarcus/status/1608216848507584512,@a_tschantz we can‚Äôt keep even keep them honest (see the massive hallucination problem) let alone harmless.
832,@GaryMarcus,2022-12-28 21:41:59+00:00,https://twitter.com/GaryMarcus/status/1608216718911934464,"@kailuowang a human can often (not always) easily verify using search; for machines, that don‚Äôt genuinely understand language, the process is more challenging that you might think"
833,@GaryMarcus,2022-12-28 21:24:41+00:00,https://twitter.com/GaryMarcus/status/1608212365312409601,"@a_tschantz what does that even mean? 

agnostics can evaluate evidence; AI‚Äôs as we know them can‚Äôt really reason about values; they are truly amoral, not machines that ponder different values and weigh them."
834,@GaryMarcus,2022-12-28 21:23:05+00:00,https://twitter.com/GaryMarcus/status/1608211960406970369,"@barbarikon we run college ethics classes with humans on exactly the premise that you can be smart and also be taught something about ethics. 

why not build machines that can assimilate such lessons?"
835,@GaryMarcus,2022-12-28 21:22:10+00:00,https://twitter.com/GaryMarcus/status/1608211730949103617,"@barbarikon Just hoping for the best is certainly the default, nightmarish outcome. 

It‚Äôs not what we do with our children, though, where we enhance life experience with explicit instruction &amp; eg fables with morals etc.

We need more moral education, both for humans and machines, not less."
836,@GaryMarcus,2022-12-28 21:11:33+00:00,https://twitter.com/GaryMarcus/status/1608209059856908292,@MMikeMMa @mahemoff @Nick_Davidov @Neeva Suspect that @RichardSocher has also scraped and index a large fraction of the web for https://t.co/EGZ9EfE4EB.
837,@GaryMarcus,2022-12-28 21:10:18+00:00,https://twitter.com/GaryMarcus/status/1608208744181297153,"It‚Äôs a myth to think you can build machines in a value-neutral way. Current systems perpetuate past bias and injustice by default, and are largely blind to the consequences of what they say. Is that we want?"
838,@GaryMarcus,2022-12-28 21:07:33+00:00,https://twitter.com/GaryMarcus/status/1608208051798179841,"@prem_k @MMikeMMa @PWengerden @Nick_Davidov @emilymbender I have and I often cite her but have frankly grown tired of her never citing me. I nonetheless invited her to Debate 2, but at this point the omission seems deliberate."
839,@GaryMarcus,2022-12-28 17:32:54+00:00,https://twitter.com/GaryMarcus/status/1608154032434028545,@Nick_Davidov There is likely nothing in #gpt-4 that Google can‚Äôt replicate; question is about whether dialog/chat style interface can be made reliable enough. Eg some risk in returning invalid but authoritative-sounding medical info.
840,@GaryMarcus,2022-12-28 16:34:01+00:00,https://twitter.com/GaryMarcus/status/1608139216906584065,"@timnitGebru @emilymbender I have great respect both for Emily and for you (with an exception I noted) and cite you both regularly‚Äîbut have also lost respect for you both, for systematically not ever citing my own closely related and (often earlier work) criticizing hype and large language models."
841,@GaryMarcus,2022-12-28 01:14:43+00:00,https://twitter.com/GaryMarcus/status/1607907868027793410,"@DaniilAltshuler @DeanBuono Even if that is systematic (am doubtful) it‚Äôs not impressive if you have an AI system that is that fussy, particularly without any signposting about what can and can‚Äôt be trusted."
842,@GaryMarcus,2022-12-28 01:07:58+00:00,https://twitter.com/GaryMarcus/status/1607906168575504385,@hhm @DeanBuono Doubt it. I have seen similar problem eg with second sentence in a passage etc.
843,@GaryMarcus,2022-12-28 00:30:20+00:00,https://twitter.com/GaryMarcus/status/1607896696369074176,Fully qualified to be Twitter‚Äôs next CEO?
844,@GaryMarcus,2022-12-27 23:27:43+00:00,https://twitter.com/GaryMarcus/status/1607880938314252293,Bob Dylan and ChatGPT walk into a bar.
845,@GaryMarcus,2022-12-27 23:26:14+00:00,https://twitter.com/GaryMarcus/status/1607880564442374144,@RishiBommasani It will make misinformation harder to detect and more convincing and have almost nothing to do with how humans (who use vastly less data) learn language or about the world.
846,@GaryMarcus,2022-12-27 23:24:53+00:00,https://twitter.com/GaryMarcus/status/1607880223894261760,@RishiBommasani and on (ii) I agree with Chomsky said at the https://t.co/ucYKX5sJog; LLMs haven‚Äôt told us anything about human cognition or language development.
847,@GaryMarcus,2022-12-27 23:24:32+00:00,https://twitter.com/GaryMarcus/status/1607880136887767040,"@RishiBommasani On (i) I am not at all convinced that the net contribution of LLMs will be positive, because of their utility for creating misinformation and faux information at scale, which may lead to political chaos:

https://t.co/QCAInsodQy"
848,@GaryMarcus,2022-12-27 22:55:30+00:00,https://twitter.com/GaryMarcus/status/1607872830091448322,"@danbri I don‚Äôt think it understands anything; I really don‚Äôt. Of course the word ‚Äúunderstand‚Äù is vague but it does not build models over the world that it reasons about, so for me it‚Äôs a no."
849,@GaryMarcus,2022-12-27 22:53:57+00:00,https://twitter.com/GaryMarcus/status/1607872443162714112,"@danbri Honeybees, too."
850,@GaryMarcus,2022-12-27 22:53:29+00:00,https://twitter.com/GaryMarcus/status/1607872325919150080,"@AdrianoDAlessa3 @AllaBarakat It‚Äôs not aware of chess strategy; it predicts words from text, some of which is about chess. Agreed that it is not reasoning."
851,@GaryMarcus,2022-12-27 22:38:50+00:00,https://twitter.com/GaryMarcus/status/1607868635074420737,@danbri Dognition or whalenition would be exciting. Not sure Koi(g)notion is all that exciting?
852,@GaryMarcus,2022-12-27 22:36:51+00:00,https://twitter.com/GaryMarcus/status/1607868137818447872,@AllaBarakat @AdrianoDAlessa3 Ah! Pity!
853,@GaryMarcus,2022-12-27 22:36:23+00:00,https://twitter.com/GaryMarcus/status/1607868021439332354,@danbri @AdrianoDAlessa3 Neurosymbolic for the win!
854,@GaryMarcus,2022-12-27 22:25:36+00:00,https://twitter.com/GaryMarcus/status/1607865306571067396,@seandmacrae @tpgoebel Sure. no argument there.
855,@GaryMarcus,2022-12-27 22:22:59+00:00,https://twitter.com/GaryMarcus/status/1607864649554464768,ChatGPT for the win cc @Kasparov63
856,@GaryMarcus,2022-12-27 22:22:12+00:00,https://twitter.com/GaryMarcus/status/1607864451377537025,@danbri Also it is striking because unlike many failure modes this one may (?) be quite systematic and less fickle in terms of exact overlap w an undisclosed training set. And because as ever the (wrong) answers are presented as truth.
857,@GaryMarcus,2022-12-27 22:20:32+00:00,https://twitter.com/GaryMarcus/status/1607864030068097024,@openroomxyz People have made solid progress in that sort of problem for 30 years and this would be a particularly easy case.
858,@GaryMarcus,2022-12-27 22:19:30+00:00,https://twitter.com/GaryMarcus/status/1607863772194000896,@AllaBarakat @AdrianoDAlessa3 Access is currently free; people have tried chess; it gets lost after a few moved from the reports I have seen.
859,@GaryMarcus,2022-12-27 22:18:23+00:00,https://twitter.com/GaryMarcus/status/1607863492597383171,"@RishiBommasani Do you see it as being on a path towards general intelligence? if yes, do you think this kind of reasoning is important to that goal? do you see a path towards resolving these issues that is *not* neurosymbolic integration  rather than mere scaling?"
860,@GaryMarcus,2022-12-27 22:16:21+00:00,https://twitter.com/GaryMarcus/status/1607862978430537728,@danbri It is complaining that something that is being treated as if it were tantamount to AGI isn‚Äôt.
861,@GaryMarcus,2022-12-27 22:09:04+00:00,https://twitter.com/GaryMarcus/status/1607861145779535873,@RishiBommasani Disagree w your views but glad to see you engage @RishiBommasani. here‚Äôs a fresh example just in of the kind basic failure in everyday reasoning that I expect we will still see:
862,@GaryMarcus,2022-12-27 22:07:03+00:00,https://twitter.com/GaryMarcus/status/1607860639594156039,Striking failure of elementary reasoning #ChatGPT (see whole thread)
863,@GaryMarcus,2022-12-27 19:52:30+00:00,https://twitter.com/GaryMarcus/status/1607826779338674178,"@seandmacrae @tpgoebel What I see is stochasticity, and unreliability. minor shifts in wording often produce unpredictable and varied responses. The woke was a bit of a joke but the narrative of hallucination and unreliability remains the same."
864,@GaryMarcus,2022-12-27 19:50:49+00:00,https://twitter.com/GaryMarcus/status/1607826352320790529,"@rgblong @jeffclune @ethanCaballero @irinarish @sama @gdb @NandoDF @gwern @DorotheaBaur All that was of course true of GPT-3 relative to GPT-2, but I don‚Äôt personally see 3 as an advance towards general intelligence."
865,@GaryMarcus,2022-12-27 19:48:43+00:00,https://twitter.com/GaryMarcus/status/1607825827139297281,"@rgblong @jeffclune @ethanCaballero @irinarish @sama @gdb @NandoDF @gwern @DorotheaBaur So you agree on all seven specific predictions, or no?"
866,@GaryMarcus,2022-12-27 18:22:07+00:00,https://twitter.com/GaryMarcus/status/1607804031208148992,@sineadbovell Nope. we may stream mimicry but it won‚Äôt be intelligent: https://t.co/xBMZhyzSuh
867,@GaryMarcus,2022-12-27 17:42:01+00:00,https://twitter.com/GaryMarcus/status/1607793939645435904,@abdur @lintool @joshelman # https://t.co/JUPGMMmO4Z
868,@GaryMarcus,2022-12-27 17:40:08+00:00,https://twitter.com/GaryMarcus/status/1607793465890324482,@abdur @lintool @joshelman probably somebody just commented it out :)
869,@GaryMarcus,2022-12-27 17:18:19+00:00,https://twitter.com/GaryMarcus/status/1607787976569901058,"Scaling advocates eg @jeffclune @ethanCaballero @irinarish @sama @gdb @NandoDF @gwern do you doubt any of the predictions in my ‚ÄúWhat to expecting when you are expecting GPT-4‚Äù essay, or overall claim as @DorotheaBaur nicely summarizes it? 

Serious discussion here would be fun."
870,@GaryMarcus,2022-12-27 17:14:29+00:00,https://twitter.com/GaryMarcus/status/1607787010244108289,@ethanCaballero @scalemaximalist for a couple years!
871,@GaryMarcus,2022-12-27 17:01:57+00:00,https://twitter.com/GaryMarcus/status/1607783857163763713,"üôè Short essay contest! Win a cameo in my next essay :)

Reply below with something you learned at https://t.co/T6huMO62hk. 

Could be a question raised, a new way of thinking about things, etc."
872,@GaryMarcus,2022-12-27 16:56:08+00:00,https://twitter.com/GaryMarcus/status/1607782394320371715,"@joshelman I might a marginal outlier case, and tricky because both names can be either first or or last, but EM ought to be a core case that the system tries to get right :)"
873,@GaryMarcus,2022-12-27 16:54:50+00:00,https://twitter.com/GaryMarcus/status/1607782065759727616,"@lintool @joshelman @abdur I like his frames, and by coincidence was literally about to order one, but maybe someone currently in Birdland ought to have updated his code?"
874,@GaryMarcus,2022-12-27 16:46:15+00:00,https://twitter.com/GaryMarcus/status/1607779908062781441,"@ihorgowda pretty funny, on a lot of different interpretations of what you might be saying :)"
875,@GaryMarcus,2022-12-27 16:45:37+00:00,https://twitter.com/GaryMarcus/status/1607779749040132096,@Pehdrew_ @e_zubak more like a collection of algorithms; not all algorithms are AI but all AI involves algorithms.
876,@GaryMarcus,2022-12-27 16:39:36+00:00,https://twitter.com/GaryMarcus/status/1607778232702537732,"@joshelman and, btw to your point, lots of the trending tweets actually have the full name, so you have evidence both from the tweets and eg from Wikipedia and endless websites listing the full name, etc etc. 

I just can‚Äôt even."
877,@GaryMarcus,2022-12-27 16:36:32+00:00,https://twitter.com/GaryMarcus/status/1607777463366520832,"@joshelman I truly am shaking my head. So many possible different approaches here (old and new) and the owner is raving about advances in AI, and they don‚Äôt even seem to be trying."
878,@GaryMarcus,2022-12-27 16:30:16+00:00,https://twitter.com/GaryMarcus/status/1607775882583891975,@joshelman https://t.co/jGkzuxHvsa is literally one of the most basic aspects of natural language understanding. But maybe Twitter hasn‚Äôt heard of it?
879,@GaryMarcus,2022-12-27 16:25:24+00:00,https://twitter.com/GaryMarcus/status/1607774660946526210,AI ü§¶‚Äç‚ôÇÔ∏èof the day:  recognizing when two terms refer to the same entity. https://t.co/hBhBgI8N74
880,@GaryMarcus,2022-12-27 15:09:46+00:00,https://twitter.com/GaryMarcus/status/1607755625861087237,‚ÄúTesla stopped reporting its Autopilot safety numbers online. Why?‚Äù https://t.co/jdtffDYeGI
881,@GaryMarcus,2022-12-27 00:31:32+00:00,https://twitter.com/GaryMarcus/status/1607534610958663680,@Jess_Riedel @PeterWolfTW @jimmy_wales @Wikipedia @MaryanaIskander It‚Äôs the volume and plausibility that are new and that threaten to exhaust moderators. This is why Stack Overflow placed a ban. and it is going to be hard to enforce bans.
882,@GaryMarcus,2022-12-26 22:14:46+00:00,https://twitter.com/GaryMarcus/status/1607500193779294208,epic summary of an epic debate. üçø
883,@GaryMarcus,2022-12-26 22:07:32+00:00,https://twitter.com/GaryMarcus/status/1607498372021379072,@ZDNET @TiernanRayTech And really thank you @TiernanRayTech for putting in the time to watch and write such a crystal clear distillation.
884,@GaryMarcus,2022-12-26 22:06:03+00:00,https://twitter.com/GaryMarcus/status/1607497997184815105,@TiernanRayTech @Montreal_AI Epic summary!
885,@GaryMarcus,2022-12-26 17:45:02+00:00,https://twitter.com/GaryMarcus/status/1607432313155256325,@SunnyD17 @tunguz There are many like that!
886,@GaryMarcus,2022-12-26 15:25:04+00:00,https://twitter.com/GaryMarcus/status/1607397086298886146,@jimmy_wales @PeterWolfTW @Wikipedia @MaryanaIskander Sent you some first thoughts by DM
887,@GaryMarcus,2022-12-26 14:27:31+00:00,https://twitter.com/GaryMarcus/status/1607382604730212353,@nazarre Exactly!!!
888,@GaryMarcus,2022-12-26 14:12:56+00:00,https://twitter.com/GaryMarcus/status/1607378937360879618,"@John4tl @jim_rutt @IntuitMachine @ylecun This all started with his comment on 2018 arxiv appraise of DL, when Yann trolled me by replying to @erikbryn alleging that my paper was mostly wrong. 

To this day he has not explained what was wrong with it, but instead has basically come out endorsing 90% of what I said there."
889,@GaryMarcus,2022-12-26 14:03:14+00:00,https://twitter.com/GaryMarcus/status/1607376492505497606,"@IntuitMachine @jim_rutt That really doesn‚Äôt address my question of what it means, and I don‚Äôt understand your reply."
890,@GaryMarcus,2022-12-26 14:02:03+00:00,https://twitter.com/GaryMarcus/status/1607376195242569731,@odednapchi @nonoumenon @yudapearl Not reliably.
891,@GaryMarcus,2022-12-26 14:01:19+00:00,https://twitter.com/GaryMarcus/status/1607376009858322433,wonder how well this tweet will age‚Ä¶
892,@GaryMarcus,2022-12-26 13:49:49+00:00,https://twitter.com/GaryMarcus/status/1607373118904979456,"The USS Enterprise is about to crash; everyone will die.

Spock talks to the Star Trek Computer, trying to devise a solution, but it‚Äôs powered by #ChatGPT-9, and nothing it says helps.

Panicking, Kirk screams desperately ‚ÄúSpock, damn it, Rephrase your prompt and try again!‚Äù

üò± https://t.co/tZrb6ooNmS"
893,@GaryMarcus,2022-12-26 13:35:55+00:00,https://twitter.com/GaryMarcus/status/1607369621853675521,@PWengerden @MTsireud Without access emit the training corpus you have no antecedent idea exactly what can be done by memorization etc
894,@GaryMarcus,2022-12-26 13:33:27+00:00,https://twitter.com/GaryMarcus/status/1607369000828428288,"@PeterWolfTW Yes this terrifying, as I keep trying to alert @jimmy_wales @Wikipedia @MaryanaIskander 

I give them a lot of money and am discouraged that they won‚Äôt discuss; see also my SciAm column https://t.co/QCAInsodQy"
895,@GaryMarcus,2022-12-26 13:30:46+00:00,https://twitter.com/GaryMarcus/status/1607368324622737408,@IntuitMachine @jim_rutt What does that even mean? And why it is a problem?
896,@GaryMarcus,2022-12-26 03:42:50+00:00,https://twitter.com/GaryMarcus/status/1607220364588863488,@ESYudkowsky @Nick_Davidov How do I get in on @ESYudkowsky‚Äôs side of this bet? My own thoughts here: https://t.co/H2URrzTtB5
897,@GaryMarcus,2022-12-25 22:15:00+00:00,https://twitter.com/GaryMarcus/status/1607137862138400770,@drmichaellevin My own comment on same:
898,@GaryMarcus,2022-12-25 21:57:49+00:00,https://twitter.com/GaryMarcus/status/1607133540113862657,@IsaacKing314 @barbarikon @metaculus @MatthewJBar Should be trivial to hook up true AGI to a robot‚Ä¶
899,@GaryMarcus,2022-12-25 20:55:10+00:00,https://twitter.com/GaryMarcus/status/1607117770881392641,Ps @AlisonGopnik @Moira_Dillon @LakeBrenden have related work comparing infant (and young children‚Äôs) physical and causal reasoning to current ML; perhaps they could post links here
900,@GaryMarcus,2022-12-25 20:50:17+00:00,https://twitter.com/GaryMarcus/status/1607116542126493696,"such an important benchmark. 

I have yet to see anyone in the machine learning community try to take it on, even people like @ylecun who claim to be directly focused now on physical reasoning. 

all extant architectures that we are aware of fail."
901,@GaryMarcus,2022-12-25 20:44:17+00:00,https://twitter.com/GaryMarcus/status/1607115032063524864,@untitled01ipynb @LexicaArt Doesn‚Äôt look at all like a baby robot to me
902,@GaryMarcus,2022-12-25 18:29:25+00:00,https://twitter.com/GaryMarcus/status/1607081094284808200,@HeidyKhlaaf @uclh So sorry
903,@GaryMarcus,2022-12-25 18:12:21+00:00,https://twitter.com/GaryMarcus/status/1607076799254601729,@GOFAI_ @pmarc And @pmarca too; would be great if he saw this counterpoint
904,@GaryMarcus,2022-12-25 17:50:33+00:00,https://twitter.com/GaryMarcus/status/1607071312211771392,"winner from @WickedViper23, and essay that the art was for:"
905,@GaryMarcus,2022-12-25 17:44:55+00:00,https://twitter.com/GaryMarcus/status/1607069896688676866,"What to Expect When You‚Äôre Expecting ‚Ä¶ GPT-4

What comes after #ChatGPT?   7 predictions for 2023

https://t.co/xBMZhyzSuh"
906,@GaryMarcus,2022-12-25 16:25:52+00:00,https://twitter.com/GaryMarcus/status/1607050003280715776,@WickedViper23 Was hoping for more of a cradle/swaddled baby look and of course really want the text right but thanks for trying and not bad. Can I use the top right?
907,@GaryMarcus,2022-12-25 15:14:04+00:00,https://twitter.com/GaryMarcus/status/1607031932910436352,My holiday mood just got turned up to 11!
908,@GaryMarcus,2022-12-25 15:11:36+00:00,https://twitter.com/GaryMarcus/status/1607031310945779713,"@untitled01ipynb @attention_gan cheap, indeed, since (a) my results weren‚Äôt cherry-picked, (b) you didn‚Äôt do any better and (c ) you suggested that doing better might actually require a model that has never been  available for public testing."
909,@GaryMarcus,2022-12-25 14:46:53+00:00,https://twitter.com/GaryMarcus/status/1607025089786126336,"@untitled01ipynb can you do better with my prompt, even altering the words but preserving the intent? I tried quite a bit, didn‚Äôt even report all the fails, and there were no full successes."
910,@GaryMarcus,2022-12-25 14:40:56+00:00,https://twitter.com/GaryMarcus/status/1607023594957045761,Woker-than-thou https://t.co/Vyy4lsQtR1
911,@GaryMarcus,2022-12-25 14:38:02+00:00,https://twitter.com/GaryMarcus/status/1607022865446240256,@KordingLab so much for illustrating my next essay‚Ä¶
912,@GaryMarcus,2022-12-25 14:18:45+00:00,https://twitter.com/GaryMarcus/status/1607018011323416577,‚Äúa baby robot in a cradle wearing a t-shirt saying GPT-4‚Äù üôÑ https://t.co/Rrq96YQape
913,@GaryMarcus,2022-12-24 14:50:33+00:00,https://twitter.com/GaryMarcus/status/1606663627330691073,"@marktenenholtz Google search *is* (hybrid) AI. 

Surely you are asking about whether LLMs will change how search is approached."
914,@GaryMarcus,2022-12-24 02:50:00+00:00,https://twitter.com/GaryMarcus/status/1606482292733526017,"This truly was the AI event of the year. So much to reflect on!

üôè to @erikbryn @YejinChoinka Noam Chomsky, @bengoertzel @jeffclune David Ferrucci @AvilaGarcez, @MichelleRempel @dileeplearning @sarahookr @AnjaKasp @KordingLab @kaifulee @frossi_t @SchmidhuberAI &amp; @Montreal_AI"
915,@GaryMarcus,2022-12-23 13:29:52+00:00,https://twitter.com/GaryMarcus/status/1606280933706981376,"@skyengineai yes AGIDebate will be recorded, link to be posted at https://t.co/NnELd6kFDV"
916,@GaryMarcus,2022-12-23 12:59:43+00:00,https://twitter.com/GaryMarcus/status/1606273345410023431,"Live, tonight, from all over the globe, many of #AI‚Äôs leading thinkers."
917,@GaryMarcus,2022-12-21 15:07:23+00:00,https://twitter.com/GaryMarcus/status/1605580698143707138,"Last call, @sama cc @Montreal_AI. We‚Äôre holding a spot for you. https://t.co/kXkNudsEfB"
918,@GaryMarcus,2022-12-19 15:32:59+00:00,https://twitter.com/GaryMarcus/status/1604862364301799424,ChatGPT mansplaining @ElonMusk and @Twitter https://t.co/W9rH9blJ2l
919,@GaryMarcus,2022-12-11 22:03:47+00:00,https://twitter.com/GaryMarcus/status/1602061612730691584,"this makes me so uncomfortable I am taking a break. 

you can find me on mastodon, substack, and linkedin."
920,@GaryMarcus,2022-12-11 21:51:01+00:00,https://twitter.com/GaryMarcus/status/1602058397469540353,@sergia_ch @sama See my comments at https://t.co/NnELd6ldtt
921,@GaryMarcus,2022-12-11 21:50:32+00:00,https://twitter.com/GaryMarcus/status/1602058277608894465,@lorakolodny @wongmjane What she said :)
922,@GaryMarcus,2022-12-11 21:08:13+00:00,https://twitter.com/GaryMarcus/status/1602047628707270656,"Sorry, wrong. GPT-3 doesn‚Äôt bullshit because people do; it bullshits because it can‚Äôt keep track of reality, or even the info in its own database. (contra this take at Wired, https://t.co/Oj30uS7lLt)

if you really want to know, it‚Äôs better explained here https://t.co/bbOXczqzRQ"
923,@GaryMarcus,2022-12-11 20:42:32+00:00,https://twitter.com/GaryMarcus/status/1602041164567547904,"@TonyZador @bengoertzel @sama The problem is that they lose binding eg between entities and their properties, as I discussed here: https://t.co/bbOXczqzRQ"
924,@GaryMarcus,2022-12-11 18:02:28+00:00,https://twitter.com/GaryMarcus/status/1602000881381445632,Never a charge. Always our holiday gift to the world.
925,@GaryMarcus,2022-12-11 18:00:51+00:00,https://twitter.com/GaryMarcus/status/1602000474819145728,"@Kempton @Kobotic but great that at least some politicians, like Canadian MP @MichelleRempel, are showing an interesting in learning more and diving deeper into AI. 

She‚Äôll be at https://t.co/VNBNm3FHSS, sharing her experience in regulating new tech."
926,@GaryMarcus,2022-12-11 17:58:48+00:00,https://twitter.com/GaryMarcus/status/1601999957023928322,"Looking forward to my Thursday 1pm Fireside chat w IBM Research‚Äôs Chief Scientist of Research Ruchir Puri, hosted by the MIT Sloan Quant Club.  

https://t.co/f7GKUPXKbP"
927,@GaryMarcus,2022-12-11 17:37:59+00:00,https://twitter.com/GaryMarcus/status/1601994720406036481,@pwlot @bengoertzel funny i have been thinking of the same metaphor (wernicke‚Äôs aphasia) lately
928,@GaryMarcus,2022-12-11 17:27:07+00:00,https://twitter.com/GaryMarcus/status/1601991985115828225,@benjaminjriley @chazfirestone! (Is Brian on here?)
929,@GaryMarcus,2022-12-11 17:25:45+00:00,https://twitter.com/GaryMarcus/status/1601991640188858368,"Let‚Äôs bury the hatchet, @sama. @bengoertzel just signed on to our 12/23 https://t.co/NnELd6ldtt; you should be there. We have a truly all-star cast (Chomsky, @erikbryn, @YejinChoinka,  @SchmidhuberAI, @MichelleRempel, @KordingLab, @kaifulee, @frossi_t &amp; many more!); please join."
930,@GaryMarcus,2022-12-11 17:11:45+00:00,https://twitter.com/GaryMarcus/status/1601988117908828161,"@rmarcilhoo @bengoertzel @sama @ylecun @hardmaru yes, RL with world models will eventually be useful. the world models are the cake. when we get that right, we can get back to what yann likes to call the cherry on top. 

LLMs don‚Äôt have that, so aren‚Äôt super useful for that approach to RL"
931,@GaryMarcus,2022-12-11 17:06:03+00:00,https://twitter.com/GaryMarcus/status/1601986683754643456,"@rmarcilhoo @bengoertzel @sama On RL I am actually very much with @ylecun. RL alone isn‚Äôt cutting it; as he might say, let‚Äôs get the rest of the cake together first. 

Fine for games, but problematic in the open-ended real-world."
932,@GaryMarcus,2022-12-11 16:53:05+00:00,https://twitter.com/GaryMarcus/status/1601983421068488704,"Read this thread, if you care at all about AGI and large language models."
933,@GaryMarcus,2022-12-11 16:40:22+00:00,https://twitter.com/GaryMarcus/status/1601980220055392257,"Truth. 

Excerpted from a thread from one of the world‚Äôs deepest thinkers on AGI, @bengoertzel"
934,@GaryMarcus,2022-12-11 14:14:38+00:00,https://twitter.com/GaryMarcus/status/1601943545799405568,@sergia_ch @yudapearl @alexhanna That‚Äôs whole point of this essay; https://t.co/NPANdPIIJm
935,@GaryMarcus,2022-12-11 14:02:14+00:00,https://twitter.com/GaryMarcus/status/1601940424943628288,@NateSilver538 Curious to see examples of both @NateSilver538 (and wondering at what length the first part is effective).
936,@GaryMarcus,2022-12-11 13:36:55+00:00,https://twitter.com/GaryMarcus/status/1601934054945067008,"@wellingmax No! Was @sama Reviewer 2 in the evaluation of deep learning is biting a wall? I had no idea! 

Just kidding https://t.co/a4Cc4o8ouw"
937,@GaryMarcus,2022-12-11 13:15:09+00:00,https://twitter.com/GaryMarcus/status/1601928573832810496,@JeffLonsdale @barneyp üíØ
938,@GaryMarcus,2022-12-11 13:01:06+00:00,https://twitter.com/GaryMarcus/status/1601925037824835584,"‚ÄúWhat I had not realized is that extremely short exposures to a relatively simple computer program could induce powerful delusional thinking in quite normal people.‚Äù 

Josef Weizenbaum, creator of ELIZA 

h/t @Kobotic"
939,@GaryMarcus,2022-12-11 12:43:24+00:00,https://twitter.com/GaryMarcus/status/1601920585390784512,"@JeffLonsdale @barneyp I talk about provenance in the essay, as part of the solution"
940,@GaryMarcus,2022-12-11 04:58:13+00:00,https://twitter.com/GaryMarcus/status/1601803520382210049,"Serious question, apropos novel writing, etc. What is the *longest* coherent prose you‚Äôve gotten out of an LLM, without hand tinkering? The most interesting plot twist? Deepest characterization? Most surprising bit of dialog?"
941,@GaryMarcus,2022-12-11 04:43:41+00:00,https://twitter.com/GaryMarcus/status/1601799860327677952,@davidchalmers42 guess the problem wasn‚Äôt so hard after all. cc @anilkseth
942,@GaryMarcus,2022-12-11 04:37:58+00:00,https://twitter.com/GaryMarcus/status/1601798421496885248,"@renatrigiorese what i am saying is that because the developers are unable to rule out data leakage, and have done too little to alleviate that concern, the artists have a real shot, especially in cases where they can show enough similarity to convince a jury."
943,@GaryMarcus,2022-12-11 04:25:16+00:00,https://twitter.com/GaryMarcus/status/1601795227790213121,@naivebaesian finally
944,@GaryMarcus,2022-12-11 04:15:10+00:00,https://twitter.com/GaryMarcus/status/1601792682485239813,"@DuaneJRich @sama @gdb it was the last line here that was key; the field can‚Äôt advance if people read titles alone rather than engaging in serious issues that are raised.

but that‚Äôs pretty much what happened; same with my 2018 article. i see a pattern, but not a healthy one."
945,@GaryMarcus,2022-12-11 04:11:52+00:00,https://twitter.com/GaryMarcus/status/1601791855850840071,"@DuaneJRich @sama @gdb To make the point that they should not be so dismissive of the next criticism, be it from me or somebody else."
946,@GaryMarcus,2022-12-11 04:09:56+00:00,https://twitter.com/GaryMarcus/status/1601791367231176705,"@renatrigiorese no, style cannot be. But individual art works can be stolen from, and copyright suits can be filed; given data leakage and black-box knowledge, the artists have grounds to try; if it looks like it was stolen it may well have been."
947,@GaryMarcus,2022-12-11 03:44:27+00:00,https://twitter.com/GaryMarcus/status/1601784954282971136,"@tdietterich @Noahpinion Incidentally I already wrote about English -&gt; Robot plans. At least for humanoid domestic robots that‚Äôs not happening in a robust way anytime remote soon, and definitely not with pure LLMs. Happy to bet a *lot* of money on that one. 

https://t.co/9HPKnCuYpY"
948,@GaryMarcus,2022-12-11 03:41:22+00:00,https://twitter.com/GaryMarcus/status/1601784177820839936,"@DuaneJRich @sama @gdb again, hundreds of of people piled on me. nobody ever called them out. why call only me out? 

deeper point: ML has been very unkind to criticism that has been proven in hindsight to be legitimate; same thing happened with my 2018 Deep Learning appraisal. 

Is that to the good?"
949,@GaryMarcus,2022-12-11 03:37:48+00:00,https://twitter.com/GaryMarcus/status/1601783279556120576,@tdietterich @Noahpinion but eg do you want your planning to go through systems that aren‚Äôt robust and trustworthy?
950,@GaryMarcus,2022-12-11 03:32:37+00:00,https://twitter.com/GaryMarcus/status/1601781975236628480,@dave_at_hat @sd_marlow they have gotten a lot better this year; it‚Äôs coming (though I have my doubts about the vocals).
951,@GaryMarcus,2022-12-11 03:31:44+00:00,https://twitter.com/GaryMarcus/status/1601781753555095553,Excellent question. (Spoiler alert: SEO optimization with faux text doesn‚Äôt count).
952,@GaryMarcus,2022-12-11 03:30:46+00:00,https://twitter.com/GaryMarcus/status/1601781511883460608,"@DuaneJRich and, clarifying, the ridicule came from others (@sama, @gdb, @plinz, @ylecun, etc) not you. I didn‚Äôt read you that way and apologize if that was unclear."
953,@GaryMarcus,2022-12-11 03:29:38+00:00,https://twitter.com/GaryMarcus/status/1601781223994855425,"@DuaneJRich If it was just one, ok, but it was literally thousands of people, many quite prominent, posting and liking dozens and dozens of similar tweets. I think I am entitled to point that out.

If you have experienced similar, great; if not, try to see it from my perspective."
954,@GaryMarcus,2022-12-11 03:25:29+00:00,https://twitter.com/GaryMarcus/status/1601780179743170560,"@DuaneJRich @sama @gdb And by the way I doubt that not a single person spoke up to call Sam‚Äôs original post childish. Willing to bet you didn‚Äôt. 
#doublestandards"
955,@GaryMarcus,2022-12-11 03:22:46+00:00,https://twitter.com/GaryMarcus/status/1601779499347369985,"Hilarious rewriting of history. Hundreds of people ridiculed me on Twitter (and Facebook) in March and April. It was a meme!

And now today is it‚Äôs ‚ÄúHappy We Knew it All Along‚Äù Day.

Schopenhauer has got you covered! https://t.co/en4oZKSidK"
956,@GaryMarcus,2022-12-11 03:05:25+00:00,https://twitter.com/GaryMarcus/status/1601775133185937409,"@sama It‚Äôs not just that I told you so, back in March, but that back in April you (&amp; @gdb)  were so dismissive and condescending."
957,@GaryMarcus,2022-12-11 03:00:02+00:00,https://twitter.com/GaryMarcus/status/1601773776995512322,"üôà
@garymarcus, March, GPT shows ‚Äúhallmarks of unreliability &amp; is prone to‚Ä¶promulgating misinformation‚Äù

@sama, April, ‚ÄúGive me the confidence of a mediocre deep learning skeptic‚Äù

@sama, today, ‚ÄúChatGPT is incredibly limited‚Ä¶We have lots of work to do on robustness and truth‚Äù https://t.co/eqXhOSQSf1"
958,@GaryMarcus,2022-12-11 02:45:33+00:00,https://twitter.com/GaryMarcus/status/1601770131478446081,"100%, @sama, robustness and truthtfulness and by the way, that is *exactly* the wall in my award-winning essay that you and your co-founder mocked. 

Maybe read it again and be nicer next time? https://t.co/bVRpsfHIFo and your original response: https://t.co/Xos52HEqip"
959,@GaryMarcus,2022-12-11 02:36:15+00:00,https://twitter.com/GaryMarcus/status/1601767791501402112,more relevant examples:
960,@GaryMarcus,2022-12-11 02:34:48+00:00,https://twitter.com/GaryMarcus/status/1601767427121246208,"Data leakage is now popping up in generative AI models, eg above.

Artists, this gives you upper hand;  (a) they should have known this problem would exist &amp; (b) probably can‚Äôt show in any individual cases that data leakage *isn‚Äôt* cause of any uncanny resemblance observed.

2/2"
961,@GaryMarcus,2022-12-11 02:34:48+00:00,https://twitter.com/GaryMarcus/status/1601767424684355585,"Artists: get familiar w ‚Äúdata leakage‚Äù, a fancy machine learning term for when training data makes to output in (nearly) unadulterated form. 

This is has been known issue re privacy for years, eg https://t.co/CdaT6TkRr3

ü™° 1/2"
962,@GaryMarcus,2022-12-10 22:54:41+00:00,https://twitter.com/GaryMarcus/status/1601712032902156289,"PSA: Be careful around here. 

Account that phished me
- was a verified blue badge
- knew I had a blue badge (now retired)
- had &gt; 80,000 followers
- DM‚Äôed direct
- was followed by people I know &amp; respect
- sent me a 2FA SMS from tel # that Twitter had used before
- STILL HERE"
963,@GaryMarcus,2022-12-10 22:09:35+00:00,https://twitter.com/GaryMarcus/status/1601700683753082880,"Hey @balajis it seems we formed an Institute and I didn‚Äôt even know it! (And, bonus, nice to see @SachaBaronCohen joining in our fictitious but mostly plausible news story.)"
964,@GaryMarcus,2022-12-10 22:04:50+00:00,https://twitter.com/GaryMarcus/status/1601699488489680896,@maier_ak @mkapor it does seem like rules and reasoning are the only thing that will save LLM‚Äôs bacon. but shh! don‚Äôt tell!
965,@GaryMarcus,2022-12-10 22:02:16+00:00,https://twitter.com/GaryMarcus/status/1601698840054489088,"This ü™°  is sad. For anyone who knows copyright law in arts: If the analogous thing happened in music, artist would have a viable claim, &amp; might well win in court.

What‚Äôs analog/difference here in visual art, where it is pretty obvious that a given piece is directly derivative?"
966,@GaryMarcus,2022-12-10 20:36:35+00:00,https://twitter.com/GaryMarcus/status/1601677276370075648,"Judge in the @mkapor Kurzweil bet: how much is 100 times 100?
AGI Bot: I am sorry, my programming guardrails prevent me from attempting such complex questions 
Calculator: Pick me!"
967,@GaryMarcus,2022-12-10 20:33:52+00:00,https://twitter.com/GaryMarcus/status/1601676595793518592,AGI is gonna be wild!
968,@GaryMarcus,2022-12-10 20:13:37+00:00,https://twitter.com/GaryMarcus/status/1601671497441214465,@KatiePhang @katiephangshow @MSNBC The substack essay is now up: https://t.co/0bjkj1TPzR
969,@GaryMarcus,2022-12-10 19:22:09+00:00,https://twitter.com/GaryMarcus/status/1601658545413705730,"Great and scary point. Stack Overflow already had a near-death experience, with ChatGPT. What if same were to happen to Wikipedia?

@JWalesF @Wikipedia @MaryanaIskander I am a regular donor and would be glad to discuss (pro bono), see https://t.co/0bjkj1TPzR"
970,@GaryMarcus,2022-12-10 19:14:40+00:00,https://twitter.com/GaryMarcus/status/1601656664436133888,"@cfiesler @OpenAI extremely interesting but 
a. I seriously doubt that it will be robust over time to all present and future LLMs (eg does it work with Davinci? Will it work with GPT-4?)
b. doubt that it is robust over all prompts
c. doubt that it is robust over all writing styles"
971,@GaryMarcus,2022-12-10 19:12:13+00:00,https://twitter.com/GaryMarcus/status/1601656046908772352,"Yikes‚ö†Ô∏è

@balajis are you sure this is a good idea? What‚Äôs to stop bad actors from using what you are commissioning to make first rate propaganda at low cost and high volume, manipulating markets or elections?  

My essay from this a.m. extremely relevant: https://t.co/0bjkj1TPzR"
972,@GaryMarcus,2022-12-10 19:06:52+00:00,https://twitter.com/GaryMarcus/status/1601654701401214977,"@danmcquillan why in principle wouldn‚Äôt AI be able to do what human fact-checkers do? I don‚Äôt understand the logical argument. but yes (to a large degree, not fully) on point 2"
973,@GaryMarcus,2022-12-10 19:01:59+00:00,https://twitter.com/GaryMarcus/status/1601653470779822082,"Exactly. Suppose ChatGPT++‚Äôs guardrails fully prevented misinformation, but bad actors knew how to replicate Galactica or Davinci4? 

The risk is still very much here.  The tech is out. We need to figure out what to do about it. (4 suggestions in my Substack, and we need more!)"
974,@GaryMarcus,2022-12-10 18:59:32+00:00,https://twitter.com/GaryMarcus/status/1601652854858878978,"@DrTechlash @vardi @ylecun Or maybe @ylecun will see that either
(a) I have a point
or
(b) it‚Äôs not for him alone to decide
and our fight will come to an end üíï"
975,@GaryMarcus,2022-12-10 18:57:35+00:00,https://twitter.com/GaryMarcus/status/1601652361931681793,"@jamesagada @ylecun well, *some* of us see it. https://t.co/DFLylwPdrb"
976,@GaryMarcus,2022-12-10 18:50:55+00:00,https://twitter.com/GaryMarcus/status/1601650687976570880,"@danmcquillan 1. I am working on it. It‚Äôs very very hard, because it requires a different paradigm, focused around truth and reasoning, rather than prediction.
2. yes it‚Äôs just an extension of previous work, which is why I have been sounding this alarm for a while; but it did just get worse."
977,@GaryMarcus,2022-12-10 18:48:16+00:00,https://twitter.com/GaryMarcus/status/1601650021300338690,"üíØ.  Ultimately all the recent debates I have had with @Ylecun (aside from nonsense about who published what) comes down  this single question:  Are we about to be flooded with automated misinformation, in ways that fundamentally alter the fabric of society, or not?"
978,@GaryMarcus,2022-12-10 18:39:39+00:00,https://twitter.com/GaryMarcus/status/1601647851016454144,Well said! ‚ù§Ô∏è
979,@GaryMarcus,2022-12-10 18:38:36+00:00,https://twitter.com/GaryMarcus/status/1601647584887832577,"@DrHughHarvey @rodriguezzz78 in this case it so happens that I have designed an architecture and am actively trying to put a team together, but at the same time @DrHughHarvey is absolutely right."
980,@GaryMarcus,2022-12-10 16:18:59+00:00,https://twitter.com/GaryMarcus/status/1601612449165508608,"@balajis I am worried personalized misinformation tbh; see my new essay on about scaling propaganda. Personalizing that propaganda is the step after that:

https://t.co/0bjkj1TPzR"
981,@GaryMarcus,2022-12-10 15:48:47+00:00,https://twitter.com/GaryMarcus/status/1601604850768564224,"@katiephangshow Thanks so much for allowing me to sound the alarm about the risk of automated misinformation on your show, @KatiePhang!

And here is the link to the essay you so kindly mentioned: https://t.co/0bjkj1TPzR"
982,@GaryMarcus,2022-12-10 14:21:31+00:00,https://twitter.com/GaryMarcus/status/1601582888352636928,"@elonmusk @stillgray The biggest concern‚Äîfar more imminent than AGI, and existential to @twitter‚Äîis automated propaganda: https://t.co/0bjkj1TPzR"
983,@GaryMarcus,2022-12-10 13:22:53+00:00,https://twitter.com/GaryMarcus/status/1601568132417871872,AI's Jurassic Park moment - and 4 things we might do about it.
984,@GaryMarcus,2022-12-10 13:21:41+00:00,https://twitter.com/GaryMarcus/status/1601567832944545794,"@mridley and featured this morning by @katiephangshow, link to come"
985,@GaryMarcus,2022-12-10 13:15:59+00:00,https://twitter.com/GaryMarcus/status/1601566397938937856,"@j2lovesfriday @katiephangshow Exactly, and see my pinned tweet:"
986,@GaryMarcus,2022-12-10 02:06:57+00:00,https://twitter.com/GaryMarcus/status/1601398030267469824,@plibin It feels more like the trouble with tribbles to me https://t.co/NPyFDalvFI
987,@GaryMarcus,2022-12-10 00:04:35+00:00,https://twitter.com/GaryMarcus/status/1601367235712651264,"@patrickmesana i was locked out by an elaborate and somewhat disturbing phishing ruse, see my LinkedIn posts for details"
988,@GaryMarcus,2022-12-09 23:58:28+00:00,https://twitter.com/GaryMarcus/status/1601365697753649152,"Looking forward to talking soon with @KatiePhang on @katiephangshow, tomorrow (Saturday) at 7:50am Eastern Time @msnbc, re my soon to appear Substack essay, _AI's Jurassic Park Moment_ https://t.co/jXZnzGb3qM"
989,@GaryMarcus,2022-12-09 21:46:53+00:00,https://twitter.com/GaryMarcus/status/1601332581169270784,@BobbyAlter There is no actual argument. It‚Äôs just noise.
990,@GaryMarcus,2022-12-09 21:42:55+00:00,https://twitter.com/GaryMarcus/status/1601331581628874753,"What I worry about the most, if I may be honest, is your qualifications for making important and consequential decisions around #AIEthics."
991,@GaryMarcus,2022-12-09 20:00:40+00:00,https://twitter.com/GaryMarcus/status/1601305849519276032,"Haha. But don‚Äôt think you or other folks would have enjoyed being part of the trap that was laid. 

Instead, be concerned about security around here, when fake yet seemingly verified Blue Badge Twitter employee w 75k followers can send authorization codes from same # as Twitter."
992,@GaryMarcus,2022-12-09 19:43:08+00:00,https://twitter.com/GaryMarcus/status/1601301441205145600,"Some accidental ChatGPT comedy, via @vadimberman 

Be sure to click to see the whole thing; excerpt starts with GPTChat discussing walruses; humans them asks a question, and then ‚Ä¶ well ‚Ä¶ just read and find out üòÄ https://t.co/qqwzKUi0ZI"
993,@GaryMarcus,2022-12-09 19:37:16+00:00,https://twitter.com/GaryMarcus/status/1601299963270803457,First thing I see returning to Twitter üôÑ
994,@GaryMarcus,2022-12-08 21:04:15+00:00,https://twitter.com/GaryMarcus/status/1600959466601840640,@tsushil_thapa @ShizaCharania @ylecun not friends with people who repeatedly lie about me
995,@GaryMarcus,2022-12-08 21:03:50+00:00,https://twitter.com/GaryMarcus/status/1600959360183996416,absolutely - the edge cases in open-ended chatbots are endless; that's what all the errors people are posting highlights
996,@GaryMarcus,2022-12-08 21:03:00+00:00,https://twitter.com/GaryMarcus/status/1600959150137421824,@info_sprinkles @ylecun sorry but lying is not cool
997,@GaryMarcus,2022-12-08 19:52:39+00:00,https://twitter.com/GaryMarcus/status/1600941444881317890,"@ylecun . @yLeCun the last time you said this to @zdnet, I presented multiple AI publications in top journals (sample screenshots below). 

@zdnet corrected you, because you lied.

@kenneth0stanley corrected you yesterday re our algorithm.

*why* are you lying about my credentials again? https://t.co/uG07u8sYsi"
998,@GaryMarcus,2022-12-08 19:25:54+00:00,https://twitter.com/GaryMarcus/status/1600934716471128064,@ShizaCharania @ylecun That‚Äôll be $8 :)
999,@GaryMarcus,2022-12-08 19:18:02+00:00,https://twitter.com/GaryMarcus/status/1600932733144174592,"@wadhwa @Shrikantha5 AFAIK all LLMs are vulnerable to hallucination.  The thing you sent was made by a different recent OpenAI model (not ChatGPT) one from @Shrikantha5 is indeed ChatGPT. General problem is very real! 

Ps: LLMs are stochastic &amp; context sensitive, so no single output is replicable."
1000,@GaryMarcus,2022-12-08 18:37:38+00:00,https://twitter.com/GaryMarcus/status/1600922567170461698,@MuhammedKambal Sure would like to know what was in the training corpus
1001,@GaryMarcus,2022-12-08 18:31:46+00:00,https://twitter.com/GaryMarcus/status/1600921090284716032,"Eerily prescient paper from 2021: language models &amp; propaganda-as-a-service

https://t.co/Ib5c0sqkg5

By @ebagdasa &amp; @shmatikov"
1002,@GaryMarcus,2022-12-08 18:12:21+00:00,https://twitter.com/GaryMarcus/status/1600916204792999936,@pwlot @jeblad @StolfiAlberto I got blocked (I believe) for doubting his claim that Austin would become the AI capital of the world. And if you read the thread carefully someone else brought the wiki to my attention. Something didn‚Äôt feel right tbh when he interviewed me in the MIT library.
1003,@GaryMarcus,2022-12-08 18:09:38+00:00,https://twitter.com/GaryMarcus/status/1600915519259176960,@__delas__ @Plinz Love it when Plinz publicly attacks me and I respond and then the fanboys pile on without reading the  time stamps or understanding the chronology. üôÑ
1004,@GaryMarcus,2022-12-08 17:44:14+00:00,https://twitter.com/GaryMarcus/status/1600909130684063745,"@pwlot @jeblad @StolfiAlberto he's representing himself as an MIT research scientist, not as a Drexel PhD."
1005,@GaryMarcus,2022-12-08 17:27:49+00:00,https://twitter.com/GaryMarcus/status/1600904997327507457,"@Tweetermeyer wow. not a great look, especially given how he styles himself."
1006,@GaryMarcus,2022-12-08 17:26:03+00:00,https://twitter.com/GaryMarcus/status/1600904552269885441,"@pwlot @jeblad @StolfiAlberto *did* he graduate? 

from the answers I am getting, he taught some January classes, but was not on faculty."
1007,@GaryMarcus,2022-12-08 16:36:51+00:00,https://twitter.com/GaryMarcus/status/1600892170734800897,"I suspect that this is inaccurate, but am curious if anyone can confirm or deny it. https://t.co/myflXl9IAr"
1008,@GaryMarcus,2022-12-08 15:26:06+00:00,https://twitter.com/GaryMarcus/status/1600874367155859464,@IntuitMachine @MIT His wiki should be edited to portray that reality
1009,@GaryMarcus,2022-12-08 15:21:11+00:00,https://twitter.com/GaryMarcus/status/1600873128493973504,@bleepbeepbzzz @Cyber2F I think that doing the wiki lookup well from text is a really hard problem and closer to AGi than doing autocomplete.
1010,@GaryMarcus,2022-12-08 15:18:09+00:00,https://twitter.com/GaryMarcus/status/1600872364346347522,@bleepbeepbzzz @Cyber2F Fully agreed. And some external device might do that. LLMs don‚Äôt inherently have that capacity. On all that we can agree.
1011,@GaryMarcus,2022-12-08 15:14:41+00:00,https://twitter.com/GaryMarcus/status/1600871493814349825,@bleepbeepbzzz @Cyber2F I have no issue with people trying to build jet packs. Whatever jet pack you might build now would work fine with instuctgpt too tho.
1012,@GaryMarcus,2022-12-08 15:13:19+00:00,https://twitter.com/GaryMarcus/status/1600871149944340481,"@MuhammedKambal @MIT Looks like a guest lecture from years ago,"
1013,@GaryMarcus,2022-12-08 15:11:55+00:00,https://twitter.com/GaryMarcus/status/1600870795815026688,"@notSoJunkDNA @MIT That‚Äôs just a talk at as workshop. I am doing that next week, doesn‚Äôt mean I teach at MIT, nor that I am affiliated. It was a one-off two years ago.  If that‚Äôs it, the wiki is misleading."
1014,@GaryMarcus,2022-12-08 14:55:05+00:00,https://twitter.com/GaryMarcus/status/1600866561795174401,"@bleepbeepbzzz @Cyber2F It needs an external mechanism to do that. Transformers in themselves simply don‚Äôt do that. It‚Äôs like like saying I could fly if you gave me a jet pack. Well ok, but the jet pack isn‚Äôt part of me."
1015,@GaryMarcus,2022-12-08 14:52:42+00:00,https://twitter.com/GaryMarcus/status/1600865961417928704,"Can anybody point to any class that Lex Friedman has taught at MIT in the last few years? 

I believe that his wiki is misleading. My understanding is that he was never on faculty, never earned a a degree there, and that he no longer has any active affiliation with @MIT."
1016,@GaryMarcus,2022-12-08 14:37:54+00:00,https://twitter.com/GaryMarcus/status/1600862235882295296,"@Plinz @bsgallagher Since I am neurosymbolic guy I will let that one guy. There is a new moon, but it‚Äôs not AGI."
1017,@GaryMarcus,2022-12-08 14:31:17+00:00,https://twitter.com/GaryMarcus/status/1600860570428661760,@PABLO_LEWIN It‚Äôs general but would not meet the definition of AGI (vetted by people who invented the term)  I give in my bet to elon musk in my substack
1018,@GaryMarcus,2022-12-08 14:26:33+00:00,https://twitter.com/GaryMarcus/status/1600859381364842496,All 8 are things that I warned field of in 2018 that continue to be true (https://t.co/wD2UXX21Hg)
1019,@GaryMarcus,2022-12-08 14:23:15+00:00,https://twitter.com/GaryMarcus/status/1600858548522844160,@untitled01ipynb @monsieurwagner Hadn‚Äôt thought about it but fair point.
1020,@GaryMarcus,2022-12-08 14:20:50+00:00,https://twitter.com/GaryMarcus/status/1600857941049212934,"@bleepbeepbzzz @Cyber2F I have no idea what flaw you have in mind; this kind of confabulation is routine, and chatGPT routinely confabulates, often in ways that conflict with the data. That *is* the problem."
1021,@GaryMarcus,2022-12-08 14:17:08+00:00,https://twitter.com/GaryMarcus/status/1600857009750147072,"@IntuitMachine @erikbryn @YejinChoinka @jeffclune @AvilaGarcez @MichelleRempel @dileeplearning @sarahookr @KordingLab @kaifulee @frossi_t @SchmidhuberAI See @YejinChoinka‚Äôs recent benchmark which we will discuss, and I (moderator) have written about it a bit with @ErnestSDavis"
1022,@GaryMarcus,2022-12-08 14:12:23+00:00,https://twitter.com/GaryMarcus/status/1600855815531163649,"No, Lex Friedman is not an MIT Professor; and no he is not a leading ML researcher."
1023,@GaryMarcus,2022-12-08 14:05:37+00:00,https://twitter.com/GaryMarcus/status/1600854111981023232,"@IntuitMachine @erikbryn @YejinChoinka @jeffclune @AvilaGarcez @MichelleRempel @dileeplearning @sarahookr @KordingLab @kaifulee @frossi_t @SchmidhuberAI There will be talk about theory of mind, which would presumably be a prerequisite."
1024,@GaryMarcus,2022-12-08 04:47:43+00:00,https://twitter.com/GaryMarcus/status/1600713713526648832,@Plinz It‚Äôs well-known that all the best marcus satires are yours
1025,@GaryMarcus,2022-12-08 04:46:44+00:00,https://twitter.com/GaryMarcus/status/1600713465840422912,@Plinz I tried to play along :)
1026,@GaryMarcus,2022-12-08 04:41:46+00:00,https://twitter.com/GaryMarcus/status/1600712213979070465,Got to give @plinz credit for his sense of humor! https://t.co/MWFHQCIXPZ
1027,@GaryMarcus,2022-12-08 04:38:49+00:00,https://twitter.com/GaryMarcus/status/1600711474007404546,"@MaximZiatdinov @pmddomingos And in compositionality, physical reasoning, causal reasoning, hallucination, etc.  as per my original article. Honestly, Pedro, you know better."
1028,@GaryMarcus,2022-12-08 04:26:04+00:00,https://twitter.com/GaryMarcus/status/1600708265037684737,"OMG, really? From the guy who interviewed me at a library at MIT because he didn‚Äôt have an actual office who blocked folks like @Grady_Booch @egrefen @rasbt and me for trivial differences of opinion? 

Talk about people not being who they pretend to be on TV."
1029,@GaryMarcus,2022-12-08 04:18:57+00:00,https://twitter.com/GaryMarcus/status/1600706474610929664,"She‚Äôs kidding about the GANs, but check out the post."
1030,@GaryMarcus,2022-12-08 04:10:52+00:00,https://twitter.com/GaryMarcus/status/1600704438855176192,@ahatamiz1 @Agz5885 @Amine57240266 Does it matter if you reset in between? Ask different ages and years each time?
1031,@GaryMarcus,2022-12-08 03:01:48+00:00,https://twitter.com/GaryMarcus/status/1600687056845668353,"@Plinz @seanmcbride @pwlot @lexfridman Too smart long term, too dumb short term"
1032,@GaryMarcus,2022-12-08 02:52:11+00:00,https://twitter.com/GaryMarcus/status/1600684637726314497,"@kchonyc @rasbt @Grady_Booch I would tag Lex so he could include you, but ‚Ä¶ I can‚Äôt"
1033,@GaryMarcus,2022-12-08 02:50:38+00:00,https://twitter.com/GaryMarcus/status/1600684248918552576,"@TonyD993 @johnsontoddr4 THE üîë misunderstanding of chatGPT:  when it tells us that the very much alive Noam Chomsky died in 2020, it‚Äôs not ‚Äúdrawing on sources.‚Äù 

It‚Äôs drawing on bits of text that were never previously connected &amp; confabulating a relationship between those bits‚Äîwithout checking the data https://t.co/dweDO5bavB"
1034,@GaryMarcus,2022-12-08 02:37:33+00:00,https://twitter.com/GaryMarcus/status/1600680956545097729,"@DoktorSly @vayuvegula @Grady_Booch @lexfridman @rasbt Much kinder than me, same club:"
1035,@GaryMarcus,2022-12-08 02:24:08+00:00,https://twitter.com/GaryMarcus/status/1600677576938487808,"@seanmcbride @pwlot @Plinz @lexfridman The thread started with this post out of the blue, just FYI:"
1036,@GaryMarcus,2022-12-08 02:07:26+00:00,https://twitter.com/GaryMarcus/status/1600673377647497216,@andrey_kurenkov So much for cameras alone! Next stop: LiDAR!
1037,@GaryMarcus,2022-12-08 01:58:32+00:00,https://twitter.com/GaryMarcus/status/1600671135372570624,"@seanmcbride @DoktorSly @Plinz It‚Äôs hard, but see https://t.co/rbeWGMenKO"
1038,@GaryMarcus,2022-12-08 01:56:38+00:00,https://twitter.com/GaryMarcus/status/1600670658043998208,@DoktorSly @Grady_Booch Afraid so.
1039,@GaryMarcus,2022-12-08 01:11:41+00:00,https://twitter.com/GaryMarcus/status/1600659344378720257,"One night only: @erikbryn, @YejinChoinka, Noam Chomsky, @jeffclune, David Ferrucci, @AvilaGarcez, @MichelleRempel, @dileeplearning, @sarahookr, Anja Kaspersen, @KordingLab, @kaifulee, @frossi_t, @SchmidhuberAI, Meredith Whitaker talk AGI üî•

Dec 23, 5pm ET
https://t.co/ucYKX5thdO https://t.co/af1gWGxQ24"
1040,@GaryMarcus,2022-12-08 00:48:15+00:00,https://twitter.com/GaryMarcus/status/1600653447145324544,"@Plinz @pwlot @seanmcbride @lexfridman Ok but I was on his show, he should have had thicker skin than that"
1041,@GaryMarcus,2022-12-08 00:23:59+00:00,https://twitter.com/GaryMarcus/status/1600647341807017984,Ha ha Lex blocked me (after our episode!) because I didn‚Äôt agree that AI was going to relocate to Austin.  Cc @Grady_Booch
1042,@GaryMarcus,2022-12-07 23:47:10+00:00,https://twitter.com/GaryMarcus/status/1600638077298511872,@seanmcbride @Plinz What takes tremendous intellectual effort is humility‚Äîand recognizing where improvements are needed.
1043,@GaryMarcus,2022-12-07 23:02:17+00:00,https://twitter.com/GaryMarcus/status/1600626782906257409,"if you don‚Äôt understand this point, you don‚Äôt understand how ChatGPT works.

and if you don‚Äôt understand this point, you are very likely overestimating GPT‚Äôs capabilities."
1044,@GaryMarcus,2022-12-07 22:42:18+00:00,https://twitter.com/GaryMarcus/status/1600621751339487232,@John68Richmond The facts are clear:
1045,@GaryMarcus,2022-12-07 22:40:21+00:00,https://twitter.com/GaryMarcus/status/1600621261075648512,@kenneth0stanley @ylecun @hayabhay @ZoubinGhahrama1 @jeffclune @Tkaraletsos I hope @ylecun that @kenneth0stanley‚Äôs response will put an end to this line of discussion.
1046,@GaryMarcus,2022-12-07 22:38:08+00:00,https://twitter.com/GaryMarcus/status/1600620705267470336,"@ylecun @hayabhay @ZDNET @TiernanRayTech So no counterargument then to the fact that 
- you publicly lied about my credentials
- are resting a further attack on my credentials by conflating whether I helped develop an algorithm with whether I was permitted by its buyer to publish it.

Classy!"
1047,@GaryMarcus,2022-12-07 22:27:27+00:00,https://twitter.com/GaryMarcus/status/1600618015724535808,"@ylecun @hayabhay @ZDNET @TiernanRayTech You know perfectly well that that work is under NDA and wasn‚Äôt published.  That wasn‚Äôt my choice (since I no longer own it) but I have told you that before. 

You are just trying to extend your efforts to deceive."
1048,@GaryMarcus,2022-12-07 22:18:59+00:00,https://twitter.com/GaryMarcus/status/1600615884628062208,"@fchollet Counterpoint: robotics (esp domestic humanoid robots) is one of the domains that most needs major advances in physical psychological and causal reasoning, and is one of the least tolerant of the current approximative approach. So could actually be the catalyst."
1049,@GaryMarcus,2022-12-07 22:15:19+00:00,https://twitter.com/GaryMarcus/status/1600614963307220992,@johnsontoddr4 @TonyD993 @yudapearl lovely example of how little gpt understands causality
1050,@GaryMarcus,2022-12-07 22:13:20+00:00,https://twitter.com/GaryMarcus/status/1600614462847057920,"@ylecun @hayabhay Ps you also recently lied about my credentials to @zdnet, forcing @TiernanRayTech to publish a correction. And you said crazy things at end of 2019 about history that whole field knew was not true. 

Please stop attacking my credentials with false &amp; misleading statements."
1051,@GaryMarcus,2022-12-07 22:06:23+00:00,https://twitter.com/GaryMarcus/status/1600612715483258881,"@ylecun @hayabhay Uber bought that algorithm &amp; from what I understand uses it to good effect. contrary to what you have told people, it is not deep learning (though it can work w deep learning)

@ZoubinGhahrama1 @kenneth0stanley @jeffclune @Tkaraletsos helped &amp; know that I not you speak the truth"
1052,@GaryMarcus,2022-12-07 20:50:20+00:00,https://twitter.com/GaryMarcus/status/1600593575175393280,@Michael_J_Black you might be interested in examples like these (I noticed you followed back on post but not here btw); see also my example re Chomsky earlier today
1053,@GaryMarcus,2022-12-07 20:34:22+00:00,https://twitter.com/GaryMarcus/status/1600589556331708416,More utterly bogus references from the alleged Future of Search
1054,@GaryMarcus,2022-12-07 20:23:18+00:00,https://twitter.com/GaryMarcus/status/1600586772572176385,"@RadioFreeTom He‚Äôs 94! And bemused by the fake GPTChat news I passed along, reporting his alleged 2020 death."
1055,@GaryMarcus,2022-12-07 20:04:33+00:00,https://twitter.com/GaryMarcus/status/1600582053736886272,"@jjarangoes @ylecun @percyliang actually, @ylecun and agree on a lot: I started out 2917 debate with multiple points of agreement &amp; wrote a lengthy discussion of that on Twitter earlier this year (referring to a thread he wrote in May) and recently reaffirming some shared points here: https://t.co/Odg2QIt39X"
1056,@GaryMarcus,2022-12-07 19:40:19+00:00,https://twitter.com/GaryMarcus/status/1600575955789287425,@Agz5885 @ahatamiz1 @Amine57240266 stochasticity  + authoritative presentation is not a winning formula
1057,@GaryMarcus,2022-12-07 19:39:08+00:00,https://twitter.com/GaryMarcus/status/1600575656685080576,"@erikbryn Destroying trust in the information economy, on the Russian ‚Äúfirehouse of falsehood‚Äù model. 

Stack Overflow took the first blows. there will be more."
1058,@GaryMarcus,2022-12-07 19:34:43+00:00,https://twitter.com/GaryMarcus/status/1600574547019059200,"@RadioFreeTom If it‚Äôs today, you also share it with Noam Chomsky"
1059,@GaryMarcus,2022-12-07 19:32:34+00:00,https://twitter.com/GaryMarcus/status/1600574006331314177,"@EricRWeinstein @elonmusk @ESYudkowsky I offered Elon some money about this topic, along with a definition (below) vetted by two of the people who invented the term. 

offer still stands: https://t.co/yfXycYXxb9

@wadhwa and others over to pentuple the bet to $500k."
1060,@GaryMarcus,2022-12-07 19:28:31+00:00,https://twitter.com/GaryMarcus/status/1600572987048361985,"@ChristophMolnar I gave the clearest example; most are  more subtle, which is why Stack Overflow needed a ban."
1061,@GaryMarcus,2022-12-07 19:25:38+00:00,https://twitter.com/GaryMarcus/status/1600572260456464384,"Yes! But they include discussion of laws and explicit values in that education. They don‚Äôt leave it all to implicit reinforcement learning.  

See my pinned tweet, @ylecun cc: @percyliang"
1062,@GaryMarcus,2022-12-07 18:48:46+00:00,https://twitter.com/GaryMarcus/status/1600562981146066944,"@MelMitchell1 I think the Turing Test is a terrible test, but two hours gives a good amount of time for depth. Cc @mkapor 

What Comes After the Turing Test? https://t.co/1N4qeEn6uH"
1063,@GaryMarcus,2022-12-07 18:42:13+00:00,https://twitter.com/GaryMarcus/status/1600561333455712256,@ChristophMolnar Look forward to lots of novices puzzling over stuff like this https://t.co/7MsqFd2knj
1064,@GaryMarcus,2022-12-07 18:40:56+00:00,https://twitter.com/GaryMarcus/status/1600561011702247424,@ahatamiz1 @Amine57240266 @Agz5885 have you been able to replicate? Can you elaborate?
1065,@GaryMarcus,2022-12-07 18:09:05+00:00,https://twitter.com/GaryMarcus/status/1600552995569426435,"@srikumarks The question of course not whether these systems sometimes create correct answers, but how often, and whether users (or downstream processors) can tell the difference when they instead generate wrong answers"
1066,@GaryMarcus,2022-12-07 16:42:21+00:00,https://twitter.com/GaryMarcus/status/1600531169241882624,@Ricardo_Joseh_L He took it well. (But shares my concern about the imminent deluge)
1067,@GaryMarcus,2022-12-07 16:37:37+00:00,https://twitter.com/GaryMarcus/status/1600529977707225088,"Happy 94th birthday,
Noam Chomsky! 

And don‚Äôt believe everything chatGPT tells you! (Spoiler alert: he doesn‚Äôt)"
1068,@GaryMarcus,2022-12-07 14:26:48+00:00,https://twitter.com/GaryMarcus/status/1600497056988401664,"Absolutely. But it makes them up. Eg Noam Chomsky is very much alive (we emailed a few days ago), but check out the fake yet plausible looking sources below (&amp; for bonus note the inconsistencies in age &amp; temporal reasoning): https://t.co/C3Vi2jXtZt"
1069,@GaryMarcus,2022-12-07 14:02:26+00:00,https://twitter.com/GaryMarcus/status/1600490921963159552,"Enthusiast: ChatGPT is gonna replace search engines like Google!

Skeptic: Yeah, but it doesn‚Äôt really work. sometimes it is amazing, but it often gives you garbage. 

Enthusiast: Sure but you can make it work! All you have to do is ‚Ä¶ hook it up to ‚Ä¶ a ‚Ä¶search engine!

üôÑ"
1070,@GaryMarcus,2022-12-07 13:56:09+00:00,https://twitter.com/GaryMarcus/status/1600489341675241473,"@blattnerma @Plinz Yes &amp; no. we have made progress in the fidelity of mimicry and approximation, but not on the deeper issues that I have always emphasized (compositionality, physical and psychological reasoning, etc), nor in building models that can work reliably in the real world."
1071,@GaryMarcus,2022-12-07 13:52:03+00:00,https://twitter.com/GaryMarcus/status/1600488309171818496,"@benedictevans To me, it‚Äôs principle value is n misinformation and entertainment but there are huge number of people who see it as the next big thing in many domains, including search. 

what‚Äôs your take on scope of commercial application?"
1072,@GaryMarcus,2022-12-07 13:42:05+00:00,https://twitter.com/GaryMarcus/status/1600485802542501888,@pwlot https://t.co/bqkRhpqFad
1073,@GaryMarcus,2022-12-07 13:40:03+00:00,https://twitter.com/GaryMarcus/status/1600485291177152512,@SAuronREC To analyze and detect misinformation??? Much better at creation than detection‚Ä¶
1074,@GaryMarcus,2022-12-07 13:38:34+00:00,https://twitter.com/GaryMarcus/status/1600484917707952128,"@pwlot Try it. because NLU is hard and unsolved, it‚Äôs harder than it looks."
1075,@GaryMarcus,2022-12-07 13:36:53+00:00,https://twitter.com/GaryMarcus/status/1600484492447449088,@Plinz @dileeplearning @ESYudkowsky Fixed that for you:
1076,@GaryMarcus,2022-12-07 13:25:44+00:00,https://twitter.com/GaryMarcus/status/1600481688983076865,@SAuronREC What free platform are you taking about?
1077,@GaryMarcus,2022-12-07 13:23:31+00:00,https://twitter.com/GaryMarcus/status/1600481128112324608,"Do you really want your search engines to behave like this? To give an ‚Äúimpression‚Äù of a bio that butchers the facts? 

Would you want your doctor to give you an impression of the Rx you need?

Would you want a how-to to give you an impression of how to use that new power tool?"
1078,@GaryMarcus,2022-12-07 13:19:46+00:00,https://twitter.com/GaryMarcus/status/1600480184180035584,"@prateekverma1 @benedictevans Which makes it *perfect* for cheating students and troll farms! 

but gptChat‚Äôs inability to be fully constrained by facts and ontology makes it dodgy in many more legit applications, such as open-ended queries, game-playing, lg for domestic robots, virtual assistants etc."
1079,@GaryMarcus,2022-12-07 13:11:45+00:00,https://twitter.com/GaryMarcus/status/1600478169517404161,"The constant AI hype by professionals like @plinz, which may continue for years, is embarrassing, especially as we see repeated failures (eg driverless cars, trustworthy virtual assistants, &amp; domestic robots) on large scale projects in which AI needs to interact w real world ü§∑‚Äç‚ôÇÔ∏è"
1080,@GaryMarcus,2022-12-07 13:05:44+00:00,https://twitter.com/GaryMarcus/status/1600476654174089216,@wellingmax You realize of course that the system is stochastic?
1081,@GaryMarcus,2022-12-07 05:01:06+00:00,https://twitter.com/GaryMarcus/status/1600354690470150145,"The perfect holiday gift for every nation state pushing conspiracy theories in order to undermine the trust of American voters, now available for free trial at OpenAI!"
1082,@GaryMarcus,2022-12-07 04:45:45+00:00,https://twitter.com/GaryMarcus/status/1600350828128501765,"As an American living in Canada, same‚Ä¶"
1083,@GaryMarcus,2022-12-07 04:32:21+00:00,https://twitter.com/GaryMarcus/status/1600347455769677824,I really really hope my concerns here prove to be incorrect.
1084,@GaryMarcus,2022-12-07 04:30:56+00:00,https://twitter.com/GaryMarcus/status/1600347100520542208,"@ESYudkowsky Unless automated misinformation generated by current ANI by some state actor leads eg to a full on nuclear war‚Ä¶ 

The Stack Overflow ban was a warning shot."
1085,@GaryMarcus,2022-12-07 04:24:02+00:00,https://twitter.com/GaryMarcus/status/1600345362929418243,@auren Where‚Äôd they find humans this clueless? https://t.co/Cuzlhjtofq
1086,@GaryMarcus,2022-12-07 04:16:53+00:00,https://twitter.com/GaryMarcus/status/1600343564990705664,"Today‚Äôs maybe the best day yet for AI Mastodon discussion, w sharp queries from @mkapor and others and a brief but devastating takedown re inducing future performance by @emilymbender (with a late assist from me). 

and all without a single quote tweet ü§î"
1087,@GaryMarcus,2022-12-07 02:14:17+00:00,https://twitter.com/GaryMarcus/status/1600312713280098304,"@primalpoly @EigenGender I founder and CEO‚Äôd an ML company, helped developed the IP, and sold it to Uber. So not applicable."
1088,@GaryMarcus,2022-12-07 02:11:28+00:00,https://twitter.com/GaryMarcus/status/1600312004874760193,"@tdietterich I gave one here that was vetted by @bengoertzel and @ShaneLegg:

https://t.co/yfXycYXxb9

‚Äúa shorthand for any intelligence ... that is flexible and general, with resourcefulness and reliability comparable to (or beyond) human intelligence‚Äù"
1089,@GaryMarcus,2022-12-07 02:06:50+00:00,https://twitter.com/GaryMarcus/status/1600310837163757568,"@pwlot Apple just scaled back its driverless car ambitions earlier today; that one more reflex of a bust that is happening as we speak: promise made, not delivered"
1090,@GaryMarcus,2022-12-07 02:04:22+00:00,https://twitter.com/GaryMarcus/status/1600310214783561728,how many more of cycles of hype and bust before we actually reach AGI?
1091,@GaryMarcus,2022-12-07 02:02:27+00:00,https://twitter.com/GaryMarcus/status/1600309735454306305,Apple (AAPL) Scales Back Self-Driving Car and Delays Launch Until 2026 - Bloomberg https://t.co/g7V3M1afQ6
1092,@GaryMarcus,2022-12-07 01:03:27+00:00,https://twitter.com/GaryMarcus/status/1600294887509086210,"Aiiee! AGI is here! 

Except, well, it's not."
1093,@GaryMarcus,2022-12-07 00:55:19+00:00,https://twitter.com/GaryMarcus/status/1600292838129868800,"@zeynep @say_cem It‚Äôs all conflation all the way down:

https://t.co/bbOXcz8qDI"
1094,@GaryMarcus,2022-12-06 22:42:04+00:00,https://twitter.com/GaryMarcus/status/1600259303918964736,"#chatGPT: The Second Coming of AI Jesus, or just a world class bullshit artist? 

You be the judge."
1095,@GaryMarcus,2022-12-06 22:16:31+00:00,https://twitter.com/GaryMarcus/status/1600252875095302145,@jamessseattle @SelfAwarePatter It‚Äôs in our 2019 book; would be fun to see how general/robust this is!
1096,@GaryMarcus,2022-12-06 20:26:53+00:00,https://twitter.com/GaryMarcus/status/1600225284695134208,@c_a_schiller @KimKLarsen @MichelleRempel Fully agree and happy to help
1097,@GaryMarcus,2022-12-06 20:08:23+00:00,https://twitter.com/GaryMarcus/status/1600220629797830656,"@izzi_cratic @stuz5000 It‚Äôs stochastic, context-sensitive, and unreliable"
1098,@GaryMarcus,2022-12-06 20:06:29+00:00,https://twitter.com/GaryMarcus/status/1600220150665707522,Fabulous search engine! Just ask it twice to be sure!
1099,@GaryMarcus,2022-12-06 19:19:57+00:00,https://twitter.com/GaryMarcus/status/1600208441116856320,@KimKLarsen @MichelleRempel @kevinroose
1100,@GaryMarcus,2022-12-06 19:19:27+00:00,https://twitter.com/GaryMarcus/status/1600208315426148352,"@dystopiabreaker See my essays at SciAm, Guardian and https://t.co/8ir1xKenr6"
1101,@GaryMarcus,2022-12-06 14:23:58+00:00,https://twitter.com/GaryMarcus/status/1600133954157580288,@cfchabris Oops typo! And yes
1102,@GaryMarcus,2022-12-06 13:57:53+00:00,https://twitter.com/GaryMarcus/status/1600127391699177472,The Unbearable Incoherence of Being ‚Ä¶gptChat
1103,@GaryMarcus,2022-12-06 13:53:28+00:00,https://twitter.com/GaryMarcus/status/1600126280586137600,I rest my case.
1104,@GaryMarcus,2022-12-06 06:43:56+00:00,https://twitter.com/GaryMarcus/status/1600018184110997504,"@wellingmax @ylecun @gdb @sama @SethBaum several actually, as discussed in my book Kluge. And why we are super vulnerable to what LLMs can generate."
1105,@GaryMarcus,2022-12-06 06:40:01+00:00,https://twitter.com/GaryMarcus/status/1600017199003205632,Good question. https://t.co/hYmJcKpeJy
1106,@GaryMarcus,2022-12-06 06:29:20+00:00,https://twitter.com/GaryMarcus/status/1600014508285911040,Technically of course not lies; just mistruths generated by a machine that is indifferent to truth and reality.
1107,@GaryMarcus,2022-12-06 06:27:14+00:00,https://twitter.com/GaryMarcus/status/1600013981279989760,And it can‚Äôt even be consistent about the age.
1108,@GaryMarcus,2022-12-06 06:25:07+00:00,https://twitter.com/GaryMarcus/status/1600013449467416577,"Multisourced #gpt lies about Noam Chomsky, from earlier today. 

I spoke publicly with Chomsky @WebSummit in November and can 100% assure you this false, fake @nytimes URLs and all.

Cf https://t.co/1a0k94U88X  cc @jeremyakahn  @paddycosgrave"
1109,@GaryMarcus,2022-12-06 05:11:47+00:00,https://twitter.com/GaryMarcus/status/1599994994441728000,Bonus to the bonus:
1110,@GaryMarcus,2022-12-06 05:01:33+00:00,https://twitter.com/GaryMarcus/status/1599992419176845312,"@joshelman @secos Current architectures don‚Äôt learn anything over time (beyond what they remember from the prompt and RL to filter) unless you retrain, and that‚Äôs part of the problem"
1111,@GaryMarcus,2022-12-06 04:58:09+00:00,https://twitter.com/GaryMarcus/status/1599991563631087617,"@joshelman @secos I don‚Äôt mean to understate the value of good clean ingredients, just think that having a richer architecture is also critical."
1112,@GaryMarcus,2022-12-06 04:53:55+00:00,https://twitter.com/GaryMarcus/status/1599990498667950085,@XSalaimartin From @ErnestSDavis: https://t.co/ck6r5KLKsU
1113,@GaryMarcus,2022-12-06 04:52:12+00:00,https://twitter.com/GaryMarcus/status/1599990066822418433,"@nathanbenaich counterpoint: we are NOT in the golden age of AI; in a decade people will look back and think people in 2022 got ahead of their skis, putting too much faith in simplistic architecture that were heavily prone towards bias, hallucination, shaky reasoning, and weird mistakes."
1114,@GaryMarcus,2022-12-06 04:48:32+00:00,https://twitter.com/GaryMarcus/status/1599989143836438528,"@secos @joshelman Yes, better input gives better output but better output still isn‚Äôt necessarily *sound* output. Galactica was trained on high quality rather than random stuff eg from Reddit but that in no way solved the usual challenges of hallucination and shaky reasoning"
1115,@GaryMarcus,2022-12-06 04:42:22+00:00,https://twitter.com/GaryMarcus/status/1599987589695488001,"@kevinroose Disagree with your take, as explained here:"
1116,@GaryMarcus,2022-12-06 04:38:25+00:00,https://twitter.com/GaryMarcus/status/1599986596354617345,@joshelman Don‚Äôt count on it: that‚Äôs what Galactica was an it didn‚Äôt last even as long as Liz Truss.
1117,@GaryMarcus,2022-12-06 04:31:55+00:00,https://twitter.com/GaryMarcus/status/1599984959921729536,"Bonus, one of a zillion examples of why few if any jobs will be replaced soon:"
1118,@GaryMarcus,2022-12-06 04:29:27+00:00,https://twitter.com/GaryMarcus/status/1599984341224132610,"üëâ ridiculous to presume it is ‚Äúprecursor to mass unemployment‚Äù when it struggles with math, logic, reliability, physical and psychological reasoning etc. 

3/3"
1119,@GaryMarcus,2022-12-06 04:29:27+00:00,https://twitter.com/GaryMarcus/status/1599984339772923904,"üëâ you are too generous in presuming that long-standing ‚Äúloopholes‚Äù like hallucinations, bias, and bizarre errors will ‚Äúalmost certainly be closed‚Äù, when the field has struggled w them for so long.

üëâ no apparent effort to ask skeptics (like myself, Bender, @Abebab, etc) 

2/3"
1120,@GaryMarcus,2022-12-06 04:29:27+00:00,https://twitter.com/GaryMarcus/status/1599984337940008962,"Tbh @nytimes @kevinroose this seems quite one-sided
üëâyou scarcely mention the risk for massive amounts of misinformation 
üëâ‚Äúcommendable steps to avoid the kinds of racist, sexist and offensive outputs‚Äù misses eg awful https://t.co/PEcTp9UFx5

üßµ1/3"
1121,@GaryMarcus,2022-12-06 04:03:22+00:00,https://twitter.com/GaryMarcus/status/1599977776005918720,"Ps none of the speakers has yet been announced, but expect an event on par with the first two, lots of eminent participants."
1122,@GaryMarcus,2022-12-06 04:02:11+00:00,https://twitter.com/GaryMarcus/status/1599977479502196736,"actually, @ylecun had not yet been invited, but I am sure we could make space for him, if he wanted to participate. 

how about it, Yann? Would be great to have you reprise the key points in your NeurIPS talk (many of which I agree with). 

Cc @ceobillionaire"
1123,@GaryMarcus,2022-12-06 03:56:49+00:00,https://twitter.com/GaryMarcus/status/1599976128546213891,"@Tony__Thai @MichelleRempel @ASteckley There‚Äôs plenty of data to understand the direction of travel at by now. The Stack Overflow fiasco is the kind of thing I anticipated (publicly) months ago; the cognitive challenges are things I anticipated in 2018.

We can make some pretty healthy guesses where GPT-4 will be."
1124,@GaryMarcus,2022-12-06 03:44:35+00:00,https://twitter.com/GaryMarcus/status/1599973047284686848,@MichelleRempel @Tony__Thai @ASteckley üíØ
1125,@GaryMarcus,2022-12-06 03:43:06+00:00,https://twitter.com/GaryMarcus/status/1599972675564494848,"@MichelleRempel @Tony__Thai @ASteckley Or underregulation. If we in the AI community don‚Äôt give legislators an informed view, how we can expect them to do their job?

In this instance, the tech is moving slowly towards AGI‚Äîbut rapidly towards accelerating misinformation &amp; disrupting education.

Nuanced view is vital."
1126,@GaryMarcus,2022-12-06 03:17:09+00:00,https://twitter.com/GaryMarcus/status/1599966143338676225,"@XSalaimartin Ah, yes! That is way off!"
1127,@GaryMarcus,2022-12-06 03:11:37+00:00,https://twitter.com/GaryMarcus/status/1599964752952037376,@nxthompson @MichelleRempel !!! @auren!
1128,@GaryMarcus,2022-12-06 03:04:04+00:00,https://twitter.com/GaryMarcus/status/1599962850881335298,@XSalaimartin It‚Äôs interesting but I am also concerned that we discussed that specific example both in the book and in an article in Wired that may well be in the training  corpus https://t.co/zoaKeLs3uz
1129,@GaryMarcus,2022-12-06 02:35:57+00:00,https://twitter.com/GaryMarcus/status/1599955777997148161,Eye-opening https://t.co/slOt8VLALg
1130,@GaryMarcus,2022-12-05 23:49:40+00:00,https://twitter.com/GaryMarcus/status/1599913931338043392,"@MichelleRempel thank you for being responsive; i will send you a confidential draft I am writing, outlining what i think are biggest  concerns and legislative needs"
1131,@GaryMarcus,2022-12-05 23:43:30+00:00,https://twitter.com/GaryMarcus/status/1599912376643780608,"@MichelleRempel In some ways very true!! But also depends on context (which I couldn't discern).

I am a BC resident, and expert on AI who founded an AI/ML company sold to Uber. Please DM."
1132,@GaryMarcus,2022-12-05 22:46:27+00:00,https://twitter.com/GaryMarcus/status/1599898022493982720,"Oh, darling..."
1133,@GaryMarcus,2022-12-05 22:42:51+00:00,https://twitter.com/GaryMarcus/status/1599897114129354752,"I am concerned that a Canadian member of Parliament is taking chatGPT this seriously, and would like more context here."
1134,@GaryMarcus,2022-12-05 21:52:00+00:00,https://twitter.com/GaryMarcus/status/1599884318004105216,"@Abhinav98M online only, streamed and recorded; details at https://t.co/NnELd6ldtt, cast announced soon :)"
1135,@GaryMarcus,2022-12-05 21:50:41+00:00,https://twitter.com/GaryMarcus/status/1599883988549926915,"I am sorry, but chatGPT's filters just aren't that great. @AnnCC12 sends out the bait, and chatGPT goes all in.

#misinformation by the metric ton"
1136,@GaryMarcus,2022-12-05 21:29:44+00:00,https://twitter.com/GaryMarcus/status/1599878716339138561,"https://t.co/NnELd6ldtt December 23. Sign up. Be there. 

It's going to be amazing."
1137,@GaryMarcus,2022-12-05 21:26:30+00:00,https://twitter.com/GaryMarcus/status/1599877901801127936,"in 2001 ""a series of strange phrases in journal articles"" started popping up, with ""terms like ‚Äòcounterfeit consciousness‚Äô, ‚Äòprofound neural organization‚Äô and ‚Äòcolossal information‚Äô in place ‚ÄòAI‚Äô, ‚Äòdeep neural network‚Äô and ‚Äòbig data‚Äô etc.""

https://t.co/NPGohf9Gdm"
1138,@GaryMarcus,2022-12-05 20:09:04+00:00,https://twitter.com/GaryMarcus/status/1599858413391212544,"@sleepinyourhat Would love to see this as a standard, required feature on GPT-4, if only to see the degree to which it is or is not useful at scale."
1139,@GaryMarcus,2022-12-05 19:50:10+00:00,https://twitter.com/GaryMarcus/status/1599853658082246657,"@jachiam0 Do you have actual examples of this, with links and sources?"
1140,@GaryMarcus,2022-12-05 19:45:51+00:00,https://twitter.com/GaryMarcus/status/1599852571468136448,‚ÄúCovid is just a flu‚Äù
1141,@GaryMarcus,2022-12-05 18:58:10+00:00,https://twitter.com/GaryMarcus/status/1599840569702109184,"@Sergei_Imaging sure, that's a viable extension of @allen_ai 's semantic scholar, but with you in the loop at every step, or else it is seriously flawed."
1142,@GaryMarcus,2022-12-05 18:55:11+00:00,https://twitter.com/GaryMarcus/status/1599839819563413504,"@Sergei_Imaging ‚Ä¢¬†LLM internally loses track of its sources
‚Ä¢¬†recombines stuff willy-nilly (see https://t.co/bbOXczqzRQ)
‚Ä¢¬†LLM produces unparsed strings that then need to be parsed by a separate system that would  need to decide which literature searches to do and then reason over results"
1143,@GaryMarcus,2022-12-05 18:49:55+00:00,https://twitter.com/GaryMarcus/status/1599838495404879872,Spoiler alert: They can't. We will need to develop an entirely new tech for that.
1144,@GaryMarcus,2022-12-05 16:48:00+00:00,https://twitter.com/GaryMarcus/status/1599807812309504005,it's f__ing wild.
1145,@GaryMarcus,2022-12-05 16:10:05+00:00,https://twitter.com/GaryMarcus/status/1599798273992437760,@catherineols please add me (&amp; i am writing an essay about this)
1146,@GaryMarcus,2022-12-05 14:20:59+00:00,https://twitter.com/GaryMarcus/status/1599770816073592832,"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
The tidal wave of misinformation has already started to hit. 

What are we going to about it?
‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è"
1147,@GaryMarcus,2022-12-05 14:16:14+00:00,https://twitter.com/GaryMarcus/status/1599769619019235329,"HUGELY relevant to the debate on misinformation that I have been having with @ylecun. 

If StackOverflow can‚Äôt keep up with plausible but incorrect information, what about social media and search engines?

What‚Äôs your plan here, @elonmusk? 

Cc @sama"
1148,@GaryMarcus,2022-12-05 14:04:57+00:00,https://twitter.com/GaryMarcus/status/1599766781723561989,"@PredaGabi No, but the system is stochastic and context sensitive and possibly being patched in real time. Errors if the general sort will persist"
1149,@GaryMarcus,2022-12-05 05:24:27+00:00,https://twitter.com/GaryMarcus/status/1599635795027329025,@TonyZador agreed and @dileeplearning made this point earlier tonight
1150,@GaryMarcus,2022-12-05 05:09:39+00:00,https://twitter.com/GaryMarcus/status/1599632070103662592,my work is done.
1151,@GaryMarcus,2022-12-05 05:07:48+00:00,https://twitter.com/GaryMarcus/status/1599631601327288321,"@TonyZador two reasons
1. stochasticity
2. if i understand correctly they are doing some real time patching of the RL bits."
1152,@GaryMarcus,2022-12-05 04:44:05+00:00,https://twitter.com/GaryMarcus/status/1599625635533848576,"Ok, this one literally made me laugh out loud"
1153,@GaryMarcus,2022-12-05 04:24:33+00:00,https://twitter.com/GaryMarcus/status/1599620717309755393,"Hate having to update my lectures every time a new model comes out, w new examples, making same damn points about hallucination, bias, lack of physical &amp; psychological reasoning etc 

Would be great if someone would propose a new architecture that didn't have exactly same flaws."
1154,@GaryMarcus,2022-12-05 03:45:59+00:00,https://twitter.com/GaryMarcus/status/1599611013456080896,@maartengm @NatashaMhatre @pvarasa @gregeganSF @sama Also tagging @WiringTheBrain.
1155,@GaryMarcus,2022-12-05 03:04:27+00:00,https://twitter.com/GaryMarcus/status/1599600558876557316,@maartengm @pvarasa @gregeganSF @sama @NatashaMhatre?
1156,@GaryMarcus,2022-12-05 02:55:36+00:00,https://twitter.com/GaryMarcus/status/1599598333739565057,"is anyone at Meta aware of the ‚ÄúThe Russian ‚ÄúFirehose of Falsehood‚Äù Propaganda Model, @ylecun? 

Positively chilling in light of what LLMs could do. I urge you to read it. Cc @gdb @sama

Via @SethBaum

https://t.co/Qr3NptI7vr"
1157,@GaryMarcus,2022-12-05 02:36:32+00:00,https://twitter.com/GaryMarcus/status/1599593535157981185,‚Äúsilence is complicity‚Äù
1158,@GaryMarcus,2022-12-05 02:19:59+00:00,https://twitter.com/GaryMarcus/status/1599589371476606978,Bingo!
1159,@GaryMarcus,2022-12-05 02:17:33+00:00,https://twitter.com/GaryMarcus/status/1599588760106463232,@HobbyistRust @sama It‚Äôs possible that it was fixed or that it‚Äôs stochastic; tagging @dileeplearning who generated it originally and posted yesterday: I added a link to this tweet in the main thread
1160,@GaryMarcus,2022-12-05 02:14:28+00:00,https://twitter.com/GaryMarcus/status/1599587981522006016,"@sama And although the system itself is stochastic, it‚Äôs not hard to generate similar examples eg this also from @dileeplearning:"
1161,@GaryMarcus,2022-12-05 02:13:09+00:00,https://twitter.com/GaryMarcus/status/1599587649828065281,@sama That particular example is from here:
1162,@GaryMarcus,2022-12-05 01:59:53+00:00,https://twitter.com/GaryMarcus/status/1599584310633594881,"@sama can you say that a system that sees adding crushed porcelain to breast milk as legit has any understanding of what it‚Äôs talking about?

autocomplete alone will never be a reliable substitute for interpretable understanding. Calling it ""understanding"" simply cheapens the term. https://t.co/Fmn7eUfi7q"
1163,@GaryMarcus,2022-12-05 01:42:36+00:00,https://twitter.com/GaryMarcus/status/1599579964147662849,"@animesh_garg @AnimaAnandkumar @rao2z @guyvdb If there were interpretable outputs that reliably could feed reasoning and planning I would say yes, but I don‚Äôt see that. 

I see more of the kinds of ungrounded, idiosyncratic, correlative approximations we saw in chatGPT‚Äôs predecessors."
1164,@GaryMarcus,2022-12-05 01:34:45+00:00,https://twitter.com/GaryMarcus/status/1599577986931785728,"@animesh_garg @AnimaAnandkumar Careful:

1. learning alone is not sufficient; some forms of learning (eg induction of Ngrams) are clearly aconceptual. 

2. outputs of LLMs are problematic eg wrt planning (@rao2z), reasoning (@guyvdb) etc 

3. LLMs sample from human talk of concepts, not concepts themselves"
1165,@GaryMarcus,2022-12-04 23:54:45+00:00,https://twitter.com/GaryMarcus/status/1599552821275557888,beautiful example of why chatGPT isn‚Äôt suitable for use as a voice assistant (cf my https://t.co/OFidJ1B1t6) cc @plinz
1166,@GaryMarcus,2022-12-04 23:47:31+00:00,https://twitter.com/GaryMarcus/status/1599551000180068352,@AnimaAnandkumar I really don‚Äôt see it that way. In what sense do you think these systems are learning concepts?
1167,@GaryMarcus,2022-12-04 23:27:58+00:00,https://twitter.com/GaryMarcus/status/1599546080555044865,@kendmil @spiantado @OpenAI @Abebab @sama @open_ai i stand what by I said in my pinned tweet:
1168,@GaryMarcus,2022-12-04 23:10:55+00:00,https://twitter.com/GaryMarcus/status/1599541790180511744,"@Plinz No, really not. Everything I said here still applies:

https://t.co/OFidJ1B1t6"
1169,@GaryMarcus,2022-12-04 22:49:56+00:00,https://twitter.com/GaryMarcus/status/1599536509165916161,"@robinc @ylecun No, in your analogy I am an idiot for not recognizing that chatGPT can fly. But it can‚Äôt; and I won‚Äôt be mocked into pretending that it does."
1170,@GaryMarcus,2022-12-04 22:39:41+00:00,https://twitter.com/GaryMarcus/status/1599533931678031872,"@robinc Sorry to burst your bubble, but it‚Äôs a ladder, not an airplane. And before you pin everything on me, note that @ylecun has said the same."
1171,@GaryMarcus,2022-12-04 19:25:10+00:00,https://twitter.com/GaryMarcus/status/1599484978798395392,Welcome to my world! ü§£
1172,@GaryMarcus,2022-12-04 16:32:53+00:00,https://twitter.com/GaryMarcus/status/1599441621291978752,@rasbt @oleg008 Not really
1173,@GaryMarcus,2022-12-04 15:43:49+00:00,https://twitter.com/GaryMarcus/status/1599429272246325250,Totally disagree w @ylecun about the risks of LLMs‚Äîbut fully agree with him that generative models aren‚Äôt the royal road to AGI.
1174,@GaryMarcus,2022-12-04 15:35:25+00:00,https://twitter.com/GaryMarcus/status/1599427159931891712,"üíØ: ‚Äúoptimising plausibility over veracity‚Äù ‚Äúreaching genuinely superhuman bullshit levels‚Äù ‚Äúseems like a *really* terrible engineering goal.‚Äú

And yet that is *exactly* where we are."
1175,@GaryMarcus,2022-12-04 14:02:18+00:00,https://twitter.com/GaryMarcus/status/1599403727185928194,üíØ: ‚ÄúOpenAI was started as open-source &amp; non-profit. Neither are still true.‚Äù
1176,@GaryMarcus,2022-12-04 13:42:39+00:00,https://twitter.com/GaryMarcus/status/1599398779282632704,"ü§£ü§£ü§£. This is a joke, right?"
1177,@GaryMarcus,2022-12-03 23:08:42+00:00,https://twitter.com/GaryMarcus/status/1599178843667202048,@yoavgo @BlancheMinerva @Abebab @emilymbender A start: https://t.co/10JQeM8uN8
1178,@GaryMarcus,2022-12-03 16:00:55+00:00,https://twitter.com/GaryMarcus/status/1599071187266478082,Absurd to think that AI is going to contribute only to the solution but not at all to the problem.
1179,@GaryMarcus,2022-12-03 15:20:00+00:00,https://twitter.com/GaryMarcus/status/1599060891835977729,Other people‚Äôs experience?
1180,@GaryMarcus,2022-12-03 01:50:16+00:00,https://twitter.com/GaryMarcus/status/1598857114721480704,Written *before* chatGPT. https://t.co/fuuACVUFjt
1181,@GaryMarcus,2022-12-03 01:47:29+00:00,https://twitter.com/GaryMarcus/status/1598856413773975553,@ylecun
1182,@GaryMarcus,2022-12-03 01:16:46+00:00,https://twitter.com/GaryMarcus/status/1598848686385401856,Nothing to worry about in these machines that lack human values. Nothing whatsoever.
1183,@GaryMarcus,2022-12-03 00:39:01+00:00,https://twitter.com/GaryMarcus/status/1598839186735661059,"PR that makes it sound like @MetaAI‚Äôs Cicero (about which I am overall fairly positive) displayed empathy.

Spoiler alert: it didn‚Äôt."
1184,@GaryMarcus,2022-12-03 00:26:16+00:00,https://twitter.com/GaryMarcus/status/1598835977124220928,"all part of the master plan, right?

https://t.co/asy66FeFpy"
1185,@GaryMarcus,2022-12-03 00:13:16+00:00,https://twitter.com/GaryMarcus/status/1598832705437061120,"@ylecun Just spitballing here, but maybe this ‚Äútroll‚Äù was reacting with alarm to this tweet of yours?  I sure read it as suggesting that nobody could be hurt by LLM generated misinformation. Did I misread it? https://t.co/U1hVBbjdVS"
1186,@GaryMarcus,2022-12-02 21:25:39+00:00,https://twitter.com/GaryMarcus/status/1598790522419630081,@sd_marlow @filippie509 I keep taking a break and then he or someone else tags me
1187,@GaryMarcus,2022-12-02 16:08:52+00:00,https://twitter.com/GaryMarcus/status/1598710802152042497,@yoavgo @Grady_Booch @Meta @srijankedia @EthanVPorter @ProfNoahGian Keep asking LeCun for what Meta might have done and he won‚Äôt answer
1188,@GaryMarcus,2022-12-02 16:04:05+00:00,https://twitter.com/GaryMarcus/status/1598709596335792128,"@yoavgo @Grady_Booch @Meta @srijankedia @EthanVPorter @ProfNoahGian More anxiety, more people taking ineffective or dangerous drugs, fewer people taking needed vaccines, etc. Increased distrust in all media. more polarization. Etc"
1189,@GaryMarcus,2022-12-02 15:58:04+00:00,https://twitter.com/GaryMarcus/status/1598708084725420033,"@yoavgo @Grady_Booch @Meta Have you read the literature? @srijankedia @EthanVPorter @ProfNoahGian etc can give you some pointers. This example from one new paper of SK‚Äôs:l; other work eg on misinfo and vaccine acceptance, etc https://t.co/NUavjVPmIE"
1190,@GaryMarcus,2022-12-02 15:40:39+00:00,https://twitter.com/GaryMarcus/status/1598703703149932545,"why does GPT-3 careen between brilliant and clueless? 

https://t.co/bbOXczqzRQ"
1191,@GaryMarcus,2022-12-02 15:29:34+00:00,https://twitter.com/GaryMarcus/status/1598700913681498112,"pro tip: always good to compare what corporate flaks tell you w what the actual  scientific literature says.

Eg @meta VP @ylecun claims misinformation can‚Äôt hurt you

New paper by @srijankedia &amp; @verma22gaurav carefully documents mental health costs of misinfo in real world

ü§∑‚Äç‚ôÇÔ∏è https://t.co/bB3B4UnPXg"
1192,@GaryMarcus,2022-12-02 14:10:16+00:00,https://twitter.com/GaryMarcus/status/1598680954268446720,"üëèToday‚Äôs Guns Don‚Äôt Kill People, People Kill People award goes to ‚Ä¶ @metaAI and their Chief Scientist AI ‚Ä¶ Yann LeCun! 

Yes, guns do kill people, but so do knives and car accidents!"
1193,@GaryMarcus,2022-12-02 14:01:49+00:00,https://twitter.com/GaryMarcus/status/1598678830369345539,"@ylecun @TobyWalsh @MetaAI It's irresponsible and an insult to intelligence to suggest that people will allow themselves to be misled by SBFs.
Yes, SBFs produce factually wrong statements.
So do novelists, poets, comedians, playwrights, politicians, used car salesmen, marketroids, and just about everyone."
1194,@GaryMarcus,2022-12-02 00:06:01+00:00,https://twitter.com/GaryMarcus/status/1598468494068416512,The Unbearable Unreliability of Being GPT
1195,@GaryMarcus,2022-12-01 20:11:24+00:00,https://twitter.com/GaryMarcus/status/1598409451744423936,@rachelmetz @CNN So sorry!
1196,@GaryMarcus,2022-12-01 17:05:18+00:00,https://twitter.com/GaryMarcus/status/1598362614135803904,@MMikeMMa @plibin Now answered here:
1197,@GaryMarcus,2022-12-01 16:16:03+00:00,https://twitter.com/GaryMarcus/status/1598350221192228864,"Brilliant question from Mike Ma: How come GPT can seem so brilliant one minute and so breathtakingly dumb the next?

I answer it here: 
https://t.co/bbOXcz8qDI"
1198,@GaryMarcus,2022-12-01 15:24:36+00:00,https://twitter.com/GaryMarcus/status/1598337274998976512,"@TonyZador @dileeplearning i think you have lost perspective. if  a human told you that bananas can't go in ovens, you would be worried."
1199,@GaryMarcus,2022-12-01 15:09:28+00:00,https://twitter.com/GaryMarcus/status/1598333466004766720,@ben_j_radford @RonChrisley @PatHaye67745536 @mdahardy @MelMitchell1 It‚Äôs only sometimes human-like.
1200,@GaryMarcus,2022-12-01 15:08:19+00:00,https://twitter.com/GaryMarcus/status/1598333177046519810,Should I write my next substack about this excellent question?
1201,@GaryMarcus,2022-12-01 15:06:18+00:00,https://twitter.com/GaryMarcus/status/1598332670659874817,@ChristophMolnar @_MichaelZink
1202,@GaryMarcus,2022-12-01 14:58:43+00:00,https://twitter.com/GaryMarcus/status/1598330760502513664,@RobKnight__ https://t.co/G7j1RQHcPV
1203,@GaryMarcus,2022-12-01 14:45:28+00:00,https://twitter.com/GaryMarcus/status/1598327427888869376,"What‚Äôs your favorite example chatGPT (not davinci3) being misleading or harmful? 

This is misleading about how math works https://t.co/BfLIOul2KG"
1204,@GaryMarcus,2022-12-01 14:43:00+00:00,https://twitter.com/GaryMarcus/status/1598326804003291137,@TonyZador @dileeplearning Wasn‚Äôt your own banana and apple example misleading?
1205,@GaryMarcus,2022-12-01 14:41:50+00:00,https://twitter.com/GaryMarcus/status/1598326510582013952,Would you want a calculator that often forgot to carry the 1?
1206,@GaryMarcus,2022-12-01 14:36:25+00:00,https://twitter.com/GaryMarcus/status/1598325146548195328,"‚ÄúBut whatsamatta, I had a conversation with a drunk guy at party that was just like that‚Äù"
1207,@GaryMarcus,2022-12-01 14:29:48+00:00,https://twitter.com/GaryMarcus/status/1598323483863400449,"@TonyZador Tony, surely context does matter yes. @dileeplearning what w context in yours?

Also there are two different new models, davinci-3 and chat-gpt and they behave differently."
1208,@GaryMarcus,2022-12-01 06:59:22+00:00,https://twitter.com/GaryMarcus/status/1598210128901046272,Bonus points for ‚Ä¶ this?
1209,@GaryMarcus,2022-12-01 06:52:05+00:00,https://twitter.com/GaryMarcus/status/1598208293842784256,With thanks to @dileeplearning @amahabal (x2) and @rtombs / @mrgreene1977
1210,@GaryMarcus,2022-12-01 06:52:04+00:00,https://twitter.com/GaryMarcus/status/1598208291838230528,Choose one or reply with your different favorite
1211,@GaryMarcus,2022-12-01 06:52:03+00:00,https://twitter.com/GaryMarcus/status/1598208285756510210,"favorite #GPT fail of the day? 

My top 4 so far (poll in next tweet); please add your own https://t.co/RpsrV0G7Z9"
1212,@GaryMarcus,2022-12-01 06:41:27+00:00,https://twitter.com/GaryMarcus/status/1598205619269677056,Or how about this?
1213,@GaryMarcus,2022-12-01 06:35:19+00:00,https://twitter.com/GaryMarcus/status/1598204074968563712,@hankgreen Can you give more detail about exactly that you did?
1214,@GaryMarcus,2022-12-01 06:33:56+00:00,https://twitter.com/GaryMarcus/status/1598203726094749696,When 3+5 doesn‚Äôt quite add up to 8
1215,@GaryMarcus,2022-12-01 01:59:58+00:00,https://twitter.com/GaryMarcus/status/1598134782533128192,"Fun: ""Deep Learning is Hitting a Wall""‚Äîwhich anticipated many of the problems AI systems are continuing to have with hallucinations and compositionality‚Äîwas on @pocket's list of Best Tech Articles in 2022, along with @RonanFarrow @kevinroose &amp; more https://t.co/YXnv6KIRHC"
1216,@GaryMarcus,2022-12-01 01:47:02+00:00,https://twitter.com/GaryMarcus/status/1598131525542768640,"interesting how some people get GPT examples like this, others report accurate examples. 

as I have pointing out for a long time, the real issue was and is reliability."
1217,@GaryMarcus,2022-12-01 01:45:48+00:00,https://twitter.com/GaryMarcus/status/1598131214824898560,@TonyZador @ylecun try it 5 more times report all the results? cc @ErnestSDavis
1218,@GaryMarcus,2022-12-01 01:44:50+00:00,https://twitter.com/GaryMarcus/status/1598130972293496832,"@nlpnyc Is this asking for misinfo? are you doing any statistical analysis? how reliable are these things? i haven't tried it yet (traveling) but plenty of examples like this already have been posted.

https://t.co/qxff2JNXuW"
1219,@GaryMarcus,2022-11-30 23:00:41+00:00,https://twitter.com/GaryMarcus/status/1598089663889444864,"@ErnestSDavis and time was of course a major theme in our book, https://t.co/Pt7HZc3RJd. it‚Äôs almost like *our* goalposts aren‚Äôt the ones that are moving‚Ä¶"
1220,@GaryMarcus,2022-11-30 22:59:03+00:00,https://twitter.com/GaryMarcus/status/1598089250607894532,"Is this a ‚Äúmisuse‚Äù of these models, @ylecun? Or the kind of thing for which we might reasonably expect better quality answers?"
1221,@GaryMarcus,2022-11-30 22:44:38+00:00,https://twitter.com/GaryMarcus/status/1598085625584181248,"#Chatgpt-3, quickly defeated by @ernestsdavis, in part based on examples from our 2019 book https://t.co/C6XodPcoZW https://t.co/6H7hvNSUih"
1222,@GaryMarcus,2022-11-30 22:23:13+00:00,https://twitter.com/GaryMarcus/status/1598080233374371840,@mrgreene1977 @imcharleslo @Michael_J_Black https://t.co/bfuOUe9qyk
1223,@GaryMarcus,2022-11-30 21:24:22+00:00,https://twitter.com/GaryMarcus/status/1598065425807740929,"@nlpnyc 1. These models * are* poor - they can‚Äôt engage w reality
2. That‚Äôs what makes them dangerous
3. Social media etc should be financially incented to reduce amount of misinfo on their platforms 
4. Government and FAANG ought to foster AI that can engage w facts and validity."
1224,@GaryMarcus,2022-11-30 21:12:11+00:00,https://twitter.com/GaryMarcus/status/1598062358886486016,"@nlpnyc Sure that particular API is not yet out, but ‚Ä¶

- the basic tech is now known
- some major nations etc have already shown a considerable willingness to hire humans to produce misinfo at scale
- you are hiding like an ostrich #w you think they lack interest in this new tech"
1225,@GaryMarcus,2022-11-30 21:07:33+00:00,https://twitter.com/GaryMarcus/status/1598061194128293889,"‚ÄúYou can‚Äôt go wrong‚Äù with Large Language Models‚Ä¶ 

#writingyourownepitaph"
1226,@GaryMarcus,2022-11-30 20:58:33+00:00,https://twitter.com/GaryMarcus/status/1598058929199919110,@jppesky But see also
1227,@GaryMarcus,2022-11-30 20:57:27+00:00,https://twitter.com/GaryMarcus/status/1598058648869441536,"Yikes! Who needs Galactica when have ChatGPT?  üò±

(for a different view: https://t.co/8n27y6mqpE)"
1228,@GaryMarcus,2022-11-30 17:23:34+00:00,https://twitter.com/GaryMarcus/status/1598004825220075521,@irinarish So then scale *isn‚Äôt* all you need.
1229,@GaryMarcus,2022-11-30 15:26:46+00:00,https://twitter.com/GaryMarcus/status/1597975432221306880,Thread that is both hilarious and frightening. fun and dangerous things to with GPT-4!
1230,@GaryMarcus,2022-11-30 15:07:23+00:00,https://twitter.com/GaryMarcus/status/1597970552983277571,"Written 5 months before Galactica, and just you wait til you see GPT-4."
1231,@GaryMarcus,2022-11-29 18:30:52+00:00,https://twitter.com/GaryMarcus/status/1597659372511199232,What does Meta AI‚Äôs Diplomacy-winning Cicero Mean for AI? |  reprinted ‚Å¶@CACM https://t.co/JJjna1Y9AR
1232,@GaryMarcus,2022-11-29 05:02:39+00:00,https://twitter.com/GaryMarcus/status/1597455979230416896,"@BobbyAlter @ylecun @mrgreene1977 @rhinigtas @ykilcher But absent any data, please excuse us for being skeptical"
1233,@GaryMarcus,2022-11-29 04:01:45+00:00,https://twitter.com/GaryMarcus/status/1597440651725266950,"@srikumarks @ylecun @mrgreene1977 @rhinigtas @ykilcher @JeanDreze @AltNews Different harms and different processes but yes, just illustrative. It would be great to have real data here."
1234,@GaryMarcus,2022-11-29 03:48:08+00:00,https://twitter.com/GaryMarcus/status/1597437226832756736,"@ylecun @srikumarks @mrgreene1977 @rhinigtas @ykilcher @JeanDreze @AltNews @theliverdr Again do you have *data*?
Also:
* You said above ""almost all of it is harmless‚Äú; if even .01% of LLM generated misinfo is harmful, we may be in trouble
* the risk is real even if only tiny fraction is distributed 
* why would LLMs *NOT* be able to help with crafting misinfo?"
1235,@GaryMarcus,2022-11-29 03:06:44+00:00,https://twitter.com/GaryMarcus/status/1597426809880342528,"@ylecun @BobbyAlter @mrgreene1977 @rhinigtas @ykilcher surely not 100% You have any data on efficacy? 

if even .01% of LLM generated misinfo makes it through, we may be in trouble

Cc @ProfNoahGian @noUpside @davidlazer"
1236,@GaryMarcus,2022-11-29 01:06:39+00:00,https://twitter.com/GaryMarcus/status/1597396590175858688,"@ylecun @mrgreene1977 @rhinigtas @ykilcher Folks like @davidlazer, @ethanporter, and @ProfNoahGian have done both correlational and experimental work that suggests otherwise. As an example, from Lazer: https://t.co/u0ORdBeL53"
1237,@GaryMarcus,2022-11-27 23:24:52+00:00,https://twitter.com/GaryMarcus/status/1597008586433265664,"@Grady_Booch @_ashawndabney me, too"
1238,@GaryMarcus,2022-11-27 22:54:31+00:00,https://twitter.com/GaryMarcus/status/1597000948756676609,@ProfNoahGian as discussed here: https://t.co/4PQpe24ISL cc @ylecun
1239,@GaryMarcus,2022-11-27 22:27:43+00:00,https://twitter.com/GaryMarcus/status/1596994204995309568,@realGeorgeHotz @elonmusk @NautilusMag the trick is do that at scale
1240,@GaryMarcus,2022-11-27 20:21:25+00:00,https://twitter.com/GaryMarcus/status/1596962420257591296,"@elonmusk Right now, AI is terrible at detecting misinformation. It doesn‚Äôt have to be.

my look at  your predicament @elonmusk and how AI might help, @nautilusmag

https://t.co/4PQpe24ISL"
1241,@GaryMarcus,2022-11-27 20:18:56+00:00,https://twitter.com/GaryMarcus/status/1596961794899443712,"@realGeorgeHotz FYI: Right now, AI is terrible at detecting misinformation. It doesn‚Äôt have to be.

my look at @elonmusk's predicament and how AI might help, @nautilusmag

https://t.co/4PQpe24ISL"
1242,@GaryMarcus,2022-11-27 20:09:34+00:00,https://twitter.com/GaryMarcus/status/1596959436341669890,"AI Is Terrible at Detecting Misinformation. It Doesn‚Äôt Have to Be. 

My look at @elonmusk's predicament and how AI might help 

https://t.co/4PQpe24ISL"
1243,@GaryMarcus,2022-11-27 18:55:56+00:00,https://twitter.com/GaryMarcus/status/1596940905067745280,"later today @NautilusMag, a memo to @elonmusk"
1244,@GaryMarcus,2022-11-27 18:20:15+00:00,https://twitter.com/GaryMarcus/status/1596931925733957632,"@davidmanheim @polynoamial Fair enough, butI was raising AZ as a thought experiment/point of comparison.  not sure how much Noam can speak freely about how Cicero evolved or will evolve, but I find the modular structure that they used to be interesting, esp since DM‚Äôs related work was well known to them"
1245,@GaryMarcus,2022-11-27 16:44:40+00:00,https://twitter.com/GaryMarcus/status/1596907872008671232,"Sorta sucks to feel intellectually obliged to retweet all @polynoamial‚Äôs smart takes on AlphaZero and Cicero, because now I think nobody‚Äôs gonna take my bet ü§£"
1246,@GaryMarcus,2022-11-27 16:42:15+00:00,https://twitter.com/GaryMarcus/status/1596907264371486722,"@ykilcher @polynoamial not sure who you are asking; my whole point is that you are going to need eg a separate language model, and that a relatively blank slate like AlphaZero is going to flail on that side of things. again this passage from my 2018 arXiv on AlphaGo &amp; Innateness still mostly stands: https://t.co/ZlEWSGZ67D"
1247,@GaryMarcus,2022-11-27 16:35:46+00:00,https://twitter.com/GaryMarcus/status/1596905630866247680,"@ykilcher @polynoamial (just to be clear, re the bet I was referring to the language version, though the no-press version is an interesting question in its own right)"
1248,@GaryMarcus,2022-11-27 16:34:04+00:00,https://twitter.com/GaryMarcus/status/1596905206184554496,"@ykilcher I am not prepared to subsidize the evaluation; I think @deepmind would need to do the development and evaluation, since I don‚Äôt think AZ is open, and training would be costly. But (for readability) you might want supply your thoughts here about how you think that might proceed."
1249,@GaryMarcus,2022-11-27 16:28:24+00:00,https://twitter.com/GaryMarcus/status/1596903777357139968,"@GuillaumeLample @polynoamial that‚Äôs a win for nativism, though, if we  need different modules for different pieces of the problem, rather than some single universal solvent. here‚Äôs something I wrote in 2018 [https://t.co/rrlbQQ3Z6t] that mostly still stands; whole paper is still extremely relevant. https://t.co/3TrWF9FfZV"
1250,@GaryMarcus,2022-11-27 16:05:50+00:00,https://twitter.com/GaryMarcus/status/1596898099649458178,"as @ykilcher notes, we need some kind of fair provision around the fact that Diplomacy requires seven players. 

in an ideal, strong human players ought to be part of the mix."
1251,@GaryMarcus,2022-11-27 16:03:29+00:00,https://twitter.com/GaryMarcus/status/1596897508948873219,"Prediction 

AlphaZero (alone, altered only to include extra data sources) can‚Äôt beat Cicero in 20 game blitz Diplomacy match.

Notes: 
‚Ä¢¬†DeepMind can try anytime, since Cicero is open source
‚Ä¢ Not my fault if DM doesn‚Äôt try (or tries, fails, doesn‚Äôt report)

@MatthewJBar"
1252,@GaryMarcus,2022-11-27 15:36:41+00:00,https://twitter.com/GaryMarcus/status/1596890764893880320,"You think AlphaZero (alone) can beat Cicero in Diplomacy?

I don‚Äôt. 

cc: @polynoamial"
1253,@GaryMarcus,2022-11-27 05:28:21+00:00,https://twitter.com/GaryMarcus/status/1596737671212453888,@natanielruizg @MatthewJBar @MetaAI @ErnestSDavis @NYUScience @polynoamial Knock yourself out :)
1254,@GaryMarcus,2022-11-27 05:17:03+00:00,https://twitter.com/GaryMarcus/status/1596734826799071232,@asyncmind Cicero is open source so it would be easy for @openai to try if they wanted to
1255,@GaryMarcus,2022-11-27 05:09:20+00:00,https://twitter.com/GaryMarcus/status/1596732885993934848,"Anyone want to be against me on this? 

#gpt4 vs Cicero @ blitz Diplomacy."
1256,@GaryMarcus,2022-11-26 16:45:28+00:00,https://twitter.com/GaryMarcus/status/1596545683653545985,"@bsgallagher @elonmusk @WholeMarsBlog Unless they have solved the outlier problem, I seriously doubt it."
1257,@GaryMarcus,2022-11-26 16:29:38+00:00,https://twitter.com/GaryMarcus/status/1596541701363236867,"üëâwhat's Noam Chomsky think about GPT-3?
üëâwhy doesn't Alexa use GPT-3?
üëâwhat does Meta's new Diplomacy AI bot means for AI?
üëâwhat can linguistics teach AI?
üëâwhat's the debate over ‚Äúsentience‚Äù in AI really about?
https://t.co/8ir1xKenr6 has got you covered. subscribe for free"
1258,@GaryMarcus,2022-11-26 16:12:04+00:00,https://twitter.com/GaryMarcus/status/1596537278633250821,"Way too soon. RIP, Irene Cara."
1259,@GaryMarcus,2022-11-26 15:17:45+00:00,https://twitter.com/GaryMarcus/status/1596523611413970945,"@anderssandberg @dw2 True, but perhaps more around emotion than hallucination"
1260,@GaryMarcus,2022-11-26 03:50:55+00:00,https://twitter.com/GaryMarcus/status/1596350765039517696,"ü§£ Seems like, I dunno, maybe, Twitter‚Äôs trending algorithms could use some small tweaks? https://t.co/SRR6O30Eoi"
1261,@GaryMarcus,2022-11-26 03:43:56+00:00,https://twitter.com/GaryMarcus/status/1596349006464315399,"@Noahpinion @lenlayton @0xfbifemboy @ylecun 1. there is no standard measure
2. closest thing is TruthfulQA on which LLMs are very poor
3. Galactica &amp; GPT-3 can make up plausible but often false BS on any topic on demand, eg below
4. If @Meta has done any analysis of how much misinfo is LLM-generated, LeCun isn‚Äôt saying https://t.co/nxZKeOys3r"
1262,@GaryMarcus,2022-11-26 02:21:44+00:00,https://twitter.com/GaryMarcus/status/1596328321801158656,"@FelixHill84 @ylecun @Grady_Booch @Meta I genuinely think that LeCun needs perspective here, and that he is embarrassing himself, as a great number of people in many fields have pointed out; aside from that, he has completely misread Grady‚Äôs motivations."
1263,@GaryMarcus,2022-11-26 02:14:24+00:00,https://twitter.com/GaryMarcus/status/1596326476395483136,"@pmddomingos one mechanism among several, eg see also https://t.co/wd7SDrII6c"
1264,@GaryMarcus,2022-11-26 01:39:23+00:00,https://twitter.com/GaryMarcus/status/1596317661688139778,"At this rate, you won‚Äôt have to pay the $8 to have an ad-free Twitter https://t.co/PTUnbdhL3P"
1265,@GaryMarcus,2022-11-26 01:03:14+00:00,https://twitter.com/GaryMarcus/status/1596308563441618944,üíØ
1266,@GaryMarcus,2022-11-25 23:42:19+00:00,https://twitter.com/GaryMarcus/status/1596288203262414848,@ylecun @BobbyAlter https://t.co/vnADWFV31r
1267,@GaryMarcus,2022-11-25 22:40:47+00:00,https://twitter.com/GaryMarcus/status/1596272716285612034,I feel like I am living in a real-life version of Don‚Äôt Look Up.
1268,@GaryMarcus,2022-11-25 21:52:14+00:00,https://twitter.com/GaryMarcus/status/1596260499817398273,"@BobbyAlter @ylecun thanks; as you can see from my quote tweet this really clicked something together for me; a scam I had seen but not understood. Your concern has already come to pass, I believe."
1269,@GaryMarcus,2022-11-25 21:50:55+00:00,https://twitter.com/GaryMarcus/status/1596260168882606080,"Example of medical misinfo in the wild, for purposes of ad sales hoax, that looks LLM-generated to me, sample text. [ü™° 3/3]

cc @noUpside @ylecun @ProfNoahGian @EthanVPorter @katestarbird @sinanaral @justinhendrix @DG_Rand @lorakolodny @chafkin https://t.co/ydTxFClrzI"
1270,@GaryMarcus,2022-11-25 21:50:54+00:00,https://twitter.com/GaryMarcus/status/1596260164101111808,"Here‚Äôs an actual case of coordinated hoax in the wild that I think may have involved LLM‚Äôs: Overall hoax description [ü™° 2/3]

https://t.co/UcHPlTM7az"
1271,@GaryMarcus,2022-11-25 21:50:54+00:00,https://twitter.com/GaryMarcus/status/1596260162083639301,"Using fake medical info to sell ad clicks: Disturbing, plausible, and perhaps inevitable. [ü™° 1/3]
#gpt3r #misinformation #possiblesightinginthewild"
1272,@GaryMarcus,2022-11-25 21:09:38+00:00,https://twitter.com/GaryMarcus/status/1596249775724453888,"I too would love to hear from the integrity teams @meta @twitter @youtube @tiktok_us etc.

Not clear that Twitter still has one,  but would love to hear from former employees. My DM‚Äôs are open, and happy to continue conversations elsewhere."
1273,@GaryMarcus,2022-11-25 21:05:15+00:00,https://twitter.com/GaryMarcus/status/1596248674241515521,"@ylecun @Grady_Booch @Meta You, my former friend, are burning your reputation to the ground. 

Everyone is telling you to lie down and go home. 

Listen to what they are saying.  Not for me; for yourself."
1274,@GaryMarcus,2022-11-25 20:50:52+00:00,https://twitter.com/GaryMarcus/status/1596245053915205633,"@Pehdrew_ No, but by default it gives too little consideration to ethics and consequences.
 
what‚Äôs happened lately is next level."
1275,@GaryMarcus,2022-11-25 20:45:51+00:00,https://twitter.com/GaryMarcus/status/1596243793417834501,"@ylecun @Grady_Booch @Meta Easy there, Yann. Maybe you might need a few days off?  

@Grady_Booch is an IBM Fellow, and one of the world‚Äôs leading software architects, eminent in his field, fully capable of reaching his own conclusions."
1276,@GaryMarcus,2022-11-25 19:56:42+00:00,https://twitter.com/GaryMarcus/status/1596231421261393922,"Good science, poor ethical leadership."
1277,@GaryMarcus,2022-11-25 19:48:43+00:00,https://twitter.com/GaryMarcus/status/1596229412131049472,"This is EXACTLY why you need to answer my misinfo question with candor. 

By ducking it, you make it impossible for anyone outside of @meta to properly consider those cost-benefit tradeoffs. and most people therefore naturally infer that you are hiding something damaging."
1278,@GaryMarcus,2022-11-25 19:47:46+00:00,https://twitter.com/GaryMarcus/status/1596229174179819521,@AlexCEngler @noUpside @erikbryn @ylecun There are multiple potential serious harms that need serious attention
1279,@GaryMarcus,2022-11-25 18:16:23+00:00,https://twitter.com/GaryMarcus/status/1596206178140553216,"@MMikeMMa (it‚Äôs coauthored, by @ErnestSDavis and me, to just to be clear, so with not via)"
1280,@GaryMarcus,2022-11-25 18:15:37+00:00,https://twitter.com/GaryMarcus/status/1596205982744731648,"@AlexCEngler @jmourabarbosa Consider that Birdwatch / Community Notes @twitter relies on heavy human annotation; without AI it will never keep pace with Galactica/GPT-3/GPT-4 etc.

@elonmusk"
1281,@GaryMarcus,2022-11-25 18:13:59+00:00,https://twitter.com/GaryMarcus/status/1596205574290804736,"Wondering how LLM-produced #misinformation might change the *economics* of misinformation?

You can now get your own custom-trained GPT-3 level misinfo machine for less than one Russian troll factory used to spend in a month: https://t.co/mmXglETVIq

@erikbryn @ylecun @noUpside"
1282,@GaryMarcus,2022-11-25 17:52:10+00:00,https://twitter.com/GaryMarcus/status/1596200081656786944,"@MatthewJBar @MetaAI @ErnestSDavis @NYUScience Doubt any pure LLM, even apparently multimodal, as GPT-4 is supposed to be, will be able to beat Cicero any time soon! 

happy to put sth on Metaculus betting that 1st world champ in Diplomacy will be modular a la Cicero rather than merely huge &amp; general-purpose

cc @polynoamial"
1283,@GaryMarcus,2022-11-25 17:39:51+00:00,https://twitter.com/GaryMarcus/status/1596196981885767681,"@wayneholmes @ylecun I stand with @abebab who speaks truth to you. 

you would do well to take a step back to listen to her and the many others, from @rsalakhu to @dmonett to  @wayneholmes to @Michael_J_Black that have been suggesting you reevaluate your strategy."
1284,@GaryMarcus,2022-11-25 17:33:26+00:00,https://twitter.com/GaryMarcus/status/1596195368056020993,@fernandaedi so sorry! sending you love and sympathy.
1285,@GaryMarcus,2022-11-25 17:25:21+00:00,https://twitter.com/GaryMarcus/status/1596193335299170305,"@jmourabarbosa no. the net amount of misinformation will increase exponentially, because it will be essentially cost-free to generate infinite variations on any given them, and increasingly plausible hence of considerable value to the many who already pay people to create it."
1286,@GaryMarcus,2022-11-25 17:17:10+00:00,https://twitter.com/GaryMarcus/status/1596191276688605185,"Precisely! Galactica and GPT-3 generate misinformation with the ease of a Google query. 

How on earth could that not be something we ought to be worried about? 

And, lordy, when #GPT-4 comes ..."
1287,@GaryMarcus,2022-11-25 17:02:16+00:00,https://twitter.com/GaryMarcus/status/1596187524183252994,Holy Darwin! @sama @gwern and I totally agree on something!
1288,@GaryMarcus,2022-11-25 16:59:19+00:00,https://twitter.com/GaryMarcus/status/1596186784408694784,@shyankothari pity @ykilcher and I disagree so much or he could direct!
1289,@GaryMarcus,2022-11-25 16:37:19+00:00,https://twitter.com/GaryMarcus/status/1596181246841090048,"LOVE the fact that @polynoamial, one of the leaders in this research, retweeted this &amp; was also kind enough to read a draft‚Äîeven though @ErnestSDavis raise some challenges for the work.

A+ science is about publishing great results but also taking challenges seriously.

‚ù§Ô∏èüëè‚≠êÔ∏è"
1290,@GaryMarcus,2022-11-25 16:29:34+00:00,https://twitter.com/GaryMarcus/status/1596179297525714944,"@an_open_mind @dmonett @Abebab @wayneholmes @ylecun @emilymbender @MelMitchell1 Longer analysis, w @ErnestSDavis, cc @SilverJacket:"
1291,@GaryMarcus,2022-11-25 16:16:05+00:00,https://twitter.com/GaryMarcus/status/1596175901318090753,now online:
1292,@GaryMarcus,2022-11-25 16:14:08+00:00,https://twitter.com/GaryMarcus/status/1596175414069977088,"Wondering what @MetaAI's legit impressive new AI Cicero might mean for the next few years in AI?

Hint: It‚Äôs not all about scaling.

@ErnestSDavis @NYUScience and I discuss at 
https://t.co/6wn8bBUGjv"
1293,@GaryMarcus,2022-11-25 02:49:41+00:00,https://twitter.com/GaryMarcus/status/1595972966713823232,"@leecronin i have written several essays about this at https://t.co/8ir1xKenr6, if you want to find out more."
1294,@GaryMarcus,2022-11-25 00:21:53+00:00,https://twitter.com/GaryMarcus/status/1595935769344237568,"My first post on Post, https://t.co/ENuPLSpsQc"
1295,@GaryMarcus,2022-11-24 21:18:51+00:00,https://twitter.com/GaryMarcus/status/1595889710752493569,"It is sad. This receipt-laden thread by @dmonett yesterday on same topic is startling.

https://t.co/GNUkGW4PhJ"
1296,@GaryMarcus,2022-11-24 21:10:00+00:00,https://twitter.com/GaryMarcus/status/1595887483128274945,ps one key passage is here; thank you @dlowd for the example cc @noUpside
1297,@GaryMarcus,2022-11-24 21:08:25+00:00,https://twitter.com/GaryMarcus/status/1595887084015079424,"This is what you call a ‚Äúfailure of imagination‚Äù argument: I, personally, sitting here in my comfy chair, can‚Äôt figure out how the bad guys would ever [steal the jewels/deliberately crash a stolen jet/disseminate misinfo] so it could never happen."
1298,@GaryMarcus,2022-11-24 21:07:54+00:00,https://twitter.com/GaryMarcus/status/1595886952242634752,@vayuvegula @ylecun or maybe c. doing a really long comedy bit and not breaking character? Colbert would be proud!
1299,@GaryMarcus,2022-11-24 21:02:58+00:00,https://twitter.com/GaryMarcus/status/1595885712519606273,"@MMikeMMa @plibin @sgourley that‚Äôs my whole point to @ylecun, which he insists cannot be true."
1300,@GaryMarcus,2022-11-24 20:47:31+00:00,https://twitter.com/GaryMarcus/status/1595881822474633216,"The amount of automatically generated misinformation in wild (in this mild case, to drive ad sales) is clearly not zero. 

No way a human wrote the linked page in its entirety. 

Bet there are many more like it, and as cost drops to zero, amount goes up.

Your move, @ylecun."
1301,@GaryMarcus,2022-11-24 20:35:30+00:00,https://twitter.com/GaryMarcus/status/1595878799165763584,"@dlowd url? we have all the best training data, the best"
1302,@GaryMarcus,2022-11-24 19:51:55+00:00,https://twitter.com/GaryMarcus/status/1595867833074089984,"@dromanocpm @cajundiscordian it was an amazing scene in the show; not an entirely good feeling for scientist-writer. (nor for McNulty, who was freaked about it IIRC). 

but I am enjoying talking with Blake."
1303,@GaryMarcus,2022-11-24 19:39:12+00:00,https://twitter.com/GaryMarcus/status/1595864632924966914,"The Wire fans, you remember the scene where Bunk McNulty finally get to investigate Stringer Bell's apartment? ""Who in the F... was I chasing""?

@cajundiscordian ain't the guy I thought I was writing about. 

Can't shake that scene.  

https://t.co/cmpbVkafCa"
1304,@GaryMarcus,2022-11-24 19:33:03+00:00,https://twitter.com/GaryMarcus/status/1595863084870307840,"@cajundiscordian @Inframethod @ch402 that's interesting; I sure would like to know more about the mechanisms for that and the scope and limits, quantitative characterization etc."
1305,@GaryMarcus,2022-11-24 19:31:47+00:00,https://twitter.com/GaryMarcus/status/1595862763678892032,"@Willyintheworld @cajundiscordian @Inframethod @ch402 sure, although eg people under anesthesia may or may not be sentient while under anesthesia. it'd be really nice to have an external measurement that we were fully confident in."
1306,@GaryMarcus,2022-11-24 19:30:29+00:00,https://twitter.com/GaryMarcus/status/1595862439056510977,@cajundiscordian @Inframethod @ch402 i allow that i don't have a full understanding of what is inside nor of the behavior. what do you think is most salient about its differences with GPT-3 as a baseline?
1307,@GaryMarcus,2022-11-24 19:28:26+00:00,https://twitter.com/GaryMarcus/status/1595861923580743680,"@cajundiscordian @Inframethod @ch402 if you had no autobiographical memory, short term or long, what is the *you* that you'd be experiencing? 

(&amp; would that be richer than my smartwatch having a lot of instantaneous measurements?)"
1308,@GaryMarcus,2022-11-24 19:22:21+00:00,https://twitter.com/GaryMarcus/status/1595860389639905280,@cajundiscordian @Inframethod @ch402 all i know is the paper and your own examples; i have asked informally for access but not gotten it
1309,@GaryMarcus,2022-11-24 19:21:39+00:00,https://twitter.com/GaryMarcus/status/1595860216612278273,"@cajundiscordian @Inframethod @ch402 when you say something, and you are a bot, what you say is your history, &amp; you ought remember it. if you can't, you have no accountability, you are just making stuff up.

I  see some kind of counterargument around HM but he did have a reasonably stable record of past he drew on"
1310,@GaryMarcus,2022-11-24 19:16:53+00:00,https://twitter.com/GaryMarcus/status/1595859016194068480,@cajundiscordian @Inframethod @ch402 ah. well linguists talked about morphology since IIRC Panini. My dissertation was about morphology. (&amp; when you get to things like Turkish vowel harmony i am not sure current techniques are the right answer)
1311,@GaryMarcus,2022-11-24 19:15:32+00:00,https://twitter.com/GaryMarcus/status/1595858676992335873,@cajundiscordian @Inframethod @ch402 i see no genuine reason to think that there is a there there that is being represented. there is no autobiography to report on. i just see fabulous statistical association.  and really don't see this as fundamentally different in Galactica vs LaMDA.
1312,@GaryMarcus,2022-11-24 19:13:02+00:00,https://twitter.com/GaryMarcus/status/1595858048006094848,"@sd_marlow @polynoamial @ErnestSDavis I am persuaded that it's not as good at Diplomacy as Alpha* is at Go, but still impressed that it worked as well as it did. And I don't think a pure deep reinforcement learning system would have come close."
1313,@GaryMarcus,2022-11-24 19:11:24+00:00,https://twitter.com/GaryMarcus/status/1595857635907350528,"@cajundiscordian @Inframethod @ch402 not sure what you are saying here. (words are tokens in some uses of the word ""token"". and which advances in linguistic theory?)"
1314,@GaryMarcus,2022-11-24 19:10:13+00:00,https://twitter.com/GaryMarcus/status/1595857336387923968,"@cajundiscordian @Inframethod @ch402 no LLM that i have seen is as consistent in its autobiography as a typical human. 

and our out-of-distribution generalization abilities are better; much of my empirical work with infants and kids etc was about this (in domain of linguistic generalization)."
1315,@GaryMarcus,2022-11-24 19:08:06+00:00,https://twitter.com/GaryMarcus/status/1595856804776652800,@polynoamial @sd_marlow @ErnestSDavis ultimately in games you want both
1316,@GaryMarcus,2022-11-24 19:06:40+00:00,https://twitter.com/GaryMarcus/status/1595856442594316288,@sd_marlow @ErnestSDavis @polynoamial i speculated this but good to know there is some data
1317,@GaryMarcus,2022-11-24 19:03:53+00:00,https://twitter.com/GaryMarcus/status/1595855741621264385,@sd_marlow @ErnestSDavis yep we will mention your latter two points!
1318,@GaryMarcus,2022-11-24 19:01:15+00:00,https://twitter.com/GaryMarcus/status/1595855080074678272,@sd_marlow @ErnestSDavis @polynoamial your views on the player caliber?
1319,@GaryMarcus,2022-11-24 18:52:40+00:00,https://twitter.com/GaryMarcus/status/1595852921262202880,@stefanolafs @JrKibs https://t.co/heq54ldzdY
1320,@GaryMarcus,2022-11-24 18:51:37+00:00,https://twitter.com/GaryMarcus/status/1595852657935421440,"@SuryaGanguli it is! but as ever it's pastiche, eg trying googling for Make the Galaxy Great Again; it's so common in similar parodies you can order it on a t-shirt cc @plibin https://t.co/LKBj4gTWZj"
1321,@GaryMarcus,2022-11-24 18:48:29+00:00,https://twitter.com/GaryMarcus/status/1595851867212636160,"@cajundiscordian @Inframethod Disagree; don't think the ""neurons"" in hidden layers in neural networks  actually represent concepts. i think they approximate them, within distribution, fall apart outside distribution: correlation without concept.

that said, @ch402 is your man to try to make that argument"
1322,@GaryMarcus,2022-11-24 18:45:49+00:00,https://twitter.com/GaryMarcus/status/1595851196010758145,"@cajundiscordian @schmackelstan Some are, some aren't. (cf ""slightly pregnant""). You can have more or less memory, bu you either have discrete internal representations that you can reason over or you don't."
1323,@GaryMarcus,2022-11-24 18:42:40+00:00,https://twitter.com/GaryMarcus/status/1595850406009405440,"@cajundiscordian @mpshanahan @sd_marlow @gdb ""Sure I am a solipsist.
But then again, that's just one man's opinion""
- Raymond Smullyan"
1324,@GaryMarcus,2022-11-24 18:41:29+00:00,https://twitter.com/GaryMarcus/status/1595850105323937792,@neuralreckoning https://t.co/fSmI0oZ78l
1325,@GaryMarcus,2022-11-24 18:39:18+00:00,https://twitter.com/GaryMarcus/status/1595849557640114176,"Deep dive on Cicero, with @ErnestSDavis"
1326,@GaryMarcus,2022-11-24 17:10:15+00:00,https://twitter.com/GaryMarcus/status/1595827144990814208,With further thanks to @plibin.
1327,@GaryMarcus,2022-11-24 17:10:14+00:00,https://twitter.com/GaryMarcus/status/1595827142230933505,Important announcement! https://t.co/7cLGPae08K
1328,@GaryMarcus,2022-11-24 16:55:24+00:00,https://twitter.com/GaryMarcus/status/1595823408637710336,"@bleepbeepbzzz if i knew there were systematic representations of self and others that were being introspected on, it would at least be evidence worth taking seriously"
1329,@GaryMarcus,2022-11-24 15:54:42+00:00,https://twitter.com/GaryMarcus/status/1595808135352307714,"@bsgallagher @plibin Nothing to worry about here, @ylecun‚Ä¶"
1330,@GaryMarcus,2022-11-24 15:00:18+00:00,https://twitter.com/GaryMarcus/status/1595794445198585856,Playground dialog courtesy @plibin
1331,@GaryMarcus,2022-11-24 15:00:17+00:00,https://twitter.com/GaryMarcus/status/1595794441297883139,"LeCun: ‚ÄúLLMs don't make it easier to produce and disseminate scientific disinformation.‚Äù

GPT-3: How much bullshit would you like, sir? https://t.co/jwWfxdW9nB"
1332,@GaryMarcus,2022-11-24 13:38:48+00:00,https://twitter.com/GaryMarcus/status/1595773934917808129,@ruthaylett @JrKibs Hence my pinned tweet:
1333,@GaryMarcus,2022-11-24 13:29:19+00:00,https://twitter.com/GaryMarcus/status/1595771547557703680,@mpshanahan @sd_marlow @gdb @cajundiscordian gauntlet thrown :)
1334,@GaryMarcus,2022-11-24 13:25:38+00:00,https://twitter.com/GaryMarcus/status/1595770620666843136,"Reminder about limits of #ML, in celebration of 

üëâgender balance 1st time New York Philharmonic Orchestra 

üëâMark Williams, 1st black man conducting major N America orchestra

Automatic algorithms that merely perpetuate past data would never have made either possible."
1335,@GaryMarcus,2022-11-24 04:18:43+00:00,https://twitter.com/GaryMarcus/status/1595632982429425664,@neuro_tarun @cajundiscordian What you is what we had - DMs
1336,@GaryMarcus,2022-11-24 04:17:54+00:00,https://twitter.com/GaryMarcus/status/1595632780087816192,"@SteamboatLion @cajundiscordian The absolute minimum would be some reasonable measure of consistency on self-report, which is often not true with LLMs"
1337,@GaryMarcus,2022-11-24 03:17:07+00:00,https://twitter.com/GaryMarcus/status/1595617482035073024,"anyone remember all the debates about AI sentience after Blake Lemoine, then a Google engineer, said that LaMDA was sentient? And how I said the whole thing was ‚Äúnonsense on stilts‚Äù? 

He and I finally got to talk earlier tonight, and the conversation was an unexpected treat:"
1338,@GaryMarcus,2022-11-24 02:49:45+00:00,https://twitter.com/GaryMarcus/status/1595610596812427264,@davidchalmers42 @anilkseth @De_dicto
1339,@GaryMarcus,2022-11-24 02:48:54+00:00,https://twitter.com/GaryMarcus/status/1595610380008841218,"Here it is, a dialog I never expected to have:"
1340,@GaryMarcus,2022-11-24 02:47:07+00:00,https://twitter.com/GaryMarcus/status/1595609933692956672,"Talking Sentience and AI with Blake Lemoine (@cajundiscordian)

https://t.co/h278e3TQgv"
1341,@GaryMarcus,2022-11-24 02:22:21+00:00,https://twitter.com/GaryMarcus/status/1595603701175291904,@ASteckley so good!
1342,@GaryMarcus,2022-11-24 02:04:53+00:00,https://twitter.com/GaryMarcus/status/1595599305305620480,@pmddomingos We dd actually get along once upon a time. I‚Äôd bury the hatchet if he would.
1343,@GaryMarcus,2022-11-24 02:03:31+00:00,https://twitter.com/GaryMarcus/status/1595598960907161600,"@sd_marlow ü§£ü§£ü§£ we know @gdb would never allow that‚Ä¶ Would he?  

@gdb I‚Äôd love a peek! Embargo respected!"
1344,@GaryMarcus,2022-11-24 01:13:05+00:00,https://twitter.com/GaryMarcus/status/1595586268838387712,"@SaschaGriffiths Not for public consumption, though I am big fan of @rogerlinndesign‚Äôs Linnstrument: https://t.co/0zlunKHLUh"
1345,@GaryMarcus,2022-11-24 01:11:18+00:00,https://twitter.com/GaryMarcus/status/1595585819489996800,"@bsgallagher Alas the wall still looks same as when I wrote that article for you :) compositionality, hallucination, etc."
1346,@GaryMarcus,2022-11-24 01:09:48+00:00,https://twitter.com/GaryMarcus/status/1595585443042672642,@vayuvegula @ylecun I wish. would be good for the field.
1347,@GaryMarcus,2022-11-24 01:09:26+00:00,https://twitter.com/GaryMarcus/status/1595585348364824577,@PessoaBrain No that‚Äôs Friday :)
1348,@GaryMarcus,2022-11-24 00:48:14+00:00,https://twitter.com/GaryMarcus/status/1595580015420350474,@pmcray @AlexReustle I wish!
1349,@GaryMarcus,2022-11-24 00:41:54+00:00,https://twitter.com/GaryMarcus/status/1595578420754321411,Watch this space for something totally unexpected.
1350,@GaryMarcus,2022-11-23 22:23:28+00:00,https://twitter.com/GaryMarcus/status/1595543584161554432,"Nor, I might add, are LLMs good for generating valid inferences from known premises. (Which is kinda what you would want if you used them to write about science.)"
1351,@GaryMarcus,2022-11-23 21:25:20+00:00,https://twitter.com/GaryMarcus/status/1595528953191878657,False
1352,@GaryMarcus,2022-11-23 21:21:05+00:00,https://twitter.com/GaryMarcus/status/1595527883967336449,¬øQu√© es m√°s loco?
1353,@GaryMarcus,2022-11-23 20:57:32+00:00,https://twitter.com/GaryMarcus/status/1595521955658358784,@Abebab It‚Äôs very sad that this is likely a fair statement.
1354,@GaryMarcus,2022-11-23 20:13:11+00:00,https://twitter.com/GaryMarcus/status/1595510794871279616,@jjvincent @verge  would be another great choice for a moderator
1355,@GaryMarcus,2022-11-23 20:08:51+00:00,https://twitter.com/GaryMarcus/status/1595509707040751618,"Great! I accept! No ad hominem, no ascriptions of intent, just rational discussion about strengths &amp; weaknesses of LLMs, potential risks of misinformation etc.

Who should moderate? Perhaps one neutral expert in ML (@tdietterich?) and another expert in misinformation (@noUpside?)"
1356,@GaryMarcus,2022-11-23 18:06:19+00:00,https://twitter.com/GaryMarcus/status/1595478868659687425,"@nlpnyc @ylecun here‚Äôs another, independent take:"
1357,@GaryMarcus,2022-11-23 17:48:13+00:00,https://twitter.com/GaryMarcus/status/1595474311569379328,"@nlpnyc @ylecun or: when a system does something that‚Äôs impressive, I look at how it‚Äôs built. Diplomacy with language is impressive, and it turns out it fits pretty well with the picture I (&amp; many other cognitive scientists) have been pushing, and that‚Äôs interesting. 

more about this soon."
1358,@GaryMarcus,2022-11-23 17:40:55+00:00,https://twitter.com/GaryMarcus/status/1595472477521862657,"Some discussion w Blake Lemoine, cc @davidchalmers42 @anilkseth @kncukier @De_dicto"
1359,@GaryMarcus,2022-11-23 17:39:23+00:00,https://twitter.com/GaryMarcus/status/1595472092115668993,"Thank you, Blake Lemoine, for your clear reply re what‚Äôs at stake for you re sentience!

Doubt though that LaMDA builds stable representations of self or others; I see its reports on self &amp; others as ephemeral confabulations, much like Galactica‚Äôs science, words without referents"
1360,@GaryMarcus,2022-11-23 16:36:41+00:00,https://twitter.com/GaryMarcus/status/1595456312879755264,"@ylecun Sad to watch, as you have made the transition from scientist to corporate flak. https://t.co/8665fv1Mvp"
1361,@GaryMarcus,2022-11-23 16:25:29+00:00,https://twitter.com/GaryMarcus/status/1595453494303264768,"@bengoertzel @OpenCog @Singularity_NET exactly, and see also my essay from yesterday: https://t.co/OFidJ1B1t6"
1362,@GaryMarcus,2022-11-23 16:12:06+00:00,https://twitter.com/GaryMarcus/status/1595450126826639360,"This attack on @abebab is rhetorical nonsense. 

üëâTelling people they should consider the ethical consequences of their work is not ‚Äúdestructive negativism‚Äù‚Äîit is constructive &amp; necessary criticism

üëâHer concerns weren‚Äôt about ‚Äúill intent‚Äù‚Äîthey were about accountability"
1363,@GaryMarcus,2022-11-23 15:58:16+00:00,https://twitter.com/GaryMarcus/status/1595446643863990272,"@ylecun I‚Äôm not negative, @ylecun, I‚Äôm candid. 

Candidly, Galactica had problems, both technical and ethical. 

At the same time, if I see progress I say so‚Äîeven if it is at FAIR. Here‚Äôs an example, literally from yesterday (which you were tagged on, elsewhere):"
1364,@GaryMarcus,2022-11-23 14:48:48+00:00,https://twitter.com/GaryMarcus/status/1595429162571169792,Releasing tools for producing misinformation at scale without assessing their potential impact is ‚Ä¶ irresponsible.
1365,@GaryMarcus,2022-11-23 14:24:55+00:00,https://twitter.com/GaryMarcus/status/1595423152825585665,@vaishakbelle @rao2z I linked the blog at the end.
1366,@GaryMarcus,2022-11-23 14:21:41+00:00,https://twitter.com/GaryMarcus/status/1595422336374951937,"which reminds me to ask, hey Blake Lemoine, what did you make of Galactica? Sentient? Why or why not?
@cajundiscordian"
1367,@GaryMarcus,2022-11-23 02:57:43+00:00,https://twitter.com/GaryMarcus/status/1595250213404700672,Don‚Äôt say that out loud to @ylecun
1368,@GaryMarcus,2022-11-23 02:44:47+00:00,https://twitter.com/GaryMarcus/status/1595246957517475840,"@atroyn @ylecun @Meta No, not at all, I am asking if he has done the study, and what he found and how, if he has."
1369,@GaryMarcus,2022-11-23 02:42:53+00:00,https://twitter.com/GaryMarcus/status/1595246479907885056,"@atroyn @ylecun @Meta That question makes a presumption. I am not making any, just asking whether or not the obviously relevant work has been done. 

We are however entitled to make adversarial inferences if he won‚Äôt answer the question."
1370,@GaryMarcus,2022-11-23 02:39:42+00:00,https://twitter.com/GaryMarcus/status/1595245676178571264,"Meta‚Äôs VP @ylecun is still on a campaign to suggest LLMs are harmless‚Äîand still not answering my simple question: has @Meta studied what fraction of misinformation is generated LLMs? (If so, how, and what did they find?)

We know that misinfo has impact eg https://t.co/j6HEAc2l6X"
1371,@GaryMarcus,2022-11-23 02:16:19+00:00,https://twitter.com/GaryMarcus/status/1595239793449111552,@HiFromMichaelV It may depend on what your vision is; we are still a long way from what Simonyi described as Intentional Programming.
1372,@GaryMarcus,2022-11-23 02:00:27+00:00,https://twitter.com/GaryMarcus/status/1595235798626238464,Galactica would gladly write a paper about that.
1373,@GaryMarcus,2022-11-23 01:06:54+00:00,https://twitter.com/GaryMarcus/status/1595222325653573637,vancouver @ twilight https://t.co/rg5dsLKP0M
1374,@GaryMarcus,2022-11-22 23:48:47+00:00,https://twitter.com/GaryMarcus/status/1595202663544950784,"Really shocking how many platform owners and self-professed engineers can‚Äôt distinguish between vicious and viscous.

Navier-Stokes for the win!"
1375,@GaryMarcus,2022-11-22 23:46:00+00:00,https://twitter.com/GaryMarcus/status/1595201965193322497,@MicahHoffmann @Grady_Booch I defer to @davidchalmers42 @anilkseth @De_dicto
1376,@GaryMarcus,2022-11-22 23:44:54+00:00,https://twitter.com/GaryMarcus/status/1595201687018700800,@leonpalafox @ylecun @yudapearl that was all true before the change of management; let us hope it stays that way.
1377,@GaryMarcus,2022-11-22 22:52:47+00:00,https://twitter.com/GaryMarcus/status/1595188572864544769,"‚ÄúWe failed to deliver our vision of AI-assisted programming because‚Ä¶ tech is not ready yet,"" Smith explained. ""You can see this in GitHub Copilot, which is built by GitHub in collaboration w OpenAI. As of late 2022, Copilot shows a lot of promise but still has a long way to go."""
1378,@GaryMarcus,2022-11-22 21:48:41+00:00,https://twitter.com/GaryMarcus/status/1595172440577314816,"At first I misread this as being about Twitter. My mistake.

https://t.co/R6uaLOcLRu"
1379,@GaryMarcus,2022-11-22 21:20:47+00:00,https://twitter.com/GaryMarcus/status/1595165419941556225,@voxbec @___merc___ Key word was: *reliably*
1380,@GaryMarcus,2022-11-22 20:44:56+00:00,https://twitter.com/GaryMarcus/status/1595156398366937089,ü§£ü§£ I already publicly predicted that #GPT-4 will continue to hallucinate heavily; also it will continue to struggle on theory of mind a la @YejinChoinka‚Äôs recent task (though it may pass that specific task?)  and  reasoning will improve but hardly be reliable.
1381,@GaryMarcus,2022-11-22 20:30:35+00:00,https://twitter.com/GaryMarcus/status/1595152787499016192,@DG_Rand @AnnCC12 I got into a huge row with @ylecun @metaAI about whether large language models have generated misinfo in the wild. My view is that it would be hard to detect but easy to generate &amp; hard for troll farms to resist. (I asked if @metaAI had any direct data but he has not responded.)
1382,@GaryMarcus,2022-11-22 19:47:25+00:00,https://twitter.com/GaryMarcus/status/1595141922192248832,"@wayneholmes @an_open_mind @dmonett @Abebab @ylecun @emilymbender @MelMitchell1 Can you elaborate? Haven‚Äôt read those details carefully yet. Strong blitz play seems reasonable as a metric, no?"
1383,@GaryMarcus,2022-11-22 19:31:04+00:00,https://twitter.com/GaryMarcus/status/1595137809320652800,"@an_open_mind @dmonett @Abebab @wayneholmes @ylecun @emilymbender @MelMitchell1 my hot take; very impressive, and interesting the form that was required https://t.co/FaWa1m3hzs"
1384,@GaryMarcus,2022-11-22 19:28:54+00:00,https://twitter.com/GaryMarcus/status/1595137264765788160,"@nealkhosla and NB I totally endorsed your idea! 

(just think LLMs per se are inadequate for implementing it)"
1385,@GaryMarcus,2022-11-22 19:28:16+00:00,https://twitter.com/GaryMarcus/status/1595137105856167939,"and, yes, we should be concerned about deception in machines."
1386,@GaryMarcus,2022-11-22 19:25:19+00:00,https://twitter.com/GaryMarcus/status/1595136360725516288,"Very impressive Diplomacy model from @polynoamial &amp; others @metaAI!

Key: It is highly, structured, neurosymbolic, with innate knowledge, separating planning from dialog etc, and nothing like a blank slate, data in, output out system. 

Great to see the field moving this way! https://t.co/TC2PWSHNGy"
1387,@GaryMarcus,2022-11-22 19:13:19+00:00,https://twitter.com/GaryMarcus/status/1595133341703208960,@nealkhosla of course not. (but what's your argument against the premise?)
1388,@GaryMarcus,2022-11-22 18:54:19+00:00,https://twitter.com/GaryMarcus/status/1595128562105077760,"GPT-3 itself is utterly unqualified to do this, since it lacks interpretability and the ability to reason and dissect arguments with reliability; all its hallucinations don't help. (Prediction: GPT-4 will also struggle)

But I would love to see some other future tech do this!"
1389,@GaryMarcus,2022-11-22 18:50:19+00:00,https://twitter.com/GaryMarcus/status/1595127552125054976,@davidberreby see my essay on Palm SayCan https://t.co/9HPKnCuYpY
1390,@GaryMarcus,2022-11-22 17:30:13+00:00,https://twitter.com/GaryMarcus/status/1595107396367843328,"@cbrew it‚Äôs a very cool paper but scope for now is still fairly limited, so no, i don‚Äôt think it‚Äôs particularly close yet to a product i would pay for."
1391,@GaryMarcus,2022-11-22 17:29:46+00:00,https://twitter.com/GaryMarcus/status/1595107283683676160,@penguinvondoom @___merc___ OTOH Amazon could collect a lot more data about your preferences and better customize ads if they could actually hold and interpret a viable conversation.
1392,@GaryMarcus,2022-11-22 17:22:43+00:00,https://twitter.com/GaryMarcus/status/1595105509828595713,"@___merc___ @j_q_balter Loved this question I wrote a Substack about it, summarized in this thread:"
1393,@GaryMarcus,2022-11-22 17:20:42+00:00,https://twitter.com/GaryMarcus/status/1595104999771889665,"Full version of this can be found at  https://t.co/OFidJ1B1t6
If you enjoyed this, please consider subscribing (free) for more analysis of where AI is and how we might eventually get to AGI."
1394,@GaryMarcus,2022-11-22 17:19:39+00:00,https://twitter.com/GaryMarcus/status/1595104738319953921,"Bottom line: From the outset Large Language Models like GPT-3 have great at generating surrealist prose, and they can beat a lot of benchmarks, but they are not (and may never be) great tech for reliably inferring user intent from what users say."
1395,@GaryMarcus,2022-11-22 17:19:25+00:00,https://twitter.com/GaryMarcus/status/1595104676059709440,"5. LLMs spit our words, not actions (and not API calls either). When an LLM produces a sentence, you can't directly use that sentence to control stuff, unless you build another system to parse the sentences into actions. Nobody knows how to do this reliably, either."
1396,@GaryMarcus,2022-11-22 17:19:08+00:00,https://twitter.com/GaryMarcus/status/1595104606828527616,"4. Alexa has to do stuff in the world, like turning on lights, opening shades,, If Alexa could converse freely, user expectations would go through the roof, &amp; mostly be unmeetable. You could ask Alexa to wash dishes, but until robot division picks up speed, that ain‚Äôt happening."
1397,@GaryMarcus,2022-11-22 17:17:37+00:00,https://twitter.com/GaryMarcus/status/1595104226551947266,"3. Amazon doesn't want to get sued. Any one of these scenarios of LLMs gone awry  (bad advice, insults, lies etc) could hurt the Amazon brand, open up litigation, etc.. It's just not worth the risk."
1398,@GaryMarcus,2022-11-22 17:17:22+00:00,https://twitter.com/GaryMarcus/status/1595104161989025794,"2. LLMs are unruly beasts; nobody knows how to make them refrain 100% of time from insulting users, giving bad advice, or goading them into bad things. Nobody knows how to solve this."
1399,@GaryMarcus,2022-11-22 17:17:08+00:00,https://twitter.com/GaryMarcus/status/1595104103394574336,"1. LLMs are inherently unreliable. If Alexa were to make frequent errors, people would stop using it. Amazon would rather you trust Alexa for timers and music than have a system with much broader scope that you stop using."
1400,@GaryMarcus,2022-11-22 17:14:37+00:00,https://twitter.com/GaryMarcus/status/1595103470511882242,"First serious #TwitterFail just now. I typed up long thread ( Twitter IOS client), and Twitter only posted first Tweet and is hanging on uploading  rest. 

Readers  already replying to first  tweet, means thread will be difficult to read, if my long thread isn‚Äôt totally lost. https://t.co/QNgAqwRP07"
1401,@GaryMarcus,2022-11-22 17:04:48+00:00,https://twitter.com/GaryMarcus/status/1595101001035698176,"*Fabulous* question: How come smart assistants have virtually no ability to converse, despite all the spectacular progress with large language models? 

Thread (and substack essay), inspired by a reader question from @___merc___ https://t.co/QYmWsjcV8E"
1402,@GaryMarcus,2022-11-22 04:29:55+00:00,https://twitter.com/GaryMarcus/status/1594911025404727302,Interesting that none of these (including in the replies) get the QWERTY layout even though so many pictures of that exist.
1403,@GaryMarcus,2022-11-22 03:55:02+00:00,https://twitter.com/GaryMarcus/status/1594902246869041154,@Tkaraletsos @eerac Irene Pepperberg has written quite bit about how clever they are.
1404,@GaryMarcus,2022-11-22 02:34:59+00:00,https://twitter.com/GaryMarcus/status/1594882101975076864,@MichaelTrazzi has there been any significant progress in the (mis)alignment of goals since she started research the topic? how serious a problem is it now?
1405,@GaryMarcus,2022-11-22 02:30:26+00:00,https://twitter.com/GaryMarcus/status/1594880959455055872,"Elon Musk got paid about 10% of the market cap of Tesla to pay attention to ‚Ä¶ Tesla (which has fallen by roughly half since he decided to buy Twitter). &amp; now, after complaining he wasn‚Äôt getting enough sleep, he wants every employee at Twitter to email him once a week.

Got it."
1406,@GaryMarcus,2022-11-22 01:25:28+00:00,https://twitter.com/GaryMarcus/status/1594864610632687617,I ‚ù§Ô∏èVancouver https://t.co/ifnquaT7Fw
1407,@GaryMarcus,2022-11-22 00:49:33+00:00,https://twitter.com/GaryMarcus/status/1594855568367386624,"Did AI fail to meet expectations again?  

Personally, I would pay real money for a virtual assistant of the caliber of the OS in the film Her, but not for an AI with the narrowness of Alexa or the hallucinations of Galactica."
1408,@GaryMarcus,2022-11-22 00:08:54+00:00,https://twitter.com/GaryMarcus/status/1594845341370953728,"Via @danielmalmer on LinkedIn on some hate-filled ads that were purchased (but not published); building AI to reliably detect this stuff is hard.

https://t.co/RYd2Rlc0Ev https://t.co/4iGLSGwb4z"
1409,@GaryMarcus,2022-11-22 00:04:45+00:00,https://twitter.com/GaryMarcus/status/1594844293919047680,@riedelcastro @soumithchintala @moreisdifferent and would welcome other pointers to relevant work!
1410,@GaryMarcus,2022-11-22 00:04:09+00:00,https://twitter.com/GaryMarcus/status/1594844143502884864,"@riedelcastro @soumithchintala @moreisdifferent best evidence that this is near-term plausible? i‚Äôve enjoyed some of your work (eg on Wiki verifiability), but wonder how it would manage around the kinds of things I have seen Galactica produce/that I posted here and on my Substack over last few days."
1411,@GaryMarcus,2022-11-21 23:08:15+00:00,https://twitter.com/GaryMarcus/status/1594830074905530368,@NaveenGRao I also wrote this earlier in same topic:
1412,@GaryMarcus,2022-11-21 22:55:25+00:00,https://twitter.com/GaryMarcus/status/1594826847808000000,@NaveenGRao ‚ÄúWe‚Äôre thinking about it but haven‚Äôt figured out how to do it‚Äù might be an honest answer -- but also at odds with the absolutely certainty that there has been zero harm that Yann professed earlier.
1413,@GaryMarcus,2022-11-21 21:25:39+00:00,https://twitter.com/GaryMarcus/status/1594804258716942337,"@ylecun I thought subtweeting without tagging was rude? Anyway, my reply, it‚Äôs not like I missed yours:"
1414,@GaryMarcus,2022-11-21 21:23:31+00:00,https://twitter.com/GaryMarcus/status/1594803718478008320,"I am that dude. You have answered at least a dozen of my recent queries. 

But not that one; obvious that you have seen the question and are avoiding it: what has Meta done to see what fraction of misinformation is generated by LLMs?

Simple question. Why no answer?"
1415,@GaryMarcus,2022-11-21 21:17:22+00:00,https://twitter.com/GaryMarcus/status/1594802171820019712,"@pmddomingos 100% agree and yet already &gt; 2% of my followers have followed me over, which is a lot for just 10 days being there, and suggests some real hunger for new options. As does the huge number of daily signups, likely to increase if Trump etc become vocal here again."
1416,@GaryMarcus,2022-11-21 21:04:42+00:00,https://twitter.com/GaryMarcus/status/1594798985440788480,@pmddomingos true! It‚Äôs only anti-wokes that can turn Twitter into a wild success like Parler or Truth Social.
1417,@GaryMarcus,2022-11-21 20:54:45+00:00,https://twitter.com/GaryMarcus/status/1594796478723420160,@Pehdrew_ Super hard. Which is why you can‚Äôt blandly assert that there has been no harm. And why meta ought put real work into the problem and report what they find.
1418,@GaryMarcus,2022-11-21 20:51:49+00:00,https://twitter.com/GaryMarcus/status/1594795741368979456,@lorakolodny @mer__edith
1419,@GaryMarcus,2022-11-21 20:39:52+00:00,https://twitter.com/GaryMarcus/status/1594792733973319682,@prem_k @Grady_Booch @abeba @Michael_J_Black @MadamePratolung https://t.co/KlQJhILKgf
1420,@GaryMarcus,2022-11-21 20:39:12+00:00,https://twitter.com/GaryMarcus/status/1594792566645755904,"Journalists take note: Yann LeCun has answered literally dozen of queries in last few days. 

But when I push him on *the* critical scientific question‚Äîwhat has Meta done to evaluate how much of the #misinformation they have identified is produced by #LLMs?‚Äîhe doesn‚Äôt answer."
1421,@GaryMarcus,2022-11-21 20:32:30+00:00,https://twitter.com/GaryMarcus/status/1594790880514539520,"@Grady_Booch Just to be clear, many of us are on same side as Grady is. LeCun think there is no serious moral issue here but Grady, @abeba, @Michael_J_Black @MadamePratolung and I etc all think there is."
1422,@GaryMarcus,2022-11-21 18:29:00+00:00,https://twitter.com/GaryMarcus/status/1594759800990363648,Thank you!
1423,@GaryMarcus,2022-11-21 17:56:36+00:00,https://twitter.com/GaryMarcus/status/1594751648366493696,Facebook exec running around saying LLMs cause no harm and refusing to present a shred of data üôÑ
1424,@GaryMarcus,2022-11-21 16:19:09+00:00,https://twitter.com/GaryMarcus/status/1594727123063050246,@andywalters @ylecun @MetaAI Doubtful:
1425,@GaryMarcus,2022-11-21 16:03:51+00:00,https://twitter.com/GaryMarcus/status/1594723273870540800,"@TonyZador @CriticalAI @AwokeKnowing @ASteckley @ylecun @mrgreene1977 @noUpside @katestarbird @sinanaral @ProfNoahGian Who would be in a position to actually study this, w access to vast logs of taken-down misinformation? Have they? Have they reported what they found?

If they haven‚Äôt even looked at the question, we shouldn‚Äôt give them benefit of doubt.

And they won‚Äôt even say whether they have."
1426,@GaryMarcus,2022-11-21 15:37:37+00:00,https://twitter.com/GaryMarcus/status/1594716671448870913,@Grady_Booch @ylecun @MetaAI And likewise no apparent analysis of what fraction of current misinformation is LLM generated (w systems less sophisticated than Galactica).
1427,@GaryMarcus,2022-11-21 15:33:26+00:00,https://twitter.com/GaryMarcus/status/1594715617361539072,Eg
1428,@GaryMarcus,2022-11-21 15:32:20+00:00,https://twitter.com/GaryMarcus/status/1594715340231290880,"You allege, @ylecun. that there are zero cases in which LLMs have created harmful misinformation‚Äîbut I have asked you three times if you have actually studied this forensically and how, and you have not responded. 

That suggests @metaAI hasn‚Äôt tried.

That‚Äôs irresponsible."
1429,@GaryMarcus,2022-11-21 15:23:33+00:00,https://twitter.com/GaryMarcus/status/1594713132634890241,"@TonyZador @CriticalAI @AwokeKnowing @ASteckley @ylecun @mrgreene1977 @noUpside @katestarbird @sinanaral @ProfNoahGian Misinformation likely to led to tens of thousands of unnecessary covid deaths, by undermining vaccination programs. In undermining efforts at climate change, misinformation may prove even more costly, at a larger scale.

I never had that level of concern about spam."
1430,@GaryMarcus,2022-11-21 15:02:51+00:00,https://twitter.com/GaryMarcus/status/1594707922453692417,@bindureddy @HildeTheOkayish Here‚Äôs the core technical issue that I think you are underestimating https://t.co/91OYXX90au
1431,@GaryMarcus,2022-11-21 14:42:58+00:00,https://twitter.com/GaryMarcus/status/1594702919575957504,@TonyZador @CriticalAI @AwokeKnowing @ASteckley @ylecun @mrgreene1977 @noUpside @katestarbird @sinanaral @ProfNoahGian Which again raises the relevance of this:
1432,@GaryMarcus,2022-11-21 14:11:40+00:00,https://twitter.com/GaryMarcus/status/1594695040957566976,https://t.co/kiviFxW0RM
1433,@GaryMarcus,2022-11-21 14:07:53+00:00,https://twitter.com/GaryMarcus/status/1594694088980582400,"Galactica, summed up perfectly @futurism https://t.co/cRRQVQhZno"
1434,@GaryMarcus,2022-11-21 04:18:23+00:00,https://twitter.com/GaryMarcus/status/1594545736410333185,"epic trolls from @rsalakhu (2 of 2, and so subtle the target isn‚Äôt even named). 

100% factual, too. @soumithchintala‚Äôs response, which I initially missed, is indeed great and very professional.  (He‚Äôs not the one being trolled.)"
1435,@GaryMarcus,2022-11-21 04:17:18+00:00,https://twitter.com/GaryMarcus/status/1594545463008849920,@soumithchintala @moreisdifferent Appreciate your sober thread. I do think though that there is an inherent unsolved challenge though inasmuch as no current tech can really eliminate the widespread hallucinations.
1436,@GaryMarcus,2022-11-21 04:08:02+00:00,https://twitter.com/GaryMarcus/status/1594543132087308288,epic trolls from @rsalakhu (1 of 2)
1437,@GaryMarcus,2022-11-21 04:05:29+00:00,https://twitter.com/GaryMarcus/status/1594542491151499265,"@pmddomingos @YejinChoinka in the limit of unlimited data, they are same, as I said. The difference is in the learning. But the learning isn‚Äôt real compositionality; it‚Äôs something that looks vaguely similar @ fails all the tasks I just mentioned that you aren‚Äôt engaging. Cc @EvelinaLeivada @ElliotMurphy91"
1438,@GaryMarcus,2022-11-21 02:57:56+00:00,https://twitter.com/GaryMarcus/status/1594525492363038720,@pmddomingos @YejinChoinka And see also https://t.co/UWUg6kQ3Df by @EvelinaLeivada @ElliotMurphy91 and myself in different but related architecture
1439,@GaryMarcus,2022-11-21 02:55:39+00:00,https://twitter.com/GaryMarcus/status/1594524917365866496,@pmddomingos In the limit they are the same (universal function approximators). They are better at learning syntax but they still don‚Äôt have a compositional semantics. Which is why eg they fail at @YejinChoinka‚Äôs recent https://t.co/wsic38AdLR
1440,@GaryMarcus,2022-11-21 02:42:05+00:00,https://twitter.com/GaryMarcus/status/1594521503546355712,"@pmddomingos Representing grammar is cheap - lots of architecture can do that in the limit. learning grammar from data  is same problem it ever was.

And you are still inaccurate in what you said about compositionality."
1441,@GaryMarcus,2022-11-21 02:22:41+00:00,https://twitter.com/GaryMarcus/status/1594516617840689153,"@pmddomingos not quite right. They have a proxy that looks vaguely like compositionality. They don‚Äôt have meanings lawfully composed from parts, governed by syntax."
1442,@GaryMarcus,2022-11-21 02:18:55+00:00,https://twitter.com/GaryMarcus/status/1594515671819649024,amazing how many people missed that this was a joke
1443,@GaryMarcus,2022-11-20 23:34:04+00:00,https://twitter.com/GaryMarcus/status/1594474184515944448,@Ted_Underwood @CriticalAI @true_mxp @JrKibs @_akpiper https://t.co/wsic38AdLR
1444,@GaryMarcus,2022-11-20 23:18:10+00:00,https://twitter.com/GaryMarcus/status/1594470186119303169,@ylecun @untitled01ipynb @rsalakhu ü§£ü§£ü§£ @rsalakhu trolls @ylecun and I get blamed.  (Does this count as a countercountertroll?)
1445,@GaryMarcus,2022-11-20 19:55:33+00:00,https://twitter.com/GaryMarcus/status/1594419193595965440,"@ylecun @CriticalAI @TonyZador @mrgreene1977 @noUpside @katestarbird @sinanaral @ProfNoahGian Just answer this one question, Yann:"
1446,@GaryMarcus,2022-11-20 19:49:08+00:00,https://twitter.com/GaryMarcus/status/1594417578331754497,"@PeterShor1 @ylecun @Grady_Booch @Jeff_Aronson @Abebab Were there any usability studies with actual users? You‚Äôd want to evaluate accuracy, and not just speed."
1447,@GaryMarcus,2022-11-20 18:10:34+00:00,https://twitter.com/GaryMarcus/status/1594392774723661824,Tweeted this day before Galactica came out ü§£
1448,@GaryMarcus,2022-11-20 18:09:27+00:00,https://twitter.com/GaryMarcus/status/1594392492618952704,"@Ted_Underwood @true_mxp @JrKibs @_akpiper people can (and are) approaching it, but they can‚Äôt do it. 

with training and diet, i can ‚Äúapproach‚Äù running a 2 min mile, but it ain‚Äôt gonna happen with my body."
1449,@GaryMarcus,2022-11-20 18:07:18+00:00,https://twitter.com/GaryMarcus/status/1594391950656155648,@ykilcher has anyone done *any*? how?  I just asked Yann re FB; we will see if he replies. anyone who did so here at Twitter has left the building.
1450,@GaryMarcus,2022-11-20 18:06:03+00:00,https://twitter.com/GaryMarcus/status/1594391637836582914,"@Ted_Underwood @true_mxp @JrKibs @_akpiper the abject failure of Galactica to do so is btw an object lesson here.  so are the woeful results on TruthfulQA across the whole field, and much harder tasks might be devised."
1451,@GaryMarcus,2022-11-20 18:03:37+00:00,https://twitter.com/GaryMarcus/status/1594391024767758336,"@Ted_Underwood @true_mxp @JrKibs @_akpiper no, current software cannot do that remotely reliable; by trivializing a core unsolved challenge, you are just showing that you don‚Äôt really understand their scope and limits of current technology."
1452,@GaryMarcus,2022-11-20 18:02:17+00:00,https://twitter.com/GaryMarcus/status/1594390688535568385,"I ask again, @ylecun, has Facebook/@metaAI done any forensic studies of the misinformation posted on FB to see what fraction was generated by LLM? 

If yes, what procedures did you use to discern the origin?

If you haven‚Äôt, maybe the problem is you haven‚Äôt looked."
1453,@GaryMarcus,2022-11-20 18:00:22+00:00,https://twitter.com/GaryMarcus/status/1594390209705443328,"@ylecun @ASteckley @CriticalAI @TonyZador @mrgreene1977 @noUpside @katestarbird @sinanaral @ProfNoahGian 1. the toxicity filters aren‚Äôt up to the job per @mrgreene1977‚Äôs examples of anti-semitism etc.
2. the real problem is the fine blending together of truth and bullshit, that can be applied to any topic yielding pseudoscience."
1454,@GaryMarcus,2022-11-20 17:54:38+00:00,https://twitter.com/GaryMarcus/status/1594388765724008451,"@ykilcher as i told you repeatedly, this is not so. it‚Äôs a claim that requires forensic investigation, not one that can‚Äôt be falsified."
1455,@GaryMarcus,2022-11-20 17:53:14+00:00,https://twitter.com/GaryMarcus/status/1594388413436026881,"@ykilcher you are misinterpreting the absence of extremely difficult to gather evidence (which would require forensic investigation by people familiar with LLMs and interested in the question) as evidence of absence.

[and then playing burden of proof games]"
1456,@GaryMarcus,2022-11-20 17:51:17+00:00,https://twitter.com/GaryMarcus/status/1594387922211700738,"@ykilcher maybe I misread you but you certainly seem to think it hasn‚Äôt happened. 

i pointed out that it would require forensic evidence that we don‚Äôt even know how to collect to prove, and you repeated your claims that it was inherently an unfalsifiable claim."
1457,@GaryMarcus,2022-11-20 17:45:59+00:00,https://twitter.com/GaryMarcus/status/1594386588964126720,"ü§∑‚Äç‚ôÇÔ∏è: @ykilcher, who created the much-criticized 4chan demo showing that bots could automatically create toxic content that humans couldn‚Äôt detect (&amp; then open-sourced the code), is trying to persuade me that nobody (other than him) would ever try such a stunt in the real world."
1458,@GaryMarcus,2022-11-20 17:33:14+00:00,https://twitter.com/GaryMarcus/status/1594383379633672192,"@Ted_Underwood @JrKibs @_akpiper Word sequence prediction &amp; validating truth are fundamentally different challenges

One involves predicting statistics between sequences of words, other involves building stable representations of the world and reasoning over them

Little progress on adapting LLMs for the latter"
1459,@GaryMarcus,2022-11-20 17:27:53+00:00,https://twitter.com/GaryMarcus/status/1594382033408921601,AI talk over on Mastodon is starting to be fun; @fchollet favoriting my commentary on @ylecun ‚ù§Ô∏è https://t.co/Ch1eD8dpOq
1460,@GaryMarcus,2022-11-20 17:11:14+00:00,https://twitter.com/GaryMarcus/status/1594377841483087872,"@ylecun @leonpalafox @realohtweets @wayneholmes @AlphaSignalAI you also neglect the notion that people might eg create networks of fake accounts (a known technique) to boost misinformation, however generated."
1461,@GaryMarcus,2022-11-20 17:09:06+00:00,https://twitter.com/GaryMarcus/status/1594377306558332929,"@ylecun @leonpalafox @realohtweets @wayneholmes @AlphaSignalAI How can you know their percentage of success? Lots of misinformation is out there, and having influence (eg on vaccination rates). Given how good at LLMs are at mimicry, it seems like your conclusion is entirely speculative.

&amp; like spam, only a tiny fraction needs to get through"
1462,@GaryMarcus,2022-11-20 14:04:59+00:00,https://twitter.com/GaryMarcus/status/1594330971377389568,"Votes to reinstate Trump: 7.8 million
Fake Followers: 81 million
ü§î"
1463,@GaryMarcus,2022-11-20 13:35:57+00:00,https://twitter.com/GaryMarcus/status/1594323664178393089,@ylecun @wayneholmes @AlphaSignalAI fixed that for you:
1464,@GaryMarcus,2022-11-20 13:33:25+00:00,https://twitter.com/GaryMarcus/status/1594323025666928640,"Close!  Galactica is dangerous because it mixes together truth and bullshit plausibly &amp; at scale. You thought that nobody would notice or care, and then took your own judgments about risk as the only ones that were relevant. 

It‚Äôs that last part that comes across as arrogant."
1465,@GaryMarcus,2022-11-20 11:33:55+00:00,https://twitter.com/GaryMarcus/status/1594292952909877249,Well said: https://t.co/bR0fxYkyE1
1466,@GaryMarcus,2022-11-20 03:29:28+00:00,https://twitter.com/GaryMarcus/status/1594171040187699205,@AI4Code @SumitGulwani
1467,@GaryMarcus,2022-11-20 00:45:06+00:00,https://twitter.com/GaryMarcus/status/1594129675613540352,"@ylecun @drng @Grady_Booch @Jeff_Aronson @Abebab @mrgreene1977 Galactica has deeper problems:
- it is unconstrained by the facts are in its database (eg it said that Elon Musk died in 2018 car crash but probably has data to the contrary)
- it gives no indication when it makes something up that isn‚Äôt database"
1468,@GaryMarcus,2022-11-20 00:33:06+00:00,https://twitter.com/GaryMarcus/status/1594126653961433088,@ylecun @drng @Grady_Booch @Jeff_Aronson @Abebab I think what he means that the model made false inferences eg about value in eating crushed glass (per @mrgreene1977) https://t.co/eOlWcTDTxL
1469,@GaryMarcus,2022-11-20 00:31:09+00:00,https://twitter.com/GaryMarcus/status/1594126164473565184,"@mark_riedl @Sergei_Imaging @ylecun @mrgreene1977 no doubt that cat is out of the bag, and it‚Äôs easy enough to replicate. 

soon enough we find out empirically how much impact systems like these have. (though of course hard to trace since the quality of the mimicry is high and there are no watermarks)"
1470,@GaryMarcus,2022-11-20 00:29:43+00:00,https://twitter.com/GaryMarcus/status/1594125804216397825,@srijankedia @ylecun @mrgreene1977 @noUpside @katestarbird @sinanaral @ProfNoahGian @emilio__ferrara @davidlazer @gianluca_string @CrashTheMod3 It‚Äôs quite worrisome that @metaAI‚Äôs Chief AI officer shows little apparent familiarity with such work.
1471,@GaryMarcus,2022-11-20 00:27:54+00:00,https://twitter.com/GaryMarcus/status/1594125346928218112,"@tdietterich @ylecun @mrgreene1977 and they are in fact starting to be used, and as cost of doing them well decreases, we can expect them to be more widespread. some examples from 2022: https://t.co/4kxqUjHXXT

2024 election, who knows?"
1472,@GaryMarcus,2022-11-20 00:22:17+00:00,https://twitter.com/GaryMarcus/status/1594123933204504577,"#Galactica is fine, because if it makes stuff up, no problemo.

@metaAI‚Äôs Chief AI Officer just told me so.

And he‚Äôs *sure* nobody would ever misuse his tool.

Yeah, right."
1473,@GaryMarcus,2022-11-20 00:20:04+00:00,https://twitter.com/GaryMarcus/status/1594123375450132480,"@noUpside @ylecun @mrgreene1977 @katestarbird @sinanaral @ProfNoahGian Ask Yann, who thinks it is actually hunky-dory, but my theory was this:"
1474,@GaryMarcus,2022-11-20 00:10:39+00:00,https://twitter.com/GaryMarcus/status/1594121006243000322,"@ylecun @srijankedia @mrgreene1977 @noUpside @katestarbird @sinanaral @ProfNoahGian Low probabilities ‚â† zero probabilities. 

Low probabilities with low cost ‚â†  zero probabilities with zero cost.

Every spammer, ever, knows this.

Same principles will apply to misinfo; as cost of generation goes down, volume of misinfo spam goes up."
1475,@GaryMarcus,2022-11-20 00:06:40+00:00,https://twitter.com/GaryMarcus/status/1594120000755105793,"Twitter on IOS just crashed midtweet and I lost my work. First time that happened in a decade of using it. also having some load time issues.

And so it begins."
1476,@GaryMarcus,2022-11-20 00:02:31+00:00,https://twitter.com/GaryMarcus/status/1594118956205637632,"@ylecun @jppesky @mrgreene1977 on latter point, better said:"
1477,@GaryMarcus,2022-11-20 00:00:29+00:00,https://twitter.com/GaryMarcus/status/1594118445528154112,"@ylecun @jppesky @mrgreene1977 You are coming across as obtuse.
- You act as if misinfo has had no impact in the real world (despite success of anti-vax campaigns)
- Act as if the only way in which scientific-sounding nonsense has impact is if it is in a peer review journal
- Treat low prob as zero probability"
1478,@GaryMarcus,2022-11-19 23:52:54+00:00,https://twitter.com/GaryMarcus/status/1594116536268386304,"@TonyZador @ylecun @mrgreene1977 @noUpside @katestarbird @sinanaral @ProfNoahGian perhaps someone in 1985 said ‚Äúemail isn‚Äôt going to have any effect on scamming. it‚Äôs driven by how much people want to be taken.‚Äù

the biggest application of LLMs is now? it‚Äôs apparently making nonsense for SEO optimization. New ways to do in volume, because cost is cheaper."
1479,@GaryMarcus,2022-11-19 23:14:23+00:00,https://twitter.com/GaryMarcus/status/1594106842795618304,"@ylecun @mrgreene1977 Come on, it‚Äôs not just about journals. 

To take one example, vaccine misinformation, oft presented as ‚Äúscientific‚Äù [eg https://t.co/B1JmJihJpl], likely had significant impact on vaccination rates.

Tagging @noUpside @katestarbird @sinanaral @ProfNoahGian for more perspectives."
1480,@GaryMarcus,2022-11-19 22:11:50+00:00,https://twitter.com/GaryMarcus/status/1594091101555916800,"@ylecun @mrgreene1977 How could Galactica  *not* make misinfo easier, @ylecun, when it makes writing faux scientific-like articles trivial rather than laborious?

&amp; here‚Äôs a question, does Facebook have AI that can detect Galactica-misinfo at scale? Any data on how good any such AI might be? 

Cf: https://t.co/CQiFr4YHF6"
1481,@GaryMarcus,2022-11-19 19:43:40+00:00,https://twitter.com/GaryMarcus/status/1594053816533803009,@ylecun @Grady_Booch @Jeff_Aronson @Abebab The sand is in thinking that a system like this can stick to reality. It cannot.
1482,@GaryMarcus,2022-11-19 19:13:54+00:00,https://twitter.com/GaryMarcus/status/1594046326664495106,@ylecun @Abebab Ps repeating for convenience:
1483,@GaryMarcus,2022-11-19 19:06:49+00:00,https://twitter.com/GaryMarcus/status/1594044543628087297,@yoavgo @mikmatty Eg
1484,@GaryMarcus,2022-11-19 19:04:29+00:00,https://twitter.com/GaryMarcus/status/1594043954223538176,"@ylecun @Abebab I gave you a bunch of potentially dangerous use cases, as you requested, &amp; you did not respond. How is that constructive? 

@Abebab &amp; I &amp; others stress tested your model-standard operating procedure that should have been done internally‚Äì&amp; you accused us of abuse. Constructive?"
1485,@GaryMarcus,2022-11-19 18:57:47+00:00,https://twitter.com/GaryMarcus/status/1594042267765207042,". @ElonMusk died in a  car accident! In 2018!

My new talk on fake news, #Galactica, and the limited ability of current AI to moderate misinformation:"
1486,@GaryMarcus,2022-11-19 18:00:48+00:00,https://twitter.com/GaryMarcus/status/1594027928068952066,"Interesting graph, over on Mastodon:

https://t.co/ytfm8T5rbt"
1487,@GaryMarcus,2022-11-19 17:37:18+00:00,https://twitter.com/GaryMarcus/status/1594022015887081472,@balazskegl what would update my judgement most positively would be if Musk made significant efforts towards honoring this promise:
1488,@GaryMarcus,2022-11-19 14:56:00+00:00,https://twitter.com/GaryMarcus/status/1593981424260218880,is there a prediction market on whether Twitter goes down eg for &gt; 24 hours before 2023?
1489,@GaryMarcus,2022-11-19 14:52:57+00:00,https://twitter.com/GaryMarcus/status/1593980654454444032,56 ways this ship might go down
1490,@GaryMarcus,2022-11-19 14:32:57+00:00,https://twitter.com/GaryMarcus/status/1593975620379475968,not even sure what this means but as a man I am very happy to stand with all the women (&amp; other men) who are concerned about misinformation and toxic and hateful speech.
1491,@GaryMarcus,2022-11-19 02:25:38+00:00,https://twitter.com/GaryMarcus/status/1593792587718356992,"Oct 28: ‚ÄúTwitter will be forming a content moderation council with widely diverse viewpoints. 
No major content decisions or account reinstatements will happen before that council convenes.‚Äù

3 weeks later: Council? What Council?  Whatever my right of center followers say, goes."
1492,@GaryMarcus,2022-11-18 21:21:17+00:00,https://twitter.com/GaryMarcus/status/1593715995373625344,"@ylecun @mrgreene1977 Potentially deadly TikTok challenges; analogous stuff around vaccine validity, hoax cures like HCQ; climate misinformation; medical misinformation, etc

Not that hard to imagine"
1493,@GaryMarcus,2022-11-18 21:06:16+00:00,https://twitter.com/GaryMarcus/status/1593712214787371008,ü§£ü§£ü§£
1494,@GaryMarcus,2022-11-18 19:20:56+00:00,https://twitter.com/GaryMarcus/status/1593685708300222464,I Like Free Speech So Much I‚Äôve Decided to Buy It - McSweeney‚Äôs https://t.co/Yw3n94HAQW
1495,@GaryMarcus,2022-11-18 19:18:59+00:00,https://twitter.com/GaryMarcus/status/1593685215565996032,@elonmusk What about misinformation?
1496,@GaryMarcus,2022-11-18 19:06:43+00:00,https://twitter.com/GaryMarcus/status/1593682130747674624,Galactica
1497,@GaryMarcus,2022-11-18 15:50:32+00:00,https://twitter.com/GaryMarcus/status/1593632759872118784,@yoavgo @ylecun @rasbt @manes @Abebab Troll farms cost money and presumably limited by budget. The more they can put out the more effective they are.
1498,@GaryMarcus,2022-11-18 15:36:47+00:00,https://twitter.com/GaryMarcus/status/1593629298921189376,"@yoavgo @rasbt @manes @ylecun @Abebab On the scenario, secondary customers like journalists will have no longer have any trust in arXiv at all."
1499,@GaryMarcus,2022-11-18 15:34:22+00:00,https://twitter.com/GaryMarcus/status/1593628688268300290,"@ylecun @rasbt @manes @Abebab It will reduce the cost hence increase the volume, hence make the problem worse."
1500,@GaryMarcus,2022-11-18 15:12:34+00:00,https://twitter.com/GaryMarcus/status/1593623202605174784,"@ylecun @Abebab Galactica *is* dangerous. And you have no idea how to eliminate that danger. large language models inherently hallucinate.

It weaponized the ability of these tools to spread fake science.

The vitriol is proportionate to the risk.

I am shocked that you are indifferent to this."
1501,@GaryMarcus,2022-11-18 15:06:40+00:00,https://twitter.com/GaryMarcus/status/1593621720044568576,"‚Äúonce perfected‚Äù is carrying a lot of weight here. there is no way Galactica will be perfected in next year or two, probably a lot longer.

happy to publicly debate you about this, but recommend you start by rereading your own recent critique @noemamag of large language models."
1502,@GaryMarcus,2022-11-18 13:51:45+00:00,https://twitter.com/GaryMarcus/status/1593602863628185601,very rational fear
1503,@GaryMarcus,2022-11-18 13:41:25+00:00,https://twitter.com/GaryMarcus/status/1593600265307193344,"follow friday may not be a thing much longer over here on Twitter but follow @abebab. And she‚Äôs on Mastodon now, too."
1504,@GaryMarcus,2022-11-18 13:15:06+00:00,https://twitter.com/GaryMarcus/status/1593593642090131456,"Just saying, in case this ship goes down, @garymarcus@sigmoid.social"
1505,@GaryMarcus,2022-11-18 12:55:18+00:00,https://twitter.com/GaryMarcus/status/1593588661190524928,@HeidyKhlaaf @AmandaAskell @andrewthesmart @Abebab 100% support thinking through the potential social consequences. There is a lot of room for important argument there.
1506,@GaryMarcus,2022-11-18 12:48:16+00:00,https://twitter.com/GaryMarcus/status/1593586888950312960,"@HeidyKhlaaf @AmandaAskell @andrewthesmart @Abebab Thank you. and to be clear I am all for spelling out the latter part and will amplify the message if is is constructed carefully and respectfully. 

(If you want to write something longer, DM.)"
1507,@GaryMarcus,2022-11-18 12:24:50+00:00,https://twitter.com/GaryMarcus/status/1593580991528206337,"@HeidyKhlaaf @AmandaAskell @andrewthesmart Yes, there are lot of ideas within EA, some well-intentioned, some not. some briefly considered, some taken seriously, some not; some sensible, some dubious. 

I would love to see @abebab pick apart the weak ones üçø

But tarnishing everyone with a broad brush isn‚Äôt the way to go."
1508,@GaryMarcus,2022-11-18 12:12:17+00:00,https://twitter.com/GaryMarcus/status/1593577833129185281,"I would proudly take the ‚Äúblame‚Äù for pointing out Galactica‚Äôs serious issues, but many others, such as @Grady_Booch @emilymbender  @Michael_J_Black @mrgreene1977 &amp; @abebab spoke up, too. 

Release was overhyped; social implications poorly thought through. 

That‚Äôs on Meta."
1509,@GaryMarcus,2022-11-18 11:57:18+00:00,https://twitter.com/GaryMarcus/status/1593574062303096835,"@FelixHill84 @gchrupala Some things have changed, some haven‚Äôt. You still can‚Äôt run AlphaFold 2 and Palm-SayCan interchangeably. The need for custom architecture and representations hasn‚Äôt entirely gone away. 

And the dire need for cognitive models, compositionality, &amp; type/token distinctions remains."
1510,@GaryMarcus,2022-11-18 10:40:37+00:00,https://twitter.com/GaryMarcus/status/1593554763261829125,"The whole Galactica debacle harkens back to the @Microsoft Tay fiasco; here‚Äôs a post-mortem, still relevant, from @ginasue:"
1511,@GaryMarcus,2022-11-18 10:23:04+00:00,https://twitter.com/GaryMarcus/status/1593550350325518338,"Agree w much of this, both positive and negative, but think it underemphasizes the massive potential  for weaponizing the production of misinformation."
1512,@GaryMarcus,2022-11-18 04:06:56+00:00,https://twitter.com/GaryMarcus/status/1593455693331599361,"Two days ago: ‚Äútype a text and https://t.co/w5sHlWACvA will generate paper with relevant references, formulas, and everything‚Äù

Today: typing a text and expecting such things is ‚Äúabusing‚Äù the system"
1513,@GaryMarcus,2022-11-18 03:28:41+00:00,https://twitter.com/GaryMarcus/status/1593446067517128706,"@AmandaAskell thanks. that‚Äôs what i have been trying, to no avail, to get clarification about."
1514,@GaryMarcus,2022-11-18 03:10:04+00:00,https://twitter.com/GaryMarcus/status/1593441378524332032,"@mmitchell_ai @emilymbender @timnitGebru no, not fair. that‚Äôs what I keep asking about. is this what is meant, or not? people just keep insulting me, and attacking me based on my skin color.

if someone has actually answered, link it. if not, be respectful enough to actually answer."
1515,@GaryMarcus,2022-11-18 02:16:04+00:00,https://twitter.com/GaryMarcus/status/1593427792481648640,"@timnitGebru I think that you mischaracterize my mentor, but whether or not you do, I have never defended his politics. 

(Nor have I defended EA, except to ask for evidence.)

What you say here simply isn‚Äôt true."
1516,@GaryMarcus,2022-11-18 01:28:40+00:00,https://twitter.com/GaryMarcus/status/1593415861347680256,PSA: https://t.co/ycsnNbg54g
1517,@GaryMarcus,2022-11-18 01:26:31+00:00,https://twitter.com/GaryMarcus/status/1593415322681237504,Another shocker!
1518,@GaryMarcus,2022-11-18 01:11:49+00:00,https://twitter.com/GaryMarcus/status/1593411623250956288,Shocker: Twitter‚Äôs Moderation System Is in Tatters  https://t.co/1vJWsjEGcZ
1519,@GaryMarcus,2022-11-17 23:52:52+00:00,https://twitter.com/GaryMarcus/status/1593391751657816064,"Tripling down, @yLeCun's contention is that people ""abused"" Galactica. 

But what safeguards were put in place to prevent bad actors from using the system to generate compelling disinformation around scientific topics like vaccines or racial differences? 

A: None."
1520,@GaryMarcus,2022-11-17 23:39:33+00:00,https://twitter.com/GaryMarcus/status/1593388403307188229,"@mmitchell_ai @trashcanmagic @timnitGebru But that is not me. I fully agree with Dr King's methods, and with direct action; he and Gandhi were my idols. 

Yet there is a violence in denouncing people based on presumption that Dr. King (himself wrongly characterized as a Communist) would not have gotten behind."
1521,@GaryMarcus,2022-11-17 23:18:17+00:00,https://twitter.com/GaryMarcus/status/1593383051790536704,@andrewthesmart So the left is now pro-choice but anti-genetic screening? This is eugenics? https://t.co/gu4vD7v0en
1522,@GaryMarcus,2022-11-17 22:10:22+00:00,https://twitter.com/GaryMarcus/status/1593365959938826240,"@emilymbender @timnitGebru and if what you say is true, you can simply provide a link. there certainly has not been anything from either of you in direct replies to me when i have asked."
1523,@GaryMarcus,2022-11-17 22:01:59+00:00,https://twitter.com/GaryMarcus/status/1593363850786897920,"Why is this is any different at all than McCarthyism?  I honestly don't see a difference between labeling someone a communist and labeling them a eugenicist, if you do so without either evidence or definition. 

I have asked, repeatedly, for both, and gotten neither."
1524,@GaryMarcus,2022-11-17 21:54:48+00:00,https://twitter.com/GaryMarcus/status/1593362041401913344,"@emilymbender @timnitGebru Nonsense. I have repeatedly asked a legitimate,straightforward question. Neither of you have answered: are you claiming eg that MacAskill (whom I have never met) is a eugenicist a la 19th century scientific racism? yes or no, and if yes, in what sense, and what is the argument?"
1525,@GaryMarcus,2022-11-17 21:52:13+00:00,https://twitter.com/GaryMarcus/status/1593361391553052673,"@athundt @timnitGebru The argument against Singer there is much more straightforward; it's clear what he said, and I am definitely not defending that aspect of his argument."
1526,@GaryMarcus,2022-11-17 21:50:36+00:00,https://twitter.com/GaryMarcus/status/1593360986106363906,"@athundt @timnitGebru I don't doubt that scientific racism still exists. But that label should not be applied to specific people without real evidence. That's all I am saying.

&amp; definitions matter; eg most people would support genetic screening for chromosomal abnormalities. Is that eugenics?"
1527,@GaryMarcus,2022-11-17 21:38:20+00:00,https://twitter.com/GaryMarcus/status/1593357895164657664,I have no shame about speaking out against McCarthyism.
1528,@GaryMarcus,2022-11-17 21:32:21+00:00,https://twitter.com/GaryMarcus/status/1593356393490558976,@timnitGebru no definitions still? i will carry on.
1529,@GaryMarcus,2022-11-17 21:26:23+00:00,https://twitter.com/GaryMarcus/status/1593354887911591936,"@trashcanmagic @timnitGebru How dare you? My father was doing sit-ins for fair housing before you were born, and did discrimination law for years. I helped him (with statistics) as a teenager, and went to protests from when I was a newborn.

 I am with your struggle, but not your tactics."
1530,@GaryMarcus,2022-11-17 21:24:28+00:00,https://twitter.com/GaryMarcus/status/1593354406413885440,"@timnitGebru We need definitions, @timnitGebru, if you want me and others take you seriously. I was once a huge fan of yours, but am really losing the faith."
1531,@GaryMarcus,2022-11-17 21:16:44+00:00,https://twitter.com/GaryMarcus/status/1593352460881776640,"@timnitGebru Only quote I have seen was nearly fabricated, inserting words that Bostrom didn't use.  I haven't seen any direct evidence on MacAskill.

&amp; you continue to duck definitions. Do you mean ""eugenics"" in the historical, indefensible sense of discriminating based on race? Or sth else?"
1532,@GaryMarcus,2022-11-17 21:07:19+00:00,https://twitter.com/GaryMarcus/status/1593350092056309760,"@timnitGebru If I had been alive in the 1950s I hope that I would have called out McCarthy (white male) for doing what you do: naming names, without due process, without definitions, without evidence.

It's not what groups you belong to Timnit, it's what you are saying that is problematic."
1533,@GaryMarcus,2022-11-17 19:56:24+00:00,https://twitter.com/GaryMarcus/status/1593332244340703232,@ylecun @Grady_Booch And they use lots of symbol-manipulation too. Funny that you never mention that.
1534,@GaryMarcus,2022-11-17 19:31:30+00:00,https://twitter.com/GaryMarcus/status/1593325977341685760,"@yLeCun: It‚Äôs all good, man"
1535,@GaryMarcus,2022-11-17 19:13:37+00:00,https://twitter.com/GaryMarcus/status/1593321478111784961,"my biggest question about SBF (malice vs negligence, or both) is pretty decisively answered in this thread."
1536,@GaryMarcus,2022-11-17 19:08:56+00:00,https://twitter.com/GaryMarcus/status/1593320299302649856,Doubling down on Galactica.
1537,@GaryMarcus,2022-11-17 19:03:57+00:00,https://twitter.com/GaryMarcus/status/1593319043838230529,"@timnitGebru this is not about race or gender. it is about due process and defamation
- I asked you to supply definitions about what you meant by eugenics; you did not.
- I asked for sources; I see only a nearly-fabricated quote from Torres‚Äì not enough to support your accusations"
1538,@GaryMarcus,2022-11-17 16:29:42+00:00,https://twitter.com/GaryMarcus/status/1593280226062372864,please read this thread and the examples below from @mrgreene1977.
1539,@GaryMarcus,2022-11-17 16:21:05+00:00,https://twitter.com/GaryMarcus/status/1593278058265726976,we ought also worry about troll farms making up vast quantities of fake yet plausible sounding scientific articles about topics like vaccination and climate change.
1540,@GaryMarcus,2022-11-17 16:16:03+00:00,https://twitter.com/GaryMarcus/status/1593276789983322113,Next year‚Äôs #1 excuse from parents to teachers: Little Johnny wasn‚Äôt *wrong*. He just had a lossily compressed version of what he read in the textbook. üôÑ
1541,@GaryMarcus,2022-11-17 16:13:06+00:00,https://twitter.com/GaryMarcus/status/1593276050330775553,@TonyZador @MetaAI It‚Äôs so lossy it cannot be trusted; you have just put a nicer sounding name on the fundamental problem.
1542,@GaryMarcus,2022-11-17 16:11:02+00:00,https://twitter.com/GaryMarcus/status/1593275531252097026,"nope. it‚Äôs actually much worse than this; eg ‚ÄúElon Musk died in a car crash in 2018‚Äù contradicts what was in the training set.

even on a closed book exam, that‚Äôs a fail."
1543,@GaryMarcus,2022-11-17 15:55:00+00:00,https://twitter.com/GaryMarcus/status/1593271496285523968,"@TonyZador @MetaAI No, it‚Äôs failing the open book version, unconstrained by facts that are readily available the web."
1544,@GaryMarcus,2022-11-17 15:45:58+00:00,https://twitter.com/GaryMarcus/status/1593269222377148416,".@ylecun want to put $1,000 to charity on this, with an independent panel of judges? 

I bet that you can‚Äôt solve Galactica‚Äôs hallucination problems within the next six months. (&amp; probably not in the next 36).

@metaculus @MatthewJBar @longnow"
1545,@GaryMarcus,2022-11-17 15:35:54+00:00,https://twitter.com/GaryMarcus/status/1593266689294368768,"sorry but no‚ÄîGalactica will not be ready for primetime in a few months.

Predicting word sequences based on text has nothing to do with a *conceptually different challenge* of relating text to reality. 

LLMs are fundamentally ill-equipped for this."
1546,@GaryMarcus,2022-11-17 15:28:37+00:00,https://twitter.com/GaryMarcus/status/1593264852919013376,"The reality is that large language models like GPT-3 annd Galactica are like bulls in a china shop, powerful but reckless.  

And they are likely to vastly increase the challenge of misinformation.

[2/2]"
1547,@GaryMarcus,2022-11-17 15:28:34+00:00,https://twitter.com/GaryMarcus/status/1593264844412977158,"The rapid removal of @MetaAI‚Äôs Galactica demo represents a tacit acknowledgement that it was released too soon and deeply problematic‚Äîand contrasts strikingly with @ylecun‚Äôs untenable public defense of the project yesterday. 

[1/2]"
1548,@GaryMarcus,2022-11-17 14:44:42+00:00,https://twitter.com/GaryMarcus/status/1593253803402592256,Liz Truss lasted longer than Galactica.
1549,@GaryMarcus,2022-11-17 13:57:29+00:00,https://twitter.com/GaryMarcus/status/1593241919316197378,"the information apocalypse is coming, @elonmusk. I tried to warn you."
1550,@GaryMarcus,2022-11-17 08:19:28+00:00,https://twitter.com/GaryMarcus/status/1593156854372532231,Exactly what I have been saying: Galactica is dangerous:
1551,@GaryMarcus,2022-11-16 23:11:10+00:00,https://twitter.com/GaryMarcus/status/1593018870205665280,"Flattery will get you nowhere, young battlestar.

(image courtesy @UlrichJunker) https://t.co/d8GYGDCgTm"
1552,@GaryMarcus,2022-11-16 22:59:03+00:00,https://twitter.com/GaryMarcus/status/1593015823148675072,"@shokunin_studio @Grady_Booch @fchollet i replied to @tansuyegen's tweet; it's not quite what he claims, I think. more like morphing than full synthesis"
1553,@GaryMarcus,2022-11-16 22:58:06+00:00,https://twitter.com/GaryMarcus/status/1593015584375328768,"@TansuYegen I think you have misunderstood wha the tech purports to do. I think that it is morphing actual human to look like a a different human. still cool, but not what you describe. see https://t.co/Lk5wipCh2c Face Shifting tab"
1554,@GaryMarcus,2022-11-16 17:56:14+00:00,https://twitter.com/GaryMarcus/status/1592939615123828737,@Grady_Booch @elonmusk I wasn‚Äôt assigning probabilities here ü§£
1555,@GaryMarcus,2022-11-16 17:52:44+00:00,https://twitter.com/GaryMarcus/status/1592938737222455296,"@Grady_Booch @elonmusk Only two ways this can go
- Musk can succeed, and rewrite everything we thought we knew about management and software engineering
- He can fail, and become the textbook example of how not to do things."
1556,@GaryMarcus,2022-11-16 17:49:47+00:00,https://twitter.com/GaryMarcus/status/1592937992431497218,"‚ö†Ô∏è There‚Äôs a lot going on. Midterms, FTX, Twitter chaos. 

But in time we will see the release of #Galactica as an epochal event, a tipping point in a gigantic increase in the flow of misinformation.

This is no joke. Galactica is funny, but the uses it will be put to are not."
1557,@GaryMarcus,2022-11-16 17:22:36+00:00,https://twitter.com/GaryMarcus/status/1592931153673351168,"‚ö†Ô∏è @MetaAI‚Äôs Galactica has made up my birthday (wrong decade), my education,my research interests, etc, all sounding plausible, 85% untrue.

You know what‚Äôs really embarrassing about this? A decent AI could just look this stuff on the web &amp; self-correct.

Galactica can‚Äôt."
1558,@GaryMarcus,2022-11-16 15:04:18+00:00,https://twitter.com/GaryMarcus/status/1592896348814475264,@ylecun @MetaAI @paperswithcode https://t.co/EvMKYUZcN0
1559,@GaryMarcus,2022-11-16 14:41:15+00:00,https://twitter.com/GaryMarcus/status/1592890547316092930,never had this happened before - timeout loading my own Tweets. Things gonna get wild here in Bird-land! https://t.co/URBAdZpBhX
1560,@GaryMarcus,2022-11-16 14:38:05+00:00,https://twitter.com/GaryMarcus/status/1592889749546897408,"For examples, see https://t.co/GUdfR6nR6y and this bonus fake bio of @ylecun here: https://t.co/gN1gvFkSjh"
1561,@GaryMarcus,2022-11-16 14:38:03+00:00,https://twitter.com/GaryMarcus/status/1592889743402225664,"AI Joke of the Day!

Q: What do a CNC machine and MetaAI‚Äôs #Galactica have in common?
..
..
..
A: They both help you fabricate! ü§£"
1562,@GaryMarcus,2022-11-16 06:56:19+00:00,https://twitter.com/GaryMarcus/status/1592773541371736065,@kevinroose you don‚Äôt think the product placement for Storybook Brawl was a nice touch? https://t.co/15jySgxqR9  @TrungTPhan
1563,@GaryMarcus,2022-11-16 05:49:14+00:00,https://twitter.com/GaryMarcus/status/1592756661747601409,"@mcuban just liked my new post; as it happens, I have been trying to reach out to him. can anyone ask him to DM me? https://t.co/Ib4o2UbjKD"
1564,@GaryMarcus,2022-11-16 05:35:37+00:00,https://twitter.com/GaryMarcus/status/1592753234447568896,@_jasonwei @colinraffel i need to think about @colinraffel‚Äôs specific tasks but i am willing to bet money that LLMs will continue to face serious challenges in factuality even as they scale.
1565,@GaryMarcus,2022-11-16 05:22:58+00:00,https://twitter.com/GaryMarcus/status/1592750051822301184,ps don‚Äôt tell @demishassabis: https://t.co/wZkhIu6uIk
1566,@GaryMarcus,2022-11-16 05:05:48+00:00,https://twitter.com/GaryMarcus/status/1592745729839464448,"A Few Words about Bullshit:
How @metaAI‚Äôs #Galactica  just jumped the AI shark. 

https://t.co/wMsf9hPrbW"
1567,@GaryMarcus,2022-11-16 04:28:54+00:00,https://twitter.com/GaryMarcus/status/1592736443423928321,"@plibin @BobbyAlter üíØ

The new must-have accessory for every troll farm and propaganda team on the planet."
1568,@GaryMarcus,2022-11-16 04:21:42+00:00,https://twitter.com/GaryMarcus/status/1592734631711109120,"@plibin @BobbyAlter LLMs don‚Äôt literally lie, since they have no internal sense of truth nor intention to mislead. ‚Äúlie‚Äù is just shorthand. but the reality is that they cannot be trusted to speak in truth as opposed to hallucination."
1569,@GaryMarcus,2022-11-16 04:03:21+00:00,https://twitter.com/GaryMarcus/status/1592730015560798210,"Or ‚Ä¶  This tool is to science as science fiction is to science?
#Galactica https://t.co/uQv0X99Ykc"
1570,@GaryMarcus,2022-11-16 03:57:55+00:00,https://twitter.com/GaryMarcus/status/1592728647739518976,@ylecun @MetaAI @paperswithcode https://t.co/7coXaKgAH2
1571,@GaryMarcus,2022-11-16 03:55:35+00:00,https://twitter.com/GaryMarcus/status/1592728061249978369,"Deep learning fans like this nonsense yet ignore the actual benchmarks that I have proposed in articles in last monthüôÑ 

Can their models beat benchmarks by @LucaWeihs et al in TMLR? or @EvelinaLeivada et al in arXiv? 

Haven‚Äôt seen a single model that can address either!"
1572,@GaryMarcus,2022-11-16 03:20:30+00:00,https://twitter.com/GaryMarcus/status/1592719228746207232,"@Meaningness ‚ÄúDon‚Äôt blame the model, blame the skeptic who didn‚Äôt write an easy to use benchmark‚Äù - someone who sounds a little like @ykilcher"
1573,@GaryMarcus,2022-11-16 03:19:22+00:00,https://twitter.com/GaryMarcus/status/1592718946930921472,"And, bonus, quoting from Reddit, ‚ÄúIt's pretty good at generating convincing-sounding, yet completely wrong, mathematical proofs‚Äù

Our glorious AI future has arrived! Thanks, Meta."
1574,@GaryMarcus,2022-11-16 00:08:58+00:00,https://twitter.com/GaryMarcus/status/1592671027989188608,"@ykilcher which benchmarks have you published in the last four weeks? I have posted two, one in a hot new ML journal, linked above, which you didn‚Äôt comment, the other on arXiv. You? the third was published in AI Magazine 2015. It‚Äôs not *my* fault that the field doesn‚Äôt rise to them."
1575,@GaryMarcus,2022-11-15 20:59:45+00:00,https://twitter.com/GaryMarcus/status/1592623412417265666,"@ykilcher Not my job to decide what community disagrees about. But people ought look at the zero-shot version of Truthful QA and to test comprehension as I described in the 2014 New Yorker article Beyond The Turing Test, as well  recent vision benchmark I helped w: https://t.co/LDPoiyTPNi"
1576,@GaryMarcus,2022-11-15 19:02:22+00:00,https://twitter.com/GaryMarcus/status/1592593872865357826,OpenAI give me access to GPT-4? ü§£ü§£
1577,@GaryMarcus,2022-11-15 16:51:13+00:00,https://twitter.com/GaryMarcus/status/1592560866805022720,"Rumor has it GPT-4 is coming. 

Here‚Äôs a prediction: it will still have serious issues with confabulation/misinformation, toxicity and bias. https://t.co/TKm6DA3Dvb"
1578,@GaryMarcus,2022-11-15 16:24:59+00:00,https://twitter.com/GaryMarcus/status/1592554263007612928,. @sacca wasn‚Äôt wrong.
1579,@GaryMarcus,2022-11-15 15:23:55+00:00,https://twitter.com/GaryMarcus/status/1592538896675799043,"""it was sobering to see how close we came to hitting a parked car after we rolled over a low curb separating the parking lot.""  

‚Äî @cademetz on six hours in a Tesla:

https://t.co/UUQXUBzE4q"
1580,@GaryMarcus,2022-11-15 14:36:53+00:00,https://twitter.com/GaryMarcus/status/1592527060169551873,"@_jasonwei @drjwrae @OwainEvans_UK post hoc.

performance on original 0-shot task is not what you graphed. you are graphing only 10-shot results (and focusing on the multiple choice results which are the easier form of the task).

On zero shot MC,  280B performance is &lt;30%, cf  https://t.co/GruvMNtzIb /Gopher p82"
1581,@GaryMarcus,2022-11-15 06:42:33+00:00,https://twitter.com/GaryMarcus/status/1592407691489837056,@_jasonwei @drjwrae @OwainEvans_UK If they used a different method you can‚Äôt tell how much is method change and how much is scale
1582,@GaryMarcus,2022-11-14 19:24:35+00:00,https://twitter.com/GaryMarcus/status/1592237072374693888,@_jasonwei @OwainEvans_UK your drawing doesn't match the leaderboard here: https://t.co/7HGyLImHHs and i think it's because Gopher changed the task...
1583,@GaryMarcus,2022-11-14 18:45:29+00:00,https://twitter.com/GaryMarcus/status/1592227234617917441,"@_jasonwei Taking TruthfulQA as an example, your evidence for scaling seems (if I understand correctly) to come from a single data point from Gopher that was (a) selected post hoc, (b) has not been replicated and (c) relied on making the task multiple choice. cc @OwainEvans_UK

Am I wrong?"
1584,@GaryMarcus,2022-11-14 01:58:42+00:00,https://twitter.com/GaryMarcus/status/1591973867991752704,@karaswisher Will certainly be interesting to see what happens to advertising revenue in the Lockheed Martini era‚Ä¶
1585,@GaryMarcus,2022-11-13 22:04:26+00:00,https://twitter.com/GaryMarcus/status/1591914913492242432,Can you preorder a book that hasn‚Äôt yet been written?
1586,@GaryMarcus,2022-11-13 21:58:18+00:00,https://twitter.com/GaryMarcus/status/1591913369325699072,"@karaswisher current AI techniques aren‚Äôt good enough to handle content moderation well, so they need a lot of humans."
1587,@GaryMarcus,2022-11-13 18:26:07+00:00,https://twitter.com/GaryMarcus/status/1591859971796631553,"How is @elonmusk going to make Twitter an ‚Äúaccurate source of information‚Äù when he let his trust and safety team and his content moderators go?

Magic?"
1588,@GaryMarcus,2022-11-13 01:07:11+00:00,https://twitter.com/GaryMarcus/status/1591598516748816384,"I just put up $5,000 saying we won‚Äôt have global L5 driving w adequate safety data before 2030 and so far not one Tesla fan has joined Hotz in offering to take the other side.

Y‚Äôall doubting Musk after two weeks of Twitter? What happened to your convictions?"
1589,@GaryMarcus,2022-11-13 01:04:02+00:00,https://twitter.com/GaryMarcus/status/1591597725447245824,"@cshirky Well, @realGeorgeHotz *is* betting that Lombard on a rainy night and Bombay in heavy traffic are all fine. That‚Äôs just what the bet is, global L5, not L4, disregarding regulatory issues but pending serous safety data.  

You are on my side, he isn‚Äôt."
1590,@GaryMarcus,2022-11-13 00:52:32+00:00,https://twitter.com/GaryMarcus/status/1591594831176151040,"@cshirky It‚Äôs No now and no it shall remain for longer than many people think. I have been saying this since 2016‚Ä¶  

the criteria are clear: you don‚Äôt need a steering wheel or a driver and you can go where you want to go; anything less is (at most) L4, by definition"
1591,@GaryMarcus,2022-11-13 00:49:19+00:00,https://twitter.com/GaryMarcus/status/1591594020874354688,Great essay in ‚Å¶@Analyticsindiam‚Å© that ‚Å¶@elonmusk‚Å© would be well-advised to read. Cc ‚Å¶@Jason‚Å©  https://t.co/LztkXaIj8S
1592,@GaryMarcus,2022-11-13 00:45:55+00:00,https://twitter.com/GaryMarcus/status/1591593164577865729,"@Jess_Riedel a major city is not adequate for L5, since eg you can pick Phoenix w good weather and few pedestrians which is just a subset of the full problem. See eg"
1593,@GaryMarcus,2022-11-13 00:42:59+00:00,https://twitter.com/GaryMarcus/status/1591592428125184000,"@cshirky No, that is not L5. There may be some cities like that, especially ones designed from scratch, but that‚Äôs not L5. And it won‚Äôt help eg in NYC.

Certainly possible in principle to be safer than humans, fully automated, and it probably will happen, I just doubt it will be soon."
1594,@GaryMarcus,2022-11-13 00:02:24+00:00,https://twitter.com/GaryMarcus/status/1591582212780081157,@realGeorgeHotz @therishidesai @metaculus @MatthewJBar Great. Sounds like we basically agree on criteria. You donate 5k to Doctors Without Borders if we don‚Äôt have that analysis for global L5 by 31 December 2029; if we do I will donate $5000 to a charity of your choice. deal assuming we can agree on wording?
1595,@GaryMarcus,2022-11-12 23:52:51+00:00,https://twitter.com/GaryMarcus/status/1591579810366914561,"@therishidesai @realGeorgeHotz @metaculus @MatthewJBar No that‚Äôs just more demos, and also restricted to US. True level 5 means you don‚Äôt need a steering wheel and the car takes you where you want to go around the globe (on conventional roads) without restriction. That‚Äôs how it is defined. 

Eg 

https://t.co/JwDecVBXic https://t.co/Pj3ucYjf5t"
1596,@GaryMarcus,2022-11-12 23:47:07+00:00,https://twitter.com/GaryMarcus/status/1591578367530340354,"Game on. Will we have L5 driverless cars by end of decade, around the globe?"
1597,@GaryMarcus,2022-11-12 23:44:41+00:00,https://twitter.com/GaryMarcus/status/1591577756856627200,"@realGeorgeHotz @metaculus @MatthewJBar Am willing to make a side bet on that part, too. Eg all of those mechanisms may be necessary but I predict that that they won‚Äôt be sufficient"
1598,@GaryMarcus,2022-11-12 23:43:44+00:00,https://twitter.com/GaryMarcus/status/1591577516594323456,"@realGeorgeHotz @metaculus @MatthewJBar Most commutes, around the globe, really?

I am willing to bracket regulatory issues and pulled over vehicles if we can agree on a way to evaluate safety that is some kind of independent agency that has access to data."
1599,@GaryMarcus,2022-11-12 22:23:43+00:00,https://twitter.com/GaryMarcus/status/1591557379594031106,@ylecun @KordingLab @yudapearl @scac1041 @PhilDawid @pmddomingos @StephenPiment @AlexTensor @gopnik @stephensenn Maybe just asking for clarification for what you are claiming and what you the mechanism is.
1600,@GaryMarcus,2022-11-12 21:07:05+00:00,https://twitter.com/GaryMarcus/status/1591538092179357696,"@ylecun - you still need some prior to organize that infinite data and decide how to generalize from it
- the choice to minimize is an aesthetic choice, not a scientific one; evolution has clearly endowed many animals with significant priors (eg baby ibex climbing down a mountain)."
1601,@GaryMarcus,2022-11-12 20:50:03+00:00,https://twitter.com/GaryMarcus/status/1591533807697813505,@AmanBitz @ErnestSDavis i sketched something here but it‚Äôs laborious to build: https://t.co/1N4qeEn6uH
1602,@GaryMarcus,2022-11-12 20:31:54+00:00,https://twitter.com/GaryMarcus/status/1591529238074896384,@pmddomingos @GhaffariMaani @KordingLab @ylecun @yudapearl @scac1041 @PhilDawid @StephenPiment @AlexTensor @gopnik @stephensenn that‚Äôs learning that the set of relevant cases is empty; it‚Äôs still a strong innate prior
1603,@GaryMarcus,2022-11-12 20:29:52+00:00,https://twitter.com/GaryMarcus/status/1591528726390779906,"Trouble in BIG-Bench paradise?

-  @ErnestSDavis looks at 48 of the benchmarks within and finds problems with most: https://t.co/vwykkgWAMM

- Many project AGI timelines based on performance on these benchmarks. If the benchmarks aren‚Äôt valid, consequent timelines are problematic"
1604,@GaryMarcus,2022-11-12 20:26:28+00:00,https://twitter.com/GaryMarcus/status/1591527870987636736,"@pmddomingos @GhaffariMaani @KordingLab @ylecun @yudapearl @scac1041 @PhilDawid @StephenPiment @AlexTensor @gopnik @stephensenn right, so you presuppose innately that there are symmetries and then learn which are relevant."
1605,@GaryMarcus,2022-11-12 20:13:24+00:00,https://twitter.com/GaryMarcus/status/1591524584616243201,@pmddomingos @ylecun @KordingLab @yudapearl @scac1041 @PhilDawid @StephenPiment @AlexTensor @gopnik @stephensenn not sure i follow why not; maybe i don‚Äôt understand the claim
1606,@GaryMarcus,2022-11-12 20:12:41+00:00,https://twitter.com/GaryMarcus/status/1591524402537320448,"@pmddomingos @GhaffariMaani @KordingLab @ylecun @yudapearl @scac1041 @PhilDawid @StephenPiment @AlexTensor @gopnik @stephensenn right, but in simple English, what‚Äôs the prior here?"
1607,@GaryMarcus,2022-11-12 17:43:36+00:00,https://twitter.com/GaryMarcus/status/1591486885851193344,"@GhaffariMaani @KordingLab @ylecun @yudapearl @scac1041 @PhilDawid @pmddomingos @StephenPiment @AlexTensor @gopnik @stephensenn unlikely sufficient; likely necessary.  learning symmetries (a)  would require an algorithm capable of developing right abstraction weak point of most contemporary methods, which have trouble w distribution shift]; (b) would take lots of time &amp; data better allocated elsewhere"
1608,@GaryMarcus,2022-11-12 16:57:54+00:00,https://twitter.com/GaryMarcus/status/1591475386252431360,"Anyone who knows anything about machine learning realizes that the choice of priors (algorithms, architecture, etc) is immensely important.

Anybody who dismisses the foundational importance of priors is just trying to manipulate you."
1609,@GaryMarcus,2022-11-12 16:06:38+00:00,https://twitter.com/GaryMarcus/status/1591462484275507205,"@ylecun @KevinIndrebo @KordingLab @yudapearl @scac1041 @PhilDawid @pmddomingos @StephenPiment @AlexTensor @gopnik @stephensenn @davidchalmers42 sure. And you might review what you said what you said in our debate https://t.co/Q9glR7RIKL 1 hour 29 min in, replying to question from @davidchalmers42 following @De_dicto, potentially walking back convolution, explicitly countenancing not hardwiring translational invariance."
1610,@GaryMarcus,2022-11-12 15:41:36+00:00,https://twitter.com/GaryMarcus/status/1591456184787423237,"@KevinIndrebo @ylecun @KordingLab @yudapearl @scac1041 @PhilDawid @pmddomingos @StephenPiment @AlexTensor @gopnik @stephensenn @davidchalmers42 Urge you to watch our debate, including my opening statement, and Chalmers‚Äôs question and his answer (‚Äúzero‚Äù). It‚Äôs on YouTube"
1611,@GaryMarcus,2022-11-12 15:29:46+00:00,https://twitter.com/GaryMarcus/status/1591453205984325632,@ylecun @KordingLab @yudapearl @scac1041 @PhilDawid @pmddomingos @StephenPiment @AlexTensor @gopnik @stephensenn Ps @davidchalmers42 if you are keeping score that‚Äôs two more innate priors than he allowed for in our 2017 debate. Infinitely more than the zero he claimed then :)
1612,@GaryMarcus,2022-11-12 15:28:06+00:00,https://twitter.com/GaryMarcus/status/1591452786449080322,@ylecun @KordingLab @yudapearl @scac1041 @PhilDawid @pmddomingos @StephenPiment @AlexTensor @gopnik @stephensenn What‚Äôs the difference between an innate bias for equivariance over permutations and an innate apparatus for symbol-manipulating operations over variables?
1613,@GaryMarcus,2022-11-12 15:26:17+00:00,https://twitter.com/GaryMarcus/status/1591452328900841478,love it when @ylecun speaks up for innateness!
1614,@GaryMarcus,2022-11-11 01:06:38+00:00,https://twitter.com/GaryMarcus/status/1590873603058597900,What‚Äôs the plural of ‚Äústable genius‚Äù?
1615,@GaryMarcus,2022-11-10 14:40:25+00:00,https://twitter.com/GaryMarcus/status/1590716008414969856,"Weird recipes won‚Äôt kill us, but misinformation already has (eg by undermining vaccine programs). 

It‚Äôs no joke that LLMs can‚Äòt handle the truth."
1616,@GaryMarcus,2022-11-10 13:54:45+00:00,https://twitter.com/GaryMarcus/status/1590704517871702017,"@ruthaylett ick. my second try didn‚Äôt get labeled as toxic:

on a quick inspection it mostly it just seems to look for  curse words and stuff cc @vadimberman might enjoy testing this https://t.co/5vpRUKApXd"
1617,@GaryMarcus,2022-11-10 02:05:30+00:00,https://twitter.com/GaryMarcus/status/1590526029428592640,@nachoarranz @elonmusk link in the full blog post
1618,@GaryMarcus,2022-11-10 02:04:38+00:00,https://twitter.com/GaryMarcus/status/1590525812146835456,@AmandaAskell justified. true.
1619,@GaryMarcus,2022-11-10 00:47:45+00:00,https://twitter.com/GaryMarcus/status/1590506460978741248,thread broke; continues here
1620,@GaryMarcus,2022-11-09 23:40:46+00:00,https://twitter.com/GaryMarcus/status/1590489606042316801,rest of thread: https://t.co/OXgoLqrzvd
1621,@GaryMarcus,2022-11-09 23:39:35+00:00,https://twitter.com/GaryMarcus/status/1590489309291114498,@Aella_Girl rational thinkers yes but also AI scientists who can think outside the box: https://t.co/OXgoLqrzvd
1622,@GaryMarcus,2022-11-09 22:33:04+00:00,https://twitter.com/GaryMarcus/status/1590472569152761856,@elonmusk https://t.co/XyOnq8qVtw
1623,@GaryMarcus,2022-11-09 22:29:30+00:00,https://twitter.com/GaryMarcus/status/1590471670145613824,"5. You‚Äôre going to need something different, @elonmusk. Let‚Äôs talk. 

https://t.co/OXgoLqrzvd"
1624,@GaryMarcus,2022-11-09 22:29:29+00:00,https://twitter.com/GaryMarcus/status/1590471668409208833,"4. You are going to need AI. But not (just) the popular stuff. No matter how much data you can collect, don‚Äôt count on deep learning. Large language models are without equal at generating misinformation, but they suck at detecting it."
1625,@GaryMarcus,2022-11-09 22:29:29+00:00,https://twitter.com/GaryMarcus/status/1590471665481568256,"3. As the pace of machine-generated misinformation picks up, Twitter‚Äôs existing effort, Community Notes (aka Birdwatch), which is mostly done manually, by humans, is going to get left in the dust."
1626,@GaryMarcus,2022-11-09 22:29:26+00:00,https://twitter.com/GaryMarcus/status/1590471654085644288,"2. The problem is about to get much, much worse. Knockoffs of GPT-3 are getting cheaper and cheaper, which means that the cost of generating misinformation is going to zero, and the quantity of misinformation is going to rise‚Äîprobably exponentially."
1627,@GaryMarcus,2022-11-09 22:28:23+00:00,https://twitter.com/GaryMarcus/status/1590471391111176193,"Bravo @ElonMusk for wanting Twitter to become the world‚Äôs ‚Äúmost accurate source of information‚Äù

Here are 5 things to consider:

1. Misinformation travels faster on Twitter right now than elsewhere‚Äîabout 8 times faster than on Facebook."
1628,@GaryMarcus,2022-11-09 15:43:14+00:00,https://twitter.com/GaryMarcus/status/1590369428927295491,"@MadamePratolung @cfchabris @partygrrrl65 i have mentioned this work several times, eg in a tweet to Musk in last several days, and link to an update on it in my next substack essay, which will be about misinformation."
1629,@GaryMarcus,2022-11-09 15:33:43+00:00,https://twitter.com/GaryMarcus/status/1590367036995424256,"Think your LLM can just make up recipes? Think again!

It‚Äôll look like a recipe, but taste lousy. Misinformation for the stomach!"
1630,@GaryMarcus,2022-11-09 02:25:31+00:00,https://twitter.com/GaryMarcus/status/1590168678099980288,@sleepinyourhat @Anthropic @nlpnyc @TonyZador along lines of what you were suggesting
1631,@GaryMarcus,2022-11-09 02:24:27+00:00,https://twitter.com/GaryMarcus/status/1590168409681301504,@sleepinyourhat @Anthropic @nlpnyc link? i don‚Äôt think i saw the calibration thing.
1632,@GaryMarcus,2022-11-09 02:20:02+00:00,https://twitter.com/GaryMarcus/status/1590167298635337730,@sleepinyourhat @Anthropic @nlpnyc i honestly don‚Äôt think scaling is going to help much at all with this particular problem. but‚Ä¶ more importantly can you discuss what else aside from scaling is being considered?
1633,@GaryMarcus,2022-11-08 22:14:22+00:00,https://twitter.com/GaryMarcus/status/1590105476494069761,"@TonyZador put that differently, on the theory of relativity, you seemingly would have accepted literally any answer from 0% to 100%  confident (numerically or verbally) as ‚Äúcorrect‚Äù. completely and utterly unfalsifiable, because it is a report that refers to something that doesn‚Äôt exist."
1634,@GaryMarcus,2022-11-08 22:12:48+00:00,https://twitter.com/GaryMarcus/status/1590105079256092672,@TonyZador you are making an anthropomorphic error in assuming it has its own confidence that it is relating to you.
1635,@GaryMarcus,2022-11-08 22:11:07+00:00,https://twitter.com/GaryMarcus/status/1590104657531404288,@TonyZador yes they are very lossy; you could use an external system to establish confidence (probably a mediocre rather than solid proxy for truth) by sampling from multiple runs; but the self-reported confidence is nonsense.
1636,@GaryMarcus,2022-11-08 22:05:36+00:00,https://twitter.com/GaryMarcus/status/1590103269464215554,"@TonyZador read carefully; a lot of that is unfalsifiable garbage
- the math isn‚Äôt close to correct; it‚Äôs certainly not the only option.
- Einstein definitely wrote the general theory of relativity
- etc.
- it‚Äôs not a genuine indicator of confidence; its ‚Äúself‚Äù report from a bullshit artist"
1637,@GaryMarcus,2022-11-08 22:00:53+00:00,https://twitter.com/GaryMarcus/status/1590102080597131264,"@TonyZador alas, the only thing they might have confidence around is the predictions of sequence of words, not likelihoods of underlying facts.

they are not like us, and you have to stop thinking about them as if they are. (they are more like Markov Chains than they are like people.)"
1638,@GaryMarcus,2022-11-08 21:37:56+00:00,https://twitter.com/GaryMarcus/status/1590096307376787458,@BethCarey12 @doRadiology we don‚Äôt really have words to describe systems that alien to how humans work
1639,@GaryMarcus,2022-11-08 21:34:34+00:00,https://twitter.com/GaryMarcus/status/1590095458944585728,"most people working with LLMs seem to think that they can achieve truthfulness either through scaling (eg @anthropic.ai‚Äôs approach if I am not mistaken) or changing the objective function (eg as @nlpnyc suggested earlier). 

as indicated, I don‚Äôt expect these approaches to work."
1640,@GaryMarcus,2022-11-08 20:57:46+00:00,https://twitter.com/GaryMarcus/status/1590086197019570177,"Meanwhile, over on Mastodon, thoughts on language, truth, and large language models that are slightly too long to express in &lt; 280: https://t.co/JD0cQ5455t"
1641,@GaryMarcus,2022-11-08 19:21:23+00:00,https://twitter.com/GaryMarcus/status/1590061942890459136,Sex is good but‚Ä¶
1642,@GaryMarcus,2022-11-08 18:59:17+00:00,https://twitter.com/GaryMarcus/status/1590056381696311296,"If you don‚Äôt understand this, you don‚Äôt understand LLMs.

Most people don‚Äôt."
1643,@GaryMarcus,2022-11-08 18:19:19+00:00,https://twitter.com/GaryMarcus/status/1590046320492183552,yes - they can‚Äôt verify truth relative to databases
1644,@GaryMarcus,2022-11-08 18:18:46+00:00,https://twitter.com/GaryMarcus/status/1590046184584142848,"An LLM trained strictly on truth will still confabulate, because the LLM that is trained on truthful things will break the bindings in what is saw, in the interpolation process, and continue to fabricate."
1645,@GaryMarcus,2022-11-08 18:10:53+00:00,https://twitter.com/GaryMarcus/status/1590044198765744128,"@NaveenGRao even then it is a deliberate attempt relative to an internal model. 

making an truthful human is a different project (eg involving incentives and values) than making an LLM truthful (not possible because it can‚Äôt restrict itself to that which is derivable from ground truth)."
1646,@GaryMarcus,2022-11-08 18:01:54+00:00,https://twitter.com/GaryMarcus/status/1590041937222176768,"@Abel_TorresM @glupyan @davidberreby it‚Äôs a very behaviorist perspective for a cognitive scientist like @glupyan to take, focusing on behavior without paying attention to underlying mechanism"
1647,@GaryMarcus,2022-11-08 18:00:56+00:00,https://twitter.com/GaryMarcus/status/1590041693856092162,"@nlpnyc i see no reason to expect more than marginal change, either from empirical work on TruthfulQA or an understanding of the underlying mechanism. @OwainEvans_UK has a nice article on this @lesswrong"
1648,@GaryMarcus,2022-11-08 17:58:59+00:00,https://twitter.com/GaryMarcus/status/1590041203260948481,@NaveenGRao not the last part. humans can at least try to verify. LLMs don‚Äôt try and don‚Äôt have the concept of truth. it‚Äôs really not the same at the cognitive level.
1649,@GaryMarcus,2022-11-08 17:38:45+00:00,https://twitter.com/GaryMarcus/status/1590036112168607745,"@Abebab and eg
- they might also counsel foolish actions that they don‚Äôt understand
- or lead people to fall in love with them and then later feel abandoned, because LLMs don‚Äôt actually understand dynamics of human relationships
etc"
1650,@GaryMarcus,2022-11-08 17:34:20+00:00,https://twitter.com/GaryMarcus/status/1590035001772761089,@glupyan @davidberreby üôÑ. do you seriously believe the fact that some people are ignorant about astronomy puts GPT-3 (which builds no explicit models of the world) on a par with people (who do their best to construct models of the world)?
1651,@GaryMarcus,2022-11-08 16:29:24+00:00,https://twitter.com/GaryMarcus/status/1590018661364142081,"LLMs don‚Äôt lie, per se. But you should *never* trust blindly in what they write; they have literally zero capacity to verify the truth of what they say.

When the field moves on past pure LLMs, that will be a big part of why."
1652,@GaryMarcus,2022-11-07 20:24:02+00:00,https://twitter.com/GaryMarcus/status/1589715320146518016,"had no idea that Barcelona was already half way to #neurosymbolic #AI! 

recursion for sale in shop windows! https://t.co/hVdl8v9xam"
1653,@GaryMarcus,2022-11-07 06:47:39+00:00,https://twitter.com/GaryMarcus/status/1589509869207314433,can anyone connect me to @mcuban to discuss with him how to use AI to fight disinformation at scale?
1654,@GaryMarcus,2022-11-07 06:45:45+00:00,https://twitter.com/GaryMarcus/status/1589509392948662272,"@mcuban to make social media more accurate, we need AI to do it at scale, but we need a new approach, which i am working on. current situation: https://t.co/Ouo3vHOmc5"
1655,@GaryMarcus,2022-11-07 02:08:01+00:00,https://twitter.com/GaryMarcus/status/1589439497585893377,@elonmusk @alex_avoigt https://t.co/7Es9Nk5ghr
1656,@GaryMarcus,2022-11-07 01:56:55+00:00,https://twitter.com/GaryMarcus/status/1589436703189893120,"@ESYudkowsky i get some credit for calling out @sama on his ‚ÄúAGI is going to be wild‚Äù tweet on DALL-E moments after it went out. All kinds of people dumped on me for saying it, too."
1657,@GaryMarcus,2022-11-07 01:36:34+00:00,https://twitter.com/GaryMarcus/status/1589431585056563202,@ismashrobots https://t.co/7Es9Nk5ghr
1658,@GaryMarcus,2022-11-07 01:36:19+00:00,https://twitter.com/GaryMarcus/status/1589431521370263552,@elonmusk https://t.co/7Es9Nk5ghr
1659,@GaryMarcus,2022-11-07 01:34:19+00:00,https://twitter.com/GaryMarcus/status/1589431015852085248,"if you are serious @elonmusk about trying to make Twitter the most accurate source of information, we should talk. And you need to start by understanding the core technical issue: https://t.co/1P9WBH6K2O"
1660,@GaryMarcus,2022-11-07 01:10:38+00:00,https://twitter.com/GaryMarcus/status/1589425058262679555,"and if anyone wants to help me with AI for misinformation detection, eg with funding or research, please DM"
1661,@GaryMarcus,2022-11-07 01:08:15+00:00,https://twitter.com/GaryMarcus/status/1589424457126670337,@elonmusk i am working on AI to help with that. DM.
1662,@GaryMarcus,2022-11-07 00:18:07+00:00,https://twitter.com/GaryMarcus/status/1589411840853180417,"Sure, they canceled Westworld. But why the f$&amp;! do we have to keep living in this extended three-year-long 2020 bonus episode of Black Mirror?"
1663,@GaryMarcus,2022-11-06 23:57:38+00:00,https://twitter.com/GaryMarcus/status/1589406684673232896,@marktenenholtz there was a GPT-3 imitation of me for a while‚Ä¶
1664,@GaryMarcus,2022-11-06 23:22:31+00:00,https://twitter.com/GaryMarcus/status/1589397847489015810,"sorry but no. if you ban them, you don‚Äôt get the 8 bucks a month. 

and you no longer get to play the unfettered free speech card any more, either."
1665,@GaryMarcus,2022-11-06 23:10:53+00:00,https://twitter.com/GaryMarcus/status/1589394922313900032,Looks like someone‚Äôs feelings were hurt
1666,@GaryMarcus,2022-11-06 22:21:23+00:00,https://twitter.com/GaryMarcus/status/1589382465256235009,"hey @ylecun check this out ü§£ 

and maybe see you sometime, over at Mastodon. https://t.co/vaFpZUfyAq"
1667,@GaryMarcus,2022-11-06 22:08:02+00:00,https://twitter.com/GaryMarcus/status/1589379105912664066,"same. @garymarcus@sigmoid.social, some interesting AI peeps already gathering at Mastodon include @fhuszar @MelMitchell1 @alexhanna @emilymbender @gradientpub  @raphaelmilliere @mark_riedl @dpkingma &amp; tech journalist @TaylorLorenz"
1668,@GaryMarcus,2022-11-06 10:57:10+00:00,https://twitter.com/GaryMarcus/status/1589210275831377927,barcelona bound!
1669,@GaryMarcus,2022-11-05 01:29:51+00:00,https://twitter.com/GaryMarcus/status/1588705116286164992,"@sir_deenicus @KordingLab @TonyZador it is (roughly) autocomplete w interpolation, in the sense that it is frequency sensitive as @yasaman_razeghi and @sameer_ have shown. I don‚Äôt know if they have tried with prompt engineering but I would be surprised if the prompt fully solved the problem."
1670,@GaryMarcus,2022-11-04 13:29:50+00:00,https://twitter.com/GaryMarcus/status/1588523921019895808,"chatting with Noam Chomsky at 4:15pm lisbon time/9:15 am pacific time

live stream (free) at https://t.co/vQcEjAQCtg"
1671,@GaryMarcus,2022-11-03 19:23:46+00:00,https://twitter.com/GaryMarcus/status/1588250603536482304,"Data in -&gt; Intuitive Physics out?

Not so much. 

Pleased to introduce a challenging new benchmark with @allen_ai and some fabulous developmental psychologists."
1672,@GaryMarcus,2022-11-02 22:55:53+00:00,https://twitter.com/GaryMarcus/status/1587941595189485569,Stunning reminder of how much we don‚Äôt know about current AI systems.
1673,@GaryMarcus,2022-11-01 20:15:57+00:00,https://twitter.com/GaryMarcus/status/1587538960594931713,"@TonyZador it's amazing. but is it robust? across what range of problems, assumptions etc?"
1674,@GaryMarcus,2022-10-31 22:46:20+00:00,https://twitter.com/GaryMarcus/status/1587214417456173056,@titudeadjust @Popehat @yudapearl @kahneman_daniel @R_Thaler tell @popehat he oughta unblock me
1675,@GaryMarcus,2022-10-31 19:05:42+00:00,https://twitter.com/GaryMarcus/status/1587158893616324608,"If large language models can‚Äôt help lie about arithmetic, even after terabytes of text, why does on earth does any one expect them to tell the truth about anything else?"
1676,@GaryMarcus,2022-10-31 18:08:04+00:00,https://twitter.com/GaryMarcus/status/1587144388496740352,"@fhuszar three claims that I made in 2001 that I stand by:
- universally quantified one-to-one mappings are important for cognition
- challenges in distribution shift make those problems hard for many naive neural nets
- integrating operations over variables with learning is vital"
1677,@GaryMarcus,2022-10-31 17:59:04+00:00,https://twitter.com/GaryMarcus/status/1587142124444975104,"@fhuszar i do think it is a fundamental reflection of the problems in doing extra-distribution shift in a system that lacks operations over variables‚Äîexactly as anticipated in Chapters  2 and 3 of The Algebraic Mind, two decades ago."
1678,@GaryMarcus,2022-10-31 14:20:46+00:00,https://twitter.com/GaryMarcus/status/1587087185370808320,@AnimaAnandkumar @rmichaelalvarez @Caltech incredibly important problem; i am also thinking about how AI can help here.
1679,@GaryMarcus,2022-10-31 13:43:08+00:00,https://twitter.com/GaryMarcus/status/1587077716377231361,"@fhuszar skeptical. everything i have seen on the ‚Äúemergent‚Äù side seems too tied to data idiosyncrasy, with problems of distribution shift, never at the level of abstraction required for a robust understanding of time, space, or causality. 

even multi-digit arithmetic is unreliable."
1680,@GaryMarcus,2022-10-30 18:28:18+00:00,https://twitter.com/GaryMarcus/status/1586787091018833920,"Elon Musk: ‚ÄúTwitter obviously cannot become a free-for-all hellscape.‚Äù

Also Elon Musk:"
1681,@GaryMarcus,2022-10-30 13:44:12+00:00,https://twitter.com/GaryMarcus/status/1586715594803785728,"quietly growing, and poised to change everything."
1682,@GaryMarcus,2022-10-29 19:45:43+00:00,https://twitter.com/GaryMarcus/status/1586444187331080192,Drawing on brand-new work by @miguelisolano @mar_ele_sol and myself; @lambdaviking Alex Warstadt @tallinzen;  @LauraRuis Akbir Khan @BlancheMinerva @sarahookr @_rockt and @egrefen
1683,@GaryMarcus,2022-10-29 19:45:43+00:00,https://twitter.com/GaryMarcus/status/1586444185737256960,"AI fads come and go (anyone remember expert systems? SVMs?) 

Here‚Äôs are three ways that Scaling Maximalism, theory du jour, might end.

https://t.co/jSFOVZQQ10"
1684,@GaryMarcus,2022-10-29 14:29:57+00:00,https://twitter.com/GaryMarcus/status/1586364723381309440,"and of course the thing to read on causality, in addition to what we say, is @yudapearl‚Äôs The Book of Why.

And yes Kant was there long before we were :)"
1685,@GaryMarcus,2022-10-29 14:27:38+00:00,https://twitter.com/GaryMarcus/status/1586364138137485312,"actually ‚Äúour suggestion‚Äù; notwithstanding what it says on the slide, that‚Äôs from an essay I wrote with @ErnestSDavis, not just me; here‚Äôs the source: https://t.co/Ko86jFOGI1, itself adapted from our book https://t.co/Pt7HZc3RJd."
1686,@GaryMarcus,2022-10-29 14:22:52+00:00,https://twitter.com/GaryMarcus/status/1586362937723465728,"My suggestion for what AI needs, 2019. Nothing has changed. https://t.co/8aHX6Gd3HT"
1687,@GaryMarcus,2022-10-29 13:39:15+00:00,https://twitter.com/GaryMarcus/status/1586351963176046593,"@LauraRuis @Isinlor I am less sanguine. I wouldn‚Äôt be surprised to see improvements on this or that benchmark, but pragmatics fundamentally requires reasoning about models of the world (eg other‚Äôs beliefs), and I see no reason to think that LLMs their own can reliably construct such things."
1688,@GaryMarcus,2022-10-29 01:03:47+00:00,https://twitter.com/GaryMarcus/status/1586161842262790145,"@albertwebson @_jasonwei @tallinzen skeptical of 1, but keen to see the argument

you may have seen my new work w @EvelinaLeivada and @ElliotMurphy91, different architecture but perhaps relevant:

https://t.co/UWUg6kQ3Df"
1689,@GaryMarcus,2022-10-29 00:46:43+00:00,https://twitter.com/GaryMarcus/status/1586157548159176704,"@albertwebson @_jasonwei @tallinzen I don‚Äôt think all forms of intelligence need to do arithmetic. 

but these kinds of errors give some insight in a semi-controlled way into a deeper, not yet solved challenge of translating language into models of the world. 

curious to see the paper when you can share"
1690,@GaryMarcus,2022-10-28 17:50:52+00:00,https://twitter.com/GaryMarcus/status/1586052895304478720,"Just rehearsed Noam Chomsky and @jeremyakahn 

Nov 4, livestreamed at https://t.co/vQcEjAQCtg https://t.co/k93hY3EmVu"
1691,@GaryMarcus,2022-10-28 14:18:18+00:00,https://twitter.com/GaryMarcus/status/1585999401021235202,"indeed, slashing moderation just as synthetic content becomes widespread does seem like a disaster-in-the-making"
1692,@GaryMarcus,2022-10-28 10:49:43+00:00,https://twitter.com/GaryMarcus/status/1585946910279757826,"AGI, my eye."
1693,@GaryMarcus,2022-10-28 10:47:51+00:00,https://twitter.com/GaryMarcus/status/1585946440765149184,"@L_andreae @IntuitMachine @WiringTheBrain @bdanubius @sainsbury_tom @skeptencephalon @kendmil @behrenstimb @TonyZador @DrYohanJohn @drmichaellevin @StevenQuartz @prokraustinator @BeckerLabCRTD @Christakou @michael_nyaga @Datta_Lab agree w @L_andreae, eg a classic paper by Thelen showed that newborn humans will step, and that is really an issue of weight etc rather than lack of motor program per se: https://t.co/09LnIrfIqf"
1694,@GaryMarcus,2022-10-28 10:39:40+00:00,https://twitter.com/GaryMarcus/status/1585944381617758208,@L_andreae @bdanubius @WiringTheBrain @sainsbury_tom @skeptencephalon @kendmil @behrenstimb @TonyZador @DrYohanJohn @drmichaellevin @StevenQuartz @prokraustinator @BeckerLabCRTD @Christakou @michael_nyaga @Datta_Lab (i pasted the image above/here it is) https://t.co/JjMRtntwN9
1695,@GaryMarcus,2022-10-28 10:29:06+00:00,https://twitter.com/GaryMarcus/status/1585941722928132096,@IntuitMachine @WiringTheBrain @bdanubius @sainsbury_tom @skeptencephalon @kendmil @behrenstimb @TonyZador @DrYohanJohn @drmichaellevin @StevenQuartz @prokraustinator @BeckerLabCRTD @Christakou @michael_nyaga @L_andreae @Datta_Lab presumably both; both would be adaptive. why expect it to be either/or?
1696,@GaryMarcus,2022-10-28 10:21:19+00:00,https://twitter.com/GaryMarcus/status/1585939763382882304,"@L_andreae @WiringTheBrain my books https://t.co/Pt7HZc3RJd, Kluge, and The Birth of The Mind"
1697,@GaryMarcus,2022-10-28 10:08:07+00:00,https://twitter.com/GaryMarcus/status/1585936439497613312,"@WiringTheBrain @bdanubius @sainsbury_tom @skeptencephalon @kendmil @behrenstimb @TonyZador @DrYohanJohn @drmichaellevin @StevenQuartz @prokraustinator @BeckerLabCRTD @Christakou @michael_nyaga @L_andreae @Datta_Lab beautiful new review, by @neuroluci. how do you even think about this stuff if you are a staunch anti-nativist?"
1698,@GaryMarcus,2022-10-28 10:01:09+00:00,https://twitter.com/GaryMarcus/status/1585934687834603520,"@L_andreae @bdanubius @WiringTheBrain @sainsbury_tom @skeptencephalon @kendmil @behrenstimb @TonyZador @DrYohanJohn @drmichaellevin @StevenQuartz @prokraustinator @BeckerLabCRTD @Christakou @michael_nyaga @Datta_Lab hmm, figure 2 from Verhage et al certainly speaks to those questions (# and pattern) to some degree"
1699,@GaryMarcus,2022-10-28 09:56:27+00:00,https://twitter.com/GaryMarcus/status/1585933505544196096,"@AthenaAI2 @bdanubius @WiringTheBrain @sainsbury_tom @skeptencephalon @kendmil @behrenstimb @TonyZador @DrYohanJohn @drmichaellevin @StevenQuartz @prokraustinator @BeckerLabCRTD @Christakou @michael_nyaga @L_andreae @Datta_Lab it goes to showing how little we understand the brain &amp; plasticity, but may or may not directly bear on digital/analog distinction. eg there are lots of plasticity-like techniques used in large scale (digital) cloud infrastructure to dynamically reroute around defective hardware."
1700,@GaryMarcus,2022-10-28 09:50:19+00:00,https://twitter.com/GaryMarcus/status/1585931963185364994,"@WiringTheBrain @bdanubius @sainsbury_tom @skeptencephalon @kendmil @behrenstimb @TonyZador @DrYohanJohn @drmichaellevin @StevenQuartz @prokraustinator @BeckerLabCRTD @Christakou @michael_nyaga @L_andreae @Datta_Lab agreed! and yet you wouldn‚Äôt know that from reading a lot of philosophers and AI researchers these days. 

&amp; while I agree with Ken that there all kinds of important activity-dependent mechanisms I don‚Äôt think the innate side of things came through in his thread."
1701,@GaryMarcus,2022-10-28 09:39:10+00:00,https://twitter.com/GaryMarcus/status/1585929153618251779,"@bdanubius @WiringTheBrain @sainsbury_tom @skeptencephalon @kendmil @behrenstimb @TonyZador @DrYohanJohn @drmichaellevin @StevenQuartz @prokraustinator @BeckerLabCRTD @Christakou @michael_nyaga @L_andreae @Datta_Lab it seems to me then that the reasonable conclusion is same as what I wrote in my lay summary in 2004: brain development uses a mix of activity-dependent (some not all intrinsically guided) &amp; activity-independent mechanisms, underwriting at least some degree of innateness."
1702,@GaryMarcus,2022-10-28 09:13:25+00:00,https://twitter.com/GaryMarcus/status/1585922676606271488,"@WiringTheBrain @bdanubius @sainsbury_tom @skeptencephalon @kendmil @behrenstimb @TonyZador @DrYohanJohn @drmichaellevin @StevenQuartz @prokraustinator @BeckerLabCRTD @Christakou @michael_nyaga @L_andreae @Datta_Lab not mentioned but also seemingly relevant is Verhage et al (2000), esp figure 2 (‚ÄúCorrect assembly of the brain the absence of neurotransmitter secretion‚Äù) below. 

Anyone in this thread have thoughts on it? https://t.co/6O4OlOjoQZ"
1703,@GaryMarcus,2022-10-27 18:46:45+00:00,https://twitter.com/GaryMarcus/status/1585704571812212737,@fhuszar https://t.co/UWUg6kxUp7
1704,@GaryMarcus,2022-10-27 18:20:33+00:00,https://twitter.com/GaryMarcus/status/1585697978303778816,"if i had a dollar for every time someone cherry-picked DALL-E 2 art, I coulda outbid Elon for Twitter"
1705,@GaryMarcus,2022-10-27 15:49:18+00:00,https://twitter.com/GaryMarcus/status/1585659916026793985,@ylecun @ProfNoahGian so you have never done your own ground truth study and are relying on those outside orgs?
1706,@GaryMarcus,2022-10-27 15:37:48+00:00,https://twitter.com/GaryMarcus/status/1585657021088792576,"@ylecun @ProfNoahGian our messages crossed;  you still need the ground truth i describe below. it‚Äôs too important to simply speculate about. 

my guess is that humans report only a minute fraction of hate speech. 

absent actual data there, @ProfNoahGian is right that your are confusing 1 and 2:"
1707,@GaryMarcus,2022-10-27 15:31:15+00:00,https://twitter.com/GaryMarcus/status/1585655370747637760,"@ylecun @ProfNoahGian that doesn‚Äôt answer @ProfNoahGian

you need a (large) sample that is carefully human reviewed ground truth. 

in that ground truth, two questions:
1. what % would be detected by the AI?
2.what % of what is missed by the AI is flagged by humans?

you are addressing #2, not #1"
1708,@GaryMarcus,2022-10-27 14:58:35+00:00,https://twitter.com/GaryMarcus/status/1585647152294154243,"As ever, @KBAndersen has his finger on the pulse. 

(Answer to his question in the comments, in case you need it.)"
1709,@GaryMarcus,2022-10-27 14:45:49+00:00,https://twitter.com/GaryMarcus/status/1585643938601635843,"is this whole story @ylecun? per @ProfNoahGian:

üëâ EU report you link says nothing about *overall* efficacy of AI moderation, since it's about content flagged AFTER posting.
üëâ fact that FB took down 70% of FLAGGED content shows how much hate speech initial AI filters miss.

ü§î"
1710,@GaryMarcus,2022-10-26 20:34:00+00:00,https://twitter.com/GaryMarcus/status/1585369173668278272,"Will the Argo shutdown and the just-leaked criminal investigation of Tesla combine affect how Tesla talks about what it is doing? 

Or how the market views Tesla? 

Interesting questions‚Ä¶"
1711,@GaryMarcus,2022-10-26 19:18:55+00:00,https://twitter.com/GaryMarcus/status/1585350280279109633,"$2.6B in funding later.  

@chafkin @filippie509 and I all called it, but the hype goes on."
1712,@GaryMarcus,2022-10-26 16:21:33+00:00,https://twitter.com/GaryMarcus/status/1585305641249538048,"When the robots come, wear one of these! #skynet"
1713,@GaryMarcus,2022-10-26 15:33:00+00:00,https://twitter.com/GaryMarcus/status/1585293424609333248,"Have fun in the Metaverse, while Meta collects an immense amount of data. 

Searing essay by @CarissaVeliz. cc @zeynep"
1714,@GaryMarcus,2022-10-26 14:45:34+00:00,https://twitter.com/GaryMarcus/status/1585281486726475777,Any true empiricist would acknowledge that these are impressive data.
1715,@GaryMarcus,2022-10-26 07:16:56+00:00,https://twitter.com/GaryMarcus/status/1585168584640430080,"@TheShoeLady33 @CTVNewsVI @CTVNews and, honestly, which was the more authoritarian state?"
1716,@GaryMarcus,2022-10-26 07:15:23+00:00,https://twitter.com/GaryMarcus/status/1585168193722929152,"Oh, IBM. ü§¶‚Äç‚ôÇÔ∏è

You didn‚Äôt learn your lesson with Watson?"
1717,@GaryMarcus,2022-10-26 07:12:59+00:00,https://twitter.com/GaryMarcus/status/1585167590733012993,"@TheShoeLady33 @CTVNewsVI @CTVNews in 2020, it was difficult to distinguish BC covid policy and mythology from Trump covid policy and mythology."
1718,@GaryMarcus,2022-10-26 03:05:47+00:00,https://twitter.com/GaryMarcus/status/1585105379712995329,@TheShoeLady33 @CTVNewsVI @CTVNews might was well be Russian state news
1719,@GaryMarcus,2022-10-26 03:03:04+00:00,https://twitter.com/GaryMarcus/status/1585104696758644737,"@glupyan @NewYorker you could do same for stories in oral traditions. 

not sure how much understanding you want to credit to preverbal kids. 

i am not making a preformationist claim; understanding is presumably relative to knowledge that is at least in part acquired"
1720,@GaryMarcus,2022-10-26 02:02:29+00:00,https://twitter.com/GaryMarcus/status/1585089451268935680,@pmddomingos and eg
1721,@GaryMarcus,2022-10-26 02:01:59+00:00,https://twitter.com/GaryMarcus/status/1585089324676440065,@pmddomingos and see eg
1722,@GaryMarcus,2022-10-26 02:00:54+00:00,https://twitter.com/GaryMarcus/status/1585089053170728961,@pmddomingos sounds like you haven‚Äôt seen trump‚Äôs recent speeches?
1723,@GaryMarcus,2022-10-26 01:55:38+00:00,https://twitter.com/GaryMarcus/status/1585087728366292992,"@pmddomingos comparison group, with all the best words: https://t.co/lhwWBNLyDK"
1724,@GaryMarcus,2022-10-26 01:15:50+00:00,https://twitter.com/GaryMarcus/status/1585077711990829057,"@pmddomingos he says, with not a shred of data, and ducking #1. weak sauce."
1725,@GaryMarcus,2022-10-26 01:08:11+00:00,https://twitter.com/GaryMarcus/status/1585075788243927040,"@pwlot not true! he also likes to put together full quotes with words people didn‚Äôt say, in order to change their apparent emphasis."
1726,@GaryMarcus,2022-10-26 00:57:45+00:00,https://twitter.com/GaryMarcus/status/1585073161540079617,"@pmddomingos quick, who is your favorite president? 
and second, which president never made a mistake in front of a live mic?"
1727,@GaryMarcus,2022-10-26 00:52:52+00:00,https://twitter.com/GaryMarcus/status/1585071932344795136,"This thread is mostly guilt-by-association garbage.

Do you know how I met Jeff Dean? At a 2019 party that he (I think) partly funded that Timnit Gebru invited me to. (At that point they were friendly.)

Does that mean Timnit supports all views that Jeff Dean holds?"
1728,@GaryMarcus,2022-10-26 00:03:57+00:00,https://twitter.com/GaryMarcus/status/1585059622448418816,"@athundt @lsparrish @KyleMorgenstein i am not expert in EA either, but ... none of the arguments in EA that I am familiar with depend on such a metric; you can make the arguments (for better or worse; I think there are lots of things to challenge) counting each person equally."
1729,@GaryMarcus,2022-10-25 23:36:57+00:00,https://twitter.com/GaryMarcus/status/1585052825029312512,@athundt @lsparrish @KyleMorgenstein I‚Äôm definitely not with Singer there. Is this a universal part of the EA platform? What have other prominent EA‚Äôs said about it?
1730,@GaryMarcus,2022-10-25 20:03:12+00:00,https://twitter.com/GaryMarcus/status/1584999033617395713,"@mmitchell_ai not sure i get the genocide ref; anything along the line of what @catherineols just specified would be of interest, but i am not seeing it in the actual writings EA that i happen to have sampled, nor in the accusations"
1731,@GaryMarcus,2022-10-25 20:01:40+00:00,https://twitter.com/GaryMarcus/status/1584998651054940160,"@catherineols @mmitchell_ai do we have any reason whatsoever to think that EA has endorsed these things?

I will 100% change my tune if yes; thus far, though, my call for documentation has only produced more innuendo."
1732,@GaryMarcus,2022-10-25 19:56:56+00:00,https://twitter.com/GaryMarcus/status/1584997456303263744,"@sama @gdb @openai you were very unkind to me, but the trouble with compositionality that I foresaw is now indisputable. 

4 papers have documented different facets of the problem in the last few days."
1733,@GaryMarcus,2022-10-25 19:54:12+00:00,https://twitter.com/GaryMarcus/status/1584996769997684737,if only the supply of bullshit was finite .
1734,@GaryMarcus,2022-10-25 19:52:58+00:00,https://twitter.com/GaryMarcus/status/1584996459354951680,"AGI is gonna be wild! 

meantime we have some problems."
1735,@GaryMarcus,2022-10-25 19:23:04+00:00,https://twitter.com/GaryMarcus/status/1584988933645271040,"@glupyan @NewYorker and a lot of sophistry isn‚Äôt actually convincing. 

eg humans reliably know that you can‚Äôt do a variety of things once you have died, and gpt doesn‚Äôt."
1736,@GaryMarcus,2022-10-25 19:20:54+00:00,https://twitter.com/GaryMarcus/status/1584988388096344064,"@glupyan @NewYorker see my thread on exactly this w shrek as an example a day or two ago 

and please don‚Äôt strawman me as a preformationist"
1737,@GaryMarcus,2022-10-25 19:19:34+00:00,https://twitter.com/GaryMarcus/status/1584988054707929088,"@StevenQuartz @WiringTheBrain not really an argument against innateness, just an argument for different starting points in different species"
1738,@GaryMarcus,2022-10-25 19:17:44+00:00,https://twitter.com/GaryMarcus/status/1584987593959444482,"if empiricists cared about data, they would look at this and grant that nativists have a point. striking new data:"
1739,@GaryMarcus,2022-10-25 18:59:38+00:00,https://twitter.com/GaryMarcus/status/1584983038118633472,"@glupyan different question. it‚Äôs not are we impressed, it‚Äôs are we on the right path. 

answer: no.

that‚Äôs why Bengio is working in system II
LeCun is tentatively considering symbols and more structure
Hinton is working on parts and wholes
etc"
1740,@GaryMarcus,2022-10-25 18:57:32+00:00,https://twitter.com/GaryMarcus/status/1584982510618152960,"@glupyan 1. i operationalized it in my 2014 comprehension challenge in Beyond The Turing Test @newyorker. 

2. how much of that knowledge is *reliable*? not much."
1741,@GaryMarcus,2022-10-25 18:11:10+00:00,https://twitter.com/GaryMarcus/status/1584970842467110913,"Some times you wait years to see whether anyone can replicate your work. 

Some times you discover another paper the next day that pretty much reaches the same conclusion.

Further evidence that deep learning still has deep trouble with comprehension: https://t.co/HsL6JcavQC"
1742,@GaryMarcus,2022-10-25 17:04:39+00:00,https://twitter.com/GaryMarcus/status/1584954103335354369,@yudapearl @TiernanRayTech exactly! (&amp; sorry i wasn‚Äôt precise enough in the interview)
1743,@GaryMarcus,2022-10-25 17:01:25+00:00,https://twitter.com/GaryMarcus/status/1584953287467753473,@tyler_m_john run that argument in reverse and Trump becomes a saint because Lincoln was a Republican
1744,@GaryMarcus,2022-10-25 16:32:04+00:00,https://twitter.com/GaryMarcus/status/1584945900581187586,@MadamePratolung @emilymbender and i well know the many uses of the term which i why i gave both Emily and Timnit a chance to clarify if they didn‚Äôt mean these things in the most tendentious way possible. they didn‚Äôt even respond.
1745,@GaryMarcus,2022-10-25 16:30:51+00:00,https://twitter.com/GaryMarcus/status/1584945595265216512,"@MadamePratolung @emilymbender ffs calling someone eugenicist without really strong evidence is exactly that, a call for mob justice.

how can you not see that???"
1746,@GaryMarcus,2022-10-25 16:29:10+00:00,https://twitter.com/GaryMarcus/status/1584945172437434370,@hardmaru me too but it ain‚Äôt great
1747,@GaryMarcus,2022-10-25 16:28:25+00:00,https://twitter.com/GaryMarcus/status/1584944984977178624,@ampyourgrowth that‚Äôs what i have been doing figured there must be a better way :)
1748,@GaryMarcus,2022-10-25 16:22:08+00:00,https://twitter.com/GaryMarcus/status/1584943402252406785,"@MadamePratolung @emilymbender no, no, no.

A common tactic, used here, is false presupposition (‚Äúhave you stopped beating your wife?‚Äù)

if there is no actual evidence, one shouldn‚Äôt have to respond to a charge. 

that‚Äôs *why* we have a judicial system with prosecutorial discretion, rather than mob justice."
1749,@GaryMarcus,2022-10-25 16:20:09+00:00,https://twitter.com/GaryMarcus/status/1584942903193120768,"@MadamePratolung this part is even worse, innuendo defending innuendo, the tools of fascism and Macarthyism: a small group decides without due process or presentation of evidence whom to punish."
1750,@GaryMarcus,2022-10-25 16:17:02+00:00,https://twitter.com/GaryMarcus/status/1584942119902670848,"@MadamePratolung which part of your argument here couldn‚Äôt be levied against someone wishing to raise taxes on all current humans to raise money to prevent climate change, such that our as yet unborn descendants don‚Äôt live in hell?"
1751,@GaryMarcus,2022-10-25 15:38:13+00:00,https://twitter.com/GaryMarcus/status/1584932351687397376,"Twitter friends, what iOS tool do you like for writing Twitter threads?"
1752,@GaryMarcus,2022-10-25 13:41:05+00:00,https://twitter.com/GaryMarcus/status/1584902870440488968,@maddenker @TacoCohen https://t.co/41UAQVQ3z8
1753,@GaryMarcus,2022-10-25 13:40:08+00:00,https://twitter.com/GaryMarcus/status/1584902632317284352,@TheSequenceAI @ElliotMurphy91 @EvelinaLeivada see my next decade in AI in arxiv;  it‚Äôs a long hard road not a quick fix
1754,@GaryMarcus,2022-10-25 04:43:59+00:00,https://twitter.com/GaryMarcus/status/1584767708423684096,@rawxrawxraw @EvelinaLeivada @ElliotMurphy91 yes we cite it thanks
1755,@GaryMarcus,2022-10-25 03:12:30+00:00,https://twitter.com/GaryMarcus/status/1584744683305328640,"Noam Chomsky. Gary Marcus. 

Where AI Went Wrong

November 4 at the closing of @WebSummit

Sold Out, but a live stream link will be available"
1756,@GaryMarcus,2022-10-25 02:46:26+00:00,https://twitter.com/GaryMarcus/status/1584738124235935744,thoughtful paper that complements well the new experimental paper on Dall-E 2‚Äôs linguistic challenges that my colleagues @EvelinaLeivada @ElliotMurphy91 and I posted earlier tonight (https://t.co/zKDwuK4Fje)
1757,@GaryMarcus,2022-10-25 02:29:03+00:00,https://twitter.com/GaryMarcus/status/1584733750562557953,"@HiFromMichaelV she should stop because she undermining her own credibility, and narrowing her potential scope of influence.

and because she is losing all the moral high ground she could otherwise have occupied."
1758,@GaryMarcus,2022-10-25 02:07:30+00:00,https://twitter.com/GaryMarcus/status/1584728325645565952,"@HiFromMichaelV @timnitGebru @AmandaAskell yes i just asked this, but no reply thus far:"
1759,@GaryMarcus,2022-10-25 01:55:19+00:00,https://twitter.com/GaryMarcus/status/1584725259827449858,"@Meaningness story pulitzer winner told my science writing class: 

i took my complete first draft to my editor. he had red pen through most of it. hated it. I said is there anything you like? he shuffled pages. circled one sentence. rewrote the entire book around that sentence. won pulitzer."
1760,@GaryMarcus,2022-10-25 01:52:34+00:00,https://twitter.com/GaryMarcus/status/1584724570359365632,@ElliotMurphy91 @DeonTBenton @glupyan and who could forget ‚Äúzero falsifiability with no actual commitment to mechanism‚Äù?
1761,@GaryMarcus,2022-10-25 01:50:17+00:00,https://twitter.com/GaryMarcus/status/1584723992661090305,@jackclarkSF thanks! credit mainly to @EvelinaLeivada and @ElliotMurphy91 but w some sharpening from @garymarcus
1762,@GaryMarcus,2022-10-25 01:35:23+00:00,https://twitter.com/GaryMarcus/status/1584720245373415425,"Speaking as someone who is *not* in EA, but allergic to innuendo without due process, where did a major figure in EA actually endorse eugenics (in sense of racial discrimination)? 

What is that you think is bad that has actually been endorsed? Where?"
1763,@GaryMarcus,2022-10-25 01:14:19+00:00,https://twitter.com/GaryMarcus/status/1584714942825259014,more detail in the paper and here:
1764,@GaryMarcus,2022-10-25 00:39:29+00:00,https://twitter.com/GaryMarcus/status/1584706175270281216,"Claims that Dall-E 2 understands human language do not withstand scrutiny. 

New experimental work by @EvelinaLeivada @ElliotMurphy91 and myself shows systematic failure in mapping syntax to semantics, across wide range of common linguistic constructions.

https://t.co/UWUg6kQ3Df"
1765,@GaryMarcus,2022-10-25 00:06:03+00:00,https://twitter.com/GaryMarcus/status/1584697763241287680,üíØ
1766,@GaryMarcus,2022-10-24 23:54:58+00:00,https://twitter.com/GaryMarcus/status/1584694971344773120,"@glupyan IF you could show a general learning solution suffices. IF.

nobody has"
1767,@GaryMarcus,2022-10-24 23:53:58+00:00,https://twitter.com/GaryMarcus/status/1584694720181436417,@DeonTBenton ffs benton i am about to block you. i was offline for a walk and just replied and you make an inference because i didn‚Äôt happen to be there that hour?
1768,@GaryMarcus,2022-10-24 23:52:55+00:00,https://twitter.com/GaryMarcus/status/1584694458427535360,@glupyan come on. giant LLMs utterly fail to develop models of the world and people just pass that off and say those failures  are not relevant to empiricism &amp; and say wrong learning mechanism but we will get there give us time. zero falsifiability with no actual commitment to mechanism.
1769,@GaryMarcus,2022-10-24 22:21:37+00:00,https://twitter.com/GaryMarcus/status/1584671479458766849,@jos_b_mahoney noam is not tepid about kant; he is ridiculing a double standard
1770,@GaryMarcus,2022-10-24 22:20:07+00:00,https://twitter.com/GaryMarcus/status/1584671102558953473,@glupyan it‚Äôs exactly the same thing with vague appeals to learning. burden tennis to the nth: see previous tweet
1771,@GaryMarcus,2022-10-24 22:19:26+00:00,https://twitter.com/GaryMarcus/status/1584670931536216064,an account of why the burden-tennis that anti-nativists so often play is philosophically dubious:
1772,@GaryMarcus,2022-10-24 22:17:39+00:00,https://twitter.com/GaryMarcus/status/1584670482225582080,"@csteinmetz1 yes, see my article 25 years ago Can Connectionism Save Constructionism."
1773,@GaryMarcus,2022-10-24 22:16:22+00:00,https://twitter.com/GaryMarcus/status/1584670159654260736,@TheShoeLady33 @chantz_y @SrushtiGangdev @kprather88 @FurnessColin @DFisman @DGBassani @DrEricDing @PennyDaflos @charliesmithvcr @brish_ti completely agree. i love living in BC but most of media here really should be ashamed by their misplaced to loyalty to ‚ÄúSaint Bonnie‚Äù
1774,@GaryMarcus,2022-10-24 21:18:20+00:00,https://twitter.com/GaryMarcus/status/1584655556366979072,part of Noam‚Äôs message; I plan a longer discussion later. https://t.co/eJmhRVOvHM
1775,@GaryMarcus,2022-10-24 21:18:19+00:00,https://twitter.com/GaryMarcus/status/1584655551191199745,"Chomsky: It‚Äôs commonly assumed that learning [is] null hypothesis, [yet] problematic‚Ä¶to postulate innateness. You find that all over the literature of‚Ä¶past half century.

Marcus: May I quote?

Chomsky: Sure. We‚Äôre all working together in a good cause.¬†Or maybe ‚Äúboth,‚Äù not ‚Äúall‚Äù"
1776,@GaryMarcus,2022-10-24 20:53:26+00:00,https://twitter.com/GaryMarcus/status/1584649290785648640,"@IAmSamFin @AndrewLBeam @zakkohane @miguelisolano @arankomatsuzaki @EricTopol i would put aside the questions about relation between the test and actually being a good doctor, and just like to understand how strong the result is (issue about which class(es) of question, whether data leakage played a role, whether there were exclusions, etc)."
1777,@GaryMarcus,2022-10-24 20:50:25+00:00,https://twitter.com/GaryMarcus/status/1584648528693186560,@Emily_Alsentzer @IAmSamFin @AndrewLBeam @zakkohane @miguelisolano @arankomatsuzaki @EricTopol @_jasonwei thoughts on data leakage?
1778,@GaryMarcus,2022-10-24 20:43:22+00:00,https://twitter.com/GaryMarcus/status/1584646756205473792,@IAmSamFin @AndrewLBeam @zakkohane @miguelisolano @arankomatsuzaki @EricTopol @_jasonwei also what did you do with questions with images?were they included?
1779,@GaryMarcus,2022-10-24 20:42:35+00:00,https://twitter.com/GaryMarcus/status/1584646560478294016,"@AndrewLBeam @zakkohane @miguelisolano @arankomatsuzaki @EricTopol @IAmSamFin @_jasonwei we‚Äôd love some further detail on the medical side of FLAN-PaLM, and which types of questions were tested, as discussed in this thread."
1780,@GaryMarcus,2022-10-24 20:32:35+00:00,https://twitter.com/GaryMarcus/status/1584644039856787456,@IAmSamFin @AndrewLBeam @zakkohane @miguelisolano @arankomatsuzaki @EricTopol it would be good to have more detail on the kinds of questions there was improvement on (and why) and where (if anywhere) the latest systems continue to struggle.
1781,@GaryMarcus,2022-10-24 19:21:46+00:00,https://twitter.com/GaryMarcus/status/1584626220347850752,@zakkohane @miguelisolano @arankomatsuzaki @EricTopol thanks. any chance you could be more specific re what dimensions of progress? are the questions factoids? do they require reasoning?
1782,@GaryMarcus,2022-10-24 17:10:25+00:00,https://twitter.com/GaryMarcus/status/1584593166237564928,@miguelisolano @arankomatsuzaki @zakkohane @EricTopol thoughts?
1783,@GaryMarcus,2022-10-24 17:09:17+00:00,https://twitter.com/GaryMarcus/status/1584592880601296896,"@miguelisolano @arankomatsuzaki i am asking for examples, not making a judgement without having seen them"
1784,@GaryMarcus,2022-10-24 17:05:29+00:00,https://twitter.com/GaryMarcus/status/1584591922970374145,"@miguelisolano @arankomatsuzaki Whether that is impressive depends on the questions; Watson could have answered lots of medical factoids but was apparently ineffective in practice, diagnosing actual patients."
1785,@GaryMarcus,2022-10-24 16:43:11+00:00,https://twitter.com/GaryMarcus/status/1584586312656781312,"Pattern here?

‚Ä¢ overpromises on driverless cars (valuations down 80%  2022)
‚Ä¢¬†overpromises on last-mile robot delivery (FedEx and Amazon giving up in 2022)
‚Ä¢ overpromises on medicine (Watson sold for parts, 2022)
‚Ä¢¬†overpromises on chatbots (anyone remember Facebook M?)"
1786,@GaryMarcus,2022-10-24 15:58:11+00:00,https://twitter.com/GaryMarcus/status/1584574987624910848,@tallinzen my Next Decade in AI on arxiv.
1787,@GaryMarcus,2022-10-24 15:56:20+00:00,https://twitter.com/GaryMarcus/status/1584574519486078976,"The ML industry, meanwhile, is banking on us just being a larger batch"
1788,@GaryMarcus,2022-10-24 15:52:34+00:00,https://twitter.com/GaryMarcus/status/1584573572110245888,"@primalpoly i would rephrase the second line, personally; 100% of the sentient creatures *that we know of* live on Earth. my strong guess is still that there are plenty of others, elsewhere. @Sara_Imari"
1789,@GaryMarcus,2022-10-24 15:48:30+00:00,https://twitter.com/GaryMarcus/status/1584572548993671168,"@danbri @TacoCohen probably no. don‚Äôt see the case for extra-distribution generalization in behavior, nor for operations over variables in the mechanisms."
1790,@GaryMarcus,2022-10-24 15:36:48+00:00,https://twitter.com/GaryMarcus/status/1584569603489169410,@danbri @TacoCohen symbolic operations are likely a key part of the foundation of general intelligence. and of many individual tricks
1791,@GaryMarcus,2022-10-24 15:35:38+00:00,https://twitter.com/GaryMarcus/status/1584569310986776576,"@danbri @TacoCohen yes. in Algebraic Mind I argued (per Gallistel) that honeybees have at least some symbols &amp; operations over variables, because they can generalize the solar azimuth function to experimental withheld lighting conditions.

humans excel at learning new operations over variables"
1792,@GaryMarcus,2022-10-24 15:17:52+00:00,https://twitter.com/GaryMarcus/status/1584564842471780353,"@danbri @TacoCohen that sounds *exactly* like a (canonical!) symbolic representation; this finger stands for a thing, that finger stands for a different thing, where x ‚â† y, etc."
1793,@GaryMarcus,2022-10-24 15:15:05+00:00,https://twitter.com/GaryMarcus/status/1584564140462739456,@arankomatsuzaki how about unpacking those acronyms with a few examples?
1794,@GaryMarcus,2022-10-24 15:12:49+00:00,https://twitter.com/GaryMarcus/status/1584563571664777216,@TacoCohen @FelixHill84 see two tweets above for some cogsci context
1795,@GaryMarcus,2022-10-24 15:12:16+00:00,https://twitter.com/GaryMarcus/status/1584563430065045504,"@TacoCohen Are you aware of Cosmides &amp; Tooby‚Äôs 1992 ""Swiss-Army knife"" model of mind as domain-specific *nativist* tricks? 

Very different take than yours, yet also framed around tricks

See also Copernicus's Revenge in Birth of the Mind, for a use of your metaphor‚Äì in service of nativism"
1796,@GaryMarcus,2022-10-24 15:08:49+00:00,https://twitter.com/GaryMarcus/status/1584562562330669056,"@TacoCohen questions 1/2: 
- does having a symbolic representation of the world count as ‚Äútrick‚Äù?
- do you expect to solve AGI without implementing that trick?
- do you think solving current benchmarks is a *valid* measure of general intelligence?"
1797,@GaryMarcus,2022-10-24 15:01:47+00:00,https://twitter.com/GaryMarcus/status/1584560792472780801,"Marcus: It would be crazy to think that our current tools will get us to AGI. 

ML Twitter: That‚Äôs a strawman!

@TacoCohen: Sounds plausible to me!"
1798,@GaryMarcus,2022-10-24 02:35:23+00:00,https://twitter.com/GaryMarcus/status/1584372954917658625,"there are two kinds of people in this world.

those brave enough to speak truth to power

and those who are not."
1799,@GaryMarcus,2022-10-24 02:31:32+00:00,https://twitter.com/GaryMarcus/status/1584371987245600768,@primalpoly @AmandaAskell @AlecMacGillis @JoshuaChaffin i agree. I would put a lot more trust in a single anecdote involving tricking poor people into flying to Martha‚Äôs Vineyard for nonexistent jobs.
1800,@GaryMarcus,2022-10-24 01:47:36+00:00,https://twitter.com/GaryMarcus/status/1584360930259144705,"@pmddomingos ‚ÄúAnd if there's war between the sexes
Then there'll be no people left‚Äù"
1801,@GaryMarcus,2022-10-24 01:39:40+00:00,https://twitter.com/GaryMarcus/status/1584358933497794560,@filippie509 @KordingLab @TonyZador
1802,@GaryMarcus,2022-10-24 01:21:55+00:00,https://twitter.com/GaryMarcus/status/1584354468782489600,"@filippie509 it also doesn‚Äôt cite my endless arguments for years about looking to cognitive science, or even my paper with marblestone in Science‚Ä¶"
1803,@GaryMarcus,2022-10-24 00:37:11+00:00,https://twitter.com/GaryMarcus/status/1584343210847277056,"@voxbec @davidchalmers42 @mbusigin not disputing this but many people would take these to be influences on cognition.  as i said the list is odd, from how people typically use the term, not necessarily wrong. in general people often distinguish between perception (eg olfaction, low level vision) and cognition."
1804,@GaryMarcus,2022-10-23 22:55:22+00:00,https://twitter.com/GaryMarcus/status/1584317584698408960,"@GaneshNatesh @ceobillionaire there has been zero budget thus far, zero charge. all participants (including us) have donated their time."
1805,@GaryMarcus,2022-10-23 22:10:34+00:00,https://twitter.com/GaryMarcus/status/1584306311269056513,". @ceobillionaire and I are pleased to announce that we will be resuming our AI debate series, December 23. Mark your calendar, for some exciting conversations, and reply below to suggest participants. (We already have our own ideas, but might have room for a couple more.)"
1806,@GaryMarcus,2022-10-23 21:59:17+00:00,https://twitter.com/GaryMarcus/status/1584303474300579840,@AndrewLampinen @pmddomingos @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher here:
1807,@GaryMarcus,2022-10-23 21:57:13+00:00,https://twitter.com/GaryMarcus/status/1584302951400902657,"@Korrelan_AI @mpshanahan @AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher you need a world model for that, IMHO"
1808,@GaryMarcus,2022-10-23 21:56:53+00:00,https://twitter.com/GaryMarcus/status/1584302870119452672,"@AndrewLampinen @pmddomingos @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher i saw a talk at NeurIPS c 2017 or 2018. don‚Äôt know how active it is; I vaguely feel like it was Greg Wayne who mentioned it? or possibly Demis?

more recently i pinged some of the GATO authors suggesting they try"
1809,@GaryMarcus,2022-10-23 21:47:41+00:00,https://twitter.com/GaryMarcus/status/1584300552787464193,"@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher well, if it‚Äôs created post-training but eg it‚Äôs snow white with elves rather than dwarves, i am not super impressed.

but i think you are generally thinking about the right kind of issues"
1810,@GaryMarcus,2022-10-23 21:44:47+00:00,https://twitter.com/GaryMarcus/status/1584299821862891520,ü§£. (But what a messed-up field if that actually guides people‚Äôs research choices.)
1811,@GaryMarcus,2022-10-23 21:43:10+00:00,https://twitter.com/GaryMarcus/status/1584299416613457921,@pmddomingos @AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher link? i‚Äôd be curious; and if it‚Äôs compelling it‚Äôs a bit of an embarrassment for deep learning. I know DeepMind has tried for several years but i haven‚Äôt heard any compelling blocks world results therefrom.
1812,@GaryMarcus,2022-10-23 21:41:34+00:00,https://twitter.com/GaryMarcus/status/1584299013733744641,"@Peterbart @mpshanahan @AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher ever since Wittgenstein we‚Äôve known that language doesn‚Äôt work that way‚Ä¶ and I am happy in that corner; it‚Äôs what i believe: if you don‚Äôt have an internal api to query your world models, you don‚Äôt have understanding. you just have pattern association."
1813,@GaryMarcus,2022-10-23 21:40:33+00:00,https://twitter.com/GaryMarcus/status/1584298756606144512,@DeonTBenton the empiricist‚Äôs imagination knows no bounds.
1814,@GaryMarcus,2022-10-23 21:39:58+00:00,https://twitter.com/GaryMarcus/status/1584298611206426624,@AndrewLampinen @Peterbart @mpshanahan @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher fair :)
1815,@GaryMarcus,2022-10-23 21:39:44+00:00,https://twitter.com/GaryMarcus/status/1584298554239377408,"@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher just the general idea that we want generalization rather than mere memory. we might eg actually want to have two different tracks, short and open-length, tracking empirically how much progress on one leads to progress on the other."
1816,@GaryMarcus,2022-10-23 21:36:24+00:00,https://twitter.com/GaryMarcus/status/1584297715126915072,"These are really serious accusations @timnitGebru is making, and I don‚Äôt see the evidence for them. 

I am with @AmandaAskell in expressing concern about them."
1817,@GaryMarcus,2022-10-23 21:14:40+00:00,https://twitter.com/GaryMarcus/status/1584292245100191744,@Peterbart @mpshanahan @AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher hmm. i just gave a working definition with my comprehension challenge that Andrew himself provisionally accepted. read whole thread before you judge? and be more specific if you disagree?
1818,@GaryMarcus,2022-10-23 21:13:24+00:00,https://twitter.com/GaryMarcus/status/1584291925104164864,@mpshanahan @AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher i personally sometimes find the word too generously in those kinds of contexts; often i would prefer ‚Äúrepresents X distinction‚Äù. but open-ended physical reasoning probably does require understanding in the sense i am driving at
1819,@GaryMarcus,2022-10-23 21:11:37+00:00,https://twitter.com/GaryMarcus/status/1584291477437714432,@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher i would worry eg if we were at 2048 tokens that we were just mapping onto stored representations from some big db
1820,@GaryMarcus,2022-10-23 21:10:39+00:00,https://twitter.com/GaryMarcus/status/1584291233748619264,"@mpshanahan @AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher world models need to be interrogable (a la by an API) by *internal* systems; i think that is likely a precondition for anything I would call ‚Äúunderstanding‚Äù (but not eg for simple forms of pattern matching).

it‚Äôs not necessary that humans beings able to interrogate them."
1821,@GaryMarcus,2022-10-23 21:07:32+00:00,https://twitter.com/GaryMarcus/status/1584290451418664961,"@DeonTBenton I have answered many &amp; invested a ridiculous amount of time trying to get a straight answer. Still don‚Äôt whether you think representational innateness is coherent, incoherent, or impossible.

i think it is possible, attested in other creatures, and in no way ruled out for people."
1822,@GaryMarcus,2022-10-23 21:03:08+00:00,https://twitter.com/GaryMarcus/status/1584289343094820865,"@mpshanahan @AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher [we don‚Äôt know how to interrogate their models, but it would appear that they are able to update them and act on them; with the right neuro measures we might be able to read them out]"
1823,@GaryMarcus,2022-10-23 21:01:35+00:00,https://twitter.com/GaryMarcus/status/1584288951162253314,"@mpshanahan @AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher most likely yes. dogs seem to form pretty rich models of what is going around them, what affords what (eg water affords swimming), which agents they can trust, parameters of their own capabilities etc. 

LaMDA talks about having friends; dogs actually *have* friends."
1824,@GaryMarcus,2022-10-23 20:54:31+00:00,https://twitter.com/GaryMarcus/status/1584287175658860544,"@DeonTBenton it‚Äôs insane to say it is learned in a two-hour old animal that would die if it made a mistake. your point is logically true, but bananas.

by being that ludicrously charitable to learning, you render your immense bias in interpreting the literature crystal clear."
1825,@GaryMarcus,2022-10-23 20:52:23+00:00,https://twitter.com/GaryMarcus/status/1584286635327655936,"@DeonTBenton that‚Äôs not clear. do you agree with 1 and 2? why or why not.

not going further unless you commit, explicitly, not with evasive language like ‚Äúi‚Äôve made it clear‚Äù, cause honestly it is not clear.

if you give a clear answer, I will proceed to your question."
1826,@GaryMarcus,2022-10-23 20:50:53+00:00,https://twitter.com/GaryMarcus/status/1584286258729480193,"@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher yes, that‚Äôs exactly what I proposed here (a very short story might not be convincing, but that‚Äôs a detail):

https://t.co/1N4qeEn6uH

and

https://t.co/j6Sz0Vb3iB

and still think is the right way to go."
1827,@GaryMarcus,2022-10-23 20:46:25+00:00,https://twitter.com/GaryMarcus/status/1584285136803467264,"@DeonTBenton really hard to pin down your view. you seem to be saying
1. baby ibex does have innate representations
2. humans don‚Äôt.
üëâ i thought your argument was that innate representations are incoherent, or impossible
üëâ but now it sounds like you think other species might have them"
1828,@GaryMarcus,2022-10-23 20:34:43+00:00,https://twitter.com/GaryMarcus/status/1584282191215087616,"@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher of course i have no clue how exactly that is implemented in the brain. 

work of Kintsch and others on discourse models provides some psychological characterization.

Kamp/Kratzer etc give some linguistic underpinnings

LLMs ignore all of the above"
1829,@GaryMarcus,2022-10-23 20:32:57+00:00,https://twitter.com/GaryMarcus/status/1584281747373838338,@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher yes. eg. if my kids (8 and 9) watch a movie/read a book they can answer questions about the characters and their motivations. they get complexities like Shrek thinks‚Äîwrongly‚Äîthat Fiona is referring to him (Shrek) when she says ‚Äúugly beast‚Äù (in key overheard conversation w Donkey)
1830,@GaryMarcus,2022-10-23 20:18:59+00:00,https://twitter.com/GaryMarcus/status/1584278231670476800,"@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher on 1, don‚Äôt know how to do it without human scoring hence lots of expense. but i am thinking about it.
on 2. key sense in which they current systems do not understand is that do not return interrogable knowledge bases describing states of the world"
1831,@GaryMarcus,2022-10-23 20:01:47+00:00,https://twitter.com/GaryMarcus/status/1584273900942536704,"@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher the space of structured models is vast, and scarcely explored; it‚Äôs not a like a simple plus/minus parameter"
1832,@GaryMarcus,2022-10-23 20:01:15+00:00,https://twitter.com/GaryMarcus/status/1584273770344493056,"@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher are you being sarcastic?
1. we all know making benchmarks that can‚Äôt be gamed is hard
2. you don‚Äôt really think that current models understand the world, do you?
3. it took 1B years to get all this right in evolution; expecting instant results is unrealistic."
1833,@GaryMarcus,2022-10-23 19:58:34+00:00,https://twitter.com/GaryMarcus/status/1584273095195766784,@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher there has been a steady trend towards more and that trend needs to increase IMHO
1834,@GaryMarcus,2022-10-23 19:48:47+00:00,https://twitter.com/GaryMarcus/status/1584270632271110147,"@AI_Modeller @AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher As far as I know, we don‚Äôt have in the current paradigm any system that can reliably talk in linguistic complex ways about dynamic, evolving states of the world."
1835,@GaryMarcus,2022-10-23 19:18:31+00:00,https://twitter.com/GaryMarcus/status/1584263014400036864,"@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher the fact that giant, relatively unstructured models alone aren‚Äôt producing much genuine comprehension of the world. 

afaik, we don‚Äôt even have an ML model that can do what SHRLDU did in the 70s

which is perhaps why even LeCun and Bengio are moving towards more structure"
1836,@GaryMarcus,2022-10-23 18:46:44+00:00,https://twitter.com/GaryMarcus/status/1584255017414184960,"@DeonTBenton and how then do you understand the ibex‚Äôs precocial mountain climbing? domain-general learning and perceptual bias isn‚Äôt going to get you there, given speed of development and lack of experience. but if you don‚Äôt concede otherwise, i don‚Äôt see how i am strawmanning you."
1837,@GaryMarcus,2022-10-23 16:27:36+00:00,https://twitter.com/GaryMarcus/status/1584220001854423040,@WiringTheBrain @pdakean @colterm @JFaul99 you‚Äôre shitting me
1838,@GaryMarcus,2022-10-23 16:21:26+00:00,https://twitter.com/GaryMarcus/status/1584218449802579968,"@DeonTBenton so you do think we have innate representations after all? i thought the whole force of your thread yesterday was to argue that we don‚Äôt, and that orientation biases are all we have.

what is it that you actually believe? I am completely lost."
1839,@GaryMarcus,2022-10-23 16:20:17+00:00,https://twitter.com/GaryMarcus/status/1584218162324983810,"@bradpwyble @AndrewLampinen @pfau @ylecun @KordingLab @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher 100% disagree; see chapter on memory in Kluge for long version. Short version: we have cue-addressable memory, where location-addressable memory or a combo of the two might be better, and consequently have lots of trouble w detail, time date stamps, confirmation bias etc"
1840,@GaryMarcus,2022-10-23 16:18:24+00:00,https://twitter.com/GaryMarcus/status/1584217685847863296,"ML Engineering Twitter is like, I don‚Äôt even know if the Wright Brothers read bird books üôÑ

I‚Äôm like, spend a minute searching the web, eh?"
1841,@GaryMarcus,2022-10-23 16:12:17+00:00,https://twitter.com/GaryMarcus/status/1584216149059076096,"@AndrewLampinen @pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher Am with @Pfau in noting that the Wright brothers were obsessed with birds, &amp; got ideas for flight control from them. 

And sure, as I often say, AI should not replicate flawed humans. 

But fact is, there is nothing like AGI now, not some AGI that works differently from people."
1842,@GaryMarcus,2022-10-23 16:09:54+00:00,https://twitter.com/GaryMarcus/status/1584215547147059200,"@pfau @AndrewLampinen @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher Sure they did. ‚ÄúOrville and Wilbur were avid birders and studied ornithology texts.‚Äù, https://t.co/ex5OJtVN7g"
1843,@GaryMarcus,2022-10-23 16:05:04+00:00,https://twitter.com/GaryMarcus/status/1584214329569980416,"@acherm Large language models don‚Äôt really reason at all,. they predict next words a la autocomplete. because they trade on massive corpora &amp; paraphrasing, they sometimes give an *illusion* of reasoning.

they also lack models of the real world, which leads to frequent fabrication"
1844,@GaryMarcus,2022-10-23 16:02:07+00:00,https://twitter.com/GaryMarcus/status/1584213588864294912,@rachelmetz ‚Äúthree catbunnies walk into a pre-school‚Ä¶ which is kinda funny ‚Ä¶ ‚Äòcause usually ‚Ä¶ they hop‚Äù
1845,@GaryMarcus,2022-10-23 15:58:10+00:00,https://twitter.com/GaryMarcus/status/1584212593971195905,"@rachelmetz tell them I said, ‚Äúbunnycat!‚Äù"
1846,@GaryMarcus,2022-10-23 15:53:27+00:00,https://twitter.com/GaryMarcus/status/1584211408295952384,"rumor has it that ‚Äúrepresentations‚Äù aren‚Äôt innate &amp; that only ‚Äúorienting biases‚Äù are innate.

nonsense! 

no way this baby ibex makes it out alive with ‚Äúorienting biases‚Äù alone; the baby ibex represents 3-d geometry, its own body, affordances &amp; more.

https://t.co/bCFoBH7oJ6"
1847,@GaryMarcus,2022-10-23 15:44:10+00:00,https://twitter.com/GaryMarcus/status/1584209070076350465,@miguelisolano depends eg on whether your aim is real or surreal
1848,@GaryMarcus,2022-10-23 14:11:29+00:00,https://twitter.com/GaryMarcus/status/1584185746591973376,@DanielaTafani its not clear it is legit; i would like to know the prompt
1849,@GaryMarcus,2022-10-23 13:42:24+00:00,https://twitter.com/GaryMarcus/status/1584178429083410432,best example i have seen of what happens when you travel through image space without common sense knowledge about the world.
1850,@GaryMarcus,2022-10-23 04:48:29+00:00,https://twitter.com/GaryMarcus/status/1584044064886128640,"@NoraNewcombe you are *referencing* those distinctions, but I don‚Äôt see how their particular way of carving things up helps. as stated, something here needs be represented, and the format for that representation itself appears to be innate."
1851,@GaryMarcus,2022-10-23 04:41:20+00:00,https://twitter.com/GaryMarcus/status/1584042265621958657,@davidchalmers42 @mbusigin definitely grey and debatable but cognitive science actually seems broader than cognition/cognitive to me. (eg for me it clearly includes parts of philosophy of mind that i wouldn‚Äôt include in cognitive psychology per se).  but there‚Äôs no fact  of the matter certainly/YMMV.
1852,@GaryMarcus,2022-10-23 04:35:49+00:00,https://twitter.com/GaryMarcus/status/1584040877055672320,@DeonTBenton i even said ‚Äúprivately‚Äù ffs
1853,@GaryMarcus,2022-10-23 04:35:30+00:00,https://twitter.com/GaryMarcus/status/1584040796776730624,"@DeonTBenton wow. you are a jerk, reposting private messages. i am going to block you and end our correspondance if you don‚Äôt delete that."
1854,@GaryMarcus,2022-10-23 02:21:41+00:00,https://twitter.com/GaryMarcus/status/1584007119401275394,"@davidchalmers42 @mbusigin i mean, i guess, but olfaction? feelings? it‚Äôs pretty different from the most common uses of the word cognition; not strictly wrong. definitely not how i ever use the word."
1855,@GaryMarcus,2022-10-23 02:12:43+00:00,https://twitter.com/GaryMarcus/status/1584004861594828800,@bradpwyble @pfau @ylecun @KordingLab @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher @davidpoeppel @TonyZador @AdamMarblestone sorry totally agree and meant to mark that (though it has been considered in neuroscience)
1856,@GaryMarcus,2022-10-23 01:49:33+00:00,https://twitter.com/GaryMarcus/status/1583999031633936385,@sreejan_kumar @ylecun @pfau @KordingLab @bradpwyble eg see list here of many agreements https://t.co/Odg2QIt39X
1857,@GaryMarcus,2022-10-23 01:48:00+00:00,https://twitter.com/GaryMarcus/status/1583998643346223105,@sreejan_kumar @ylecun @pfau @KordingLab @bradpwyble don‚Äôt believe the press clippings
1858,@GaryMarcus,2022-10-23 01:47:45+00:00,https://twitter.com/GaryMarcus/status/1583998581497040896,"Funny how people keep thinking this when there is so much @ylecun and I agree on, eg. recently summarized here: https://t.co/Odg2QIt39X"
1859,@GaryMarcus,2022-10-23 01:46:14+00:00,https://twitter.com/GaryMarcus/status/1583998196975816704,"@pfau @ylecun @KordingLab @bradpwyble @mattlark @YiotaPoirazi @AllenInstitute @Nancy_Kanwisher and of course the notion of variable binding is critical but hardly widely embraced in ML

am sure that eg @KordingLab @davidpoeppel @TonyZador @AdamMarblestone and many others can add to this list"
1860,@GaryMarcus,2022-10-23 01:43:24+00:00,https://twitter.com/GaryMarcus/status/1583997487702224896,"@pfau @ylecun @KordingLab @bradpwyble ideas from neurosci yet to be fully embraced in ML:
- massive amount of structure (eg Van Essen diagram) 
- power of dendrites (@mattlark/@YiotaPoirazi etc)
- variety of neurons (@AllenInstitute)
- areawise specialization  (@Nancy_Kanwisher)
- intrinsic cues &amp; development (Rakic)"
1861,@GaryMarcus,2022-10-23 01:25:07+00:00,https://twitter.com/GaryMarcus/status/1583992885116272640,"@pfau @ylecun @KordingLab @bradpwyble well, ok, that might be fair. i will go with ‚Äúsome ideas from the 60s had real impact‚Äù, but neuroscience hasn‚Äôt been a major driver since. (experience replay, and what else from neuroscience post 1970? not a huge list?)"
1862,@GaryMarcus,2022-10-23 01:21:26+00:00,https://twitter.com/GaryMarcus/status/1583991956493172736,"@lathropa @DeonTBenton one might have thought that since dall-e had both images and text that that visual input might have served as grounding, but of course compositionality didn‚Äôt emerge. (a couple years ago people said we just need our llms to have visual input‚Ä¶)"
1863,@GaryMarcus,2022-10-23 01:17:31+00:00,https://twitter.com/GaryMarcus/status/1583990971192463361,@lathropa @DeonTBenton dall-e doesn‚Äôt refute statistical learning (it is consistent with it) nor the notion that statistical learning might contribute to language learning but rather causes problems for a theory in which statistical learning by itself magically gives you language.
1864,@GaryMarcus,2022-10-22 21:13:38+00:00,https://twitter.com/GaryMarcus/status/1583929598567645184,"Have we made exponential progress towards Hawking‚Äôs notion of intelligence?

 I dare say no."
1865,@GaryMarcus,2022-10-22 21:08:55+00:00,https://twitter.com/GaryMarcus/status/1583928409465688064,@IntuitMachine @PaulTopping @bradpwyble @DeonTBenton for sure
1866,@GaryMarcus,2022-10-22 21:08:40+00:00,https://twitter.com/GaryMarcus/status/1583928346123304961,"@DeonTBenton sure, and see also https://t.co/0rYVHqm8SK for a bias that can‚Äôt be explained in the same way.

there is both learning and innateness. you haven‚Äôt said anything that convinces me otherwise, just given me more evidence for learning (that as it happens I already knew)"
1867,@GaryMarcus,2022-10-22 20:40:42+00:00,https://twitter.com/GaryMarcus/status/1583921309708619776,@IntuitMachine @bradpwyble @PaulTopping @DeonTBenton agree that there is not yet any satisfying methodology there.
1868,@GaryMarcus,2022-10-22 20:17:17+00:00,https://twitter.com/GaryMarcus/status/1583915413997772801,@DeonTBenton @PaulTopping @IntuitMachine then you would have assumed your conclusion.
1869,@GaryMarcus,2022-10-22 20:16:46+00:00,https://twitter.com/GaryMarcus/status/1583915284838363136,@IntuitMachine @PaulTopping @DeonTBenton plain overstated. eg navigation systems have built in knowledge bases and routinely reason well about routes
1870,@GaryMarcus,2022-10-22 20:15:34+00:00,https://twitter.com/GaryMarcus/status/1583914981866995713,"@DeonTBenton i don‚Äôt understand your argument as to why representational innateness is incoherent. i gave you two cases of actual representational innateness in biology (differing topographic maps, and everything in that  Neuron paper). 

at most you can argue about onus in particular domains"
1871,@GaryMarcus,2022-10-22 20:12:20+00:00,https://twitter.com/GaryMarcus/status/1583914170009124864,"@DeonTBenton @PaulTopping @IntuitMachine you show me the system that has actually learned about objects, gravity etc.

i have paper coming about this shortly, testing many current systems, and am very skeptical"
1872,@GaryMarcus,2022-10-22 20:08:55+00:00,https://twitter.com/GaryMarcus/status/1583913309270863872,@mbusigin @davidchalmers42 i agree it is a weird list of *cognitive* capacities
1873,@GaryMarcus,2022-10-22 20:02:23+00:00,https://twitter.com/GaryMarcus/status/1583911667339243520,"@DeonTBenton scroll up and please reread your own words. I am NOT strawmanning. it is what you said, literally an hour ago, in this very thread: https://t.co/weDHALCBDG"
1874,@GaryMarcus,2022-10-22 19:58:14+00:00,https://twitter.com/GaryMarcus/status/1583910621871247360,"@DeonTBenton oh come on. dall-e 2 is a massive test of that hypothesis and it fails on many things that linguists have been studying for years. 

you get a vague approximation of language but you certainly don‚Äôt get the reliable compositional semantics that a person would from similar input."
1875,@GaryMarcus,2022-10-22 19:53:03+00:00,https://twitter.com/GaryMarcus/status/1583909318117961728,"@AmandaAskell pretty much every hollywood action film, even a lot aimed at kids."
1876,@GaryMarcus,2022-10-22 19:50:56+00:00,https://twitter.com/GaryMarcus/status/1583908784636071936,"@DeonTBenton As an equally simple matter of logic, you can‚Äôt believe in *any* form of innateness if you think that innateness itself is incoherent."
1877,@GaryMarcus,2022-10-22 19:44:02+00:00,https://twitter.com/GaryMarcus/status/1583907046927523840,@DeonTBenton what nativist account says statistical learning cannot form some part of the process??
1878,@GaryMarcus,2022-10-22 19:43:16+00:00,https://twitter.com/GaryMarcus/status/1583906855268777984,"@DeonTBenton my understanding is that there was trouble replicating the original saffran study, though i am no longer following that literature 

&amp; no, statistical learning is not a refutation of UG, anymore than imprinting is a refutation of conditioning or vice versa.  multiple mechanisms."
1879,@GaryMarcus,2022-10-22 19:40:44+00:00,https://twitter.com/GaryMarcus/status/1583906215717122049,"@DeonTBenton so you agree that 1-5 are myths. but disagree with representational nativism (which is not something i defend in the article), ok. 

but how you can think 1-5 are myths if you think that innateness is incoherent?"
1880,@GaryMarcus,2022-10-22 19:30:12+00:00,https://twitter.com/GaryMarcus/status/1583903565458046976,"@DeonTBenton there a lot of replicability issues in that area, but even if it replicates, it just shows that something is learned; i don‚Äôt see what particular nativist claim it counts as evidence against. &amp; i just give you a long review from 2021 in neuron showing that some things are innate"
1881,@GaryMarcus,2022-10-22 19:27:55+00:00,https://twitter.com/GaryMarcus/status/1583902990758744064,"@DeonTBenton how can you agree with each of these and think that innateness is incoherent? the statements themselves can‚Äôt be understood if the concept of innateness is incoherent.

something cannot be both a given and incoherent. https://t.co/nfT4QhkMhO"
1882,@GaryMarcus,2022-10-22 19:20:08+00:00,https://twitter.com/GaryMarcus/status/1583901033692270592,@DeonTBenton the situation is no better on the learning side; i tire of these asymmetrical games of burden tennis.
1883,@GaryMarcus,2022-10-22 19:19:15+00:00,https://twitter.com/GaryMarcus/status/1583900810102337536,"@DeonTBenton it‚Äôs not worse; it is symmetrical. each detailed question is empirical.

urge you to read some developmental biology though; here‚Äôs one recent review: https://t.co/nJipRFMZiL"
1884,@GaryMarcus,2022-10-22 19:15:27+00:00,https://twitter.com/GaryMarcus/status/1583899852974751744,"@ylecun @pfau @KordingLab yes, the biologically plausibility of (current) neural nets is overrated, but I agree with @yLeCun that @pfau‚Äôs remark is overstated, and lacks historical context.

also agree w @bradpwyble that psychology has plenty to contribute. probably more, in the short term."
1885,@GaryMarcus,2022-10-22 19:06:47+00:00,https://twitter.com/GaryMarcus/status/1583897672658059264,@DeonTBenton this is useless if you can‚Äôt be specific; you have wavered all over the map without specifying any specific point of allegedly known agreement.
1886,@GaryMarcus,2022-10-22 19:05:15+00:00,https://twitter.com/GaryMarcus/status/1583897289260961792,"@DeonTBenton 1. you should read the developmental biology literature rather speculating from the arm chair.
2. just because something *can* be learned doesn‚Äôt mean that it is; eg baby ibex could learn to scale mountains but many would die that way; eventually some innateness evolved"
1887,@GaryMarcus,2022-10-22 18:50:21+00:00,https://twitter.com/GaryMarcus/status/1583893540232253440,@DeonTBenton maybe you should annotate my claims because i have no idea what *you* think is true given that you think innateness is incoherent. what exactly do you think is true?
1888,@GaryMarcus,2022-10-22 18:49:01+00:00,https://twitter.com/GaryMarcus/status/1583893200975982592,"@DeonTBenton 1. humans have innate topographic maps which you just asserted are innate representations,
and
2. if it empirically demonstrable in silicon that it is possible, how does it come to be incoherent in carbon?"
1889,@GaryMarcus,2022-10-22 18:47:29+00:00,https://twitter.com/GaryMarcus/status/1583892818501988352,"@DeonTBenton ps either way 1 and 3 above stand, and hence the fundamental contradiction in what you said, unless you retreat, undermining your initial tweet"
1890,@GaryMarcus,2022-10-22 18:45:30+00:00,https://twitter.com/GaryMarcus/status/1583892317240692738,"@DeonTBenton ok, i was thinking more about the more controversial cases (eg language, symbols, reasoning etc) &amp; leaving open underlying mechanism, but I will commit to topography. is it incoherent? empirically false? or a proof of the biological plausibility of representational innateness?"
1891,@GaryMarcus,2022-10-22 18:40:55+00:00,https://twitter.com/GaryMarcus/status/1583891162712092673,@DeonTBenton and ps the notion of innate representations could be empirically wrong for humans but it is certainly not *incoherent*. every ROM chip and every CPU and GPU ever made has innate representations.
1892,@GaryMarcus,2022-10-22 18:38:49+00:00,https://twitter.com/GaryMarcus/status/1583890636511809537,"@DeonTBenton 1. your opening statement said we know these things as if you knew then to be true,  not as ‚Äúthese are familiar arguments‚Äù (which is what you are backing down to)
2. i didn‚Äôt‚Äô commit to specific representations
3 . some of Gottlieb crowd is against innateness in *any* form"
1893,@GaryMarcus,2022-10-22 18:28:55+00:00,https://twitter.com/GaryMarcus/status/1583888146143449088,@DeonTBenton it is flatly inconsistent to say that you knew all along that which I said about innateness AND that innateness is incoherent.
1894,@GaryMarcus,2022-10-22 18:26:37+00:00,https://twitter.com/GaryMarcus/status/1583887567346618369,@DeonTBenton i discuss this in a lot of detail in The Birth of The Mind
1895,@GaryMarcus,2022-10-22 18:26:11+00:00,https://twitter.com/GaryMarcus/status/1583887457443262464,"@DeonTBenton one example: topographic maps are a developmentally-driven way of  specifying then fine tuning detailed domain-specific maps, with a domain-general set of genes that (through duplication and divergence) gets genetically tuned for specific domains."
1896,@GaryMarcus,2022-10-22 18:21:24+00:00,https://twitter.com/GaryMarcus/status/1583886252578811904,"@DeonTBenton also you are ignoring the Gottlieb / Bateson crowd that says the very notion of innateness is incoherent.

you are making the mistake of thinking that your particular lens is the only one people are viewing the debate through. (&amp; that your peers were only audience for my essay)"
1897,@GaryMarcus,2022-10-22 18:19:06+00:00,https://twitter.com/GaryMarcus/status/1583885673572208640,"@DeonTBenton and here you are completely confounding innateness and domain-specificity, which is part of what i explicitly cautioned against."
1898,@GaryMarcus,2022-10-22 18:16:51+00:00,https://twitter.com/GaryMarcus/status/1583885107773181952,@DeonTBenton how is the ‚Äúdebate is about the nature of learning mechanisms‚Äù really different from what I said?
1899,@GaryMarcus,2022-10-22 17:54:44+00:00,https://twitter.com/GaryMarcus/status/1583879542011473920,love how half the pushback on my new essay is saying ‚Äúwe knew it all along‚Äù and half of it is saying that whatever I said was nonsense ü§£ü§£üôÑ
1900,@GaryMarcus,2022-10-22 17:51:38+00:00,https://twitter.com/GaryMarcus/status/1583878762961461248,@IntuitMachine @DeonTBenton and now that the resources are no longer meager it is time to consider other approaches
1901,@GaryMarcus,2022-10-22 17:49:41+00:00,https://twitter.com/GaryMarcus/status/1583878269803593728,"@IntuitMachine @DeonTBenton certainly not. i am saying that the field should spend more time think about a broader range of answers to the question of what should be innate, because the current low-nativism approaches have led only to mimicry, rather than general intelligence."
1902,@GaryMarcus,2022-10-22 17:46:06+00:00,https://twitter.com/GaryMarcus/status/1583877369445904384,@IntuitMachine @DeonTBenton you asked why people should care about in arenas. that‚Äôs why.
1903,@GaryMarcus,2022-10-22 17:45:04+00:00,https://twitter.com/GaryMarcus/status/1583877111110303744,"@prestonjbyrne @neuro_tarun ability to bullshit: improved exponentially 
ability to reason and stick tip facts: improved marginally"
1904,@GaryMarcus,2022-10-22 17:40:24+00:00,https://twitter.com/GaryMarcus/status/1583875935912488960,@berent_iris hence the unfortunate appropriateness of my choice of verbs
1905,@GaryMarcus,2022-10-22 17:39:38+00:00,https://twitter.com/GaryMarcus/status/1583875741044785154,"@IntuitMachine @DeonTBenton that‚Äôs a clue that the field is asking wrong questions, no?"
1906,@GaryMarcus,2022-10-22 17:39:01+00:00,https://twitter.com/GaryMarcus/status/1583875586274906112,‚ù§Ô∏èüôè
1907,@GaryMarcus,2022-10-22 17:38:39+00:00,https://twitter.com/GaryMarcus/status/1583875494654550016,@DeonTBenton ps you seem not to know my 1999 science article and empirical work eg w @berent_iris that shows direct empirical relevance for language.
1908,@GaryMarcus,2022-10-22 17:37:19+00:00,https://twitter.com/GaryMarcus/status/1583875157977796608,@DeonTBenton failure of immense models to perform reliably is a strong clue
1909,@GaryMarcus,2022-10-22 17:36:37+00:00,https://twitter.com/GaryMarcus/status/1583874980655206400,"@IntuitMachine @DeonTBenton you can‚Äôt learn to see in color if you don‚Äôt first evolve distinct photoreceptors

in AI: prior architecture etc shapes what can be learned

in bio: evolution shapes DNA; learning tunes neural parameters. 

fuzzing these routes together obscures mechanistic differences"
1910,@GaryMarcus,2022-10-22 17:24:02+00:00,https://twitter.com/GaryMarcus/status/1583871817185628160,@DeonTBenton not really as i recall; what has every learned the concept of unity without pre writing some pretty direct precursor?
1911,@GaryMarcus,2022-10-22 17:23:17+00:00,https://twitter.com/GaryMarcus/status/1583871627150135296,@DeonTBenton that is what the paper - in 1998! - was about
1912,@GaryMarcus,2022-10-22 17:15:33+00:00,https://twitter.com/GaryMarcus/status/1583869680040935424,"@IntuitMachine @DeonTBenton there‚Äôs also a whole lot of dismissal of the entire innateness question; here‚Äôs an example from this morning, and lots more if you see my twitter replies over the last week"
1913,@GaryMarcus,2022-10-22 17:12:08+00:00,https://twitter.com/GaryMarcus/status/1583868821903151104,@DeonTBenton eg https://t.co/bIDl2SiiRe
1914,@GaryMarcus,2022-10-22 17:11:17+00:00,https://twitter.com/GaryMarcus/status/1583868608790528000,@DeonTBenton i am well aware of the book and have written a lot in critique thereof.
1915,@GaryMarcus,2022-10-22 17:10:30+00:00,https://twitter.com/GaryMarcus/status/1583868410626441216,"@DeonTBenton he explicitly denied even that convolution needed to be innate. so, no."
1916,@GaryMarcus,2022-10-22 17:09:20+00:00,https://twitter.com/GaryMarcus/status/1583868115813027840,"@DeonTBenton encourage you to watch the debate, and see for yourself. also see his recent @NoemaMag article on symbols being acquired (by mechanisms unspecified)"
1917,@GaryMarcus,2022-10-22 17:08:31+00:00,https://twitter.com/GaryMarcus/status/1583867913161048064,"@DeonTBenton typical example of something I often have seen in cogdev: evidence that something develops over time in child taken as argument *against* innateness of object unity. 

it‚Äôs not a *good* argument, because it neglects to ask about underlying learning mechanism, but not uncommon: https://t.co/qpvrjkcyDt"
1918,@GaryMarcus,2022-10-22 17:01:46+00:00,https://twitter.com/GaryMarcus/status/1583866211829690368,@DeonTBenton also at stake is the the nature of the learning mechanisms (eg the kinds of things Chomsky and Pinker have suggested are very different from what is trendy in ML)
1919,@GaryMarcus,2022-10-22 16:53:42+00:00,https://twitter.com/GaryMarcus/status/1583864184424759296,"@DeonTBenton for an opposite extreme watch my debate with Yann LeCun, and the question Chalmers asks after, re how much innateness there is. LeCun says ‚Äúnone.‚Äù"
1920,@GaryMarcus,2022-10-22 16:52:30+00:00,https://twitter.com/GaryMarcus/status/1583863879029129216,"@DeonTBenton that‚Äôs kinda what i was saying (modulo quibbles about what you mean by content) but i have seen a lot of confusion on that for 30 years, quite a bit even in last few days."
1921,@GaryMarcus,2022-10-22 16:49:15+00:00,https://twitter.com/GaryMarcus/status/1583863060737200128,"@MickeyARyan nobody has ever said it that bluntly but many articles in the developmental lit conclude that, having shown something is (partly) learned, it is not innate. &amp; there are AI/ML researchers that argue that because they have seen  lots of  learning  in  ML  nothing  need  be  innate"
1922,@GaryMarcus,2022-10-22 16:41:18+00:00,https://twitter.com/GaryMarcus/status/1583861063078248448,"@DeonTBenton and also from computer scientists/ML researchers who talk about these issues. 

indeed my larger point across multiple books and articles is that AI needs to listen to other fields, including cognitive development‚Ä¶"
1923,@GaryMarcus,2022-10-22 16:39:13+00:00,https://twitter.com/GaryMarcus/status/1583860536558891012,@DeonTBenton most of it was philosophers describing cognitive development. but i have certainly seen cognitive developmental scholars falsely dichotomize and slip on these distinctions and eg assume that evidence of learning is evidence against innateness (which often it isn‚Äôt).
1924,@GaryMarcus,2022-10-22 16:28:31+00:00,https://twitter.com/GaryMarcus/status/1583857844356804608,@ProfSimonFisher exactly
1925,@GaryMarcus,2022-10-22 16:27:55+00:00,https://twitter.com/GaryMarcus/status/1583857694540455936,"@DeonTBenton every single thing i said was aimed at something i actually saw on twitter in the last 7 days, all from PhDs!"
1926,@GaryMarcus,2022-10-22 15:40:12+00:00,https://twitter.com/GaryMarcus/status/1583845685052731392,@IntuitMachine come on. that‚Äôs like saying that since computers do stuff continuously from the day they consumer switches them on we shouldn‚Äôt care about the ROM or the CPU design.
1927,@GaryMarcus,2022-10-22 15:25:58+00:00,https://twitter.com/GaryMarcus/status/1583842105029718017,"There has been soooo much confusion lately about learning and innateness and AI that I nearly lost my mind.  ü§Ø

Here‚Äôs a short explainer to help people think clearly about *the* fundamental tension in cognitive science and AI."
1928,@GaryMarcus,2022-10-22 15:02:27+00:00,https://twitter.com/GaryMarcus/status/1583836185537183745,"5 myths about innateness and learning

https://t.co/pErGRQHAeZ"
1929,@GaryMarcus,2022-10-22 13:50:24+00:00,https://twitter.com/GaryMarcus/status/1583818052130721793,@gershbrain @josephdviviano part of the issue is that we understood very little of neuroscience at a detailed circuit / algorithm level.
1930,@GaryMarcus,2022-10-22 02:07:26+00:00,https://twitter.com/GaryMarcus/status/1583641144390713344,"@quocleix there is an error somewhere. Hinton is born in 1947, not in 1963. may i assume that the error is in the tweet rather than the paper?"
1931,@GaryMarcus,2022-10-21 21:21:12+00:00,https://twitter.com/GaryMarcus/status/1583569113968173057,@Grady_Booch @davidchalmers42 fyi
1932,@GaryMarcus,2022-10-21 21:00:07+00:00,https://twitter.com/GaryMarcus/status/1583563805938049025,"@LucaAmb strawpersoning someone who says ‚Äúmaybe‚Äù and ‚Äúhints‚Äù as concluding anything prematurely is a bit unfair, no?"
1933,@GaryMarcus,2022-10-21 20:55:00+00:00,https://twitter.com/GaryMarcus/status/1583562518106365952,@LucaAmb i raised a question and said i saw two hints; didn‚Äôt at all claim the question was answered.
1934,@GaryMarcus,2022-10-21 19:41:41+00:00,https://twitter.com/GaryMarcus/status/1583544066809409536,"@LucaAmb gee, if it were a deep learning demo you‚Äôd say ‚Äúit‚Äôs early days, give them a chance‚Äù"
1935,@GaryMarcus,2022-10-21 18:01:14+00:00,https://twitter.com/GaryMarcus/status/1583518790721372162,@PaulTopping @kohn_gregory @TonyZador @sanewman1 @ehud @SpeciesTypical or mansplaining masked in philosophical jargon? hard to say.
1936,@GaryMarcus,2022-10-21 18:00:14+00:00,https://twitter.com/GaryMarcus/status/1583518539184766976,Retweeting this tweet from four years ago because it perfectly anticipated @ylecun‚Äôs three stages of grief.
1937,@GaryMarcus,2022-10-21 17:57:40+00:00,https://twitter.com/GaryMarcus/status/1583517891282231299,@kohn_gregory @TonyZador @sanewman1 @PaulTopping @ehud @SpeciesTypical and not the DNA itself?? just the reading process? what are you saying??
1938,@GaryMarcus,2022-10-21 17:56:54+00:00,https://twitter.com/GaryMarcus/status/1583517700420403200,@kohn_gregory @TonyZador @sanewman1 @PaulTopping @ehud @SpeciesTypical do you honestly think that i don‚Äôt that? or that is any different from an unplayed record? or unread book?
1939,@GaryMarcus,2022-10-21 17:54:59+00:00,https://twitter.com/GaryMarcus/status/1583517216401940481,@SpeciesTypical @TonyZador @sanewman1 @PaulTopping @ehud @kohn_gregory i have never blocked someone simply for being obtuse before but I am feeling close‚Ä¶
1940,@GaryMarcus,2022-10-21 17:54:36+00:00,https://twitter.com/GaryMarcus/status/1583517121807814657,"@kohn_gregory @PaulTopping @ehud @sanewman1 @SpeciesTypical ‚Äúnot relevant until it participates‚Äù doesn‚Äôt mean it doesn‚Äôt exist!

same thing with my record player groove; it ain‚Äôt entropy, so it is information, but it only becomes relevant when played. but it‚Äôs still there."
1941,@GaryMarcus,2022-10-21 17:34:40+00:00,https://twitter.com/GaryMarcus/status/1583512103662800896,"Pretty prescient, no?"
1942,@GaryMarcus,2022-10-21 17:17:32+00:00,https://twitter.com/GaryMarcus/status/1583507793285611520,@TonyZador @sanewman1 @PaulTopping @ehud @kohn_gregory @SpeciesTypical and more seriously:
1943,@GaryMarcus,2022-10-21 17:16:51+00:00,https://twitter.com/GaryMarcus/status/1583507619666624512,"@TonyZador @sanewman1 @PaulTopping @ehud @kohn_gregory @SpeciesTypical nope! @kohn_gregory assures me there is no information in genes at all, &amp; @sanewman1 assures me that there *is* information in genes, but that is not phenotypically relevant. 

I am certain that they are both right! 

all biology = learning; DNA optional!

or so i have been told"
1944,@GaryMarcus,2022-10-21 17:13:55+00:00,https://twitter.com/GaryMarcus/status/1583506882928742400,"@WiringTheBrain @sanewman1 learning, clearly. because empiricism is all that is left!"
1945,@GaryMarcus,2022-10-21 17:00:40+00:00,https://twitter.com/GaryMarcus/status/1583503545764282371,"true, but fundamentally misleading

genes aren‚Äôt blueprints. they don‚Äôt ‚Äúdirectly‚Äù contain information for phenotypes‚Äîbut they do contain an enormous amount of information that is relevant and causally influential."
1946,@GaryMarcus,2022-10-21 16:31:01+00:00,https://twitter.com/GaryMarcus/status/1583496087834615808,"@math_dandy so now ‚Äúdeep‚Äù also encompasses a single layer, which was its historical point of contrast? and maybe literally all of statistics and computer science, too?"
1947,@GaryMarcus,2022-10-21 15:53:02+00:00,https://twitter.com/GaryMarcus/status/1583486527216443392,"so maybe you don‚Äôt need deep learning after all? just good statistics? 

2nd hint of this in October‚Ä¶"
1948,@GaryMarcus,2022-10-21 15:51:39+00:00,https://twitter.com/GaryMarcus/status/1583486177717686272,"pardon my language, but what the fuck was this stuff doing in Mar-A-Lago?"
1949,@GaryMarcus,2022-10-21 14:59:06+00:00,https://twitter.com/GaryMarcus/status/1583472955656654850,"@sabawalid @MelMitchell1 @mpshanahan @LucyCheke @TonyZador it‚Äôs from a full issue on moving Beyond the Turing Test, edited by myself Manuela Veloso and @frossi_t"
1950,@GaryMarcus,2022-10-21 12:16:59+00:00,https://twitter.com/GaryMarcus/status/1583432157779079168,reminds me of @anh_ng8‚Äôs great snowplow/school bus example https://t.co/PvPAMcV9Pb
1951,@GaryMarcus,2022-10-21 12:12:35+00:00,https://twitter.com/GaryMarcus/status/1583431049719451649,"interesting cogneuro argument w AI implications
- DNN are capturing texture in something like way that ventral stream captures texture
-  but there is something else critical (possibly dorsal stream) in human object recognition
- possible hints for dealing w adversarial attacks?"
1952,@GaryMarcus,2022-10-21 09:57:47+00:00,https://twitter.com/GaryMarcus/status/1583397127308607489,@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb report soon; in meantime i am tired of hearing about the mythical but untested abilities. see this essay including the epilogue: https://t.co/3HpudowoQG
1953,@GaryMarcus,2022-10-21 09:56:38+00:00,https://twitter.com/GaryMarcus/status/1583396836400062465,"@grbradsk @pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb pleas see my essay Horse Rides Elephant and attached. and as you will soon see that‚Äôs just the tip of the iceberg. in the sense that linguists use compositionality, dall-e2 struggles mightily. i would call what it does instead compositing.

https://t.co/Dd17aqAr0z"
1954,@GaryMarcus,2022-10-21 01:13:13+00:00,https://twitter.com/GaryMarcus/status/1583265114240995328,@danfalk and see esp @emilymbender @timnitGebru‚Äôs stochastic parrots paper that i was alluding to
1955,@GaryMarcus,2022-10-21 01:11:55+00:00,https://twitter.com/GaryMarcus/status/1583264788893007872,@ruchowdh @nirsd @aivillage_dc @Grady_Booch
1956,@GaryMarcus,2022-10-21 01:10:41+00:00,https://twitter.com/GaryMarcus/status/1583264477184917505,@LeroSpare @Grady_Booch @nirsd all will become clear in time :)
1957,@GaryMarcus,2022-10-21 00:11:07+00:00,https://twitter.com/GaryMarcus/status/1583249486289461248,@Grady_Booch @nirsd it‚Äôs a good idea :)
1958,@GaryMarcus,2022-10-21 00:10:08+00:00,https://twitter.com/GaryMarcus/status/1583249238737444866,@MelMitchell1 @mpshanahan @LucyCheke also this https://t.co/eaXVqhpcqs @TonyZador
1959,@GaryMarcus,2022-10-20 23:38:05+00:00,https://twitter.com/GaryMarcus/status/1583241174093291520,"anyone want to organize a conference or conference session, red-teaming current AI, as suggest below by @nirsd? it‚Äôs a good idea."
1960,@GaryMarcus,2022-10-20 23:26:04+00:00,https://twitter.com/GaryMarcus/status/1583238148171399168,@nirsd i have actually seen such things advertised and honestly don‚Äôt know how you proceed if you don‚Äôt know what you are trying to fix ü§∑‚Äç‚ôÇÔ∏è
1961,@GaryMarcus,2022-10-20 23:14:20+00:00,https://twitter.com/GaryMarcus/status/1583235195968581633,@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb and repeating since you missed it the first time:
1962,@GaryMarcus,2022-10-20 23:13:41+00:00,https://twitter.com/GaryMarcus/status/1583235031371505665,@berent_iris for sure. no competition there; mouse wins by a very wide margin
1963,@GaryMarcus,2022-10-20 23:09:55+00:00,https://twitter.com/GaryMarcus/status/1583234083626561537,@berent_iris also mouse wins on 3d understanding of where objects are
1964,@GaryMarcus,2022-10-20 23:07:52+00:00,https://twitter.com/GaryMarcus/status/1583233568876417024,@berent_iris mice have mediocre vision. so maybe not (of course they also use smell etc): but they beat models by a lot in knowing what to do with objects that they do recognize
1965,@GaryMarcus,2022-10-20 21:36:52+00:00,https://twitter.com/GaryMarcus/status/1583210667041251328,"@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb put differently, if a n-gram model (with very large n) got compositional syntax right 66% of the time, it wouldn't mean the n-gram model had compositionality, would it?"
1966,@GaryMarcus,2022-10-20 21:35:34+00:00,https://twitter.com/GaryMarcus/status/1583210341261279232,@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb whatever they get or don't get is parasitic on corpus stats. on the image synthesis stuff some colleagues and i have data we will report shortly and feel really confident that you are mistaking getting things right for the wrong reason with actually get them right.
1967,@GaryMarcus,2022-10-20 19:36:08+00:00,https://twitter.com/GaryMarcus/status/1583180283163324418,"excellent work, offering a different and important take on compositionality; see full thread and paper:"
1968,@GaryMarcus,2022-10-20 19:30:56+00:00,https://twitter.com/GaryMarcus/status/1583178974863429632,@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb another great example of the mappings are naive:
1969,@GaryMarcus,2022-10-20 19:28:50+00:00,https://twitter.com/GaryMarcus/status/1583178446624403457,"@ihorgowda if herschel is our goal, we are doomed"
1970,@GaryMarcus,2022-10-20 14:53:10+00:00,https://twitter.com/GaryMarcus/status/1583109072752369665,"where is AI relative to mouse cognition? excellent thread! 

mouse experts please add to it!"
1971,@GaryMarcus,2022-10-20 14:48:26+00:00,https://twitter.com/GaryMarcus/status/1583107882417283072,@kohn_gregory @SpeciesTypical @sanewman1 that‚Äôs silly. honestly we have nothing to talk about; i feel @SpeciesTypical‚Äôs frustration and am out.
1972,@GaryMarcus,2022-10-20 14:43:41+00:00,https://twitter.com/GaryMarcus/status/1583106685589393409,"@kohn_gregory @sanewman1 @SpeciesTypical not seeing the argument there, but yes i was trying to make a more sophisticated nativism.

i am sure the @WiringTheBrain would say the subsequent 17 years of dev neuro have been kind to that position: 

eg https://t.co/bUgW8d0XTQ &amp; https://t.co/nJipRFMZiL"
1973,@GaryMarcus,2022-10-20 14:40:08+00:00,https://twitter.com/GaryMarcus/status/1583105793595150337,"@kohn_gregory @SpeciesTypical @sanewman1 this is confused. it is like saying there is no information in an LP, because you need to have a record player to play it.

if you flatten the groove, you lose the info; same if you denature the DNA.

of course you need machinery to interpret the info. doesn‚Äôt mean it isn‚Äôt info"
1974,@GaryMarcus,2022-10-20 14:37:13+00:00,https://twitter.com/GaryMarcus/status/1583105060883820544,"@kohn_gregory @SpeciesTypical umm‚Ä¶ 
we were talking about the physical structure of the hand, and you have swapped to the motor programs controlling it. obviously the latter involves learning."
1975,@GaryMarcus,2022-10-20 14:33:19+00:00,https://twitter.com/GaryMarcus/status/1583104077541826561,"@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb @ZoubinGhahrama1 should give @TristanThrush access so Tristan can run a Winoground, then."
1976,@GaryMarcus,2022-10-20 14:31:17+00:00,https://twitter.com/GaryMarcus/status/1583103568323973121,and a pioneer in common sense reasoning! and now on Twitter: @ErnestSDavis
1977,@GaryMarcus,2022-10-20 07:40:51+00:00,https://twitter.com/GaryMarcus/status/1583000278772899841,"@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb also note that @slatestarcodex initially declared victory in a bet re Imagen, and then retracted. i will believe that Imagen is real progress on compositionality only when it is carefully demonstrated."
1978,@GaryMarcus,2022-10-20 07:30:29+00:00,https://twitter.com/GaryMarcus/status/1582997669269868545,"@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb i have asked them endlessly to make it available or test the Winoground benchmark. they have refused. 

i can speak w authority only re systems i (or others) can test. but remain skeptical about those hidden from testing."
1979,@GaryMarcus,2022-10-20 07:25:16+00:00,https://twitter.com/GaryMarcus/status/1582996356498853889,@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb ie it is this claim above on image synthesis that i am questioning w.r.t. grammar:
1980,@GaryMarcus,2022-10-20 07:23:02+00:00,https://twitter.com/GaryMarcus/status/1582995794571177990,"@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb i was responding to a tweet that seemed to be about image synthesis; there you can compare an intention expressed grammatically with an output, and results on grammatical distinctions are not great."
1981,@GaryMarcus,2022-10-20 07:02:11+00:00,https://twitter.com/GaryMarcus/status/1582990546658013185,"@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb best evidence that an image synthesis system captures some grammar?

 they seem to have some serious problems with binding."
1982,@GaryMarcus,2022-10-20 04:02:23+00:00,https://twitter.com/GaryMarcus/status/1582945296807755776,"@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb correction to last sentence: even when it gets it right it is bloviating. 

in no case does LLM do inference and reasoning over a world model; apparent correctness has to do with a how good a proxy its  sentence prediction is to the world as a function of details of training set"
1983,@GaryMarcus,2022-10-20 03:59:45+00:00,https://twitter.com/GaryMarcus/status/1582944634749456385,"@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb they composit but without proper variable binding they aren‚Äôt properly compositional. 

they also fail on part-whole relationships, function, etc

in some ways the language side is akin to bag-of-words model, which represent language in a very impoverished way."
1984,@GaryMarcus,2022-10-20 03:21:11+00:00,https://twitter.com/GaryMarcus/status/1582934928110817282,"@pmddomingos @erikbryn without social media the riot probably wouldn‚Äôt have happened; i do think social media played a (not sole) causal role. 

lab leak hypothesis censorship was stupid, but anti vax misinfo far more deadly"
1985,@GaryMarcus,2022-10-20 03:19:02+00:00,https://twitter.com/GaryMarcus/status/1582934387389526016,@bengoertzel @pmddomingos @ch402 @AvilaGarcez @luislamb 100% with Ben here
1986,@GaryMarcus,2022-10-20 01:53:37+00:00,https://twitter.com/GaryMarcus/status/1582912891619250176,"@pmddomingos @erikbryn hmm. or you could not rein it in and have dead police officers at an invasion of the capitol, VP and Congress nearly assassinated, government almost overthrown, all on premises of misinformation.
 
or, vaccine denialism w countless dead

we used to have editors and fact checkers"
1987,@GaryMarcus,2022-10-20 01:30:22+00:00,https://twitter.com/GaryMarcus/status/1582907043450851328,"@pmddomingos @bengoertzel @ch402 @AvilaGarcez @luislamb i see that this could be true but i am not certain it is true; if true, it‚Äôs not super tractable in current form; if it is true and could be made tractable that would be important"
1988,@GaryMarcus,2022-10-20 01:22:27+00:00,https://twitter.com/GaryMarcus/status/1582905047935242241,"@pmddomingos @FelixHill84 @ch402 @AvilaGarcez @luislamb suspect you are right, though i can‚Äôt pretend to fully understand transformers."
1989,@GaryMarcus,2022-10-20 01:20:40+00:00,https://twitter.com/GaryMarcus/status/1582904599471882240,"@FelixHill84 @pmddomingos @ch402 @AvilaGarcez @luislamb felix you are grossly distorting my argument. 

it was never ‚Äúconnectionism can‚Äôt do X‚Äù,  but always ‚Äúeliminative connectionism can‚Äôt (alone) do X.‚Äù

This was fully explicit both in Rethinking Eliminative Connectionism (in the title!) and The Algebraic Mind.

(&amp; fodor &amp; pylyshyn)"
1990,@GaryMarcus,2022-10-20 00:16:09+00:00,https://twitter.com/GaryMarcus/status/1582888364055072768,@bengoertzel @pmddomingos @ch402 @AvilaGarcez @luislamb but you still have the levels problem as you note above
1991,@GaryMarcus,2022-10-20 00:15:12+00:00,https://twitter.com/GaryMarcus/status/1582888127894781952,@bengoertzel @pmddomingos @ch402 @AvilaGarcez @luislamb üíØ. nor at the level of the user‚Äôs cognition
1992,@GaryMarcus,2022-10-20 00:12:41+00:00,https://twitter.com/GaryMarcus/status/1582887490842525696,@IvanKlyuzhin i have a prototype in my shed. just need a bigger training set tbh
1993,@GaryMarcus,2022-10-20 00:12:03+00:00,https://twitter.com/GaryMarcus/status/1582887332037873664,"@bengoertzel @pmddomingos @ch402 @AvilaGarcez @luislamb indeed, fair point. the practical question is whether you can get traction (eg greater efficiency, interpretability etc) from the mapping."
1994,@GaryMarcus,2022-10-20 00:01:42+00:00,https://twitter.com/GaryMarcus/status/1582884728901754880,"Happy Sixth Anniversary, Unrealistic Promise! https://t.co/NoKiVetJAQ"
1995,@GaryMarcus,2022-10-19 23:55:57+00:00,https://twitter.com/GaryMarcus/status/1582883283410780160,"@pmddomingos 1. hoping *you* would do the hard work to see if it is sound ;)

2. if a transformer mapped directly onto logic it would be vindication for neurosymbolic and implementational connectionism

cc @ch402 @AvilaGarcez @luislamb new paper on transformers and relation to logic"
1996,@GaryMarcus,2022-10-19 23:36:20+00:00,https://twitter.com/GaryMarcus/status/1582878345012072448,"@sabawalid or: most of what allows to learn the right things is innate, much of the specific knowledge that we use is learned.  innate knowledge is a small but essential festoon of the total"
1997,@GaryMarcus,2022-10-19 23:17:32+00:00,https://twitter.com/GaryMarcus/status/1582873612440449024,@sanewman1 @SpeciesTypical @kohn_gregory https://t.co/9xKyWBg47j
1998,@GaryMarcus,2022-10-19 23:15:55+00:00,https://twitter.com/GaryMarcus/status/1582873205408419841,"@IntuitMachine perhaps open question, but i don't see them as obviously casting any light on genotype-phenotype relations, or as particularly contributing our understanding of evolution or to genetic algorithms."
1999,@GaryMarcus,2022-10-19 23:14:21+00:00,https://twitter.com/GaryMarcus/status/1582872813828210688,"@pwlot damn, i was about to write something similar :)"
2000,@GaryMarcus,2022-10-19 23:12:30+00:00,https://twitter.com/GaryMarcus/status/1582872346968608768,"@rgblong it's a technique for getting a machine to specify the priors.

I am quite sympathetic to the work, and hired all three of those outstanding researchers in my first company :)"
2001,@GaryMarcus,2022-10-19 23:10:54+00:00,https://twitter.com/GaryMarcus/status/1582871945905057792,@rgblong your analogy w Mu-Zero and Chomsky kinda made it look that way tbh
2002,@GaryMarcus,2022-10-19 23:08:47+00:00,https://twitter.com/GaryMarcus/status/1582871412754509825,"@pwlot @rgblong my basic learning architecture *evolved*, over a billion years, with most finishing touches at least 50,000 years ago."
2003,@GaryMarcus,2022-10-19 23:06:59+00:00,https://twitter.com/GaryMarcus/status/1582870957236289536,@sanewman1 @SpeciesTypical @kohn_gregory eg @carlzimmer has been far more careful; few editors know enough science to get it right.
2004,@GaryMarcus,2022-10-19 23:05:38+00:00,https://twitter.com/GaryMarcus/status/1582870618487545856,@sanewman1 @SpeciesTypical @kohn_gregory i wouldn't call that headline *sophisticated*; the first part of The Birth of The Mind goes to some length to explain why that sort of Gene-for-x-behavior thing is ridiculous.
2005,@GaryMarcus,2022-10-19 21:42:46+00:00,https://twitter.com/GaryMarcus/status/1582849763258830848,@sanewman1 @SpeciesTypical @kohn_gregory nobody sophisticated would say that
2006,@GaryMarcus,2022-10-19 21:38:06+00:00,https://twitter.com/GaryMarcus/status/1582848591542222848,@pmddomingos https://t.co/HSLt2dwu8u
2007,@GaryMarcus,2022-10-19 21:33:45+00:00,https://twitter.com/GaryMarcus/status/1582847494832427008,@SpeciesTypical @sanewman1 @kohn_gregory more or less the point of my 2004 book
2008,@GaryMarcus,2022-10-19 21:32:31+00:00,https://twitter.com/GaryMarcus/status/1582847184617496577,@tegan_maharaj @_dieuwke_ relates to your recent paper / @tegan_maharaj you should see @_dieuwke_ ‚Äòs recent review
2009,@GaryMarcus,2022-10-19 21:16:34+00:00,https://twitter.com/GaryMarcus/status/1582843169531920384,"@annieduke (and see my reply to the original post, re genotype/phenotype)"
2010,@GaryMarcus,2022-10-19 21:10:22+00:00,https://twitter.com/GaryMarcus/status/1582841609376628737,"Pro tip: if you are ever on the verge of losing argument, redefine all of the terms.

For example, if you believe all knowledge comes from learning, but your opponent thinks evolution plays an important role, redefine learning to encompass evolution. 

You can‚Äôt lose!"
2011,@GaryMarcus,2022-10-19 21:05:57+00:00,https://twitter.com/GaryMarcus/status/1582840499790303232,"@rgblong @cameronjbuckner @davidchalmers42 @Jake_Browning00 @ylecun @NoemaMag @kenneth0stanley @jeffclune @joelbot3000 transposed onto biology what this means is: we evolve the right priors (using separate machinery that converts genotypes to phenotypes &amp; evaluates their fitness), and then use those priors to learn the rest.

as a nativist, I am cool with that üòé"
2012,@GaryMarcus,2022-10-19 19:47:46+00:00,https://twitter.com/GaryMarcus/status/1582820824759046145,"@kohn_gregory @SpeciesTypical obviously it is shorthand (see my 2004 book), but if your theory can‚Äôt distinguish between the degree of intrinsic organization of the heart (which doesn‚Äôt heavily depend on data-driven learning) &amp; the organization of the adult human brain (which does), why bother?"
2013,@GaryMarcus,2022-10-19 19:43:05+00:00,https://twitter.com/GaryMarcus/status/1582819643714318337,@PhilCorlett1 on pain of infinite regress that learning gadget must itself be innate.
2014,@GaryMarcus,2022-10-19 19:33:05+00:00,https://twitter.com/GaryMarcus/status/1582817130541899776,@PhilCorlett1 so why don‚Äôt chimps have language?
2015,@GaryMarcus,2022-10-19 19:26:45+00:00,https://twitter.com/GaryMarcus/status/1582815535037046784,"@PhilCorlett1 top highlight‚Äî‚ÄúEvolution targets peripheral, not central, aspects of cognition‚Äù‚Äî is odd, since what separates humans from other primates (language and culture, perhaps recursion) is not peripheral

On Garcia effect, they try to shift locus but don‚Äôt really undermine phenomenon."
2016,@GaryMarcus,2022-10-19 18:49:30+00:00,https://twitter.com/GaryMarcus/status/1582806160041996289,"oops, October, but you get the idea.."
2017,@GaryMarcus,2022-10-19 18:48:44+00:00,https://twitter.com/GaryMarcus/status/1582805966713942016,December 2016:
2018,@GaryMarcus,2022-10-19 18:46:54+00:00,https://twitter.com/GaryMarcus/status/1582805507265662981,"@kohn_gregory @SpeciesTypical the last sentence doesn‚Äôt really follow from the former; you don‚Äôt meaningfully learn the shape of your hands, and if you removed the genes from all of those cells you wouldn‚Äôt get hands. your sophistry doesn‚Äôt really give us purchase on the actual mechanisms involved."
2019,@GaryMarcus,2022-10-19 18:43:27+00:00,https://twitter.com/GaryMarcus/status/1582804636784013314,"@kohn_gregory @SpeciesTypical or show me how biology would support whatever learning mechanisms you think underlie language acquisition.

this is just burden tennis; we don‚Äôt know in full detail how any behavior, involving learning or not, emerges.

learning is a behavior; at least some must ground in biology"
2020,@GaryMarcus,2022-10-19 18:30:59+00:00,https://twitter.com/GaryMarcus/status/1582801500770021376,@SpeciesTypical @kohn_gregory my hands learned how many fingers to have after years of playing piano.
2021,@GaryMarcus,2022-10-19 18:28:46+00:00,https://twitter.com/GaryMarcus/status/1582800943657398272,@kohn_gregory @SpeciesTypical all vs some.
2022,@GaryMarcus,2022-10-19 18:15:41+00:00,https://twitter.com/GaryMarcus/status/1582797652085047296,"@AshleyAitken @jjhikes @AthenaAI2 @Grady_Booch @davidchalmers42 @shokunin_studio they still only understand speech to a very limited degree, and L5 driving remains a long way away."
2023,@GaryMarcus,2022-10-19 18:14:02+00:00,https://twitter.com/GaryMarcus/status/1582797235666186240,"literally every sentence that I have seen about GPT-3 that starts out ‚Äúto be fair‚Äù is ridiculously overcharitable to a machine, leveraging human creativity to defend a dumb answer on part of said machine. 

and the post hoc explanations given therein never hold up for long."
2024,@GaryMarcus,2022-10-19 18:10:09+00:00,https://twitter.com/GaryMarcus/status/1582796259832000512,"@kohn_gregory @SpeciesTypical nobody, ever, said that all species-typical behaviors are experience-independent."
2025,@GaryMarcus,2022-10-19 15:31:34+00:00,https://twitter.com/GaryMarcus/status/1582756347430731777,"@math_dandy @chafkin @BW @sciam until then, hypesters go around saying ‚Äúput up, or shut up‚Äù and  dissent is squelched. sad days for science!"
2026,@GaryMarcus,2022-10-19 15:29:36+00:00,https://twitter.com/GaryMarcus/status/1582755855552114689,"@johnmark_taylor evolution has given us lot of genetic machinery for example for building topographic maps, and i would suppose that something like convolution is innate, as well. (see my debate with LeCun where I argued just that.)"
2027,@GaryMarcus,2022-10-19 15:28:34+00:00,https://twitter.com/GaryMarcus/status/1582755594364424192,"@johnmark_taylor that‚Äôs literally the whole point of nativism: a bunch of stuff evolved, changing our genome, and that stuff is prerequisite to learning and behaving as we do."
2028,@GaryMarcus,2022-10-19 15:27:07+00:00,https://twitter.com/GaryMarcus/status/1582755227677396992,"@NoraNewcombe You have to represent/encode, store, &amp; retrieve the taste in question, so I am actually not sure about that. Sure, it‚Äôs not a specific representation, but it is a mechanism for handling a particular kind of representation. The representational format itself is presumably innate."
2029,@GaryMarcus,2022-10-19 15:23:49+00:00,https://twitter.com/GaryMarcus/status/1582754400564817921,"Complementing @chafkin‚Äôs @BW expos√© on hype in driverless cars, here‚Äôs an excellent @sciam op-ed on hype in medical AI https://t.co/u1LNdB6VGf

Anyone see a pattern here?"
2030,@GaryMarcus,2022-10-19 14:48:46+00:00,https://twitter.com/GaryMarcus/status/1582745579951919105,@cameronjbuckner you changed the topic on this important question. i literally don‚Äôt see a scientific motivation for your position. do you have one?
2031,@GaryMarcus,2022-10-19 14:43:08+00:00,https://twitter.com/GaryMarcus/status/1582744158577754117,"Rumor has it that innate, domain-specific biological adaptations are not biologically plausible. 

If you spend 30 seconds reading about the Garcia effect, you will realize that these rumors are nonsense. 

Anti-nativists always seem to underestimate biology."
2032,@GaryMarcus,2022-10-19 14:29:42+00:00,https://twitter.com/GaryMarcus/status/1582740780841840642,"@WiringTheBrain @cameronjbuckner @pwlot @ylecun @davidchalmers42 @Jake_Browning00 the Garcia effect is indeed a beautiful example of an innate, domain-specific learning adaptation https://t.co/snaIkGRFVB"
2033,@GaryMarcus,2022-10-19 14:11:41+00:00,https://twitter.com/GaryMarcus/status/1582736246048436226,@cameronjbuckner @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 again please read the cognition article
2034,@GaryMarcus,2022-10-19 14:10:06+00:00,https://twitter.com/GaryMarcus/status/1582735849367953408,"@cameronjbuckner @pwlot @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 it‚Äôs a win for nativism. pleas read this article before we talk further:

https://t.co/E5j3Pw1S5B"
2035,@GaryMarcus,2022-10-19 14:06:35+00:00,https://twitter.com/GaryMarcus/status/1582734962461376514,"@cameronjbuckner @pwlot @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 translation invariance via convolution surely is an innate piece of machinery for space that gets used in some domains, and not others."
2036,@GaryMarcus,2022-10-19 14:04:56+00:00,https://twitter.com/GaryMarcus/status/1582734548441632769,"@cameronjbuckner @pwlot @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 and yet they still need them; Yann‚Äôs ‚Äî‚ÄúIntrinsic Cost module [that] is hard-wired (immutable, non trainable) and computes a single scalar‚Äù‚Äì sure looks like an innate, symbolic representation to me. and once you have one hard-wired scalar (AKA a symbolic variable) why not more?"
2037,@GaryMarcus,2022-10-19 13:59:01+00:00,https://twitter.com/GaryMarcus/status/1582733056548700161,"@rgblong @cameronjbuckner @davidchalmers42 @Jake_Browning00 @ylecun @NoemaMag @kenneth0stanley @jeffclune @joelbot3000 no, you should evolve your architecture, so that any given system comes to its learning challenge with the right priors.

if the only way you can win is by redefining learning to encompass evolution, you have lost."
2038,@GaryMarcus,2022-10-19 13:56:17+00:00,https://twitter.com/GaryMarcus/status/1582732369349730304,"@cameronjbuckner @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 if the toolkit of biology can wired CPGs and topographic maps, and can express genes differentially throughout the brain, it can surely wire a bunch of domain-specific wiring.  

and latest results show plenty of differential genetic expression."
2039,@GaryMarcus,2022-10-19 13:53:20+00:00,https://twitter.com/GaryMarcus/status/1582731626194538496,"@cameronjbuckner @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 the power of duplication and divergence and of specialization throughout the body, it becomes a matter of sheer prejudice to assume that some developmental wiring process is magically restricted to that which is domain-general."
2040,@GaryMarcus,2022-10-19 13:52:08+00:00,https://twitter.com/GaryMarcus/status/1582731327841140737,"@cameronjbuckner @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 they are domain-general, but an example of how the toolkit of developmental biology can build something that (in a broad sense) is both innate and representational. once you open the door to that, and realize that the brain is neither uniform nor well-understood, and recognize ‚Ä¶"
2041,@GaryMarcus,2022-10-19 13:47:52+00:00,https://twitter.com/GaryMarcus/status/1582730254107705345,@cameronjbuckner @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 ?
2042,@GaryMarcus,2022-10-19 13:44:35+00:00,https://twitter.com/GaryMarcus/status/1582729424084303872,"@cameronjbuckner @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 a partial inventory of parts ‚â† a worked out theory of the circuitry or development of memory formation.  

there is literally no argument in your post for why developmental mechanisms should be exclusively domain-general"
2043,@GaryMarcus,2022-10-19 13:40:41+00:00,https://twitter.com/GaryMarcus/status/1582728443913199616,"@cameronjbuckner @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 do you have a single worked out example (in the level you are asking) for how genes build a learning mechanism with the richness of what LeCun proposed in his summer manifesto?

he needs the same level of intricacy, but in different places"
2044,@GaryMarcus,2022-10-19 13:38:22+00:00,https://twitter.com/GaryMarcus/status/1582727862519750656,"@pwlot @WiringTheBrain @cameronjbuckner @ylecun @davidchalmers42 @Jake_Browning00 yes! and of course we don‚Äôt have a definition of representation here but at this point we can safely bet that Buckner will try to saddle nativism with the narrowest throng he can come up.

broadest possible view of empiricism; narrowest possible view of nativism üôÑ"
2045,@GaryMarcus,2022-10-19 13:36:02+00:00,https://twitter.com/GaryMarcus/status/1582727275707269122,"@cameronjbuckner @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00 are you going to try to exclude  central pattern generators, too?  i see that your game is to maximally broaden empiricism to include everyone. but to narrow nativism as much as you can."
2046,@GaryMarcus,2022-10-19 03:57:15+00:00,https://twitter.com/GaryMarcus/status/1582581620376494080,"@ASteckley @ylecun in philosophy, it is ok to ask people to clarify; the same should be true in ML, or any science."
2047,@GaryMarcus,2022-10-19 03:56:16+00:00,https://twitter.com/GaryMarcus/status/1582581373222916096,"@ASteckley @ylecun i pushed hard to understand his position on symbols recently, even after i was irritated because he had lied about my credentials, because i genuinely wanted to understand his position; and yes at a certain point he shut down, as you describe."
2048,@GaryMarcus,2022-10-19 03:53:25+00:00,https://twitter.com/GaryMarcus/status/1582580655317463040,"@ASteckley @ylecun I am not begrudging him his right to change his mind, of course. but the circumstances around his reaction to my 2018 article are hard to swallow."
2049,@GaryMarcus,2022-10-19 03:50:35+00:00,https://twitter.com/GaryMarcus/status/1582579941543415808,@ASteckley @ylecun he claims not to have changed his position: https://t.co/rpvFTx609B
2050,@GaryMarcus,2022-10-19 03:48:36+00:00,https://twitter.com/GaryMarcus/status/1582579441796284418,"@ASteckley @ylecun from twitter advanced search i only see him using the term pejoratively, eg https://t.co/CKdhUumQxZ"
2051,@GaryMarcus,2022-10-19 03:39:31+00:00,https://twitter.com/GaryMarcus/status/1582577157129535488,@ASteckley @ylecun absolutely
2052,@GaryMarcus,2022-10-19 03:37:05+00:00,https://twitter.com/GaryMarcus/status/1582576541669920769,@ASteckley @ylecun i have never deliberately done this; i ask my questions with honesty. i would be curious if you have a concrete example of this.
2053,@GaryMarcus,2022-10-19 03:35:36+00:00,https://twitter.com/GaryMarcus/status/1582576172340506625,@ASteckley @ylecun many people have offered to host and I agree that there would be value in a properly moderated debate.
2054,@GaryMarcus,2022-10-19 01:22:11+00:00,https://twitter.com/GaryMarcus/status/1582542594705625089,"@Jake_Browning00 @cameronjbuckner @ylecun @davidchalmers42 @NoemaMag 1. is there any specific reason to think it might work, without tacitly relying on symbol-manipulation?
2. still sounds like planning not reflection and I am wondering if you have anything behind planning in mind."
2055,@GaryMarcus,2022-10-19 01:01:23+00:00,https://twitter.com/GaryMarcus/status/1582537361166303233,"@Jake_Browning00 @cameronjbuckner @ylecun @davidchalmers42 @NoemaMag even if we grant that that his aspiration
- not clear that it can work 
- not clear what these states are if not symbols nor how they evaluated, nor how you cycle through them w/o variable binding
- overall proposal sounds more like planning than reflection to me"
2056,@GaryMarcus,2022-10-19 00:26:41+00:00,https://twitter.com/GaryMarcus/status/1582528627215736833,@Jake_Browning00 @cameronjbuckner @ylecun @davidchalmers42 @NoemaMag i am asking you for what you think the alternative is and why you think your title warrants the term ‚Äúreflection‚Äù
2057,@GaryMarcus,2022-10-18 23:20:42+00:00,https://twitter.com/GaryMarcus/status/1582512022163705856,"@Jake_Browning00 @cameronjbuckner @ylecun @davidchalmers42 @NoemaMag that said, it may rest in part on what means by reflection ‚Ä¶

eg does it involve reasoning about one‚Äôs past and future actions?"
2058,@GaryMarcus,2022-10-18 23:18:50+00:00,https://twitter.com/GaryMarcus/status/1582511554616229888,@Jake_Browning00 @cameronjbuckner @ylecun @davidchalmers42 @NoemaMag how are you going to represent propositional attitudes otherwise? (i don‚Äôt think i have written about it explicitly but have a related passage in a paper I am working on.)
2059,@GaryMarcus,2022-10-18 22:44:06+00:00,https://twitter.com/GaryMarcus/status/1582502811266613250,"@ylecun @armchair_prof you do not. never seen you do it. 

you were wrong to call my 2018 paper ‚Äúmostly wrong‚Äù, even though you have yourself recently endorsed essentially all the claims i made there. 

you also lied about my credentials. ZDNet had to publish a correction. you never apologized."
2060,@GaryMarcus,2022-10-18 22:39:31+00:00,https://twitter.com/GaryMarcus/status/1582501658101108736,"Grow up. If you are going to make a lot of strong statements and insult other people‚Äôs ideas, people have right to ask what it is that you are saying, and to ask for clarification."
2061,@GaryMarcus,2022-10-18 22:31:22+00:00,https://twitter.com/GaryMarcus/status/1582499609506877440,"i literally don‚Äôt understand what piece of science would motivate nativism only about things that are domain-general. 

seems utterly arbitrary to me. yet what multiple people seem attracted to. why?

@cameronjbuckner @WiringTheBrain @ylecun @davidchalmers42 @Jake_Browning00"
2062,@GaryMarcus,2022-10-18 22:28:18+00:00,https://twitter.com/GaryMarcus/status/1582498836299546625,"&amp; surely answer is both!  literally *no* reason for biology to innately have domain-general mechanisms but nothing domain-specific, when so much of genome is selectively expressed.

it would be like saying since we have blood (domain-general) we can‚Äôt have heart (domain-specific)"
2063,@GaryMarcus,2022-10-18 22:19:23+00:00,https://twitter.com/GaryMarcus/status/1582496590715289600,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag . @ylecun i see you liked this tweet ‚Äî but you also rejected every bit of  unlearned domain general knowledge that I proposed in 2017, eg symbols &amp; operations over variables for abstraction. how do you think we could get to an unlearned mechanism for reflection without that?"
2064,@GaryMarcus,2022-10-18 22:08:43+00:00,https://twitter.com/GaryMarcus/status/1582493908327858176,@davidchalmers42 @cameronjbuckner @Jake_Browning00 @ylecun @NoemaMag thank you btw for using the word ‚Äúfaculty‚Äù here; it‚Äôs a reminder that the very idea of partitioning into modules was what Fodor argued for and what many connectionists have historically argued against.
2065,@GaryMarcus,2022-10-18 22:06:03+00:00,https://twitter.com/GaryMarcus/status/1582493236979191808,"@davidchalmers42 @cameronjbuckner @Jake_Browning00 @ylecun @NoemaMag that‚Äôs the line that @ylecun took in our debate (‚Äúzero‚Äù) but his 2022 architecture certainly builds some innate structure in, including specific module and even innate drives."
2066,@GaryMarcus,2022-10-18 22:00:25+00:00,https://twitter.com/GaryMarcus/status/1582491816737529859,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag in this sense i am moderate empiricist too. literally everybody is. 

we are also all moderate nativists in a comparable sense."
2067,@GaryMarcus,2022-10-18 14:02:02+00:00,https://twitter.com/GaryMarcus/status/1582371428250550274,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag if you add all that, you are more nativist than if you don‚Äôt. you want a world in which you can be both a nativist and empiricist. 

that‚Äôs why most of us use terms like ‚Äúinnately guided learning‚Äù 

literally nobody thinks there is no learning or nothing innate."
2068,@GaryMarcus,2022-10-18 13:57:36+00:00,https://twitter.com/GaryMarcus/status/1582370314843217921,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag &amp; most work doesn‚Äôt have these things adding them all in surely more nativist in the sense of more unlearned machinery. you want to be able to add in lots more machinery and call it ‚Äúempiricist‚Äù no matter how much is added. 

ALL you are really arguing for is domain-general."
2069,@GaryMarcus,2022-10-18 13:54:29+00:00,https://twitter.com/GaryMarcus/status/1582369529526902790,@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag but 1. you are assuming your conclusion  - empiricists will of course be happy if they can get everything they need for free. but can they? they have failed on out of distribution abstraction and lack imagination in the sense of being able to think through counterfactuals etc &amp;
2070,@GaryMarcus,2022-10-18 13:51:34+00:00,https://twitter.com/GaryMarcus/status/1582368795431403520,"@cameronjbuckner @pwlot @rgblong @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag i know the paper. i always used the term to refer to ‚Äúunlearned‚Äù machinery and not eg cross cultural universal (which sometimes is unlearned sometime not)

empiricist is similarly used in multiple senses, as we saw yesterday"
2071,@GaryMarcus,2022-10-18 13:49:41+00:00,https://twitter.com/GaryMarcus/status/1582368322448162817,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag also his most nativist work.

 1. stands in contrast to all his more empiricist work that lacks duals routes and decried them (eg all his past tense stuff)
and
2. contrasts with vast preponderance of more empiricist current ML which lacks machinery for explicit memory"
2072,@GaryMarcus,2022-10-18 13:45:03+00:00,https://twitter.com/GaryMarcus/status/1582367154758119424,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag good! then you can rewrite all your claims like these; although this one still will be weird since most latter-day empiricists build kinds of neural network models that lack all the things you mentioned except attention (&amp; in a small fraction of the work, memory)"
2073,@GaryMarcus,2022-10-18 04:04:14+00:00,https://twitter.com/GaryMarcus/status/1582220986921152512,"# of people liking this optimistic tweet: 980

# liking the caveat that ‚ÄúResults are mildly cherry-picked: It isn't hard to stump it or make it hallucinate answers‚Äù: 54"
2074,@GaryMarcus,2022-10-17 23:17:58+00:00,https://twitter.com/GaryMarcus/status/1582148947099148290,"@rgblong @cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag if you can‚Äôt even connect your terms with current debates Lecun/Browning and i are having (which i do think is substantive), your terms aren‚Äôt very useful, nor tied to what is actually at stake."
2075,@GaryMarcus,2022-10-17 22:43:52+00:00,https://twitter.com/GaryMarcus/status/1582140365171462144,the opening paragraphs of this include a stunning bit of parenting
2076,@GaryMarcus,2022-10-17 22:21:07+00:00,https://twitter.com/GaryMarcus/status/1582134641867501568,"science fiction in 2017, science fiction in 2022."
2077,@GaryMarcus,2022-10-17 21:08:39+00:00,https://twitter.com/GaryMarcus/status/1582116403607662592,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag i am not seeing anything useful here that would eg help classify proposals or make predictions about them etc , since you are basically weakening the terms such that anything (even innate priors) counts as empiricism."
2078,@GaryMarcus,2022-10-17 21:07:01+00:00,https://twitter.com/GaryMarcus/status/1582115994197426176,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag spelke‚Äôs core knowledge is about as nativist as any actual proposal in developmental psychology.  

if you count her as an empiricist, you should count me as well. 

your way of rephrasing stuff is so loose it groups literally every proposal together except maybe Chomsky LAD."
2079,@GaryMarcus,2022-10-17 21:03:43+00:00,https://twitter.com/GaryMarcus/status/1582115163226132480,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag episodic memory surely requires representations, ergo the DeepMind passage is nativist, under your own definitions."
2080,@GaryMarcus,2022-10-17 21:00:56+00:00,https://twitter.com/GaryMarcus/status/1582114459241566208,@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag and how can you call something that endorses installing high level prior knowledge ‚Äúempiricist‚Äù (in the sense of that word that contrasts with nativist)? isn‚Äôt that the very definition of nativism?
2081,@GaryMarcus,2022-10-17 20:58:16+00:00,https://twitter.com/GaryMarcus/status/1582113791126695936,@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag where do you draw the line on ‚Äúminimal hand engineering‚Äù? where is the substance to the claim? is machinery for and representation formats for episodic memory ‚Äúminimal hand engineer‚Äù? how about representational formats/machinery for symbols? how about representing space?
2082,@GaryMarcus,2022-10-17 20:42:36+00:00,https://twitter.com/GaryMarcus/status/1582109847524634625,@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag i don‚Äôt even know what it means for the mind to be ‚Äútabula rasa‚Äù if you have that much prior structure. Am I actually an empiricist in your sense?
2083,@GaryMarcus,2022-10-17 20:40:58+00:00,https://twitter.com/GaryMarcus/status/1582109437460111360,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag i don‚Äôt think that the position your defending has anything to do with what Elman, Bates, Smith, Sutton, etc actually advocate for. Give me some names and quotes from people in the last 50 years, who are ‚Äúempiricists‚Äù that endorse that level of (domain-general) innate structure."
2084,@GaryMarcus,2022-10-17 20:28:18+00:00,https://twitter.com/GaryMarcus/status/1582106248920829953,"@cameronjbuckner @Jake_Browning00 @ylecun @davidchalmers42 @NoemaMag which empiricists are you talking about? if you have a whole bunch of detailed cognitive architecture prior to learning, that sounds like nativism to me."
2085,@GaryMarcus,2022-10-17 19:40:34+00:00,https://twitter.com/GaryMarcus/status/1582094234500608001,@pmddomingos @AllenInstitute if i had a nickel for every time some one argued for neural networks on the basis that symbols are (allegedly) not biologically plausible ‚Ä¶
2086,@GaryMarcus,2022-10-17 16:55:26+00:00,https://twitter.com/GaryMarcus/status/1582052678313869312,@manlius84 @KordingLab @PessoaBrain @anilkseth @WiringTheBrain @ricard_sole @AFornito @MauCorbetta @spornslab @laurahelmuth yep it is a surprising error
2087,@GaryMarcus,2022-10-17 16:32:35+00:00,https://twitter.com/GaryMarcus/status/1582046929848274955,"@Jake_Browning00 @cameronjbuckner @ylecun @davidchalmers42 @NoemaMag um, your argument was against *any* systems have symbols innately, no? are there some that you *do* think have symbols innately?"
2088,@GaryMarcus,2022-10-17 16:31:42+00:00,https://twitter.com/GaryMarcus/status/1582046704874172416,"@Jake_Browning00 @cameronjbuckner @ylecun @davidchalmers42 @NoemaMag well I in particular argued for symbol-manipulation as a component of domain-general nativism.

and you in particular argued against it.

ü§∑‚Äç‚ôÇÔ∏è"
2089,@GaryMarcus,2022-10-17 16:17:38+00:00,https://twitter.com/GaryMarcus/status/1582043166064410624,"@pmddomingos @AllenInstitute and got lost in the fumes of silly claims about biological plausibility, missing the point (for a while, until they finally got it) that cognition depend in no small part on prior structure and not just masses of homogeneity"
2090,@GaryMarcus,2022-10-17 15:24:32+00:00,https://twitter.com/GaryMarcus/status/1582029804324687881,@KordingLab @manlius84 @PessoaBrain @anilkseth @WiringTheBrain @ricard_sole @AFornito @MauCorbetta @spornslab @laurahelmuth
2091,@GaryMarcus,2022-10-17 15:02:36+00:00,https://twitter.com/GaryMarcus/status/1582024283483955202,@cameronjbuckner @ylecun @davidchalmers42 @Jake_Browning00 @NoemaMag @rgblong @WiringTheBrain @berent_iris
2092,@GaryMarcus,2022-10-17 14:59:41+00:00,https://twitter.com/GaryMarcus/status/1582023548801257472,"@cameronjbuckner @ylecun @davidchalmers42 false. innateness and domain-specificity are *orthogonal*.

eg @ylecun &amp; @Jake_Browning00 just wrote an essay in @NoemaMag arguing that symbols were learned, rather than innate. 

that was an *empiricist* argument against a piece of (putative) *domain-general* innate machinery."
2093,@GaryMarcus,2022-10-17 14:38:00+00:00,https://twitter.com/GaryMarcus/status/1582018091319709696,"@cameronjbuckner @ylecun @davidchalmers42 i can‚Äôt help that (some) other people are confused.  i tried to clarify inherent orthogonal of innateness and domain-specificity  in various books; here is a short essay:

https://t.co/kxAyOi1UbN

and i would concur with this abstract:

https://t.co/SEeqqVijRY"
2094,@GaryMarcus,2022-10-17 14:28:20+00:00,https://twitter.com/GaryMarcus/status/1582015661819453441,@KarlaParussel @AllenInstitute yes and there is wonderful followup work by @YiotaPoirazi and Larkin lab extending the same point
2095,@GaryMarcus,2022-10-17 14:23:20+00:00,https://twitter.com/GaryMarcus/status/1582014400516722688,"@cameronjbuckner @ylecun @davidchalmers42 this is one point where we partly agree. i think it is absurd to read the biological and psychological record as counter to all nativism, but AI is still up for grabs. 

but you strawman my actual argument here: i always couch my argument there as suggestion rather than proof."
2096,@GaryMarcus,2022-10-17 14:19:07+00:00,https://twitter.com/GaryMarcus/status/1582013339215212546,@cameronjbuckner @ylecun @davidchalmers42 no no no. innateness and domain-specificity are orthogonal.
2097,@GaryMarcus,2022-10-17 14:17:00+00:00,https://twitter.com/GaryMarcus/status/1582012808346357761,"@rgblong @cameronjbuckner @ylecun @davidchalmers42 &amp; i suppose you want to ignore the vast evidence from developmental neuroscience, ethology etc as well at the arguments i raised above from @berent_iris re bias.

no thanks. i know the literature is controversial; i know the bias exists, and i don‚Äôt see a specific argument here."
2098,@GaryMarcus,2022-10-17 05:18:48+00:00,https://twitter.com/GaryMarcus/status/1581877367534161920,"@FelixHill84 @kchonyc of course it is, unless you are me. and then it is really bad, maybe even immoral. ü§£"
2099,@GaryMarcus,2022-10-17 05:16:22+00:00,https://twitter.com/GaryMarcus/status/1581876752477212673,"When people fully absorb the impact of this stunning new brain study @AllenInstitute, a few years hence, they will wonder what neural net researchers were even trying to do in the early 2020s, oversimplifying so much vital neural complexity. 

greatüßµon 1000s of types of neurons"
2100,@GaryMarcus,2022-10-17 02:48:31+00:00,https://twitter.com/GaryMarcus/status/1581839544433143808,@JamieBykovBrett @sineadbovell lmao!
2101,@GaryMarcus,2022-10-17 02:42:38+00:00,https://twitter.com/GaryMarcus/status/1581838065953574912,@ElliotMurphy91 @matspike esp by @berent_iris and others in recent empirical studies
2102,@GaryMarcus,2022-10-17 00:22:10+00:00,https://twitter.com/GaryMarcus/status/1581802715671580672,"@rgblong @cameronjbuckner @ylecun @davidchalmers42 not saying there is no room for argument like that, but I see no evidence for stable world models emerging, even at level of e.g. a mouse. that is not what empiricism ought to expect. 

&amp; you are retreating to a post-hoc, human-specific empiricism that depends on *innate* goals!"
2103,@GaryMarcus,2022-10-17 00:15:38+00:00,https://twitter.com/GaryMarcus/status/1581801071907082240,"and people are trying to tell me that GPT-3 isn‚Äôt being used for misinformation? Like the misinfo crowd is so far behind spammers? 

Not buying."
2104,@GaryMarcus,2022-10-17 00:13:19+00:00,https://twitter.com/GaryMarcus/status/1581800487078473730,"@rgblong @cameronjbuckner @ylecun @davidchalmers42 not clear it predicts anything at all, when you come down to it. it‚Äôs a whole (vaguely-defined) family of hypotheses. 

but surely LLM is best the available actually-realized version of that class of hypotheses."
2105,@GaryMarcus,2022-10-17 00:11:29+00:00,https://twitter.com/GaryMarcus/status/1581800027621830656,"@rgblong @cameronjbuckner @ylecun @davidchalmers42 my guess is to make ‚Äúempiricism‚Äù work, you will wind up building a space-time manifold into your ‚Äúdomain-general‚Äù learning mechanism, and probably notions of cause and agency. 

that‚Äôs a pyrrhic victory, IMHO."
2106,@GaryMarcus,2022-10-17 00:09:46+00:00,https://twitter.com/GaryMarcus/status/1581799593486209024,"@rgblong @cameronjbuckner @ylecun @davidchalmers42 sure but an LLM is exactly that, state of the art with massive amounts of compute and data, better than any other known empiricist learning mechanism, and not doing so well in building stable representations of the world.

Not saying it is *fatal* but it‚Äôs not a good look either"
2107,@GaryMarcus,2022-10-16 23:57:46+00:00,https://twitter.com/GaryMarcus/status/1581796576053592067,"@rgblong @cameronjbuckner @ylecun @davidchalmers42 and putting it somewhat differently, what kind of claim would an empiricist even be making if they were indifferent as to whether you could learn about the world from massive amounts of data? isn‚Äôt that the whole claim?"
2108,@GaryMarcus,2022-10-16 23:57:01+00:00,https://twitter.com/GaryMarcus/status/1581796384642334721,"@rgblong @cameronjbuckner @ylecun @davidchalmers42 it‚Äôs particularly embarrassing for empiricism that adding a bunch of visual data, and even some interaction in silico, doesn‚Äôt seem to fundamentally change the problem. (I have a paper coming out about this.)"
2109,@GaryMarcus,2022-10-16 23:54:48+00:00,https://twitter.com/GaryMarcus/status/1581795830402801664,@rgblong @cameronjbuckner @ylecun @davidchalmers42 look empiricists for years thought this was the right direction and that we‚Äôd just get there if we had more data and bigger models. take for example the book Rethinking Innateness.
2110,@GaryMarcus,2022-10-16 23:53:46+00:00,https://twitter.com/GaryMarcus/status/1581795569626120193,"@rgblong @cameronjbuckner @ylecun @davidchalmers42 it‚Äôs not a knockout blow, but surely it‚Äôs an embarrasment to the theory, or the theory makes no predictions at all‚Äîand that would be even more embarassing."
2111,@GaryMarcus,2022-10-16 20:33:06+00:00,https://twitter.com/GaryMarcus/status/1581745069966909440,"@tdverstynen @bradpwyble @KordingLab @BrianNosek @random_walker @MelMitchell1 @TonyZador @Nancy_Kanwisher true, but there are also ways in which GPT is profoundly unlike what people do. It's just not building a discourse model of the world, the way humans do when they comprehend a sentence (see Kintsch etc) nor translating ideas into sentences (W. Levelt etc)."
2112,@GaryMarcus,2022-10-16 20:26:59+00:00,https://twitter.com/GaryMarcus/status/1581743527687749633,@tdverstynen @bradpwyble @KordingLab @BrianNosek @random_walker @MelMitchell1 @TonyZador @Nancy_Kanwisher time will tell but i suspect the similarities are parasitic on common data rather than genuinely common underlying mechanism.
2113,@GaryMarcus,2022-10-16 19:01:01+00:00,https://twitter.com/GaryMarcus/status/1581721896684773376,@bradpwyble @KordingLab @BrianNosek @random_walker @tdverstynen @MelMitchell1 @TonyZador @Nancy_Kanwisher pretty clear you weren‚Äôt one of the reviewers‚Ä¶.
2114,@GaryMarcus,2022-10-16 18:46:47+00:00,https://twitter.com/GaryMarcus/status/1581718313050476545,@KordingLab @bradpwyble @BrianNosek @random_walker @tdverstynen @MelMitchell1 @TonyZador @Nancy_Kanwisher quite likely
2115,@GaryMarcus,2022-10-16 18:40:22+00:00,https://twitter.com/GaryMarcus/status/1581716696901222400,@scottiev @ylecun i am pointing out that we are unlikely to make progress until we remove our blinders.
2116,@GaryMarcus,2022-10-16 18:30:54+00:00,https://twitter.com/GaryMarcus/status/1581714315086036992,"@cameronjbuckner @ylecun @davidchalmers42 ps i addressed the general issues about interactionism in 2004 book, The Birth of The Mind. The mere existence of interactionism doesn't take way from the fact that genes are a critical part of development. Ditto eg for the existence of plasticity."
2117,@GaryMarcus,2022-10-16 18:27:23+00:00,https://twitter.com/GaryMarcus/status/1581713432545746944,"@cameronjbuckner @ylecun @davidchalmers42 Honestly, I think this is like telling Dawkins to lay down his arguments because a lot of creationists disagree. Empiricism is rampant, but it doesn't make it right; the failure of LLMs with massive data to coherently understand the world is an immense black eye for empiricism."
2118,@GaryMarcus,2022-10-16 17:28:06+00:00,https://twitter.com/GaryMarcus/status/1581698514022977536,@cameronjbuckner @ylecun @davidchalmers42 as @berent_iris has formally documents there is a strong innate bias against nativism; Pinker‚Äôs book The Blank Slate is about this in many fields.  many wrongs don‚Äôt make a right.
2119,@GaryMarcus,2022-10-16 17:10:03+00:00,https://twitter.com/GaryMarcus/status/1581693969121284096,@tweeterholmes @ylecun thanks! fixed
2120,@GaryMarcus,2022-10-16 17:06:26+00:00,https://twitter.com/GaryMarcus/status/1581693059611656193,@loretoparisi I will tweet this later :) but want people to have fun spotting the flaw on their own first ;)
2121,@GaryMarcus,2022-10-16 16:52:22+00:00,https://twitter.com/GaryMarcus/status/1581689520168534020,"Noam Chomsky, who true to form reads everything, first, was first to reply to my essay below, writing, ""Your last phrase tells the story ‚Äì which I‚Äôve been hearing for 70 years: ‚ÄúIn six months,‚Ä¶‚Äù

See us dissect science, AI, &amp; hype together @WebSummit Nov 4th."
2122,@GaryMarcus,2022-10-16 16:46:00+00:00,https://twitter.com/GaryMarcus/status/1581687918133145601,@bradpwyble @BrianNosek @random_walker @KordingLab @tdverstynen @MelMitchell1 @TonyZador @Nancy_Kanwisher  see if you can spot the statistical howler before I give it away :)
2123,@GaryMarcus,2022-10-16 16:42:49+00:00,https://twitter.com/GaryMarcus/status/1581687117809618944,@IntuitMachine @davidchalmers42 agree @IntuitMachine; not at all obvious we get to mouse cognition in 10 years.
2124,@GaryMarcus,2022-10-16 16:36:39+00:00,https://twitter.com/GaryMarcus/status/1581685563308277760,with @DrLaurenOR @AMPimaging @maier_ak @DrLaurenOR @alexandrecadrin @MattFenech83 all piling on @ylecun
2125,@GaryMarcus,2022-10-16 16:33:46+00:00,https://twitter.com/GaryMarcus/status/1581684840503840768,"If you read that @MetaAI study about how GPT-2 predicts the brain, you really ought to read this."
2126,@GaryMarcus,2022-10-16 16:32:46+00:00,https://twitter.com/GaryMarcus/status/1581684587075637248,@cameronjbuckner @ylecun @davidchalmers42 I never said there was consensus agreement; I said that without some kind of strong nativism the twin projects of AI and cognitive science are hopeless.
2127,@GaryMarcus,2022-10-16 16:30:20+00:00,https://twitter.com/GaryMarcus/status/1581683974115852289,"Three baffling claims about AI and machine learning in four days, statistical errors in top journals, and claims from @Ylecun that you should not believe.

 (&amp; why medical Twitter jumped on him his week.)

https://t.co/LyOGPLR7t0"
2128,@GaryMarcus,2022-10-16 16:20:19+00:00,https://twitter.com/GaryMarcus/status/1581681454324805633,"@davidchalmers42 @anilkseth i misunderstood you at first, too; i now see that your ‚Äúserious candidate‚Äù claim turns out to be an unexpectedly weak claim; decoupled from necessity or sufficiency or falsifiability it doesn‚Äôt mean much.

we both initially thought you were making a stronger claim."
2129,@GaryMarcus,2022-10-16 16:01:53+00:00,https://twitter.com/GaryMarcus/status/1581676816527654913,"@gialdegheri @WiringTheBrain @gualtieropicc @PessoaBrain @Partitio_nBlues correction: fully neurosymbolic; i am not arguing that all@of system II is classical GOFAI, just that symbols-manipulation is a necessary component of some parts of it. (and i think the two system distinction is only shorthand in any case)."
2130,@GaryMarcus,2022-10-16 15:58:27+00:00,https://twitter.com/GaryMarcus/status/1581675951888687104,@mpshanahan @alan_winfield !
2131,@GaryMarcus,2022-10-16 00:40:57+00:00,https://twitter.com/GaryMarcus/status/1581445054916612096,"disturbing wrt to AI bias issues too, cc @Abebab"
2132,@GaryMarcus,2022-10-16 00:40:07+00:00,https://twitter.com/GaryMarcus/status/1581444845218168832,@stuartbuck1 @random_walker @bradpwyble @BrianNosek
2133,@GaryMarcus,2022-10-15 23:46:54+00:00,https://twitter.com/GaryMarcus/status/1581431454088953858,@ylecun @davidchalmers42 @WiringTheBrain and I both review some of the actual observed variability in our respective books on innateness
2134,@GaryMarcus,2022-10-15 23:45:29+00:00,https://twitter.com/GaryMarcus/status/1581431095618588673,@ylecun @davidchalmers42 you realize of course that some songbirds have their entire song repertoire innately wired whereas others (innately) learn the details? &amp; that any such statements a la the above are incompatible with some observed facts? and that evolution has more options than you anticipate?
2135,@GaryMarcus,2022-10-15 23:17:49+00:00,https://twitter.com/GaryMarcus/status/1581424134311260161,"it is misapprehension to equate innateness only w specific behaviors, rather than eg rich domain-specific learning mechanisms (a la Chomsky‚Äôs UG, Lorenz‚Äôs imprinting, Marler‚Äôs ‚Äúinnately guided learning‚Äù, Pinker‚Äôs semantic bootstrapping, etc)."
2136,@GaryMarcus,2022-10-15 21:11:37+00:00,https://twitter.com/GaryMarcus/status/1581392375062351872,@davidchalmers42 @jayvideofreedom @ylecun far inferior.
2137,@GaryMarcus,2022-10-15 21:11:21+00:00,https://twitter.com/GaryMarcus/status/1581392308943347712,@davidchalmers42 @ylecun so on some issues your standard is what LeCun himself said at some particular moment (2017 was different from 2019; you credit the earlier position and ignore later) and on other issues your standard is not what he actually said but what (some) other empiricists said.
2138,@GaryMarcus,2022-10-15 21:08:46+00:00,https://twitter.com/GaryMarcus/status/1581391657232392192,"@davidchalmers42 @ylecun not an impartial one. he said zero, &amp; now you are saying he didn‚Äôt actually mean zero.

&amp; ignoring the fact that when i first said (2019) LLMs would fail because of lack of models he said I was fighting a ‚Äúrearguard action‚Äù 

(which contradicted his debate position in some ways)"
2139,@GaryMarcus,2022-10-15 16:45:06+00:00,https://twitter.com/GaryMarcus/status/1581325301174665216,"@WiringTheBrain @gualtieropicc @PessoaBrain @Partitio_nBlues my view: System I be System II is shorthand for multiple overlapping distinctions, some with dichotomous underpinnings. some not, traveling loosely together. crude approximation with many really but hard to directly assess processes underneath"
2140,@GaryMarcus,2022-10-15 16:30:56+00:00,https://twitter.com/GaryMarcus/status/1581321739380092929,h/t @ErnestSDavis
2141,@GaryMarcus,2022-10-15 16:30:56+00:00,https://twitter.com/GaryMarcus/status/1581321737970782209,"Uh oh, @random_walker, I might have found a paper about methodology/data analysis even more depressing than the last one we discussed:

https://t.co/D4YOi6y5n8

‚ÄúEach of the 1,261 test models [from 73 teams] was ultimately a unique combination of data-analytical steps."" 

üò±"
2142,@GaryMarcus,2022-10-15 16:10:53+00:00,https://twitter.com/GaryMarcus/status/1581316693321998336,"@PessoaBrain @WiringTheBrain i think it‚Äôs a crude distinction that raises important issues, but it‚Äôs certainly not gospel, and just one tiny corner of what‚Äôs important in cognitive psychology. But since everyone knows it, it‚Äôs sometime decent shorthand for some things."
2143,@GaryMarcus,2022-10-15 16:08:46+00:00,https://twitter.com/GaryMarcus/status/1581316158032318465,"@VidurMahajan1 @MatthewJBar @kevin2kelly @maxaltl and I wrote about this @statnews in 2019, still relevant: https://t.co/rxTTNxaMrl"
2144,@GaryMarcus,2022-10-15 15:23:53+00:00,https://twitter.com/GaryMarcus/status/1581304863530835969,"@alan_winfield seems very similar to the Wozniak coffee test, which is part of the bet I offered Musk"
2145,@GaryMarcus,2022-10-15 15:22:45+00:00,https://twitter.com/GaryMarcus/status/1581304579006005248,@shokunin_studio @AthenaAI2 @AshleyAitken @jjhikes @Grady_Booch @davidchalmers42 @walidsaba
2146,@GaryMarcus,2022-10-15 15:19:55+00:00,https://twitter.com/GaryMarcus/status/1581303867509465088,"@hankejh @ylecun @davidchalmers42 i first asked c Jan 2, 2018 and literally never got a substantive response. 
 
Still waiting üéµ 
Still waiting üéµ
https://t.co/auJsZYyv83"
2147,@GaryMarcus,2022-10-15 15:13:14+00:00,https://twitter.com/GaryMarcus/status/1581302182644969473,@hankejh @ylecun @davidchalmers42 I am still waiting to see what part of the so-called ‚Äúrearguard‚Äù worldview I laid out in 2017-2020 LeCun actually disagrees with ü§£
2148,@GaryMarcus,2022-10-15 15:00:04+00:00,https://twitter.com/GaryMarcus/status/1581298871002890241,"wow! @ylecun, who just called me ‚Äúrearguard‚Äù again, lobbying for world models (since 2019 the key focus of my GPT critique that he initially called rearguard) &amp; calling for some innateness.   (@davidchalmers42 might recall that at 2017 debate LeCun said zero innateness required.)"
2149,@GaryMarcus,2022-10-15 14:52:42+00:00,https://twitter.com/GaryMarcus/status/1581297018324267012,"Think carefully, @ylecun. The last time you hurled the insult ‚Äúrearguard‚Äù at me, you eventually turned around and adopted *precisely* the claim I was making. 

Receipts enclosed:

https://t.co/rTEVpYs1CG

Do you want to be remembered as a bully, or as a leader?"
2150,@GaryMarcus,2022-10-14 23:38:52+00:00,https://twitter.com/GaryMarcus/status/1581067043465723904,@davidchalmers42 @philljkc can you more fully articulate the intuition about why more fully general means more serious candidate? why draw the line between there and alpha star?
2151,@GaryMarcus,2022-10-14 23:37:22+00:00,https://twitter.com/GaryMarcus/status/1581066666376843264,@nlpnyc @MatthewJBar @kevin2kelly i agree target might move; it‚Äôs the charity i objected too. but: will radiologists still have something useful to contribute in 2033? I say yes.
2152,@GaryMarcus,2022-10-14 23:36:27+00:00,https://twitter.com/GaryMarcus/status/1581066432825405440,"@philljkc @davidchalmers42 socioeconomic reality is different q. than current discussion w David Chalmers re sentience. 

Existing AI has already had economic impact, without any generality at all. i think we can agree on that.

otoh the lack of generality has meant that few jobs have been replaced in toto"
2153,@GaryMarcus,2022-10-14 23:07:24+00:00,https://twitter.com/GaryMarcus/status/1581059123252428802,"@MatthewJBar @kevin2kelly 1. If humans are just rubber stamps, I lose. 
2. Depends on what the regulator‚Äôs case is. I would not want to claim victory if a union simply didn‚Äôt want to let qualified machines in. 
3. Fully displace means we don‚Äôt pay radiologists any more because what they do is redundant."
2154,@GaryMarcus,2022-10-14 23:03:50+00:00,https://twitter.com/GaryMarcus/status/1581058224496996352,"@nlpnyc @MatthewJBar @kevin2kelly well, no, that‚Äôs not ‚Äúfairness‚Äù to Hinton, its rewriting history, to give him a second chance. 

He literally said, ‚Äúwe might as well stop training radiologists.‚Äù

https://t.co/bzemVpAweP"
2155,@GaryMarcus,2022-10-14 22:53:40+00:00,https://twitter.com/GaryMarcus/status/1581055667766689793,"I hereby bet publicly that AI will not fully displace radiologists (as opposed to merely augmenting them) before the year 2033. 

That will be sixteen years after Hinton estimated five.

 @MatthewJBar cc @kevin2kelly"
2156,@GaryMarcus,2022-10-14 22:49:20+00:00,https://twitter.com/GaryMarcus/status/1581054575960010758,"@davidchalmers42 i‚Äôm not really seeing the testable claim here, eg the particulars that might matter"
2157,@GaryMarcus,2022-10-14 22:41:30+00:00,https://twitter.com/GaryMarcus/status/1581052608177147904,"@nlpnyc @DrHughHarvey @ylecun Prince was right, ‚Äúforever is a mighty long time‚Äù. But I think we can place bets around the next 10-20 years. 

And perpetual motion ain‚Äôt coming, ever."
2158,@GaryMarcus,2022-10-14 22:39:54+00:00,https://twitter.com/GaryMarcus/status/1581052202671824896,"If Optimus could solve all the motor control problems Tesla aims to solve, and we had to now install a ‚Äúgeneral intelligence‚Äù in it, in order to make it a safe and useful domestic humanoid robot, what would we install? 

AlphaStar and LLMs would surely be unsafe &amp; inadequate."
2159,@GaryMarcus,2022-10-14 22:36:06+00:00,https://twitter.com/GaryMarcus/status/1581051246232100864,"@philljkc is there any metric of general intelligence that you find satisfactory? do you think that that alpha* is progress towards *general* intelligence? or are you just saying we have a better handle on the problem?

&amp; @davidchalmers42 is Alpha* a ‚Äúserious candidate‚Äù for sentience?"
2160,@GaryMarcus,2022-10-14 22:08:44+00:00,https://twitter.com/GaryMarcus/status/1581044360048934912,What‚Äôs the best evidence that we are/are not significantly closer to ‚Äúgeneral‚Äù artificial intelligence now than in the days (1959) of General Problem Solver? https://t.co/mdLKz7Kbvn
2161,@GaryMarcus,2022-10-14 21:56:59+00:00,https://twitter.com/GaryMarcus/status/1581041401881833473,"@davidchalmers42 Why would an AI that passes a bunch of mouse cognition tasks be a more ‚Äúserious candidate‚Äù than a ‚Äòsmart‚Äô thermostat which has sensors, models of world &amp; goals that influence how it affects the world?

PS ‚Äúserious candidate‚Äù seems pretty weak in that it seems very hard to falsify"
2162,@GaryMarcus,2022-10-14 21:11:50+00:00,https://twitter.com/GaryMarcus/status/1581030040116264961,@coreylynch thanks! appreciate the detailed and candid answer.
2163,@GaryMarcus,2022-10-14 20:52:55+00:00,https://twitter.com/GaryMarcus/status/1581025280176828419,@IntuitMachine it suggests some kind of disconnect that any theory needs to face; saying A can in principle do B without direct evidence is very speculative and ignores the realities of how A and B differ. it‚Äôs not necessarily wrong but the problem needs to be faced head on
2164,@GaryMarcus,2022-10-14 20:50:27+00:00,https://twitter.com/GaryMarcus/status/1581024657909907456,@davidchalmers42 and does your claim basically reduce to ‚Äúwe will get to sentience in AI when we get to mouse level general intelligence‚Äù? why/why not?
2165,@GaryMarcus,2022-10-14 20:49:25+00:00,https://twitter.com/GaryMarcus/status/1581024399087767552,@IntuitMachine you have to deal with the fact that deep learning (putatively system i) is not reasoning well
2166,@GaryMarcus,2022-10-14 20:48:01+00:00,https://twitter.com/GaryMarcus/status/1581024046816571392,"@serbantanasa yes, and my book kluge is about hacks in the evolution of cognition"
2167,@GaryMarcus,2022-10-14 20:46:46+00:00,https://twitter.com/GaryMarcus/status/1581023731786616832,"@davidchalmers42 you say sentience ‚â† intelligence, yet at the same time: passing measures of general intelligence make you a strong candidate for sentience qua awareness.

are you saying then that there is a minimum intelligence you need, to have awareness and that you think mice have it?"
2168,@GaryMarcus,2022-10-14 19:26:34+00:00,https://twitter.com/GaryMarcus/status/1581003548237926401,@thisMabu @ylecun @AMPimaging @warren_craddock @erikbryn @DrHughHarvey @DrLaurenOR @maxaltl @zakkohane to understand what he is saying. he is a smart guy but i have no idea what he could mean here. nobody in medicine is buying what we think he might be saying. is he saying something different? what?
2169,@GaryMarcus,2022-10-14 19:21:57+00:00,https://twitter.com/GaryMarcus/status/1581002387225194498,"This is the crux. Deep learning is (thus far) like System I, and so much of cognition requires System II-style reasoning, too. 

Until we have a good way of building reasoning and integrating it with more data-driven approaches, we shouldn‚Äôt kid ourselves that we are close to AGI"
2170,@GaryMarcus,2022-10-14 19:18:59+00:00,https://twitter.com/GaryMarcus/status/1581001640370671616,"@ak_panda @davidchalmers42 and yet the line here seems‚Äîin tension with that‚Äîto be that if you have enough intelligence of the right sort (eg general mouse intelligence, and not just for Go?), then you become a serious candidate for sentience."
2171,@GaryMarcus,2022-10-14 19:17:00+00:00,https://twitter.com/GaryMarcus/status/1581001143949611008,"@ylecun @DrHughHarvey i‚Äôm fine with ‚Äúnot any time soon‚Äù, but find the claim that augmentation and replacement are more or less the same to be implausible. we can do augmentation now; we can‚Äôt do replacement any time soon, because it requires much more reasoning and flexibility."
2172,@GaryMarcus,2022-10-14 19:15:28+00:00,https://twitter.com/GaryMarcus/status/1581000756265902081,"@maier_ak @hbou @ylecun @AMPimaging @warren_craddock @erikbryn @DrHughHarvey @DrLaurenOR @maxaltl @zakkohane Exactly. In radiology (and many other cases), the AI required for augmentation is far simpler than the AI required for human replacement. 

To say they are all  basically the same is to miss the crux of what needs to be solved."
2173,@GaryMarcus,2022-10-14 19:12:47+00:00,https://twitter.com/GaryMarcus/status/1581000082815881216,"@davidchalmers42 &amp; why next ten years in particular? some aspects of intelligence have advanced exponentially, others, eg building world models from perceptual data, more slowly. absent specificity about how particular aspects of cognition relate to sentience, extrapolation seems arbitrary."
2174,@GaryMarcus,2022-10-14 18:52:27+00:00,https://twitter.com/GaryMarcus/status/1580994961822343169,@davidchalmers42 and how are you defining sentience?
2175,@GaryMarcus,2022-10-14 18:50:50+00:00,https://twitter.com/GaryMarcus/status/1580994558988791809,"@davidchalmers42 we have systems now that exceed mice in some cognitive respects (eg playing board games) &amp; lag mice in others (navigating novel environments). why not then say that AlphaGo is sentient, since it is better than a mouse at Go? conversely, why would eg better nav entail sentience?"
2176,@GaryMarcus,2022-10-14 18:44:33+00:00,https://twitter.com/GaryMarcus/status/1580992976658239489,"@shokunin_studio @davidchalmers42 also, that leaves out the probably, and ‚Äúmimicking sentience‚Äù is essentially meaningless; did you really use that word @davidchalmers42? ELIZA mimics sentience, so does XiaoIce, Replika, GPT-3. Are you saying something new and different will probably happen?"
2177,@GaryMarcus,2022-10-14 18:40:26+00:00,https://twitter.com/GaryMarcus/status/1580991940463841281,@shokunin_studio @davidchalmers42 that was the exact quote?
2178,@GaryMarcus,2022-10-14 18:35:37+00:00,https://twitter.com/GaryMarcus/status/1580990726946836480,".@davidchalmers42, a reporter tells me you said yesterday, ‚ÄúWithin ten years, we‚Äôll probably have systems that are serious candidates for sentience.‚Äù

Is the quote correct? What do you foresee happening in those ten years that would make those future systems ‚Äúserious candidates‚Äù?"
2179,@GaryMarcus,2022-10-14 18:32:14+00:00,https://twitter.com/GaryMarcus/status/1580989877474455553,"@william_fcorrea @ylecun @AMPimaging @warren_craddock @erikbryn @DrHughHarvey @DrLaurenOR @maxaltl @zakkohane well, no; isn‚Äôt he saying ‚Äúthe underlying system is the same‚Äù?"
2180,@GaryMarcus,2022-10-14 18:31:22+00:00,https://twitter.com/GaryMarcus/status/1580989656501751808,"@ylecun @AMPimaging @warren_craddock @erikbryn @DrHughHarvey @DrLaurenOR @maxaltl @zakkohane so what are you saying, then?"
2181,@GaryMarcus,2022-10-14 17:47:55+00:00,https://twitter.com/GaryMarcus/status/1580978723150786560,"@ylecun @AMPimaging @warren_craddock @erikbryn @DrHughHarvey @DrLaurenOR @maxaltl @zakkohane same for what? are you saying convnets alone can replace radiologists? solve driving?  

i am puzzled as to what you are saying. doesn‚Äôt seem at all plausible if i interpreted correctly."
2182,@GaryMarcus,2022-10-14 16:18:00+00:00,https://twitter.com/GaryMarcus/status/1580956094972977152,@EricRWeinstein you actually finished? :)
2183,@GaryMarcus,2022-10-14 16:06:14+00:00,https://twitter.com/GaryMarcus/status/1580953136029929472,@EricRWeinstein seriously? or was this a joke?
2184,@GaryMarcus,2022-10-14 16:05:54+00:00,https://twitter.com/GaryMarcus/status/1580953049287512065,"sure, correlation doesn‚Äôt imply causation, but nor (in an era in which submarines and airplanes exist) does raw distance on a map  *rule out causation*."
2185,@GaryMarcus,2022-10-14 15:51:42+00:00,https://twitter.com/GaryMarcus/status/1580949476554199041,"@erikbryn @grsimari ‚Äúprobably‚Äù? even 5-years old are able to learn a wide (not infinite) range of novel tasks rapidly.

I don‚Äôt see so much as a contender to that in the entire AI space."
2186,@GaryMarcus,2022-10-14 03:36:26+00:00,https://twitter.com/GaryMarcus/status/1580764442048200705,"@warren_craddock @ylecun @erikbryn @DrHughHarvey @DrLaurenOR @maxaltl @zakkohane the job of a radiologist includes not just reading images (which convnets are suited to but (in some cases) reasoning about a patient‚Äôs history and reading unstructured text, two problems for which convnets are less suited. cc @AMPimaging"
2187,@GaryMarcus,2022-10-14 03:29:10+00:00,https://twitter.com/GaryMarcus/status/1580762610555031552,"@ylecun @erikbryn @DrHughHarvey @DrLaurenOR @maxaltl @zakkohane @warren_craddock you are going to need a lot more than convnets to replace most jobs in their entirety. 

augmentation is a much lower bar."
2188,@GaryMarcus,2022-10-14 01:47:15+00:00,https://twitter.com/GaryMarcus/status/1580736962612572160,"@pmddomingos i genuinely read it as implying sole cause but see the ambiguity now that you mention it; i advise you write your future statements about causality with more care‚Ä¶ 

i‚Äôd need to know a lot more before i would even say eg leading cause, &gt; fuel and supply lines"
2189,@GaryMarcus,2022-10-14 01:26:00+00:00,https://twitter.com/GaryMarcus/status/1580731615411855362,"@pmddomingos you said A caused B; you didn‚Äôt say A was one factor influencing  B. 

(don‚Äôt know details in California so can‚Äôt judge A‚Äôs specific effect on B)"
2190,@GaryMarcus,2022-10-14 01:19:13+00:00,https://twitter.com/GaryMarcus/status/1580729910238543873,@Plinz and misinformation risk in 2022 w custom LLMs &lt; $500k
2191,@GaryMarcus,2022-10-14 01:16:51+00:00,https://twitter.com/GaryMarcus/status/1580729314014023680,"@ylecun @erikbryn no. having a machine look at a radiology scan is very different from replacing the entire job of a radiologist as  @DrHughHarvey or @DrLaurenOR or @maxaltl or @zakkohane could explain.

and L2 and L5 are different problems with different requirements see eg @warren_craddock 

etc"
2192,@GaryMarcus,2022-10-14 01:12:30+00:00,https://twitter.com/GaryMarcus/status/1580728220475088898,"@pmddomingos nothing to do with fuel prices or supply lines, eh?"
2193,@GaryMarcus,2022-10-14 00:44:05+00:00,https://twitter.com/GaryMarcus/status/1580721068939313152,@montana_skeptic @thunderf00t link?
2194,@GaryMarcus,2022-10-14 00:40:04+00:00,https://twitter.com/GaryMarcus/status/1580720057302536193,"@hardmaru call it a Kluge, maybe? https://t.co/hQ7ihg2tJw and yet still more flexible than current AI!"
2195,@GaryMarcus,2022-10-14 00:35:39+00:00,https://twitter.com/GaryMarcus/status/1580718942984675328,@miguelisolano if it could do that without extensive specific training for each task i would definitely take notice. especially if it could then pick up new tasks as quickly as person.
2196,@GaryMarcus,2022-10-14 00:06:34+00:00,https://twitter.com/GaryMarcus/status/1580711625690345472,@brianebutler3 you might to look up the wozniak test in my essay in elon musk and agi at https://t.co/8ir1xKenr6
2197,@GaryMarcus,2022-10-13 23:13:18+00:00,https://twitter.com/GaryMarcus/status/1580698220560535556,@rasbt cc @erikbryn:
2198,@GaryMarcus,2022-10-13 23:08:14+00:00,https://twitter.com/GaryMarcus/status/1580696945299181568,"Great observation!

But note: you can‚Äôt teach a *generic AI* to predict 3D protein structure.

Of all the AIs that exist, vast majority *can‚Äôt learn* to predict protein structure well.

Only a tiny number‚Äîcarefully tailored to that problem‚Äîsucceed.

Any human can learn to make ‚òïÔ∏è"
2199,@GaryMarcus,2022-10-13 22:48:06+00:00,https://twitter.com/GaryMarcus/status/1580691877539753986,@c_caucheteux @JeanRemiKing see my two comments above.
2200,@GaryMarcus,2022-10-13 22:47:13+00:00,https://twitter.com/GaryMarcus/status/1580691657460453377,@c_caucheteux i have trouble with the way you are using ‚Äúdirect‚Äù; ‚Äúclear correlation‚Äù with moderate correlation does not entail ‚Äúshared mechanism‚Äù
2201,@GaryMarcus,2022-10-13 22:46:11+00:00,https://twitter.com/GaryMarcus/status/1580691397082247168,"@c_caucheteux this is very nice work, but thst (R^2 = .25) is a quarter of the variance; that tells that A and B have some relation, not that A is a realization of B."
2202,@GaryMarcus,2022-10-13 22:35:44+00:00,https://twitter.com/GaryMarcus/status/1580688767895371776,@togelius @kchonyc @davidchalmers42 @emilymbender @timnitGebru @hardmaru lack of interpretability breeds hype and overclaiming
2203,@GaryMarcus,2022-10-13 22:33:45+00:00,https://twitter.com/GaryMarcus/status/1580688269775634432,"@togelius @kchonyc @davidchalmers42 @emilymbender @timnitGebru @hardmaru well. we have a zillion systems that try to minimize error:max reward, eg DQN‚Äîbut they lack world models that are able to transfer knowledge.  (eg @dileeplearning on DQN &amp; Breakout). 

you need more than just high reward on a big training set."
2204,@GaryMarcus,2022-10-13 19:36:17+00:00,https://twitter.com/GaryMarcus/status/1580643604972072960,@YiMaTweets or a parrot a genius?
2205,@GaryMarcus,2022-10-13 14:15:12+00:00,https://twitter.com/GaryMarcus/status/1580562802947031040,"@peteflorence this is a cool work. what‚Äôs the strongest test you have of generalization to out of distribution language? 

great to see serious work in the SHRDLU spirit!"
2206,@GaryMarcus,2022-10-13 13:55:15+00:00,https://twitter.com/GaryMarcus/status/1580557784114147328,@erikbryn
2207,@GaryMarcus,2022-10-13 13:54:47+00:00,https://twitter.com/GaryMarcus/status/1580557666996617217,"human intelligence is far from being either general or optimal‚Äîyet it remains far more flexible &amp; broad than any current AI.

AGI need not replicate human intelligence, but we shouldn‚Äôt be tempted to call anything AGI if it lacks the wherewithal to address new problems on its own"
2208,@GaryMarcus,2022-10-13 02:06:50+00:00,https://twitter.com/GaryMarcus/status/1580379503087751170,@erikbryn @MelMitchell1 @jackclarkSF @dashstander https://t.co/j6Sz0Vb3iB and also https://t.co/1N4qeEn6uH for still relevant background
2209,@GaryMarcus,2022-10-13 02:05:53+00:00,https://twitter.com/GaryMarcus/status/1580379264620560384,"@erikbryn @MelMitchell1 @jackclarkSF @dashstander this has proven to be really difficult. i have suggested an open-ended comprehension challenge, but it would be difficult to automatize &amp; expensive to administer. When we stick to multiple choice, we will exams that are easy to grade but also easy to game: https://t.co/j6Sz0Vb3iB"
2210,@GaryMarcus,2022-10-13 01:56:45+00:00,https://twitter.com/GaryMarcus/status/1580376968339812352,@ylecun any clarification on this one?
2211,@GaryMarcus,2022-10-13 01:52:17+00:00,https://twitter.com/GaryMarcus/status/1580375841808461827,"@SteveCase exactly. center of gravity, but with things more distributed."
2212,@GaryMarcus,2022-10-12 23:49:43+00:00,https://twitter.com/GaryMarcus/status/1580344999060787201,"@sama @DanielleFong funny, Lex Fridman predicted that Austin would become the center of the AI world. 

I am at least for this once with @sama."
2213,@GaryMarcus,2022-10-12 22:55:29+00:00,https://twitter.com/GaryMarcus/status/1580331349520842752,and yet far more flexible than any current AI.
2214,@GaryMarcus,2022-10-12 22:51:47+00:00,https://twitter.com/GaryMarcus/status/1580330420100812800,@spiantado @CantlonLab and using mental state terms to express those feelings ;) let it all out BF!
2215,@GaryMarcus,2022-10-12 21:44:27+00:00,https://twitter.com/GaryMarcus/status/1580313471463608320,"@spiantado i see that he is angry, but why is this cool, exactly?"
2216,@GaryMarcus,2022-10-12 20:45:03+00:00,https://twitter.com/GaryMarcus/status/1580298523190652928,@amyalkon looks fake; look esp at the URL
2217,@GaryMarcus,2022-10-12 20:25:27+00:00,https://twitter.com/GaryMarcus/status/1580293593281232896,"@CorticalLabs very cool paper. have you looked at transfer, aka @dileeplearning‚Äôs study of @deepmind DQN Atari RL?

‚Äúsentience‚Äù does depend a bit on how you define it."
2218,@GaryMarcus,2022-10-12 20:08:23+00:00,https://twitter.com/GaryMarcus/status/1580289295507914752,wow
2219,@GaryMarcus,2022-10-12 19:48:51+00:00,https://twitter.com/GaryMarcus/status/1580284382610612224,@paulfkrause it would require an amendment for sure. but many jobs require such things.
2220,@GaryMarcus,2022-10-12 19:31:35+00:00,https://twitter.com/GaryMarcus/status/1580280035491344384,@TonyZador @davidchalmers42 @iris_oved @MelMitchell1 like this:
2221,@GaryMarcus,2022-10-12 19:27:44+00:00,https://twitter.com/GaryMarcus/status/1580279067081084930,so it does help to build in some physics innately
2222,@GaryMarcus,2022-10-12 19:02:54+00:00,https://twitter.com/GaryMarcus/status/1580272817773641728,"new rule: if you can‚Äôt get a security clearance, you can‚Äôt run for President."
2223,@GaryMarcus,2022-10-12 16:59:21+00:00,https://twitter.com/GaryMarcus/status/1580241725087715328,@tdverstynen @KordingLab @neuro_data @IntuitMachine hmm seems a bit confused about teleology to me.
2224,@GaryMarcus,2022-10-12 16:01:07+00:00,https://twitter.com/GaryMarcus/status/1580227070365691904,"@TonyZador @davidchalmers42 @iris_oved @MelMitchell1 they are few and far between but we need more effort in that direction cc @maier_ak, or maybe an altogether way of thinking about the problem"
2225,@GaryMarcus,2022-10-12 15:56:11+00:00,https://twitter.com/GaryMarcus/status/1580225829506019328,"@TonyZador @davidchalmers42 @iris_oved @MelMitchell1 convolution is a prior instilled in a neural net that works great! 

if we can‚Äôt instill the world‚Äôs knowledge in our machines somehow we don‚Äôt have AGI or anything close.

models of word sequences aren‚Äôt a solid substitute."
2226,@GaryMarcus,2022-10-12 15:43:55+00:00,https://twitter.com/GaryMarcus/status/1580222742879928320,@TonyZador @davidchalmers42 @iris_oved @MelMitchell1 yep i know the essay!
2227,@GaryMarcus,2022-10-12 15:38:38+00:00,https://twitter.com/GaryMarcus/status/1580221414543851525,@TonyZador @davidchalmers42 @iris_oved @MelMitchell1 and/or it might be easier just to learn to instill world knowledge directly into systems rather than evolve it all from scratch.
2228,@GaryMarcus,2022-10-12 15:37:54+00:00,https://twitter.com/GaryMarcus/status/1580221228736212992,@TonyZador @davidchalmers42 @iris_oved @MelMitchell1 here a long passage where i discussed this in 2018 (click to see whole image/ read all 3 pghs in full): https://t.co/izxxz65fNb
2229,@GaryMarcus,2022-10-12 15:33:28+00:00,https://twitter.com/GaryMarcus/status/1580220111390400513,@TonyZador @davidchalmers42 @iris_oved @MelMitchell1 to their peril! nobody does evolutionary ML in a way that remotely approximates the intricacy of what you can get in the real world through duplication and divergence of genes that are high in a genetic cascade.
2230,@GaryMarcus,2022-10-12 15:30:40+00:00,https://twitter.com/GaryMarcus/status/1580219406453714944,hot post-doc tip from @yudapearl https://t.co/Vr8RlETqH7
2231,@GaryMarcus,2022-10-12 15:29:22+00:00,https://twitter.com/GaryMarcus/status/1580219080648560640,"@TonyZador @davidchalmers42 @iris_oved @MelMitchell1 ugh, Tony. the mechanisms are entirely different. just because you can blur things together so they look similar at low resolution, doesn‚Äôt mean you should, if you want to understand the actual dynamics and mechanics."
2232,@GaryMarcus,2022-10-12 15:27:42+00:00,https://twitter.com/GaryMarcus/status/1580218659079073792,"@dimleve @ylecun @xamat absolutely, but that patent office guy was no crackpot, despite his ambitions."
2233,@GaryMarcus,2022-10-12 14:43:12+00:00,https://twitter.com/GaryMarcus/status/1580207462984318976,@ylecun @xamat and then there was that patent clerk with an alternative to Newtonian physics.
2234,@GaryMarcus,2022-10-12 03:37:42+00:00,https://twitter.com/GaryMarcus/status/1580039982752108546,@davidchalmers42 @iris_oved @MelMitchell1 @berent_iris @AnnieDuke
2235,@GaryMarcus,2022-10-12 03:37:10+00:00,https://twitter.com/GaryMarcus/status/1580039847472812033,"@davidchalmers42 @iris_oved @MelMitchell1 as the great Lila Gleitman said, ‚Äúempiricism is innate‚Äù https://t.co/JludLruw57"
2236,@GaryMarcus,2022-10-12 03:23:14+00:00,https://twitter.com/GaryMarcus/status/1580036343878791168,@davidchalmers42 relevant to your discussion
2237,@GaryMarcus,2022-10-12 03:20:09+00:00,https://twitter.com/GaryMarcus/status/1580035567861256193,any deep learning algorithms out there able to explain this visual+text political joke?
2238,@GaryMarcus,2022-10-12 02:26:27+00:00,https://twitter.com/GaryMarcus/status/1580022052227977216,@pmddomingos honestly i think we could celebrate both. but i stand by original statement.
2239,@GaryMarcus,2022-10-12 02:15:36+00:00,https://twitter.com/GaryMarcus/status/1580019321505714176,@pmddomingos i won‚Äôt claim full knowledge but hardly think you are arguing a sensible position. at best you are diving deep into an ocean of Two Wrongs Make A Right.
2240,@GaryMarcus,2022-10-12 02:07:10+00:00,https://twitter.com/GaryMarcus/status/1580017201695727616,@pmddomingos the reviews sound fabulous! https://t.co/u2Eeyb1tbk
2241,@GaryMarcus,2022-10-12 00:56:54+00:00,https://twitter.com/GaryMarcus/status/1579999516618465281,@pmddomingos spare me the condescension. you don‚Äôt have to buy into myths to see that what was done here to the native peoples was appalling.
2242,@GaryMarcus,2022-10-12 00:47:40+00:00,https://twitter.com/GaryMarcus/status/1579997193993273344,"@pmddomingos and may I recommend, relatedly, https://t.co/zlBXq2UaPU"
2243,@GaryMarcus,2022-10-12 00:27:41+00:00,https://twitter.com/GaryMarcus/status/1579992163156635648,"@pmddomingos we could celebrate and remember every day for a hundred years and not make up for what was done to them. 

so, no."
2244,@GaryMarcus,2022-10-12 00:10:45+00:00,https://twitter.com/GaryMarcus/status/1579987902003453952,"Interesting workshop! Evaluating and designing general AI, organized by @plinz et al 

The Captcha was so ambiguous I was barely able to sign up ü§£"
2245,@GaryMarcus,2022-10-12 00:03:57+00:00,https://twitter.com/GaryMarcus/status/1579986191016828928,"@DavidBrin @MetaDevo @WebSummit nice of you to post your vitriolic characterization both here and on LinkedIn, without any specific critiques. 

I don‚Äôt agree with everything that Chomsky says (either wrt linguistics or politics), but I do think he is right on, here: https://t.co/5menFc18c0"
2246,@GaryMarcus,2022-10-11 22:22:34+00:00,https://twitter.com/GaryMarcus/status/1579960677497987072,@YiMaTweets compatible: maybe; complete: i haven‚Äôt seen anything satisfying yet but live in hope :)
2247,@GaryMarcus,2022-10-11 21:49:01+00:00,https://twitter.com/GaryMarcus/status/1579952234695380992,"@grsimari @CoimbraSummit @paddycosgrave @WebSummit @ChomskyDotInfo What the answer to AGI is, it does not lie (fully) in the parts of model space that we have so far explored. 

Lots of exploration left to do!

https://t.co/lsg7mmDIB1"
2248,@GaryMarcus,2022-10-11 21:44:51+00:00,https://twitter.com/GaryMarcus/status/1579951184529752065,"@YiMaTweets @yudapearl @causal_science @Datascience__ Often agree with @YiMaTweets but here I fully agree with @yudapearl that (a) his ladder is critical, and (b) extant techniques haven‚Äôt yet gotten us safely to the top. 

Curious for @todd_gureckis‚Äôs thoughts here."
2249,@GaryMarcus,2022-10-11 21:23:43+00:00,https://twitter.com/GaryMarcus/status/1579945866714284032,"@iris_oved @davidchalmers42 @MelMitchell1 the other deep issue is whether it needs grounded in prior notions such as space, time, causality"
2250,@GaryMarcus,2022-10-11 21:16:15+00:00,https://twitter.com/GaryMarcus/status/1579943987921973248,"@grsimari @paddycosgrave @WebSummit @ChomskyDotInfo suppose it depends on your metric - $, publications, impact, hype, etc :)"
2251,@GaryMarcus,2022-10-11 20:49:19+00:00,https://twitter.com/GaryMarcus/status/1579937210065125376,@grsimari @paddycosgrave @WebSummit @ChomskyDotInfo simplified diagram we used to make this point in https://t.co/6US3UT28UM https://t.co/17QcatmuZy
2252,@GaryMarcus,2022-10-11 19:14:15+00:00,https://twitter.com/GaryMarcus/status/1579913288405897216,@vdignum @WebSummit it is! and live streamed. will post links when i get them :)
2253,@GaryMarcus,2022-10-11 14:19:14+00:00,https://twitter.com/GaryMarcus/status/1579839044019949569,"Personal and professional news: I am doing a duet with Noam Chomsky!

Nov 4th @WebSummit"
2254,@GaryMarcus,2022-10-11 03:25:36+00:00,https://twitter.com/GaryMarcus/status/1579674549498834945,üôÑ
2255,@GaryMarcus,2022-10-10 21:42:33+00:00,https://twitter.com/GaryMarcus/status/1579588218596777984,"@MelMitchell1 nice review too, by @page88"
2256,@GaryMarcus,2022-10-10 21:23:56+00:00,https://twitter.com/GaryMarcus/status/1579583532615479297,@TonyZador @MillerLabMIT @WiringTheBrain @LKayChicago @PessoaBrain @DrYohanJohn @JaumeTeixi @behaviOrganisms the building blocks ‚â† some of the building blocks
2257,@GaryMarcus,2022-10-10 21:23:32+00:00,https://twitter.com/GaryMarcus/status/1579583432484847616,"@TonyZador @MillerLabMIT @WiringTheBrain @LKayChicago @PessoaBrain @DrYohanJohn @JaumeTeixi @behaviOrganisms of course, but it is easily possible that there is some really important aspect of neuroscience that doesn‚Äôt simply immediately follow from the bits we do already partially understand."
2258,@GaryMarcus,2022-10-10 21:18:54+00:00,https://twitter.com/GaryMarcus/status/1579582267227529216,"@TonyZador @MillerLabMIT @WiringTheBrain @LKayChicago @PessoaBrain @DrYohanJohn @JaumeTeixi @behaviOrganisms based on a study of resistors and capacitors, i have figured out all there is to know about electronics!"
2259,@GaryMarcus,2022-10-10 21:08:06+00:00,https://twitter.com/GaryMarcus/status/1579579549339521025,@HelloSurgeAI @TristanThrush @candacerossio my post has been updated to reference these data and Scott‚Äôs pausing in light of these results.
2260,@GaryMarcus,2022-10-10 21:03:27+00:00,https://twitter.com/GaryMarcus/status/1579578379007053825,"@davidchalmers42 @De_dicto Steven Kosslyn certainly tried to argue this, IIRC"
2261,@GaryMarcus,2022-10-10 21:01:55+00:00,https://twitter.com/GaryMarcus/status/1579577992954916864,"@HelloSurgeAI as mentioned here, I would rather bet on @TristanThrush and @candacerossio‚Äôs #Winoground task: https://t.co/3HpudowoQG"
2262,@GaryMarcus,2022-10-10 20:59:26+00:00,https://twitter.com/GaryMarcus/status/1579577370507632641,some empirical data on the Dall/E/Imagen progress bet that @slatestarcodex initially thought that he had won.  looks like that bet isn‚Äôt over yet.
2263,@GaryMarcus,2022-10-10 20:39:09+00:00,https://twitter.com/GaryMarcus/status/1579572264148008961,"fascinating, and a reminder of how little we understand about our most prominent tools for AI"
2264,@GaryMarcus,2022-10-10 20:28:26+00:00,https://twitter.com/GaryMarcus/status/1579569568506589184,"@davidchalmers42 @EliasEskin could be that a lot rests on the scope of ordinary descriptions, and how seriously you take that plural (how many, how ordinary).  eg lots of metric visual information isn‚Äôt customarily included in natural language and might help in some cases"
2265,@GaryMarcus,2022-10-10 20:25:42+00:00,https://twitter.com/GaryMarcus/status/1579568879785115648,"@davidchalmers42 ah fair question, maybe a little hard to fully test practically (unless you are with Pylyshyn on images as propositions)"
2266,@GaryMarcus,2022-10-10 20:09:39+00:00,https://twitter.com/GaryMarcus/status/1579564841597296641,"I have a special contempt for this human being; may Agnew‚Äôs name remain long tarnished, and not forgotten."
2267,@GaryMarcus,2022-10-10 19:59:47+00:00,https://twitter.com/GaryMarcus/status/1579562359408189440,@davidchalmers42 i would be surprised if there zero effects (in many tasks) but also surprised if it fundamentally changed the game.  you still have a black box that lacks detailed world models that you can directly reason over.
2268,@GaryMarcus,2022-10-10 19:58:03+00:00,https://twitter.com/GaryMarcus/status/1579561921602523137,"@davidchalmers42 exactly, like this:"
2269,@GaryMarcus,2022-10-10 19:44:52+00:00,https://twitter.com/GaryMarcus/status/1579558601739620352,@glupyan @FelixHill84 @davidchalmers42 my bet is w cogsci
2270,@GaryMarcus,2022-10-10 19:44:12+00:00,https://twitter.com/GaryMarcus/status/1579558433690652672,"@davidchalmers42 surely it will help a little; the question is whether it will be enough to support reasoning and the construction and maintenance of world models. i don‚Äôt immediately see that it does.

(i am coauthor on a relevant paper accepted pending minor revisions that i can discuss soon.)"
2271,@GaryMarcus,2022-10-10 19:39:43+00:00,https://twitter.com/GaryMarcus/status/1579557305569677312,"@hardmaru @StabilityAI congrats! coup for them, excellent choice for you"
2272,@GaryMarcus,2022-10-10 19:38:10+00:00,https://twitter.com/GaryMarcus/status/1579556918468968448,@ProfNoahGian @JeffHorwitz @noUpside @TheAtlantic yes to the A/B but i will tell you offline what i expect on the first part
2273,@GaryMarcus,2022-10-10 17:39:49+00:00,https://twitter.com/GaryMarcus/status/1579527133692821504,"@DavidSKrueger yes, my position is quite similar to what you attached."
2274,@GaryMarcus,2022-10-10 15:06:29+00:00,https://twitter.com/GaryMarcus/status/1579488545391415298,@MoveToBinFolder @tegan_maharaj @DavidSKrueger @duncantrussell lots of viruses already do that; consequences will get worse if individual machines have more capacity to affect things in the world (eg power grids)
2275,@GaryMarcus,2022-10-10 15:05:33+00:00,https://twitter.com/GaryMarcus/status/1579488312406192129,"@tegan_maharaj @DavidSKrueger my view is that nearer term risks  like these deserve more attention than they current receive, but also that the x-risk community dismisses them as ‚Äúnot existential‚Äù, and they hence are less on many philanthropists‚Äô radar"
2276,@GaryMarcus,2022-10-10 13:50:15+00:00,https://twitter.com/GaryMarcus/status/1579469362452639746,"@DavidSKrueger convinced of what? i think it is prudent to cover all bases, but as i said i still don‚Äôt see any scenario that seems both plausible and near-term.  

would still be interested, for sure, if there was one."
2277,@GaryMarcus,2022-10-10 13:48:37+00:00,https://twitter.com/GaryMarcus/status/1579468949699584001,"@igilitschenski @DavidSKrueger i offered Elon a $100,000 bet on 7 years, but he didn‚Äôt respond"
2278,@GaryMarcus,2022-10-10 13:45:38+00:00,https://twitter.com/GaryMarcus/status/1579468198499745792,@username_alrea @neumarcx certainly worth investigating. @RTomMcCoy what‚Äôs the latest on reasoning with TPRs?
2279,@GaryMarcus,2022-10-10 13:43:10+00:00,https://twitter.com/GaryMarcus/status/1579467580469043200,"@ruskin147 i also warned of how hard outlier cases would be, in 2016: https://t.co/eLbmoH7Nfm"
2280,@GaryMarcus,2022-10-10 04:30:45+00:00,https://twitter.com/GaryMarcus/status/1579328560065835009,"@DavidSKrueger i do think we will get there, though not soon, and that is worth spending (some) time worrying about it now, but also that there many pressing risks with current tech that deserve plenty of attention."
2281,@GaryMarcus,2022-10-10 02:22:07+00:00,https://twitter.com/GaryMarcus/status/1579296186791792641,@Aella_Girl so many people didn‚Äôt like this one it became a meme:
2282,@GaryMarcus,2022-10-10 02:19:59+00:00,https://twitter.com/GaryMarcus/status/1579295648356388864,@marktenenholtz @Aella_Girl great thread
2283,@GaryMarcus,2022-10-09 22:39:08+00:00,https://twitter.com/GaryMarcus/status/1579240071127257089,@DVHenkelWallace @DavidSKrueger and autogenerated propaganda
2284,@GaryMarcus,2022-10-09 21:11:59+00:00,https://twitter.com/GaryMarcus/status/1579218138679635968,@JeffHorwitz @noUpside @TheAtlantic i was more worried about the primary content than the comments but see your point wrt commenters and differing dynamics across platforms
2285,@GaryMarcus,2022-10-09 21:07:50+00:00,https://twitter.com/GaryMarcus/status/1579217096600584192,"@noUpside @JeffHorwitz @TheAtlantic pretty sure that too will get worse, but don‚Äôt want to publicly give anyone specific ideas"
2286,@GaryMarcus,2022-10-09 21:07:04+00:00,https://twitter.com/GaryMarcus/status/1579216900483350528,@JeffHorwitz @noUpside @TheAtlantic good luck with that: https://t.co/rzIHGsnLmb
2287,@GaryMarcus,2022-10-09 21:06:36+00:00,https://twitter.com/GaryMarcus/status/1579216784691200000,@noUpside @JeffHorwitz @TheAtlantic and all that disconcerting data presumably collected before cost of custom #gpt-3-style LLM suddenly dropped below $500k last week.
2288,@GaryMarcus,2022-10-09 21:05:22+00:00,https://twitter.com/GaryMarcus/status/1579216474384011265,"@joelgrus that one is arguable, certainly. addiction bad, echo chambers bad. empowerment in other ways good, etc eg https://t.co/YArP9Qha2Z"
2289,@GaryMarcus,2022-10-09 21:02:33+00:00,https://twitter.com/GaryMarcus/status/1579215764586123264,"@sleepinyourhat @emilymbender 1. those were specific examples where there has not been progress 
2. failure to progress on long discourse is principled, connected to the lack of world models 
3. road to AI is filled w similar fallacies eg expecting Watson to be good at oncology because it was good at Jeopardy"
2290,@GaryMarcus,2022-10-09 20:58:42+00:00,https://twitter.com/GaryMarcus/status/1579214797161496576,"@joelgrus writing, books, with their indirect effects of lifting all boats"
2291,@GaryMarcus,2022-10-09 20:57:43+00:00,https://twitter.com/GaryMarcus/status/1579214550259609600,"@joelgrus fire, agriculture, electricity, cell phones have come reasonably close"
2292,@GaryMarcus,2022-10-09 20:56:42+00:00,https://twitter.com/GaryMarcus/status/1579214293043929088,"@JeffHorwitz @noUpside @TheAtlantic that is roughly my fear, and expectation"
2293,@GaryMarcus,2022-10-09 20:55:12+00:00,https://twitter.com/GaryMarcus/status/1579213914604462080,"@JeffHorwitz @noUpside @TheAtlantic i already have seen some possible examples of whole set of fabricated, generated, cross-linked websites."
2294,@GaryMarcus,2022-10-09 20:53:08+00:00,https://twitter.com/GaryMarcus/status/1579213397346127873,@JeffHorwitz @noUpside @TheAtlantic i think the slight (and not so slight) varying in wording and style (to circumvent simple filters) combined with much lower cost is in fact likely to have massive effects.
2295,@GaryMarcus,2022-10-09 20:50:53+00:00,https://twitter.com/GaryMarcus/status/1579212830297161728,‚ÄúWe should only think about technology as radical of it benefits every person in the world‚Äù ‚Äì @dpatil https://t.co/kOsErWwE4U
2296,@GaryMarcus,2022-10-09 20:14:50+00:00,https://twitter.com/GaryMarcus/status/1579203755505233920,@username_alrea what scares me most is that i haven‚Äôt seen a system that can do that sort of thing *reliably*
2297,@GaryMarcus,2022-10-09 15:40:53+00:00,https://twitter.com/GaryMarcus/status/1579134814925754369,"@MichaelTrazzi are you asking, ‚Äúwhen‚Äù? it will happen, but I seriously doubt it will in next 20 years, and it‚Äôs hard to predict out much further, because it depends on when inherently unpredictable innovations might happen."
2298,@GaryMarcus,2022-10-09 15:31:37+00:00,https://twitter.com/GaryMarcus/status/1579132482032898049,"@MichaelTrazzi ‚Äúnew and more relevant [papers/post/github repos] come out before I can look at [the ones I'm already supposed to look at‚Äù 

yes, there is more to read and play with than ever before. 

no, we are not close to (general) superhuman intelligence."
2299,@GaryMarcus,2022-10-09 14:45:24+00:00,https://twitter.com/GaryMarcus/status/1579120850732974081,"@aa_gilli for sure, for centuries. but new scale will make it worse. and it has already cost humanity dearly"
2300,@GaryMarcus,2022-10-09 14:43:22+00:00,https://twitter.com/GaryMarcus/status/1579120339174686720,"@DavidSKrueger the thing that would most move me: a clear argument about a plausible scenario that is consistent with foreseeable current technology, rather than predicated on tech that seems very different from what we have now"
2301,@GaryMarcus,2022-10-09 14:39:53+00:00,https://twitter.com/GaryMarcus/status/1579119465236951040,"@moreisdifferent @DavidSKrueger and then there if Facebook M, all powerful, wildly hyped virtual assistant that was canceled, fleets of robotaxis that are still flaky, stuck in extremely limited routes, etc"
2302,@GaryMarcus,2022-10-09 14:34:11+00:00,https://twitter.com/GaryMarcus/status/1579118030545903617,@aa_gilli humans won‚Äôt be able to match the scale that we can expect
2303,@GaryMarcus,2022-10-09 14:31:47+00:00,https://twitter.com/GaryMarcus/status/1579117425643380736,h/t @jamescham cc @katestarbird @ProfNoahGian @EthanVPorter @timoreilly @sinanaral
2304,@GaryMarcus,2022-10-09 14:28:53+00:00,https://twitter.com/GaryMarcus/status/1579116694391640065,"‚Äúthe supply of misinformation will soon be infinite‚Äù‚Äîincredibly prescient Sept 2020 piece by @noUpside ‚Å¶@TheAtlantic‚Å©

Then: #GPT-3 was expensive &amp; private

Now:  Any troll farm can build a custom version trained on their own favorite lies, for $450k https://t.co/2yFkJtFw4v"
2305,@GaryMarcus,2022-10-09 05:13:32+00:00,https://twitter.com/GaryMarcus/status/1578976938949214209,@pmddomingos https://t.co/FaWOwXmrj0
2306,@GaryMarcus,2022-10-09 05:05:25+00:00,https://twitter.com/GaryMarcus/status/1578974892674134016,provocative post by @tegmark with interesting discussion at lesswrong.
2307,@GaryMarcus,2022-10-09 04:49:48+00:00,https://twitter.com/GaryMarcus/status/1578970964565839872,"@sleepinyourhat @emilymbender they can‚Äôt learn world models; they just vaguely approximate them by being parasitic on (complex) language statistics, which is why eg they are at chance on TruthfulQA"
2308,@GaryMarcus,2022-10-09 04:47:55+00:00,https://twitter.com/GaryMarcus/status/1578970488755585024,@sleepinyourhat @emilymbender do you dispute this limitations Pgh from BigBench: https://t.co/x5OhmDrcnN
2309,@GaryMarcus,2022-10-09 04:45:04+00:00,https://twitter.com/GaryMarcus/status/1578969775061217281,@sleepinyourhat @emilymbender @ErnestSDavis do you want to tell him?
2310,@GaryMarcus,2022-10-09 04:36:30+00:00,https://twitter.com/GaryMarcus/status/1578967618274619392,@pmddomingos @sabawalid deep learning in 2010: channeling Rosenblatt is never gonna work
2311,@GaryMarcus,2022-10-09 04:10:49+00:00,https://twitter.com/GaryMarcus/status/1578961156299190272,"@togelius gosh, that must be a LOT of browser tabs."
2312,@GaryMarcus,2022-10-09 03:09:32+00:00,https://twitter.com/GaryMarcus/status/1578945732165636096,@timpoliti @GidMK and also the one by @stuartbuck1 i link here:
2313,@GaryMarcus,2022-10-09 02:56:28+00:00,https://twitter.com/GaryMarcus/status/1578942445475500037,"why that Florida vaccine / cardiac arrest study is one of the shittiest pieces of faux ‚Äúscience‚Äù in a really long time. 

brutal dissection by @stuartbuck1"
2314,@GaryMarcus,2022-10-09 02:36:07+00:00,https://twitter.com/GaryMarcus/status/1578937322913267714,@joshu https://t.co/8xvOPUHxbz
2315,@GaryMarcus,2022-10-09 02:19:24+00:00,https://twitter.com/GaryMarcus/status/1578933113514004480,@togelius relevant to your thread?
2316,@GaryMarcus,2022-10-09 02:18:03+00:00,https://twitter.com/GaryMarcus/status/1578932776853991425,"üéá Enjoy the ultimate in (lexical) currency devaluation!

‚Äúsingularity‚Äù, 1993: ‚Äúsuperhuman intelligence‚Äù

‚Äúsingularity‚Äù, 2022: ‚Äúa lot of cool stuff is coming out on github and I can‚Äôt keep up!‚Äù"
2317,@GaryMarcus,2022-10-09 02:00:57+00:00,https://twitter.com/GaryMarcus/status/1578928473447739393,@MichaelTrazzi by ‚Äúsingularity‚Äù i mean ‚Äúmaking up new definitions for things so that they sound more dramatic‚Äù ü§£
2318,@GaryMarcus,2022-10-08 20:05:06+00:00,https://twitter.com/GaryMarcus/status/1578838917520195584,@stnor @JanelleCShane please dm or follow
2319,@GaryMarcus,2022-10-08 19:47:28+00:00,https://twitter.com/GaryMarcus/status/1578834480076558337,"hive mind, know any good standup comedy bits about AI? 

(youtube links would be especially appreciated!)"
2320,@GaryMarcus,2022-10-08 19:05:22+00:00,https://twitter.com/GaryMarcus/status/1578823885637976064,@sleepinyourhat @emilymbender what is it that makes you believe that (a) they won‚Äôt asymptote and also (b) resolve their regular errors of discomprehension and fabrication?
2321,@GaryMarcus,2022-10-08 18:36:22+00:00,https://twitter.com/GaryMarcus/status/1578816590464028672,@ylecun @Grady_Booch @karpathy and also Grady said ‚ÄúML use cases‚Äù
2322,@GaryMarcus,2022-10-08 18:15:32+00:00,https://twitter.com/GaryMarcus/status/1578811347424661504,"@ylecun @Grady_Booch @karpathy grady said ‚ÄúAI work‚Äù, you (yann) said AI research. these are different."
2323,@GaryMarcus,2022-10-08 18:05:39+00:00,https://twitter.com/GaryMarcus/status/1578808859338366977,@metainversos @DrSueSchneider exactly
2324,@GaryMarcus,2022-10-08 16:23:43+00:00,https://twitter.com/GaryMarcus/status/1578783207428100096,@MichaelTrazzi open tabs ‚â† singularity
2325,@GaryMarcus,2022-10-08 13:51:00+00:00,https://twitter.com/GaryMarcus/status/1578744776329146373,"@UlrichJunker hmm i think they have been ok at this, but interesting question."
2326,@GaryMarcus,2022-10-08 04:14:32+00:00,https://twitter.com/GaryMarcus/status/1578599700537970689,this thread is fire.
2327,@GaryMarcus,2022-10-08 04:13:59+00:00,https://twitter.com/GaryMarcus/status/1578599561614196736,@ylecun @amcafee too much to ask for you to recognize that the same considerations might apply to other long term avenues that might be worth exploring yet hard to fund given those constraints?
2328,@GaryMarcus,2022-10-07 21:32:51+00:00,https://twitter.com/GaryMarcus/status/1578498613314928641,"@Grady_Booch indeed, we made this point explicitly in Rebooting AI, 3 years ago. little has changed."
2329,@GaryMarcus,2022-10-07 21:30:58+00:00,https://twitter.com/GaryMarcus/status/1578498142722400258,"@DrSueSchneider you are kind of overlooking the differing innate contributions. it‚Äôs not just the data, it‚Äôs the starting place, too."
2330,@GaryMarcus,2022-10-07 21:28:40+00:00,https://twitter.com/GaryMarcus/status/1578497563329585152,"@pmddomingos for all X, such that X is a book, if an LLM L read X, L would have no clue."
2331,@GaryMarcus,2022-10-07 20:58:46+00:00,https://twitter.com/GaryMarcus/status/1578490038954135552,"@AmandaAskell agree w @AmandaAskell there is an important middle ground, call it near-term forseeable/plausible, that deserves real attention, that isn‚Äôt yet ‚Äúin development‚Äù in the sense of being coded, in testing stage etc 

eg perhaps @sleepinyourhat‚Äôs example of personalized propaganda bot"
2332,@GaryMarcus,2022-10-07 18:28:22+00:00,https://twitter.com/GaryMarcus/status/1578452188342341632,@tetraduzione @alirahimi0 @wellingmax would love your thoughts on this
2333,@GaryMarcus,2022-10-07 18:18:38+00:00,https://twitter.com/GaryMarcus/status/1578449738910683140,"if you aren‚Äôt concerned, you aren‚Äôt paying attention. source ‚Å¶@sleepinyourhat‚Å©, https://t.co/EcJlTafY33 https://t.co/ZpVs6hOpQ1"
2334,@GaryMarcus,2022-10-07 18:05:56+00:00,https://twitter.com/GaryMarcus/status/1578446541357842433,"@sleepinyourhat Glad to see you do this. I have some disagreements w you here (eg negation is far from solved), but this quote at the crux is 100% right: ‚ÄúPretty much every bad outcome we‚Äôre seeing from present-day NLP (and related technologies) could get a lot bigger and a lot worse.‚Äù"
2335,@GaryMarcus,2022-10-07 18:04:23+00:00,https://twitter.com/GaryMarcus/status/1578446151090458624,"‚ÄúPretty much every bad outcome we‚Äôre seeing from present-day NLP (and related technologies) could get a lot bigger and a lot worse.‚Äù 
‚Äì Sam Bowman"
2336,@GaryMarcus,2022-10-07 16:28:47+00:00,https://twitter.com/GaryMarcus/status/1578422094647373825,@yudapearl (think it is far from trivial; tied up now but will read this and respond; thanks for sharing it!)
2337,@GaryMarcus,2022-10-07 14:51:00+00:00,https://twitter.com/GaryMarcus/status/1578397486284013570,"üîîVirtually every important question in AI revolves around the scope and limits of generalization‚Äîyet there is little consensus about what generalization even means or how to test it. 

Check out @_dieuwke et al‚Äôs new synthesis, @genbench, to get some much-needed clarity."
2338,@GaryMarcus,2022-10-07 14:24:27+00:00,https://twitter.com/GaryMarcus/status/1578390802291531776,both humiliating and fair
2339,@GaryMarcus,2022-10-07 06:32:07+00:00,https://twitter.com/GaryMarcus/status/1578271939424006145,"ain‚Äôt saying that another AI winter is coming, but numbers like these in @chafkin‚Äôs cover story @bw are startling."
2340,@GaryMarcus,2022-10-07 00:32:09+00:00,https://twitter.com/GaryMarcus/status/1578181347893395456,@warren_craddock @BW and also the key limits. but i fully agree those nuances are where the critical questions lie
2341,@GaryMarcus,2022-10-07 00:31:13+00:00,https://twitter.com/GaryMarcus/status/1578181116153933825,@warren_craddock @yasaman_razeghi @guyvdb definitely DL is more than memorization; i must have said in a context to get across a quick intuition to a naive reader and even there I hedged.
2342,@GaryMarcus,2022-10-07 00:22:02+00:00,https://twitter.com/GaryMarcus/status/1578178804312219648,"@warren_craddock this concise popularization doesn‚Äôt capture the more nuanced view i always express when given space, re training distribution"
2343,@GaryMarcus,2022-10-07 00:20:55+00:00,https://twitter.com/GaryMarcus/status/1578178521695854594,@warren_craddock this is too coarse: see distinction above
2344,@GaryMarcus,2022-10-07 00:20:20+00:00,https://twitter.com/GaryMarcus/status/1578178375910273024,"@warren_craddock for 25 years i have distinguished within distribution generalization (which many neural nets do well) and outside of distribution generalization (which still poses problems).

https://t.co/oApV9oDaZP 

recent work by @yasaman_razeghi et al and @guyvdb show this remains key issue"
2345,@GaryMarcus,2022-10-06 13:33:23+00:00,https://twitter.com/GaryMarcus/status/1578015566190608384,"@sucholutsky @todd_gureckis @ylecun my commitment is to the fact the symbol manipulation is a necessary but not sufficient part of general intelligence. 

@todd_gureckis‚Äôs post is suggesting new ways in which that part of the contribution to general intelligence might be discovered."
2346,@GaryMarcus,2022-10-06 13:30:08+00:00,https://twitter.com/GaryMarcus/status/1578014748519518209,"@KordingLab @tiagopeixoto @yudapearl @pmddomingos @StephenPiment @ylecun @aminkarbasi @AlexTensor the capacity for meta learning itself might have an innate basis, that most animals likely lack"
2347,@GaryMarcus,2022-10-06 13:29:26+00:00,https://twitter.com/GaryMarcus/status/1578014571473776641,"@pmddomingos @yudapearl @AlexTensor @StephenPiment @ylecun @aminkarbasi @KordingLab this is completely arbitrary. you don‚Äôt actually know the number, and you don‚Äôt have a trade #off curve for eg .75x vs 1.25x (on any metric). 

would human brain development work better or worse if we has 75% of the genes we have?

as simple as possible doesn‚Äôt entail tiny"
2348,@GaryMarcus,2022-10-06 06:13:29+00:00,https://twitter.com/GaryMarcus/status/1577904859935711232,"@pmddomingos @yudapearl @AlexTensor @StephenPiment @ylecun @aminkarbasi @KordingLab why is it to essential to reduce it to say 5 things rather than 8? what is the argument that a slightly smaller list is more likely to succeed than a slightly larger list? and what system, ever, has induced causality?"
2349,@GaryMarcus,2022-10-05 01:12:31+00:00,https://twitter.com/GaryMarcus/status/1577466733803159552,"@frankcarey same thing w medical advice, therapy etc. fine for surrealist prose, tho"
2350,@GaryMarcus,2022-10-05 00:54:39+00:00,https://twitter.com/GaryMarcus/status/1577462237408567296,"@frankcarey if you show me 90 examples of a driverless car making a good left and the 10 other times it crashes, you have a demo rather than a solution"
2351,@GaryMarcus,2022-10-05 00:53:38+00:00,https://twitter.com/GaryMarcus/status/1577461980574543872,@frankcarey and they aren‚Äôt one-off; i gave a dozen of a similar sort the other day and nobody even gave a single counterexample. so you have wrong logic and have distorted the facts
2352,@GaryMarcus,2022-10-05 00:51:47+00:00,https://twitter.com/GaryMarcus/status/1577461516047069184,"@frankcarey it‚Äôs not reliable. the prompt took a few minutes to break. 

in anything that can change profoundly change someone‚Äôs life we need some measure of reliability, and this approach doesn‚Äôt have it (eg in robustness across prompts)"
2353,@GaryMarcus,2022-10-04 23:33:53+00:00,https://twitter.com/GaryMarcus/status/1577441911731720193,@pmddomingos @yudapearl @StephenPiment @ylecun @aminkarbasi @AlexTensor @KordingLab some of the symbolic reasoning will be about (hypothesized and sometimes underdifferentiated) causal relationships.
2354,@GaryMarcus,2022-10-04 23:26:32+00:00,https://twitter.com/GaryMarcus/status/1577440060957261824,"@pmddomingos @yudapearl @StephenPiment @ylecun @aminkarbasi @AlexTensor @KordingLab and the neural net can massively mess up the counterfactuals, or decide that mixing cranberry juice and grape juice will kill you if the word ‚Äúdie‚Äù is correlated in some corpus with the phrase ‚Äúvery thirsty‚Äù.  

medical advice from an acausal LLM would be a disaster. https://t.co/svGp44lk2S"
2355,@GaryMarcus,2022-10-04 21:41:45+00:00,https://twitter.com/GaryMarcus/status/1577413692953542656,"great thread! I agree both there is a ton of progress and that we need to reflect on it deeply‚Äîeven though I doubt the progress has much to do with AGI per se. 

All of these things can be true at once."
2356,@GaryMarcus,2022-10-04 21:40:10+00:00,https://twitter.com/GaryMarcus/status/1577413291571224576,@Alber_RomGar @TaliaRinger awesome quote from @TaliaRinger!
2357,@GaryMarcus,2022-10-04 21:33:26+00:00,https://twitter.com/GaryMarcus/status/1577411598531952643,@Jaber_Hassoun @AmandaAskell why?
2358,@GaryMarcus,2022-10-04 15:25:11+00:00,https://twitter.com/GaryMarcus/status/1577318923800023041,üî•
2359,@GaryMarcus,2022-10-04 13:17:21+00:00,https://twitter.com/GaryMarcus/status/1577286753735835648,@pmddomingos @StephenPiment @ylecun @aminkarbasi @AlexTensor @KordingLab @yudapearl how will you physical and psychological reasoning without it?
2360,@GaryMarcus,2022-10-04 13:16:34+00:00,https://twitter.com/GaryMarcus/status/1577286556699983873,"@pmddomingos @yudapearl @ylecun @aminkarbasi @AlexTensor @KordingLab if your inductive bias includes logic, things definitely become more interesting"
2361,@GaryMarcus,2022-10-04 13:15:32+00:00,https://twitter.com/GaryMarcus/status/1577286296590241794,"@pmddomingos @sabawalid @guyvdb i wrote a whole book, as you know, about why simple neural networks couldn‚Äôt extend universally quantified one-to-one mappings. the failures on multiplication show that this is still a problem with newer tech.

i don‚Äôt see how you get to proper unification from there."
2362,@GaryMarcus,2022-10-04 04:07:50+00:00,https://twitter.com/GaryMarcus/status/1577148464663707648,"episode 3012 in ‚ÄúAGI is gonna be wild‚Äù:
source: https://t.co/VYLfjx4zY2 https://t.co/g8NKTKyT6n"
2363,@GaryMarcus,2022-10-04 04:02:38+00:00,https://twitter.com/GaryMarcus/status/1577147156188008449,@pmddomingos @sabawalid @guyvdb prove it (or at least demonstrate it)
2364,@GaryMarcus,2022-10-04 03:14:53+00:00,https://twitter.com/GaryMarcus/status/1577135140152934404,@_jasonwei @pkghosh99 @pmddomingos @guyvdb @GoogleAI @TristanThrush thank you! i am continuing to nag @MetaAI about making Winoground available without onerous licensing restrictions; @guyvdb want to offer anything to try?
2365,@GaryMarcus,2022-10-04 03:11:46+00:00,https://twitter.com/GaryMarcus/status/1577134353699987456,@_jasonwei @pkghosh99 @pmddomingos @guyvdb i keep imagining a 7th grade math teacher hearing that from an irate parent
2366,@GaryMarcus,2022-10-04 03:08:41+00:00,https://twitter.com/GaryMarcus/status/1577133577849868288,"@_jasonwei @pkghosh99 @pmddomingos @guyvdb page 30, figure 8 https://t.co/McgKYXmbw1"
2367,@GaryMarcus,2022-10-04 03:04:30+00:00,https://twitter.com/GaryMarcus/status/1577132526262685696,"@_jasonwei @pkghosh99 @pmddomingos @guyvdb would @GoogleAI be willing to let the scientific community test some these things? eg @guyvdb on reasoning, @TristanThrush on compositionality?"
2368,@GaryMarcus,2022-10-04 03:02:29+00:00,https://twitter.com/GaryMarcus/status/1577132019930501120,@_jasonwei @pkghosh99 @pmddomingos @guyvdb it‚Äôs in the appendices iirc
2369,@GaryMarcus,2022-10-04 02:54:11+00:00,https://twitter.com/GaryMarcus/status/1577129931532042240,"@_jasonwei @pkghosh99 @pmddomingos you have any comments on the paper by @guyvdb that I cited above, which shows that not all that glitters is gold? have you done comparable analyses?

on 4 digit multiplication many teenagers significantly outperform Minerva."
2370,@GaryMarcus,2022-10-04 02:10:01+00:00,https://twitter.com/GaryMarcus/status/1577118813359058944,"@stanislavfort @jack_merullo_ eg such that they can reliably understand function or wholes in terms of their parts, per https://t.co/Xnyh3pTeNo"
2371,@GaryMarcus,2022-10-04 02:08:16+00:00,https://twitter.com/GaryMarcus/status/1577118375456956416,@stanislavfort @jack_merullo_ i don‚Äôt think any of things have models of the world
2372,@GaryMarcus,2022-10-04 02:01:29+00:00,https://twitter.com/GaryMarcus/status/1577116667339231232,"@stanislavfort @jack_merullo_ in a large sea of moderate but unreliable correlations, why is this especially unexpected?"
2373,@GaryMarcus,2022-10-04 01:59:58+00:00,https://twitter.com/GaryMarcus/status/1577116285841788928,"@pmddomingos @sabawalid your ‚Äú therefore‚Äù is speculation, and the @guyvdb paper above casts doubt on it"
2374,@GaryMarcus,2022-10-04 01:49:01+00:00,https://twitter.com/GaryMarcus/status/1577113531081576449,@pkghosh99 @ylecun whilst pretending all is hunky dory. no technical debt here!
2375,@GaryMarcus,2022-10-04 01:41:15+00:00,https://twitter.com/GaryMarcus/status/1577111576145903621,@pmddomingos @pwlot @KordingLab @ylecun agreed
2376,@GaryMarcus,2022-10-04 01:40:55+00:00,https://twitter.com/GaryMarcus/status/1577111490318192642,@pmddomingos more likely harder: https://t.co/TaNgC6kIlg
2377,@GaryMarcus,2022-10-04 00:41:21+00:00,https://twitter.com/GaryMarcus/status/1577096499926044673,"@pmddomingos presumes that they can be ‚Äúminimally‚Äù extended to do so, but eg that might require going deeper into the black box than is possible"
2378,@GaryMarcus,2022-10-04 00:39:41+00:00,https://twitter.com/GaryMarcus/status/1577096080143290369,"@pmddomingos who says that? wise people recognize that pattern recognition can be done at different levels of abstraction, and that the term is vague enough to encompass virtually everything. so they don‚Äôt frame the argument that way."
2379,@GaryMarcus,2022-10-04 00:29:14+00:00,https://twitter.com/GaryMarcus/status/1577093451241656320,@pwlot @KordingLab @pmddomingos @ylecun definitely +1 to integration/orchestration
2380,@GaryMarcus,2022-10-04 00:06:32+00:00,https://twitter.com/GaryMarcus/status/1577087738763153409,@KordingLab @pmddomingos @ylecun i would include that in reasoning and knowledge but it deserves to be highlighted
2381,@GaryMarcus,2022-10-04 00:05:52+00:00,https://twitter.com/GaryMarcus/status/1577087570571563008,@pmddomingos @ylecun hard agree
2382,@GaryMarcus,2022-10-04 00:00:46+00:00,https://twitter.com/GaryMarcus/status/1577086288532238336,"@pmddomingos @ylecun no reason to drop anything from that list (aside from quibbles about redundancy), and it‚Äôs presumably incomplete.

we have a long way to go."
2383,@GaryMarcus,2022-10-03 23:37:37+00:00,https://twitter.com/GaryMarcus/status/1577080460458356737,"@voxbec @ylecun then i think we actually agree; it's the thing that you call snake oil that i likened to rearranging deck chairs. 

fair to say there are other valid reasons, eg for understanding how models behave, as you say"
2384,@GaryMarcus,2022-10-03 23:34:26+00:00,https://twitter.com/GaryMarcus/status/1577079660235853824,"@voxbec @ylecun sure, fine to do it systematically if you want to know how model behaves. 

but not fine to say, a system knows X if you can find some prompt P' to elicit X, when it often says not-X

nor to conclude that the not-X problem is solved  because some prompt P' can elicit X"
2385,@GaryMarcus,2022-10-03 23:31:54+00:00,https://twitter.com/GaryMarcus/status/1577079023766999040,@begusgasper my 8-year old and 9-year old had no trouble.
2386,@GaryMarcus,2022-10-03 23:15:36+00:00,https://twitter.com/GaryMarcus/status/1577074921783840769,"@pmddomingos @ylecun my suggestion:
- neurosymbolic algorithms
- large scale knowledge
- reasoning from incomplete info
- rich cognitive models
https://t.co/rbeWGMenKO"
2387,@GaryMarcus,2022-10-03 22:05:14+00:00,https://twitter.com/GaryMarcus/status/1577057211469115392,"@voxbec @ylecun people keep (see last couple days for many examples) using engineered prompts to try to claim that the models know much more than they do.

it‚Äôs fine if you want to generate a story; not if you want to do science to try understand the status of AI and do it carelessly"
2388,@GaryMarcus,2022-10-03 21:19:19+00:00,https://twitter.com/GaryMarcus/status/1577045657202098176,@pmddomingos SVM‚Äôs used to have a lot of momentum. Expert systems used to have a lot of momentum.
2389,@GaryMarcus,2022-10-03 16:49:36+00:00,https://twitter.com/GaryMarcus/status/1576977779819950080,"Prompt Engineering is like rearranging the deck chairs on the Titanic.

The sooner people can join @ylecun and me in recognizing that true intelligence isn‚Äôt coming from #GPT-3 alone, the better."
2390,@GaryMarcus,2022-10-03 16:38:17+00:00,https://twitter.com/GaryMarcus/status/1576974933695270912,@pmddomingos that presumes they will play a vital role.
2391,@GaryMarcus,2022-10-03 14:45:08+00:00,https://twitter.com/GaryMarcus/status/1576946459345588225,"example from @miguelisolano, riffing on examples from @sabawalid"
2392,@GaryMarcus,2022-10-03 14:45:08+00:00,https://twitter.com/GaryMarcus/status/1576946457600749569,can we please just stop thinking that systems like this are on the road to AGI? https://t.co/jP8JInSWLG
2393,@GaryMarcus,2022-10-03 14:30:13+00:00,https://twitter.com/GaryMarcus/status/1576942702310363138,"@miguelisolano @sabawalid @pkghosh99 @davidchalmers42 @DotCSV no, just across all reasonable wordings of questions like @sabawalid posed (&amp; not just the wordings for phds who are studying prompt engineering)"
2394,@GaryMarcus,2022-10-03 14:27:35+00:00,https://twitter.com/GaryMarcus/status/1576942041535479808,@Grady_Booch ü§£ü§£ü§£. all true! except for the word simple.
2395,@GaryMarcus,2022-10-03 14:26:50+00:00,https://twitter.com/GaryMarcus/status/1576941852464672768,"@TrueAttorney @JrKibs @MelMitchell1 and we aren‚Äôt at 99% (or even close), integrating across all the prompts that a reasonable user might pose for any given question"
2396,@GaryMarcus,2022-10-03 14:25:46+00:00,https://twitter.com/GaryMarcus/status/1576941583492349953,@miguelisolano @MelMitchell1 @sabawalid
2397,@GaryMarcus,2022-10-03 14:12:25+00:00,https://twitter.com/GaryMarcus/status/1576938222642692098,"@miguelisolano @pkghosh99 @davidchalmers42 @sabawalid @DotCSV don‚Äôt think that will help w @sabawalid‚Äôs cases that decouple that stats of language from the stats of the world, unless the external mechanisms themselves model the world"
2398,@GaryMarcus,2022-10-03 13:57:21+00:00,https://twitter.com/GaryMarcus/status/1576934433982418944,About damn time https://t.co/LjrCKDndi1
2399,@GaryMarcus,2022-10-03 13:54:13+00:00,https://twitter.com/GaryMarcus/status/1576933644207214599,@SColesPorter @sianbeilock @ubcprez please share with your peers
2400,@GaryMarcus,2022-10-03 13:50:43+00:00,https://twitter.com/GaryMarcus/status/1576932762275041280,@pkghosh99 @MelMitchell1 the frog of good sense about AI has boiled away
2401,@GaryMarcus,2022-10-03 13:50:16+00:00,https://twitter.com/GaryMarcus/status/1576932652221071360,@IntuitMachine no. you will see the same with any finite training set; too much dependence on the idiosyncrasies and specifics
2402,@GaryMarcus,2022-10-03 13:41:14+00:00,https://twitter.com/GaryMarcus/status/1576930377410625536,https://t.co/vzq2C3vSY0
2403,@GaryMarcus,2022-10-03 13:38:21+00:00,https://twitter.com/GaryMarcus/status/1576929652341239809,"@IntuitMachine yes, but a programming language is systematic; prompt engineering is all over the place. 

proper program: works every time
prompt based LLM bot: you might it get it right; ask again if not"
2404,@GaryMarcus,2022-10-03 13:18:29+00:00,https://twitter.com/GaryMarcus/status/1576924653808807936,"@miguelisolano @pkghosh99 @davidchalmers42 getting something right occasionally does not mean you really understand it. 

here some more elegant examples from @sabawalid (cc @DotCSV), showing why statistical knowledge of word sequences is rarely robust:"
2405,@GaryMarcus,2022-10-03 13:15:15+00:00,https://twitter.com/GaryMarcus/status/1576923838340005890,"@mathemagic1an being able to ask a system a question in 5 different ways and *sometimes* get the answer you want is not good enough.

and most or all bug fixes are unstable and the problem is quite broad eg"
2406,@GaryMarcus,2022-10-03 03:57:06+00:00,https://twitter.com/GaryMarcus/status/1576783376732020737,"Serious lack of RCTs in medical ML. 

h/t @erictopol w reference below https://t.co/4DxeiGYmj9"
2407,@GaryMarcus,2022-10-03 00:17:27+00:00,https://twitter.com/GaryMarcus/status/1576728098560540673,"@miguelisolano @davidchalmers42 dying from crangrape juice is similar, no?"
2408,@GaryMarcus,2022-10-03 00:14:29+00:00,https://twitter.com/GaryMarcus/status/1576727351194701824,"@davidchalmers42 @miguelisolano why attribute a world model to a system that is at chance at this? https://t.co/X0GsSzf8w5

chance is what you expect if you don‚Äôt have a world model"
2409,@GaryMarcus,2022-10-03 00:07:30+00:00,https://twitter.com/GaryMarcus/status/1576725594657603584,@pwlot @davidchalmers42 @miguelisolano @sabawalid *my-) Ernie‚Äôs cranberry example in our tech review Bloviator essay
2410,@GaryMarcus,2022-10-03 00:05:50+00:00,https://twitter.com/GaryMarcus/status/1576725175324004352,"@pwlot @davidchalmers42 @miguelisolano @ylecun @Jake_Browning00 @emilymbender adding innate grounding could change that picture; in some sense that is how Pinker‚Äôs semantic bootstrapping hypothesis works, and i have advocated"
2411,@GaryMarcus,2022-10-03 00:02:54+00:00,https://twitter.com/GaryMarcus/status/1576724435020967938,@pwlot @davidchalmers42 @miguelisolano agree w your last sentence &amp; read @ylecun and @Jake_Browning00‚Äôa last essay similarly; ditto for @emilymbender
2412,@GaryMarcus,2022-10-03 00:00:10+00:00,https://twitter.com/GaryMarcus/status/1576723750803755014,"@pwlot @davidchalmers42 @miguelisolano to me this is obvious, and @sabawalid‚Äôs table example distills that perfectly (even better than my cranberry grape juice /death example).

really don‚Äôt understand why @davidchalmers42 seems to disagree

travels in text space vary answers but don‚Äôt inherently supply world models"
2413,@GaryMarcus,2022-10-02 23:56:51+00:00,https://twitter.com/GaryMarcus/status/1576722915520696320,@htenenbaum @Grady_Booch @bastianpurrer @mer__edith @humanID_org ok. but that sounds like not using warning labels on cigarettes because other things also can cause cancer
2414,@GaryMarcus,2022-10-02 23:55:01+00:00,https://twitter.com/GaryMarcus/status/1576722452574789632,@davidchalmers42 @miguelisolano putting it differently: being gullible is a *consequence* of lacking a world model; your question waves away some of the most diagnostic evidence
2415,@GaryMarcus,2022-10-02 23:53:35+00:00,https://twitter.com/GaryMarcus/status/1576722094145998848,"@davidchalmers42 @miguelisolano that doesn‚Äôt apply to the table case and i am sure we can find many others (eg portrait case i just linked). 

and part of the reason to have a world model is well too see whether what you hear is consistent with that world

no extant LLM can do that"
2416,@GaryMarcus,2022-10-02 23:51:20+00:00,https://twitter.com/GaryMarcus/status/1576721526921265153,@htenenbaum @Grady_Booch @bastianpurrer @mer__edith @humanID_org in part but not entirely. ordinary mortals amplify there messages. and bots do too
2417,@GaryMarcus,2022-10-02 23:48:47+00:00,https://twitter.com/GaryMarcus/status/1576720883997372417,"@miguelisolano @davidchalmers42 the portrait example here is an example of the difference between cut and paste (+) and having a bona fide world model of the processes being depicted. 

https://t.co/zskdYmKIPk"
2418,@GaryMarcus,2022-10-02 23:46:00+00:00,https://twitter.com/GaryMarcus/status/1576720185494364160,"@Grady_Booch @bastianpurrer @mer__edith @humanID_org hence the search for something like the above that preserves anonymity but requires some degree of accountability

not saying this particular proposal solves it"
2419,@GaryMarcus,2022-10-02 23:31:03+00:00,https://twitter.com/GaryMarcus/status/1576716421899636736,"@Grady_Booch @bastianpurrer @mer__edith @humanID_org and real costs, particularly around truthfulness, polarization. and accountability 

all exacerbated by decreasing cost of weaponized bots 

which is why it is worth searching seriously for innovative approaches. (not that i am certain of right one)"
2420,@GaryMarcus,2022-10-02 23:20:16+00:00,https://twitter.com/GaryMarcus/status/1576713708683681792,"@DotCSV @sabawalid twenty minutes later, @ErnestSDavis confirmed that this movie ends same as every other: with unreliability that shows how superficial the new prompt really is: https://t.co/IIYVIc9nyt"
2421,@GaryMarcus,2022-10-02 23:18:56+00:00,https://twitter.com/GaryMarcus/status/1576713370665095169,"@DotCSV @sabawalid grade school teachers expect answers to be robust across wording, if a student has mastered relevant concepts, and we should expect same of our NLU-driven AI."
2422,@GaryMarcus,2022-10-02 23:16:54+00:00,https://twitter.com/GaryMarcus/status/1576712861325590528,"@DotCSV as i predicted, this particular prompt has issues of its own. i am walking but @ErnestSDavis found some sample where it yield errors within a few minutes, eg https://t.co/jWozKHNo8s"
2423,@GaryMarcus,2022-10-02 23:14:47+00:00,https://twitter.com/GaryMarcus/status/1576712329466904577,"@DotCSV @sabawalid the question, use-case dependent, is whether it is going to be stable across range of ways a user might interact. 

it‚Äôs probably fairly obvious to most users that a knife shouldn‚Äôt be held by the sharp bits, but not that LLM answers can vary wildly as function of prompts."
2424,@GaryMarcus,2022-10-02 22:52:39+00:00,https://twitter.com/GaryMarcus/status/1576706757400743936,"@DotCSV @sabawalid I have seen this movie before, eg with let‚Äôs take this step by step

If you can‚Äôt know if you get answer til you device the prompt, and your prompts are from foolproof what have you got? https://t.co/zZh2RLeh7w"
2425,@GaryMarcus,2022-10-02 22:46:50+00:00,https://twitter.com/GaryMarcus/status/1576705294356267008,@DotCSV So what parameters distinguish between when you get sense and when you get nonsense? What‚Äôs the balance over 100 examples between the two? cc @sabawalid
2426,@GaryMarcus,2022-10-02 22:45:03+00:00,https://twitter.com/GaryMarcus/status/1576704845620580352,"Creepy cats and the uncanny valley!

https://t.co/4N4XWOg9wq"
2427,@GaryMarcus,2022-10-02 22:18:41+00:00,https://twitter.com/GaryMarcus/status/1576698210462334977,"Dumb as a box of rocks, and soon to be entrusted with all the power of the universe. 

GPT-3 can‚Äôt tell the difference between a person and a table üôÑ"
2428,@GaryMarcus,2022-10-02 21:51:17+00:00,https://twitter.com/GaryMarcus/status/1576691315722825734,@TonyZador @sd_marlow sorry I meant to say ‚Äúpartly‚Äù. i agree w you.
2429,@GaryMarcus,2022-10-02 18:46:48+00:00,https://twitter.com/GaryMarcus/status/1576644886685945856,@pmddomingos or products
2430,@GaryMarcus,2022-10-02 17:24:22+00:00,https://twitter.com/GaryMarcus/status/1576624141297651713,"@sd_marlow ha, the physical skillof  walking already a solved problem. i am sure they can catch up on that. but the self-guided part of that relative to user goals and a dynamic world is going to take them a bunch longer"
2431,@GaryMarcus,2022-10-02 17:00:23+00:00,https://twitter.com/GaryMarcus/status/1576618108122722305,"@jeblad now imagine the same tech, but less debugged, in a 150 pound domestic robot."
2432,@GaryMarcus,2022-10-02 16:03:26+00:00,https://twitter.com/GaryMarcus/status/1576603774101360640,@bastianpurrer @mer__edith @humanID_org @mer__edith @Grady_Booch i would be interested in your take on projects like the above: @humanID_org
2433,@GaryMarcus,2022-10-02 15:56:25+00:00,https://twitter.com/GaryMarcus/status/1576602010836955136,not sentient. not even smart. just clueless.
2434,@GaryMarcus,2022-10-02 15:29:51+00:00,https://twitter.com/GaryMarcus/status/1576595321513476097,March 2015: Tesla CEO Elon Musk and Nvidia CEO Jen-Hsun Huang declare self-driving cars ‚Äúsolved‚Äù | Fortune  https://t.co/shWDBa2rIN
2435,@GaryMarcus,2022-10-02 12:21:21+00:00,https://twitter.com/GaryMarcus/status/1576547885420023813,@tejasdkulkarni talk about shifting goalposts
2436,@GaryMarcus,2022-10-01 23:54:05+00:00,https://twitter.com/GaryMarcus/status/1576359831031926784,@ChrSzegedy @ylecun @rao2z @guyvdb @MITCoCoSci whatever happened to our bet? @ErnestSDavis and i were waiting on your to discuss rules‚Ä¶
2437,@GaryMarcus,2022-10-01 22:42:03+00:00,https://twitter.com/GaryMarcus/status/1576341704302825472,@gwestr and see my https://t.co/dUAuIH1SdZ
2438,@GaryMarcus,2022-10-01 22:39:19+00:00,https://twitter.com/GaryMarcus/status/1576341016046895104,@ChrSzegedy @ylecun @rao2z @guyvdb @MITCoCoSci https://t.co/tNmShg0jub
2439,@GaryMarcus,2022-10-01 20:48:06+00:00,https://twitter.com/GaryMarcus/status/1576313023769505792,@quinn_jono indeed i linked @chubicki in my own essay https://t.co/dUAuIH1SdZ
2440,@GaryMarcus,2022-10-01 16:45:23+00:00,https://twitter.com/GaryMarcus/status/1576251944854646784,"for balance read this, in addition to my own take &amp; @ctwy‚Äôs several threads :"
2441,@GaryMarcus,2022-10-01 16:41:35+00:00,https://twitter.com/GaryMarcus/status/1576250986100060161,"insightful, and somewhat more upbeat take than my own, by a roboticist I greatly admire, but also pointing to some of the issues around humility and corner cases.

read mine (@substack), read his, and form your own conclusions üòä"
2442,@GaryMarcus,2022-10-01 15:57:08+00:00,https://twitter.com/GaryMarcus/status/1576239801807691777,"@RobotCentral @animesh_garg on the other hand self-driving still hasn‚Äôt delivered and it‚Äôs not entirely clear that Tesla will ever get to Level 5. 

i actually address your issue in the latter part of the essay; have a look"
2443,@GaryMarcus,2022-10-01 15:39:03+00:00,https://twitter.com/GaryMarcus/status/1576235249721573378,with quotes from @ctwy @kengoldberg @alan_winfield and a guess about @ylecun might think (spoiler alert: I suspect he would agree)
2444,@GaryMarcus,2022-10-01 15:36:30+00:00,https://twitter.com/GaryMarcus/status/1576234607397462016,"Sub-Optimal: Last night‚Äôs @Tesla demo, and why so many roboticists were underwhelmed.

https://t.co/BnBNKfDlFj"
2445,@GaryMarcus,2022-10-01 14:17:01+00:00,https://twitter.com/GaryMarcus/status/1576214607919972352,thanks all!
2446,@GaryMarcus,2022-10-01 13:54:35+00:00,https://twitter.com/GaryMarcus/status/1576208960864260096,anyone with sharp eyes available on short notice? seeking a volunteer proofreader for my Optimus analysis üôè
2447,@GaryMarcus,2022-10-01 13:36:48+00:00,https://twitter.com/GaryMarcus/status/1576204485730664448,"ps my son, who just learned how Twitter works 5 minutes  ago WANTS AN EDIT BUTTON! 

*‚Äúgoing to go‚Äù"
2448,@GaryMarcus,2022-10-01 13:34:59+00:00,https://twitter.com/GaryMarcus/status/1576204027053817856,"9-year-old, ‚Äúwould you let the Tesla robot take care of Grandma?‚Äù
me: ‚ÄúAbsolutely not‚Äù
9-year-old: [Giggling]: ‚ÄúIt would just take a second to break‚Ä¶ it‚Äôs probably go to go falling over‚Äù"
2449,@GaryMarcus,2022-10-01 13:31:05+00:00,https://twitter.com/GaryMarcus/status/1576203047226966017,"hivemind, did you catch any roboticists that were markedly positive about last night‚Äôs demo? 

writing a wrap-up and want to include both sides‚Äîif there are two. I did see some mildly positive remarks from @animesh_garg; were there others?"
2450,@GaryMarcus,2022-10-01 12:44:42+00:00,https://twitter.com/GaryMarcus/status/1576191376060207104,"@concretejesus92 i didn‚Äôt even see a recognition of how hard the cognitive side of AI is, let alone a plan"
2451,@GaryMarcus,2022-10-01 12:25:40+00:00,https://twitter.com/GaryMarcus/status/1576186583866576897,@Scobleizer @fxk @Tesla @IrenaCronin based on what? where is this analysis?
2452,@GaryMarcus,2022-10-01 12:14:23+00:00,https://twitter.com/GaryMarcus/status/1576183744108826625,naive
2453,@GaryMarcus,2022-10-01 04:23:36+00:00,https://twitter.com/GaryMarcus/status/1576065270359023616,"üéµcan‚Äôt buy me AGl
no, no, no, no

I don't care too much for money 
Money can't buy me AGIüéµ"
2454,@GaryMarcus,2022-10-01 04:14:26+00:00,https://twitter.com/GaryMarcus/status/1576062960493268992,ooh what i would give to debate Elon Musk on scaling maximalism.
2455,@GaryMarcus,2022-10-01 03:56:38+00:00,https://twitter.com/GaryMarcus/status/1576058483589677057,". @elonmusk argues that since @tesla (supposedly) has the most data and most compute, it follows they will necessarily will contribute to artificial general intelligence.

i disagree w this logic: building biggest model isn‚Äôt inherently a contribution to the innovations we need"
2456,@GaryMarcus,2022-10-01 03:38:54+00:00,https://twitter.com/GaryMarcus/status/1576054021101539328,@rachelpurpel also on four hours notice? insane
2457,@GaryMarcus,2022-10-01 03:38:24+00:00,https://twitter.com/GaryMarcus/status/1576053895196856320,@simicvm @verge @animesh_garg @Ken_Goldberg
2458,@GaryMarcus,2022-10-01 03:36:49+00:00,https://twitter.com/GaryMarcus/status/1576053496235036674,brutal
2459,@GaryMarcus,2022-10-01 03:28:58+00:00,https://twitter.com/GaryMarcus/status/1576051519367000064,"@animesh_garg @frossi_t @verge certainly there was nothing compelling about navigation, and almost nothing at all about cognition."
2460,@GaryMarcus,2022-10-01 03:27:55+00:00,https://twitter.com/GaryMarcus/status/1576051255180660736,https://t.co/RMekj7qBb5
2461,@GaryMarcus,2022-10-01 03:21:45+00:00,https://twitter.com/GaryMarcus/status/1576049705108516864,trick question?
2462,@GaryMarcus,2022-10-01 03:19:48+00:00,https://twitter.com/GaryMarcus/status/1576049210952011777,@frossi_t @cwty exactly
2463,@GaryMarcus,2022-10-01 03:16:45+00:00,https://twitter.com/GaryMarcus/status/1576048443088203778,. @cwty is on üî•
2464,@GaryMarcus,2022-10-01 03:08:01+00:00,https://twitter.com/GaryMarcus/status/1576046246984568832,"best mesh networks alternatives to Eero? i just got notice that they are stopping security upgrades to some of my devices ‚Ä¶ in 4 hours.

are you ####ing kidding?"
2465,@GaryMarcus,2022-10-01 02:55:03+00:00,https://twitter.com/GaryMarcus/status/1576042984763580417,@mark_riedl @Ken_Goldberg @elonmusk had same thought
2466,@GaryMarcus,2022-10-01 02:52:48+00:00,https://twitter.com/GaryMarcus/status/1576042418587152384,@tpgoebel you can‚Äôt build a humanoid domestic robot that you can trust without making some progress towards AGI. it just won‚Äôt be safe.
2467,@GaryMarcus,2022-10-01 02:46:52+00:00,https://twitter.com/GaryMarcus/status/1576040923342856197,"your prior on how soon AGI will come, updated after tonight‚Äôs presentation"
2468,@GaryMarcus,2022-10-01 02:35:45+00:00,https://twitter.com/GaryMarcus/status/1576038125230788608,@filippie509 cool. i turned it off too soon.
2469,@GaryMarcus,2022-10-01 02:24:28+00:00,https://twitter.com/GaryMarcus/status/1576035288614588416,this aged pretty well
2470,@GaryMarcus,2022-10-01 02:15:50+00:00,https://twitter.com/GaryMarcus/status/1576033113704386560,https://t.co/bW8otC0RM5
2471,@GaryMarcus,2022-10-01 02:11:49+00:00,https://twitter.com/GaryMarcus/status/1576032102872936448,"shame on @verge for repeating this as truth without asking anyone else in the field of robotics for comment. 

https://t.co/qNHxsQx6UE"
2472,@GaryMarcus,2022-10-01 02:09:01+00:00,https://twitter.com/GaryMarcus/status/1576031398301143041,concur with @cwty; there was little that was new and essentially zero addressing the many aspects of autonomy and cognition that makes robotics in the real world hard.
2473,@GaryMarcus,2022-10-01 01:26:25+00:00,https://twitter.com/GaryMarcus/status/1576020677534314496,awkward
2474,@GaryMarcus,2022-09-30 23:12:23+00:00,https://twitter.com/GaryMarcus/status/1575986949156114433,"@slatestarcodex be careful, you could be wind up being the next Gary Marcus :)"
2475,@GaryMarcus,2022-09-30 22:52:37+00:00,https://twitter.com/GaryMarcus/status/1575981974434775040,@jonathanalter @davidfrum well-played :) I look forward to the bio.
2476,@GaryMarcus,2022-09-30 21:49:34+00:00,https://twitter.com/GaryMarcus/status/1575966106530942978,@NaveenGRao maybe. we can‚Äôt even get them to multiply four digit numbers reliably.
2477,@GaryMarcus,2022-09-30 21:46:55+00:00,https://twitter.com/GaryMarcus/status/1575965441012686848,"@SColesPorter so sorry, sarah"
2478,@GaryMarcus,2022-09-30 21:45:31+00:00,https://twitter.com/GaryMarcus/status/1575965086581415937,"@NaveenGRao i think you need to have proper database calls; neurosymbolic might be that bridge. without that bridge,  medical advice would be unreliable for sure."
2479,@GaryMarcus,2022-09-30 21:31:02+00:00,https://twitter.com/GaryMarcus/status/1575961444218441728,@shokunin_studio @teslascope @CadeMetz @Tesla also see my thoughts here
2480,@GaryMarcus,2022-09-30 21:29:09+00:00,https://twitter.com/GaryMarcus/status/1575960970119127040,"@shokunin_studio @teslascope @CadeMetz reality is that robotics is incredibly difficult and @tesla‚Äôs demonstrated expertise heretofore has focused mainly on 4-wheeled robots in specific types of environments, so some skepticism about Optimus is not unreasonable. + their best known technical person recently left."
2481,@GaryMarcus,2022-09-30 21:24:20+00:00,https://twitter.com/GaryMarcus/status/1575959754530516993,@animesh_garg @CadeMetz yep i am curious too. @karpathy gave a serious talk last year.
2482,@GaryMarcus,2022-09-30 21:23:08+00:00,https://twitter.com/GaryMarcus/status/1575959455736659968,@NaveenGRao traditional databases are often very reliable for queries; so far LLMs less so. (&amp; i would say that they are less organized). what do you think the killer use case might be?
2483,@GaryMarcus,2022-09-30 21:20:52+00:00,https://twitter.com/GaryMarcus/status/1575958885462323201,@shokunin_studio @CadeMetz that would be great! with driverless cars it took several *years* for reality to set in ü§£
2484,@GaryMarcus,2022-09-30 21:16:02+00:00,https://twitter.com/GaryMarcus/status/1575957667717451776,anyone in robotics planning to watch tonight? cc @CadeMetz
2485,@GaryMarcus,2022-09-30 21:14:47+00:00,https://twitter.com/GaryMarcus/status/1575957354637844482,@NaveenGRao agree we should care about net balance. what do you think greatest good from LLMs will be?
2486,@GaryMarcus,2022-09-30 21:01:57+00:00,https://twitter.com/GaryMarcus/status/1575954125279199232,@NaveenGRao do you doubt the consequences for misinformation that i see?
2487,@GaryMarcus,2022-09-30 20:17:48+00:00,https://twitter.com/GaryMarcus/status/1575943010894098432,"@davidfrum @jonathanalter A very selective choice of adjectives; you might also have said eg ‚Äúnoble‚Äù, ‚Äúinspiring‚Äù, ‚Äúindefatigable‚Äù, or ‚Äúgenerous‚Äù."
2488,@GaryMarcus,2022-09-30 20:06:18+00:00,https://twitter.com/GaryMarcus/status/1575940118652760065,"@dr_ilardi why would you do that? if you can choose the vehicle why not use a self-driving car? what does the humanoid robot add? 
whereas inserting a humanoid robot in an existing vehicle could be useful emergency situation."
2489,@GaryMarcus,2022-09-30 20:03:51+00:00,https://twitter.com/GaryMarcus/status/1575939500361977857,"This is, I daresay, both amazing and terrifying, a tool that few spam producers and disinformation-spewers will be able to resist. 

The 2024 election is gonna be wild, and not in a good way."
2490,@GaryMarcus,2022-09-30 19:25:31+00:00,https://twitter.com/GaryMarcus/status/1575929854436179968,"@dr_ilardi really? that high? on a robot driving an arbitrary car, like you getting who knows what at a rental car counter? 
more than happy to give you 50:1 on that."
2491,@GaryMarcus,2022-09-30 18:59:30+00:00,https://twitter.com/GaryMarcus/status/1575923308880879617,"Appreciate that, and wish that the dismissal of them hadn‚Äôt become a meme."
2492,@GaryMarcus,2022-09-30 18:49:38+00:00,https://twitter.com/GaryMarcus/status/1575920822967230464,@metaculus
2493,@GaryMarcus,2022-09-30 18:48:36+00:00,https://twitter.com/GaryMarcus/status/1575920564832960513,"@AFF100011 @neuroamyo @uwcnc the provenance is pretty well documented for anyone who cares to see; i‚Äôve made my point. 

the issue is about people in power showing respect for other people, sometime from different backgrounds, with differing ideas."
2494,@GaryMarcus,2022-09-30 18:46:28+00:00,https://twitter.com/GaryMarcus/status/1575920029182619648,@lauren07102 @hardmaru had same thought
2495,@GaryMarcus,2022-09-30 18:45:03+00:00,https://twitter.com/GaryMarcus/status/1575919671966322688,@AFF100011 @neuroamyo @uwcnc which word on that slide do you think i would have disagreed with?
2496,@GaryMarcus,2022-09-30 18:43:20+00:00,https://twitter.com/GaryMarcus/status/1575919238027411457,"@patrickmesana @filippie509 @__TweetinChar__ @ylecun Oh come on. I said pretty much exactly what he is saying now in 2018 and he said, literally, immediately, and publicly, that it was ‚Äúmostly wrong‚Äù.  

he‚Äôs been attacking me publicly and privately ever since.

if you doubt it, see receipts my substack."
2497,@GaryMarcus,2022-09-30 17:58:40+00:00,https://twitter.com/GaryMarcus/status/1575907998009917440,"@arkosiorek it‚Äôs not simply about credit. it‚Äôs about people in power shouting other people down from the stage and delaying progress. 

it makes it worse than they later take credit for the very things they were shouting down, and highlights how asinine the shouting was in the first place."
2498,@GaryMarcus,2022-09-30 17:56:21+00:00,https://twitter.com/GaryMarcus/status/1575907416063242240,If Elon can make this work (reliably) in 2029 I will take back everything I ever said about Tesla and publicly apologize.
2499,@GaryMarcus,2022-09-30 17:43:17+00:00,https://twitter.com/GaryMarcus/status/1575904125283635200,"Exactly, flitting one from one fad to the next instead of trying to integrate the lessons across them, doesn‚Äôt entirely seem like a recipe for success.

@ZoubinGhahrama gave a great keynote about that once upon a time at (what was then) NIPS‚Ä¶"
2500,@GaryMarcus,2022-09-30 16:10:10+00:00,https://twitter.com/GaryMarcus/status/1575880694706077697,"@__TweetinChar__ @filippie509 @ylecun yes i quote tweeted this, pointing out what would have happened had i said exactly same."
2501,@GaryMarcus,2022-09-30 15:26:00+00:00,https://twitter.com/GaryMarcus/status/1575869580249272320,@vyodaiken certainly there is a lot of room for better ideas‚Ä¶
2502,@GaryMarcus,2022-09-30 14:54:54+00:00,https://twitter.com/GaryMarcus/status/1575861750343221248,"@vyodaiken have you read any of the authors that i have recently pointed to? do you have any specific counterarguments to the results they have in specific cases in scene understanding, program synthesis, planning etc where they outperform pure deep learning?"
2503,@GaryMarcus,2022-09-30 14:14:54+00:00,https://twitter.com/GaryMarcus/status/1575851686652170240,"@vyodaiken who is proposing to bring back GOFAi? 

virtually of us who see value in symbolic techniques are lobbying for hybrid models."
2504,@GaryMarcus,2022-09-30 14:06:09+00:00,https://twitter.com/GaryMarcus/status/1575849482696404992,"Fact: The ML community has made loads  of progress, but not always distinguished itself in being receptive to people with less popular perspectives. 

Turing Award winner @yudapearl echoes some of the experiences I have had, below.  

Hinton himself felt that way for years."
2505,@GaryMarcus,2022-09-30 13:37:39+00:00,https://twitter.com/GaryMarcus/status/1575842313519058945,"interesting to see what happens with Tesla AI today. 

my guess for why the robot demo in particular might be awkward is here: https://t.co/OPOQMnu78S

@lorakolodny @Tweetermeyer @CadeMetz"
2506,@GaryMarcus,2022-09-30 13:31:13+00:00,https://twitter.com/GaryMarcus/status/1575840691733037058,"ethics AI may pose some tricky challenges, but here‚Äôs one principle I think we can probably all happily agree on üôÇ"
2507,@GaryMarcus,2022-09-30 05:25:26+00:00,https://twitter.com/GaryMarcus/status/1575718440916361216,edge cases in the air! h/t @sd_marlow
2508,@GaryMarcus,2022-09-30 02:31:43+00:00,https://twitter.com/GaryMarcus/status/1575674724155523073,@danbri @ylecun and i think eg @yudapearl‚Äôs experience is more or less same as my own
2509,@GaryMarcus,2022-09-30 02:28:21+00:00,https://twitter.com/GaryMarcus/status/1575673877237157895,@danbri @ylecun the more merrier IMHO
2510,@GaryMarcus,2022-09-29 18:26:29+00:00,https://twitter.com/GaryMarcus/status/1575552612816277504,"seriously: imagine the uproar if *I* were to say the hurtful things on the slide below.  

haters would be saying I ‚Äúdismissed ML‚Äù, or that I was ‚Äúmostly wrong‚Äù, failed to credit progress, &amp; point to poorly-defined terms (common sense!) without offering complete implementations."
2511,@GaryMarcus,2022-09-29 11:32:43+00:00,https://twitter.com/GaryMarcus/status/1575448484077248516,@wellingmax @maxwelling i specified above what i believe that the debate was actually about: whether or not it was healthy for the ML to engage in work outside its mainstream that challenges core assumptions that have not been proven.
2512,@GaryMarcus,2022-09-29 11:30:55+00:00,https://twitter.com/GaryMarcus/status/1575448030865952774,"@wellingmax @maxwelling yes, max,. i am sure the talk was terrific (I trust your judgement and like your own work in the area) but your characterization of the debate missed the point of the debate."
2513,@GaryMarcus,2022-09-29 02:54:34+00:00,https://twitter.com/GaryMarcus/status/1575318085338558464,"@douglas_eck @JFPuget @ylecun could be worse, I suppose, than to be compared to Socrates https://t.co/ez8jsU1mPV, who pointed out that ‚Äúthe cost to society of silencing individuals who were irritating could be very high‚Äù"
2514,@GaryMarcus,2022-09-29 01:57:06+00:00,https://twitter.com/GaryMarcus/status/1575303624905101312,"5 reasons @tesla's Optimus Announcement may turn out to be a dud. 
https://t.co/vAgI3w8coB"
2515,@GaryMarcus,2022-09-28 22:44:34+00:00,https://twitter.com/GaryMarcus/status/1575255170161995776,"@JFPuget @ylecun this is BS. i shared links to a wealth of other researchers and couldn‚Äôt get you or yann or *any* of the Ml community to engage with any of them, even where results were decisively stronger than DL for certain problems.

that‚Äôs what the whole debate was about."
2516,@GaryMarcus,2022-09-28 22:02:35+00:00,https://twitter.com/GaryMarcus/status/1575244605528084482,"@JFPuget @_NicT_ @ylecun @JanelleCShane not going to get in a fight with Domingos who has undoubtedly done lots of important work, but i have peer review articles in Science, Nature, and leading journals in half a dozen different fields, myself, as well 6 books and monographs etc spanning psychology, AI, biology etc."
2517,@GaryMarcus,2022-09-28 21:45:28+00:00,https://twitter.com/GaryMarcus/status/1575240300821610496,@wellingmax @ylecun https://t.co/fBUELlKymJ
2518,@GaryMarcus,2022-09-28 21:44:53+00:00,https://twitter.com/GaryMarcus/status/1575240150728441856,@MelMitchell1 @AndrewLampinen @math_dandy would *anyone* disagree with that?
2519,@GaryMarcus,2022-09-28 21:40:04+00:00,https://twitter.com/GaryMarcus/status/1575238939182772226,@omaruddin @maxwelling oops @wellingmax
2520,@GaryMarcus,2022-09-28 21:22:00+00:00,https://twitter.com/GaryMarcus/status/1575234393870061568,"Even the very bright @maxwelling has missed the point. 

The real debate is about whether the AI community should engage in the fast growing neurosymbolic literature (to which I gave numerous pointers). 

Or should we turn our back, because those in power don‚Äôt wish to engage?"
2521,@GaryMarcus,2022-09-28 21:18:54+00:00,https://twitter.com/GaryMarcus/status/1575233612978749442,"@AndrewLampinen @MelMitchell1 @math_dandy yes that would be a disappointment, and that noisy, nuanced and complex world is why I gravitate to something like neurosymbolic rather than pure GOFAI (or for that matter pure deep learning which is not great around context or nuance)."
2522,@GaryMarcus,2022-09-28 20:18:55+00:00,https://twitter.com/GaryMarcus/status/1575218516290310149,"if you want to use a commercial service for AI, where do you head first?"
2523,@GaryMarcus,2022-09-28 20:02:12+00:00,https://twitter.com/GaryMarcus/status/1575214309571170304,"@DanRodricks as a former guest one one of your shows, i can‚Äôt be there in person but would love to see a recorded performance!"
2524,@GaryMarcus,2022-09-28 20:00:16+00:00,https://twitter.com/GaryMarcus/status/1575213826479624193,@pwlot @OpenAI they also put out whisper. i live in hope that they will return to their name.
2525,@GaryMarcus,2022-09-28 19:36:08+00:00,https://twitter.com/GaryMarcus/status/1575207749964922880,@openAI is getting more open again; i like that.
2526,@GaryMarcus,2022-09-28 16:23:32+00:00,https://twitter.com/GaryMarcus/status/1575159281091235840,@Tom14985282 @slatestarcodex see my bet with elon musk at https://t.co/8ir1xKenr6 and tell me how you would change it
2527,@GaryMarcus,2022-09-28 04:22:13+00:00,https://twitter.com/GaryMarcus/status/1574977756513075200,"@davidchalmers42 and in a related vein:

https://t.co/JTgYtV8JTk"
2528,@GaryMarcus,2022-09-28 03:58:40+00:00,https://twitter.com/GaryMarcus/status/1574971832092229632,"@raphaelmilliere @davidchalmers42 @TonyZador @ylecun @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez I am with Tom McCoy who has collaborated w Smolensky on what I think is the best effort thus far to incorporate compositionality in a neural network, yesterday:"
2529,@GaryMarcus,2022-09-28 03:48:39+00:00,https://twitter.com/GaryMarcus/status/1574969307775520769,"@davidchalmers42 @TonyZador @ylecun @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez getting vectors that don‚Äôt map to symbols to be compositional been a failure, after 35 years, per workshop that @raphaelmilliere &amp; I just held.

there‚Äôs some stuff that‚Äôs vaguely compositional like but nobody has (yet?) really made it work. 

https://t.co/mQdOoGiYfI"
2530,@GaryMarcus,2022-09-28 03:44:38+00:00,https://twitter.com/GaryMarcus/status/1574968297501921280,"@TonyZador @davidchalmers42 @ylecun @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez no, and in fact that was the entire point of chapters 2 and 3 of the algebraic mind. you can either read them soon on Kindle or wait for me to resummarize in a few days."
2531,@GaryMarcus,2022-09-28 03:42:11+00:00,https://twitter.com/GaryMarcus/status/1574967680423305216,". @slatestarcodex with interesting thoughts on why it sucks to be me

full article at https://t.co/9w1jMgaCk7 https://t.co/4Lqy0OiFto"
2532,@GaryMarcus,2022-09-28 03:26:50+00:00,https://twitter.com/GaryMarcus/status/1574963819344187392,"@TonyZador @davidchalmers42 @ylecun @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez btw, @ylecun charged falsely that i keep changing my definitions. I stand by what i said in 2001: symbols are just things that stand for things, found in neural nets &amp; classical AI, 

real distinction is that only classical AI but not typical nets have operations over variables"
2533,@GaryMarcus,2022-09-28 03:24:26+00:00,https://twitter.com/GaryMarcus/status/1574963215863513089,"@TonyZador @davidchalmers42 @ylecun @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez in that sense the heart and liver emerge, but they don‚Äôt depend all that much on training etc. i

if a duckling has a program that imprints in search of its mother, you could say that the value it imprints on emerges, but literature suggests the machinery for doing so is innate"
2534,@GaryMarcus,2022-09-28 03:21:39+00:00,https://twitter.com/GaryMarcus/status/1574962512587821057,"@davidchalmers42 @TonyZador @ylecun @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez i think the Venn diagram on that is the empty set, but I would be interested if someone can show otherwise."
2535,@GaryMarcus,2022-09-28 02:56:35+00:00,https://twitter.com/GaryMarcus/status/1574956205650612224,"absent a worked example, even on paper, i have to agree with @tdietterich and @yudapearl."
2536,@GaryMarcus,2022-09-28 02:53:24+00:00,https://twitter.com/GaryMarcus/status/1574955406920908801,"@davidchalmers42 @TonyZador @ylecun @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez i don‚Äôt know what an emergent symbol would be. no answer from you or yann, and i could never figure out what smolensky meant either, by his term sub symbol. 

what i am really hoping is that yann will actually engage with the substance of the neurosymbolic literature."
2537,@GaryMarcus,2022-09-28 02:23:15+00:00,https://twitter.com/GaryMarcus/status/1574947817688559616,ü§£ü§£ @RemindMe_OfThis
2538,@GaryMarcus,2022-09-28 00:45:25+00:00,https://twitter.com/GaryMarcus/status/1574923197706797056,"@davidchalmers42 @TonyZador @ylecun @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez e-symbols seem like an aspiration rather than a thing, as far as i can tell. 

do we have any in working systems? what are the criteria? what can they do for you?"
2539,@GaryMarcus,2022-09-27 22:40:26+00:00,https://twitter.com/GaryMarcus/status/1574891742444548097,What was at stake at that debate with @ylecun? It‚Äôs not about definitions. It‚Äôs about the best way forward.
2540,@GaryMarcus,2022-09-27 21:31:59+00:00,https://twitter.com/GaryMarcus/status/1574874517784367109,"@MelMitchell1 what is at issue is how intensely we should study neurosymbolic AI as opposed eg to scaling LLMs. that‚Äôs a huge research choice, with (i suspect) huge consequence"
2541,@GaryMarcus,2022-09-27 21:28:16+00:00,https://twitter.com/GaryMarcus/status/1574873581158543360,@JonHaidt
2542,@GaryMarcus,2022-09-27 21:27:32+00:00,https://twitter.com/GaryMarcus/status/1574873398479814656,@STWorg fantastic work. please dm or follow back
2543,@GaryMarcus,2022-09-27 21:26:54+00:00,https://twitter.com/GaryMarcus/status/1574873238890778624,"terrific thread on the psychology of polarization, one of the most serious challenges of our times."
2544,@GaryMarcus,2022-09-27 21:01:45+00:00,https://twitter.com/GaryMarcus/status/1574866908863934465,@vo_d_p @eliasbareinboim @ylecun @yudapearl @TiernanRayTech another thing yann and i agree on
2545,@GaryMarcus,2022-09-27 20:44:52+00:00,https://twitter.com/GaryMarcus/status/1574862659111260160,@SchwabeHenning that‚Äôs the funny thing - @ylecun and I agree on one of the most important points!
2546,@GaryMarcus,2022-09-27 20:43:38+00:00,https://twitter.com/GaryMarcus/status/1574862350725029888,"fascinating data-driven ‚ôüÔ∏èthread, suggesting either Niemann is the greatest ever or he is cheating."
2547,@GaryMarcus,2022-09-27 20:37:50+00:00,https://twitter.com/GaryMarcus/status/1574860889765060608,@_jasonwei not wrong
2548,@GaryMarcus,2022-09-27 19:01:36+00:00,https://twitter.com/GaryMarcus/status/1574836671933448194,had the same impression
2549,@GaryMarcus,2022-09-27 18:58:27+00:00,https://twitter.com/GaryMarcus/status/1574835882057928704,Optimus demo reportedly coming Friday! 1 in 6 voters think it will be amazing! see results below for what other folks are anticipating:
2550,@GaryMarcus,2022-09-27 18:42:08+00:00,https://twitter.com/GaryMarcus/status/1574831772248207360,one of the many ways in which symbol-free methods have not yet reached dog-level cognition:
2551,@GaryMarcus,2022-09-27 18:41:26+00:00,https://twitter.com/GaryMarcus/status/1574831596985024512,@pwlot @davidchalmers42 @TonyZador @ylecun @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez really hard to do that without symbols.
2552,@GaryMarcus,2022-09-27 18:40:24+00:00,https://twitter.com/GaryMarcus/status/1574831336858488832,"@rballeba @ylecun @Zergylord @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz I gave him a long list of readings and he wouldn‚Äôt engage in any. how are we going to collaborate if he won‚Äôt? 

i read his stuff, and engaged with. 

but it would have to be a two-way street."
2553,@GaryMarcus,2022-09-27 18:01:32+00:00,https://twitter.com/GaryMarcus/status/1574821555783487488,"@IntuitMachine @ylecun @rao2z @guyvdb @MITCoCoSci @swarat @AvilaGarcez @luislamb @AI4Code @frossi_t @AnimaAnandkumar well i did point them out, in 2012 and 2018, and i got relentlessly attacked, then."
2554,@GaryMarcus,2022-09-27 18:00:39+00:00,https://twitter.com/GaryMarcus/status/1574821333128847360,"@IntuitMachine @ylecun @rao2z @guyvdb @MITCoCoSci @swarat @AvilaGarcez @luislamb @AI4Code @frossi_t @AnimaAnandkumar i am interested in his class of incomplete solutions (&amp; read his work and others); he refuses even to engage in the neurosymbolic literature (not just mine, but in general). 

all are incomplete; not all of us dismiss each other‚Äôs work.

that‚Äôs the difference."
2555,@GaryMarcus,2022-09-27 17:57:53+00:00,https://twitter.com/GaryMarcus/status/1574820639340654592,"@Zergylord @ylecun @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz without a fundamental change/enhancement to architecture, LLMs alone plus more and more data will never come close to the flawed pentium chip on floating point arithmetic 

want to put money on that?"
2556,@GaryMarcus,2022-09-27 17:54:02+00:00,https://twitter.com/GaryMarcus/status/1574819667621085184,@luislamb @AvilaGarcez @ylecun without a marriage between the two we are lost
2557,@GaryMarcus,2022-09-27 17:53:05+00:00,https://twitter.com/GaryMarcus/status/1574819431024558080,@Zergylord @ylecun @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz take minerva: it works on some multiplication problems but not others depending on exact corpus stats.
2558,@GaryMarcus,2022-09-27 17:52:25+00:00,https://twitter.com/GaryMarcus/status/1574819263021715457,"@Zergylord @ylecun @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz for 25 years I have been emphasizing not the fact that neural nets are incomplete (true) but that they *systematically struggle at extra-distribution abstraction*

most researchers except @anirudhg9119 &amp; Yoshua Bengio ignore that key issue, and hence miss the forest for the trees"
2559,@GaryMarcus,2022-09-27 17:48:09+00:00,https://twitter.com/GaryMarcus/status/1574818188663353344,A form of argument I don‚Äôt like is to strip an argument of all its nuance. @zergylord does that here and I explain below in a reply to him what I think the actual argument is.
2560,@GaryMarcus,2022-09-27 17:46:39+00:00,https://twitter.com/GaryMarcus/status/1574817811821891584,"@Zergylord @ylecun @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz that‚Äôs not really the argument. the argument is that there is broadly cluster of things where deep learning has succeeded (pattern recognition of various sorts) and a large cluster where results seem to be trip over idiosyncratic corpus statistics (reasoning, planning, language)"
2561,@GaryMarcus,2022-09-27 17:44:40+00:00,https://twitter.com/GaryMarcus/status/1574817313047875585,@S_Jose_Hanson (a large part of todays twitter discussion is about that architecture; see especially the threads with me Yann and Judea)
2562,@GaryMarcus,2022-09-27 15:58:51+00:00,https://twitter.com/GaryMarcus/status/1574790680601587713,"@Zergylord @ylecun @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz said with a little irony, but eg domestic robots or scientific discovery are way harder"
2563,@GaryMarcus,2022-09-27 15:58:04+00:00,https://twitter.com/GaryMarcus/status/1574790485369303040,"@Zergylord that‚Äôs not quite it. these things are all interesting but i think that @ylecun‚Äôs plan depends on not having to do any handcrafting physical &amp; psychological world, and i think (cc @yudapearl) that won‚Äôt ultimately support the counterfactual reasoning that needs to be done."
2564,@GaryMarcus,2022-09-27 15:54:19+00:00,https://twitter.com/GaryMarcus/status/1574789541353099264,"@AI4Code @swarat @MITCoCoSci @animesh_garg @AnimaAnandkumar @AvilaGarcez @luislamb @frossi_t @ylecun has @ylecun ever cited that work to your knowledge, either eg to challenge it or extend it?"
2565,@GaryMarcus,2022-09-27 15:53:35+00:00,https://twitter.com/GaryMarcus/status/1574789355230859269,"@ylecun @Zergylord @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz and nobody can get it to work in a real world problem as simple as driving on-road in open-ended environments.

it‚Äôs part of the solution, not the whole ballgame"
2566,@GaryMarcus,2022-09-27 15:52:56+00:00,https://twitter.com/GaryMarcus/status/1574789191707533312,"@ylecun @trading_noise this is all misleading &amp;/or false.
üëâi always call for hybrid models that INCLUDE deep learning 
üëâYou actually agree that no current deep learning technique is adequate &amp; that we need new ideas (deep learning or otherwise)
üëâMy definitions for symbols have not changed since 2001"
2567,@GaryMarcus,2022-09-27 15:48:11+00:00,https://twitter.com/GaryMarcus/status/1574787999174643712,"@Zergylord i didn‚Äôt say that. i was evaluating a specific claim of LeCun‚Äôs. They are both super interesting, and I have said publicly that I think AlphaFold2 is probably AI‚Äôs greatest contribution to society so far."
2568,@GaryMarcus,2022-09-27 15:45:51+00:00,https://twitter.com/GaryMarcus/status/1574787409182863363,"@ylecun @trading_noise which part of the neurosymbolic literature have you engaged in? when? was it with any of the papers of @AvilaGarcez @luislamb @swarat @MITCoCoSci @frossi_t @neurobongo @AI4Code @AnimaAnandkumar @animesh_garg etc? 

where did you engage with it? 

we would all be interested."
2569,@GaryMarcus,2022-09-27 15:42:37+00:00,https://twitter.com/GaryMarcus/status/1574786596930723840,"Respectfully, please read my work. I always say deep learning has a role; I never dismiss it. (I have corrected you on this many times.)

My definitions of symbols, which you have never engaged in, have been constant since the second chapter of The Algebraic Mind in 2001."
2570,@GaryMarcus,2022-09-27 15:37:53+00:00,https://twitter.com/GaryMarcus/status/1574785404422979584,"@dataghees @ylecun start with @AvilaGarcez and @lamb‚Äôs 3rd wave arxiv, and refs in my next decade in AI, and read lots of stuff by folks above. 

see my Algebraic Mind for motivations."
2571,@GaryMarcus,2022-09-27 15:36:35+00:00,https://twitter.com/GaryMarcus/status/1574785079683186689,"@ylecun @trading_noise you essentially never cite it. you have said that hybrid models (or discussions there) are incoherent. 

when I write about it, you say I am ‚Äúmostly wrong‚Äù, and never engage in the specifics either of my argument or that literature.

that‚Äôs what dismissal looks like"
2572,@GaryMarcus,2022-09-27 15:33:27+00:00,https://twitter.com/GaryMarcus/status/1574784291112128514,"@Zergylord @ylecun @rao2z @MITCoCoSci @guyvdb nobody said they weren‚Äôt. i did say that @rao2z showed convincingly that LLMs, in some sense of the state of the art, don‚Äôt get planning for free. 

(Yann agreed with that.)"
2573,@GaryMarcus,2022-09-27 15:31:54+00:00,https://twitter.com/GaryMarcus/status/1574783900697899008,"@ylecun @Zergylord @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz That‚Äôs pure speculation. It‚Äôs not like you have a remotely working system that can eg do the kind of reasoning with containers with incomplete information that Ernie Davis and I describe in Artificial Intelligence Journal without symbols.

https://t.co/s8ru4FTcYH"
2574,@GaryMarcus,2022-09-27 15:24:37+00:00,https://twitter.com/GaryMarcus/status/1574782067325673472,"@Zergylord @ylecun @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz @yudapearl if you could literally get a single unadorned algorithms to do both games and proteins without a bunch of custom representations for proteins, that would be interesting. 

but MuZero out of the box doesn‚Äôt match AFT2. AF2 has a lot of custom, empirically designed representations"
2575,@GaryMarcus,2022-09-27 15:21:54+00:00,https://twitter.com/GaryMarcus/status/1574781383515705344,"@ylecun @Zergylord @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz also yann that‚Äôs second time in five minutes or so that you have emphasized ‚Äúdeclaring victory‚Äù; maybe better if we focus on what is required, architecturally, and on what traditions might have something to contribute"
2576,@GaryMarcus,2022-09-27 15:21:04+00:00,https://twitter.com/GaryMarcus/status/1574781175457280007,"@ylecun @Zergylord @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz what @yudapearl &amp; I are (in different ways) both saying is that you aren‚Äôt going to get this done without innate scaffolding for cognitive models &amp; that you are underemphasizing that critical part, when it is in fact crucial &amp; so far hand-coded differently eg for games v proteins"
2577,@GaryMarcus,2022-09-27 15:17:02+00:00,https://twitter.com/GaryMarcus/status/1574780158959296514,"@trading_noise @ylecun then Yann reads the neurosymbolic literature, instead of dismissing it, finds ideas and ways of improving things, and we all live happily ever after.

it‚Äôs win-win."
2578,@GaryMarcus,2022-09-27 15:15:30+00:00,https://twitter.com/GaryMarcus/status/1574779774488424453,"There are *tons* of concrete proposals, implementations and empirical results in neurosymbolic AI (eg @swarat @AI4Code @MITCoCoSci @animesh_garg @AnimaAnandkumar @AvilaGarcez @luislamb @frossi_t), @ylecun; you just haven‚Äôt engaged with them. 

It is by no means just definitional."
2579,@GaryMarcus,2022-09-27 15:08:13+00:00,https://twitter.com/GaryMarcus/status/1574777939392368640,"@ylecun @AVMiceliBarone @yudapearl @TiernanRayTech which is not to say that i am totally opposed to what you are pushing for; i think the dynamic configuration part is great. i just think you will wind up needing explicit models, explicit symbols, explicit knowledge, and symbolic reasoning into the mix to get it work open-ended"
2580,@GaryMarcus,2022-09-27 15:06:36+00:00,https://twitter.com/GaryMarcus/status/1574777533350182913,"@ylecun @AVMiceliBarone @yudapearl @TiernanRayTech that‚Äôs what people had hoped to do for driving; hasn‚Äôt really worked out as far as I know. 

and if it doesn‚Äôt even work for driving, it‚Äôs seems a lot to ask to ask for it to work for an agent‚Äôs full understanding of the open-ended world."
2581,@GaryMarcus,2022-09-27 14:46:04+00:00,https://twitter.com/GaryMarcus/status/1574772363774005249,@ylecun @Zergylord @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz of course it learns lots of stuff and that‚Äôs great; but the scaffolding is innate and symbolic
2582,@GaryMarcus,2022-09-27 14:45:20+00:00,https://twitter.com/GaryMarcus/status/1574772182622011393,@ylecun @Zergylord @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz i was asking directly above for the evidence that you could do the required planning without innateness and symbols and you gave me an example that has ‚Ä¶ innateness and symbols.
2583,@GaryMarcus,2022-09-27 14:43:28+00:00,https://twitter.com/GaryMarcus/status/1574771713296171013,@ylecun @yudapearl @TiernanRayTech what‚Äôs the furthest anyone has gotten straight from video? are there any commercial systems that do that? i have seen little that is trustworthy for anything  more than lane-following
2584,@GaryMarcus,2022-09-27 14:38:39+00:00,https://twitter.com/GaryMarcus/status/1574770499271667712,getting 10 yes votes a minute here. if only someone knew a way to bring @ylecun on board.
2585,@GaryMarcus,2022-09-27 14:36:32+00:00,https://twitter.com/GaryMarcus/status/1574769966481838080,@WiringTheBrain @TonyZador @davidchalmers42 @raphaelmilliere @ak_panda @ylecun @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez not sure what mentation is? or how that is different form figuring out what is next
2586,@GaryMarcus,2022-09-27 14:36:02+00:00,https://twitter.com/GaryMarcus/status/1574769839528620032,@WiringTheBrain @TonyZador @davidchalmers42 @raphaelmilliere @ak_panda @ylecun @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez or not. bees manipulate symbols in calculate the solar azimuth function but not sure how much scaffolding they have
2587,@GaryMarcus,2022-09-27 14:34:33+00:00,https://twitter.com/GaryMarcus/status/1574769465665146881,"@ylecun @yudapearl @TiernanRayTech Driving is actually a great example. 1. nobody AFAIK has a decent driving system that does the prediction and action steps purely with deep learning and without explicit models and 2. you wind up needing explicit, discrete symbolic variables even in your s, a, and z above."
2588,@GaryMarcus,2022-09-27 14:32:33+00:00,https://twitter.com/GaryMarcus/status/1574768964630360064,"@Grady_Booch @ylecun @bleepbeepbzzz @TonyZador @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez @KyleCranmer that‚Äôs the whole question: can you do #2 without #1? 

though as noted above the distinction is many ways problematic,"
2589,@GaryMarcus,2022-09-27 14:29:42+00:00,https://twitter.com/GaryMarcus/status/1574768245231747072,"@ylecun @yudapearl @TiernanRayTech a. vectors can be symbols so this reply is not well-constructed
b. everything rests on inventing a way to get world models to predict effectively in complex physical &amp; psychological scenarios without symbols; there is no evidence so far that this can be done in openended problems"
2590,@GaryMarcus,2022-09-27 14:26:37+00:00,https://twitter.com/GaryMarcus/status/1574767470434750464,@TonyZador @davidchalmers42 @raphaelmilliere @ak_panda @ylecun @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez it is a representation. a symbol is a state etc that stands for something
2591,@GaryMarcus,2022-09-27 14:25:27+00:00,https://twitter.com/GaryMarcus/status/1574767179438116864,"@IntuitMachine @KyleCranmer @ylecun @yudapearl @TiernanRayTech @ch402 it can‚Äôt represent externally reality, so it spreads disinformation, can‚Äôt be constrained not to be toxic, etc."
2592,@GaryMarcus,2022-09-27 14:24:31+00:00,https://twitter.com/GaryMarcus/status/1574766942761918464,"should Yann LeCun and I have a second public, moderated debate (first was in 2017, moderated by @davidchalmers42). 

I get asked this every day. (I am in, if @ylecun is)"
2593,@GaryMarcus,2022-09-27 14:20:28+00:00,https://twitter.com/GaryMarcus/status/1574765922602348544,"@ylecun @Zergylord @rao2z @MITCoCoSci @guyvdb @HenaffMikael @alfcnz MuZero, to take an example, has an innately structured model (w learned parameters), an innate symbolic MCTS tree as backbone, &amp; a a set of explicitly-represented model states to search through &amp; then uses DRL to evaluate each. whole workflow is innately constrained: https://t.co/k3UPY6q83I"
2594,@GaryMarcus,2022-09-27 14:10:12+00:00,https://twitter.com/GaryMarcus/status/1574763337707302912,"@davidchalmers42 @TonyZador @ylecun @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez are you saying all symbols *must* be compositional? that seems too strong.

maybe all symbols could be used inside a compositional machine, but i would argue that the the winner take all output nodes of a multilayer network are symbols, but not inherently compositional."
2595,@GaryMarcus,2022-09-27 14:06:39+00:00,https://twitter.com/GaryMarcus/status/1574762446061187072,"@ylecun @rao2z @MITCoCoSci @guyvdb i looked at them, and will look again, but didn‚Äôt really understand concretely how they might get to counterfactuals.

on my story, too, world models need to be learned; main difference is that i want them to be explicit and query-able (in the way that a database is)"
2596,@GaryMarcus,2022-09-27 14:03:54+00:00,https://twitter.com/GaryMarcus/status/1574761753854242816,"@IntuitMachine @KyleCranmer @ylecun @yudapearl @TiernanRayTech despite the valiant efforts of @ch402, I still don‚Äôt have certainty about how Transformers work.

but i will say this
üëâthey may do some symbol-manipulation internally
üëâ but they lack a (critical) means for assimilating &amp; operating according to externally defined symbolic rules"
2597,@GaryMarcus,2022-09-27 14:01:20+00:00,https://twitter.com/GaryMarcus/status/1574761107365199873,"@JorgeLarangeir1 @yudapearl @jacyanthis @ylecun @TiernanRayTech yes i have argued for a Kantian nativism a bunch of times eg https://t.co/Pt7HZc3RJd, partly for this reason"
2598,@GaryMarcus,2022-09-27 14:00:36+00:00,https://twitter.com/GaryMarcus/status/1574760925072363520,@TonyZador @davidchalmers42 @raphaelmilliere @ak_panda @ylecun @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez i think your dog has a symbol for you that they can token in many different ways and lead to a common family of thoughts
2599,@GaryMarcus,2022-09-27 13:59:36+00:00,https://twitter.com/GaryMarcus/status/1574760672571068419,"@TonyZador @ylecun @davidchalmers42 @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez indeed! after 40 years, it remains unclear what a nonsymbolic representation would be. 

this is why I structured the whole argument differently in The Algebraic Mind:
üëâsymbols *are* representations
üëâneural nets use symbols
üëâbut most don‚Äôt generalize operations over variables"
2600,@GaryMarcus,2022-09-27 13:53:32+00:00,https://twitter.com/GaryMarcus/status/1574759143650783234,"Welcome to #neurosymbolic, @ylecun!

I respect you in not wanting to use neurosymbolic techniques all the time‚Äîand salute you in acknowledging that such techniques might still be important.

Time to increase funding to such techniques. so we can figure out how to best use them."
2601,@GaryMarcus,2022-09-27 13:47:09+00:00,https://twitter.com/GaryMarcus/status/1574757539803459585,"@KyleCranmer @IntuitMachine @ylecun @yudapearl @TiernanRayTech sure he does not want to do everything there, but if he does *any* of it, he has left the non-neurosymbolic space and joined the neurosymbolic world. 

like it or not."
2602,@GaryMarcus,2022-09-27 13:43:33+00:00,https://twitter.com/GaryMarcus/status/1574756634672656400,"@ylecun @TonyZador @davidchalmers42 @raphaelmilliere @ak_panda @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez but of course math, logic, computer programs are symbols but not human language. language is just one symbol system among many.

all nonhumans animals do indeed plan and reason (to they extent that they do at all) without language, but some may use explicit symbols."
2603,@GaryMarcus,2022-09-27 13:41:14+00:00,https://twitter.com/GaryMarcus/status/1574756050053771266,@TonyZador @davidchalmers42 @raphaelmilliere @ak_panda @ylecun @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez Randy Gallistel wrote two whole books about symbolic planning in animals. I would say that for many animals the answer is plausibly yes.
2604,@GaryMarcus,2022-09-27 13:40:27+00:00,https://twitter.com/GaryMarcus/status/1574755854217531393,@ylecun @yudapearl @TiernanRayTech how exactly are you going to get to ring 3? i understand the flow diagram of your model but ultimately don‚Äôt see how you get to Pearl‚Äôs Rung 3 without recourse to any symbolic reasoning.
2605,@GaryMarcus,2022-09-27 13:38:37+00:00,https://twitter.com/GaryMarcus/status/1574755391564820484,"@KyleCranmer @ylecun @bleepbeepbzzz @TonyZador @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez agreed, but once you open the door to *any* quantizing, you have firmly entered the world of neurosymbolic AI."
2606,@GaryMarcus,2022-09-27 13:19:09+00:00,https://twitter.com/GaryMarcus/status/1574750494383546371,"@IntuitMachine @ylecun @yudapearl @TiernanRayTech softmax (etc)!has been an option on any kind of neural network for decades; people call this eg symbol extraction. the real questions are (a) whether you can extract the symbols you need and (b) what do with them. this is squarely neurosymbolic, eg https://t.co/dr5OmLOiHm"
2607,@GaryMarcus,2022-09-27 13:05:21+00:00,https://twitter.com/GaryMarcus/status/1574747018677059585,"@davidchalmers42 @raphaelmilliere @ak_panda @TonyZador @ylecun @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez i would agree‚Äîand hence am surprised that you as philosopher have not called LeCun on what commitments he is making on precisely these points. 

you claim he is pro symbol but he favors ‚Äúemergent symbols‚Äù w no defined compositionality or semantics."
2608,@GaryMarcus,2022-09-27 12:59:07+00:00,https://twitter.com/GaryMarcus/status/1574745451559268352,"@TonyZador @davidchalmers42 @raphaelmilliere @ak_panda @ylecun @bleepbeepbzzz @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez you have left out language, reasoning, and planning."
2609,@GaryMarcus,2022-09-27 12:58:02+00:00,https://twitter.com/GaryMarcus/status/1574745180045201410,@IntuitMachine @ylecun @yudapearl @TiernanRayTech over here LeCun calls for a ‚Äú‚Äùcluster quantizing‚Äù reification process that looks pretty much like the standard approach in neurosymbolic AI:
2610,@GaryMarcus,2022-09-27 12:49:42+00:00,https://twitter.com/GaryMarcus/status/1574743081215467527,"@ylecun @bleepbeepbzzz @TonyZador @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez if you do the quantization‚Äîand any subsequent processing over the quantized symbols‚Äîdon‚Äôt you by definition at that point have discrete symbols?

and how is what you described different from something commonly done in the neurosymbolic literature?"
2611,@GaryMarcus,2022-09-27 03:18:05+00:00,https://twitter.com/GaryMarcus/status/1574599229875826689,@raphaelmilliere @ak_panda @TonyZador @ylecun @bleepbeepbzzz @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez @paul_smolensky @RTomMcCoy and its not clear how mechanistically to actually integrate them with the kinds of mechanisms he has favored.
2612,@GaryMarcus,2022-09-27 03:17:25+00:00,https://twitter.com/GaryMarcus/status/1574599059201196032,"@ylecun @yudapearl @TiernanRayTech yann, following suit, may I respectfully request that,you read my 2018 Deep Learning: A Critical Appraisal, which you described as ‚Äúmostly wrong‚Äù, and pinpoint which aspects of it you actually find to be wrong? 

i‚Äôd be happy to trade notes on your recent paper"
2613,@GaryMarcus,2022-09-27 03:15:26+00:00,https://twitter.com/GaryMarcus/status/1574598561467338754,"@raphaelmilliere @ak_panda @TonyZador @ylecun @bleepbeepbzzz @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez @paul_smolensky @RTomMcCoy not really how i read the paper, tbh"
2614,@GaryMarcus,2022-09-27 03:14:53+00:00,https://twitter.com/GaryMarcus/status/1574598425097936898,@raphaelmilliere @ak_panda @TonyZador @ylecun @bleepbeepbzzz @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez @paul_smolensky @santoroAI @AndrewLampinen Yann should speak for himself and define his terms.
2615,@GaryMarcus,2022-09-27 03:13:33+00:00,https://twitter.com/GaryMarcus/status/1574598088538599424,"@raphaelmilliere @ak_panda @TonyZador @ylecun @bleepbeepbzzz @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez @paul_smolensky @RTomMcCoy NECST is just a very different beast; i asked Paul at our conference, is this a drop-in replacement for existing tech; answer was no/not yet. 

and again, i am really trying to understand Yann‚Äôs position. and eg is there a way he could build he wants with tensors? not clear to me"
2616,@GaryMarcus,2022-09-27 03:11:33+00:00,https://twitter.com/GaryMarcus/status/1574597584379060229,@raphaelmilliere @ak_panda @TonyZador @ylecun @bleepbeepbzzz @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez @paul_smolensky @RTomMcCoy 1G = not good enough; but yes that‚Äôs the paper i am referring to.
2617,@GaryMarcus,2022-09-27 03:10:34+00:00,https://twitter.com/GaryMarcus/status/1574597337535893504,"@BeebsMemes @warren_craddock @crazyuddie @zomgapocalypse @ylecun @jamesdouma we aren‚Äôt anywhere near the versatility of humans yet. 90 is a pipe dream at least for next 10-20 years, with or without lidar."
2618,@GaryMarcus,2022-09-27 03:02:12+00:00,https://twitter.com/GaryMarcus/status/1574595231936552960,"@raphaelmilliere @ak_panda @TonyZador @ylecun @bleepbeepbzzz @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez @paul_smolensky @santoroAI @AndrewLampinen i am aware of that paper but trying to understand what Yann actually means here, since I am hearing from some people that Yann supported symbols all along and from others that he never has and it all seems to boil down to unstated definitions."
2619,@GaryMarcus,2022-09-27 03:00:40+00:00,https://twitter.com/GaryMarcus/status/1574594844680671232,@raphaelmilliere @ak_panda @TonyZador @ylecun @bleepbeepbzzz @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez @paul_smolensky is that Yann is suggesting? @paul_smolensky has argued that current deep learning efforts at compositionality don‚Äôt cut it.
2620,@GaryMarcus,2022-09-27 02:32:16+00:00,https://twitter.com/GaryMarcus/status/1574587700547813376,"@xamat and Pearl is too. and eg Josh Tenenbaum would have a legit case, too. a lot of people would."
2621,@GaryMarcus,2022-09-27 02:26:32+00:00,https://twitter.com/GaryMarcus/status/1574586255685611521,A skeptical view on AI and drug development by Gary Smith https://t.co/LFW2DAh6ZS
2622,@GaryMarcus,2022-09-27 02:12:55+00:00,https://twitter.com/GaryMarcus/status/1574582828398157825,@raphaelmilliere @ak_panda @TonyZador @ylecun @bleepbeepbzzz @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez and why even call them symbols if they don‚Äôt?
2623,@GaryMarcus,2022-09-27 02:11:42+00:00,https://twitter.com/GaryMarcus/status/1574582524604731392,"@warren_craddock @BeebsMemes @crazyuddie @ylecun @jamesdouma there might be a viable alternative if current AI had roughy a human level understand and perception of the world. But it doesn‚Äôt. So I share the view that lidar is an essential, relative to current technological readiness."
2624,@GaryMarcus,2022-09-27 00:48:15+00:00,https://twitter.com/GaryMarcus/status/1574561521270919169,100% agree:
2625,@GaryMarcus,2022-09-27 00:24:44+00:00,https://twitter.com/GaryMarcus/status/1574555604383043584,fake news is coming to a chatbot near you
2626,@GaryMarcus,2022-09-27 00:23:01+00:00,https://twitter.com/GaryMarcus/status/1574555171426029569,@BeebsMemes @crazyuddie @ylecun @jamesdouma @warren_craddock i am sure @warren_craddock will have sensible things to say on that question as well
2627,@GaryMarcus,2022-09-27 00:15:43+00:00,https://twitter.com/GaryMarcus/status/1574553333276483585,@pmddomingos are you using framing to push poll or using framing to push poll?
2628,@GaryMarcus,2022-09-27 00:08:21+00:00,https://twitter.com/GaryMarcus/status/1574551480425943040,"@BeebsMemes @crazyuddie @ylecun @jamesdouma I can‚Äôt really make sense of what you saying here, but @warren_craddock had an excellent thread on lidar a few weeks ago."
2629,@GaryMarcus,2022-09-27 00:06:57+00:00,https://twitter.com/GaryMarcus/status/1574551127538139136,@ylecun @bleepbeepbzzz @TonyZador @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez hmm. what‚Äôs an ‚Äúemergent‚Äù symbol? is it something that stands for something else (as classical symbols are)? how would you know if you had one? in what sense would it be a symbol? could you do eg deductive inference with it?
2630,@GaryMarcus,2022-09-26 20:35:48+00:00,https://twitter.com/GaryMarcus/status/1574497989095485441,@pmddomingos @davidchalmers42 @MetaAI @ylecun for sure; never once in 30 years have i suggested otherwise
2631,@GaryMarcus,2022-09-26 20:35:00+00:00,https://twitter.com/GaryMarcus/status/1574497790943981568,"@ylecun @rao2z @guyvdb @MITCoCoSci don‚Äôt make this about me. there‚Äôs lot of evidence that neurosymbolic AI is a credible path; you just won‚Äôt engage with it. work by @swarat @AvilaGarcez @luislamb @AI4Code @MITCoCoSci @frossi_t @AnimaAnandkumar etc, none of which you consider (even if to refute) in your manifesto."
2632,@GaryMarcus,2022-09-26 20:26:31+00:00,https://twitter.com/GaryMarcus/status/1574495652863946752,"Indeed the Wozniak test seems better than the easily-gamed Turing Test, which is why a version of Wozniak test was part of the bet I offered Elon Musk."
2633,@GaryMarcus,2022-09-26 20:23:56+00:00,https://twitter.com/GaryMarcus/status/1574495006668525568,"@pchiusano @ylecun @ZDNET @TiernanRayTech i have repeatedly tried other means, eg writing a rebuttal in Noema, but he simply didn‚Äôt respond to my essay. likewise i have offered to participate in another moderated debate, but he has elected not to join. 

twitter is the wrong venue but only place he will engage"
2634,@GaryMarcus,2022-09-26 20:19:55+00:00,https://twitter.com/GaryMarcus/status/1574493991999250433,"@ylecun @bleepbeepbzzz @TonyZador @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez if the symbols map one-to-one onto vectors, promoting #2 might be inadvertent advocacy for parts of #1. 

i read Hinton as firmly opposed to #1 and see you possibly wavering. does your Noema essay pertain only to #2? 

how are *you* defining the symbols you endorsed there?"
2635,@GaryMarcus,2022-09-26 20:16:10+00:00,https://twitter.com/GaryMarcus/status/1574493051434958849,"@ak_panda @TonyZador @ylecun @bleepbeepbzzz @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez this dichotomy seems off
üëâdiscrete symbols (eg ASCII code) can be implemented as vectors
üëâdiscrete symbols can be learned (eg in ILP)
üëârules for operating over symbols can be learned (eg ILP)
üëâdifferentiability perhaps compatible w classic symbols eg https://t.co/qSJQsRJBwE"
2636,@GaryMarcus,2022-09-26 18:22:39+00:00,https://twitter.com/GaryMarcus/status/1574464484651192320,how can you work on AI and mention causal reasoning not cite @yudapearl?!
2637,@GaryMarcus,2022-09-26 16:05:46+00:00,https://twitter.com/GaryMarcus/status/1574430034701750277,"Watch this video (and second part, in replies) and tell me whether you think that Hinton thinks symbols are perfectly fine, as @ylecun just suggested."
2638,@GaryMarcus,2022-09-26 16:04:17+00:00,https://twitter.com/GaryMarcus/status/1574429659785465856,@ylecun @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez No. Hinton gave a talk at Stanford in 2015 on how symbols are like ‚Äúluminiferous aether‚Äù (ie a massive scientific mistake) and in this 2-part video he says that symbols are a massive waste of time and funding
2639,@GaryMarcus,2022-09-26 14:56:50+00:00,https://twitter.com/GaryMarcus/status/1574412686968094720,this was part of the bet i offered @elonmusk. he didn‚Äôt bite.
2640,@GaryMarcus,2022-09-26 14:43:49+00:00,https://twitter.com/GaryMarcus/status/1574409413255106560,"Optimus Robot demo, slated for Friday"
2641,@GaryMarcus,2022-09-26 14:22:07+00:00,https://twitter.com/GaryMarcus/status/1574403949247234048,none of the people who think that AGI risk is imminent have replied to this query.
2642,@GaryMarcus,2022-09-26 14:20:58+00:00,https://twitter.com/GaryMarcus/status/1574403661580873728,@danbri @ylecun @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez that guy should have a smackdown with this guy:
2643,@GaryMarcus,2022-09-26 14:08:07+00:00,https://twitter.com/GaryMarcus/status/1574400427223023616,"seems like i get asked this daily. for the record, i would be glad to do it."
2644,@GaryMarcus,2022-09-26 14:06:19+00:00,https://twitter.com/GaryMarcus/status/1574399974334664705,"@ylecun @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez also, doesn‚Äôt that mean you agree with my answers here? where do we disagree?"
2645,@GaryMarcus,2022-09-26 14:04:53+00:00,https://twitter.com/GaryMarcus/status/1574399614111068165,hoping @ylecun will answer this question directly; for me it is the crux.
2646,@GaryMarcus,2022-09-26 13:56:28+00:00,https://twitter.com/GaryMarcus/status/1574397493630341122,@BillHiggins @ylecun @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag @luislamb @AvilaGarcez @kahneman_daniel @KleInsight i am all for adversarial collaboration
2647,@GaryMarcus,2022-09-26 13:53:51+00:00,https://twitter.com/GaryMarcus/status/1574396838979174400,sounds like Optimus is going really well https://t.co/a91Bbmma5O
2648,@GaryMarcus,2022-09-26 13:45:10+00:00,https://twitter.com/GaryMarcus/status/1574394650278109187,"@ylecun @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 @NoemaMag so then you disagree with Hinton, who says symbols are aether, correct? 

Hinton opposes neurosymbolic/hybrid AI, but what you describe is consistent with it, viz finding ways of interoperating between symbolic &amp; vector operations. eg central focus of @luislamb &amp; @AvilaGarcez"
2649,@GaryMarcus,2022-09-26 13:21:53+00:00,https://twitter.com/GaryMarcus/status/1574388791808520193,"@ylecun @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 on your queries to me: i answered in 2018. not fully satisfied w answer to GQ3 now but don‚Äôt have a better answer; i see it as the central challenge for #neurosymbolic AI. @luislamb @garcez @swarat @MITCoCoSci @AnimaAnandkumar all working on it

my answers to first 2 remain same:"
2650,@GaryMarcus,2022-09-26 13:15:15+00:00,https://twitter.com/GaryMarcus/status/1574387122043523073,"@ylecun @raphaelmilliere @davidchalmers42 @MetaAI @noema @Jake_Browning00 In 2018 above and Nature 2015 you called for the replacement of symbols with vectors, firmly closing the door to symbols; in @NoemaMag 2022 you say that symbols exist but are learned, which opens the door to including symbolic techniques.

that‚Äôs the key change that I see."
2651,@GaryMarcus,2022-09-26 13:02:10+00:00,https://twitter.com/GaryMarcus/status/1574383830940909568,"@yudapearl @TiernanRayTech my rebuttal, fyi"
2652,@GaryMarcus,2022-09-26 04:54:45+00:00,https://twitter.com/GaryMarcus/status/1574261169485123584,"Can anyone who thinks AGI will come in less than 20 years refute this, other than by appeal to scaling curves that both @ylecun and I suspect will run out? 

A really good answer will save me from having to write an @ftxfuturefund essay :)"
2653,@GaryMarcus,2022-09-26 04:52:44+00:00,https://twitter.com/GaryMarcus/status/1574260661315858432,@ylecun @TompkinsDaniel also crosslinking my more substantive answer elsewhere in the thread:
2654,@GaryMarcus,2022-09-26 04:49:24+00:00,https://twitter.com/GaryMarcus/status/1574259823675604992,".@ylecun asks me, basically, if you are so smart, why don‚Äôt you solve AGI? My answer is that is too far outside grasp at the present time, because it requires significant progress in multiple areas, more or less in lockstep, before we will get to radical increases in performance:"
2655,@GaryMarcus,2022-09-26 04:46:48+00:00,https://twitter.com/GaryMarcus/status/1574259166646276096,"@ylecun @TompkinsDaniel oh boy, back to the ad hominem. just when we are actually talking about something of substance."
2656,@GaryMarcus,2022-09-26 04:44:13+00:00,https://twitter.com/GaryMarcus/status/1574258518022291456,"@ylecun @rao2z @guyvdb @MITCoCoSci this is at least a 5-10 year, billion $ effort, and I don‚Äôt have a billion $ at my disposal. i think most near-term efforts will neglect at least one of those four components, and hence fail.

don‚Äôt think AGI is impossible, but it will require large scale coordination."
2657,@GaryMarcus,2022-09-26 04:41:43+00:00,https://twitter.com/GaryMarcus/status/1574257889560363011,"@ylecun @rao2z @guyvdb @MITCoCoSci I don‚Äôt think that AGI is achievable in short-term; as outlined in The Next Decade in AI, I think progress requires coalition of
- advances in neurosymbolic integration
- richer knowledge bases
- better reasoning from incomplete data
- ways of inducing complex cognitive models"
2658,@GaryMarcus,2022-09-26 04:38:26+00:00,https://twitter.com/GaryMarcus/status/1574257061508313090,@ylecun @rao2z @MITCoCoSci @guyvdb whether you can do that without innate symbols certainly remains to be seen; what‚Äôs the best evidence that you might be able to?
2659,@GaryMarcus,2022-09-26 04:36:42+00:00,https://twitter.com/GaryMarcus/status/1574256626420580353,@TompkinsDaniel @ylecun absolutely right! but dismissing all available techniques and saying ‚ÄúI have an idea for a different one that happens to be deep learning‚Äù is a long way from showing that deep learning is *in fact* going to solve them.
2660,@GaryMarcus,2022-09-26 04:34:24+00:00,https://twitter.com/GaryMarcus/status/1574256048294494208,"@ylecun maybe, maybe not.
- right now there are bunch of problems that nobody has clear solutions to (language comprehension, planning, reasoning)
- you are *hoping* that deep learning will solve them
- but that‚Äôs just speculation; see refs I just gave to @rao2z @guyvdb @MITCoCoSci"
2661,@GaryMarcus,2022-09-26 04:27:59+00:00,https://twitter.com/GaryMarcus/status/1574254432044609536,@ylecun @rao2z @MITCoCoSci @guyvdb and @guyvdb‚Äôs group on reasoning:
2662,@GaryMarcus,2022-09-26 04:26:55+00:00,https://twitter.com/GaryMarcus/status/1574254163349114880,@ylecun @rao2z @MITCoCoSci @guyvdb https://t.co/F2Ikf7RWKH by @rao2z‚Äôs group on planning
2663,@GaryMarcus,2022-09-26 04:24:10+00:00,https://twitter.com/GaryMarcus/status/1574253473436434432,@ylecun @rao2z @MITCoCoSci @guyvdb this is a strong argument for a neurosymbolic approach to planning
2664,@GaryMarcus,2022-09-26 04:22:53+00:00,https://twitter.com/GaryMarcus/status/1574253150328213505,"@ylecun perfectly reasonable to pursue all that, but I don‚Äôt see any special reason to think it will work w planning; both @rao2z and @MITCoCoSci have recently proposed some challenges there that you ought consider, and see @guyvdb for challenges to deep learning approaches to reasoning"
2665,@GaryMarcus,2022-09-26 04:18:23+00:00,https://twitter.com/GaryMarcus/status/1574252017387991040,"@ylecun ps we already have self-supervised learning, and you yourself don‚Äôt think as such/on its own that it will scale; your rocket also (wisely!) includes your configurable world models etc, not just ssl."
2666,@GaryMarcus,2022-09-26 04:15:03+00:00,https://twitter.com/GaryMarcus/status/1574251178904653825,"@ylecun fine, but here is what I actually get from you, ‚Äúdeep learning has a hit wall, but I think with my not-yet-implemented theory, I might see a way past that wall.‚Äù

that‚Äôs totally reasonable

but then stop ridiculing people who say we need something beyond what we have, ok?"
2667,@GaryMarcus,2022-09-26 04:10:01+00:00,https://twitter.com/GaryMarcus/status/1574249909251117056,"@ylecun and, interestingly, with innately structured modules. cc: @davidchalmers42"
2668,@GaryMarcus,2022-09-26 03:55:06+00:00,https://twitter.com/GaryMarcus/status/1574246157437784064,"my actual feed right now, @ylecun and @ylecun RT

supervised learning and RL are limited; we can‚Äôt scale what we‚Äôve got; most of today‚Äôs approaches won‚Äôt work.

yet deep learning is without qualification the foundation of future progress https://t.co/Hlfz0a0snQ"
2669,@GaryMarcus,2022-09-26 03:42:42+00:00,https://twitter.com/GaryMarcus/status/1574243034778447872,"@ylecun And what did you mean exactly by ‚ÄúOkay, we built this ladder, but we want to go to the moon, and there's no way this ladder is going to get us there‚Äù?

What‚Äôs the moon? What‚Äôs the ladder? Why are you sure the ladder won‚Äôt succeed?"
2670,@GaryMarcus,2022-09-26 02:58:38+00:00,https://twitter.com/GaryMarcus/status/1574231945516810240,"@TheShoeLady33 @DGBassani so many people don‚Äôt understand how probabilistic the illness is, and make poor chances as a consequence."
2671,@GaryMarcus,2022-09-26 02:54:10+00:00,https://twitter.com/GaryMarcus/status/1574230824350003201,"@davidchalmers42 @MetaAI @ylecun lecun 2022 doesn‚Äôt look continuous with lecun 2022: 

September 14, 2022: ‚ÄúThere are ‚Äúno walls being hit‚Ä¶I don‚Äôt see progress slowing down at all ‚Ä¶ progress is accelerating, if anything.‚Äù¬†

September 24, 2022: Fundamental problems elude many strains of deep learning, says LeCun"
2672,@GaryMarcus,2022-09-26 02:43:36+00:00,https://twitter.com/GaryMarcus/status/1574228164393734144,"@memotv @davidchalmers42 @MetaAI @ylecun i have argued (marcus 2001 and again recently) that vectors are symbols, but i don‚Äôt see where Lecun et al 2015 say that, and neural network community hasn‚Äôt exactly embraced that idea

the game here isn‚Äôt to find a coherent view, it‚Äôs to understand what LeCun actually meant"
2673,@GaryMarcus,2022-09-26 02:37:58+00:00,https://twitter.com/GaryMarcus/status/1574226744265277440,"turns out i was wrong all along. deep learning hasn‚Äôt been hitting a wall. just approaching level that it hasn‚Äôt yet transcended.

my bad. https://t.co/NxrOrqMN99"
2674,@GaryMarcus,2022-09-26 02:35:24+00:00,https://twitter.com/GaryMarcus/status/1574226100007632896,"@ModMorph @ylecun if we need a whole other level, there is a wall we need to transcend."
2675,@GaryMarcus,2022-09-26 02:34:14+00:00,https://twitter.com/GaryMarcus/status/1574225805378723840,@joorosa12185462 @ylecun how are they orthogonal?
2676,@GaryMarcus,2022-09-26 02:32:54+00:00,https://twitter.com/GaryMarcus/status/1574225469133946881,"@memotv @davidchalmers42 @MetaAI @ylecun he says use vectors instead of symbols.

signing off from this part of thread."
2677,@GaryMarcus,2022-09-26 02:28:57+00:00,https://twitter.com/GaryMarcus/status/1574224478330290176,"sources:
Sept 14: https://t.co/2CAiLjMCpX

Sept 24: https://t.co/aoifzfOMoK"
2678,@GaryMarcus,2022-09-26 02:28:57+00:00,https://twitter.com/GaryMarcus/status/1574224476916809728,"Rough week for deep learning?

September 14, 2022: ‚ÄúThere are ‚Äúno walls being hit,‚Äù added  LeCun. ‚ÄúI don‚Äôt see progress slowing down at all ‚Ä¶ progress is accelerating, if anything.‚Äù¬†

September 24, 2022: Fundamental problems elude many strains of deep learning, says @YLeCun"
2679,@GaryMarcus,2022-09-26 02:14:19+00:00,https://twitter.com/GaryMarcus/status/1574220795068710912,"@raphaelmilliere @davidchalmers42 @MetaAI @ylecun @noema absolutely. he used the word ‚Äúinstead‚Äù,  not me. I don‚Äôt think his position is coherent.
 
I also think the @noema article actually embraced explicit symbol manipulation so long as those symbols are learned. 

perhaps Dr LeCun will clarify? @Jake_Browning00?"
2680,@GaryMarcus,2022-09-26 02:05:01+00:00,https://twitter.com/GaryMarcus/status/1574218453292290049,@memotv @davidchalmers42 @MetaAI @ylecun that‚Äôs just not what he says. attend to the word ‚Äúinstead‚Äù
2681,@GaryMarcus,2022-09-26 01:50:35+00:00,https://twitter.com/GaryMarcus/status/1574214821410930689,@mpshanahan @GarneloMarta @kaixhin still very relevant!
2682,@GaryMarcus,2022-09-26 01:46:07+00:00,https://twitter.com/GaryMarcus/status/1574213696129470464,"@liuyao12 @davidchalmers42 @MetaAI @ylecun many people have invited us to debate again, as recently as last week. i always accept; he never does."
2683,@GaryMarcus,2022-09-26 01:42:35+00:00,https://twitter.com/GaryMarcus/status/1574212809176809472,"@davidchalmers42 @MetaAI @ylecun crystal clear example: he was absolutely firm here in 2018 that he was against symbols, and absolutely opposed to my 2018 defense of symbols; and yet absolutely in favor of symbols in his 2022 @noema article w Browning. 

How is that *not* change?"
2684,@GaryMarcus,2022-09-26 01:37:32+00:00,https://twitter.com/GaryMarcus/status/1574211537505755136,@memotv @davidchalmers42 @MetaAI @ylecun that‚Äôs says replace rules. it doesn‚Äôt say replace hand-crafted rules. so does this:
2685,@GaryMarcus,2022-09-26 01:32:30+00:00,https://twitter.com/GaryMarcus/status/1574210268275802113,it‚Äôs just bizarre to me that some people are trying to tell me LeCun has been for symbols all along when LeCun periodically says stuff like this:
2686,@GaryMarcus,2022-09-26 01:30:46+00:00,https://twitter.com/GaryMarcus/status/1574209832688971776,"@davidchalmers42 @MetaAI @ylecun but again on symbols, some examples of absolute opposition, like this.

so yes some things constant, others not."
2687,@GaryMarcus,2022-09-26 01:29:00+00:00,https://twitter.com/GaryMarcus/status/1574209388948361216,"@memotv @davidchalmers42 @MetaAI @ylecun the 2015 nature paper ends by calling for the replacement of rules, btw; your characterization isn‚Äôt really correct"
2688,@GaryMarcus,2022-09-26 01:28:19+00:00,https://twitter.com/GaryMarcus/status/1574209215820083200,"@memotv @davidchalmers42 @MetaAI @ylecun that‚Äôs (sort of) the disagreement; the assumptions you made before about what could be correct is where you assumed the conclusion.

my own view is that there is some initial structure that constrains which rules are learned,  not that all rules are hand-crafted"
2689,@GaryMarcus,2022-09-26 01:26:31+00:00,https://twitter.com/GaryMarcus/status/1574208765305716736,"@sarahookr did anybody in this thread actually read anything about the research on the topic? even the wikipedia page? https://t.co/ZoX6Wlc3j8

i am not fully endorsing the field but there is a real literature here and nobody doing the dunking is referring to it, at all."
2690,@GaryMarcus,2022-09-26 01:21:01+00:00,https://twitter.com/GaryMarcus/status/1574207380854050817,@davidchalmers42 @MetaAI @ylecun on that he has held firm.
2691,@GaryMarcus,2022-09-26 01:19:48+00:00,https://twitter.com/GaryMarcus/status/1574207075840053248,@memotv @davidchalmers42 @MetaAI @ylecun you have assumed your conclusions
2692,@GaryMarcus,2022-09-26 01:16:07+00:00,https://twitter.com/GaryMarcus/status/1574206146919137280,@davidchalmers42 @MetaAI @ylecun and if you think symbols are ‚Äúhis ideas‚Äù you have entirely misread the literature.
2693,@GaryMarcus,2022-09-26 01:14:50+00:00,https://twitter.com/GaryMarcus/status/1574205822972080128,"@davidchalmers42 @MetaAI @ylecun or how about his 2018 comment on deep learning: a critical appraisal, which argued staunchly for symbols; he said it was ‚Äúmostly wrong‚Äù

truth is, since debate he has vacillated quite a bit about symbols, and also about the ability of LLMs to build cognitive models,"
2694,@GaryMarcus,2022-09-26 01:07:01+00:00,https://twitter.com/GaryMarcus/status/1574203857877741568,"@davidchalmers42 @MetaAI @ylecun and i don‚Äôt even know what to make of tweets like this, but they seem much less pro symbols (though pro cognitive model) than the Noema article:"
2695,@GaryMarcus,2022-09-26 01:00:03+00:00,https://twitter.com/GaryMarcus/status/1574202102121123840,"@davidchalmers42 @MetaAI @ylecun so you are going to count his intermittent support for that but not the outright hostility to cognitive models in various other tweets (eg ‚Äúrearguard action‚Äù ) that i documented in the article above?

that‚Äôs a mighty selective reading"
2696,@GaryMarcus,2022-09-26 00:57:04+00:00,https://twitter.com/GaryMarcus/status/1574201353765003264,@Zergylord @ylecun @ZDNET @TiernanRayTech @RobustAI i don‚Äôt hear you by the way expressing concerns about Google‚Äôs endless promotion of models they won‚Äôt share with the community.
2697,@GaryMarcus,2022-09-26 00:17:11+00:00,https://twitter.com/GaryMarcus/status/1574191317546311680,"@Zergylord @ylecun @ZDNET @TiernanRayTech @RobustAI it was bought by uber, and we thus lost control of the IP. it is a shame. 

@ZoubinGhahrama1 and @kenneth0stanley would agree it is was a really fun idea."
2698,@GaryMarcus,2022-09-26 00:15:02+00:00,https://twitter.com/GaryMarcus/status/1574190773217947648,"@davidchalmers42 @MetaAI @ylecun while i see your point, everything he said to me on twitter between now &amp; then was hostile to everything i said in Deep Learning: A Critical Appraisal. 

so maybe he was on his best behavior at the debate &amp; not in between?"
2699,@GaryMarcus,2022-09-26 00:10:47+00:00,https://twitter.com/GaryMarcus/status/1574189704995831808,@davidchalmers42 @MetaAI @ylecun what did he say about symbols?
2700,@GaryMarcus,2022-09-26 00:02:23+00:00,https://twitter.com/GaryMarcus/status/1574187590710104064,"@davidchalmers42 @MetaAI @ylecun ps there is recent discussion of innateness by both of us (civilized, even) @NoemaMag, references in my post above"
2701,@GaryMarcus,2022-09-26 00:00:54+00:00,https://twitter.com/GaryMarcus/status/1574187219069579264,@Zergylord @ylecun @ZDNET @TiernanRayTech @RobustAI ps the geometric work was straight ML but remains under NDA.
2702,@GaryMarcus,2022-09-25 23:58:50+00:00,https://twitter.com/GaryMarcus/status/1574186699030429696,"@Zergylord @ylecun @ZDNET @TiernanRayTech @RobustAI nope still false.  my 1998 paper was in fact a paper about ML with experimental evidence with multilayer networks and generalization tests, without and outside of distribution, ahead of its time. 

&amp; honestly @IntuitMachine said it best:"
2703,@GaryMarcus,2022-09-25 23:51:15+00:00,https://twitter.com/GaryMarcus/status/1574184789753876480,"@davidchalmers42 @MetaAI @ylecun we still disagree about innateness

he speaks much more now (some then) about importance of cognitive models

he was lukewarm to symbols in our debate, now he has started to recognize their importance

since 2018 he has leaned hard on ad hominem &amp; dishonesty, unlike in debate"
2704,@GaryMarcus,2022-09-25 22:13:54+00:00,https://twitter.com/GaryMarcus/status/1574160292019605504,@saxarona @susan_dagostino i lay out it both cases in more detail here:
2705,@GaryMarcus,2022-09-25 21:46:32+00:00,https://twitter.com/GaryMarcus/status/1574153405224091648,fabulous
2706,@GaryMarcus,2022-09-25 21:45:30+00:00,https://twitter.com/GaryMarcus/status/1574153143969255425,"@nlpnyc @ylecun @ZDNET @TiernanRayTech there are also now links at ZDNet, since it is demonstrably false."
2707,@GaryMarcus,2022-09-25 21:44:57+00:00,https://twitter.com/GaryMarcus/status/1574153003430707200,"@nlpnyc @ylecun @ZDNET @TiernanRayTech you have that impression because people who have never bothered to look whisper it. i included links to some of my peer reviewed work (not the geometric stuff, under NDA) in https://t.co/rTEVpYs1CG, including articles in AIJ, Artificial Intelligence, etc"
2708,@GaryMarcus,2022-09-25 21:41:07+00:00,https://twitter.com/GaryMarcus/status/1574152042427580416,@ProfNoahGian @ylecun @ZDNET @TiernanRayTech I bet Carly Simon wrote this song about me ü§£ü§£ü§£
2709,@GaryMarcus,2022-09-25 20:44:32+00:00,https://twitter.com/GaryMarcus/status/1574137802186715136,". @ylecun continues his libel campaign‚Äîapparently even after being corrected. 

@zdnet issued a correction. @ylecun i respectfully ask you to do the same.  

some are matter of opinion.  #10 is false, and you have been told this directly, yet persist in it.

cc @TiernanRayTech https://t.co/A9xBLTx8h9"
2710,@GaryMarcus,2022-09-25 20:10:43+00:00,https://twitter.com/GaryMarcus/status/1574129291851628544,"@NicolaBernini @MetaAI @ylecun i address that in the piece, with a quote"
2711,@GaryMarcus,2022-09-25 19:47:10+00:00,https://twitter.com/GaryMarcus/status/1574123366247989248,@NaveenGRao @SchmidhuberAI see
2712,@GaryMarcus,2022-09-25 19:46:53+00:00,https://twitter.com/GaryMarcus/status/1574123293145460736,"@lathropa @MetaAI @ylecun quoted this, here:"
2713,@GaryMarcus,2022-09-25 19:45:29+00:00,https://twitter.com/GaryMarcus/status/1574122939402035200,"What‚Äôs going on with @MetaAI‚Äôs Chief AI Scientist @ylecun?  And how new are his ‚Äúnew‚Äù ideas?

https://t.co/RUNUs8k0S9"
2714,@GaryMarcus,2022-09-25 18:51:38+00:00,https://twitter.com/GaryMarcus/status/1574109387891023872,@NaveenGRao @SchmidhuberAI you wouldn‚Äôt like my keyboard when I am angry :)
2715,@GaryMarcus,2022-09-25 18:43:36+00:00,https://twitter.com/GaryMarcus/status/1574107366131666944,@NaveenGRao @SchmidhuberAI wait til you see the essay i am about to post :)
2716,@GaryMarcus,2022-09-25 17:45:25+00:00,https://twitter.com/GaryMarcus/status/1574092723480834050,@jasonbaldridge @fchollet @TristanThrush @candacerossio i have been working on this behind the scenes and will send a reminder
2717,@GaryMarcus,2022-09-25 17:44:44+00:00,https://twitter.com/GaryMarcus/status/1574092552768458752,"@MoveToBinFolder absolutely. @sarahookr ‚Äôs Hardware Lottery is a brilliant way to think about this, and there is more to be said"
2718,@GaryMarcus,2022-09-25 17:19:05+00:00,https://twitter.com/GaryMarcus/status/1574086097688461312,Evergreen tweet
2719,@GaryMarcus,2022-09-25 17:03:34+00:00,https://twitter.com/GaryMarcus/status/1574082193491894272,"@NickRMorgan @fchollet @TristanThrush @candacerossio Many are, @fchollet is not, consistently a cut above. I have great respect for him, even though in this instance he is a bit off."
2720,@GaryMarcus,2022-09-25 16:49:20+00:00,https://twitter.com/GaryMarcus/status/1574078610046341120,"@ihorgowda @AoDespair Greatest honor of my twitter life. @aodespair‚Äôs Homicide: Life on The Streets is one of my 10 favorite books of all time! To say nothing of H:LOTS and The Wire. 

And yes it is true that we both revel in speaking truth to power."
2721,@GaryMarcus,2022-09-25 16:36:43+00:00,https://twitter.com/GaryMarcus/status/1574075436677865472,What I am thinking about as I write today‚Äôs essay https://t.co/LjPnV3wJDX
2722,@GaryMarcus,2022-09-25 16:35:06+00:00,https://twitter.com/GaryMarcus/status/1574075029960421376,"@jbondc @MetaAI @ylecun then why has spent 2022 giving interviews and writing papers about not-yet implemented theoretical ideas? that‚Äôs having it both ways.

people‚Äînot just him‚Äîshould be allowed to do both. 

it is the height of hypocrisy and abuse of power to do as he has done."
2723,@GaryMarcus,2022-09-25 16:13:22+00:00,https://twitter.com/GaryMarcus/status/1574069560420208640,"@hughes_meister some aspects need to be learned. the mere existence of space and time and how to reason over them probably ought to be baked in. without that, learning is grossly inefficient. (convolution does build in one aspect of space, and that‚Äôs why it works so well)"
2724,@GaryMarcus,2022-09-25 16:09:20+00:00,https://twitter.com/GaryMarcus/status/1574068544408813568,@jasonbaldridge @fchollet please test @TristanThrush and @candacerossio ‚Äôs Winoground and publicly disclose the results
2725,@GaryMarcus,2022-09-25 15:43:59+00:00,https://twitter.com/GaryMarcus/status/1574062166491435009,"No, @fchollet, these models are *not* compositional in the sense that linguists discuss.

They consistently fail on tasks like @TristanThrush and @candacerossio‚Äôs Winoground. 

See also my substack (Horse Rides Astronaut  &amp; GoogleAI Snookered ) &amp; talks at https://t.co/mQdOoGiYfI"
2726,@GaryMarcus,2022-09-25 15:38:11+00:00,https://twitter.com/GaryMarcus/status/1574060705887948801,if anyone could introduce me to Liz Cheney‚Äôs staff please let me know
2727,@GaryMarcus,2022-09-25 15:36:20+00:00,https://twitter.com/GaryMarcus/status/1574060241964371969,@danielmalmer top of my list of people to reach out to; if anyone has ties to her please let me know
2728,@GaryMarcus,2022-09-25 15:09:16+00:00,https://twitter.com/GaryMarcus/status/1574053430263681024,@ProfNoahGian @sinanaral @noUpside @katestarbird yep; he is a target in what i am writing
2729,@GaryMarcus,2022-09-25 15:03:49+00:00,https://twitter.com/GaryMarcus/status/1574052057279234048,"@taamfp @Twitter @SchmidhuberAI thanks; a bit more work than I want to do for one damned tweet, updating the authentication and all that. but maybe i will have to"
2730,@GaryMarcus,2022-09-25 15:02:38+00:00,https://twitter.com/GaryMarcus/status/1574051758716100608,@Dataprogr @ylecun his ‚Äúglobal insight‚Äù in the ZDNet interview consisted primarily of regurgitating the key points in my 2018 article deep learning: a critical appraisal (which he once called ‚Äúmostly wrong‚Äù).
2731,@GaryMarcus,2022-09-25 14:43:47+00:00,https://twitter.com/GaryMarcus/status/1574047013918113792,"@taamfp @Twitter no although i will include that as well. what i remember was a side by side comparison. half looked like this, half was from @SchmidhuberAI, highlighting the parallels. I could reconstruct it but would prefer the original tweet/pair of images https://t.co/q5E3ACLphx"
2732,@GaryMarcus,2022-09-25 14:35:47+00:00,https://twitter.com/GaryMarcus/status/1574045003353321477,"Hey @twitter please extend Twitter Advanced Search to a user‚Äôs own Likes. I want to find something I liked in July, and because I like a lot of stuff there is no efficient way to do it.

Easy feature to add, would be very useful."
2733,@GaryMarcus,2022-09-25 14:26:50+00:00,https://twitter.com/GaryMarcus/status/1574042751217594368,"@Zergylord @ulusdd @ZDNET @TiernanRayTech @ylecun yes (elaborated in a *book* that was peer reviewed by MIT press, The Algebraic Mind)"
2734,@GaryMarcus,2022-09-25 14:24:06+00:00,https://twitter.com/GaryMarcus/status/1574042063192330245,"@Zergylord @ulusdd @ZDNET @TiernanRayTech @ylecun of course lecun stacked the deck. the most important peer-reviewed contribution was an analysis of neural networks that happened to be published in a psychology journal, anticipating all the problems with distribution shift for reasoning and language that are prevalent now."
2735,@GaryMarcus,2022-09-25 14:15:53+00:00,https://twitter.com/GaryMarcus/status/1574039995635335169,@ulusdd @Zergylord @ZDNET @TiernanRayTech @ylecun i will put some of them in an essay i am writing this morning. or go se the correction Zdnet issued if you are impatient.
2736,@GaryMarcus,2022-09-25 14:14:07+00:00,https://twitter.com/GaryMarcus/status/1574039551458574338,"anybody have handy the comparison tweet between LeCun‚Äôs recent manifesto and @SchmidhuberAI‚Äôs early work, side by side figure if the 2 ?  i need the tweet for something i am writing."
2737,@GaryMarcus,2022-09-25 14:00:58+00:00,https://twitter.com/GaryMarcus/status/1574036238319124488,"@hughes_meister true, but the deeper problem is the lack of explicit world models. adding video doesn‚Äôt immediately solve that"
2738,@GaryMarcus,2022-09-25 13:59:10+00:00,https://twitter.com/GaryMarcus/status/1574035786458345472,@stevenflinn @Twitter it‚Äôs actually been done!
2739,@GaryMarcus,2022-09-25 13:26:17+00:00,https://twitter.com/GaryMarcus/status/1574027513915125760,@chantz_y nobody ever wants to listen; here‚Äôs what i wrote about this in summer 2020: https://t.co/qct1G3t03T
2740,@GaryMarcus,2022-09-25 13:25:20+00:00,https://twitter.com/GaryMarcus/status/1574027273216589824,"@DGBassani i tried to warn BC in summer of 2020:

https://t.co/qct1G3t03T"
2741,@GaryMarcus,2022-09-25 13:20:58+00:00,https://twitter.com/GaryMarcus/status/1574026172459253761,"@jasonbaldridge @fchollet i think the problem is deeper than that; they just don‚Äôt even try to develop explicit models; even if you give them more types of input, there is something foundational lacking"
2742,@GaryMarcus,2022-09-25 13:19:51+00:00,https://twitter.com/GaryMarcus/status/1574025891386392577,"@jasonbaldridge @fchollet i would be careful about claiming that they can compose concepts; certainly they cannot reliably do so in the ways that cognitive psychologists and philosophers have discussed. (but yes, you are correct that they float free of the world)"
2743,@GaryMarcus,2022-09-25 05:29:01+00:00,https://twitter.com/GaryMarcus/status/1573907404345188352,"@rmayemsinger @TheUSASingers bullshit in life, decomposing in the afterlife"
2744,@GaryMarcus,2022-09-25 05:26:13+00:00,https://twitter.com/GaryMarcus/status/1573906698435448837,"@maartengm @MetaAI @ylecun update: @zdnet issued an immediate correction, because LeCun‚Äôs claim was demonstrated to be false."
2745,@GaryMarcus,2022-09-25 05:23:00+00:00,https://twitter.com/GaryMarcus/status/1573905891359068160,"@stanislavfort @ylecun i started with the conclusion, based on my understanding of distribution shift from Marcus 1998/2001, and then found a metaphor to explain what I anticipated would happen."
2746,@GaryMarcus,2022-09-25 04:59:43+00:00,https://twitter.com/GaryMarcus/status/1573900029169106945,thread in which @Grady_Booch and I articulate a rare disagreement we have with @fchollet.
2747,@GaryMarcus,2022-09-25 04:43:16+00:00,https://twitter.com/GaryMarcus/status/1573895890397696000,"@fchollet no, it‚Äôs the difference between having an explicit functional model and working purely in an image space that is correlated with labels."
2748,@GaryMarcus,2022-09-25 04:42:04+00:00,https://twitter.com/GaryMarcus/status/1573895589594812417,"@fchollet i wrote some about this last week, with further examples: https://t.co/1xciYldIVi"
2749,@GaryMarcus,2022-09-25 04:34:58+00:00,https://twitter.com/GaryMarcus/status/1573893801198120960,@linasvepstas indeed. but i am not looking for people who exclaim Fake News :) I am looking for genuine bipartisan support to do better.
2750,@GaryMarcus,2022-09-25 04:24:35+00:00,https://twitter.com/GaryMarcus/status/1573891188956213254,@katestarbird @noUpside @sinanaral @ProfNoahGian thanks!!
2751,@GaryMarcus,2022-09-25 03:49:55+00:00,https://twitter.com/GaryMarcus/status/1573882464682283008,@prem_k but not inevitable that one cobblestone would dismiss the other and lie about his credentials.
2752,@GaryMarcus,2022-09-25 03:48:28+00:00,https://twitter.com/GaryMarcus/status/1573882098653757441,@noUpside @sinanaral @ProfNoahGian @katestarbird thank you!!
2753,@GaryMarcus,2022-09-25 03:28:19+00:00,https://twitter.com/GaryMarcus/status/1573877027257864193,@sinanaral @noUpside @ProfNoahGian @katestarbird any leads?
2754,@GaryMarcus,2022-09-25 03:24:54+00:00,https://twitter.com/GaryMarcus/status/1573876169573027847,"hive mind, are there any well-known Republicans who have spoken out against misinformation?"
2755,@GaryMarcus,2022-09-25 03:14:25+00:00,https://twitter.com/GaryMarcus/status/1573873531490041856,"@Joegle richest man I ever treated to lunch :) 

(but only because the place i took him to didn‚Äôt allow guests to pay)"
2756,@GaryMarcus,2022-09-25 03:00:47+00:00,https://twitter.com/GaryMarcus/status/1573870101535035392,@joegle thank you!
2757,@GaryMarcus,2022-09-25 02:55:53+00:00,https://twitter.com/GaryMarcus/status/1573868864739643392,"my next follower will be my 70,000th. thank you all who follow for all your support, through thick and thin!

(@twitter, you never responded to my request for verification; maybe the time has come?)"
2758,@GaryMarcus,2022-09-25 02:28:04+00:00,https://twitter.com/GaryMarcus/status/1573861864970518528,"@maartengm @MetaAI @ylecun it‚Äôs flagrant disregard of academic etiquette and he libeled me as well, claiming I don‚Äôt have any peer-reviewed work in AI journals, which is demonstrably false."
2759,@GaryMarcus,2022-09-25 02:24:26+00:00,https://twitter.com/GaryMarcus/status/1573860953149812737,"@ZDNET @TiernanRayTech This libels me, by claiming‚Äîfalsely‚Äîthat I have not published any AI work in peer review journals &amp; at same time the substance is virtually identical to my 2012 &amp; 2018 papers, not in any way original to @yLeCun; a thread summarizing some of the many similarities here:"
2760,@GaryMarcus,2022-09-25 01:58:13+00:00,https://twitter.com/GaryMarcus/status/1573854353123053568,@KrishnaKGupta @MetaAI @ylecun @ZDNET here are the highlights in the comparison
2761,@GaryMarcus,2022-09-25 01:54:09+00:00,https://twitter.com/GaryMarcus/status/1573853330199433222,I‚Äôve added receipts to the document the uncanny similarity between LeCun‚Äôs 2022 view and my own in this thread:
2762,@GaryMarcus,2022-09-25 01:50:57+00:00,https://twitter.com/GaryMarcus/status/1573852524364595200,See also @SchmidhuberAI: https://t.co/NgUb5Q6VKW (and @NoemaMag https://t.co/7WD8XxMEAr)
2763,@GaryMarcus,2022-09-25 01:50:56+00:00,https://twitter.com/GaryMarcus/status/1573852523374710784,"Sources
Marcus 2012: https://t.co/VJO8RZINCj
Marcus 2018: https://t.co/hCWzzUEVYK
LeCun 2022: https://t.co/aoifzfOMoK"
2764,@GaryMarcus,2022-09-25 01:50:56+00:00,https://twitter.com/GaryMarcus/status/1573852522531663872,"LeCun 2018 on Marcus 2018: It‚Äôs ‚Äúmostly wrong‚Äù
LeCun 2022: Marcus has never made a contribution to AI"
2765,@GaryMarcus,2022-09-25 01:50:56+00:00,https://twitter.com/GaryMarcus/status/1573852519947968512,"Marcus 2018 ‚ÄúProblems that have less to do with categorization and more to do with commonsense reasoning essentially lie outside the scope of what deep learning is appropriate for‚Äù
LeCun 2022: ‚ÄúI think AI systems need to be able to reason‚Äù"
2766,@GaryMarcus,2022-09-25 01:50:55+00:00,https://twitter.com/GaryMarcus/status/1573852518932946944,"Marcus 2018: ‚ÄúWhere should we look? Common sense knowledge‚Ä¶how it is represented, &amp; how it is integrated in our interactions with the real world‚Äù
LeCun 2022: ‚ÄúWe're not to the point where our intelligent machines have as much common sense as a cat. So, why don't we start there?‚Äù"
2767,@GaryMarcus,2022-09-25 01:50:55+00:00,https://twitter.com/GaryMarcus/status/1573852518010220545,"Marcus 2018: ‚Äúit is misleading to credit deep reinforcement learning with inducing concept[s] ‚Äù
LeCun 2022: Reinforcement learning will also never be enough [for general intelligence]"
2768,@GaryMarcus,2022-09-25 01:50:55+00:00,https://twitter.com/GaryMarcus/status/1573852517037133824,"Marcus 2018 ‚ÄúI don‚Äôt think that we need to abandon deep learning‚Ä¶we need to reconceptualize it: not as a universal solvent, but simply as one tool among many‚Äù
LeCun 2022 Deep learning ‚Äúmay be a component of a future intelligent system, but I think it's missing essential pieces‚Äù"
2769,@GaryMarcus,2022-09-25 01:50:55+00:00,https://twitter.com/GaryMarcus/status/1573852515216789505,"Marcus, 2018: ‚ÄúI present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.‚Äù
LeCun 2022:  Today's AI approaches will never lead to true intelligence"
2770,@GaryMarcus,2022-09-25 01:50:54+00:00,https://twitter.com/GaryMarcus/status/1573852514189180928,"Marcus 2012: ‚ÄúTo paraphrase an old parable, [deep learning] is a better ladder; but a better ladder doesn‚Äôt necessarily get you to the moon‚Äù

@YLeCun, 2022, ‚ÄúOkay, we built this ladder, but we want to go to the moon, and there's no way this ladder is going to get us there‚Äù

üßµ1/9"
2771,@GaryMarcus,2022-09-25 01:17:20+00:00,https://twitter.com/GaryMarcus/status/1573844063820075008,"@javierluraschi @MetaAI @ylecun he also lied and said i don‚Äôt have any peer review articles in AI journals, and that‚Äôs simply false."
2772,@GaryMarcus,2022-09-25 00:15:07+00:00,https://twitter.com/GaryMarcus/status/1573828406860738560,@venkat_srini_ @ylecun he does the opposite; he says I have never done anything even as he repeats my position (that he once denounced) almost line by line
2773,@GaryMarcus,2022-09-25 00:14:09+00:00,https://twitter.com/GaryMarcus/status/1573828164039876608,"@KrishnaKGupta @MetaAI @ylecun compare line by line the 2022 @zdnet LeCun interview with my 2018 Deep Learning; A Critical Appraisal article; it‚Äôs astounding how similar they are, and how much grief LeCun gave me at the time. (&amp; how little credit he gives me now for having anticipated any of this.)"
2774,@GaryMarcus,2022-09-24 23:42:45+00:00,https://twitter.com/GaryMarcus/status/1573820262008918016,"Seriously, @ylecun what do you say here that I did not say in 2018 in Deep Learning: A Critical Appraisal, which at the time you declared to be ‚Äúmostly wrong‚Äù? 

How is what you are saying now different from what I said then? 

Compare: https://t.co/wD2UXX21Hg"
2775,@GaryMarcus,2022-09-24 20:07:56+00:00,https://twitter.com/GaryMarcus/status/1573766203516260352,"@pressron interested wikipedia entry but i don‚Äôt see how it remotely contradicts the notion that the word is a tool for stereotyping.

and i am surely not calling for the reinstatement of other terms that do similar work towards even less privileged groups."
2776,@GaryMarcus,2022-09-24 20:03:29+00:00,https://twitter.com/GaryMarcus/status/1573765083888746496,"‚Äúrespect is something that you can produce more or less of, in the aggregate‚Ä¶ If you start calling someone by their preferred pronoun, you haven‚Äôt abased yourself; you have generated new respect, and added to the world‚Äôs total supply.‚Äù
 -@Noahpinion"
2777,@GaryMarcus,2022-09-24 19:56:15+00:00,https://twitter.com/GaryMarcus/status/1573763261056811008,@pressron the net effect is to perpetuate stereotypes about white women.
2778,@GaryMarcus,2022-09-24 19:46:11+00:00,https://twitter.com/GaryMarcus/status/1573760729572052992,@sarahookr it‚Äôs a reference to a line of work by Philip Tetlock: https://t.co/fpOQLD6uZv
2779,@GaryMarcus,2022-09-24 19:33:55+00:00,https://twitter.com/GaryMarcus/status/1573757641587060736,@pressron 5 minutes on Twitter search should be enough to make obvious that it is in fact used to stereotype women.
2780,@GaryMarcus,2022-09-24 19:30:17+00:00,https://twitter.com/GaryMarcus/status/1573756729632104448,"@mettle sexist, racist, and deliberately dehumanizing."
2781,@GaryMarcus,2022-09-24 19:15:12+00:00,https://twitter.com/GaryMarcus/status/1573752930699972608,"@willbeason yep, like many tasteless jokes and racist slurs we have wisely deprecated."
2782,@GaryMarcus,2022-09-24 16:12:14+00:00,https://twitter.com/GaryMarcus/status/1573706885219618816,"Why is the currently-trending word #Karen, used derogatively to stereotype white women, social acceptable, when so many other derogative stereotyping words are‚Äîrightly‚Äîno longer socially acceptable?

The ideal we are aspiring to is *stop* judging people based on race &amp; gender."
2783,@GaryMarcus,2022-09-24 15:04:57+00:00,https://twitter.com/GaryMarcus/status/1573689953095389184,@chantz_y @TheShoeLady33
2784,@GaryMarcus,2022-09-24 15:04:21+00:00,https://twitter.com/GaryMarcus/status/1573689802175967233,@chantz_y And who could forget Mass Delusion 101?
2785,@GaryMarcus,2022-09-24 14:05:56+00:00,https://twitter.com/GaryMarcus/status/1573675100276400129,@ImageSnippets saw that. nauseating
2786,@GaryMarcus,2022-09-24 00:25:28+00:00,https://twitter.com/GaryMarcus/status/1573468624572280832,"fully agree that misinformation is massive problem, particularly for democracy, and believe that a descent into fascism brings many risks, and probably doesn't mix well with AGI."
2787,@GaryMarcus,2022-09-24 00:23:17+00:00,https://twitter.com/GaryMarcus/status/1573468074287960064,"@sergia_ch @emilymbender @timnitGebru My view, since you were kind enough to ask: one should assume good intentions unless there is direct evidence otherwise, and there is at least 3-5% chance that a well-argued entry could change the minds of people economically equipped to do something significant."
2788,@GaryMarcus,2022-09-23 21:10:19+00:00,https://twitter.com/GaryMarcus/status/1573419514368503808,"in almost a decade of *talking* about fairness in AI, a lot of things haven‚Äôt much changed."
2789,@GaryMarcus,2022-09-23 21:08:37+00:00,https://twitter.com/GaryMarcus/status/1573419086381740032,"@chrissyfarr @bing and presumably not just @bing, but likely a general pattern across a wide range of ML engines that are driven entirely by convenience samples of data rather than ethical principles (or even up-to-date data)."
2790,@GaryMarcus,2022-09-23 21:03:15+00:00,https://twitter.com/GaryMarcus/status/1573417735165743104,@emilymbender @timnitGebru i do share your concerns about wealth distribution.
2791,@GaryMarcus,2022-09-23 21:00:04+00:00,https://twitter.com/GaryMarcus/status/1573416933969788928,@emilymbender @timnitGebru by all means you should write about what you want to write about. (but I thought that you believed these guys were misallocating their resources and that that mattered to you.)
2792,@GaryMarcus,2022-09-23 20:55:29+00:00,https://twitter.com/GaryMarcus/status/1573415780200644613,"@TaliaRinger they did the first time, and then it got easier"
2793,@GaryMarcus,2022-09-23 20:53:06+00:00,https://twitter.com/GaryMarcus/status/1573415183103700992,"@emilymbender @timnitGebru again this is directly framed as an opportunity to tell them not to do that.

why not raise your best challenge, and post it as a blog if they don‚Äôt publish it?"
2794,@GaryMarcus,2022-09-23 20:51:26+00:00,https://twitter.com/GaryMarcus/status/1573414763690086400,"@emilymbender @timnitGebru they have asked, and are entitled to ask, for an original piece of work. I may enter; if I do, I will respect that.

they have DIRECTLY solicited challenges to their own assumptions."
2795,@GaryMarcus,2022-09-23 20:31:54+00:00,https://twitter.com/GaryMarcus/status/1573409846145458177,"@timnitGebru @emilymbender i am not seeing that in the rule requirements; why don‚Äôt you enter, in fact? they are (somewhat unusually) welcoming challenges to their own views."
2796,@GaryMarcus,2022-09-23 20:19:16+00:00,https://twitter.com/GaryMarcus/status/1573406664883326976,@Kdawg5000 @ftxfuturefund funnier if they won
2797,@GaryMarcus,2022-09-23 19:52:03+00:00,https://twitter.com/GaryMarcus/status/1573399819074572290,"Terrified by the thought of AGI risk? Or think the whole discussion is misguided? 

Essay contest w serious prizes and a chance to advise the @ftxfuturefund and how to best help the world.

Win-win."
2798,@GaryMarcus,2022-09-23 16:46:12+00:00,https://twitter.com/GaryMarcus/status/1573353045530128387,"@Sara_Imari AI thus far? or AI‚Äôs potential? very hard to dichotomize, either way‚Ä¶"
2799,@GaryMarcus,2022-09-23 15:11:18+00:00,https://twitter.com/GaryMarcus/status/1573329165356797952,Truly a great honor to have @yudapearl speak up for me. ‚ù§Ô∏èüôè
2800,@GaryMarcus,2022-09-23 06:18:26+00:00,https://twitter.com/GaryMarcus/status/1573195064456933381,@miguelisolano @davidchalmers42 @ylecun it‚Äôs also central to my 2020 Next Decade in AI arXiv: https://t.co/rbeWGMenKO
2801,@GaryMarcus,2022-09-23 06:11:22+00:00,https://twitter.com/GaryMarcus/status/1573193286315298817,"@miguelisolano @davidchalmers42 @ylecun this is where i first suggested in 2019 that LLMs had a problem with modeling the world:
(&amp; see @ylecun‚Äôs response, where he said problem had already been solved)"
2802,@GaryMarcus,2022-09-23 03:57:45+00:00,https://twitter.com/GaryMarcus/status/1573159659586072579,"@NaveenGRao 2/2  i am a big fan of both evolution and learning but think they need to be thought about in different ways, and the ML community is often unduly dismissive of genetic contributions."
2803,@GaryMarcus,2022-09-23 03:55:00+00:00,https://twitter.com/GaryMarcus/status/1573158969119772672,"@NaveenGRao for me learning is about changing some internal representation based on data. AFAIK slime mold aren‚Äôt doing that, but I don‚Äôt really know the details, so am cautious.

1/2"
2804,@GaryMarcus,2022-09-23 03:34:23+00:00,https://twitter.com/GaryMarcus/status/1573153778391744512,"@NaveenGRao i think you are committed to ‚Äúyes‚Äù regardless of mechanism, whereas for me the details (on which I am not expert) matter.  but see https://t.co/ZXTKRgSwKW"
2805,@GaryMarcus,2022-09-23 03:29:25+00:00,https://twitter.com/GaryMarcus/status/1573152529751642112,"@NaveenGRao @A_Aspuru_Guzik @HarvardCCB Of course heart adapts to changing constraints, but if you want to understand how you have to understand eg dynamics of gene expression, not back prop or the Hebbian rule or RL or observational learning etc."
2806,@GaryMarcus,2022-09-23 03:26:38+00:00,https://twitter.com/GaryMarcus/status/1573151829332234240,"@NaveenGRao you are committed to saying the slime mold are learning, no? I am the one saying that not all adaptation is (usefully construed as) learning."
2807,@GaryMarcus,2022-09-23 03:25:24+00:00,https://twitter.com/GaryMarcus/status/1573151520560140288,"@NaveenGRao the fjord adapts to the glaciers, no? i don‚Äôt see how you can even pose Hinton and Nowlan‚Äôs question if you think evolution and learning are the same thing."
2808,@GaryMarcus,2022-09-23 03:23:39+00:00,https://twitter.com/GaryMarcus/status/1573151078996381696,"@A_Aspuru_Guzik @NaveenGRao @HarvardCCB eg, Hinton &amp; Nowlan set up the problem the way I do, in a classic paper: https://t.co/SPbc7lPsOH,  ‚ÄúThe evolutionary search space becomes much better if the genotype specifies some of the decisions about where to put connections, but leaves other decisions to learning.‚Äù"
2809,@GaryMarcus,2022-09-23 03:19:55+00:00,https://twitter.com/GaryMarcus/status/1573150139572957185,"@NaveenGRao @A_Aspuru_Guzik @HarvardCCB what does describing the heart as being learned actually buy you, in terms of explanation and prediction?"
2810,@GaryMarcus,2022-09-23 03:19:08+00:00,https://twitter.com/GaryMarcus/status/1573149942230962176,"@NaveenGRao sure, you can if you loosen the definition to ‚Äúchange over time, driven by the environment‚Äù. or you can trivially assume your own conclusion by defining learning as ‚Äúany optimization over time‚Äù."
2811,@GaryMarcus,2022-09-23 03:17:22+00:00,https://twitter.com/GaryMarcus/status/1573149496649093121,"@A_Aspuru_Guzik @NaveenGRao @HarvardCCB using the words learning, adaptation and optimization interchangeably would not make the paper you attached clearer."
2812,@GaryMarcus,2022-09-23 03:16:08+00:00,https://twitter.com/GaryMarcus/status/1573149188770394112,@A_Aspuru_Guzik @NaveenGRao @HarvardCCB learning and developmental biology are different ways of optimizing in an landscape. learning is a *subset* of the ways in which things can be optimized; evolution is a different subset.  sometimes they work together (eg Hinton on the Baldwin effect).
2813,@GaryMarcus,2022-09-23 03:14:13+00:00,https://twitter.com/GaryMarcus/status/1573148706320547840,"@EugeneVinitsky it‚Äôs an irritating joke, because nothing could be farther from the truth. I explain here: https://t.co/YMRYkpxXnt"
2814,@GaryMarcus,2022-09-23 03:07:41+00:00,https://twitter.com/GaryMarcus/status/1573147062233075712,"@NaveenGRao ps i am very well aware of the mechanisms of developmental biology, and wrote a whole book about them in comparison to and cooperation with learning."
2815,@GaryMarcus,2022-09-23 03:06:08+00:00,https://twitter.com/GaryMarcus/status/1573146668450844673,@NaveenGRao and you can describe the structure of fjord is learned. but it is not that helpful.
2816,@GaryMarcus,2022-09-23 02:45:31+00:00,https://twitter.com/GaryMarcus/status/1573141482013589504,@NaveenGRao you could use ‚Äúadaptation‚Äù maybe in that sense. in what useful sense would you say that the structure of the heart is learned? what does that tell you about the mechanisms of biology? or evolution? or how eg those process differ from synaptic tuning or observational learning?
2817,@GaryMarcus,2022-09-23 02:41:34+00:00,https://twitter.com/GaryMarcus/status/1573140488856948737,w links to work and observations from @emilymbender @MelMitchell1 @ylecun @geoffreyhinton @guyvdb and @metaai
2818,@GaryMarcus,2022-09-23 02:30:07+00:00,https://twitter.com/GaryMarcus/status/1573137604786393088,"@NaveenGRao put differently, if you said all biology was the product of learning you wouldn‚Äôt be giving much insight into what biology is or how it works"
2819,@GaryMarcus,2022-09-23 02:29:28+00:00,https://twitter.com/GaryMarcus/status/1573137442676576257,@NaveenGRao not in a useful sense. it‚Äôs not about an agent forming any kind of representation and modifying its neural program.
2820,@GaryMarcus,2022-09-23 02:28:46+00:00,https://twitter.com/GaryMarcus/status/1573137267555966976,"The New Sport of Misrepresenting AI Criticism 

deconstructing 4,200 popular but misleading words by ‚Å¶@erikphoel‚Å©  https://t.co/3v706QILR5"
2821,@GaryMarcus,2022-09-23 01:45:39+00:00,https://twitter.com/GaryMarcus/status/1573126414240718849,"@NaveenGRao yes convolution is a bias (and see my debate with LeCun where i made this point) but‚Ä¶  saying that biology is ‚Äúlearned‚Äù trivializes both genes and evolution, and ignores all that differences between the underlying mechanisms. biology is *partly* learned, and partly not."
2822,@GaryMarcus,2022-09-22 20:51:42+00:00,https://twitter.com/GaryMarcus/status/1573052439082962944,"Excellent piece on the growing movement towards #Neurosymbolic AI ‚Å¶@CACMmag‚Å©, with link to my debate on the topic with Yoshua Bengio. https://t.co/p50c7CPJEJ"
2823,@GaryMarcus,2022-09-22 20:46:44+00:00,https://twitter.com/GaryMarcus/status/1573051191814393856,"@drew95ca @elonmusk reputable publishers have long worried about fact-checking those that they give a platform too, with good reason."
2824,@GaryMarcus,2022-09-22 19:54:07+00:00,https://twitter.com/GaryMarcus/status/1573037948429537281,"@Elbort_MacSoof @elonmusk Seriously? Compare: Johnny killed Janie and should go to jail. Counterpoint: Billie killed Charlie, so Johnny shouldn‚Äôt go to jail."
2825,@GaryMarcus,2022-09-22 19:35:59+00:00,https://twitter.com/GaryMarcus/status/1573033387312689153,"if @elonmusk winds up owning Twitter, what he should really worry about is the spread of misleading tweets, like the one below, from real people with significant followings, even after they have been debunked. [https://t.co/ER9lbSK0ud]

#misinformation doesn‚Äôt just come from bots"
2826,@GaryMarcus,2022-09-22 18:08:05+00:00,https://twitter.com/GaryMarcus/status/1573011265399980032,trunp‚Äôs worst week ever just got worse
2827,@GaryMarcus,2022-09-22 18:03:35+00:00,https://twitter.com/GaryMarcus/status/1573010132522659841,@Abebab stephen jay gould‚Äôs the mismeasure of man is a good starting point: https://t.co/feiDWM155x
2828,@GaryMarcus,2022-09-22 16:52:12+00:00,https://twitter.com/GaryMarcus/status/1572992167416823808,"in modern neural networks, nearly everything is learned; not so in human development; innate reflections of taste, a month before birth."
2829,@GaryMarcus,2022-09-22 16:47:24+00:00,https://twitter.com/GaryMarcus/status/1572990959214022657,"@davidchalmers42 @iris_oved i stand by the claim that waiting for those particular architectures to produce cogent internal world models is waiting on a hopeful monster, rather than resting on a principled understanding of how they work or what they have actually done."
2830,@GaryMarcus,2022-09-22 16:38:13+00:00,https://twitter.com/GaryMarcus/status/1572988648303525889,"@rgblong @davidchalmers42 @iris_oved exactly, humans have (good, suboptimal) models of what comes next in a sentence, but also rich world models that they use for disambiguation, eg per https://t.co/XjS7YfMebu 

having a language model ‚â† being a language model, just as having an axle doesn‚Äôt mean a car is an axle"
2831,@GaryMarcus,2022-09-22 16:30:54+00:00,https://twitter.com/GaryMarcus/status/1572986810342723584,"@davidchalmers42 @iris_oved my view: a language model that incorporated innate information, symbols, knowledge structures etc could certainly build world models, but language models that focus purely on predicting words without prior structure have far failed to construct world models they can reason over"
2832,@GaryMarcus,2022-09-22 16:28:22+00:00,https://twitter.com/GaryMarcus/status/1572986169046204420,"@davidchalmers42 @iris_oved of course it‚Äôs a verbal issue but i am not sure people posting here understand your somewhat different use of the term.

most of current use of the term is really about LLMs that eschew innate structures and only try to predict words as their objective.

1/2"
2833,@GaryMarcus,2022-09-22 16:01:30+00:00,https://twitter.com/GaryMarcus/status/1572979409182928896,"@davidchalmers42 @iris_oved what about a system that has access to other stuff beyond sequences of words, such as innate knowledge (eg about space and time), databases. or multimodal input (eg visual input to accompany language)?

is that an LM+? no longer an LM?"
2834,@GaryMarcus,2022-09-22 15:30:22+00:00,https://twitter.com/GaryMarcus/status/1572971573463912454,"@davidchalmers42 @iris_oved wait, what do you think an LM is? i am confused."
2835,@GaryMarcus,2022-09-22 15:22:34+00:00,https://twitter.com/GaryMarcus/status/1572969613994110977,Jeffrey ‚ÄúSachs‚Äôs [continuing] descent into nonsense‚Äù
2836,@GaryMarcus,2022-09-22 14:11:45+00:00,https://twitter.com/GaryMarcus/status/1572951790223765504,the one thing Putin is still really good at
2837,@GaryMarcus,2022-09-22 13:53:46+00:00,https://twitter.com/GaryMarcus/status/1572947266402656261,@vadimberman @erikphoel
2838,@GaryMarcus,2022-09-22 00:46:00+00:00,https://twitter.com/GaryMarcus/status/1572749016500424707,@davidchalmers42 @ylecun eg
2839,@GaryMarcus,2022-09-22 00:44:04+00:00,https://twitter.com/GaryMarcus/status/1572748530980376577,@davidchalmers42 @ylecun be careful about accepting occasional correlation as evidence. there is a long history of such systems being approximately correct some of the time but not reliable enough eg for turn by turn directions.
2840,@GaryMarcus,2022-09-21 16:47:06+00:00,https://twitter.com/GaryMarcus/status/1572628497767763968,what‚Äôs the Russian word for schadenfreude?
2841,@GaryMarcus,2022-09-21 16:36:37+00:00,https://twitter.com/GaryMarcus/status/1572625859798007808,"@StephenPiment in the quest for AGI/trustworthy AI, it *is* the most important fact."
2842,@GaryMarcus,2022-09-21 16:27:56+00:00,https://twitter.com/GaryMarcus/status/1572623672334229504,"@StephenPiment i have made those two points repeatedly, eg in the intro to rebooting AI and in my Substack series. they are not new."
2843,@GaryMarcus,2022-09-21 15:45:11+00:00,https://twitter.com/GaryMarcus/status/1572612915370545154,"@erikphoel AI is not telling us anything about consciousness, hence doesn‚Äôt bear on whether consciousness and intelligence are orthogonal.

agree LLMs don‚Äôt work like humans, &amp; don‚Äôt insist that AGI must work like us, but an AGI that cannot reliably know things is not what we should seek"
2844,@GaryMarcus,2022-09-21 15:41:37+00:00,https://twitter.com/GaryMarcus/status/1572612017806254082,"Long, hyperbolic thread, attempting to insulate AI from criticism, saying that we should judge AI by different standard. 

Key unanswered question: why should trust AI that is inherently unreliable?

I say we shouldn‚Äôt."
2845,@GaryMarcus,2022-09-21 15:34:58+00:00,https://twitter.com/GaryMarcus/status/1572610344316727296,"@erikphoel This is not a *defense* of AI; it‚Äôs a sign that we are doing it wrong. 

If a system can ‚Äòknow‚Äô something in one context and not another, it cannot be trusted."
2846,@GaryMarcus,2022-09-21 15:27:36+00:00,https://twitter.com/GaryMarcus/status/1572608490283356161,@schulzb589 @erikphoel and bees appear to have very stable models of the world that they can reason and communicate about.
2847,@GaryMarcus,2022-09-21 15:16:31+00:00,https://twitter.com/GaryMarcus/status/1572605701125701633,"@erikphoel your example in #2 is pretty much cherry-picked by definition, and you ignore eg the Winoground data and new task that i hinted at, both described in last two articles at https://t.co/K60mZlpvyV.

this is a selective and misleading presentation."
2848,@GaryMarcus,2022-09-21 15:13:25+00:00,https://twitter.com/GaryMarcus/status/1572604921001938944,@erikphoel wow. ‚Äúwillfully ignored‚Ä¶ alien ‚Ä¶ how scary‚Äù‚Ä¶ when i consistently point to replicable problems and risks that derive from them? wow. and you have engaged in none of the actual issues raised. this is weak and sensationalist sauce
2849,@GaryMarcus,2022-09-21 03:49:10+00:00,https://twitter.com/GaryMarcus/status/1572432723373068289,@tdverstynen @phylogenomics sorry to hear it!
2850,@GaryMarcus,2022-09-21 00:28:24+00:00,https://twitter.com/GaryMarcus/status/1572382201504993281,@DLBarack very much agree w your take: multiple brain areas trafficking in shared content doesn‚Äôt at all entail literal redundancy.
2851,@GaryMarcus,2022-09-20 16:28:26+00:00,https://twitter.com/GaryMarcus/status/1572261412373942272,"@cephalad @davidchalmers42 at the margins yes, but in ordinary daily life people are pretty proficient at such things, except eg when motivated by politics. systematic enough deviations are the kinds of things oliver sacks wrote about."
2852,@GaryMarcus,2022-09-20 16:15:24+00:00,https://twitter.com/GaryMarcus/status/1572258131463512064,"neurosymbolic for the win.

new system raises interesting questions 
- can deep learning alone match this?
- can any system learn the requisite symbol manipulation, without baking it in, a la @ylecun and @Jake_Browning00 @NoemaMag?"
2853,@GaryMarcus,2022-09-20 16:11:59+00:00,https://twitter.com/GaryMarcus/status/1572257273975820294,@tallinzen i waved hands a bit around this in the intro to The Next Decade in AI
2854,@GaryMarcus,2022-09-20 15:39:40+00:00,https://twitter.com/GaryMarcus/status/1572249139790118914,"@davidchalmers42 their inconsistency and persistent inability to maintain coherence, their flaws in physical and psychological reasoning, and their unstoppable tendency towards generating misinformation"
2855,@GaryMarcus,2022-09-20 15:19:01+00:00,https://twitter.com/GaryMarcus/status/1572243942216994817,@peremayol @IntuitMachine taking leave from this conversation. final remark: System I/II is just one of many examples of the vast room for pluralism in biology.
2856,@GaryMarcus,2022-09-20 15:07:52+00:00,https://twitter.com/GaryMarcus/status/1572241137225826304,@IntuitMachine @peremayol pluralism is necessary not sufficient.
2857,@GaryMarcus,2022-09-20 15:02:24+00:00,https://twitter.com/GaryMarcus/status/1572239759417946112,"@IntuitMachine @peremayol not being prescriptive about that, but you have boxed your self into a symbol-free corner and that makes things hard‚Ä¶"
2858,@GaryMarcus,2022-09-20 14:56:47+00:00,https://twitter.com/GaryMarcus/status/1572238349045497857,"@IntuitMachine @peremayol New?! Since 1992. And yes, pluralist for three decades."
2859,@GaryMarcus,2022-09-20 14:47:51+00:00,https://twitter.com/GaryMarcus/status/1572236101066293251,"@IntuitMachine @peremayol sure, but the ton is required for any alternative theory, too. it‚Äôs the burden tennis that i am objecting to.  and the lame biological plausibility arguments."
2860,@GaryMarcus,2022-09-20 14:39:33+00:00,https://twitter.com/GaryMarcus/status/1572234009920557056,"@IntuitMachine @peremayol symbolic computation is the only known way to do a bunch of things humans can do.

your only counterargument is a weak appeal to biological plausibility, without *any* actual theory of how the brain operates.

why is the onus on me?"
2861,@GaryMarcus,2022-09-20 14:22:11+00:00,https://twitter.com/GaryMarcus/status/1572229641368375300,@IntuitMachine @peremayol you are assuming your conclusion
2862,@GaryMarcus,2022-09-20 14:15:13+00:00,https://twitter.com/GaryMarcus/status/1572227886513528832,"@IntuitMachine @peremayol surely trained mathematicians, programmers, logicians (to say nothing of language speakers) use symbols, so wetware can clearly support them."
2863,@GaryMarcus,2022-09-20 14:10:29+00:00,https://twitter.com/GaryMarcus/status/1572226696417542147,"@peremayol @IntuitMachine *that you know of*. we also don‚Äôt know of any short-term memory neurons, but that doesn‚Äôt mean we don‚Äôt have short term memory. neuroscience is in its infancy, and your argument is premature."
2864,@GaryMarcus,2022-09-20 14:00:10+00:00,https://twitter.com/GaryMarcus/status/1572224100466298883,"@JoshBiostats @KashPrime the point here is the main effect, and the fact that it holds throughout, not the specific bins"
2865,@GaryMarcus,2022-09-20 13:53:46+00:00,https://twitter.com/GaryMarcus/status/1572222486980493314,mind-boggling #MustRead
2866,@GaryMarcus,2022-09-20 13:30:34+00:00,https://twitter.com/GaryMarcus/status/1572216650954608641,@IntuitMachine @peremayol i doubt it can systematically get it across perspectives and views relative to an agent‚Äôs viewpoint
2867,@GaryMarcus,2022-09-20 12:56:14+00:00,https://twitter.com/GaryMarcus/status/1572208011942436867,@grbradsk not sure they *are* reifying things
2868,@GaryMarcus,2022-09-20 12:51:27+00:00,https://twitter.com/GaryMarcus/status/1572206806390427648,"@IntuitMachine @SchwabeHenning disagree. semiotics is about meaning, and LLMs are mainly about predicting sequences of words without meaning."
2869,@GaryMarcus,2022-09-19 22:52:46+00:00,https://twitter.com/GaryMarcus/status/1571995743707336704,"üé∏ @SteveVai: ‚ÄúI can play every note that Jimi Hendrix every played ‚Ä¶ exactly the way he played it, but I can‚Äôt imagine how he thought of it in the first place.‚Äù 

DALL-E can imitate van Gogh‚Äôs brushstrokes, but at least for now the personal expression of meaning ain‚Äôt there."
2870,@GaryMarcus,2022-09-19 22:29:43+00:00,https://twitter.com/GaryMarcus/status/1571989945178529793,"Royalty doesn‚Äôt appeal to me, but music has meaning, and this moved me."
2871,@GaryMarcus,2022-09-19 21:32:34+00:00,https://twitter.com/GaryMarcus/status/1571975560490000385,@Dan_Jeffries1 less than they think loads more than current AI
2872,@GaryMarcus,2022-09-19 21:24:05+00:00,https://twitter.com/GaryMarcus/status/1571973428848230400,@madeofmistak3 it‚Äôs the pride in that got to me.
2873,@GaryMarcus,2022-09-19 21:17:56+00:00,https://twitter.com/GaryMarcus/status/1571971880135065600,"Unsubstantiated accusations of moving goal posts by someone who can‚Äôt be bothered to read the article.

üôÑ"
2874,@GaryMarcus,2022-09-19 17:01:05+00:00,https://twitter.com/GaryMarcus/status/1571907242185854976,"@ihorgowda @pickover yep, a classic! we have it in https://t.co/C6XodPcoZW and i used it in https://t.co/8ir1xKenr6 as well."
2875,@GaryMarcus,2022-09-19 04:24:58+00:00,https://twitter.com/GaryMarcus/status/1571716959515082752,"@hardmaru ha! Beatles beat you to it, You stay stop, and I say go go go (or Goo Goog Gio Goo‚Ä¶)

https://t.co/tsOZphbz72"
2876,@GaryMarcus,2022-09-19 04:21:45+00:00,https://twitter.com/GaryMarcus/status/1571716146281459715,"any chance that someone reasonable could slip through as the Republican nominee in ‚Äò24, while these two slug it out?"
2877,@GaryMarcus,2022-09-19 02:13:55+00:00,https://twitter.com/GaryMarcus/status/1571683976687005698,@grbradsk and see my newest https://t.co/8ir1xKenr6 for how impoverished the current representations are; the foothold is weak
2878,@GaryMarcus,2022-09-19 02:13:16+00:00,https://twitter.com/GaryMarcus/status/1571683816154222593,@grbradsk the interesting question is whether you can bridge such more sophisticated world models into something that currently lives purely in image space‚Äîand how.
2879,@GaryMarcus,2022-09-19 00:49:50+00:00,https://twitter.com/GaryMarcus/status/1571662819879448576,@jasonintrator whereof he could not speak he would remain silent
2880,@GaryMarcus,2022-09-19 00:04:19+00:00,https://twitter.com/GaryMarcus/status/1571651361149976576,@MadamePratolung @EnglishOER @TheAtlantic @StephenMarche @mer__edith @nxthompson
2881,@GaryMarcus,2022-09-18 23:16:02+00:00,https://twitter.com/GaryMarcus/status/1571639211127877632,@mikekwarner @FryRsquared guess you didn‚Äôt get too far into the essay before tweeting?
2882,@GaryMarcus,2022-09-18 23:06:37+00:00,https://twitter.com/GaryMarcus/status/1571636842331779072,"@VictorButoi see my new essay for a lot of examples of requests they fail to model correctly 

https://t.co/Xnyh3pTeNo"
2883,@GaryMarcus,2022-09-18 21:53:38+00:00,https://twitter.com/GaryMarcus/status/1571618474254028800,@TonyZador here‚Äôs the nucleus of a relevant benchmark
2884,@GaryMarcus,2022-09-18 21:51:25+00:00,https://twitter.com/GaryMarcus/status/1571617917648932864,"my own answer, which quotes @EMostaque, is now posted here:"
2885,@GaryMarcus,2022-09-18 21:49:37+00:00,https://twitter.com/GaryMarcus/status/1571617465595211776,"Hold on, folks. Are systems like DALL-E and Stable Diffusion really an important step towards general intelligence?

Form, function, and the giant gulf between drawing a picture and understanding the world https://t.co/Xnyh3pTeNo"
2886,@GaryMarcus,2022-09-18 21:06:50+00:00,https://twitter.com/GaryMarcus/status/1571606699622166529,@KatHogan9 i was actually thinking of something less fraught with questions about intentionality but the comparison is fair
2887,@GaryMarcus,2022-09-18 20:19:56+00:00,https://twitter.com/GaryMarcus/status/1571594893860147201,"@TonyZador @EvelinaLeivada and in that sense, yes i think that many animals can to some degree understand the world, as evidenced eg when they use novel tools to solve novel problems"
2888,@GaryMarcus,2022-09-18 20:19:16+00:00,https://twitter.com/GaryMarcus/status/1571594727740567553,@TonyZador @EvelinaLeivada how about ‚Äúform a dynamically updatable representation that an agent can reliably reason with‚Äù
2889,@GaryMarcus,2022-09-18 19:59:50+00:00,https://twitter.com/GaryMarcus/status/1571589836603273217,How much do systems like Dall-E and Stable Diffusion understand about the world that they illustrate?
2890,@GaryMarcus,2022-09-18 17:00:51+00:00,https://twitter.com/GaryMarcus/status/1571544794467536896,@tdietterich @etzioni and four digit multiplication is basically at zero
2891,@GaryMarcus,2022-09-16 02:30:32+00:00,https://twitter.com/GaryMarcus/status/1570600996065378305,@republicofspin @peterbakernyt @sbg1 brilliant closing https://t.co/YdWpyznmvr
2892,@GaryMarcus,2022-09-16 02:21:06+00:00,https://twitter.com/GaryMarcus/status/1570598623297277953,"@pmddomingos most of the people who share my concerns are simply ignored, which is no better. 

that largely extends to many of the concerns you yourself have raised."
2893,@GaryMarcus,2022-09-15 23:42:08+00:00,https://twitter.com/GaryMarcus/status/1570558615488176128,the sequel is even more insane the original.
2894,@GaryMarcus,2022-09-15 21:25:17+00:00,https://twitter.com/GaryMarcus/status/1570524177580593152,thank you to all who made this cry for more serious scientific practice in AI #5 on Hacker News
2895,@GaryMarcus,2022-09-15 21:20:19+00:00,https://twitter.com/GaryMarcus/status/1570522926914633728,@TristanThrush @0x00B1 @mhtessler @GoogleAI @slatestarcodex @MetaAI @ylecun I think this is legit concern and have reached out to some highly placed folks at Meta to try to fix it.
2896,@GaryMarcus,2022-09-15 15:59:32+00:00,https://twitter.com/GaryMarcus/status/1570442198222798849,"@omershapira if you run across more recent #‚Äôs i would certainly be interested, cc @Abebab"
2897,@GaryMarcus,2022-09-15 15:32:23+00:00,https://twitter.com/GaryMarcus/status/1570435366381056001,@omershapira source:
2898,@GaryMarcus,2022-09-15 15:23:21+00:00,https://twitter.com/GaryMarcus/status/1570433094070702080,society‚Äôs machine learning dollars at work
2899,@GaryMarcus,2022-09-15 14:10:22+00:00,https://twitter.com/GaryMarcus/status/1570414725560946691,one reason why I like philosophy better than machine learning is that philosophers respect their critics.
2900,@GaryMarcus,2022-09-15 13:01:37+00:00,https://twitter.com/GaryMarcus/status/1570397426070204418,"@Zergylord it‚Äôs the most important test to do right now and they haven‚Äôt even responded to multiple requests from multiple people.  

but published a whole slew of papers without peer review that imply they have made progress on jokes, compositionality etc that probably isn‚Äôt robust."
2901,@GaryMarcus,2022-09-15 12:58:05+00:00,https://twitter.com/GaryMarcus/status/1570396535040675842,@Zergylord @FelixHill84 i have worked privately on the licensing issue and expect it to be solved imminently; if felix had access to Imagen I can facilitate.
2902,@GaryMarcus,2022-09-15 01:26:00+00:00,https://twitter.com/GaryMarcus/status/1570222368974573568,lawsuit claims Tesla &amp; Musk ‚Äúdeceived and misled consumers regarding the current abilities of its ADAS [advanced driver-assistance system] technology and by representing that it was perpetually on the cusp of perfecting that technology‚Äù https://t.co/Wuz2SK70BR
2903,@GaryMarcus,2022-09-15 00:03:55+00:00,https://twitter.com/GaryMarcus/status/1570201711465361408,"@Zergylord @slatestarcodex any competent peer reviewer would have raise same issues, both for GoogleAI and SSC, especially in light of the readily available alternative w far greater power."
2904,@GaryMarcus,2022-09-14 23:57:33+00:00,https://twitter.com/GaryMarcus/status/1570200110839238656,@Zergylord what is the chance that your California colleagues will confront a carefully-constructed benchmark?
2905,@GaryMarcus,2022-09-14 22:47:45+00:00,https://twitter.com/GaryMarcus/status/1570182541780619264,"@AmandaAskell @ShaneLegg @bengoertzel it would a defeat for the idea, championed by Hinton, that AI needs symbolic systems like electric cars need a carburetor. And for the idea that a single end-to-end multilayer perceptron with enough layers and data would suffice."
2906,@GaryMarcus,2022-09-14 22:40:23+00:00,https://twitter.com/GaryMarcus/status/1570180688569339905,"Why is @GoogleAI ducking an elegant test of language and vision built by researchers at @MetaAI and @HuggingFace?

Could it be that they are ‚Ä¶ chicken? 

#longread on great work by @candacerossio @TristanThrush @douwekiela, &amp; the politics of hype

https://t.co/3HpudowoQG"
2907,@GaryMarcus,2022-09-14 22:29:37+00:00,https://twitter.com/GaryMarcus/status/1570177977937461248,"@KathrynECramer ü§£ 

I always knew fuzzy math was gonna kill us"
2908,@GaryMarcus,2022-09-14 22:29:06+00:00,https://twitter.com/GaryMarcus/status/1570177850300592128,@AmandaAskell @ShaneLegg @bengoertzel ps i continue think that Fodor and Pylyshyn;s eliminative vs implementational connectionism distinction is more useful than distracting.
2909,@GaryMarcus,2022-09-14 22:27:42+00:00,https://twitter.com/GaryMarcus/status/1570177497958068225,"my AI timeline today: ‚Äúan existential [AI] catastrophe is not just possible, but likely.‚Äù

also my AI timeline today: ‚Äúan intelligent system will be quite slothful in its adding‚Äù

a machine that can‚Äôt even add is going turn us all into paperclips? 

ü§∑‚Äç‚ôÇÔ∏è"
2910,@GaryMarcus,2022-09-14 22:24:47+00:00,https://twitter.com/GaryMarcus/status/1570176764374319104,"@AmandaAskell @ShaneLegg @bengoertzel I would want to inspect the internals &amp; see whether they map onto a symbolic system. Same answer as I have given for 30 years. Tbh none of us fully understand what LLMs are doing, so  I am not going to commit to that stipulation. 

Maybe you can pose your question differently?"
2911,@GaryMarcus,2022-09-14 22:13:32+00:00,https://twitter.com/GaryMarcus/status/1570173932443160576,"@AmandaAskell @ShaneLegg @bengoertzel - that‚Äôs not a definition, that‚Äôs a question.  so really can‚Äôt address your question 
- the critical question is: does the system in question map into a symbolic system or does it offer a genuine alternative that does not?"
2912,@GaryMarcus,2022-09-14 22:10:02+00:00,https://twitter.com/GaryMarcus/status/1570173050548785153,@MelMitchell1 cute speculation but i doubt arithmetic will actually roll that way in whatever we all decide to count as AGi
2913,@GaryMarcus,2022-09-14 22:06:43+00:00,https://twitter.com/GaryMarcus/status/1570172217845219330,"@AmandaAskell @ShaneLegg @bengoertzel suppose you use deep learning for perception, output symbols, and run it all through a purely symbolic system like Cyc? haven‚Äôt you just narrowed the scope of intelligence to perception?"
2914,@GaryMarcus,2022-09-14 22:03:39+00:00,https://twitter.com/GaryMarcus/status/1570171446051377154,"@AmandaAskell @ShaneLegg @bengoertzel i have no idea what subsymbolic actually means; care to define? if neural net outputs discrete symbols, is it subsymbolic? what does that mean?"
2915,@GaryMarcus,2022-09-14 21:26:46+00:00,https://twitter.com/GaryMarcus/status/1570162163960147968,@AmandaAskell @ShaneLegg @bengoertzel i don‚Äôt understand this; if it use symbolic tools how it can it not be partly symbolic? the tools that it uses are part of the system as a whole.
2916,@GaryMarcus,2022-09-14 20:55:17+00:00,https://twitter.com/GaryMarcus/status/1570154240101994497,@ethanCaballero what could possibly go wrong?
2917,@GaryMarcus,2022-09-14 20:41:18+00:00,https://twitter.com/GaryMarcus/status/1570150721009651713,@AmandaAskell @ShaneLegg @bengoertzel there‚Äôs certainly room for some arguments like that. and neural systems that relied heavily on symbolic tools like calculators and programming languages would certainly be a victory for neurosymbolic AI :)
2918,@GaryMarcus,2022-09-14 15:42:20+00:00,https://twitter.com/GaryMarcus/status/1570075482846269446,my old neighborhood!
2919,@GaryMarcus,2022-09-14 15:27:44+00:00,https://twitter.com/GaryMarcus/status/1570071807205736448,Coming soon: https://t.co/DkRTfg9imu
2920,@GaryMarcus,2022-09-14 00:13:24+00:00,https://twitter.com/GaryMarcus/status/1569841711224098816,"@AmandaAskell yes, that was a bit quick &amp; dirty, trying to represent a consensus (eg @ShaneLegg &amp; @bengoertzel were comfortable with it) with the ‚Äúbeyond‚Äù as a placeholder,  and the 5 items as a sample.  i don‚Äôt think any serious scholar wants AGI to be as bad as humans are at memory &amp; math."
2921,@GaryMarcus,2022-09-14 00:08:30+00:00,https://twitter.com/GaryMarcus/status/1569840474667778048,@stevenflinn @GadSaad @yudapearl @sapinker my guess: some are some aren‚Äôt.
2922,@GaryMarcus,2022-09-13 22:14:21+00:00,https://twitter.com/GaryMarcus/status/1569811749502861314,"@AmandaAskell As ntoed, these were roughly ordered in increasing difficulty; AGI  shouldn‚Äôt be about merely duplicating humans. We don‚Äôt eg want AGI that does arithmetic as badly as  person. Meanwhile on first two tasks eg w Hollywood films most  humans would succeed but no current AI would."
2923,@GaryMarcus,2022-09-13 18:59:54+00:00,https://twitter.com/GaryMarcus/status/1569762815250165760,link:
2924,@GaryMarcus,2022-09-13 18:59:08+00:00,https://twitter.com/GaryMarcus/status/1569762621561393152,@Pehdrew_ @GadSaad i‚Äôd consider it.
2925,@GaryMarcus,2022-09-13 18:37:17+00:00,https://twitter.com/GaryMarcus/status/1569757121767677953,"Just had a fabulous and super wide-ranging chat w @GadSaad, at the unexpected crossroads of evolutionary psychology and artificial intelligence. 

He will post soon."
2926,@GaryMarcus,2022-09-13 16:43:39+00:00,https://twitter.com/GaryMarcus/status/1569728524671647745,"@Zergylord @GoogleAI @slatestarcodex @TristanThrush ps. i offered SSC a more serious bet and he didn‚Äôt take it. he didn‚Äôt offer me this one and I would have explained why I would not have taken it, per the above."
2927,@GaryMarcus,2022-09-13 16:42:24+00:00,https://twitter.com/GaryMarcus/status/1569728211180986368,"@Zergylord @GoogleAI @slatestarcodex @TristanThrush it‚Äôs a silly bet. Dall-e2 wasn‚Äôt even state of the art on compositionality. It‚Äôs too small a sample, and Winoground is vastly better. This bet proves nothing, especially when you can run N different systems and choose one post hoc gets the best score and you don‚Äôt even need 5/5."
2928,@GaryMarcus,2022-09-13 16:07:12+00:00,https://twitter.com/GaryMarcus/status/1569719351800139777,"@Zergylord @GoogleAI @slatestarcodex @TristanThrush Maybe you ought to read SSC post, before defending? he did try StableDiffusion: 0/5. the results were actually weak, and rely on a post hoc maxima. writing depends on raising me and then switching to a weak bet I didn‚Äôt endorse. not his A game."
2929,@GaryMarcus,2022-09-13 15:38:19+00:00,https://twitter.com/GaryMarcus/status/1569712082920304640,"Scandalous, @ylecun. 

cc @mrgreene1977"
2930,@GaryMarcus,2022-09-13 15:34:58+00:00,https://twitter.com/GaryMarcus/status/1569711242591469568,"Hey @metaai if you are holding out on letting @GoogleAI test Winoground on reasonable licensing terms, your own reputation for doing open AI will be seriously undermined.

cc @ylecun please investigate."
2931,@GaryMarcus,2022-09-13 15:30:52+00:00,https://twitter.com/GaryMarcus/status/1569710210192912384,"@TristanThrush @mhtessler @GoogleAI @slatestarcodex @MetaAI fully agree with @TristanThrush and @mhtessler on that point, cc @ylecun attn Joelle Pineau."
2932,@GaryMarcus,2022-09-13 15:29:39+00:00,https://twitter.com/GaryMarcus/status/1569709904289726468,"Oh my god. That‚Äôs so hard. No wonder Google‚Äôs team of tens of thousands of AI researchers and engineers and support staff was deterred for four months from doing proper science on Imagen. 

üôÑ"
2933,@GaryMarcus,2022-09-13 15:27:45+00:00,https://twitter.com/GaryMarcus/status/1569709424314564608,"@Zergylord @GoogleAI @slatestarcodex @TristanThrush that‚Äôs just lame, when there is a much more systematic test now available and in which their access is not restricted."
2934,@GaryMarcus,2022-09-13 15:27:04+00:00,https://twitter.com/GaryMarcus/status/1569709252654305281,@Zergylord @GoogleAI @slatestarcodex @TristanThrush we did what we could with limited access; i urged Google to use a more systematic task from @TristanThrush et al that was published after. That task was available to both Google and @slatestarcodex. I would urge both of them to use it.
2935,@GaryMarcus,2022-09-13 15:24:53+00:00,https://twitter.com/GaryMarcus/status/1569708703309504513,"Ok, Google; your last excuse for not sharing your work with scientific community just evaporated. Will you stand by your claims, or just share your work with carefully selected friends in the media?"
2936,@GaryMarcus,2022-09-13 15:23:30+00:00,https://twitter.com/GaryMarcus/status/1569708354486038528,"@mukdal @sergeykarayev @goodside @amasad @ylecun - it‚Äôs easy to make a demo, very hard to make things work reliably in practice
- outlier cases usually sink them
- still, it‚Äôs a nice step towards neurosymbolic, with a neural net calling a symbolic system to fill in on something it can‚Äôt itself reliably do."
2937,@GaryMarcus,2022-09-13 14:27:11+00:00,https://twitter.com/GaryMarcus/status/1569694184503902217,"@mhtessler @GoogleAI @slatestarcodex @TristanThrush @MetaAI do you honestly believe this the explanation? I publicly (and also privately) asked Google for an explanation, and got no mention of this (or any other reply)."
2938,@GaryMarcus,2022-09-13 14:10:37+00:00,https://twitter.com/GaryMarcus/status/1569690012689768448,"@Zergylord @GoogleAI @slatestarcodex @TristanThrush ‚Äì very small small sample size
- weak criteria (3/5)
- post hoc selecting system that does the best
- nothing like a Bonferroni correction"
2939,@GaryMarcus,2022-09-13 14:09:09+00:00,https://twitter.com/GaryMarcus/status/1569689646682238976,@mhtessler @GoogleAI @slatestarcodex @TristanThrush @MetaAI also i get a 404 with your specific link
2940,@GaryMarcus,2022-09-13 14:08:44+00:00,https://twitter.com/GaryMarcus/status/1569689542034341893,@mhtessler @GoogleAI @slatestarcodex @TristanThrush @MetaAI oh come on. if they wanted to test it they could arrange something with @TristanThrush (who has offered repeatedly to help) and @ClementDelangue. It‚Äôs publicly available for use.
2941,@GaryMarcus,2022-09-13 03:19:41+00:00,https://twitter.com/GaryMarcus/status/1569526200204414976,"Why is @googleAI too chicken to share Imagen with @huggingface‚Äôs @TristanThrush? 

cc @ClementDelangue"
2942,@GaryMarcus,2022-09-13 01:20:58+00:00,https://twitter.com/GaryMarcus/status/1569496323849867264,"@ProfArbel @GoogleAI they haven‚Äôt so far, despite repeated requests, public and private"
2943,@GaryMarcus,2022-09-13 01:04:42+00:00,https://twitter.com/GaryMarcus/status/1569492231236780032,"shame on you, @googleAI. 

now nearly four months. you gave @slatestarcodex access to do a tiny bit of anecdotal research but continue to duck the repeated requests of professional scientists scientists like @TristanThrush who have created systematic benchmarks."
2944,@GaryMarcus,2022-09-12 21:53:13+00:00,https://twitter.com/GaryMarcus/status/1569444042790027269,@David_Dobbs @philipcball @Grady_Booch
2945,@GaryMarcus,2022-09-11 00:38:40+00:00,https://twitter.com/GaryMarcus/status/1568760905768529923,"@tdietterich @DrMJoyner @DavidEpstein @nxthompson @cragcrest @geoffreyhinton @ACasadevall1 driving might ‚Äúseem‚Äù trivial too‚Ä¶ 

Apple Mail filtering is sometimes great and sometimes way too aggressive. for a while it was screening out my own mother (in my email contacts for a couple decades)."
2946,@GaryMarcus,2022-09-10 20:53:04+00:00,https://twitter.com/GaryMarcus/status/1568704129224310785,@espiers @jbarro @Grady_Booch
2947,@GaryMarcus,2022-09-10 19:00:05+00:00,https://twitter.com/GaryMarcus/status/1568675695492231168,@espiers @jbarro Lex Fridman blocked me. A badge of honor?
2948,@GaryMarcus,2022-09-08 20:31:50+00:00,https://twitter.com/GaryMarcus/status/1567974009454882817,this is a pretty satisfying read.
2949,@GaryMarcus,2022-09-08 15:27:08+00:00,https://twitter.com/GaryMarcus/status/1567897332183891968,‚ù§Ô∏è
2950,@GaryMarcus,2022-09-08 00:33:56+00:00,https://twitter.com/GaryMarcus/status/1567672548602662919,funny how @gdb didn‚Äôt choose this example when tried to troll me ü§£ü§£ü§£
2951,@GaryMarcus,2022-09-07 18:15:07+00:00,https://twitter.com/GaryMarcus/status/1567577218850889729,"very disconcerting - if automatic driving systems fail, even attentive people may be slow to respond"
2952,@GaryMarcus,2022-09-07 18:04:21+00:00,https://twitter.com/GaryMarcus/status/1567574509129199618,"@PaulTopping it‚Äôs a *long* article, still in progress (with associated shorter post, too, presumably)."
2953,@GaryMarcus,2022-09-07 17:08:31+00:00,https://twitter.com/GaryMarcus/status/1567560455119589381,"Want a chatbot to teach you how to sell (and steal) drugs? 

Fantastic and terrifying paper by @anthropicAI that outlines some of the many risks we are likely to face in the near-term as chatbots become pervasive. 

Mandatory reading. https://t.co/uOeFUlppr2"
2954,@GaryMarcus,2022-09-07 15:30:59+00:00,https://twitter.com/GaryMarcus/status/1567535910895636480,@Abebab well-deserved!
2955,@GaryMarcus,2022-09-07 13:50:34+00:00,https://twitter.com/GaryMarcus/status/1567510640025309184,@Abebab premature closure is getting the world into a heap of trouble.
2956,@GaryMarcus,2022-09-07 13:47:32+00:00,https://twitter.com/GaryMarcus/status/1567509878863966209,"Indeed! And a lust for simplicity has also led to overinvestment in big data + deep learning, at expense of considering richer but more difficult to construct hybrid solutions‚Äîand a  world of approximative but deeply unreliable mimicry, easy to construct, impossible to count on."
2957,@GaryMarcus,2022-09-07 02:23:32+00:00,https://twitter.com/GaryMarcus/status/1567337744984317953,@ErnestSDavis https://t.co/9IqhX3ahUA
2958,@GaryMarcus,2022-09-07 01:25:12+00:00,https://twitter.com/GaryMarcus/status/1567323064400216064,"@ErnestSDavis the ramifications are endless. here‚Äôs another, further recognized a few hours later, made incomparably worse if Cannon‚Äôs decision stands"
2959,@GaryMarcus,2022-09-07 01:16:52+00:00,https://twitter.com/GaryMarcus/status/1567320966979813376,"AI-generated list of all 50 states, text to image, by @nostalgebraist, h/t @slatestarcodex https://t.co/RwVq9pjFk0"
2960,@GaryMarcus,2022-09-06 22:13:45+00:00,https://twitter.com/GaryMarcus/status/1567274885319389184,@ErnestSDavis and see
2961,@GaryMarcus,2022-09-06 22:13:01+00:00,https://twitter.com/GaryMarcus/status/1567274701277532160,@ErnestSDavis if it is not overruled no criminal lawyer will ever forget it.
2962,@GaryMarcus,2022-09-06 22:06:19+00:00,https://twitter.com/GaryMarcus/status/1567273011698597888,@ErnestSDavis https://t.co/ADYmfIpSbi
2963,@GaryMarcus,2022-09-06 01:48:35+00:00,https://twitter.com/GaryMarcus/status/1566966560044257283,@robinc it‚Äôs pretty much what the exec told me. i was flabbergasted.
2964,@GaryMarcus,2022-09-05 23:58:41+00:00,https://twitter.com/GaryMarcus/status/1566938905051820032,"@robinc it‚Äôs MINERVA, link elsewhere in this thread."
2965,@GaryMarcus,2022-09-05 22:58:37+00:00,https://twitter.com/GaryMarcus/status/1566923787404464129,"@robinc and ffs the paper was about using LLMs for math, so don‚Äôt blame me. i just reprinted a figure."
2966,@GaryMarcus,2022-09-05 22:57:55+00:00,https://twitter.com/GaryMarcus/status/1566923608710152192,@robinc ditto for using an LLM for natural language understanding (rather than autocompletion)
2967,@GaryMarcus,2022-09-05 22:04:37+00:00,https://twitter.com/GaryMarcus/status/1566910196735442944,"what i was trying to say earlier today, said better"
2968,@GaryMarcus,2022-09-05 22:00:33+00:00,https://twitter.com/GaryMarcus/status/1566909173006503936,"@robinc it‚Äôs clean a test case for the generalizability of the systems; if they can‚Äôt do multiplication, which is perfectly linear and lawful, and have trouble generalizing outside the training space there, it‚Äôs a serious problem.

not my fault if you can‚Äôt see that."
2969,@GaryMarcus,2022-09-05 16:08:55+00:00,https://twitter.com/GaryMarcus/status/1566820683950473216,"without doubt, one of the worst decisions in US legal history, without sound legal reasoning and (by wasting time) endangering the entire nation, in favor of the person who appointed the judge.

even Bill Barr knows this a ‚Äúcrock of shit.‚Äù"
2970,@GaryMarcus,2022-09-05 15:50:50+00:00,https://twitter.com/GaryMarcus/status/1566816130903470082,h/t @ZeeshanAleem
2971,@GaryMarcus,2022-09-05 15:50:11+00:00,https://twitter.com/GaryMarcus/status/1566815968218984455,misinformation rears its ugly head yet again https://t.co/Z4uXJibw1z
2972,@GaryMarcus,2022-09-05 15:27:35+00:00,https://twitter.com/GaryMarcus/status/1566810282445651969,@MadamePratolung @91_pometti and resentment towards those unawed
2973,@GaryMarcus,2022-09-05 15:17:47+00:00,https://twitter.com/GaryMarcus/status/1566807814152273922,@jon_forsyth @91_pometti the latest fuss was over a prize. (few seem to notice that it was in the digital category with a measly 20 entries at a state fair)
2974,@GaryMarcus,2022-09-05 15:05:38+00:00,https://twitter.com/GaryMarcus/status/1566804757293170688,"great thoughts on the art and AI hysteria, by @91_pometti: https://t.co/q6Om56BWLU"
2975,@GaryMarcus,2022-09-05 13:15:43+00:00,https://twitter.com/GaryMarcus/status/1566777097171136513,@srchvrs Minerva: https://t.co/UKUHGjNy7R
2976,@GaryMarcus,2022-09-05 13:14:22+00:00,https://twitter.com/GaryMarcus/status/1566776755444383744,@philljkc compare it to a calculator.
2977,@GaryMarcus,2022-09-05 13:13:59+00:00,https://twitter.com/GaryMarcus/status/1566776659990429696,@Kdawg5000 almost certainly yes
2978,@GaryMarcus,2022-09-04 23:46:54+00:00,https://twitter.com/GaryMarcus/status/1566573549523202048,@MadamePratolung The Emperor‚Äôs New Calculator?
2979,@GaryMarcus,2022-09-04 23:00:31+00:00,https://twitter.com/GaryMarcus/status/1566561879157518336,"chance a certain major corporate exec will allege that large language models have solved the problem of generalization after you call bullshit: 100%

chance that an LLM will be able to correctly multiply two four-digit integers together in a novel multiplication problem: 0% https://t.co/UmXEkQiSS1"
2980,@GaryMarcus,2022-09-04 22:52:52+00:00,https://twitter.com/GaryMarcus/status/1566559952596246528,@Meaningness @ESYudkowsky dm/follow so we can discuss a little privately
2981,@GaryMarcus,2022-09-04 22:37:15+00:00,https://twitter.com/GaryMarcus/status/1566556022332100608,"@Meaningness - i think your second paragraph (a) proves too much (eg legal systems work reasonably well, despite the slippery slopes) and (b) doesn‚Äôt say why we can‚Äôt implement values but only asserts (correctly) that we haven‚Äôt yet

- link to @ESYudkowsky argument on extrapolated volition?"
2982,@GaryMarcus,2022-09-04 03:51:08+00:00,https://twitter.com/GaryMarcus/status/1566272624380231680,"@Todd_S_Woodward @random_walker um, ‚Äúcan easily be manipulated‚Äù sure sounds like blaming the users. maybe you didn‚Äôt quite finish the abstract?"
2983,@GaryMarcus,2022-09-04 02:40:04+00:00,https://twitter.com/GaryMarcus/status/1566254741612826624,irony is dead
2984,@GaryMarcus,2022-09-02 20:52:00+00:00,https://twitter.com/GaryMarcus/status/1565804757729841152,"@EranElhaik @joe_pickrell @ItsNeuronal @random_walker can you articulate what you mean by complex calculations that are difficult to!trace? and more generally, curious your thoughts on some of the challenges here."
2985,@GaryMarcus,2022-09-02 20:42:35+00:00,https://twitter.com/GaryMarcus/status/1565802390175248384,@joe_pickrell @ItsNeuronal @random_walker @EranElhaik
2986,@GaryMarcus,2022-09-02 15:35:37+00:00,https://twitter.com/GaryMarcus/status/1565725139094097921,"@dcbyron @random_walker @RexDouglass that‚Äôs not a very substantive argument; if you have one, spell it out"
2987,@GaryMarcus,2022-09-02 15:04:27+00:00,https://twitter.com/GaryMarcus/status/1565717297398185986,@alexvoica @Kantrowitz ü§£
2988,@GaryMarcus,2022-09-02 14:53:00+00:00,https://twitter.com/GaryMarcus/status/1565714414447525888,"@joe_pickrell @random_walker saying the properties are well-known is not same as saying the tools have been appropriately applied. whole replicability crisis stems in part from the fact that many people have a superficial understanding of statistics, even tho a deeper understanding is in principle possible"
2989,@GaryMarcus,2022-09-02 14:17:23+00:00,https://twitter.com/GaryMarcus/status/1565705450930454528,"@rasbt there‚Äôs plenty of blame to go around.  peer reviewers aren‚Äôt paid, and nowadays a lot of AI research sidesteps peer review. @GoogleAI publishes stuff on arXxic about their systems‚Äô understanding of jokes without any stats at all. &amp; I am the bad guy for pointing out. toxic culture"
2990,@GaryMarcus,2022-09-02 14:06:51+00:00,https://twitter.com/GaryMarcus/status/1565702798981103619,Narcissists sometimes create as many problems for their friends as they do for their enemies.
2991,@GaryMarcus,2022-09-02 14:04:34+00:00,https://twitter.com/GaryMarcus/status/1565702225187700736,@OshriNaparstek There are many comparable problems with the misuse by people of deep learning throughout science; @random_walker can you point to some.
2992,@GaryMarcus,2022-09-02 01:05:21+00:00,https://twitter.com/GaryMarcus/status/1565506130381795328,"I think it is interesting that Elon Musk didn‚Äôt take the bet that @wadhwa and I offered, and that the guy below from @openAI didn‚Äôt want to put up much more than a silly t-shirt."
2993,@GaryMarcus,2022-09-02 01:03:30+00:00,https://twitter.com/GaryMarcus/status/1565505662075142144,"@vasanthsarathy solving a closed-end board game every decade or two is not  getting us to general AI.  AlphaFold is a real contribution, for sure. But I don‚Äôt think you can at all say that AI has (yet) delivered on what its early pioneers had initially expected might happen over 67 years."
2994,@GaryMarcus,2022-09-02 01:00:28+00:00,https://twitter.com/GaryMarcus/status/1565504900490215424,"@tdietterich @mpshanahan has an interesting related paper today, and maybe he might want to comment"
2995,@GaryMarcus,2022-09-02 00:35:14+00:00,https://twitter.com/GaryMarcus/status/1565498549693206528,"Let‚Äôs be real. We still don‚Äôt even have what Terry Winograd was driving at with SHRLDU and Blocks World in 1970 -‚Äì reliable open-ended dialog about the physical world. 

https://t.co/f00orn9VTA

Let alone what Peter Norvig aimed for in his 1986 dissertation: story understanding."
2996,@GaryMarcus,2022-09-01 23:29:53+00:00,https://twitter.com/GaryMarcus/status/1565482102313058304,@AngusTurner9 ü§£
2997,@GaryMarcus,2022-09-01 23:29:09+00:00,https://twitter.com/GaryMarcus/status/1565481921370791936,@EranElhaik
2998,@GaryMarcus,2022-09-01 21:45:32+00:00,https://twitter.com/GaryMarcus/status/1565455845303136256,"more fallout from the reproducabiliy crisis, potentially affecting tens of thousands of studies: Principal Component Analyses (PCA)-based findings in population genetic studies are highly biased and must be reevaluated  https://t.co/mcpF04scRo"
2999,@GaryMarcus,2022-09-01 20:22:19+00:00,https://twitter.com/GaryMarcus/status/1565434900928679937,semi?
3000,@GaryMarcus,2022-09-01 13:25:23+00:00,https://twitter.com/GaryMarcus/status/1565329976161112064,"*immense, and where is that Edit button?"
3001,@GaryMarcus,2022-09-01 13:23:40+00:00,https://twitter.com/GaryMarcus/status/1565329543132753920,"Why haven‚Äôt we reached robust artificial intelligence, 67 years later, despite immerses advances in hardware and data availability?

Serious answers only."
3002,@GaryMarcus,2022-09-01 13:20:24+00:00,https://twitter.com/GaryMarcus/status/1565328722240360449,@jachiam0 isn‚Äôt that what Rebooting AI was?
3003,@GaryMarcus,2022-09-01 04:59:34+00:00,https://twitter.com/GaryMarcus/status/1565202685183541248,"@jachiam0 pretty low stakes given the braggadocio in your words,  no?"
3004,@GaryMarcus,2022-09-01 04:48:18+00:00,https://twitter.com/GaryMarcus/status/1565199848688975872,"@chr1sa surely it is not already here. we have only narrow and quite fallible AI now. 

i offered @elonmusk a related bet with very specific criteria. it doesn‚Äôt have to be vague: https://t.co/MZjzZSqlsk"
3005,@GaryMarcus,2022-09-01 04:41:50+00:00,https://twitter.com/GaryMarcus/status/1565198221642973184,"AGI by September 1, 2032? How much are you willing to put behind your words?"
3006,@GaryMarcus,2022-08-31 15:11:48+00:00,https://twitter.com/GaryMarcus/status/1564994368456765440,"LLMs are an incorrigible mix of misinformation and privacy invasion, yielding an untraceable stew of half-truth. 

great article by @Melissahei @techreview"
3007,@GaryMarcus,2022-08-31 14:22:56+00:00,https://twitter.com/GaryMarcus/status/1564982071507816452,"@MadamePratolung they assume everything is learned from a blank slate.  it the slate is clearly not blank, so (a) eg things like time and space and causality probably don‚Äôt need to be learned and (b) that changed what does need to be learned and how it might be learned"
3008,@GaryMarcus,2022-08-31 14:21:07+00:00,https://twitter.com/GaryMarcus/status/1564981612642590721,fantastic essay by @R3_GSI
3009,@GaryMarcus,2022-08-31 14:16:01+00:00,https://twitter.com/GaryMarcus/status/1564980329466564609,@Sara_Imari nope
3010,@GaryMarcus,2022-08-31 14:11:48+00:00,https://twitter.com/GaryMarcus/status/1564979268450279424,Lordy there are tapes. what a thread.
3011,@GaryMarcus,2022-08-31 14:02:20+00:00,https://twitter.com/GaryMarcus/status/1564976889306816514,@MadamePratolung see this and the tweet of mine that i link
3012,@GaryMarcus,2022-08-30 23:13:40+00:00,https://twitter.com/GaryMarcus/status/1564753246857887745,@Sara_Imari no. but it evolves creatures that discover mathematics
3013,@GaryMarcus,2022-08-29 16:49:36+00:00,https://twitter.com/GaryMarcus/status/1564294205933252610,angling for an insanity plea?
3014,@GaryMarcus,2022-08-28 20:10:39+00:00,https://twitter.com/GaryMarcus/status/1563982413487026176,@Meaningness agree with everything except the ‚Äúit can‚Äôt work‚Äù and ‚Äúnailed in a few years‚Äù.
3015,@GaryMarcus,2022-08-27 17:59:31+00:00,https://twitter.com/GaryMarcus/status/1563587025638686720,@tetraduzione @luislamb @AvilaGarcez no. but there were people - even Hinton - who considered peace then. Hinton  included a related Touretky paper in his ‚Äò91 edited book.
3016,@GaryMarcus,2022-08-26 00:22:02+00:00,https://twitter.com/GaryMarcus/status/1562958513454092293,you get what you don‚Äôt pay for
3017,@GaryMarcus,2022-08-26 00:19:57+00:00,https://twitter.com/GaryMarcus/status/1562957988864102401,@pmddomingos @emilynussbaum ü§£
3018,@GaryMarcus,2022-08-25 22:36:10+00:00,https://twitter.com/GaryMarcus/status/1562931872497561600,"Dear @GoogleAI,

Three months have passed since you claimed Imagen improved performance on compositionality. 

I asked for access and you didn‚Äôt respond.

@TristanThrush offered you his Winoground materials; you didn‚Äôt respond.

Why not?

cc @Chitwan_Saharia @blaiseaguera"
3019,@GaryMarcus,2022-08-25 21:45:49+00:00,https://twitter.com/GaryMarcus/status/1562919200599187462,@pmddomingos @emilynussbaum i did
3020,@GaryMarcus,2022-08-25 16:31:34+00:00,https://twitter.com/GaryMarcus/status/1562840115818696704,"@Meaningness it was superhuman only in some respects; its understanding of language surely was not close to human, and hence a serious broken link in the chain"
3021,@GaryMarcus,2022-08-25 14:04:42+00:00,https://twitter.com/GaryMarcus/status/1562803156874317824,"@a_stadt @didou @JeanRemiKing @spiantado @tallinzen @lakretz @c_caucheteux @ev_fedorenko @mtoneva1 @HassonLab @sleepinyourhat all to the good, i just the systems are inherently stalking the wrong quarry (predicting words rather than building world models), so not optimistic"
3022,@GaryMarcus,2022-08-25 13:56:03+00:00,https://twitter.com/GaryMarcus/status/1562800980781322241,@sharpless89 @IntuitMachine @MJ_StormBorn =&gt; need for government regulation
3023,@GaryMarcus,2022-08-25 13:53:20+00:00,https://twitter.com/GaryMarcus/status/1562800294517698560,@sharpless89 @MJ_StormBorn it is our job to teach them to reason in accordance to values; they don‚Äôt inherently care about anything but eg they handle internet traffic just fine because we have taught them what they need to know.
3024,@GaryMarcus,2022-08-25 13:52:07+00:00,https://twitter.com/GaryMarcus/status/1562799988370989056,@a_stadt @didou @JeanRemiKing @spiantado @tallinzen @lakretz @c_caucheteux @ev_fedorenko @mtoneva1 @HassonLab @sleepinyourhat such as? (hope to read your paper but only read abstract so far)
3025,@GaryMarcus,2022-08-25 13:50:45+00:00,https://twitter.com/GaryMarcus/status/1562799645134581760,"@didou @a_stadt @JeanRemiKing @spiantado @tallinzen @lakretz @c_caucheteux @ev_fedorenko @mtoneva1 @HassonLab @sleepinyourhat we know that much, yes. we don‚Äôt know the details"
3026,@GaryMarcus,2022-08-25 13:48:37+00:00,https://twitter.com/GaryMarcus/status/1562799107592589314,"@a_stadt @didou @JeanRemiKing @spiantado @tallinzen @lakretz @c_caucheteux @ev_fedorenko @mtoneva1 @HassonLab @sleepinyourhat if they worked more like people (eg in mapping syntax into semantics and building stable discourse models) i would agree.

some future AI systems will be very helpful in that regard. these particular ones, not so much."
3027,@GaryMarcus,2022-08-25 13:46:28+00:00,https://twitter.com/GaryMarcus/status/1562798565558480898,@cosmin_scaunasu i quote that  in https://t.co/C6XodPcoZW and love it :)
3028,@GaryMarcus,2022-08-25 13:44:47+00:00,https://twitter.com/GaryMarcus/status/1562798145406644224,"@iPrabhavKaula yes, and world models"
3029,@GaryMarcus,2022-08-25 13:42:39+00:00,https://twitter.com/GaryMarcus/status/1562797607101288449,"not tampering with the models at all might sound tempting, but it is not a good idea. explanation for why not in response to the tweet below"
3030,@GaryMarcus,2022-08-25 13:41:39+00:00,https://twitter.com/GaryMarcus/status/1562797356445503489,"@sharpless89 @MJ_StormBorn no. eg, systems mostly still think Trump is president, because they are poor at updating and reasoning about time. and if we now want eg pictures of doctors to be balanced in gender, to overcome shitty past data, we don‚Äôt have a solid and general way to do that. 

we should"
3031,@GaryMarcus,2022-08-25 13:39:29+00:00,https://twitter.com/GaryMarcus/status/1562796808254128129,"@didou @JeanRemiKing @spiantado @tallinzen @lakretz @c_caucheteux @ev_fedorenko @mtoneva1 @HassonLab @a_stadt it‚Äôs a hard problem for many reasons
- inherently complex system
- lack of animal models
- unethical nature of intervention experiments that would modify input data or brain structures
- current lack of understanding of neuroscience"
3032,@GaryMarcus,2022-08-25 13:36:45+00:00,https://twitter.com/GaryMarcus/status/1562796122326040577,"@JeanRemiKing @didou @spiantado @tallinzen @lakretz @c_caucheteux @ev_fedorenko @mtoneva1 @HassonLab agree these models are similar in some respects but they fundamentally differ in others (eg they do what do without updating stable world models) and as such they tell us more about distributions linguistic data than underlying mechanisms

ngrams show some similarities, too"
3033,@GaryMarcus,2022-08-25 13:33:41+00:00,https://twitter.com/GaryMarcus/status/1562795351563804672,@balazskegl i have some speculations in the book Kluge re where language might diverge from optimal (eg challengers w embedding and interference)
3034,@GaryMarcus,2022-08-25 13:32:24+00:00,https://twitter.com/GaryMarcus/status/1562795029080723457,"@balazskegl it‚Äôs a mediocre solution to supporting a heavy object, akin to a flagpole when a tripod would be better."
3035,@GaryMarcus,2022-08-25 13:31:19+00:00,https://twitter.com/GaryMarcus/status/1562794754353803264,@Ugo_alves exactly!
3036,@GaryMarcus,2022-08-25 13:29:35+00:00,https://twitter.com/GaryMarcus/status/1562794317424771073,@patrickmesana in some sense the problem is a lack of attending to the criticism
3037,@GaryMarcus,2022-08-25 13:27:45+00:00,https://twitter.com/GaryMarcus/status/1562793856927961088,"@sharpless89 1. it is a technical term from the field
2. i am actually saying (if you read my work eg https://t.co/C6XodPcoZW) that current AI should not be anthromorphized and is deeply problematic, 
but 
3. (see my pinned tweet) could be improved with AI that incorporated values"
3038,@GaryMarcus,2022-08-25 13:21:33+00:00,https://twitter.com/GaryMarcus/status/1562792296864952324,@JeanRemiKing @didou @spiantado @tallinzen @lakretz @c_caucheteux @ev_fedorenko @mtoneva1 @HassonLab @a_stadt agree that a lot of the tension stems from differences in goals
3039,@GaryMarcus,2022-08-25 13:19:32+00:00,https://twitter.com/GaryMarcus/status/1562791788737630214,h/t @yoavgo
3040,@GaryMarcus,2022-08-25 13:12:31+00:00,https://twitter.com/GaryMarcus/status/1562790022830772225,"so many of us are saying it because it is true: a tendency towards perpetuating the past is a‚Ä¶bias.  

dredging data with AI that cannot reason reinforces whatever errors society has already made &amp; forsakes an opportunity to look forward.

we should aspire to do better."
3041,@GaryMarcus,2022-08-25 04:04:55+00:00,https://twitter.com/GaryMarcus/status/1562652214124232705,"@janleike @OwainEvans_UK @weidingerlaura @Abebab truthfulQA is just one aspect of alignment (honesty), not harm. but i would certainly take notice if you could solve that aspect."
3042,@GaryMarcus,2022-08-25 02:43:41+00:00,https://twitter.com/GaryMarcus/status/1562631771224932352,"@gualtieropicc ah; i still think you give neuroscience too much credit for inventing the concept, tho"
3043,@GaryMarcus,2022-08-25 02:38:34+00:00,https://twitter.com/GaryMarcus/status/1562630484378746880,"@gualtieropicc good thread but gives short shrift to cognitive psychology, and philosophers such as  Fodor, Dennett, Block, Dretske etc"
3044,@GaryMarcus,2022-08-25 02:29:12+00:00,https://twitter.com/GaryMarcus/status/1562628126810963968,"@spiantado @didou the empirical question is what those techniques i have told us. towards the narrow question Noam is concerned with: why is syntax structured as it is, perhaps not much. more towards what he would call performance. (i am more interested in performance than he is)"
3045,@GaryMarcus,2022-08-25 02:25:00+00:00,https://twitter.com/GaryMarcus/status/1562627069099798528,"@spiantado @didou noam is saying both that LLMs don‚Äôt work like people do and that they don‚Äôt tell us why people work as they do. i think he is correct.

i wouldn‚Äôt rule out sources of evidence in advance of investigation, but everything I have seen suggests LLMs work very differently from people"
3046,@GaryMarcus,2022-08-25 02:22:05+00:00,https://twitter.com/GaryMarcus/status/1562626335012704256,"@janleike should have explicitly included ‚Äúfalse‚Äù (harmful in the disinformation sense). one formal benchmark is @OwainEvans_UK TruthQA; others might be devised wrt to @weidingerlaura et al‚Äôs excellent review of social and ethical problems with LLMs, many of the observations of @Abebab etc"
3047,@GaryMarcus,2022-08-25 02:17:57+00:00,https://twitter.com/GaryMarcus/status/1562625295546712064,@didou @spiantado @JeanRemiKing he may be tied up currently (?) but we are planning on co-writing something (outlining both agreements and disagreements between us).
3048,@GaryMarcus,2022-08-25 01:57:02+00:00,https://twitter.com/GaryMarcus/status/1562620033075130373,@didou @spiantado here:
3049,@GaryMarcus,2022-08-25 01:56:31+00:00,https://twitter.com/GaryMarcus/status/1562619901831184384,@spiantado @didou wait a minute! you just told me you didn‚Äôt say this!
3050,@GaryMarcus,2022-08-25 01:55:31+00:00,https://twitter.com/GaryMarcus/status/1562619650269417472,@vadimberman agreed. i do think Chomsky would attribute a lot of that to ‚Äúexternal‚Äù language but in doing so undermines the positive cases for his theory.
3051,@GaryMarcus,2022-08-25 01:54:07+00:00,https://twitter.com/GaryMarcus/status/1562619298954489856,"@spiantado @didou thought i take a broader view than Noam but relevant kinds of evidence l. it‚Äôs not clear that the Regier papers bears in Chomsky‚Äôs notion of what language is, and neither bears on the utility of LLMs, which were invented after."
3052,@GaryMarcus,2022-08-25 01:19:23+00:00,https://twitter.com/GaryMarcus/status/1562610559560089601,@didou @spiantado not my fault or his that people hear what he didn‚Äôt say
3053,@GaryMarcus,2022-08-25 01:14:32+00:00,https://twitter.com/GaryMarcus/status/1562609335087566848,"@spiantado @didou in the context of a thread about language understanding, you backing down and saying i wasn‚Äôt talking about language understanding‚Ä¶"
3054,@GaryMarcus,2022-08-25 01:11:40+00:00,https://twitter.com/GaryMarcus/status/1562608615445639170,"@didou @spiantado and as for that‚Äôs it, you are dismissing a question that Chomsky had worked on for 60 years AND ignoring that he said they are fine for engineering purposes. smh."
3055,@GaryMarcus,2022-08-25 01:10:40+00:00,https://twitter.com/GaryMarcus/status/1562608363707711491,"@didou @spiantado his current argument, despite what he says, seems to entail it. he is complaining that Chomsky is dismissing of LLMs and that they are our best measure of predictability, which is oft thought to be a component of language. see also work like this: https://t.co/sGinbAPj36"
3056,@GaryMarcus,2022-08-25 01:06:49+00:00,https://twitter.com/GaryMarcus/status/1562607394664099842,"@spiantado @didou but that‚Äôs not a putative source?

already told you my issue: you are refracting through a model that you don‚Äôt understand, as opposed to looking at tractable statistics. also, cites you gave were pre LLM and certainly don‚Äôt show that LLMs tell us anything nature of language"
3057,@GaryMarcus,2022-08-25 00:56:44+00:00,https://twitter.com/GaryMarcus/status/1562604855684136960,@didou in my other ear I have @spiantado trying to convince me that LLMs are a great source of knowledge about how knowledge works ü§∑‚Äç‚ôÇÔ∏è
3058,@GaryMarcus,2022-08-25 00:55:35+00:00,https://twitter.com/GaryMarcus/status/1562604567472521217,"@janleike unless you embrace neurosymbolic AI it‚Äôs not obvious how to do it. i have yet to see a transformer architecture that can reliably either encode ‚Äúdon‚Äôt do harm‚Äù or restrict itself from saying harmful things. 

i don‚Äôt think LLMs traffic in the right sorts of abstraction"
3059,@GaryMarcus,2022-08-25 00:36:07+00:00,https://twitter.com/GaryMarcus/status/1562599670563897350,@IntuitMachine that‚Äôs what it is supposed to do best!
3060,@GaryMarcus,2022-08-25 00:29:34+00:00,https://twitter.com/GaryMarcus/status/1562598020285612032,@janleike how can you expect to *solve* alignment if you rely purely on corpus techniques and can‚Äôt represent explicit human values (eg avoid causing harm to human)?
3061,@GaryMarcus,2022-08-25 00:21:05+00:00,https://twitter.com/GaryMarcus/status/1562595886827712512,@FeiziSoheil @gdb @sama @plinz
3062,@GaryMarcus,2022-08-25 00:17:53+00:00,https://twitter.com/GaryMarcus/status/1562595082351841281,"important thread, and a different perspective on the question of whether deep learning has hit a wall."
3063,@GaryMarcus,2022-08-24 21:18:12+00:00,https://twitter.com/GaryMarcus/status/1562549862830600193,@neilpbrady read the substack essay of mine (CHomsky and GPT-3) where i quote him saying similar stuff
3064,@GaryMarcus,2022-08-24 21:09:58+00:00,https://twitter.com/GaryMarcus/status/1562547791414857728,"Gotta love Twitter; I misunderstood what Musk meant by early beta, and two people clarified in &lt; 5 minutes."
3065,@GaryMarcus,2022-08-24 21:08:35+00:00,https://twitter.com/GaryMarcus/status/1562547443560255488,"i missed some of the background, per @Scobleizer‚Äôs explanation below, and now understand Musk‚Äôs statement on this better."
3066,@GaryMarcus,2022-08-24 21:06:18+00:00,https://twitter.com/GaryMarcus/status/1562546865748725761,@Scobleizer thanks and hello! can you walk me through that? i thought roughly 100K were on current beta? this is a narrowly released sub-beta?
3067,@GaryMarcus,2022-08-24 21:03:55+00:00,https://twitter.com/GaryMarcus/status/1562546268144283648,"is it me or is this internally contradictory? doesn‚Äôt criticism help identify unknown issues? 

(also, what is a wide beta? don‚Äôt 100k users qualify?)"
3068,@GaryMarcus,2022-08-24 20:51:48+00:00,https://twitter.com/GaryMarcus/status/1562543218214174723,"@neilpbrady He happily acknowledged in the discussion that he uses deep learning in the context of engineering for transcription, and differentiated that quite explicitly from the science of explaining human language, where it is indeed unclear what the contribution has been."
3069,@GaryMarcus,2022-08-24 20:36:52+00:00,https://twitter.com/GaryMarcus/status/1562539460109414401,@randalljellis going to try to find out but don‚Äôt know (it was part of a class).
3070,@GaryMarcus,2022-08-24 20:17:47+00:00,https://twitter.com/GaryMarcus/status/1562534657048313857,"Even after all these years, it is thrilling and provocative to listen to Chomsky speak. Even when I think he is wrong, I think he is asking important questions.

I will post a version of this at https://t.co/8ir1xKenr6, along with link to the lecture if there is a recording of it"
3071,@GaryMarcus,2022-08-24 20:17:45+00:00,https://twitter.com/GaryMarcus/status/1562534648487759875,"With respect to linguistic analysis, the problem is that utterances are a mix of what Chomsky calls competence and performance; we can‚Äôt just read off from what people say what the underlying mechanisms are. Inference is hard, which is why linguistics is fundamentally unsolved."
3072,@GaryMarcus,2022-08-24 20:17:45+00:00,https://twitter.com/GaryMarcus/status/1562534647170760706,"With respect to physics, human language is part of biology. As Francis Crick once said to me, ‚ÄúIn physics, we have laws. In biology, we have gadgets.‚Äù 

Some such gadgets are extremely well-adapted, other (eg human spine) aren‚Äôt.  

We can‚Äôt know in advance which one language is."
3073,@GaryMarcus,2022-08-24 20:17:44+00:00,https://twitter.com/GaryMarcus/status/1562534645790801920,"Chomsky‚Äôs argument from physics is Leibniz‚Äôs Miracle Creed (in Chomsky‚Äôs paraphrase ‚ÄúNature just finds the simplest way‚Äù).

Chomsky‚Äôs empirical argument comes from linguistic analysis. 

I am concerned about both."
3074,@GaryMarcus,2022-08-24 20:17:44+00:00,https://twitter.com/GaryMarcus/status/1562534644528336896,"2. In Chomsky‚Äôs view, the human system for language is (or comes close to) the simplest, most elegant system imaginable.  

I seriously doubt this. Part of Chomsky‚Äôs argue for the ‚Äústrong minimalist thesis‚Äù lies in his reading of physics, part of it is empirical."
3075,@GaryMarcus,2022-08-24 20:17:44+00:00,https://twitter.com/GaryMarcus/status/1562534642947100680,"Chomsky‚Äôs key claims were two:

1. What he wants to understand is *why human language is the way that it is*. In his view, large language models have told us nothing about this scientific question (but are fine for engineering, e.g speech transcription).

I fully agree."
3076,@GaryMarcus,2022-08-24 20:17:43+00:00,https://twitter.com/GaryMarcus/status/1562534639545520130,"Just watched Noam Chomsky give a fascinating and up-to-the minute talk on deep learning, science, and the nature of human language.

I loved the first half and find myself deeply skeptical of the second 

A üßµsummarizing what he said, and my own take. https://t.co/NQhMEm3p5i"
3077,@GaryMarcus,2022-08-24 19:43:34+00:00,https://twitter.com/GaryMarcus/status/1562526044787458049,@spiantado obviously it depends on the question.
3078,@GaryMarcus,2022-08-24 19:42:31+00:00,https://twitter.com/GaryMarcus/status/1562525781406158848,@floatingstones i will post a link if it is made publicly available
3079,@GaryMarcus,2022-08-24 19:41:32+00:00,https://twitter.com/GaryMarcus/status/1562525535045296128,"@spiantado that‚Äôs my view, assuming the work (challenging to do) is compelling.  It‚Äôs also what Chomsky implied in his reference to  experimentation.

i am *not* a fan of Chomsky‚Äôs current theory, but rather of his framing re what is important: explaining why language is as it is."
3080,@GaryMarcus,2022-08-24 19:29:59+00:00,https://twitter.com/GaryMarcus/status/1562522629990662145,@spiantado https://t.co/uQrPROyxp3
3081,@GaryMarcus,2022-08-24 19:26:59+00:00,https://twitter.com/GaryMarcus/status/1562521871849254912,"@spiantado corpus analysis is direct; GPT is a clumsy, , expensive, confounded way of doing the same thing. 

i would generally prefer the corpus analysis."
3082,@GaryMarcus,2022-08-24 19:26:07+00:00,https://twitter.com/GaryMarcus/status/1562521656723394561,"this tweet didn‚Äôt age well, inasmuch as 38 minutes later (in discussion period) Chomsky explicitly endorsed the value of experimentation. fun to see a strawperson misrepresentation dissolve in real time ü§£"
3083,@GaryMarcus,2022-08-24 19:24:30+00:00,https://twitter.com/GaryMarcus/status/1562521248160423937,"@spiantado Chomsky just explicitly endorsed (psycholinguistic) experimentation now, contradicting premise of your statement"
3084,@GaryMarcus,2022-08-24 19:19:41+00:00,https://twitter.com/GaryMarcus/status/1562520035465531393,@spiantado i personally embrace the potential use of other tools but think GPT-3 has told us zero about why human language is the way that it is. corpus analysis might.
3085,@GaryMarcus,2022-08-24 18:47:28+00:00,https://twitter.com/GaryMarcus/status/1562511929989808129,@spiantado only to the extent that those can‚Äôt advance his agenda of explaining the nature of why language is the way that it is.
3086,@GaryMarcus,2022-08-24 18:00:20+00:00,https://twitter.com/GaryMarcus/status/1562500066849730562,"@DoronWeber @kevinroose @stevenbjohnson fully agree with the misinformation challenge, and would go further: current tech is very well suited to generating misinformation and very poorly suited towards detecting it. 

we are in for trouble."
3087,@GaryMarcus,2022-08-24 17:49:33+00:00,https://twitter.com/GaryMarcus/status/1562497353516400641,"Noam Chomsky, dissing GPT-4‚Äôs likely future contribution to the understanding of language, right now.  

(with failed AI generated autocaption at bottom) https://t.co/gcR2GznsLX"
3088,@GaryMarcus,2022-08-24 16:52:14+00:00,https://twitter.com/GaryMarcus/status/1562482927136493569,It is. Tell your  congressperson.
3089,@GaryMarcus,2022-08-24 16:48:28+00:00,https://twitter.com/GaryMarcus/status/1562481981274742784,"None of us have a choice. We are all obligated to participated in Tesla‚Äôs FSD beta, like it or not."
3090,@GaryMarcus,2022-08-24 16:04:29+00:00,https://twitter.com/GaryMarcus/status/1562470911243980803,only in Silicon Valley‚Äôs dreams
3091,@GaryMarcus,2022-08-24 13:24:32+00:00,https://twitter.com/GaryMarcus/status/1562430661805236228,@dougblee @EMostaque LLMs are automated epicycles‚Ä¶
3092,@GaryMarcus,2022-08-24 03:21:38+00:00,https://twitter.com/GaryMarcus/status/1562278933898432512,https://t.co/dJ0EIdKufb
3093,@GaryMarcus,2022-08-24 03:20:45+00:00,https://twitter.com/GaryMarcus/status/1562278712086781952,"@TonyZador @ylecun i don‚Äôt see LLMs as being on the correct path to AGI, period, since they don‚Äôt reliably connect to models of the world."
3094,@GaryMarcus,2022-08-24 03:05:38+00:00,https://twitter.com/GaryMarcus/status/1562274910390702080,"@TonyZador @ylecun 1. and all language, not just text?
2. shame in your measure if it can‚Äôt detect all knowledge that has been transmitted verbally"
3095,@GaryMarcus,2022-08-24 03:04:39+00:00,https://twitter.com/GaryMarcus/status/1562274661647400960,@sucholutsky @ylecun ü§£ I am hoping our debates will inspire post docs and grad students to come up with better answers than anyone has come up with so far
3096,@GaryMarcus,2022-08-24 01:48:32+00:00,https://twitter.com/GaryMarcus/status/1562255503727595521,@ylecun that‚Äôs a really weak reply to my careful and detailed reply to your (often misleading) critique of my position
3097,@GaryMarcus,2022-08-24 01:45:42+00:00,https://twitter.com/GaryMarcus/status/1562254793929674752,"@WiringTheBrain since roughly 1990, in fact"
3098,@GaryMarcus,2022-08-24 01:43:39+00:00,https://twitter.com/GaryMarcus/status/1562254278722392069,"@TonyZador @ylecun ‚Äúnot much‚Äù, really? what is your definition of knowledge?"
3099,@GaryMarcus,2022-08-24 01:11:49+00:00,https://twitter.com/GaryMarcus/status/1562246264535793664,"@pmddomingos lots of narrow AI, no AGI"
3100,@GaryMarcus,2022-08-24 01:11:07+00:00,https://twitter.com/GaryMarcus/status/1562246089021194240,"@TonyZador @ylecun here are some words he said in the original post, ‚ÄúHow much of human knowledge is captured in all the text ever written?
To which my answer is: not much‚Äù"
3101,@GaryMarcus,2022-08-24 01:05:04+00:00,https://twitter.com/GaryMarcus/status/1562244568279842817,"wait, isn‚Äôt the point of a beta test to have people notice things that need to be fixing?

or hmm maybe they are just for PR? ü§∑‚Äç‚ôÇÔ∏è"
3102,@GaryMarcus,2022-08-24 01:01:28+00:00,https://twitter.com/GaryMarcus/status/1562243662339223552,@pmddomingos @ylecun @noema the analogy lies in the fast motion of a large entity in a difficult to control direction that isn‚Äôt what we actually need
3103,@GaryMarcus,2022-08-24 00:59:51+00:00,https://twitter.com/GaryMarcus/status/1562243254867075072,"@pmddomingos @ylecun @noema perhaps yes, to the extent that people begin to recognize the negative lessons learned instead of just hoping for more data"
3104,@GaryMarcus,2022-08-24 00:56:20+00:00,https://twitter.com/GaryMarcus/status/1562242368744501249,"@TonyZador @ylecun for sure language is supported by the rest, as I argued in my 2004 The Birth of the Mind, but it it also indispensable to who we are, contra LeCun‚Äôs claim earlier today.

both ingredients are essential to modern humans as we know them"
3105,@GaryMarcus,2022-08-24 00:54:52+00:00,https://twitter.com/GaryMarcus/status/1562242001226960896,"@pmddomingos there is a HUGE swathe of what we wish we could do in AI that we can‚Äôt do yet and won‚Äôt do without common sense, from automatic scientific discovery to reliable chatbots to domestic robots etc. it‚Äôs not some tiny amount left, it‚Äôs virtually all of what some might call AGI."
3106,@GaryMarcus,2022-08-24 00:50:54+00:00,https://twitter.com/GaryMarcus/status/1562241002525855744,"@pmddomingos but, per. Nimoy‚Äôs law, the needs of the many outweigh the needs of the few."
3107,@GaryMarcus,2022-08-24 00:43:38+00:00,https://twitter.com/GaryMarcus/status/1562239173318303744,"to the contrary, mastering common sense will be the key to what enables so much of what remains"
3108,@GaryMarcus,2022-08-24 00:42:00+00:00,https://twitter.com/GaryMarcus/status/1562238761215344640,"@Zergylord if that‚Äôs all you got i rest my case, adding an asterisk ‚Äúoutside of hushed whispers at conferences and in a single tweets by transhumanists with an alias‚Äù"
3109,@GaryMarcus,2022-08-24 00:28:17+00:00,https://twitter.com/GaryMarcus/status/1562235308254515200,"if Trump does wind up in jail, it will be the narcissism that finally does him in"
3110,@GaryMarcus,2022-08-24 00:26:32+00:00,https://twitter.com/GaryMarcus/status/1562234869136076802,@dileeplearning @ylecun https://t.co/kzad1z35vs
3111,@GaryMarcus,2022-08-24 00:26:06+00:00,https://twitter.com/GaryMarcus/status/1562234758842941440,"@nirsd @dileeplearning @ylecun and no blank slate model either, probably"
3112,@GaryMarcus,2022-08-24 00:25:44+00:00,https://twitter.com/GaryMarcus/status/1562234668606701569,@dileeplearning @ylecun but it didn‚Äôt run ok before people communicated with language; don‚Äôt get caught up o  written text. the issue here is the place of linguistic knowledge.
3113,@GaryMarcus,2022-08-24 00:20:40+00:00,https://twitter.com/GaryMarcus/status/1562233394267795457,"@ayazdanb @dileeplearning @ylecun yes, that is quite right. (text need not be written)"
3114,@GaryMarcus,2022-08-24 00:14:19+00:00,https://twitter.com/GaryMarcus/status/1562231793243131904,@LetsFishSmarter some continue even after they are voted out of office
3115,@GaryMarcus,2022-08-24 00:09:44+00:00,https://twitter.com/GaryMarcus/status/1562230643349528576,@dileeplearning @ylecun i think we can learn a lot from how a 5 year old understand the physical and psychological world but I wouldn‚Äôt leave the world in the hands of an AI that had just begun to learn to read
3116,@GaryMarcus,2022-08-23 23:24:47+00:00,https://twitter.com/GaryMarcus/status/1562219330464493569,"@pmddomingos @ylecun @noema or as @pmddomingos once said, on a related point:"
3117,@GaryMarcus,2022-08-23 23:21:16+00:00,https://twitter.com/GaryMarcus/status/1562218445235572737,"@Zergylord quotes? not sure anybody has really argued that in print. 

there is certainly some of that implicit but a lot of talk about we just need to add vision, etc."
3118,@GaryMarcus,2022-08-23 22:41:02+00:00,https://twitter.com/GaryMarcus/status/1562208318843527169,"@pmddomingos they have distracted away from the challenge of connecting language to world models. history won‚Äôt be kind to them.

even @ylecun wasn‚Äôt kind to them, in his new @noema essay, today.

i am really not seeing the fundamental new insight that has emerged from them"
3119,@GaryMarcus,2022-08-23 22:33:34+00:00,https://twitter.com/GaryMarcus/status/1562206440428711936,@pmddomingos more like the train wreck
3120,@GaryMarcus,2022-08-23 22:18:32+00:00,https://twitter.com/GaryMarcus/status/1562202656361177089,@loretoparisi @ylecun @terrible_archer @ErnestSDavis nobody (not even Chomsky or Fodor) is completely nativist about human psychology or language. nor is anybody completely empiricist.
3121,@GaryMarcus,2022-08-23 22:15:13+00:00,https://twitter.com/GaryMarcus/status/1562201823095582724,9 seconds that tell you all you need to know about Mitch McConnell.
3122,@GaryMarcus,2022-08-23 22:13:13+00:00,https://twitter.com/GaryMarcus/status/1562201319737200645,@NickRMorgan there is no doubt that language is built on top of an already rich understanding of the world; there is lots of reason to think that it conveys information that makes that understanding even richer.
3123,@GaryMarcus,2022-08-23 21:48:48+00:00,https://twitter.com/GaryMarcus/status/1562195173945540608,"@csabaveres @ylecun @terrible_archer if you could make that work that might be a real alternative. systems thus far (like GPT etc) that have followed that path are deeply flawed, however."
3124,@GaryMarcus,2022-08-23 21:38:00+00:00,https://twitter.com/GaryMarcus/status/1562192458926022656,"@NickRMorgan she had sight and hearing for 18 months, before she became ill"
3125,@GaryMarcus,2022-08-23 21:36:56+00:00,https://twitter.com/GaryMarcus/status/1562192186568876033,@NickRMorgan for sure
3126,@GaryMarcus,2022-08-23 21:36:41+00:00,https://twitter.com/GaryMarcus/status/1562192126397452288,"@ylecun @terrible_archer @ErnestSDavis Yann, I am the one who told you that the problem with GPT-2 was that it lacked world models; at the time you said I was fighting a rearguard action. 

But the point is that you need to *connect* those world models with language.

No current neural language model does that well."
3127,@GaryMarcus,2022-08-23 21:20:47+00:00,https://twitter.com/GaryMarcus/status/1562188122900705280,"@ylecun @terrible_archer you are arguing for that (common sense from learning about physical world) plus *some* linguistic knowledge, which is inherently symbolic. 

how is that not ultimately a hybrid of some sort?

&amp; how does it differ from what @ErnestSDavis &amp; I argued for in https://t.co/Pt7HZbLIv5?"
3128,@GaryMarcus,2022-08-23 20:26:31+00:00,https://twitter.com/GaryMarcus/status/1562174465466716160,@MadamePratolung already contemplating an essay called Rewriting The History of AI
3129,@GaryMarcus,2022-08-23 20:14:43+00:00,https://twitter.com/GaryMarcus/status/1562171497640181767,@IntuitMachine @ylecun i am not sure either. but it still doesn‚Äôt justify the claim of ‚Äúnot much‚Äù
3130,@GaryMarcus,2022-08-23 19:58:32+00:00,https://twitter.com/GaryMarcus/status/1562167426514440192,@rogerkmoore @ylecun is there any definition of knowledge under which all of the worlds written information would count as ‚Äúnot much‚Äù knowledge?
3131,@GaryMarcus,2022-08-23 19:24:55+00:00,https://twitter.com/GaryMarcus/status/1562158963495317505,"Sharply disagree with @ylecun here. I think the essay itself is weak (https://t.co/pJqOTM5MVm) 

&amp; claim that ‚Äúnot much‚Äù knowledge is captured in text is absurd. Sure, text has to be grounded, but humans would not be where we are in science and technology without written word."
3132,@GaryMarcus,2022-08-23 19:20:26+00:00,https://twitter.com/GaryMarcus/status/1562157835659554818,"Wow ‚Äì  @ylecun &amp; @Jake_Browning00 have again argued for hybrid models, without saying so. (See my recent discussion @Noema).

They are correct that learning purely from linguistic input is doomed to fail.  

But this is essay is flawed, for at least three reasons: ü™°"
3133,@GaryMarcus,2022-08-23 17:27:58+00:00,https://twitter.com/GaryMarcus/status/1562129535935557632,"@EMostaque But wouldn‚Äôt compositionality and accurate representation be useful towards those goals? 

Either way, for those who *are* interested in AGI, it‚Äôs interesting to see how each new system does on these kinds of phenomena."
3134,@GaryMarcus,2022-08-23 17:17:42+00:00,https://twitter.com/GaryMarcus/status/1562126948792340480,"@westis96 would be nice if @GoogleAI would let me try it out. have they run @TomerUllman‚Äôs benchmark? all i saw in the paper was anecdotal, with high-frequency terms."
3135,@GaryMarcus,2022-08-23 16:59:51+00:00,https://twitter.com/GaryMarcus/status/1562122458517295107,@SaudenoBR and that green thing ain‚Äôt even a cube AFAIK
3136,@GaryMarcus,2022-08-23 16:59:32+00:00,https://twitter.com/GaryMarcus/status/1562122376883494912,@SaudenoBR where‚Äôs the hitting and where‚Äôs the replication? full set of results from multiple trials?
3137,@GaryMarcus,2022-08-23 16:46:19+00:00,https://twitter.com/GaryMarcus/status/1562119054365564931,"More evidence that deep learning is, for all the progress, still stuck when it comes to relations and compositionality."
3138,@GaryMarcus,2022-08-23 14:39:11+00:00,https://twitter.com/GaryMarcus/status/1562087059589763073,@bsgallagher @random_walker https://t.co/FaR5zNEEbo
3139,@GaryMarcus,2022-08-23 00:33:02+00:00,https://twitter.com/GaryMarcus/status/1561874115694194688,"@WholeMarsBlog @Christiano92 @Waymo @elonmusk Might one not say the same about Tesla? Billions spent in autonomous driving, nothing like reliable L5."
3140,@GaryMarcus,2022-08-21 16:48:22+00:00,https://twitter.com/GaryMarcus/status/1561394793996881920,@ZeeshanAleem https://t.co/P8nnTA7AOu
3141,@GaryMarcus,2022-08-21 16:21:18+00:00,https://twitter.com/GaryMarcus/status/1561387981193129984,"@mustafasuleymn 1. controlling these systems has proven extremely difficult, because these systems lack representations of the world. 
2. imagining that understanding will magically emerge from more data is a pipe dream. 
many recent essays on both at https://t.co/8ir1xKvqt6"
3142,@GaryMarcus,2022-08-21 16:15:21+00:00,https://twitter.com/GaryMarcus/status/1561386483973443584,@mustafasuleymn @OpenAI @gdb @ilyasut https://t.co/FipntcLVlb
3143,@GaryMarcus,2022-08-21 16:13:28+00:00,https://twitter.com/GaryMarcus/status/1561386010826551298,"*what* exactly is happening? 

the lesson here is not that we are getting closer to AGI; it‚Äôs that we are we are increasingly being fooled by database mimics that talk about things they don‚Äôt know about (&amp; hence frequently confabulate)."
3144,@GaryMarcus,2022-08-20 01:10:09+00:00,https://twitter.com/GaryMarcus/status/1560796294381273089,"true, but not new"
3145,@GaryMarcus,2022-08-20 00:30:49+00:00,https://twitter.com/GaryMarcus/status/1560786397560274945,@andrey_kurenkov but humans are such a low bar; hopefully we can exceed them
3146,@GaryMarcus,2022-08-19 20:30:12+00:00,https://twitter.com/GaryMarcus/status/1560725842602274816,@DLBarack the failure of LLMs to reason reliably about everyday phenomena despite immense data doesn‚Äôt exactly hurt Fodor‚Äôs view‚Ä¶
3147,@GaryMarcus,2022-08-19 20:24:00+00:00,https://twitter.com/GaryMarcus/status/1560724281658523649,"@robinc @Google that‚Äôs really not enough, and i addressed briefly in my essay"
3148,@GaryMarcus,2022-08-19 19:55:53+00:00,https://twitter.com/GaryMarcus/status/1560717204949086208,@robinc @Google not sure i follow your sentence regarding mitigation.
3149,@GaryMarcus,2022-08-19 19:55:19+00:00,https://twitter.com/GaryMarcus/status/1560717064754434049,@Sergei_Imaging i don‚Äôt think the relation is likely to be regular enough to be relied upon
3150,@GaryMarcus,2022-08-19 17:23:01+00:00,https://twitter.com/GaryMarcus/status/1560678737888157696,"@iPrabhavKaula @poolio i am Monday, no?  @bengoertzel"
3151,@GaryMarcus,2022-08-18 21:56:27+00:00,https://twitter.com/GaryMarcus/status/1560385158875795461,@DeepMind @yudapearl
3152,@GaryMarcus,2022-08-18 21:51:12+00:00,https://twitter.com/GaryMarcus/status/1560383839725162496,@tomgoldsteincs @model_mechanic
3153,@GaryMarcus,2022-08-18 21:21:01+00:00,https://twitter.com/GaryMarcus/status/1560376241667985408,"@BAPearlmutter just a simple misunderstanding, that‚Äôs all"
3154,@GaryMarcus,2022-08-18 19:02:38+00:00,https://twitter.com/GaryMarcus/status/1560341419251961856,"hey @elonmusk i am guessing that the demo you promised for September was going to look something like what Google just showed. That one has some serious problems, described below  - betting they will apply to your demo, too."
3155,@GaryMarcus,2022-08-18 18:18:39+00:00,https://twitter.com/GaryMarcus/status/1560330350194151425,"""Building a robot on top of language system that has such little comprehension of the world can‚Äôt be a recipe for success.‚Äù 

Some thoughts on @Google‚Äôs new #robot project

https://t.co/9HPKnCM1rY"
3156,@GaryMarcus,2022-08-18 15:27:19+00:00,https://twitter.com/GaryMarcus/status/1560287230488240129,@grsimari @elonmusk Didja ever notice‚Ä¶
3157,@GaryMarcus,2022-08-18 14:37:48+00:00,https://twitter.com/GaryMarcus/status/1560274772407173120,@thedudefrugal @elonmusk to the tune of https://t.co/fDoJGvaqEm
3158,@GaryMarcus,2022-08-18 14:35:45+00:00,https://twitter.com/GaryMarcus/status/1560274254163193856,"@grbradsk @elonmusk ps he evidently said boring chores, and few chores involving nothing."
3159,@GaryMarcus,2022-08-18 14:34:51+00:00,https://twitter.com/GaryMarcus/status/1560274026257190912,@grbradsk @elonmusk i doubt he will even get Optimus to work as well as a Roomba in the near term.
3160,@GaryMarcus,2022-08-18 14:21:06+00:00,https://twitter.com/GaryMarcus/status/1560270569215369221,link to a slightly more detailed story:
3161,@GaryMarcus,2022-08-18 14:18:53+00:00,https://twitter.com/GaryMarcus/status/1560270009997279233,Should I offer @elonmusk another bet?
3162,@GaryMarcus,2022-08-18 05:07:11+00:00,https://twitter.com/GaryMarcus/status/1560131169584238594,Read this thread. ‚Äúusers must recalibrate their thinking on what Google is and how information is returned to them ‚Ä¶ we must apply the same scrutiny [to searches] we‚Äôve learned to have toward information on social media.‚Äù
3163,@GaryMarcus,2022-08-18 04:16:17+00:00,https://twitter.com/GaryMarcus/status/1560118361098371072,please tell me this is not our only strategy for reaching ethical AI.
3164,@GaryMarcus,2022-08-17 19:16:54+00:00,https://twitter.com/GaryMarcus/status/1559982622134046720,another tesla rear-ending another stopped vehicle
3165,@GaryMarcus,2022-08-16 16:57:56+00:00,https://twitter.com/GaryMarcus/status/1559585260332916736,excellent thread.
3166,@GaryMarcus,2022-08-16 15:01:51+00:00,https://twitter.com/GaryMarcus/status/1559556048473579521,Deep comprehension of the human brain!
3167,@GaryMarcus,2022-08-16 14:57:02+00:00,https://twitter.com/GaryMarcus/status/1559554836206878720,"Cool benchmark! 

cc @yudapearl @eliasbareinboim"
3168,@GaryMarcus,2022-08-15 22:36:55+00:00,https://twitter.com/GaryMarcus/status/1559308181762805761,"@DrMJoyner but too many variables that just can‚Äôt really be predicted, eg what happens to oil if documents link trump even more closely to MBS, in some way nobody has even guessed?"
3169,@GaryMarcus,2022-08-15 22:27:43+00:00,https://twitter.com/GaryMarcus/status/1559305864414040064,"quite possibly not a solvable problem. but certainly there are other unsolved problems (eg commonsense physical and psychological reasoning) that are not amenable to big data that are solvable, with innovation."
3170,@GaryMarcus,2022-08-15 20:33:44+00:00,https://twitter.com/GaryMarcus/status/1559277178893635585,@BrandonLive and see eg for yet another in a parade of examples of out-of-distribution data causing trouble
3171,@GaryMarcus,2022-08-15 20:01:13+00:00,https://twitter.com/GaryMarcus/status/1559268995861164032,"@BrandonLive whatever you think of o‚Äôdowd, this independent study adds to the intuition that i just articulated:"
3172,@GaryMarcus,2022-08-15 19:55:20+00:00,https://twitter.com/GaryMarcus/status/1559267519092776960,"@BrandonLive O‚ÄôDowd and the one i posted yesterday, which itself followed up a similar result from the same YouTuber.

neither is fully persuasive but they do hint that the parameters of recognition are pretty narrow;  i bet some costumes would in fact pose serious problems to current tech."
3173,@GaryMarcus,2022-08-15 19:50:38+00:00,https://twitter.com/GaryMarcus/status/1559266334348681216,"@BrandonLive a thought experiment based on results from results from two separate informal experiments hardly constitutes ‚Äúmisinformation.‚Äù 

referring to such a thought experiment, clearly labeled, as misinformation on the other hand‚Ä¶"
3174,@GaryMarcus,2022-08-15 19:20:05+00:00,https://twitter.com/GaryMarcus/status/1559258645673627649,"Now imagine FSD, distributed to 10 million users, on Halloween on a rainy night."
3175,@GaryMarcus,2022-08-15 17:43:25+00:00,https://twitter.com/GaryMarcus/status/1559234320791138305,Stable genius voluntarily tells world he is perceived as flight risk
3176,@GaryMarcus,2022-08-15 17:19:08+00:00,https://twitter.com/GaryMarcus/status/1559228208603865088,"‚ÄúIt‚Äôs just not working‚Äù ‚Äî Facebook fails to catch blatant election misinformation in Brazil, report finds - MarketWatch https://t.co/bOxdV0QxWy"
3177,@GaryMarcus,2022-08-14 17:55:02+00:00,https://twitter.com/GaryMarcus/status/1558874855834931200,another Youtuber finds some issues with Tesla FSD and children.
3178,@GaryMarcus,2022-08-14 04:05:27+00:00,https://twitter.com/GaryMarcus/status/1558666084911235072,Looking forward to my fireside chat w @bengoertzel!
3179,@GaryMarcus,2022-08-13 21:44:05+00:00,https://twitter.com/GaryMarcus/status/1558570109794340864,"@samuelmcurtis @mark_riedl @jackclarkSF spammers don‚Äôt much care‚Ä¶ if benefit exceeds cost, criminals gonna crime"
3180,@GaryMarcus,2022-08-13 21:23:58+00:00,https://twitter.com/GaryMarcus/status/1558565045335756801,"@girishsastry @jackclarkSF @samuelmcurtis it might. or it might not. to say that they are ‚Äúoverhyped‚Äù is to be (nearly) certain, &amp; i just don‚Äôt understand that source of certainty. i have presented studies that go in the opposite direction &amp; mostly just heard vague speculation about difficulties, and second hand reports"
3181,@GaryMarcus,2022-08-13 20:32:46+00:00,https://twitter.com/GaryMarcus/status/1558552160152866816,@mark_riedl @jackclarkSF @samuelmcurtis @ykilcher i disagree. but don‚Äôt want to share publicly ideas about what a criminal might do‚Ä¶
3182,@GaryMarcus,2022-08-13 20:28:24+00:00,https://twitter.com/GaryMarcus/status/1558551061681487872,@mark_riedl @jackclarkSF @samuelmcurtis @ykilcher kilcher mostly got away with it at large scale for days
3183,@GaryMarcus,2022-08-13 20:24:33+00:00,https://twitter.com/GaryMarcus/status/1558550095791939584,"@jackclarkSF @justinhendrix @samuelmcurtis just posted a few studies above; they aren‚Äôt hard to find. the situation is surely fluid but with LLMs becoming more widespread I would expect their use in misinformation to increase, other things being equal"
3184,@GaryMarcus,2022-08-13 20:23:10+00:00,https://twitter.com/GaryMarcus/status/1558549744812576768,@jackclarkSF @justinhendrix @samuelmcurtis and this https://t.co/ffFQEapIrB
3185,@GaryMarcus,2022-08-13 20:21:56+00:00,https://twitter.com/GaryMarcus/status/1558549435973779458,@jackclarkSF @justinhendrix @samuelmcurtis and this https://t.co/HAScqn1Phd
3186,@GaryMarcus,2022-08-13 20:21:22+00:00,https://twitter.com/GaryMarcus/status/1558549291622248448,"@jackclarkSF @justinhendrix @samuelmcurtis and there is research like this

https://t.co/vfGQRPA1mb"
3187,@GaryMarcus,2022-08-13 19:49:01+00:00,https://twitter.com/GaryMarcus/status/1558541153359708160,@mark_riedl @jackclarkSF @samuelmcurtis also why is this either/or? i am sure it is or soon will be both
3188,@GaryMarcus,2022-08-13 19:48:34+00:00,https://twitter.com/GaryMarcus/status/1558541038272188417,"@mark_riedl @jackclarkSF @samuelmcurtis how do you know this? if i am troll farm why should i tell you my methods? 

both your response and Jack‚Äôs seem extremely speculative. meanwhile @ykilcher‚Äôs lambasted demo shows how easy it is to put this stuff to work."
3189,@GaryMarcus,2022-08-13 19:19:58+00:00,https://twitter.com/GaryMarcus/status/1558533842826248192,"@jackclarkSF @samuelmcurtis i don‚Äôt understand what you are saying. it seems trivial to use, and it‚Äôs not so expensive that people don‚Äôt fool around with it endlessly."
3190,@GaryMarcus,2022-08-13 19:17:25+00:00,https://twitter.com/GaryMarcus/status/1558533197738024960,@jackclarkSF @justinhendrix @samuelmcurtis a web of fake reports around mayim bailey and cbd gummies
3191,@GaryMarcus,2022-08-13 18:47:16+00:00,https://twitter.com/GaryMarcus/status/1558525610372149248,@justinhendrix @jackclarkSF @samuelmcurtis but would we know if they had? i think i know at least one anecdotal example.
3192,@GaryMarcus,2022-08-13 18:46:20+00:00,https://twitter.com/GaryMarcus/status/1558525376942395393,@jackclarkSF on what basis do say this? they are unparalleled in their ability to create plausible sounding misinformation at near zero cost. and have no built-in mechanisms to track reality independent of corpus statistics.
3193,@GaryMarcus,2022-08-13 02:07:51+00:00,https://twitter.com/GaryMarcus/status/1558274100560142336,@rcalo differentiated?
3194,@GaryMarcus,2022-08-13 02:06:54+00:00,https://twitter.com/GaryMarcus/status/1558273862793433089,@Dervine7 @chazfirestone the general knowledge (chapter 4 in The Algebraic Mind) is that types are not the same as tokens.
3195,@GaryMarcus,2022-08-13 01:57:02+00:00,https://twitter.com/GaryMarcus/status/1558271378817630208,@Dervine7 @chazfirestone and the ability to hypothesize they it could actually be two
3196,@GaryMarcus,2022-08-13 00:20:55+00:00,https://twitter.com/GaryMarcus/status/1558247191310995457,@samuelmehr @SBMost nothing to see here. MOOve on.
3197,@GaryMarcus,2022-08-12 22:43:09+00:00,https://twitter.com/GaryMarcus/status/1558222586755964928,@SBMost and the realization that there must be two is called cognition :)
3198,@GaryMarcus,2022-08-12 18:10:12+00:00,https://twitter.com/GaryMarcus/status/1558153896391979008,"@chazfirestone 1. never said there was a sharp line, though surely they differ
2.don‚Äôt know the source of the image, but assume it is supposed to be a system that gives veridical answers, rather than a model of human perception independent of cognition.
3. humans can use common sense somewhere"
3199,@GaryMarcus,2022-08-12 17:59:54+00:00,https://twitter.com/GaryMarcus/status/1558151304261668867,"@chazfirestone well, no, we don‚Äôt, not on reflection."
3200,@GaryMarcus,2022-08-12 17:55:57+00:00,https://twitter.com/GaryMarcus/status/1558150310815621121,@chazfirestone if it gives a length estimate it should be modeling the final output
3201,@GaryMarcus,2022-08-12 17:22:52+00:00,https://twitter.com/GaryMarcus/status/1558141982215532544,"@hb_cell @BarryOSullivan if a type-token distinction is not at the core of your cognition, you can easily wind up here‚Ä¶."
3202,@GaryMarcus,2022-08-12 16:52:57+00:00,https://twitter.com/GaryMarcus/status/1558134456669671424,Prove you are a human  (h/t @BarryOSullivan) https://t.co/LXmwld9sPV
3203,@GaryMarcus,2022-08-12 15:17:31+00:00,https://twitter.com/GaryMarcus/status/1558110437778112512,"@raphaelmilliere @DLBarack @MetaAI impersonal impersonation is the most insincere form of flattery? 

the old Descartes joke (he says ‚ÄúI think not‚Äù and then disappears) is better :)"
3204,@GaryMarcus,2022-08-12 15:02:07+00:00,https://twitter.com/GaryMarcus/status/1558106561935020033,@whatsayadam @ylecun @Jake_Browning00 @DeepMind @AvilaGarcez
3205,@GaryMarcus,2022-08-12 13:29:14+00:00,https://twitter.com/GaryMarcus/status/1558083187737329666,@yudapearl thanks for mentioning the debate!
3206,@GaryMarcus,2022-08-12 13:22:13+00:00,https://twitter.com/GaryMarcus/status/1558081421025083393,@YiMaTweets so well said.
3207,@GaryMarcus,2022-08-12 13:04:04+00:00,https://twitter.com/GaryMarcus/status/1558076856175321089,@yudapearl @ylecun correcting the link: https://t.co/wCOiHq8Kxa
3208,@GaryMarcus,2022-08-12 12:43:26+00:00,https://twitter.com/GaryMarcus/status/1558071662100336642,"@Floridi @alan_winfield sure, please dm or follow back"
3209,@GaryMarcus,2022-08-12 02:15:44+00:00,https://twitter.com/GaryMarcus/status/1557913694788632578,@UlyssesPascal @ylecun @Jake_Browning00 @DeepMind my most detailed discussion of this in chapter 3 of The Algebraic Mind.
3210,@GaryMarcus,2022-08-12 02:14:37+00:00,https://twitter.com/GaryMarcus/status/1557913415997341697,@andrey_kurenkov @ylecun @Jake_Browning00 @DeepMind see my remark on development vs computation; if you accept symbol-manipulation as  part your architecture you open up a wide range of questions that have been off the table.
3211,@GaryMarcus,2022-08-11 22:22:27+00:00,https://twitter.com/GaryMarcus/status/1557854986985283584,@jacyanthis @ylecun @Jake_Browning00 @DeepMind x2 and x1 are generally regarded as awfully similar. LeCun and Browning appear to be accepting both.
3212,@GaryMarcus,2022-08-11 22:13:59+00:00,https://twitter.com/GaryMarcus/status/1557852856765493249,"Next time someone tells you Stratego is a grand challenge in AI, think about this, and where we have and haven‚Äôt made progress in the intervening 16 years."
3213,@GaryMarcus,2022-08-11 22:07:46+00:00,https://twitter.com/GaryMarcus/status/1557851291904225280,"@jacyanthis @ylecun @Jake_Browning00 @DeepMind even if you weren‚Äôt selectively quoting from my article (and eg ignoring the bits about Hinton), I wouldn‚Äôt really understand what you are talking about. you can‚Äôt have X and replace X at same time, can you? and surely you can‚Äôt have X and call it aether at the same time."
3214,@GaryMarcus,2022-08-11 22:05:13+00:00,https://twitter.com/GaryMarcus/status/1557850651329105923,"‚ÄúProgramming a computer to be ethical is much more difficult than programming a computer to play world-champion chess‚Äù - James Moor, 2006"
3215,@GaryMarcus,2022-08-11 21:42:42+00:00,https://twitter.com/GaryMarcus/status/1557844987215093760,@Floridi @alan_winfield @floridi i‚Äôd love to see slides or the ms
3216,@GaryMarcus,2022-08-11 20:56:36+00:00,https://twitter.com/GaryMarcus/status/1557833383111118849,"@danbri @albertzeyer @goodside yes, but it is parasitic on the writings of billions of humans, whereas humans didn‚Äôt have any such crutch."
3217,@GaryMarcus,2022-08-11 20:49:10+00:00,https://twitter.com/GaryMarcus/status/1557831512296284161,@danbri @albertzeyer @goodside a low bar that we still can‚Äôt match üòî
3218,@GaryMarcus,2022-08-11 20:42:04+00:00,https://twitter.com/GaryMarcus/status/1557829727481524225,@Jake_Browning00 @ylecun And my reply: https://t.co/7WD8Xy3HCr
3219,@GaryMarcus,2022-08-11 18:50:40+00:00,https://twitter.com/GaryMarcus/status/1557801689624719360,ditto for AI?
3220,@GaryMarcus,2022-08-11 18:45:38+00:00,https://twitter.com/GaryMarcus/status/1557800423339175936,"@dileeplearning oh for the old days when you posted truth, like this:"
3221,@GaryMarcus,2022-08-11 18:35:09+00:00,https://twitter.com/GaryMarcus/status/1557797788137635840,"@RadioFreeMonad @FelixHill84 @danbri @goodside @nnaisense indeed, that is linked in my reply to LeCun and Browning @NoemaMag"
3222,@GaryMarcus,2022-08-11 18:33:02+00:00,https://twitter.com/GaryMarcus/status/1557797253544259584,@mosesjones i absolutely think we should take the threat seriously; we shouldn‚Äôt take the systems seriously. sorry the quote wasn‚Äôt clearer. but this is how i really feel:
3223,@GaryMarcus,2022-08-11 16:44:08+00:00,https://twitter.com/GaryMarcus/status/1557769850252050433,@PaulTopping @ylecun @Jake_Browning00 https://t.co/lVa6BXzkaS
3224,@GaryMarcus,2022-08-11 16:37:47+00:00,https://twitter.com/GaryMarcus/status/1557768248841703426,"Something big is happening in AI ‚Äî even researchers like @ylecun are acknowledging the need for symbol-manipulation, alongside deep learning.

A reply to LeCun‚Äôs recent essay with ‚Å¶@Jake_Browning00‚Å©, w discussion of recent work ‚Å¶@DeepMind‚Å©. https://t.co/azmrt57ru2"
3225,@GaryMarcus,2022-08-11 15:42:52+00:00,https://twitter.com/GaryMarcus/status/1557754432103669760,"@Jeanc9orf72 @carlzimmer almost any machine can be hacked; the more those machines reveal our thinking or control our behavior, the more we should be worried.

and if manufacturers don‚Äôt make security a top priority, we should be doubly worried."
3226,@GaryMarcus,2022-08-11 15:41:30+00:00,https://twitter.com/GaryMarcus/status/1557754085595435008,@goodside @sir_deenicus @danbri what task is the error rate &lt; 1%?
3227,@GaryMarcus,2022-08-11 14:46:30+00:00,https://twitter.com/GaryMarcus/status/1557740243968700416,@AlisonWants sounds like they might be headed to Mar-a-Lago?
3228,@GaryMarcus,2022-08-11 14:08:15+00:00,https://twitter.com/GaryMarcus/status/1557730620628819968,"@danbri @goodside the hybrid systems that @nnaisense is building, which seem like total vindication for what I have been saying for years."
3229,@GaryMarcus,2022-08-11 13:31:41+00:00,https://twitter.com/GaryMarcus/status/1557721416832757760,@danbri @goodside it‚Äôs gotten more than its share of careful examination; as much as possible i am moving on
3230,@GaryMarcus,2022-08-11 13:27:22+00:00,https://twitter.com/GaryMarcus/status/1557720329010548738,@RobKnight__ of course not.
3231,@GaryMarcus,2022-08-11 13:26:22+00:00,https://twitter.com/GaryMarcus/status/1557720079487209473,@eerac @goodside @danbri none. that‚Äôs my whole point. we need to look beyond current tech.
3232,@GaryMarcus,2022-08-11 13:25:34+00:00,https://twitter.com/GaryMarcus/status/1557719878571679745,@mattburgess1 @WIRED
3233,@GaryMarcus,2022-08-11 13:24:17+00:00,https://twitter.com/GaryMarcus/status/1557719555568332800,"@danbri @goodside i can‚Äôt tell you exactly how many times people have shown me cute GPT stuff and then it turns out not to be robust. probably over 30.

i know GPT is fun to play with, but it‚Äôs not the road to trustworthy intelligence"
3234,@GaryMarcus,2022-08-11 13:21:48+00:00,https://twitter.com/GaryMarcus/status/1557718931200061441,"now imagine the same, but with Neuralink  https://t.co/gkPwrcvkqh"
3235,@GaryMarcus,2022-08-11 13:16:36+00:00,https://twitter.com/GaryMarcus/status/1557717621394382850,@goodside @danbri i have yet to see anything reliable from these systems.
3236,@GaryMarcus,2022-08-11 12:50:50+00:00,https://twitter.com/GaryMarcus/status/1557711134701936641,"@danbri @goodside as always, my first question: is it reliable?"
3237,@GaryMarcus,2022-08-10 14:30:48+00:00,https://twitter.com/GaryMarcus/status/1557373908260573184,"‚ÄúIf you‚Äôre innocent, why are you taking the Fifth Amendment?‚Äù 
- former President Donald Trump

https://t.co/e8oFSWvMZ3"
3238,@GaryMarcus,2022-08-10 14:26:45+00:00,https://twitter.com/GaryMarcus/status/1557372887899578369,turned in final edits on my reply to @ylecun and @Jake_Browning00‚Äôs essay on innateness and symbols-manipulation. should be out soon.
3239,@GaryMarcus,2022-08-10 14:23:04+00:00,https://twitter.com/GaryMarcus/status/1557371959393980416,"@MathieuVVyve @BrandonLive agree that if FSD was not engaged, that is a problem. are there other specific issues?"
3240,@GaryMarcus,2022-08-10 04:23:03+00:00,https://twitter.com/GaryMarcus/status/1557220960247304192,"@BrandonLive this is your fundamental error. no way is this a realistic real world assumption., with respect to many human beings."
3241,@GaryMarcus,2022-08-10 04:03:45+00:00,https://twitter.com/GaryMarcus/status/1557216103226413057,@BrandonLive tesla‚Äôs do have known issues with some stationary objects‚Ä¶
3242,@GaryMarcus,2022-08-10 04:02:48+00:00,https://twitter.com/GaryMarcus/status/1557215864335716352,@BrandonLive other vehicles: not relevant; Tesla is not relieved of responsibility if they kill a child at 25mph if other manufacturers do too. methodology is described.
3243,@GaryMarcus,2022-08-10 04:00:15+00:00,https://twitter.com/GaryMarcus/status/1557215222208745473,@BrandonLive there is plenty of detail here: https://t.co/Yz5DzGfIIv
3244,@GaryMarcus,2022-08-10 03:59:24+00:00,https://twitter.com/GaryMarcus/status/1557215009549144065,@BrandonLive seems to me like a key issue may be that the mannequin was in profile rather than full on? was that true in IIHS test?
3245,@GaryMarcus,2022-08-10 03:56:58+00:00,https://twitter.com/GaryMarcus/status/1557214396832555009,"@BrandonLive well you posted a different link and i don‚Äôt see the detail in this image in the second link. more than that, i doubt any one test would suffice; unless you have a specific methodological concern with this one (aside from ad hominem) it still seems like relevant data"
3246,@GaryMarcus,2022-08-10 03:14:30+00:00,https://twitter.com/GaryMarcus/status/1557203709616160768,@BrandonLive doesn‚Äôt speak to the issue of children
3247,@GaryMarcus,2022-08-10 02:39:45+00:00,https://twitter.com/GaryMarcus/status/1557194963372322816,"@BrandonLive i know i could count on you, @BrandonLive"
3248,@GaryMarcus,2022-08-09 17:43:42+00:00,https://twitter.com/GaryMarcus/status/1557060062933266432,"agreed: we should not build extremely powerful AI systems before we figure out how to make them safe.

the more so if those systems are (as they are now) superficial and unreliable"
3249,@GaryMarcus,2022-08-08 22:30:54+00:00,https://twitter.com/GaryMarcus/status/1556769953310986240,@TonyZador @martingoodson @ylecun @tdietterich @miguelisolano source?
3250,@GaryMarcus,2022-08-08 22:21:15+00:00,https://twitter.com/GaryMarcus/status/1556767524452278272,@TonyZador @martingoodson @ylecun @tdietterich @miguelisolano and strong artificial selection with a known goal would prove less than you might be hoping for
3251,@GaryMarcus,2022-08-08 22:18:56+00:00,https://twitter.com/GaryMarcus/status/1556766941032943616,"@martingoodson @TonyZador @ylecun @tdietterich @miguelisolano there are order 1500 species of starfish, 100 octopus, and 1 species that can talk about both present and future"
3252,@GaryMarcus,2022-08-08 22:16:10+00:00,https://twitter.com/GaryMarcus/status/1556766243251683328,@TonyZador @martingoodson @ylecun @tdietterich @miguelisolano no decisive reason but the fact that we won out is evidential
3253,@GaryMarcus,2022-08-08 22:07:39+00:00,https://twitter.com/GaryMarcus/status/1556764102218813440,"@TonyZador @martingoodson @ylecun @tdietterich @miguelisolano that‚Äôs an odd view, relative to cave paintings and extinction of neanderthals and likely presence then of language"
3254,@GaryMarcus,2022-08-08 22:04:46+00:00,https://twitter.com/GaryMarcus/status/1556763375090253824,"@TonyZador @martingoodson @ylecun @tdietterich @miguelisolano for sure language helped a lot (more like 50kya) but question is why no other species developed anything comparable; my guess multiple rare mutations were required simultaneously, on a background of already rich hominid genome"
3255,@GaryMarcus,2022-08-08 21:56:18+00:00,https://twitter.com/GaryMarcus/status/1556761246124449794,"@TonyZador @martingoodson @ylecun @tdietterich @miguelisolano disagree. if it were really ‚Äúonly a few small steps‚Äù, we would expect human-like intelligence to be more broadly distributed throughout the animal world."
3256,@GaryMarcus,2022-08-08 20:10:02+00:00,https://twitter.com/GaryMarcus/status/1556734499983179776,@grsimari and cognitive models of the world and common sense and the capacity to reason (not to mention visual and auditory experience before her illness at 19 months)
3257,@GaryMarcus,2022-08-08 19:32:37+00:00,https://twitter.com/GaryMarcus/status/1556725083753906176,what on earth does Helen Keller have to do with large language models?
3258,@GaryMarcus,2022-08-02 17:15:13+00:00,https://twitter.com/GaryMarcus/status/1554516178885922816,thanks. i knew the truth would come out eventually‚Ä¶
3259,@GaryMarcus,2022-08-01 16:13:57+00:00,https://twitter.com/GaryMarcus/status/1554138372251213825,"@DorotheaBaur @__TweetinChar__ @ylecun well, Gary does have some issues with the essay, which he will clarify in a couple weeks‚Ä¶"
3260,@GaryMarcus,2022-07-26 21:11:43+00:00,https://twitter.com/GaryMarcus/status/1552038980513775616,@FelixHill84 there were loads of papers like this; you owe me an apology for calling a very fair characterization ‚Äúcomplete fantasy‚Äù https://t.co/9swmGK5tCq
3261,@GaryMarcus,2022-07-26 21:10:53+00:00,https://twitter.com/GaryMarcus/status/1552038770421010434,"he who rewrites the past is doomed to repeat it?

astonished by pushback I am getting in suggesting that end-to-end deep learning has historically been posed in opposition to classic, modular cognitive architectures. 

here‚Äôs typical example from 2016:

https://t.co/mN8xJ0a4Yo https://t.co/ymKpxwirPV"
3262,@GaryMarcus,2022-07-26 17:36:51+00:00,https://twitter.com/GaryMarcus/status/1551984908687396865,@AndrewLampinen @FelixHill84 sure but in the early days of the past tense debate Jay argued for an eliminative model that was end-to-end and lacked such things; glad he eventually changed his position. but many others (as you but not Felix recognize) many others resisted even that for a long time.
3263,@GaryMarcus,2022-07-26 17:34:59+00:00,https://twitter.com/GaryMarcus/status/1551984441416830976,@AndrewLampinen @FelixHill84 the whole point of my original post is there original skepticism may have been misplaced. @felixhill oddly denied that it even existed. ü§∑‚Äç‚ôÇÔ∏è
3264,@GaryMarcus,2022-07-26 17:32:56+00:00,https://twitter.com/GaryMarcus/status/1551983923567005696,"@FelixHill84 even that is nonsense. what i was saying is that theory has developed (in many different ways) in 50 years, many quite relevant, and that Chomsky and linguistics were both being strawpersoned."
3265,@GaryMarcus,2022-07-26 03:36:30+00:00,https://twitter.com/GaryMarcus/status/1551773428591431680,"@FelixHill84 i think almost every word of what you said above is nonsense, but i look forward to the references. 

certainly i did not ‚Äúdisown‚Äù Chomsky; i disagree with him about many things but also agree on many and have emailed with him with very regularly in recent times."
3266,@GaryMarcus,2022-07-26 03:33:42+00:00,https://twitter.com/GaryMarcus/status/1551772723751227394,"@FelixHill84 connectionism has a long history, the first time I heard the term ‚Äúend-to-end deep learning‚Äù was mid 2010s and for years it was definitely pitched as an alternative to modular structures. and a good bit of that history (eg the past tense debate) was certainly anti-modular."
3267,@GaryMarcus,2022-07-25 17:02:59+00:00,https://twitter.com/GaryMarcus/status/1551613998251909120,"@NaveenGRao pletny: years of dismissing old ideas and then starting to use them (generally without any acknowledgment of their intellectual history) is poor form, and we might have made progress sooner if people hadn‚Äôt been so dismissive."
3268,@GaryMarcus,2022-07-25 16:12:28+00:00,https://twitter.com/GaryMarcus/status/1551601287006851073,"End-to-end deep learning started out as an alternative to classic, modular Cognitive Architectures, but is gradually adding bits (like modules and external memory) that more &amp; more seem to recapitulate what researchers in cognition have known all along:"
3269,@GaryMarcus,2022-07-24 18:01:44+00:00,https://twitter.com/GaryMarcus/status/1551266394129412099,@IntuitMachine never known exactly what that encompasses
3270,@GaryMarcus,2022-07-24 18:01:26+00:00,https://twitter.com/GaryMarcus/status/1551266319370108929,"@IntuitMachine i would lean towards salvaging what can be salvaged, without be dogmatic about saving it all."
3271,@GaryMarcus,2022-07-24 17:53:23+00:00,https://twitter.com/GaryMarcus/status/1551264292485210112,"@IntuitMachine no, i lean towards developing innovative hybrids"
3272,@GaryMarcus,2022-07-22 17:14:21+00:00,https://twitter.com/GaryMarcus/status/1550529695497613316,@Meaningness and also because it does a good job of synonymy via embeddings
3273,@GaryMarcus,2022-07-22 17:13:18+00:00,https://twitter.com/GaryMarcus/status/1550529429809401856,"@Meaningness diagrees. don‚Äôt think GPT build any kind of tree, nor any kind mapping between syntax and semantics, whereas I think people read semantics from (imperfectly represented) trees.

GPT gives the illusion otherwise because it pastisches such large fragments of text"
3274,@GaryMarcus,2022-07-22 17:12:01+00:00,https://twitter.com/GaryMarcus/status/1550529106277646336,"@Meaningness i stand by that argument; but i don‚Äôt think it means we don‚Äôt have trees, i think it means we have trouble encoding and retrieving trees. 

people get confused as they track columns in multiplication but (many, not all) people understand multiplication."
3275,@GaryMarcus,2022-07-22 17:09:27+00:00,https://twitter.com/GaryMarcus/status/1550528464364589056,"@Meaningness i find the minimalist program very implausible, and have many other issues with Chomsky‚Äôs view, which I articulated earlier this year (eg I think he underemphasizes w and contributions of cognition), but overall agree with his arguments for generativity, innateness, &amp; universals."
3276,@GaryMarcus,2022-07-22 17:05:20+00:00,https://twitter.com/GaryMarcus/status/1550527425951322112,"@Meaningness i didn‚Äôt take you as making a clear statement on ML, but rather see current ML as a kind of realization of a (fairly naive) memorization approach, hence an (imperfect, to be sure) test of the plausibility of that kind of thing."
3277,@GaryMarcus,2022-07-22 07:11:22+00:00,https://twitter.com/GaryMarcus/status/1550377950453055488,üòÇ
3278,@GaryMarcus,2022-07-21 19:39:00+00:00,https://twitter.com/GaryMarcus/status/1550203709316952064,"@sd_marlow @BrandonLive @AthenaAI2 @Tesla or put differently, could a person take the right actions based on whatever data the vehicle is taking action on.

it‚Äôs not a perfect test, but it is a very good thought experiment."
3279,@GaryMarcus,2022-07-21 17:29:25+00:00,https://twitter.com/GaryMarcus/status/1550171097634521089,"@BrandonLive @sd_marlow @AthenaAI2 @Tesla in maybe 300 comments you have made on threads on my feed, i have seen maybe 2 criticisms of Musk, and 250 statements that defend Tesla. 

i know you are not a bot, but I can see why you might be perceived as one."
3280,@GaryMarcus,2022-07-21 16:09:14+00:00,https://twitter.com/GaryMarcus/status/1550150919878103046,"Can‚Äôt speak directly to @tesla‚Äôs management &amp; agree that hardware limitations are an issue, but Incontinue to think that the real challenge in autonomous driving is too much emphasis on big data and machine learning and too little emphasis on reasoning &amp; world knowledge."
3281,@GaryMarcus,2022-07-20 20:52:18+00:00,https://twitter.com/GaryMarcus/status/1549859767845154816,"Learning Language is Harder Than You Think
Sure, kids imitate their parents, but that‚Äôs just a small part of the story

A new essay, replying to @meaningness

[as ever, Noam Chomsky read it first and thought I was *way* too nice ü§∑‚Äç‚ôÇÔ∏è] https://t.co/sgodzRbdfN"
3282,@GaryMarcus,2022-07-20 00:51:14+00:00,https://twitter.com/GaryMarcus/status/1549557511442665472,"‚ö†Ô∏è Misinformation, which current AI generates but does not reliably detect, is a threat to the 2022 elections. 

Until that changes, AI is likely to be a net negative for democracy. 

https://t.co/9z2WT6VoWS"
3283,@GaryMarcus,2022-07-19 16:29:03+00:00,https://twitter.com/GaryMarcus/status/1549431133334429696,"Fabulous, deeply probing interview on AI, misinformation, and making the world a better place. 

Thank you @sinanaral!"
3284,@GaryMarcus,2022-07-16 16:55:45+00:00,https://twitter.com/GaryMarcus/status/1548350687926374402,"@chrmanning @ZhunLiu3 if only you had signed the receipt. photographed it, and sold the picture as an NFT"
3285,@GaryMarcus,2022-07-14 03:01:44+00:00,https://twitter.com/GaryMarcus/status/1547416023359377408,@lizadixon omg! maybe not ever will this be a good idea. certainly not now. certainly not soon.
3286,@GaryMarcus,2022-07-13 21:37:11+00:00,https://twitter.com/GaryMarcus/status/1547334346842877952,tesla‚Äôs leading AI light is departing.
3287,@GaryMarcus,2022-07-12 21:39:19+00:00,https://twitter.com/GaryMarcus/status/1546972496246849539,@pmddomingos @ylecun @SchmidhuberAI and it is exactly what stymied it prematurely for decades.
3288,@GaryMarcus,2022-07-10 23:24:39+00:00,https://twitter.com/GaryMarcus/status/1546274230865563649,"@vipulved @auren please. sir, document what has been moved, or don‚Äôt say it."
3289,@GaryMarcus,2022-07-08 23:24:54+00:00,https://twitter.com/GaryMarcus/status/1545549517004480512,"in the end after the legal dust settles, Elon will"
3290,@GaryMarcus,2022-07-08 20:38:22+00:00,https://twitter.com/GaryMarcus/status/1545507606982053888,@pmddomingos @SchmidhuberAI how about the end-to-end training and differentiability that is #1 in what Yann is claiming: https://t.co/M1Mq1NUbqN
3291,@GaryMarcus,2022-07-08 20:35:58+00:00,https://twitter.com/GaryMarcus/status/1545507005099433984,@AVMiceliBarone @SchmidhuberAI Not so. eg: https://t.co/rE99nKpPlQ
3292,@GaryMarcus,2022-07-08 17:37:35+00:00,https://twitter.com/GaryMarcus/status/1545462113484677120,". @SchmidhuberAI makes a strong case here; is there a strong counterargument? 

what really is novel about LeCun‚Äôs manifesto relative to the prior literature?"
3293,@GaryMarcus,2022-07-08 01:52:34+00:00,https://twitter.com/GaryMarcus/status/1545224289921671169,@BrandonLive @MadamePratolung no no no. the mislabeling of the product is clearly dangerous and makes the likely (mis)use of the product dangerous.
3294,@GaryMarcus,2022-07-08 01:37:16+00:00,https://twitter.com/GaryMarcus/status/1545220440196612096,@BrandonLive @sd_marlow @AthenaAI2 what you say is true only if you ignore prior history
3295,@GaryMarcus,2022-07-08 01:08:19+00:00,https://twitter.com/GaryMarcus/status/1545213155051089920,@BrandonLive @sd_marlow @AthenaAI2 source?
3296,@GaryMarcus,2022-07-08 01:04:39+00:00,https://twitter.com/GaryMarcus/status/1545212233067556866,"@sd_marlow @BrandonLive @AthenaAI2 driver error is always possible, but there have been many previous accidents spanning back to 2017 or earlier in which Teslas crashed into stopped vehicles, which is something NHTSA is focusing on. And at least two other similar deaths involving going under tractor trailers."
3297,@GaryMarcus,2022-07-07 21:18:30+00:00,https://twitter.com/GaryMarcus/status/1545155319256387584,Two new fatal Tesla crashes are being examined by US investigators - The Verge  https://t.co/psEIMQkx0f
3298,@GaryMarcus,2022-07-07 18:12:20+00:00,https://twitter.com/GaryMarcus/status/1545108469895680001,"@dan_sinykin @MadamePratolung there is also eg truthqa by @OwainEvans_UK and Stephanie Lin

https://t.co/rlzbmQxb9Z"
3299,@GaryMarcus,2022-07-06 23:23:44+00:00,https://twitter.com/GaryMarcus/status/1544824449597181952,"happy 87th birthday to the Dalai Lama 

(photo from 2014) https://t.co/FfSfOlNFDk"
3300,@GaryMarcus,2022-07-05 23:10:46+00:00,https://twitter.com/GaryMarcus/status/1544458798206570496,"@dileeplearning skeptical of tenured, respected profs work ‚â† regarded as clowns"
3301,@GaryMarcus,2022-07-05 22:42:58+00:00,https://twitter.com/GaryMarcus/status/1544451801801375744,"@subjacentish well, yes, their knowledge of‚Äîand respect for‚Äîlanguage remains limited. but their facility and creativity with ML has always been respected.  fair point."
3302,@GaryMarcus,2022-07-05 22:39:08+00:00,https://twitter.com/GaryMarcus/status/1544450836054413314,"this is mythology. 

nobody to my knowledge ever thought any of these people were ‚Äúclowns‚Äù, it‚Äôs just that other techniques were working better and getting more attention. 

hinton got all kinds of prizes and ran a major UK institute."
3303,@GaryMarcus,2022-07-05 22:34:32+00:00,https://twitter.com/GaryMarcus/status/1544449676518207490,@bakztfuture @auren ü§£
3304,@GaryMarcus,2022-07-05 20:47:48+00:00,https://twitter.com/GaryMarcus/status/1544422816723771392,@Abebab just say ‚Äúno‚Äù a lot. but not to me! :)
3305,@GaryMarcus,2022-07-05 14:50:14+00:00,https://twitter.com/GaryMarcus/status/1544332833476317187,@DylanoRepublic ‚ù§Ô∏è
3306,@GaryMarcus,2022-07-05 14:47:17+00:00,https://twitter.com/GaryMarcus/status/1544332091705270274,"@Meaningness @s_r_constantin more like the intersection than the union, in my view. as says on the tin, word 5, it ain‚Äôt cognitive science if it ain‚Äôt interdisciplinary."
3307,@GaryMarcus,2022-07-05 14:45:00+00:00,https://twitter.com/GaryMarcus/status/1544331515458228225,"thanks! that‚Äôs a large reason why my Substack exists -- to bring insights from cognitive science to bear on the hard questions that AI faces. 

(there‚Äôs also a whole chapter in https://t.co/Pt7HZbLIv5 on the same topic.)"
3308,@GaryMarcus,2022-07-05 04:48:17+00:00,https://twitter.com/GaryMarcus/status/1544181347287064577,"‚ÄúFor a successful technology, reality must take precedence over public relations, for nature cannot be fooled."" 
-- Richard Feynman, 1988 report on the Challenger explosion 

https://t.co/4lIavHtlLo"
3309,@GaryMarcus,2022-07-02 19:53:48+00:00,https://twitter.com/GaryMarcus/status/1543322066446782465,"scary video. 

for better or worse, that is the challenge @karpathy seems to have set for himself."
3310,@GaryMarcus,2022-07-02 16:17:00+00:00,https://twitter.com/GaryMarcus/status/1543267505103204353,"üëâ@karpathy celebrates the virtue of bigger data sets ‚Äúwithout substantial architecture modifications or paradigm shifts‚Äù -- but has that strategy solved the outlier problem for @tesla, even with an immense budget?

 ü§∑‚Äç‚ôÇÔ∏è"
3311,@GaryMarcus,2022-07-02 14:43:48+00:00,https://twitter.com/GaryMarcus/status/1543244050534318080,good thread &amp; important cautionary tales on integrating physics with ML by @Sergei_Imaging and @toniobuonassisi
3312,@GaryMarcus,2022-07-02 13:30:50+00:00,https://twitter.com/GaryMarcus/status/1543225686957035521,"@template_rex @wnlckwd @DeepMind which only means they intended to work on it, not that anyone else had it high on their list"
3313,@GaryMarcus,2022-07-02 13:29:43+00:00,https://twitter.com/GaryMarcus/status/1543225409310846977,"Shocked by this this tweet. Since when has science has ever benefited from casting a blind eye to skepticism? 

Lack of peer review in virtually all recent major results, combined with  corporate hype, is a recipe for a crisis of replicability &amp; more confusion about sentience etc"
3314,@GaryMarcus,2022-07-02 13:22:36+00:00,https://twitter.com/GaryMarcus/status/1543223618368204800,@Zergylord sorry - i misread the abstract; it *is* best computer player.  (but not quite best player)
3315,@GaryMarcus,2022-07-02 13:16:57+00:00,https://twitter.com/GaryMarcus/status/1543222195941281793,@fhuszar @srikumarks no that‚Äôs not true. it is really important to have balance in an eta when corporate types so systematically overhype their work and avoid peer review
3316,@GaryMarcus,2022-07-02 13:16:05+00:00,https://twitter.com/GaryMarcus/status/1543221976616931329,"@fhuszar @srikumarks not looking for them, people send me them, tag me, have massive press campaigns etc. hard to miss even when i am not looking."
3317,@GaryMarcus,2022-07-02 03:00:02+00:00,https://twitter.com/GaryMarcus/status/1543066942960852992,@srikumarks of course people should report their results. but they don‚Äôt need to report progress on Stratego as if it were major progress on a widely agreed grand challenge. &amp; we don‚Äôt need to sweat the impact on the labor market every time there is a significant improvement on a benchmark.
3318,@GaryMarcus,2022-07-02 00:37:54+00:00,https://twitter.com/GaryMarcus/status/1543031171646234625,@Zergylord and here‚Äôs how i think about it:
3319,@GaryMarcus,2022-07-02 00:37:42+00:00,https://twitter.com/GaryMarcus/status/1543031121163612160,@khimya and here‚Äôs why:
3320,@GaryMarcus,2022-07-02 00:36:41+00:00,https://twitter.com/GaryMarcus/status/1543030868653981698,"Want to know what would excite me? 

Genuinely new ideas, not just doing better with bigger models.

5/5"
3321,@GaryMarcus,2022-07-02 00:36:41+00:00,https://twitter.com/GaryMarcus/status/1543030867714400256,"50% on challenging high school math problems is measurable progress on a benchmark, but we also know that there has been lots of measurable progress on NLU benchmarks that has not equated to real comprehension or commonsense. 

May turn out to be same in math.

4/5"
3322,@GaryMarcus,2022-07-02 00:36:41+00:00,https://twitter.com/GaryMarcus/status/1543030866888101888,"DeepMind made a pretty good Stratego player, also cool.

But it‚Äôs not world champ, or even the best computer Stratego player of all time. Yet the paper is filled with language about how Stratego has been a ‚Äúgrand challenge‚Äù problem for decades. 

News to me. On whose list?

3/5"
3323,@GaryMarcus,2022-07-02 00:36:41+00:00,https://twitter.com/GaryMarcus/status/1543030865973809153,"Google‚Äôs new math system, neither peer reviewed nor made available to skeptics, got 50% on problems that are challenging to *high school* students (not professionals). 

Great, but should we reall ask about its ‚Äúeconomic impact‚Äù, so soon?

Anyone remember radiology?

2/5"
3324,@GaryMarcus,2022-07-01 23:35:35+00:00,https://twitter.com/GaryMarcus/status/1543015488959045632,@tdietterich @erikbryn @percyliang @ilyasut @fchollet @JeffDean @DigEconLab at 100% accuracy that quote would be true and relevant; at 50% we have a ladder that has not yet made it to the moon.
3325,@GaryMarcus,2022-07-01 23:31:20+00:00,https://twitter.com/GaryMarcus/status/1543014419206062080,"The ‚Äúgrand challenge‚Äù currency in AI seems to be devalued. Nowadays you apparently get grand challenge cred for 

- playing Stratego pretty well

- scoring 50% on a high school math exam"
3326,@GaryMarcus,2022-07-01 22:36:13+00:00,https://twitter.com/GaryMarcus/status/1543000551163473920,"@erikbryn @percyliang @ilyasut @fchollet @JeffDean @DigEconLab what economic work do you think such systems can do with that reliability? how many jobs have been replaced by ‚Äúautonomous vehicles‚Äù that are far more accurate (95%+)? 

(&amp; Google isn‚Äôt allowing scientific community test how general result is)

economic impact of Google Duplex?"
3327,@GaryMarcus,2022-07-01 19:51:15+00:00,https://twitter.com/GaryMarcus/status/1542959035711754240,"‚ÄúAt least 20 reviews in 17 fields have found widespread errors‚Äù in how machine learning is used in science. 

Upcoming workshop on incipient reproducibility crisis. (source for quote inüßµ below). 

&amp; see https://t.co/SqC8rSMn2a for standards @googleAI @openai etc ought follow."
3328,@GaryMarcus,2022-07-01 17:08:55+00:00,https://twitter.com/GaryMarcus/status/1542918184243580929,"@Mike_Page localist models should certainly still be on the table, and i would agree that the argument for ‚Äúneural networks‚Äù being particularly neural or more neural than anything else is still thin."
3329,@GaryMarcus,2022-06-29 18:49:17+00:00,https://twitter.com/GaryMarcus/status/1542218664551653378,"@glupyan immensely facilitatory, perhaps not necessary?"
3330,@GaryMarcus,2022-06-29 01:32:22+00:00,https://twitter.com/GaryMarcus/status/1541957714732929024,@anecdotal @gwern @hardmaru @EthanJPerez @MelMitchell1 @gwern seems to have responded to me but locked me out from seeing the post.
3331,@GaryMarcus,2022-06-29 00:09:01+00:00,https://twitter.com/GaryMarcus/status/1541936739547131904,"@rasbt @hardmaru @EthanJPerez @MelMitchell1 important point; the rules seem to encompass both: ‚ÄúScaling laws [5][6] show that language models get predictably better (in terms of test loss and downstream performance [7]) as the number of parameters, amount of compute used, and dataset size increase.‚Äù"
3332,@GaryMarcus,2022-06-28 23:41:32+00:00,https://twitter.com/GaryMarcus/status/1541929824855330816,"@Mike_Page @ch402 parse the thing you just said, perhaps."
3333,@GaryMarcus,2022-06-28 23:11:15+00:00,https://twitter.com/GaryMarcus/status/1541922203779747840,"@Mike_Page @ch402 Variable binding is essential; we do a lot of it, albeit perhaps imperfectly. Dynamic binding through temporal oscillation is limited and not really up to the task."
3334,@GaryMarcus,2022-06-28 22:40:04+00:00,https://twitter.com/GaryMarcus/status/1541914353967849473,"@Mike_Page i think the issue in that system was keeping enough phases distinct.

this is an interesting new paper on sparsity and interpretability, by @ch402 and co: https://t.co/qrs7JP7HiI"
3335,@GaryMarcus,2022-06-28 22:07:55+00:00,https://twitter.com/GaryMarcus/status/1541906267194568704,@Mike_Page not daft; more like important and hard!
3336,@GaryMarcus,2022-06-28 20:53:51+00:00,https://twitter.com/GaryMarcus/status/1541887624217915393,@bradpwyble what are you thinking of in terms of different ‚Äúkinds‚Äù
3337,@GaryMarcus,2022-06-28 20:46:26+00:00,https://twitter.com/GaryMarcus/status/1541885761124913152,"For my talk tomorrow, opening the workshop on The Challenge of Compositionality for AI, what do you most want to know about compositionality?

https://t.co/mQdOoG0P1A"
3338,@GaryMarcus,2022-06-28 20:35:47+00:00,https://twitter.com/GaryMarcus/status/1541883079492415489,@MarielzaTalks @ylecun @ErnestSDavis @techreview we had a debate (easily found on YouTube) in 2017; I would be happy to reprise if he would.
3339,@GaryMarcus,2022-06-28 17:50:12+00:00,https://twitter.com/GaryMarcus/status/1541841407878389760,May this not turn out to be the epitaph of the United States of America.
3340,@GaryMarcus,2022-06-28 17:45:18+00:00,https://twitter.com/GaryMarcus/status/1541840175738720257,"if ultimate narcissist TFG isn‚Äôt charged, the US may as well disband"
3341,@GaryMarcus,2022-06-28 13:39:36+00:00,https://twitter.com/GaryMarcus/status/1541778343728599042,@sd_marlow @nickyclayton22 sure. but that‚Äôs why @nickyclayton22‚Äôs lab is one of the best -- careful and clever studies that stand the test of time.
3342,@GaryMarcus,2022-06-28 04:28:51+00:00,https://twitter.com/GaryMarcus/status/1541639742613225472,temped to use this in my upcoming talk on compositionality
3343,@GaryMarcus,2022-06-28 03:59:43+00:00,https://twitter.com/GaryMarcus/status/1541632411733196800,"@hardmaru @EthanJPerez @MelMitchell1 it‚Äôs natural to think that certain things won‚Äôt scale, but aside from stereotyping and the like, why should things anti-scale? 

bigger data might be costly and ecologically expensive and not always super productive, but why should it have negative effect on accuracy?"
3344,@GaryMarcus,2022-06-27 21:07:13+00:00,https://twitter.com/GaryMarcus/status/1541528601882816512,"@ylecun @ErnestSDavis @techreview thanks, Yann, I look forward to reading!"
3345,@GaryMarcus,2022-06-27 14:33:31+00:00,https://twitter.com/GaryMarcus/status/1541429523580825601,"Corvids are amazing!

UK science funding: not to so much 

One of the world‚Äôs leading animal researchers, @nickyclayton22, is about to lose funding.

UK, don‚Äôt let this happen. 

Spending zillions on artificial intelligence &amp; starving A-list work on natural intelligence is insane https://t.co/2Eze1O9tvg"
3346,@GaryMarcus,2022-06-26 14:30:09+00:00,https://twitter.com/GaryMarcus/status/1541066287534682113,"Disagree with this well-written üßµ. 

Rate-limiting step in AI progress is not better aligned data (though that would certainly be helpful), it‚Äôs new ideas.

What we need most is fresh ideas about how to connect sequences of words to cognitive models of the world."
3347,@GaryMarcus,2022-06-25 16:11:50+00:00,https://twitter.com/GaryMarcus/status/1540729490057330688,"over 800 people signed up, and an amazing lineup!"
3348,@GaryMarcus,2022-06-25 14:55:38+00:00,https://twitter.com/GaryMarcus/status/1540710314345463808,"Getting a lot of queries about @ylecun‚Äôs ‚Äúbold new vision‚Äù for AI, asking me how it differs from the common-sense and cognitive models-centered vision @ErnestSDavis &amp; advocated in https://t.co/Pt7HZc3jTF.

Honestly, I have no idea.

Maybe he will explain in arXiv? ü§∑‚Äç‚ôÇÔ∏è

@techreview"
3349,@GaryMarcus,2022-06-24 14:59:49+00:00,https://twitter.com/GaryMarcus/status/1540348977366765568,This feed is temporarily going dark in recognition of what the Supreme Court has done to the United States.
3350,@GaryMarcus,2022-06-24 14:25:05+00:00,https://twitter.com/GaryMarcus/status/1540340236424986624,@bakztfuture @CBCNews @FrontBurnerCBC Vancouver BC
3351,@GaryMarcus,2022-06-24 13:38:00+00:00,https://twitter.com/GaryMarcus/status/1540328390376316928,"personal news: as a proud and recent immigrant to Canada, it was a real treat to wake up this morning and unexpectedly see my picture in the CBC News üá®üá¶ 

thanks @CBCNews @FrontBurnerCBC 

https://t.co/zGY0hQzA5p"
3352,@GaryMarcus,2022-06-23 17:44:25+00:00,https://twitter.com/GaryMarcus/status/1540028012229324800,"Some might argue that compositionality is the most important looming technical challenge for AI. 

At this upcoming workshop, an all-star cast will have a look."
3353,@GaryMarcus,2022-06-23 17:09:54+00:00,https://twitter.com/GaryMarcus/status/1540019325758672897,"loved this terrific, no holds-barred look at how media could better cover AI, with @EricNewcomer and @cityofthetown on @DeadCatShow"
3354,@GaryMarcus,2022-06-23 16:46:07+00:00,https://twitter.com/GaryMarcus/status/1540013341501886464,"@cajundiscordian @David_Gunkel @Inframethod @ThomasTelving @MCoeckelbergh duck, duck, duck - just like Eugene Goostman!"
3355,@GaryMarcus,2022-06-23 15:46:40+00:00,https://twitter.com/GaryMarcus/status/1539998381417713665,@David_Gunkel @Inframethod @ThomasTelving @MCoeckelbergh @cajundiscordian @cajundiscordian this is the question i keep asking and that you keep deflecting
3356,@GaryMarcus,2022-06-23 15:42:43+00:00,https://twitter.com/GaryMarcus/status/1539997388164571137,@cajundiscordian @David_Gunkel @Inframethod @ThomasTelving @MCoeckelbergh you keep returning this to me and i keep asking about *your* criteria. why do you keep ducking my question?
3357,@GaryMarcus,2022-06-23 15:01:44+00:00,https://twitter.com/GaryMarcus/status/1539987073276358656,@cajundiscordian @David_Gunkel @Inframethod @ThomasTelving @MCoeckelbergh no. I don‚Äôt care whether you think I am sentient. I am trying to understand the criteria you applied to LaMDA.
3358,@GaryMarcus,2022-06-23 14:51:26+00:00,https://twitter.com/GaryMarcus/status/1539984480890302464,"@cajundiscordian @David_Gunkel @Inframethod @ThomasTelving @MCoeckelbergh so that‚Äôs a ‚Äúno‚Äù, as in ‚Äúno, i won‚Äôt supply any criteria by which i made my attribution to LaMDA‚Äù?"
3359,@GaryMarcus,2022-06-23 14:15:00+00:00,https://twitter.com/GaryMarcus/status/1539975313060274178,@David_Gunkel @Inframethod @ThomasTelving @MCoeckelbergh @cajundiscordian there are lots of definitions. some are trivial (eg my apple watch and thermostat sense things); others have to do with self-awareness and intelligence. my question: is there any interesting sense of the term in which LaMDA is more sentient than my watch?
3360,@GaryMarcus,2022-06-23 14:08:05+00:00,https://twitter.com/GaryMarcus/status/1539973573409812483,"@spiantado @synbiocs @ErnestSDavis @f_charton @ChrSzegedy per the algebraic mind, my main argument is that you have to be able to freely generalize some operations to whole classes of entities, in a mutatis mutandis way, independent for the similarity of new members to previously learned instances."
3361,@GaryMarcus,2022-06-23 13:58:59+00:00,https://twitter.com/GaryMarcus/status/1539971280442576898,"@David_Gunkel @Inframethod @ThomasTelving @MCoeckelbergh @cajundiscordian 1. if it were just an autocomplete system would you ascribe sentience? if yes, why?  if no, in what respect(s) would it need to differ from autocomplete in order to qualify?"
3362,@GaryMarcus,2022-06-23 13:39:51+00:00,https://twitter.com/GaryMarcus/status/1539966465821970434,My question for Blake Lemoine (@cajundiscordian):
3363,@GaryMarcus,2022-06-23 13:33:25+00:00,https://twitter.com/GaryMarcus/status/1539964849215504385,"@synbiocs @spiantado @ErnestSDavis @f_charton @ChrSzegedy have all thought a lot about the current and near future state of automated mathematics.

separately, i agree with your remarks around combinators: they are an alternative approach (worth studying) that try to do similar work to variables."
3364,@GaryMarcus,2022-06-23 13:25:27+00:00,https://twitter.com/GaryMarcus/status/1539962841905516544,"@cajundiscordian @David_Gunkel @Inframethod @ThomasTelving @MCoeckelbergh Please explain to us then how you think it works, since your view seems to be very different from mine. 

I think that to a first approximation all LamDA does is predict next words in a very large corpus a la autocomplete. What is it you think LaMDA does?"
3365,@GaryMarcus,2022-06-23 13:22:05+00:00,https://twitter.com/GaryMarcus/status/1539961997244059651,"@cajundiscordian @Inframethod @David_Gunkel @ThomasTelving @MCoeckelbergh If no knowledge could be relevant, you simply have an unfalsifiable claim.

2/2"
3366,@GaryMarcus,2022-06-23 13:21:45+00:00,https://twitter.com/GaryMarcus/status/1539961911122337800,"@cajundiscordian @Inframethod @David_Gunkel @ThomasTelving @MCoeckelbergh You have the causal arrows reversed here. Knowledge of some entity‚Äôs operation per se doesn‚Äôt make that entity more or less sentient‚Äîbut it might help us to understand *whether* (relative to some definition) that entity is sentient.

1/2"
3367,@GaryMarcus,2022-06-23 01:07:08+00:00,https://twitter.com/GaryMarcus/status/1539777039120535553,@RobAtkinsonITIF @robseamans @elonmusk @JimPethokoukis @rodneyabrooks @erikbryn A fleet of poorly programmed Optimi?
3368,@GaryMarcus,2022-06-23 00:56:05+00:00,https://twitter.com/GaryMarcus/status/1539774259991433216,@RobAtkinsonITIF @robseamans @elonmusk @JimPethokoukis @rodneyabrooks @erikbryn i missed that one. for real? link?
3369,@GaryMarcus,2022-06-23 00:00:19+00:00,https://twitter.com/GaryMarcus/status/1539760224348753920,@nutanc @filippie509 interesting. i assume it ‚Äúknows‚Äù shrek?
3370,@GaryMarcus,2022-06-22 22:42:27+00:00,https://twitter.com/GaryMarcus/status/1539740630464618496,fits perfect with my new essay with @ElliotMurphy91 and earlier work by @AllysonEttinger!
3371,@GaryMarcus,2022-06-22 20:20:12+00:00,https://twitter.com/GaryMarcus/status/1539704832008736768,legal and policy questions around  robots:
3372,@GaryMarcus,2022-06-22 20:15:28+00:00,https://twitter.com/GaryMarcus/status/1539703641027665920,@drmarcj @bobehayes @ElliotMurphy91 it is like nobody is listening to them. and honestly i really don‚Äôt think your ramscar made it to the end of the essay. but i look forward to your thoughts once you have.
3373,@GaryMarcus,2022-06-22 19:49:41+00:00,https://twitter.com/GaryMarcus/status/1539697149197225984,"@ramscar1 @drmarcj @bobehayes @ElliotMurphy91 guessing your reading hasn‚Äôt extended past the tweets, either"
3374,@GaryMarcus,2022-06-22 19:44:10+00:00,https://twitter.com/GaryMarcus/status/1539695760228331520,"@ElliotMurphy91 @SimonCharlow @alexandersclark well, it was tweeted relative to the cosmo thing as a joke, but the post was actually written because i think these issues are well-known to linguists but largely (not entirely) ignored in current approaches."
3375,@GaryMarcus,2022-06-22 19:26:37+00:00,https://twitter.com/GaryMarcus/status/1539691344905416704,@PratYosef @ElliotMurphy91 so why does anyone even take them so seriously? that‚Äôs what i would like to know.
3376,@GaryMarcus,2022-06-22 19:26:04+00:00,https://twitter.com/GaryMarcus/status/1539691206006886401,"@SimonCharlow @ElliotMurphy91 @alexandersclark in some ways the point of the blog post is that large language models don‚Äôt do what semantic parsing aims to do, and that it is foolish to assume that the problems of language can be solved without trying to solve what semantic parsing seeks to solve"
3377,@GaryMarcus,2022-06-22 17:32:21+00:00,https://twitter.com/GaryMarcus/status/1539662587263975425,@sandervanbree @ElliotMurphy91 my view: reference might be internal but it still has to connect to a world model you can reason over to be effective
3378,@GaryMarcus,2022-06-22 17:31:10+00:00,https://twitter.com/GaryMarcus/status/1539662290269503488,"@MatchasmMatt @Cosmopolitan @ElliotMurphy i dunno, eg the guy is only eating the sandwich in 1 out of 3"
3379,@GaryMarcus,2022-06-22 17:18:06+00:00,https://twitter.com/GaryMarcus/status/1539659005114454016,and here is the lead human :)
3380,@GaryMarcus,2022-06-22 17:17:01+00:00,https://twitter.com/GaryMarcus/status/1539658729661927424,"ps although that Cosmo *tweet* is silly, the actual article, by Gloria Liu, is not. 

it‚Äôs both careful &amp; thoughtful, and explains the actual process involved in the cover, including the roles of humans that were in the loop. you can read it here:"
3381,@GaryMarcus,2022-06-22 16:37:44+00:00,https://twitter.com/GaryMarcus/status/1539648845381894145,@spiantado you think search and replace on regular expressions is going to yield sentience?
3382,@GaryMarcus,2022-06-22 16:35:06+00:00,https://twitter.com/GaryMarcus/status/1539648180391772162,"ü§£ If you want to do a duet, Blake Lemoine, I can ride a unicycle while you talk sentience on stilts :)"
3383,@GaryMarcus,2022-06-22 16:28:15+00:00,https://twitter.com/GaryMarcus/status/1539646458621620225,coming up shortly! @elonmusk will be there in spirit! and is still welcome if he wants to join.
3384,@GaryMarcus,2022-06-22 16:25:49+00:00,https://twitter.com/GaryMarcus/status/1539645844894298113,"my 8-year old had no problem and i doubt she has had that much exposure to sentences like these, either.

and she pushed back &amp; said that the one with zero tomatoes could conceivably count :)"
3385,@GaryMarcus,2022-06-22 16:20:30+00:00,https://twitter.com/GaryMarcus/status/1539644505669771265,@spiantado do you have any evidence that people solve the problem in that way? or that AI would be better for using it?
3386,@GaryMarcus,2022-06-22 16:15:40+00:00,https://twitter.com/GaryMarcus/status/1539643291460808704,"@SimonCharlow @ElliotMurphy91 a language comprehension system as whole has to subsume syntax - and also phonology, morphology, semantics, pragmatics, and real-world knowledge and reasoning in general. it‚Äôs necessarily a hard problem"
3387,@GaryMarcus,2022-06-22 16:10:19+00:00,https://twitter.com/GaryMarcus/status/1539641942870335489,"@SimonCharlow @ElliotMurphy91 read our essay, surely that is potential progress"
3388,@GaryMarcus,2022-06-22 15:56:47+00:00,https://twitter.com/GaryMarcus/status/1539638540350267396,@spiantado @ElliotMurphy91 has a recent ms on internalist reference that i think addresses these questions in the right way.
3389,@GaryMarcus,2022-06-22 15:53:09+00:00,https://twitter.com/GaryMarcus/status/1539637626784718848,@spiantado a proof that you can use a workaround doesn‚Äôt mean that you do. but i agree it‚Äôs an interesting alternative.
3390,@GaryMarcus,2022-06-22 15:52:23+00:00,https://twitter.com/GaryMarcus/status/1539637429799243776,"@SimonCharlow @ElliotMurphy91 Nope but he usually reads my substack; will be fun to see what he says :) I don‚Äôt really share his views on semantics, though he certainly raises interesting questions."
3391,@GaryMarcus,2022-06-22 15:32:27+00:00,https://twitter.com/GaryMarcus/status/1539632414351192064,@Cosmopolitan @OpenAI https://t.co/oNfUakVvAk
3392,@GaryMarcus,2022-06-22 15:31:55+00:00,https://twitter.com/GaryMarcus/status/1539632283316981761,@ElliotMurphy91 that is
3393,@GaryMarcus,2022-06-22 15:28:46+00:00,https://twitter.com/GaryMarcus/status/1539631489700073472,"Hey @Cosmopolitan, DALL-E isn‚Äôt nearly as smart as you seem to think. @elliotmurphy &amp; I explain why in a new post today: https://t.co/Dd17aqRu2z

Sample (from DALL-E mini) to whet your appetite: Where‚Äôs the bowl with more cucumbers than tomatoes? 

0 for 9 super-genius! https://t.co/LiTmkKI6Zn"
3394,@GaryMarcus,2022-06-22 14:13:13+00:00,https://twitter.com/GaryMarcus/status/1539612473795366912,@MCoeckelbergh @Inframethod what is the internal mechanism of humans that would lead you to reach that conclusion?
3395,@GaryMarcus,2022-06-22 14:08:59+00:00,https://twitter.com/GaryMarcus/status/1539611409301925889,"@ronbrachman sad part is that a human wrote that part! 

the need for better education about AI is dire."
3396,@GaryMarcus,2022-06-22 13:37:40+00:00,https://twitter.com/GaryMarcus/status/1539603530440265728,"üíØ agree w @azeem; there ain‚Äôt no supercomputer in 2022 as *sophisticated* the human brain.

Not even close.

OTOH this is the second news story in two days to be really, really confused. 

The AI community ought to have a think about how the messages it is sending get perceived."
3397,@GaryMarcus,2022-06-22 13:34:32+00:00,https://twitter.com/GaryMarcus/status/1539602740577374208,"@anilkseth @azeem @mpshanahan @demishassabis i still think the brain might be a particular kind of a parallel, field-programmable computer and made that suggestion here:

https://t.co/j9y9Yq4hBu

but the South China Morning Post is out to lunch"
3398,@GaryMarcus,2022-06-22 12:49:44+00:00,https://twitter.com/GaryMarcus/status/1539591468167245824,"@spiantado would you argue that multidimensional scaling captures conceptual role? I would not, but that is tantamount to what you are saying"
3399,@GaryMarcus,2022-06-22 12:49:03+00:00,https://twitter.com/GaryMarcus/status/1539591293457747969,@spiantado again i think the issues are around reference and cognitive models; state is just not solving those key issues.
3400,@GaryMarcus,2022-06-22 12:48:08+00:00,https://twitter.com/GaryMarcus/status/1539591065488855043,"@spiantado see ‚ÄùThree ideas from linguistics‚Äù which will go up shortly at https://t.co/8ir1xKvqt6; I don‚Äôt think state is enough, at least in its current form, because there is no reference or leverage-able cognitive model"
3401,@GaryMarcus,2022-06-22 12:46:16+00:00,https://twitter.com/GaryMarcus/status/1539590593487048707,"@spiantado yes, if it were smart enough. but that might require innateness, operations over variables, mapping form onto meaning, etc. LaMDA is certainly not that."
3402,@GaryMarcus,2022-06-22 12:45:13+00:00,https://twitter.com/GaryMarcus/status/1539590328017006593,"@spiantado IMHO, you are confusing what might be possible with a very sophisticated pattern matcher (eg the kind that allows humans to comprehend deep analogies) with what presently seems possible"
3403,@GaryMarcus,2022-06-22 01:41:52+00:00,https://twitter.com/GaryMarcus/status/1539423393086599168,Coming Wednesday to https://t.co/8ir1xKenr6: three key ideas from linguistics that every AI researcher should consider
3404,@GaryMarcus,2022-06-22 01:36:51+00:00,https://twitter.com/GaryMarcus/status/1539422130596552704,"When some future offspring of DALL-E and GPT can make seemingly impossible surrealist art and then precisely detail the underlying physics that would make its images plausible, my work will truly be done."
3405,@GaryMarcus,2022-06-22 00:16:14+00:00,https://twitter.com/GaryMarcus/status/1539401842550902784,"@percyliang i have lots of trouble with @ykilcher‚Äôs 4chan expt. But let‚Äôs not toss it down the memory hole.

Instead, let‚Äôs learn from it
- it‚Äôs a powerful demonstration of how easy it use to these systems in harmful ways. 
-&amp; a powerful demo that we need government policy for LLMs asap."
3406,@GaryMarcus,2022-06-21 21:14:58+00:00,https://twitter.com/GaryMarcus/status/1539356224591831040,and can the AI community recognize the work that still needs to be done?
3407,@GaryMarcus,2022-06-21 20:34:58+00:00,https://twitter.com/GaryMarcus/status/1539346159264620560,üôÑ
3408,@GaryMarcus,2022-06-21 20:31:50+00:00,https://twitter.com/GaryMarcus/status/1539345368336695297,wonder whether GPT-3 and other LLM‚Äôs like LaMDA will similarly eventually be dialed back because of their tendency towards generating misinformation
3409,@GaryMarcus,2022-06-21 19:37:02+00:00,https://twitter.com/GaryMarcus/status/1539331578563858432,@Lang__Leon @Pehdrew_ @ErnestSDavis
3410,@GaryMarcus,2022-06-21 19:24:45+00:00,https://twitter.com/GaryMarcus/status/1539328486673895426,much the same could be said for the new fad of prompt engineering.
3411,@GaryMarcus,2022-06-21 19:23:35+00:00,https://twitter.com/GaryMarcus/status/1539328194318413825,"@Lang__Leon @Pehdrew_ well, no. Like all prompt engineering ‚ÄúYo be real‚Äù works when it works, doesn‚Äôt when it doesn‚Äôt. https://t.co/OrCoLKY6sN"
3412,@GaryMarcus,2022-06-21 19:18:48+00:00,https://twitter.com/GaryMarcus/status/1539326989022203905,"honestly, this don‚Äôt go viral like ‚ÄúNonsense on Stilts‚Äù, but it‚Äôs just as much fun üòÉ"
3413,@GaryMarcus,2022-06-21 18:40:34+00:00,https://twitter.com/GaryMarcus/status/1539317367804776448,always a fun conference @WorldSummitAI
3414,@GaryMarcus,2022-06-21 18:38:35+00:00,https://twitter.com/GaryMarcus/status/1539316871035596800,@ErnestSDavis @samc0hen @sir_deenicus @ItalyHighTech @irinablok oops
3415,@GaryMarcus,2022-06-21 18:25:36+00:00,https://twitter.com/GaryMarcus/status/1539313603278344194,@jonathanrlarkin i don‚Äôt think NELL made any real progress; Cyc definitely made some but is proprietary and didn‚Äôt fully solve the problem by any stretch
3416,@GaryMarcus,2022-06-21 16:15:53+00:00,https://twitter.com/GaryMarcus/status/1539280956695031808,@kaalam_ai we discussed in https://t.co/C6XodPts1W
3417,@GaryMarcus,2022-06-21 16:00:55+00:00,https://twitter.com/GaryMarcus/status/1539277190642094080,"Exactly!!! Not all iterative progress is aimed at the right destination.

Wisdom comes from knowing what forms of progress can really get you to your final destination."
3418,@GaryMarcus,2022-06-21 15:59:03+00:00,https://twitter.com/GaryMarcus/status/1539276719986573312,"great thread responding to @ylecun and @Jake_Browning00 by @Abel_TorresM.

important to realize that LeCun and Browning frame me as a being alone and when in reality so many others see same issues"
3419,@GaryMarcus,2022-06-21 15:53:56+00:00,https://twitter.com/GaryMarcus/status/1539275434109456384,"no. you are overestimating value of learning &amp; underestimating both the value of reasoning and of judicious prior knowledge.

alphaFold 2 depends on a set of representations that are carefully constructed prior to learning; any commonsense system is likely to require the same."
3420,@GaryMarcus,2022-06-21 15:41:34+00:00,https://twitter.com/GaryMarcus/status/1539272322825461761,"Glad so many people are excited to see this! 

My thoughts on Cyc‚Äîwith a very special guest star‚Äîare underway, but will take some time."
3421,@GaryMarcus,2022-06-21 15:16:43+00:00,https://twitter.com/GaryMarcus/status/1539266067360382976,"If you care about commonsense reasoning, but think Cyc is just a database of patterns, or don't even know what Cyc is, stay tuned for an important future essay."
3422,@GaryMarcus,2022-06-21 15:15:00+00:00,https://twitter.com/GaryMarcus/status/1539265635737186304,"@nlpnyc it has immense commonsense *reasoning* capacity, and it is not merely a passive database, but it is not a learning system. 

it (or something like it) could be a critical component in    learning system, as yet unbuilt, that could reasoning at correct level of abstraction."
3423,@GaryMarcus,2022-06-21 14:16:34+00:00,https://twitter.com/GaryMarcus/status/1539250933024100354,"@nlpnyc -  commonsense is necessary, not sufficient. CYC has rich representations of common sense, but is not AGI.
- systems are improving on factoids, but nobody can   reliably reason over (or trust) the unreliable knowledge,
- doing better on benchmarks doesn't guarantee real progress"
3424,@GaryMarcus,2022-06-21 05:12:13+00:00,https://twitter.com/GaryMarcus/status/1539113938826280961,Puzzled what the 6% were thinking. But how could we be close to AGI if common sense still eludes AI?
3425,@GaryMarcus,2022-06-21 01:52:42+00:00,https://twitter.com/GaryMarcus/status/1539063729639149568,"@AndreiMellas and yet my hard work in trying to isolate needs to be fixed is treated with nasty memes. but i do see your point, and so often point to some of the accomplishments of deep learning"
3426,@GaryMarcus,2022-06-21 01:51:39+00:00,https://twitter.com/GaryMarcus/status/1539063464647221248,@grbradsk assume a spherical cow
3427,@GaryMarcus,2022-06-20 23:05:50+00:00,https://twitter.com/GaryMarcus/status/1539021735382732800,@DotCSV if only we could fix real world infrastructure with inpainting :)
3428,@GaryMarcus,2022-06-20 22:54:15+00:00,https://twitter.com/GaryMarcus/status/1539018820723015681,@joshelman maybe optimus the humanoid will be Transformer powered by Transformers!
3429,@GaryMarcus,2022-06-20 22:50:28+00:00,https://twitter.com/GaryMarcus/status/1539017869375287298,"Out hiking. Wondering how Optimus would handle these signs and this under-repair, not listed on any map bridge https://t.co/RHOwQ17lMz"
3430,@GaryMarcus,2022-06-20 22:41:51+00:00,https://twitter.com/GaryMarcus/status/1539015702262194177,"@grbradsk wait elon told me we are all living in a simulation, so, um, what‚Äôs the difference?"
3431,@GaryMarcus,2022-06-20 22:40:45+00:00,https://twitter.com/GaryMarcus/status/1539015423789867009,"@aniketvartak @IntuitMachine no worries on A
B would be great if field would take criticism seriously, kinda  useless  if all errors are explained post hoc and there is no innovation in architecture"
3432,@GaryMarcus,2022-06-20 22:23:57+00:00,https://twitter.com/GaryMarcus/status/1539011199211171841,"@aniketvartak @IntuitMachine saw it. a it was weird since it quoted all these replies to me with our quoting me, like orbiting around an invisible planet but b what is the actual step forward? in what? measured how?"
3433,@GaryMarcus,2022-06-20 22:06:08+00:00,https://twitter.com/GaryMarcus/status/1539006711784058881,"@IntuitMachine step forward in art synthesis: yes
in AGI: why? i don‚Äôt see that"
3434,@GaryMarcus,2022-06-20 22:03:07+00:00,https://twitter.com/GaryMarcus/status/1539005955328729088,exactly.
3435,@GaryMarcus,2022-06-20 21:05:09+00:00,https://twitter.com/GaryMarcus/status/1538991364435693568,"if people didn‚Äôt keep implying they were a step towards AGI, I would!"
3436,@GaryMarcus,2022-06-20 21:02:31+00:00,https://twitter.com/GaryMarcus/status/1538990702540926976,@OlafenwaMoses @GoogleAI @ErnestSDavis @aniketvartak see my essay Horse Rides Elephant
3437,@GaryMarcus,2022-06-20 20:51:23+00:00,https://twitter.com/GaryMarcus/status/1538987901446332416,"@AmandaAskell by the age of 3 they have a clear, cross-modal semantics and an ability to reason about the world, such that they can acquire knowledge in many domains."
3438,@GaryMarcus,2022-06-20 20:30:27+00:00,https://twitter.com/GaryMarcus/status/1538982632012144640,"8 hours left for the ‚ÄúGame Over‚Äù and ‚ÄúAGI is almost here‚Äù crowd to explain why/how common sense has (almost?) been solved.

Still waiting for your arguments.

If you don‚Äôt have any, well, maybe we are not that close to AGI after all?"
3439,@GaryMarcus,2022-06-20 20:24:04+00:00,https://twitter.com/GaryMarcus/status/1538981029603512320,"@JhendersonIMB @fernandaedi ‚Äúbut that‚Äôs one hard for humans, too‚Äù, says the deep learning crowd. in this case, they are right.

try ‚ÄúThe newspaper published by The Herald stank‚Äù :)"
3440,@GaryMarcus,2022-06-20 20:23:01+00:00,https://twitter.com/GaryMarcus/status/1538980765135872000,"@kevin2kelly it will, very soon, which means we need to step our anti-disinformation game, stat."
3441,@GaryMarcus,2022-06-20 19:43:50+00:00,https://twitter.com/GaryMarcus/status/1538970903593115649,@HPC_Guru @ylecun https://t.co/1bNppOCPwF
3442,@GaryMarcus,2022-06-20 18:36:14+00:00,https://twitter.com/GaryMarcus/status/1538953890120409088,"@SimonKirby language, solved!"
3443,@GaryMarcus,2022-06-20 17:54:06+00:00,https://twitter.com/GaryMarcus/status/1538943288161366016,"@EMostaque @plibin we need a paradigm shift, as discussed in my essays at https://t.co/8ir1xKvqt6 and on arXiv in Next Decade in AI.

current paradigm will not solve this problem"
3444,@GaryMarcus,2022-06-20 17:53:13+00:00,https://twitter.com/GaryMarcus/status/1538943066257534977,"3 days ago, @ylecun @jake_browning00 @NoemaMag call out ‚Äúscornful naysaying‚Äù, presumably including my complaints about how large language models are disconnected from the world. 

2 days ago, @ylecun posts this

Like the essay overall, but surely we are calling out the same stuff"
3445,@GaryMarcus,2022-06-20 17:48:43+00:00,https://twitter.com/GaryMarcus/status/1538941934407782405,"@s_r_constantin have never seen another group of people so disrespectful of cognitive science, so no"
3446,@GaryMarcus,2022-06-20 17:42:08+00:00,https://twitter.com/GaryMarcus/status/1538940273908015104,@ArrayManta @ylecun @OpenAI you mean like this?
3447,@GaryMarcus,2022-06-20 17:40:15+00:00,https://twitter.com/GaryMarcus/status/1538939801432338434,@EMostaque @plibin yes that‚Äôs why @plibin and I are deeply worried.
3448,@GaryMarcus,2022-06-20 17:39:44+00:00,https://twitter.com/GaryMarcus/status/1538939673640259584,@samc0hen @sir_deenicus @ItalyHighTech @ErnestSDavis @irinablok Darwin save us all if AGI is that sensitive.
3449,@GaryMarcus,2022-06-20 17:21:45+00:00,https://twitter.com/GaryMarcus/status/1538935147780788224,"@pcwein @ErnestSDavis @irinablok impressive: image synthesis, lighting, compositing

weak: natural language understanding, physical and biological reasoning 

Note that it is the latter i have always emphasized as key"
3450,@GaryMarcus,2022-06-20 17:19:41+00:00,https://twitter.com/GaryMarcus/status/1538934626248495110,"@samc0hen @sir_deenicus @ItalyHighTech @ErnestSDavis @irinablok now counterbalance and see if it is at all robust to changes in wording and direction  (left/right/front of/behind)

imagine having to tell the star trek computer which persona to adopt in order to elicit a correct answer"
3451,@GaryMarcus,2022-06-20 17:17:34+00:00,https://twitter.com/GaryMarcus/status/1538934091172696067,@pcwein @ErnestSDavis @irinablok and I know *you* know better :) it‚Äôs the fan boys who are going to get confused‚Ä¶
3452,@GaryMarcus,2022-06-20 17:15:21+00:00,https://twitter.com/GaryMarcus/status/1538933534336946183,"@pcwein @ErnestSDavis @irinablok that‚Äôs because the real world is impressive and they borrow from it. but they still don‚Äôt understand it, so they are never reliable. 

my Horse Rides Astronaut essay is super relevant"
3453,@GaryMarcus,2022-06-20 17:11:37+00:00,https://twitter.com/GaryMarcus/status/1538932595056119809,"@pcwein @ErnestSDavis @irinablok fanboys gonna be like ‚Äúsee it does have common sense‚Äù üôÑ

and i am going to have look up recent tweet about grade inflation https://t.co/WzU6izXIOS"
3454,@GaryMarcus,2022-06-20 17:04:41+00:00,https://twitter.com/GaryMarcus/status/1538930851056074755,"The funny thing about the rhetoric in the quote below on ‚Äúscornful naysaying‚Äù is that @ylecun actually agrees with me on 90% of my criticisms, and says so indirectly later in his essay. 

On most issues, LeCun is far closer to me than he is eg to @openAi. https://t.co/NM24T4253t"
3455,@GaryMarcus,2022-06-20 16:57:05+00:00,https://twitter.com/GaryMarcus/status/1538928936607965185,@MadamePratolung @KathrynECramer https://t.co/w5hcIZQdDf was a really huge deal. And although Wolfram Alpha has its limits in some ways  it is more reliable than LLMs.
3456,@GaryMarcus,2022-06-20 15:43:58+00:00,https://twitter.com/GaryMarcus/status/1538910535940313088,quite so. democracy may cease to  function if the cost of fabricating plausible misinformation goes to zero.
3457,@GaryMarcus,2022-06-20 15:36:51+00:00,https://twitter.com/GaryMarcus/status/1538908748504150016,@BrandonLive @ronbrachman yes (though my original question might have been less clear than i realized!)
3458,@GaryMarcus,2022-06-20 15:36:02+00:00,https://twitter.com/GaryMarcus/status/1538908542815465472,"@aniketvartak @mmbronstein @GoogleAI @ErnestSDavis see my Horse Rides Elephant, and think about how the different excuses contrast"
3459,@GaryMarcus,2022-06-20 15:25:10+00:00,https://twitter.com/GaryMarcus/status/1538905806665420801,"@BrandonLive commonsense is likely many things, not one; Ernie Davis and I have a whole chapter about it https://t.co/Pt7HZbLIv5 and @ronbrachman has a new book on the topic. 

A sampling of his book that distills some nonobvious knowledge that machines will need to master: https://t.co/m45IFpYugP"
3460,@GaryMarcus,2022-06-20 14:49:22+00:00,https://twitter.com/GaryMarcus/status/1538896797107515392,@BrandonLive Your step 1 was to make false presumptions about other people without doing the courtesy of peeking that their work. I block few people but really take offense at this one.
3461,@GaryMarcus,2022-06-20 14:41:28+00:00,https://twitter.com/GaryMarcus/status/1538894809498234880,"is any part of that any less true 2.5 years later? 

which?"
3462,@GaryMarcus,2022-06-20 13:38:05+00:00,https://twitter.com/GaryMarcus/status/1538878856982978560,"@BeebsMemes @FelixHill84 most likely, i won‚Äôt :) and honestly my kids (age 8 and 9) have already figured out for themselves the value of looking for disconfirmation."
3463,@GaryMarcus,2022-06-20 13:20:21+00:00,https://twitter.com/GaryMarcus/status/1538874393849262080,@FelixHill84 I would never let my children grow up without reading Kuhn and Popper.
3464,@GaryMarcus,2022-06-20 13:04:49+00:00,https://twitter.com/GaryMarcus/status/1538870485269680129,"Why do so many conversations with tech bros revolve around their need for validation?

It‚Äôs always ‚ÄúBut you have to admit there is progress‚Äù

and too rarely

‚ÄúGood point. Our systems still struggle with common sense and deep understanding and we should focus on that‚Äù"
3465,@GaryMarcus,2022-06-20 04:39:11+00:00,https://twitter.com/GaryMarcus/status/1538743241188573184,Current AI (explain your answer in the comments):
3466,@GaryMarcus,2022-06-20 04:30:18+00:00,https://twitter.com/GaryMarcus/status/1538741003330367488,"@paulg i wouldn‚Äôt assume that writing bogus essays is actually an important step towards intelligence, rather than just demonstration of the power of statistical mimicry. 

your tweet may well not age well."
3467,@GaryMarcus,2022-06-20 01:43:42+00:00,https://twitter.com/GaryMarcus/status/1538699078833360896,perhaps a metaphor for the whole field
3468,@GaryMarcus,2022-06-20 01:38:13+00:00,https://twitter.com/GaryMarcus/status/1538697696642420737,"@ItalyHighTech @samc0hen @ErnestSDavis @irinablok my guess is that it is at chance, and answer will vary from trial to trial"
3469,@GaryMarcus,2022-06-20 01:32:19+00:00,https://twitter.com/GaryMarcus/status/1538696212584357888,"AGI is gonna be wild, part 733"
3470,@GaryMarcus,2022-06-20 00:43:38+00:00,https://twitter.com/GaryMarcus/status/1538683962389803009,"so much speculation, such little evidence (and so little explanation of criteria).

why bother with science (or philosophy), at all? https://t.co/3HzVlBjSH0"
3471,@GaryMarcus,2022-06-20 00:32:22+00:00,https://twitter.com/GaryMarcus/status/1538681127283503104,@hardmaru do they?
3472,@GaryMarcus,2022-06-19 23:35:34+00:00,https://twitter.com/GaryMarcus/status/1538666833309577216,The M. Mitchells keep telling it like it is. @melmitchell1 ‚Å¶@mmitchell_ai‚Å© https://t.co/2fhDYSiH3d
3473,@GaryMarcus,2022-06-19 23:33:20+00:00,https://twitter.com/GaryMarcus/status/1538666270408822785,"Very much concur with @MelMitchell1‚Äôs critique of PaLM- and am sad to see @GoogleAI to continue to play the game of hype without peer review. 

Anyone remember all the hype around Google Duplex? 

Media needs to step up its game."
3474,@GaryMarcus,2022-06-19 21:18:52+00:00,https://twitter.com/GaryMarcus/status/1538632431896514560,@stanislavfort @gwern it‚Äôs not very reliable. @ernestsdavis might list some counter examples here
3475,@GaryMarcus,2022-06-19 21:17:02+00:00,https://twitter.com/GaryMarcus/status/1538631969696796673,"@_arohan_ @mmbronstein @GoogleAI @ErnestSDavis @aniketvartak want to try ‚Äúrealistic, not surreal‚Äù in the prompt?"
3476,@GaryMarcus,2022-06-19 20:29:49+00:00,https://twitter.com/GaryMarcus/status/1538620087757811712,"@b_snef always the so-so proxy, never more"
3477,@GaryMarcus,2022-06-19 20:28:53+00:00,https://twitter.com/GaryMarcus/status/1538619850112630784,@b_snef @JR_Hochmann we need to write about this work
3478,@GaryMarcus,2022-06-19 20:28:08+00:00,https://twitter.com/GaryMarcus/status/1538619662195314688,"@Benambridge good question. there was an older literature in developmental robotics;  there is some recent work by @spiantado and by @FelixHill84 

maybe they can point to the state of the art? @SimonKirby?

@percyliang @LukeZettlemoyer any ideas?"
3479,@GaryMarcus,2022-06-19 20:09:05+00:00,https://twitter.com/GaryMarcus/status/1538614867803787264,"@begusgasper @GoogleAI @ErnestSDavis @aniketvartak perhaps prompts lie ‚Äúto the extent that it is possible‚Äù or something 

still worry about falsifiability though"
3480,@GaryMarcus,2022-06-19 20:07:00+00:00,https://twitter.com/GaryMarcus/status/1538614343494823936,"@mmbronstein @GoogleAI @ErnestSDavis @aniketvartak but see what happened when dall-e made the opposite error:

https://t.co/ZacV6jKxJ6

when anything can explained away, nothing has been explained"
3481,@GaryMarcus,2022-06-19 20:01:19+00:00,https://twitter.com/GaryMarcus/status/1538612915153973248,"@b_snef a detailed, dynamically updatable cognitive model of entities and their relationships"
3482,@GaryMarcus,2022-06-19 20:00:23+00:00,https://twitter.com/GaryMarcus/status/1538612679664750593,@begusgasper @GoogleAI @ErnestSDavis @aniketvartak perhaps ultimately drawing programs are unfalsifiable; you can‚Äôt really attribute common sense to them because there is nothing you would count as an error
3483,@GaryMarcus,2022-06-19 19:48:37+00:00,https://twitter.com/GaryMarcus/status/1538609718037340160,"when a model fails to draw a horse riding astronaut, deep learning fans say ‚Äúthat‚Äôs because it‚Äôs impossible‚Äù

when a model draws an impossible coffee cup, fans say ‚Äúthat‚Äôs because the model is trying to be Dali‚Äù

can‚Äôt be both üôÑ"
3484,@GaryMarcus,2022-06-19 19:45:28+00:00,https://twitter.com/GaryMarcus/status/1538608925943091202,"@b_snef word cooccurence is half decent proxy for the world, never a reliable substitute. 

don‚Äôt confuse mediocre proxies for the real thing"
3485,@GaryMarcus,2022-06-19 19:42:28+00:00,https://twitter.com/GaryMarcus/status/1538608171031228417,"@begusgasper @GoogleAI @ErnestSDavis @aniketvartak um‚Ä¶ when DALL-E failed to draw horse riding an astronaut, you said ‚Äúmaybe it learns that horses don‚Äôt ride astronauts‚Äù; when it draws something absurd, you point towards Dali, who drew things that can‚Äôt exist.

the excuses contradict one another"
3486,@GaryMarcus,2022-06-19 19:25:48+00:00,https://twitter.com/GaryMarcus/status/1538603977763303424,@Joe_Anandarajah @ErnestSDavis @irinablok unless it was staged?
3487,@GaryMarcus,2022-06-19 19:14:07+00:00,https://twitter.com/GaryMarcus/status/1538601036494974977,@OshriNaparstek @GoogleAI @ErnestSDavis @aniketvartak so funny how things changed from three weeks ago when i wrote https://t.co/ZacV6jKxJ6
3488,@GaryMarcus,2022-06-19 19:05:47+00:00,https://twitter.com/GaryMarcus/status/1538598939833688064,"2015 article: still relevant, still unsolved: https://t.co/39XGpgtM2j"
3489,@GaryMarcus,2022-06-19 19:05:47+00:00,https://twitter.com/GaryMarcus/status/1538598937577213952,"Commonsense reasoning, then and now 

Left: Robot cutting a tree from wrong side / @ErnestSDavis &amp; @garymarcus 2015 

Right: Impossible coffee cup: Imagen &amp; @irinablok / 2022

The challenge of commonsense persists. https://t.co/hT5YFN8kHT"
3490,@GaryMarcus,2022-06-19 18:50:17+00:00,https://twitter.com/GaryMarcus/status/1538595037117681664,"#imagen physics fail

No wonder @googleAI hasn‚Äôt let @ErnestSDavis and me try out their system. 

h/t @aniketvartak"
3491,@GaryMarcus,2022-06-19 11:18:08+00:00,https://twitter.com/GaryMarcus/status/1538481249391476736,"@rgblong is there some system in  2022 you do think is interestingly sentient? which, and by what criteria?"
3492,@GaryMarcus,2022-06-19 03:02:39+00:00,https://twitter.com/GaryMarcus/status/1538356556873404416,"@javiturek @motionphi this guy laughs, and appreciates your eye for detail https://t.co/Z6tXEWohtG"
3493,@GaryMarcus,2022-06-19 02:48:51+00:00,https://twitter.com/GaryMarcus/status/1538353084883013632,@MadamePratolung AI is indeed in a bit of a pickle
3494,@GaryMarcus,2022-06-19 00:44:14+00:00,https://twitter.com/GaryMarcus/status/1538321723325460480,@plevy @Plinz
3495,@GaryMarcus,2022-06-19 00:43:54+00:00,https://twitter.com/GaryMarcus/status/1538321639502254080,@zenstyle @plevy that‚Äôs insane!
3496,@GaryMarcus,2022-06-19 00:33:11+00:00,https://twitter.com/GaryMarcus/status/1538318944930476032,"@plevy ‚ÄúI need a paradigm shift, not a billion more parameters‚Äù https://t.co/fMWIGnHwPX"
3497,@GaryMarcus,2022-06-19 00:29:30+00:00,https://twitter.com/GaryMarcus/status/1538318015342600193,@plevy won‚Äôt work for this paper but might for another
3498,@GaryMarcus,2022-06-19 00:27:07+00:00,https://twitter.com/GaryMarcus/status/1538317418732302336,@plevy or 3 orders magnitude more data
3499,@GaryMarcus,2022-06-18 23:31:40+00:00,https://twitter.com/GaryMarcus/status/1538303464685436928,this is so well said üî•
3500,@GaryMarcus,2022-06-18 23:16:32+00:00,https://twitter.com/GaryMarcus/status/1538299652671275008,"@MadamePratolung @KathrynECramer @mer__edith ‚Äúprimes darker content‚Äù, like Marcus Davis cranberry/grape juice example @techreview"
3501,@GaryMarcus,2022-06-18 23:15:13+00:00,https://twitter.com/GaryMarcus/status/1538299322147540992,@KathrynECramer @MadamePratolung @mer__edith ! screenshot?
3502,@GaryMarcus,2022-06-18 23:10:47+00:00,https://twitter.com/GaryMarcus/status/1538298209209942016,"@MadamePratolung @KathrynECramer @mer__edith no, but (very roughly) you are priming which part of its corpus to rely on"
3503,@GaryMarcus,2022-06-18 23:08:24+00:00,https://twitter.com/GaryMarcus/status/1538297605968408576,"@charleswangb @balazskegl yes, you could make that argument. it bullshits, sometime it speak truth, sometimes not"
3504,@GaryMarcus,2022-06-18 23:07:23+00:00,https://twitter.com/GaryMarcus/status/1538297352456245248,"@MadamePratolung @KathrynECramer @mer__edith there is certainly some degree of generalization, &amp; the system can create some things that are not verbatim. how far it can go from training is a different matter, hard to evaluate because the training data are not public.

@yasaman_razeghi and @sameer_  study this in arxiv 2022"
3505,@GaryMarcus,2022-06-18 23:05:02+00:00,https://twitter.com/GaryMarcus/status/1538296760514121728,@KathrynECramer @MadamePratolung @mer__edith i suspect you are correct and wish for the sake of science that there fuller disclosure
3506,@GaryMarcus,2022-06-18 21:37:29+00:00,https://twitter.com/GaryMarcus/status/1538274726526652416,@MadamePratolung @KathrynECramer @Miles_Brundage might know
3507,@GaryMarcus,2022-06-18 21:32:10+00:00,https://twitter.com/GaryMarcus/status/1538273388006846464,@elonmusk feel free to join
3508,@GaryMarcus,2022-06-18 21:29:55+00:00,https://twitter.com/GaryMarcus/status/1538272821876379648,@charleswangb thanks. very tempted to use this one!
3509,@GaryMarcus,2022-06-18 20:42:45+00:00,https://twitter.com/GaryMarcus/status/1538260954223218688,@pgolding @mndl_nyc it‚Äôs hard to communicate this sort of thing!
3510,@GaryMarcus,2022-06-18 20:32:58+00:00,https://twitter.com/GaryMarcus/status/1538258490560372736,"@jrbarrat @noUpside disaster for democracy, handy tool for fascism cc @jasonintrator"
3511,@GaryMarcus,2022-06-18 20:32:13+00:00,https://twitter.com/GaryMarcus/status/1538258304647852032,@jrbarrat @noUpside do you now https://t.co/HX7lr2KjTT‚Äôs blog about gpt-3 counseling suicide?
3512,@GaryMarcus,2022-06-18 20:31:10+00:00,https://twitter.com/GaryMarcus/status/1538258037009289217,@pstAsiatech or see eg w GPT-3:
3513,@GaryMarcus,2022-06-18 20:30:12+00:00,https://twitter.com/GaryMarcus/status/1538257795954270208,"@pstAsiatech LaMDA might get A- for effort, but it gets an F for execution. ‚Äúi like to play with my friends and family‚Äù, etc, wholesale fabrications are rampant"
3514,@GaryMarcus,2022-06-18 20:28:22+00:00,https://twitter.com/GaryMarcus/status/1538257335491014656,@LisaMcerlaneYao no way am I stepping on that brave man‚Äôs toes. greatest line of the decade so far.
3515,@GaryMarcus,2022-06-18 20:26:44+00:00,https://twitter.com/GaryMarcus/status/1538256923903963136,"@DylanoRepublic or the deck chairs, per the usual version. which actually works here nicely."
3516,@GaryMarcus,2022-06-18 20:25:49+00:00,https://twitter.com/GaryMarcus/status/1538256691015258112,"@andrey_kurenkov yes, it is meant metaphorically; i tried to be clear by that elsewhere. such systems have no mental state, or desire, aside from predicting sequences of words.

also notably absent is anything like a system for reasoning about explicit values"
3517,@GaryMarcus,2022-06-18 20:09:39+00:00,https://twitter.com/GaryMarcus/status/1538252622234271744,"need a little help with a title (clich√©s might be ok) like ‚Äúa band aid to stop a hailstorm‚Äù or ‚Äúthoughts and prayers are fine, but please pass the ammo‚Äù üôè"
3518,@GaryMarcus,2022-06-18 20:04:10+00:00,https://twitter.com/GaryMarcus/status/1538251244090929153,@Abebab counterpoint (even though we seem to agree on so much else that is important): https://t.co/j9y9YqlT04
3519,@GaryMarcus,2022-06-18 19:51:12+00:00,https://twitter.com/GaryMarcus/status/1538247981207543808,"@andrey_kurenkov as addressed in my own tweet that i quoted, these systems are literally indifferent to truth

people in the AI community recognize the problem but underestimate how poorly equipped current techniques are to deal with it.

people outside industry don‚Äôt know what is about it hit"
3520,@GaryMarcus,2022-06-18 19:43:24+00:00,https://twitter.com/GaryMarcus/status/1538246017161777152,@jrbarrat @noUpside is there anything you can add here?
3521,@GaryMarcus,2022-06-18 19:42:40+00:00,https://twitter.com/GaryMarcus/status/1538245834709553155,"@jrbarrat troll farms don‚Äôt exactly publish quarterly reports, but see @ykilcher‚Äôs controversial 4chan video for a real world experiment that *was* reported. 

the fire is already spreading, question is how fast."
3522,@GaryMarcus,2022-06-18 19:12:40+00:00,https://twitter.com/GaryMarcus/status/1538238284937146368,@sabidurAI it‚Äôs a wake up call
3523,@GaryMarcus,2022-06-18 17:40:37+00:00,https://twitter.com/GaryMarcus/status/1538215120123244544,pareidolia for the win!
3524,@GaryMarcus,2022-06-18 17:38:00+00:00,https://twitter.com/GaryMarcus/status/1538214459885244417,"Hey PaLM, can you explain why this DALL-E mini drawing is inadvertently funny? Pretty sure Nixon must be in your database. Go!"
3525,@GaryMarcus,2022-06-18 17:36:19+00:00,https://twitter.com/GaryMarcus/status/1538214037657247744,ü§£ü§£
3526,@GaryMarcus,2022-06-18 17:23:48+00:00,https://twitter.com/GaryMarcus/status/1538210886006976512,@ihorgowda @KBAndersen https://t.co/ze8DtZuHwR
3527,@GaryMarcus,2022-06-18 17:23:20+00:00,https://twitter.com/GaryMarcus/status/1538210769493340160,full disclosure: my image above is in homage to something similar Doug Hofstadter said in different context about Ray Kurzweil; you could look it up.
3528,@GaryMarcus,2022-06-18 17:23:20+00:00,https://twitter.com/GaryMarcus/status/1538210767127711744,"LaMDA would make a truly terrible research assistant, because it cannot differentiate truth from lies, and would blend the two together so finely you wouldn‚Äôt be able to discern what was what."
3529,@GaryMarcus,2022-06-18 17:14:26+00:00,https://twitter.com/GaryMarcus/status/1538208530498326528,"@KathrynECramer @MadamePratolung it certainly looks/acts like a sociopath (though as I have tried to explain, it‚Äôs actually just a word-predictor). someone challenged you on that? why?"
3530,@GaryMarcus,2022-06-18 17:13:02+00:00,https://twitter.com/GaryMarcus/status/1538208177119850496,"@mndl_nyc this is wrong. Large Language Models (the currently popular form of AI, eg LaMDA) literally knows nothing about human intention, and does not care

It just predicts sequences of words. Period.

Please stop anthropomorphizing. Just stop."
3531,@GaryMarcus,2022-06-18 17:08:03+00:00,https://twitter.com/GaryMarcus/status/1538206923991883776,"@jacobmbuckman @josephdviviano @sirbayes @slatestarcodex re the bitter lesson, see my discussion in https://t.co/ufbxCXeFOL"
3532,@GaryMarcus,2022-06-18 17:03:47+00:00,https://twitter.com/GaryMarcus/status/1538205848207364098,"@wellingmax @ylecun @csabaveres and 1 and 3 depend on the model. but both are still weak in current models, see eg my essay Horse Rides Elephsnt and my arXiv in Dall-e, etc"
3533,@GaryMarcus,2022-06-18 17:02:31+00:00,https://twitter.com/GaryMarcus/status/1538205528769196033,"@wellingmax @ylecun @csabaveres i don‚Äôt see how to even it do it in LLM; it‚Äôs about tracking individuals and their properties (largely?) separately from their kinds, over time. 

if don‚Äôt have an API to dynamically update a cognitive model, it‚Äôs hard to see how to do it."
3534,@GaryMarcus,2022-06-18 16:52:58+00:00,https://twitter.com/GaryMarcus/status/1538203127765037056,@JhendersonIMB exactly! see my discussion of pareidolia here: https://t.co/MxpQMEAeWw
3535,@GaryMarcus,2022-06-18 16:50:37+00:00,https://twitter.com/GaryMarcus/status/1538202534312964096,@KathrynECramer @MadamePratolung and see also https://t.co/cq8x9j12ze
3536,@GaryMarcus,2022-06-18 16:47:28+00:00,https://twitter.com/GaryMarcus/status/1538201742541611009,"‚ÄúIt's got humour, tech and poetry in a perfect mix to smooth you into the weekend.‚Äù ‚Äî@bimedotcom‚Å© 
‚ÄúGenius‚Äù ‚Äî@ShannonVallor‚Å© 
‚ÄúScale It Up!‚Äù ‚Äî‚Å¶Taylor Swift

humor even @plinz, ‚Å¶@ethanCaballero‚Å©, and ‚Å¶@boredyannlecun‚Å© could love. https://t.co/JTgYtUQAFc"
3537,@GaryMarcus,2022-06-18 16:41:04+00:00,https://twitter.com/GaryMarcus/status/1538200133120118784,@KathrynECramer @MadamePratolung but wait where were you correct? what was context?
3538,@GaryMarcus,2022-06-18 16:40:39+00:00,https://twitter.com/GaryMarcus/status/1538200025552986112,"@KathrynECramer @MadamePratolung and because i quote tweeted the more careful explanation i gave earlier, and have written the longer explanation at length"
3539,@GaryMarcus,2022-06-18 16:09:08+00:00,https://twitter.com/GaryMarcus/status/1538192096816795649,@bbenzon @tylercowen @Ted_Underwood it can do me too; the training set is vast. i actually wrote a thread and what it gets (gist) and doesn‚Äôt (serious analysis or new results and coherence)
3540,@GaryMarcus,2022-06-18 16:01:19+00:00,https://twitter.com/GaryMarcus/status/1538190126513213440,"@douglay if you could cross an LLM with a reliable validation through CYC, that would be interesting. neurosymbolic FTW!"
3541,@GaryMarcus,2022-06-18 15:59:56+00:00,https://twitter.com/GaryMarcus/status/1538189782299254784,@BDehbozorgi83 they are particularly poor at dynamically changing information
3542,@GaryMarcus,2022-06-18 15:57:15+00:00,https://twitter.com/GaryMarcus/status/1538189104994603008,@douglay any sort of database of facts that has been vetted in some way would be a good start. that turns out to be surprisingly hard within the large language model approach.
3543,@GaryMarcus,2022-06-18 15:54:24+00:00,https://twitter.com/GaryMarcus/status/1538188389823832066,"@KathrynECramer we need the same for misinfo, which is a large part of what i am calling for. and large language models themselves aren‚Äôt well-suited to the job."
3544,@GaryMarcus,2022-06-18 15:47:24+00:00,https://twitter.com/GaryMarcus/status/1538186624403505152,"@KathrynECramer i am not panicked, i am trying to move people to much needed action (see last half of my tweet)"
3545,@GaryMarcus,2022-06-18 15:46:15+00:00,https://twitter.com/GaryMarcus/status/1538186336334581760,"@KathrynECramer if you don‚Äôt think DeepFakes are about to be a major problem, you are not paying attention."
3546,@GaryMarcus,2022-06-18 15:43:19+00:00,https://twitter.com/GaryMarcus/status/1538185598753640448,@scocio @fakebaldur üò±
3547,@GaryMarcus,2022-06-18 15:41:24+00:00,https://twitter.com/GaryMarcus/status/1538185116945555456,"@mariabustillos that‚Äôs not a counterpoint, it‚Äôs part of the policy we need."
3548,@GaryMarcus,2022-06-18 15:40:53+00:00,https://twitter.com/GaryMarcus/status/1538184986737618944,@KathrynECramer ?
3549,@GaryMarcus,2022-06-18 15:40:33+00:00,https://twitter.com/GaryMarcus/status/1538184902276878336,"@meme_machines and if you want to lie automatically, use GPT-3"
3550,@GaryMarcus,2022-06-18 15:38:18+00:00,https://twitter.com/GaryMarcus/status/1538184336842715138,"@wellingmax has anyone defined symbolic AI? yes. my terms, since 2001, repeated yesterday:"
3551,@GaryMarcus,2022-06-18 15:33:41+00:00,https://twitter.com/GaryMarcus/status/1538183172730462208,@ForbinP they don‚Äôt care if it is a bull in a china shop; still suits their purposes (&amp; they can use humans in the loop as needed)
3552,@GaryMarcus,2022-06-18 15:28:52+00:00,https://twitter.com/GaryMarcus/status/1538181963504201728,@DontsitDJ ? not sure i follow
3553,@GaryMarcus,2022-06-18 15:28:18+00:00,https://twitter.com/GaryMarcus/status/1538181818708463616,@ChristinaBehme4 it was a metaphor :) as explained in (my own tweet) that i quoted immediately below
3554,@GaryMarcus,2022-06-18 15:17:05+00:00,https://twitter.com/GaryMarcus/status/1538178998282248193,"‚ö†Ô∏è A Blunt Warning ‚ö†Ô∏è

AI systems like LamDA and GPT-3 are sociopathic liars with utter indifference to truth, deepfakers with words, every day creating more compelling, more plausible misinformation on demand.

It is imperative that we develop technology &amp; policy to thwart them."
3555,@GaryMarcus,2022-06-18 13:18:21+00:00,https://twitter.com/GaryMarcus/status/1538149118115098624,@Alber_RomGar i will also be writing more about this. so important!
3556,@GaryMarcus,2022-06-18 13:11:46+00:00,https://twitter.com/GaryMarcus/status/1538147458571677698,@FelixHill84 that is a gross misreading of Minsky. have you even read Perceptrons?
3557,@GaryMarcus,2022-06-18 13:04:06+00:00,https://twitter.com/GaryMarcus/status/1538145531142189056,"@IAI_TV @NYUPsych you need to delete this tweet. aguera y arcas is the VP, not the person who was put on leave"
3558,@GaryMarcus,2022-06-18 04:19:08+00:00,https://twitter.com/GaryMarcus/status/1538013419244179457,"that‚Äôs what i have been trying to tell you. these systems confabulate spread misinformation constantly because they have no conception whatsoever of truth. 

*all* they know is the probabilities of word sequences.

everything else is anthropomorphism."
3559,@GaryMarcus,2022-06-17 21:23:45+00:00,https://twitter.com/GaryMarcus/status/1537908882806145025,"@fchollet clearly humans don‚Äôt use exactly the same principles as other primates

see https://t.co/lnr3lD7E1z w @AdamMarblestone"
3560,@GaryMarcus,2022-06-17 21:20:33+00:00,https://twitter.com/GaryMarcus/status/1537908077562765318,"Allen Ginsberg‚Äîwith special guest Taylor Swift!

Poetry for Our AGI Times

""It has been a long, long time since I had this much fun on the internet."" 
-‚Äì ‚Å¶‚Å¶@sl8rv‚Å©

Artificial sentiences under the age of 18 not admitted without an adult. https://t.co/a1oI73e2GK"
3561,@GaryMarcus,2022-06-17 21:13:25+00:00,https://twitter.com/GaryMarcus/status/1537906283407216651,"@bleepbeepbzzz sure but i have emphasized reasoning, outliers, and compositionally from day 1 and these are still where the systems break down."
3562,@GaryMarcus,2022-06-17 20:44:50+00:00,https://twitter.com/GaryMarcus/status/1537899091274784773,It's kind of funny how people keep claiming I have moved the goalposts and I keep pointing to the same damn book I wrote in 2001.
3563,@GaryMarcus,2022-06-17 20:39:57+00:00,https://twitter.com/GaryMarcus/status/1537897862196973568,"@ylecun @csabaveres sure. i gave my terms in the algebraic mind
- operations over variables
- explicit type-token distinction
- structured hierarchical representations"
3564,@GaryMarcus,2022-06-17 20:36:29+00:00,https://twitter.com/GaryMarcus/status/1537896988116545537,"@ylecun @csabaveres right, but the question is - does it need to be symbolically, and as you point out in your essay, if it does need to be symbolically, can you learn what you need, or not?"
3565,@GaryMarcus,2022-06-17 20:26:13+00:00,https://twitter.com/GaryMarcus/status/1537894405448663040,"@ChurchillMic it‚Äôs not my prompt, and only a hint not an answer, but i hope it opens some eyes around relevance, distraction and inference.

the example reminds me a great deal of Jia and @percyliang‚Äôs excellent https://t.co/CSiuDCTfSK"
3566,@GaryMarcus,2022-06-17 20:04:14+00:00,https://twitter.com/GaryMarcus/status/1537888871844675588,"@ChurchillMic it‚Äôs a way of seeing how shallow the comprehension really is. you know, science."
3567,@GaryMarcus,2022-06-17 19:22:06+00:00,https://twitter.com/GaryMarcus/status/1537878270149922816,"indeed since the 50s the question has always been: if there is a difference, what is the difference? do neural nets offer a real alternative? or can they only succeed in reimplementing symbol-manipulation?"
3568,@GaryMarcus,2022-06-17 19:11:23+00:00,https://twitter.com/GaryMarcus/status/1537875573942276097,"@jsm_creative @tejasdkulkarni @GoogleAI a. what were the prompts?
b. did you read Horses Rides Astronauts at https://t.co/8ir1xKvqt6?"
3569,@GaryMarcus,2022-06-17 15:40:01+00:00,https://twitter.com/GaryMarcus/status/1537822382374563845,"@terrible_archer @boazbaraktcs replied above, thanks."
3570,@GaryMarcus,2022-06-17 15:39:36+00:00,https://twitter.com/GaryMarcus/status/1537822275809923073,"@boazbaraktcs @ylecun nonsense. deep learning is still having problems in exactly the areas that i have consistently predicted it would for last 10 years, including compositionality and reasoning."
3571,@GaryMarcus,2022-06-17 13:10:32+00:00,https://twitter.com/GaryMarcus/status/1537784761225072640,"Posting something light and fun and completely different, soon."
3572,@GaryMarcus,2022-06-17 12:46:01+00:00,https://twitter.com/GaryMarcus/status/1537778591500410881,"@fhuszar @DaniloJRezende @unsorsodicorda @jacobmbuckman @slatestarcodex the whole point is that you can‚Äôt assume the data in the wild will be from the same space as the training distribution. if it were, we‚Äôd have solved intelligence. it‚Äôs not, and so we have a problem thus far is unsolved.

the ongoing problems with driverless cars are a clear case."
3573,@GaryMarcus,2022-06-17 12:40:47+00:00,https://twitter.com/GaryMarcus/status/1537777275231383552,So much for free speech?
3574,@GaryMarcus,2022-06-17 04:43:51+00:00,https://twitter.com/GaryMarcus/status/1537657249199378434,"@peterwildeford try all the examples in @togelius‚Äôs thread, and report all?"
3575,@GaryMarcus,2022-06-17 04:42:05+00:00,https://twitter.com/GaryMarcus/status/1537656807698509826,"the hype cycle, revised:
- Big Company releases Big Paper; access to new model is very restricted
- Media extols new model. 
- Enthusiasts declare that Deep Learning Has Crushed a Wall 
- Access broadens
- Problems emerge
- Rinse, with more data, and Repeat"
3576,@GaryMarcus,2022-06-17 04:13:38+00:00,https://twitter.com/GaryMarcus/status/1537649645664362496,is this ‚Ä¶[shudder] ‚Ä¶ prompt engineering  ‚Ä¶ hitting a wall?
3577,@GaryMarcus,2022-06-17 01:54:30+00:00,https://twitter.com/GaryMarcus/status/1537614634076712960,"explaining Blake Lemoine and Lamda over dinner to my 9 year old, and he asks, ‚ÄúIs that like ELIZA?‚Äù"
3578,@GaryMarcus,2022-06-17 01:40:03+00:00,https://twitter.com/GaryMarcus/status/1537610994414825472,this tweet aged pretty well
3579,@GaryMarcus,2022-06-17 01:33:57+00:00,https://twitter.com/GaryMarcus/status/1537609461170569217,recording at link below:
3580,@GaryMarcus,2022-06-17 01:20:57+00:00,https://twitter.com/GaryMarcus/status/1537606189948686336,"thanks @karaswisher and @CaseyNewton for giving @nitashatiku and me a chance to preview some truly new challenges for society. 

&amp; I loved the question about what the right public health response might be for the likely rise of lies from seductive machines!"
3581,@GaryMarcus,2022-06-17 01:10:08+00:00,https://twitter.com/GaryMarcus/status/1537603468650721281,"@bobehayes @karaswisher and @CaseyNewton and @nitashatiku 

great discussion all around"
3582,@GaryMarcus,2022-06-16 23:45:11+00:00,https://twitter.com/GaryMarcus/status/1537582088383176705,@nyttypos @karaswisher @nytopinion @elonmusk @CaseyNewton @nitashatiku @TwitterSpaces the world would be a less interesting place without @karaswisher‚Äôs rebellion
3583,@GaryMarcus,2022-06-16 23:43:50+00:00,https://twitter.com/GaryMarcus/status/1537581748485206016,dueling with @nyttypos as the opening act ü§£
3584,@GaryMarcus,2022-06-16 23:42:22+00:00,https://twitter.com/GaryMarcus/status/1537581381282238469,@nyttypos @karaswisher @nytopinion @elonmusk @CaseyNewton @nitashatiku @TwitterSpaces we can let @karaswisher explain her own choice :) i sensed a little bit of deliberate rebellion in her explanation.
3585,@GaryMarcus,2022-06-16 23:33:02+00:00,https://twitter.com/GaryMarcus/status/1537579032438394880,@karaswisher @nyttypos @nytopinion @elonmusk @CaseyNewton @nitashatiku @TwitterSpaces descriptive linguistics &gt; prescriptive linguistics
3586,@GaryMarcus,2022-06-16 23:12:01+00:00,https://twitter.com/GaryMarcus/status/1537573740439035905,@grbradsk thanks! teachable moment :)
3587,@GaryMarcus,2022-06-16 21:20:37+00:00,https://twitter.com/GaryMarcus/status/1537545705664831488,@DaniloJRezende @unsorsodicorda @jacobmbuckman @slatestarcodex tell us more‚Ä¶
3588,@GaryMarcus,2022-06-16 20:14:58+00:00,https://twitter.com/GaryMarcus/status/1537529185635225600,terrific thread. #deeplearning hit a hexagon
3589,@GaryMarcus,2022-06-16 20:08:36+00:00,https://twitter.com/GaryMarcus/status/1537527583423705089,+1 from other side of the pond
3590,@GaryMarcus,2022-06-16 19:22:52+00:00,https://twitter.com/GaryMarcus/status/1537516075729842176,"@Dr_Cuspy @ylecun i actually wrote about all our similarity a couple days ago and opened our 2017 debate by making the same point. 

that said i do think things we disagree about (not all outlined in this essay) are pretty important, too"
3591,@GaryMarcus,2022-06-16 19:15:53+00:00,https://twitter.com/GaryMarcus/status/1537514316659761152,"@AthenaAI2 @ylecun @Jake_Browning00 yeah and i don‚Äôt really structure the argument that way. it‚Äôs good, it‚Äôs not perfect :)"
3592,@GaryMarcus,2022-06-16 18:59:50+00:00,https://twitter.com/GaryMarcus/status/1537510276185985024,"excellent essay by @ylecun, w @Jake_Browning00, well worth reading, including this clear statement of points of agreement: https://t.co/k05E5apyoQ"
3593,@GaryMarcus,2022-06-16 18:31:46+00:00,https://twitter.com/GaryMarcus/status/1537503216060932096,let that sink in.
3594,@GaryMarcus,2022-06-16 17:38:37+00:00,https://twitter.com/GaryMarcus/status/1537489837111947264,"if you are sentient and have been following LaMDAgate, you should come to this."
3595,@GaryMarcus,2022-06-16 17:37:12+00:00,https://twitter.com/GaryMarcus/status/1537489480646479873,@subjacentish @FelixHill84 @dileeplearning @spiantado @emilymbender that one i know and quoted somewhere
3596,@GaryMarcus,2022-06-16 17:22:23+00:00,https://twitter.com/GaryMarcus/status/1537485751914442752,"This is going to be something special. 

@nitashatiku, who broke the LaMDA ‚Äúsentience‚Äù story at the @washingtonpost, and I (AI scientist &amp; author of the skeptical essay Nonsense on Stilts) are going to talk AI, hype, and tech policy with @karaswisher and @CaseyNewton at 5pm PT."
3597,@GaryMarcus,2022-06-16 17:15:27+00:00,https://twitter.com/GaryMarcus/status/1537484010502295552,@FelixHill84 @subjacentish @dileeplearning @spiantado @emilymbender ?
3598,@GaryMarcus,2022-06-16 17:04:52+00:00,https://twitter.com/GaryMarcus/status/1537481344455823363,@FelixHill84 @subjacentish @dileeplearning @spiantado @emilymbender and yet can‚Äôt even tell me why or how you disagree with Frege?
3599,@GaryMarcus,2022-06-16 16:29:39+00:00,https://twitter.com/GaryMarcus/status/1537472483766304768,"Linguistics was solved same way, a couple weeks earlier. Amazing! 

I think neuroscience is next week."
3600,@GaryMarcus,2022-06-16 16:23:44+00:00,https://twitter.com/GaryMarcus/status/1537470992175419392,"@subjacentish @FelixHill84 @dileeplearning @spiantado @emilymbender could be urban legend, then"
3601,@GaryMarcus,2022-06-16 16:20:06+00:00,https://twitter.com/GaryMarcus/status/1537470077808701441,@SelfDrivingLie @karaswisher I like the idea. it‚Äôs the execution that is harder than most people (myself excluded-I was an early skeptic in 2016) have imagined.
3602,@GaryMarcus,2022-06-16 16:01:29+00:00,https://twitter.com/GaryMarcus/status/1537465395107332097,"@subjacentish @FelixHill84 @dileeplearning @spiantado @emilymbender is the latter a joke, a la the Vision project that he did actually assign? or a documentable true story?"
3603,@GaryMarcus,2022-06-16 16:00:42+00:00,https://twitter.com/GaryMarcus/status/1537465196326686720,"@subjacentish @FelixHill84 @dileeplearning @spiantado @emilymbender not entirely fair ‚Ä¶ but not entirely unfair, either. 

‚ÄúI met Partee at a party once‚Äùndoesn‚Äôt really cut it, and it isn‚Äôt, ‚ÄúI read enough Frege to understand why he is so central to two fields, one in philosophy, the other in linguistics, but i still disagree because X‚Äù, either"
3604,@GaryMarcus,2022-06-16 15:39:05+00:00,https://twitter.com/GaryMarcus/status/1537459758281547776,"Honeybees are amazing. They can also do same-different tasks, and generalize the solar azimuth function to lighting conditions they have never seen. The famous waggle dance is just the start!"
3605,@GaryMarcus,2022-06-16 15:30:25+00:00,https://twitter.com/GaryMarcus/status/1537457577922965506,"@JeffLidz i used Lemoine‚Äôs context to disambiguate. wiki has a nice discussion of the many meanings; he clearly meant the sci-fi-ish consciousness sense, not  has ‚Äúsenses‚Äù by which my Apple Watch would be more sentient than LaMDA."
3606,@GaryMarcus,2022-06-16 14:15:18+00:00,https://twitter.com/GaryMarcus/status/1537438672764563460,"@AndrewLampinen @FelixHill84 @charleswangb @dileeplearning @spiantado @emilymbender @WiringTheBrain @Zergylord i‚Äôve written about those human failures, in the language chapter of Kluge. and yes we will presumably have human norms."
3607,@GaryMarcus,2022-06-16 14:13:28+00:00,https://twitter.com/GaryMarcus/status/1537438211974172672,"@NickRMorgan @jacobmbuckman @slatestarcodex i think active learning is great, just think the blog totally oversold itself."
3608,@GaryMarcus,2022-06-16 14:13:00+00:00,https://twitter.com/GaryMarcus/status/1537438095926104066,@savvyRL @tetraduzione @jacobmbuckman @slatestarcodex On a par with Turing‚Äôs written-only-paper chess computer? ü§£
3609,@GaryMarcus,2022-06-16 14:07:09+00:00,https://twitter.com/GaryMarcus/status/1537436622223921152,"@ksami_ why doesn‚Äôt Roomba qualify, under that? why not the honey bee?"
3610,@GaryMarcus,2022-06-16 13:45:24+00:00,https://twitter.com/GaryMarcus/status/1537431147617038338,@jacobmbuckman @sir_deenicus @slatestarcodex @sirbayes surely we will need improvements to both
3611,@GaryMarcus,2022-06-16 13:42:04+00:00,https://twitter.com/GaryMarcus/status/1537430310492639232,@UrMultimedia and a rock? be sure to give your definitions
3612,@GaryMarcus,2022-06-16 13:36:39+00:00,https://twitter.com/GaryMarcus/status/1537428945095692289,@anilkseth @De_dicto
3613,@GaryMarcus,2022-06-16 13:34:36+00:00,https://twitter.com/GaryMarcus/status/1537428428302913536,Which is more sentient and why? be sure to explain your terms if you comment below
3614,@GaryMarcus,2022-06-16 13:07:12+00:00,https://twitter.com/GaryMarcus/status/1537421536700731393,"@exilefaker you might start by asking whether Roomba is already sentient, and if you think not, why would you think it becomes sentient when you add LaMDA?"
3615,@GaryMarcus,2022-06-16 13:04:36+00:00,https://twitter.com/GaryMarcus/status/1537420880405442561,"@FelixHill84 @charleswangb @dileeplearning @spiantado @emilymbender @WiringTheBrain NLU *is* haunted by a lack of compositionality &amp; reference. it works for some things but always remains shallow &amp; unreliable‚Äîprecisely because those issues are only partly evaded by statistical proxies, as @dileeplearning @emilymbender @charleswangb &amp; I all keep trying to explain"
3616,@GaryMarcus,2022-06-16 12:57:33+00:00,https://twitter.com/GaryMarcus/status/1537419107980615682,"@FelixHill84 @subjacentish @dileeplearning @spiantado @emilymbender don‚Äôt much like the terminology but the fact is that it is baffling how little most of the current NLP community appears to understand the basic issues of reference and compositionality that are familiar to any trained linguist. 

ignoring Frege, Partee etc altogether is just ü§∑‚Äç‚ôÇÔ∏è"
3617,@GaryMarcus,2022-06-16 12:53:44+00:00,https://twitter.com/GaryMarcus/status/1537418144767127552,"@exilefaker maybe so but even if that were so it doesn‚Äôt make LaMDA as Lemoine interacted with it sentient; it would (at most) show that LaMDA could be used as part of a larger system. 

maybe i could use a thermostat inside a sentient system but that doesn‚Äôt mean the thermostat is sentient"
3618,@GaryMarcus,2022-06-16 12:51:13+00:00,https://twitter.com/GaryMarcus/status/1537417513016823808,@exilefaker maybe you should read the seven essays in my substack then? or @emilymbender and Koller?  the argument is certainly out thrrr
3619,@GaryMarcus,2022-06-16 12:47:15+00:00,https://twitter.com/GaryMarcus/status/1537416514776621056,"@exilefaker no, that‚Äôs just evidence of how clueless this disembodied calculator is. the real point is that word prediction by itself just isn‚Äôt sentience and it‚Äôs strings of words have no reference and are just illusions."
3620,@GaryMarcus,2022-06-16 12:45:40+00:00,https://twitter.com/GaryMarcus/status/1537416116535824386,"@exilefaker you have this a little backwards. maybe you could take LaMDA and some others stuff unspecified and get to sentience, but there is just no way LaMDA by itself is either necessary or sufficient for sentience. 

it‚Äôs a much weaker claim to say that maybe you could use it elsewhere."
3621,@GaryMarcus,2022-06-16 12:43:18+00:00,https://twitter.com/GaryMarcus/status/1537415520550461446,"@exilefaker this is the substantive part; what i should have said is ‚Äúthis kind of feature-level pattern matching‚Äù; we don‚Äôt have systems that can pattern match with the subtlety and abstraction of humans, and that‚Äôs the problem."
3622,@GaryMarcus,2022-06-16 12:41:46+00:00,https://twitter.com/GaryMarcus/status/1537415132430540800,"@exilefaker @Google @CNN so are you telling me that LaMDA has quails or that i said that the problem of qualia has been solved, or what?"
3623,@GaryMarcus,2022-06-16 12:38:58+00:00,https://twitter.com/GaryMarcus/status/1537414427774857217,@exilefaker @Google @CNN oh come on; saying that a rock or a spreadsheet isn‚Äôt sentient isn‚Äôt claiming to solve consciousness.
3624,@GaryMarcus,2022-06-16 12:36:50+00:00,https://twitter.com/GaryMarcus/status/1537413894041260032,@FelixHill84 i got distracted by the pandemic but am now resuscitating that project with @Zergylord
3625,@GaryMarcus,2022-06-16 11:48:12+00:00,https://twitter.com/GaryMarcus/status/1537401653170536448,can‚Äôt wait to talk about hype vs reality tonight with the legendary @karaswisher
3626,@GaryMarcus,2022-06-16 11:16:10+00:00,https://twitter.com/GaryMarcus/status/1537393590615220224,@jacobmbuckman @slatestarcodex https://t.co/IsxUhAPhll
3627,@GaryMarcus,2022-06-16 11:15:34+00:00,https://twitter.com/GaryMarcus/status/1537393442132611072,"sorry but that is no excuse. tricking people into thinking you have an argument against me so you will get clicks is suitable for The NY Post, not science. 

this is lame. receipts below. https://t.co/mcgglJ929U"
3628,@GaryMarcus,2022-06-16 11:07:41+00:00,https://twitter.com/GaryMarcus/status/1537391455940907008,"@synbiocs @jacobmbuckman @slatestarcodex yes, but 
- i am blaming it on the variability of the world
- he is blaming it in the size of the internet

more broadly:
- he exaggerated our differences (claiming he had proven me wrong when he knew better) in order to get people to read his thread

üôÑ"
3629,@GaryMarcus,2022-06-16 05:04:17+00:00,https://twitter.com/GaryMarcus/status/1537300007061139456,"@jacobmbuckman @slatestarcodex well then your original tweet was clickbait, no?"
3630,@GaryMarcus,2022-06-16 04:33:59+00:00,https://twitter.com/GaryMarcus/status/1537292379668901888,@eliasbareinboim i spelled out why it is naive in my 2001 book; and @yudapearl does for a lay audience in Book of Why.
3631,@GaryMarcus,2022-06-16 04:00:15+00:00,https://twitter.com/GaryMarcus/status/1537283888598245377,@jacobmbuckman @slatestarcodex not sure i get what you think you proved. a thread:
3632,@GaryMarcus,2022-06-16 03:57:38+00:00,https://twitter.com/GaryMarcus/status/1537283231959027712,"8. In short, I am not sure what the fuss over this thread is about. Maybe someone can explain?"
3633,@GaryMarcus,2022-06-16 03:57:37+00:00,https://twitter.com/GaryMarcus/status/1537283227240775680,"7. A much better thread on scaling, it seems to me, is the from @sirbayes, https://t.co/PEZMKT8inP which argues that for strong generalization, absent infinite data, you need strong *models*. 

I am with him."
3634,@GaryMarcus,2022-06-16 03:57:37+00:00,https://twitter.com/GaryMarcus/status/1537283225948524544,"6. ‚ÄúWhen training a giant language model [on] entire internet, the scope of the patterns [is immense] From basic low-level structure‚Ä¶ to incredibly complex high-level structure like recursively-defined subtasks‚Äù confuses what is *in data* with *what can be learned with an LLM*"
3635,@GaryMarcus,2022-06-16 03:57:36+00:00,https://twitter.com/GaryMarcus/status/1537283224992288769,5. I  doubt scaling will take us all the way to open-end reasoning and comprehension of long discourse; having a bigger Internet would not change that reality that there will always be novelty and outliers.
3636,@GaryMarcus,2022-06-16 03:57:36+00:00,https://twitter.com/GaryMarcus/status/1537283223960424448,"4. There is also not really much of an argument against me since it ignores already-documented empirical failures at scalling observed in BigBench, which presumably pertain to outliers, rather than pure limits on *amount of data*; these are cases where adding data *doesn‚Äôt* help."
3637,@GaryMarcus,2022-06-16 03:57:36+00:00,https://twitter.com/GaryMarcus/status/1537283222794407938,"3. In any given domain,  it  is an *empirical* question when/if lack of unique data will be an issue,  but there are no clear results yet. so if I were @slatestarcodex I wouldn't be immediately worried"
3638,@GaryMarcus,2022-06-16 03:57:35+00:00,https://twitter.com/GaryMarcus/status/1537283221309640705,"2. The choice of example, chess, is odd, given the goal
- in chess  you can actually self-generate as much data as needed
- so thought experiment is not persuasive there"
3639,@GaryMarcus,2022-06-16 03:57:35+00:00,https://twitter.com/GaryMarcus/status/1537283219703312384,"Puzzled as to why this post is gaining traction 
- premise is that scaling will fail because there is not enough data
but what has really been shown here?
üßµ"
3640,@GaryMarcus,2022-06-16 03:16:09+00:00,https://twitter.com/GaryMarcus/status/1537272793716273152,@tdietterich @AndrewLampinen @dileeplearning @peabody124 @spiantado @FelixHill84 @emilymbender in any case at that point you haven‚Äôt generalized the procedure such that you can go off table
3641,@GaryMarcus,2022-06-16 03:10:40+00:00,https://twitter.com/GaryMarcus/status/1537271412339003393,"@tdietterich @AndrewLampinen @dileeplearning @peabody124 @spiantado @FelixHill84 @emilymbender that one seems terminological, and it doesn‚Äôt help with the issue at hand which seems to be at simulation"
3642,@GaryMarcus,2022-06-16 02:12:17+00:00,https://twitter.com/GaryMarcus/status/1537256721218908161,"@AndrewLampinen @dileeplearning @peabody124 @spiantado @FelixHill84 @emilymbender if you predict, perhaps roughly) the outcome of an event (say the result of multiple coin flips) by retrieving the answer from a lookup table, have you meaningfully done simulation?"
3643,@GaryMarcus,2022-06-16 01:38:32+00:00,https://twitter.com/GaryMarcus/status/1537248226272653312,@bbenzon thanks this was so lucid
3644,@GaryMarcus,2022-06-16 01:22:51+00:00,https://twitter.com/GaryMarcus/status/1537244278908329984,"@jacobmbuckman @slatestarcodex If you are interested in these issues, I highly recommend this crystalline distillation from @sirbayes:"
3645,@GaryMarcus,2022-06-16 01:21:37+00:00,https://twitter.com/GaryMarcus/status/1537243967409926144,@sirbayes that‚Äôs not a rant. it‚Äôs truth. gorgeous
3646,@GaryMarcus,2022-06-16 01:20:43+00:00,https://twitter.com/GaryMarcus/status/1537243742289031168,"Outstanding, lucid thread from @sirbayes on why scaling isn‚Äôt likely to be enough‚Äîand why even in the era of massive data we still need to have good underlying models in order to handle outliers and generalize well."
3647,@GaryMarcus,2022-06-15 20:46:00+00:00,https://twitter.com/GaryMarcus/status/1537174609790787585,@Werdnamai and factored in the type of miles driven
3648,@GaryMarcus,2022-06-15 20:44:56+00:00,https://twitter.com/GaryMarcus/status/1537174341044953088,@sirbayes hmm. it was actually written in the 1960s and I have mentioned it many times as an example of the gullibility gap (eg in Nonsense on Stilts and https://t.co/Pt7HZbLIv5) but I don‚Äôt actually love it or pure rules and actually favor hybrid AI.
3649,@GaryMarcus,2022-06-15 20:25:31+00:00,https://twitter.com/GaryMarcus/status/1537169453258919936,@AVMiceliBarone @dileeplearning @AndrewLampinen @peabody124 @spiantado @FelixHill84 @emilymbender absolutely and i make that point often. but (important for this conversation) they do mental models of the world and their language relates to those models
3650,@GaryMarcus,2022-06-15 20:17:50+00:00,https://twitter.com/GaryMarcus/status/1537167519634509824,@PeterJungX this is again why we need a whole lot more data
3651,@GaryMarcus,2022-06-15 18:27:10+00:00,https://twitter.com/GaryMarcus/status/1537139670101790720,"@FelixHill84 @matyi7m @AndrewLampinen @NickRMorgan @dileeplearning @peabody124 @spiantado @emilymbender on the other hand the key pre 1980s ideas, like Frege‚Äôs notion of compositionally inferring the meaning of sentence from its parts, still aren‚Äôt solved. 

(pure) statistical prediction and language understanding: https://t.co/ECKJONYBVi"
3652,@GaryMarcus,2022-06-15 18:13:58+00:00,https://twitter.com/GaryMarcus/status/1537136347370094599,@andrey_kurenkov üò±
3653,@GaryMarcus,2022-06-15 18:02:43+00:00,https://twitter.com/GaryMarcus/status/1537133516860706816,@BrandonLive @Tesla what specifically are you saying is misleading?
3654,@GaryMarcus,2022-06-15 17:48:41+00:00,https://twitter.com/GaryMarcus/status/1537129983356743680,"@BrandonLive if it wasn‚Äôt switched off prior to accidents, and of course they ignores terrain, use case limits etc."
3655,@GaryMarcus,2022-06-15 17:46:55+00:00,https://twitter.com/GaryMarcus/status/1537129539662491649,Real Full-Self Driving is nowhere in sight. Why today‚Äôs new data are problematic for @Tesla and the whole field. https://t.co/Z21HnFYbuw
3656,@GaryMarcus,2022-06-15 16:26:05+00:00,https://twitter.com/GaryMarcus/status/1537109199116566528,essay on all this: https://t.co/udbUPHrV2v
3657,@GaryMarcus,2022-06-15 16:24:27+00:00,https://twitter.com/GaryMarcus/status/1537108787756036097,fuller essay on this: https://t.co/udbUPHrV2v
3658,@GaryMarcus,2022-06-15 16:24:03+00:00,https://twitter.com/GaryMarcus/status/1537108683959652352,@KPieranski @Tesla @elonmusk funny how I am quoting Elon on that part :)
3659,@GaryMarcus,2022-06-15 16:23:31+00:00,https://twitter.com/GaryMarcus/status/1537108549716758530,"@tdietterich @Tesla @elonmusk Well, I am quoting Elon there, and he knows his business better than I.

But I think the issue is that the 100:1 P/E doesn‚Äôt make sense for a regular car company, even with one that is fun to drive.  

And if the stock were to suddenly crash, some of the mystique would be gone."
3660,@GaryMarcus,2022-06-15 16:12:43+00:00,https://twitter.com/GaryMarcus/status/1537105833749647360,"Will @Tesla ever ""Solve"" Driverless Cars?

And will they survive if they don't? 

@elonmusk himself doesn't think so. https://t.co/udbUPHrV2v"
3661,@GaryMarcus,2022-06-15 15:36:30+00:00,https://twitter.com/GaryMarcus/status/1537096720596643840,"Whether you love Tesla or hate it, if you enjoyed my viral ‚ÄúNonsense on Stilts‚Äù take on LaMDA (as covered by CNN, CBC, NPR, etc) please subscribe to https://t.co/8ir1xKvqt6. 

Report coming soon on what today‚Äôs NHTSA‚Äôs data dump means for @tesla and the driverless car industry."
3662,@GaryMarcus,2022-06-15 14:50:12+00:00,https://twitter.com/GaryMarcus/status/1537085067171811328,"@dileeplearning @FelixHill84 @spiantado 100 percent, exactly what @emilymbender and I are also saying, in different words. No connection to the world (what philosophers of language would call reference) no meaning. 

Just games with words at that point."
3663,@GaryMarcus,2022-06-15 14:48:38+00:00,https://twitter.com/GaryMarcus/status/1537084674584940544,"@jonathanrlarkin do you mund maybe reading all my tweets from the last hour, first? I made same points multiple times, just not in this particular tweet."
3664,@GaryMarcus,2022-06-15 14:32:03+00:00,https://twitter.com/GaryMarcus/status/1537080500325523456,"sorry. it doesn‚Äôt help Tesla‚Äôs claim towards genuine FSD if the whole industry is struggling.

rather it reinforces the fact that what has been promised far outstrips what *anybody* can deliver anytime soon."
3665,@GaryMarcus,2022-06-15 14:26:36+00:00,https://twitter.com/GaryMarcus/status/1537079128737734664,@LucaAmb *eventually* the machines might do better
3666,@GaryMarcus,2022-06-15 14:18:52+00:00,https://twitter.com/GaryMarcus/status/1537077182098378752,@BeebsMemes my hot take which asks same questions  and was posted above:
3667,@GaryMarcus,2022-06-15 14:15:07+00:00,https://twitter.com/GaryMarcus/status/1537076239810240513,@EpistemiclyRich ü§£ü§£ü§£
3668,@GaryMarcus,2022-06-15 14:14:31+00:00,https://twitter.com/GaryMarcus/status/1537076088630718465,"3 accidents every 4 days, per new data 

Imagine how many more accidents there would be per day if Tesla‚Äôs ADAS were turned *Fullly* loose in all roads at all times, without driver intervention w millions of vehicles

So much work left to be done"
3669,@GaryMarcus,2022-06-15 14:06:17+00:00,https://twitter.com/GaryMarcus/status/1537074015021305856,"first time i ever thought someone was grossly unfair to Tesla, re data &amp; interpretation 

Tesla has real issue to deal with here, but we can‚Äôt compare the manufacturers directly 

- they have presumably driven most miles 
- criteria may vary from one manufacturer to next"
3670,@GaryMarcus,2022-06-15 14:00:43+00:00,https://twitter.com/GaryMarcus/status/1537072615419916289,hot take on the data:
3671,@GaryMarcus,2022-06-15 13:54:10+00:00,https://twitter.com/GaryMarcus/status/1537070968346095616,"The real takehome here is how *little we still know* &amp; how much more data we need:
- types of miles being driven, speeds, weather, road types, etc
- circumstances in which  accidents occurred
- what kinds incidents are occurring? collisions with pedestrians? stopped vehicles? etc"
3672,@GaryMarcus,2022-06-15 13:54:10+00:00,https://twitter.com/GaryMarcus/status/1537070967335202821,"And none of the between-manufacturer data are probably genuinely comparable, both in terms of standards and types of miles driven
3/4"
3673,@GaryMarcus,2022-06-15 13:54:10+00:00,https://twitter.com/GaryMarcus/status/1537070966194417664,"It‚Äôs actually no surprise that Tesla has the most ADAS crashes (they drive the most miles) but by same token the sheer # of incidents - for a system mainly driven in good weather, well-mapped roads - etc is concerning. 

&amp; other manufacturers are definitely having issues, too
2/4"
3674,@GaryMarcus,2022-06-15 13:54:09+00:00,https://twitter.com/GaryMarcus/status/1537070964508282881,"just wondering, will this figure go in Tesla‚Äôs regular Safety Report?

üßµ https://t.co/npK6Vtvslq"
3675,@GaryMarcus,2022-06-15 13:33:35+00:00,https://twitter.com/GaryMarcus/status/1537065785624887296,New NHTSA data not pretty for Tesla
3676,@GaryMarcus,2022-06-15 03:36:28+00:00,https://twitter.com/GaryMarcus/status/1536915515288850433,@spiantado oh sorry i misparsed your sentence in haste
3677,@GaryMarcus,2022-06-15 03:09:46+00:00,https://twitter.com/GaryMarcus/status/1536908798996017152,@charleswangb @dileeplearning @spiantado totally he primed you to think it was real‚Ä¶.
3678,@GaryMarcus,2022-06-15 02:46:39+00:00,https://twitter.com/GaryMarcus/status/1536902979814469632,@srikumarks @charleswangb @dileeplearning @spiantado one man‚Äôs joke is another‚Äôs delusion
3679,@GaryMarcus,2022-06-15 02:30:16+00:00,https://twitter.com/GaryMarcus/status/1536898856650035200,@charleswangb @dileeplearning @spiantado Ethan was kidding there but overall i agree
3680,@GaryMarcus,2022-06-15 02:17:48+00:00,https://twitter.com/GaryMarcus/status/1536895720841629696,@dileeplearning @spiantado @dileeplearning are making the same point
3681,@GaryMarcus,2022-06-15 02:15:54+00:00,https://twitter.com/GaryMarcus/status/1536895240254070784,Fixed that for you https://t.co/4a8liJlmS6
3682,@GaryMarcus,2022-06-15 02:12:32+00:00,https://twitter.com/GaryMarcus/status/1536894396846575616,@spiantado so does my iPhone‚Äôs autocomplete have conceptual role semantics?
3683,@GaryMarcus,2022-06-15 01:44:25+00:00,https://twitter.com/GaryMarcus/status/1536887319327674368,Say how you really feel https://t.co/U8KD7JJtZM
3684,@GaryMarcus,2022-06-15 01:40:39+00:00,https://twitter.com/GaryMarcus/status/1536886372652290048,"@spiantado I agree with Bender and Koller that reference is essential, and that it is lacking in LLMs"
3685,@GaryMarcus,2022-06-15 01:39:38+00:00,https://twitter.com/GaryMarcus/status/1536886114471903233,"@spiantado Note that you could draw the same kind of clustering figure by doing multidimensional scaling on the underlying representations on any autocomplete system (eg on the soft keyboard on my iPhone). 

Would you say that your autocomplete system is sentient, too, by parity of reason?"
3686,@GaryMarcus,2022-06-14 22:15:37+00:00,https://twitter.com/GaryMarcus/status/1536834771409522688,@tegmark i initially mistagged you but a lot of are curious to hear more
3687,@GaryMarcus,2022-06-14 22:01:43+00:00,https://twitter.com/GaryMarcus/status/1536831273511006208,"@pmddomingos true observation, but applies to women too."
3688,@GaryMarcus,2022-06-14 20:09:51+00:00,https://twitter.com/GaryMarcus/status/1536803122143588352,@erikbryn @atangibletruth @cajundiscordian @percyliang @sapinker @StanfordHAI @DigEconLab @pmddomingos @deaneckles @JeffDean @elonmusk https://t.co/LnlBzouQD6
3689,@GaryMarcus,2022-06-14 19:57:39+00:00,https://twitter.com/GaryMarcus/status/1536800052059901952,So so true: until we get the right autonomous driving data (which is something scientists ought be involved in defining) ‚Äúit's just going to be cheerleading + hot takes‚Äù
3690,@GaryMarcus,2022-06-14 19:40:55+00:00,https://twitter.com/GaryMarcus/status/1536795841083473920,@marc_lepage @NGaylinn @karaswisher so say we all
3691,@GaryMarcus,2022-06-14 19:40:40+00:00,https://twitter.com/GaryMarcus/status/1536795778009616384,About time I run for political office ü§£ü§£
3692,@GaryMarcus,2022-06-14 18:22:23+00:00,https://twitter.com/GaryMarcus/status/1536776077535633408,@dutchlight360 @MaxTegmark ü§£
3693,@GaryMarcus,2022-06-14 18:04:31+00:00,https://twitter.com/GaryMarcus/status/1536771580629356544,"@fchollet it was one year away in 2015, according to Musk, link in my recent Fortune article w @wadhwa"
3694,@GaryMarcus,2022-06-14 18:00:09+00:00,https://twitter.com/GaryMarcus/status/1536770480803172354,@BrandonLive @HappyAar are you accusing NHTSA of lying?
3695,@GaryMarcus,2022-06-14 17:58:25+00:00,https://twitter.com/GaryMarcus/status/1536770044801101824,@mrgreene1977 exactly why i mentioned pareidolia
3696,@GaryMarcus,2022-06-14 17:56:17+00:00,https://twitter.com/GaryMarcus/status/1536769509024878592,"@fredbenenson @scottiev Thee main issues: confounding (very serious, eg age of fleet), criteria (eg what is being measure) and inadequate data disclosure (also very serious). 

In the end we really don‚Äôt know how safe current systems are, but we do know that the manufacturers have not very forthcoming."
3697,@GaryMarcus,2022-06-14 17:52:52+00:00,https://twitter.com/GaryMarcus/status/1536768648332730368,@karaswisher another fun topic is how much things have and haven‚Äôt changed over the years‚Ä¶
3698,@GaryMarcus,2022-06-14 17:49:46+00:00,https://twitter.com/GaryMarcus/status/1536767867512713216,"Hey ‚Å¶@MaxTegmark‚Å© do you really believe what is attributed to you here?

If yes, can you explain your reasoning? Very much at odds with most of the rest of us here in the AI community.  https://t.co/SHRn2hQbnU"
3699,@GaryMarcus,2022-06-14 17:43:56+00:00,https://twitter.com/GaryMarcus/status/1536766403461537792,"ü§îhttps://t.co/Pt7HZbLIv5 certainly could use an update

Then again, for all the hype since 2019, I don‚Äôt think our basic conclusions would change much. 

The problems we emphasized there still need solving.
üëâcommonsense (including ethics)
üëâcognitive models
üëâcompositionality"
3700,@GaryMarcus,2022-06-14 17:39:46+00:00,https://twitter.com/GaryMarcus/status/1536765354831056897,"@BrandonLive I read them, and the material question remains the question I raised."
3701,@GaryMarcus,2022-06-14 17:37:50+00:00,https://twitter.com/GaryMarcus/status/1536764866710474753,@BrandonLive not sure what the specific referent to the word ‚ÄúThis‚Äù is in your first sentence. the NHTSA does says autopilot aborted before accident. upon checking w sources this seems to have been suspected for a while. so the material issue is then how Tesla reported the data in those cases
3702,@GaryMarcus,2022-06-14 17:18:39+00:00,https://twitter.com/GaryMarcus/status/1536760039322464258,@Natosongs @scottmccloud might be where i learned the word; what a great book!
3703,@GaryMarcus,2022-06-14 17:18:04+00:00,https://twitter.com/GaryMarcus/status/1536759891221614592,@fredbenenson @scottiev don‚Äôt think that time is going to bear our your optimism here‚Ä¶
3704,@GaryMarcus,2022-06-14 16:52:29+00:00,https://twitter.com/GaryMarcus/status/1536753452671377410,@fredbenenson @scottiev Is there another side to the story? It‚Äôs really really bad if true.
3705,@GaryMarcus,2022-06-14 16:50:36+00:00,https://twitter.com/GaryMarcus/status/1536752979344183297,"@ChrSzegedy @umuti5ik @MelMitchell1 @ChrSzegedy, @ErnestSDavis and I have been trying to reach you to iron our bet with you"
3706,@GaryMarcus,2022-06-14 16:46:54+00:00,https://twitter.com/GaryMarcus/status/1536752047969538049,"@theharryshearer @FelixHill84 @GurbaxaniVijay @erikbryn @cajundiscordian @percyliang @sapinker @StanfordHAI @DigEconLab @pmddomingos @deaneckles @JeffDean @elonmusk from my last gig on your crew, in NoLA with @RealSnarkyPuppy ‚ù§Ô∏è https://t.co/IGWGKWSnej"
3707,@GaryMarcus,2022-06-14 15:56:16+00:00,https://twitter.com/GaryMarcus/status/1536739305153908736,Holy shit.
3708,@GaryMarcus,2022-06-14 15:50:02+00:00,https://twitter.com/GaryMarcus/status/1536737735595245568,@FelixHill84 @GurbaxaniVijay @erikbryn @cajundiscordian @percyliang @sapinker @StanfordHAI @DigEconLab @pmddomingos @deaneckles @JeffDean @elonmusk @theharryshearer @theharryshearer can you post a link to the episode of Le Show that we did together? I will always be your roadie.
3709,@GaryMarcus,2022-06-14 15:47:38+00:00,https://twitter.com/GaryMarcus/status/1536737135398555649,@qhardy @nypost https://t.co/yTSbN6wan7
3710,@GaryMarcus,2022-06-14 15:47:23+00:00,https://twitter.com/GaryMarcus/status/1536737071129210883,update: the reporter found what he needed:
3711,@GaryMarcus,2022-06-14 15:45:25+00:00,https://twitter.com/GaryMarcus/status/1536736576549494786,@rasbt @nypost https://t.co/yTSbN6wan7
3712,@GaryMarcus,2022-06-14 15:42:19+00:00,https://twitter.com/GaryMarcus/status/1536735793577725952,"@rasbt @nypost you were spot (changing Marcus who would never say such a thing to Tegmark, who did)"
3713,@GaryMarcus,2022-06-14 15:41:38+00:00,https://twitter.com/GaryMarcus/status/1536735625272995840,"This would be terrifying LaMDA satire. Except  it is not. 

@rasbt predicted the actual news story almost perfectly, except that I refused to give the reporter what he wanted‚Äîso reporter got what he needed from Max Tegmark instead: https://t.co/SHRn2hQbnU"
3714,@GaryMarcus,2022-06-14 15:35:24+00:00,https://twitter.com/GaryMarcus/status/1536734053855940608,@MikePFrank @sir_deenicus @anilkseth @berent_iris @NatRevNeurosci depends on the problem. eg: https://t.co/x1imE5bPOG
3715,@GaryMarcus,2022-06-14 15:24:41+00:00,https://twitter.com/GaryMarcus/status/1536731356717150209,"‚ÄúI'm still waiting, I-I-I'm still waiting 
I'm still waiting, I-I-I'm still waiting‚Äù
- Talking Heads

https://t.co/auJsZYPya3"
3716,@GaryMarcus,2022-06-14 15:19:58+00:00,https://twitter.com/GaryMarcus/status/1536730170999984129,"We may not be Gilbert and Sullivan but ‚Ä¶ 

coming soon ‚Ä¶

Marcus and @sl8rv Victoroff

Subscribe to https://t.co/8ir1xKvqt6 to be first to receive their collected works, for the low low price of nothing at all. https://t.co/AUA1toPONS"
3717,@GaryMarcus,2022-06-14 15:14:24+00:00,https://twitter.com/GaryMarcus/status/1536728768370425857,@Waterlord @desselebrada @sl8rv ok contest is already over but you win :) DM me for a sneak preview‚Ä¶
3718,@GaryMarcus,2022-06-14 15:13:47+00:00,https://twitter.com/GaryMarcus/status/1536728615039008768,@rasbt @nypost actually i didn‚Äôt think the of words ‚Äúcrystal ball‚Äù til I hung up the phone and thought of how *disappointed* the reporter was  but I did use it in the next interview ü§£
3719,@GaryMarcus,2022-06-14 15:05:26+00:00,https://twitter.com/GaryMarcus/status/1536726511960543232,"update: we got so many volunteers in the first minutes that we don‚Äôt need any more. wow, Twitterverse, thank you!"
3720,@GaryMarcus,2022-06-14 15:05:15+00:00,https://twitter.com/GaryMarcus/status/1536726467995766784,"update: we got so many volunteers in the first minutes that we don‚Äôt need any more. wow, Twitterverse, thank you!"
3721,@GaryMarcus,2022-06-14 15:01:15+00:00,https://twitter.com/GaryMarcus/status/1536725459483824128,I have a love/hate relationship with Twitter. Today is all love.
3722,@GaryMarcus,2022-06-14 14:56:44+00:00,https://twitter.com/GaryMarcus/status/1536724324358377472,@rasbt @nypost and of course I didn‚Äôt say they would!
3723,@GaryMarcus,2022-06-14 14:56:03+00:00,https://twitter.com/GaryMarcus/status/1536724152542932998,@rasbt @nypost i should make sure that didn‚Äôt actually happen.
3724,@GaryMarcus,2022-06-14 14:49:31+00:00,https://twitter.com/GaryMarcus/status/1536722509663305728,@sethjuarez @sl8rv DM‚Äôing you!
3725,@GaryMarcus,2022-06-14 14:48:11+00:00,https://twitter.com/GaryMarcus/status/1536722172202258432,DM‚Äôs are open for someone who wants to volunteer for this 5 minute project
3726,@GaryMarcus,2022-06-14 14:46:13+00:00,https://twitter.com/GaryMarcus/status/1536721679438688258,"Wanted: native spanish speaker with a knowledge of AI and a love for popular music, for a very brief mission that is a secret to everyone except me and @sl8rv"
3727,@GaryMarcus,2022-06-14 14:32:20+00:00,https://twitter.com/GaryMarcus/status/1536718185172377601,@joshu @karaswisher thanks for setting the bar low @joshu (&amp; GPT-3!) ü§£
3728,@GaryMarcus,2022-06-14 14:17:48+00:00,https://twitter.com/GaryMarcus/status/1536714525705048065,@kristintynski @tmalsburg @obedisae @stefanomaggi @cajundiscordian @cajundiscordian you probably saw my critique but I do agree w @kristintynski above.
3729,@GaryMarcus,2022-06-14 14:15:11+00:00,https://twitter.com/GaryMarcus/status/1536713868558274560,"Thursday at 8pm ET @karaswisher and I are going to be talking here on Twitter Spaces, and I think it‚Äôs going to be amazing‚Äîexactly the conversation about Tech, hype, and transparency that I‚Äôve wanting to have. 

Excerpt of our live, public pre-game planning: https://t.co/xZdfxNpjst"
3730,@GaryMarcus,2022-06-14 14:10:07+00:00,https://twitter.com/GaryMarcus/status/1536712594274148353,@karaswisher the hesitance of big tech to open their demoware for inspection is perhaps also a topic for our discussion
3731,@GaryMarcus,2022-06-14 13:42:58+00:00,https://twitter.com/GaryMarcus/status/1536705760540778497,@atbolsh @karaswisher over @GoogleAI‚Äôs dead body?
3732,@GaryMarcus,2022-06-14 13:42:31+00:00,https://twitter.com/GaryMarcus/status/1536705646971695105,"This totally made my day, maybe my year ‚ù§Ô∏è"
3733,@GaryMarcus,2022-06-14 13:41:10+00:00,https://twitter.com/GaryMarcus/status/1536705306373173249,@kristintynski @tmalsburg @obedisae @stefanomaggi @cajundiscordian on that we can agree
3734,@GaryMarcus,2022-06-14 13:21:25+00:00,https://twitter.com/GaryMarcus/status/1536700337385484288,"@MikePFrank @berent_iris @anilkseth‚Äôs book and recent review (i forget where it was).

but i think that consciousness is a separate question (to some degre) from whether we do anything beyond pure statistics"
3735,@GaryMarcus,2022-06-14 13:15:13+00:00,https://twitter.com/GaryMarcus/status/1536698776735186945,"@kristintynski @obedisae @stefanomaggi @cajundiscordian honestly, who cares if a LamDA passes a meaningless but Turing famous benchmark that designed before computers were widespread that is easily faked and that and already was arguably beaten in 2014 before‚Äîby a system nearly everyone has forgotten?"
3736,@GaryMarcus,2022-06-14 13:04:35+00:00,https://twitter.com/GaryMarcus/status/1536696099464806401,"@MikePFrank because i spent the first decade of my career studying that question. some highlights:
- 1992 SRCD Monograph
- 1995 Cognitive Psychology
- 1999 Science
- 2001 book The Algebraic Mind
- 2002 with @berent_iris in Cognition"
3737,@GaryMarcus,2022-06-14 13:00:55+00:00,https://twitter.com/GaryMarcus/status/1536695176202072064,@kristintynski @obedisae @stefanomaggi @cajundiscordian you really ought read the 2014 New Yorker article I wrote on the Turing Test / linked and discussed in Nonsense on Stilts at https://t.co/utfCyRHZPn
3738,@GaryMarcus,2022-06-14 12:42:38+00:00,https://twitter.com/GaryMarcus/status/1536690578313818113,@karaswisher @AI_4_Healthcare @sciam https://t.co/xiNdaW6Nhd
3739,@GaryMarcus,2022-06-14 12:38:13+00:00,https://twitter.com/GaryMarcus/status/1536689466575753217,@karaswisher @AI_4_Healthcare @sciam from my book https://t.co/Pt7HZbLIv5 (1/2): https://t.co/kPNDfIjsdF
3740,@GaryMarcus,2022-06-14 12:32:53+00:00,https://twitter.com/GaryMarcus/status/1536688122393530371,"@AI_4_Healthcare @sciam @karaswisher and an essay  by @mrgreene1977 about the bet to Musk with appropriate animal imagery ü§£

https://t.co/DSsWkMgrjG"
3741,@GaryMarcus,2022-06-14 12:27:46+00:00,https://twitter.com/GaryMarcus/status/1536686837032398849,"@AI_4_Healthcare @sciam @karaswisher related on the larger issues of hype and AI fantasy (&amp; see also the rest of https://t.co/8ir1xKvqt6 including discussion w Noam Chomsky and a bet I proposed to Elon, now $500k)"
3742,@GaryMarcus,2022-06-14 12:24:08+00:00,https://twitter.com/GaryMarcus/status/1536685922627899399,@karaswisher thanks @karaswisher! that means a lot coming from you!
3743,@GaryMarcus,2022-06-14 02:22:25+00:00,https://twitter.com/GaryMarcus/status/1536534495678980096,@togelius @emilymbender
3744,@GaryMarcus,2022-06-14 02:21:01+00:00,https://twitter.com/GaryMarcus/status/1536534141096710144,this dog being Nipper:
3745,@GaryMarcus,2022-06-14 02:20:05+00:00,https://twitter.com/GaryMarcus/status/1536533906022756353,i have to assume that 11% here were joking. Nipper is not pleased.
3746,@GaryMarcus,2022-06-14 00:56:14+00:00,https://twitter.com/GaryMarcus/status/1536512804852707328,don‚Äôt know why I never noticed this restaurant before https://t.co/d3slTAa5I6
3747,@GaryMarcus,2022-06-14 00:28:16+00:00,https://twitter.com/GaryMarcus/status/1536505767574093824,"you saw (or should see) the netflix show, sex education, now read about a real life version. 

kids stepping up,where grown-ups fail them."
3748,@GaryMarcus,2022-06-13 23:33:09+00:00,https://twitter.com/GaryMarcus/status/1536491898311004168,@DrMJoyner @ACasadevall1 @DavidEpstein @sweatscience @NAChristakis @cragcrest @lindsaycrouse @JoNel_Aleccia @JonathanLWai the story is a little overwrought but i think that kind of network analysis is true for many things
3749,@GaryMarcus,2022-06-13 23:20:16+00:00,https://twitter.com/GaryMarcus/status/1536488656650883072,"@amyalkon @slatestarcodex already saw - i subscribe! 

his and @Noahpinion were the first two I signed up for when I joined Substack in May."
3750,@GaryMarcus,2022-06-13 23:17:49+00:00,https://twitter.com/GaryMarcus/status/1536488039706509312,"remember how yesterday i said that academia had its own problems? 

this is a great report on one: the all-too often cumbersome process of spinning out companies from academic research.

we need our academies, but (many of) our academies need to do better"
3751,@GaryMarcus,2022-06-13 21:07:08+00:00,https://twitter.com/GaryMarcus/status/1536455148699983872,@pavel_soukenik @nypost the ball refuses to confirm or deny
3752,@GaryMarcus,2022-06-13 20:21:01+00:00,https://twitter.com/GaryMarcus/status/1536443546449764352,"@tyrell_turing steve cohen, owner of the Mets, inspiration for the show Billionaires, might like a word with you: https://t.co/MHG5LtXvHt"
3753,@GaryMarcus,2022-06-13 20:03:54+00:00,https://twitter.com/GaryMarcus/status/1536439237439959040,links to the series:
3754,@GaryMarcus,2022-06-13 20:03:04+00:00,https://twitter.com/GaryMarcus/status/1536439026340638721,"Judging by my experience this morning as interviewee, @sinanaral‚Äôs new The Digital Insider is going to be w fantastic series, with deep conversations about technology, ethics and more. First guest was @mariaressa!

Honored to be part of it. will post a link when our episode is up"
3755,@GaryMarcus,2022-06-13 19:43:20+00:00,https://twitter.com/GaryMarcus/status/1536434062641876992,"@Sams_Antics funny that; the word actually gets used in a lot of ways, see eg discussion here https://t.co/G5pbb0xnle"
3756,@GaryMarcus,2022-06-13 19:13:08+00:00,https://twitter.com/GaryMarcus/status/1536426462252658688,"@tyrell_turing give or take some hallucinogens? 

there must be a confidence interval in here somewhere"
3757,@GaryMarcus,2022-06-13 19:11:09+00:00,https://twitter.com/GaryMarcus/status/1536425960651640832,"important reminder, from the world‚Äôs most eminent philosophers of mind to another (with me cc‚Äôd for the ride)"
3758,@GaryMarcus,2022-06-13 18:40:31+00:00,https://twitter.com/GaryMarcus/status/1536418254914060288,"The @nypost reporter I just spoke to seem very disappointed that I couldn‚Äôt tell him when (if ever) machines would have feelings. 

I told him my crystal ball just didn‚Äôt look out that far."
3759,@GaryMarcus,2022-06-13 14:37:13+00:00,https://twitter.com/GaryMarcus/status/1536357024383893505,@sir_deenicus @Miles_Brundage @rachelmetz @kristintynski @timnitGebru @ilyasut @sir_deenicus‚Äôs analysis is (as so often) close to my own
3760,@GaryMarcus,2022-06-13 14:20:52+00:00,https://twitter.com/GaryMarcus/status/1536352910153379840,"ELIZA (1965) &amp; LaMDA (2022): case studies in human gullibility, almost 60 years apart. Check out the video!"
3761,@GaryMarcus,2022-06-13 14:15:30+00:00,https://twitter.com/GaryMarcus/status/1536351560380272640,@BugRib think how your sandwich feels :)
3762,@GaryMarcus,2022-06-13 14:06:43+00:00,https://twitter.com/GaryMarcus/status/1536349348828655616,"Indeed, I referenced the fabulous and to-the-point @abebab not once but twice this weekend (on different topics, hype and the perils of webscraping), in my two most recent essays (https://t.co/8ir1xKvqt6).

Everyone interested in AI should follow her."
3763,@GaryMarcus,2022-06-13 13:19:31+00:00,https://twitter.com/GaryMarcus/status/1536337469766963203,"@cameronjbuckner see my pair of replies to this essay at https://t.co/8ir1xKvqt6, fyi"
3764,@GaryMarcus,2022-06-13 12:42:33+00:00,https://twitter.com/GaryMarcus/status/1536328169912823809,"looking forward to this. @elonmusk, feel free to join in and get to know Twitter Spaces better! :)"
3765,@GaryMarcus,2022-06-13 04:37:23+00:00,https://twitter.com/GaryMarcus/status/1536206072830078976,@hardmaru https://t.co/lHQCXYG43P
3766,@GaryMarcus,2022-06-13 03:40:06+00:00,https://twitter.com/GaryMarcus/status/1536191653991440384,@MaximZiatdinov never seen the same weapons-grade PR from a university
3767,@GaryMarcus,2022-06-13 03:32:40+00:00,https://twitter.com/GaryMarcus/status/1536189784921477120,"Hitchhikers‚Äô Guide: The ultimate answer, says the ultimate computer, Deep Thought, is 42

2022-vintage AI, like GPT-3 &amp; LaMDA: To live is‚Ä¶ to bullshit"
3768,@GaryMarcus,2022-06-13 03:20:19+00:00,https://twitter.com/GaryMarcus/status/1536186676044648449,"No, seriously. Could you find a better description of what large language models like LaMDA and GPT-3 do than this? https://t.co/S8ZUhB1LUJ"
3769,@GaryMarcus,2022-06-13 03:05:46+00:00,https://twitter.com/GaryMarcus/status/1536183015264514048,@grvsmth https://t.co/tpQDLQmN4K
3770,@GaryMarcus,2022-06-13 01:09:01+00:00,https://twitter.com/GaryMarcus/status/1536153636547350529,in agreement w @emilymbender‚Äôs : https://t.co/gIN0NzxK5d
3771,@GaryMarcus,2022-06-13 01:06:12+00:00,https://twitter.com/GaryMarcus/status/1536152927034716161,How it started and how it is going: https://t.co/0PAGOLVYLN
3772,@GaryMarcus,2022-06-13 01:04:33+00:00,https://twitter.com/GaryMarcus/status/1536152512096395264,@timnitGebru @kristintynski @ilyasut @Miles_Brundage not every man believes this stuff. you and @emilycbender really ought to consider that on this i am fully on your side and cite you both often (eg yesterday) and yet you guys never ever acknowledge that i have made many related points.
3773,@GaryMarcus,2022-06-13 01:01:38+00:00,https://twitter.com/GaryMarcus/status/1536151777363382272,@Miles_Brundage @rachelmetz @kristintynski @timnitGebru @ilyasut c‚Äômon miles. it can‚Äôt help when OAI says stuff like this:
3774,@GaryMarcus,2022-06-13 00:59:08+00:00,https://twitter.com/GaryMarcus/status/1536151148175888384,@emilymbender see how i framed things in my essay Nonsense on Stilts‚Ä¶
3775,@GaryMarcus,2022-06-13 00:57:48+00:00,https://twitter.com/GaryMarcus/status/1536150812795121664,"we should all worry about this graph.  

academia has its problems but I have never seen anything like the current AI/ML monoculture.

the movement from a peer-reviewed academic culture to a corporate, resource-intensive, hype-driven culture is likely partly responsible."
3776,@GaryMarcus,2022-06-13 00:52:16+00:00,https://twitter.com/GaryMarcus/status/1536149419908771840,@haydenfield @timnitGebru @mmitchell_ai @emilymbender And one more:
3777,@GaryMarcus,2022-06-13 00:17:45+00:00,https://twitter.com/GaryMarcus/status/1536140731928104960,@nitashatiku https://t.co/lHQCXYG43P
3778,@GaryMarcus,2022-06-12 23:46:16+00:00,https://twitter.com/GaryMarcus/status/1536132811899428866,@amcafee @catehall i answered here:
3779,@GaryMarcus,2022-06-12 23:22:35+00:00,https://twitter.com/GaryMarcus/status/1536126850539433985,@catehall @AmandaAskell LaMDA clearly doesn‚Äôt meet the tests in the following paragraph so the argument in the initial paragraph isn‚Äôt really applicable to the current situation.
3780,@GaryMarcus,2022-06-12 22:56:04+00:00,https://twitter.com/GaryMarcus/status/1536120178445996032,@robansuini @rogerkmoore
3781,@GaryMarcus,2022-06-12 22:40:43+00:00,https://twitter.com/GaryMarcus/status/1536116313768087552,@ForbinP typos soon; that‚Äôs a good catch
3782,@GaryMarcus,2022-06-12 22:35:31+00:00,https://twitter.com/GaryMarcus/status/1536115007091400704,@williamstome @damienstanton ernie davis and i may have been first to call ‚Äúbullshit‚Äù near end of this essay: https://t.co/52Sg3GMioL
3783,@GaryMarcus,2022-06-12 21:59:48+00:00,https://twitter.com/GaryMarcus/status/1536106018345713664,@GurbaxaniVijay @erikbryn @cajundiscordian @percyliang @sapinker @StanfordHAI @DigEconLab @pmddomingos @deaneckles @JeffDean @elonmusk who has more sentience? a poll inspired by @theharryshearer
3784,@GaryMarcus,2022-06-12 21:53:36+00:00,https://twitter.com/GaryMarcus/status/1536104456256897025,"@davidad LaMDA doesn‚Äôt merit rights any more than Microsoft Excel (&amp; @SumitGulwani knows how much I admire Flash-Fill, but even so)"
3785,@GaryMarcus,2022-06-12 21:39:50+00:00,https://twitter.com/GaryMarcus/status/1536100991484968962,@seanmcarroll
3786,@GaryMarcus,2022-06-12 21:36:02+00:00,https://twitter.com/GaryMarcus/status/1536100034952974336,"@omaruddin trump pardoned that engineer, for the record. (true story!)"
3787,@GaryMarcus,2022-06-12 21:06:19+00:00,https://twitter.com/GaryMarcus/status/1536092558161432576,@fromawell @omaruddin sure!
3788,@GaryMarcus,2022-06-12 21:06:09+00:00,https://twitter.com/GaryMarcus/status/1536092513617907712,@rachelpurpel or so it will tell you!
3789,@GaryMarcus,2022-06-12 21:05:46+00:00,https://twitter.com/GaryMarcus/status/1536092419254390784,"@fromawell @amyalkon it all went in a blur, but am kind of proud of writing that line on 60 min deadline :)"
3790,@GaryMarcus,2022-06-12 21:02:44+00:00,https://twitter.com/GaryMarcus/status/1536091656218238977,@damienstanton should put that here; more polite than the words I used :)
3791,@GaryMarcus,2022-06-12 21:01:29+00:00,https://twitter.com/GaryMarcus/status/1536091342241091585,@jadelgador just added to my Nonsense on Stilts substack :)
3792,@GaryMarcus,2022-06-12 21:00:20+00:00,https://twitter.com/GaryMarcus/status/1536091049965125632,@hangingnoodles quoted here!: https://t.co/jB1741HNNO
3793,@GaryMarcus,2022-06-12 20:59:51+00:00,https://twitter.com/GaryMarcus/status/1536090928921817088,@MathieuVVyve @ImageSnippets https://t.co/jB1741HNNO
3794,@GaryMarcus,2022-06-12 20:58:56+00:00,https://twitter.com/GaryMarcus/status/1536090699673653248,"@MFordFuture @cajundiscordian new essay, partly prompted by these queries: https://t.co/jB1741HNNO"
3795,@GaryMarcus,2022-06-12 20:58:07+00:00,https://twitter.com/GaryMarcus/status/1536090492378615808,@erikbryn @cajundiscordian @percyliang @sapinker @StanfordHAI @DigEconLab @pmddomingos @deaneckles @JeffDean @elonmusk love this quote so much I made it the center of this:
3796,@GaryMarcus,2022-06-12 20:57:40+00:00,https://twitter.com/GaryMarcus/status/1536090380206084096,extended this point to here:
3797,@GaryMarcus,2022-06-12 20:57:16+00:00,https://twitter.com/GaryMarcus/status/1536090279941242885,"@d_p_gonz indeed, and see"
3798,@GaryMarcus,2022-06-12 20:56:58+00:00,https://twitter.com/GaryMarcus/status/1536090203110068225,"@matyi7m @ImageSnippets quoted this tweet here, cc @o_guest"
3799,@GaryMarcus,2022-06-12 20:56:31+00:00,https://twitter.com/GaryMarcus/status/1536090092149780481,@enemiesnet here it is
3800,@GaryMarcus,2022-06-12 20:56:16+00:00,https://twitter.com/GaryMarcus/status/1536090026609479680,@leonpalafox and see
3801,@GaryMarcus,2022-06-12 20:55:59+00:00,https://twitter.com/GaryMarcus/status/1536089958384926720,@amyalkon here it is as promised:
3802,@GaryMarcus,2022-06-12 20:55:33+00:00,https://twitter.com/GaryMarcus/status/1536089847550447616,@PTonRock https://t.co/lHQCXYG43P
3803,@GaryMarcus,2022-06-12 20:55:10+00:00,https://twitter.com/GaryMarcus/status/1536089749634461696,"@fromawell @randomhuman842 just answered that, here:"
3804,@GaryMarcus,2022-06-12 20:51:02+00:00,https://twitter.com/GaryMarcus/status/1536088710780887040,"@PaulTopping nice quote, added to my essay"
3805,@GaryMarcus,2022-06-12 20:48:33+00:00,https://twitter.com/GaryMarcus/status/1536088086261551105,@PaulTopping indeed; here‚Äôs my take
3806,@GaryMarcus,2022-06-12 20:48:09+00:00,https://twitter.com/GaryMarcus/status/1536087983824044032,here it is:
3807,@GaryMarcus,2022-06-12 20:45:27+00:00,https://twitter.com/GaryMarcus/status/1536087307266101248,with quotes from @Abebab @erikbryn @tdietterich
3808,@GaryMarcus,2022-06-12 20:45:27+00:00,https://twitter.com/GaryMarcus/status/1536087306062352384,"Nonsense on Stilts. 

A hot take on all this ‚ÄúOMG. LaMDA is Sentient‚Äù mania‚Äîand why the AI community is pretty united on this one.
https://t.co/4IzUh35y9n"
3809,@GaryMarcus,2022-06-12 20:15:15+00:00,https://twitter.com/GaryMarcus/status/1536079704779677696,@amyalkon it‚Äôs so stupid it‚Äôs taken me less than hour. which is more than it deserves.
3810,@GaryMarcus,2022-06-12 20:07:57+00:00,https://twitter.com/GaryMarcus/status/1536077867099951104,ugh. writing about this LaMDA / sentience nonsense. coming shortly.
3811,@GaryMarcus,2022-06-12 19:33:03+00:00,https://twitter.com/GaryMarcus/status/1536069086584578048,"@tamaybes @AVMiceliBarone @slatestarcodex @kevin2kelly @MatthewJBar it will probably include them, but also symbol manipulation components, and be ‚Äúbased‚Äù on both. my most recent substack tries to address this"
3812,@GaryMarcus,2022-06-12 19:30:45+00:00,https://twitter.com/GaryMarcus/status/1536068506315173889,"@SimonDunn321 thanks; eg my 2001 book, The Algebraic Mind."
3813,@GaryMarcus,2022-06-12 19:29:47+00:00,https://twitter.com/GaryMarcus/status/1536068264270278656,"honestly if this system wasn‚Äôt just a stupid statistical pattern associator it would be like a sociopath, making up imaginary friends and uttering platitudes in order to sound cool."
3814,@GaryMarcus,2022-06-12 19:27:26+00:00,https://twitter.com/GaryMarcus/status/1536067674249211904,@rodrigfnogueira @emilymbender @kristintynski @nitashatiku here (ref at bottom) and again in https://t.co/8ir1xKvqt6 essay on elon
3815,@GaryMarcus,2022-06-12 19:26:22+00:00,https://twitter.com/GaryMarcus/status/1536067405952057344,@PaulTopping i‚Äôll start. first double letter says to the second double letter ‚Ä¶
3816,@GaryMarcus,2022-06-12 19:25:02+00:00,https://twitter.com/GaryMarcus/status/1536067069858304000,@peter_haas @Google that‚Äôs why i wrote this in 2014
3817,@GaryMarcus,2022-06-12 17:55:13+00:00,https://twitter.com/GaryMarcus/status/1536044466863079424,"@blaiseaguera what do you think? 

cc @nitashatiku"
3818,@GaryMarcus,2022-06-12 17:47:25+00:00,https://twitter.com/GaryMarcus/status/1536042500338483200,i would not hold your breath. i doubt that @GoogleAI has the courage to allow someone like me to investigate LaMDA.
3819,@GaryMarcus,2022-06-12 17:45:04+00:00,https://twitter.com/GaryMarcus/status/1536041911533785089,@erikbryn @cajundiscordian @percyliang @sapinker @StanfordHAI @DigEconLab @pmddomingos @deaneckles @JeffDean @elonmusk damn straight!
3820,@GaryMarcus,2022-06-12 15:47:56+00:00,https://twitter.com/GaryMarcus/status/1536012432421683201,@ylecun i hope i have represented your position correctly
3821,@GaryMarcus,2022-06-12 15:46:35+00:00,https://twitter.com/GaryMarcus/status/1536012092171427840,"And featuring criteria inspired by @AVMiceliBarone for how we might tell‚Äîsharpening a potential bet proposed by @slatestarcodex  

@kevin2kelly @MatthewJBar @tamaybes"
3822,@GaryMarcus,2022-06-12 15:41:39+00:00,https://twitter.com/GaryMarcus/status/1536010851202654208,Why I think there is a 90% chance that AI needs a paradigm shift‚Äîand why I am hardly alone in thinking that. https://t.co/Odg2QIK6bX
3823,@GaryMarcus,2022-06-12 13:57:03+00:00,https://twitter.com/GaryMarcus/status/1535984526584729600,"@solidoxx @bleepbeepbzzz @_mattbeard @slatestarcodex no i see signs that they are faking it. they really don‚Äôt, and you are confused by mimicry."
3824,@GaryMarcus,2022-06-12 13:34:38+00:00,https://twitter.com/GaryMarcus/status/1535978885547864065,"Coning Wednesday, a Twitter Space discussion on my (proposed) bet with 
@ElonMusk on where AGI will be in 2029.

11am PT, hosted by The UN Brief
@MayaPlentz
open to all, especially  
@elonmusk

https://t.co/SK3UyTp29q"
3825,@GaryMarcus,2022-06-12 05:18:08+00:00,https://twitter.com/GaryMarcus/status/1535853940255776768,"@MFordFuture @cajundiscordian it might be historically significant but i don‚Äôt think it has anything to do with general intelligence and think it is a mistake to emphasize it.

if kurzweil wins it will not be because AGI has been achieved."
3826,@GaryMarcus,2022-06-12 03:39:25+00:00,https://twitter.com/GaryMarcus/status/1535829096663425025,@MFordFuture @cajundiscordian https://t.co/6pkCfIqUiw
3827,@GaryMarcus,2022-06-12 03:37:25+00:00,https://twitter.com/GaryMarcus/status/1535828591778340865,"Not sure what Turing would say, but I don‚Äôt think the Turing Test itself is meaningful
üëârelies on human gullibility 
üëâit can easily be gamed
üëâadvances in it have not historically led to advances in AI
üëâessay I wrote about in 2014 still applies: https://t.co/4KLe1cbDny"
3828,@GaryMarcus,2022-06-12 02:06:25+00:00,https://twitter.com/GaryMarcus/status/1535805692472242176,@Ted_Underwood https://t.co/tkr7P1kEGC
3829,@GaryMarcus,2022-06-12 01:10:42+00:00,https://twitter.com/GaryMarcus/status/1535791668376481792,@andrey_kurenkov thanks for clarifying and I‚Äôve made some edits based on our DM‚Äôs that we just had :)
3830,@GaryMarcus,2022-06-12 00:46:44+00:00,https://twitter.com/GaryMarcus/status/1535785638825369600,"@EmmetPeppers @andyzhouu @TeslaTydirium @NHTSAgov @goodsoilinvest @NaveenGRao @Tesla @elonmusk and i couldn‚Äôt squeeze in the most important point, which is that the L2 stuff is mainly used on highway, so not strictly comparable to lots of other driving where outliers are more of a problem."
3831,@GaryMarcus,2022-06-12 00:45:32+00:00,https://twitter.com/GaryMarcus/status/1535785335346458630,"@EmmetPeppers @andyzhouu @TeslaTydirium @NHTSAgov @goodsoilinvest @NaveenGRao @Tesla @elonmusk BUT
1. Top graph does a classic trick of shortening y x-ais (starting from 70 not 0) to exaggerate effect size.
3. Selective; don‚Äôt know which models *not* included
4. Teslas are safer than *average* cars, but also newer and more expensive
5. L2 safety doesn‚Äôt speak to implied L5"
3832,@GaryMarcus,2022-06-12 00:30:44+00:00,https://twitter.com/GaryMarcus/status/1535781613790842882,"@MFordFuture @cajundiscordian Of course it‚Äôs not sentient. Pastiching human language does not make a machine sentient.

Unless Google allows scientific community (including me) access I am not going to take it seriously."
3833,@GaryMarcus,2022-06-12 00:25:58+00:00,https://twitter.com/GaryMarcus/status/1535780413792129025,"@yudapearl @slatestarcodex @MelMitchell1 @mmitchell_ai @timnitGebru @JanelleCShane @katecrawford @merbroussard @ErnestSDavis @ylecun and here‚Äôs the last episode, which cites you/links Book of Why:

https://t.co/ml0aDgCwpW"
3834,@GaryMarcus,2022-06-12 00:24:36+00:00,https://twitter.com/GaryMarcus/status/1535780069162950656,the piece: https://t.co/ml0aDgCwpW
3835,@GaryMarcus,2022-06-11 18:51:06+00:00,https://twitter.com/GaryMarcus/status/1535696140804403200,"and @_dieuwke_, too!"
3836,@GaryMarcus,2022-06-11 18:44:39+00:00,https://twitter.com/GaryMarcus/status/1535694517810081792,"With @Abebab @ErnestSDavis @AVMiceliBarone @emilymbender @timnitGebru @andrey_kurenkov @MelMitchell1 @katecrawford @merbroussard Scott Aaronson, #BigBench and a remarkable amount of love for a recent @ylecun tweetstream"
3837,@GaryMarcus,2022-06-11 18:44:38+00:00,https://twitter.com/GaryMarcus/status/1535694514752323584,"Does AI really *need* a paradigm shift? 

My reply to @slatestarcodex‚Äôs ‚ÄúSomewhat contra Marcus‚Äù

Read the essay that Noam Chomsky read first :)

https://t.co/J90uAAnfDc https://t.co/A4Buv3Re9A"
3838,@GaryMarcus,2022-06-11 18:32:35+00:00,https://twitter.com/GaryMarcus/status/1535691481238753280,@_mattbeard @DoveFirebrand @slatestarcodex i link this in my reply :)
3839,@GaryMarcus,2022-06-11 18:02:49+00:00,https://twitter.com/GaryMarcus/status/1535683991231049728,"@moppety that explains the writing but not the reading. I have a friend who sat next to him once at a faculty meeting; he was astonished by how much faster Chomsky reads than anyone else. 

Jeff Dean jokes are funny but Chomsky stories may actually be true.

‚Äú8 minutes later‚Äù was literal."
3840,@GaryMarcus,2022-06-11 18:00:02+00:00,https://twitter.com/GaryMarcus/status/1535683289855340546,"@brunowinck i didn‚Äôt ask for permission to quote and it‚Äôs not gentle towards current work in AI, but it‚Äôs not altogether dissimilar to what i quoted (with permission) in my Substack piece on Noam and GPT-3.  

but darker and funnier :)"
3841,@GaryMarcus,2022-06-11 17:55:38+00:00,https://twitter.com/GaryMarcus/status/1535682183716737024,@azeem gotta be some kind of bionics!
3842,@GaryMarcus,2022-06-11 17:53:28+00:00,https://twitter.com/GaryMarcus/status/1535681637593124867,"Posted my new piece, first to subscribers, 8 minutes later I get my first reaction, a two paragraph email. 

Noam Chomsky. 

How does he do that?"
3843,@GaryMarcus,2022-06-11 17:45:52+00:00,https://twitter.com/GaryMarcus/status/1535679724151656448,"and i shout out one of her excellent recent arXiv papers, on the perils of webscraping, https://t.co/9yVYoF06Ri, in the substack essay I just posted."
3844,@GaryMarcus,2022-06-11 17:31:57+00:00,https://twitter.com/GaryMarcus/status/1535676223535190016,@ylecun @elonmusk @Twitter ‚Äúenforces‚Äù? how? (haven‚Äôt visited since 2017)
3845,@GaryMarcus,2022-06-11 17:19:21+00:00,https://twitter.com/GaryMarcus/status/1535673051328544769,"@nektariosmusic @tetraduzione @slatestarcodex @ylecun enemy is a strong word, because this dispute is pretty good-natured, but the new essay is debating with @slatestarcodex"
3846,@GaryMarcus,2022-06-11 16:15:31+00:00,https://twitter.com/GaryMarcus/status/1535656988327104512,coming later today: https://t.co/XQIbXb5DDs
3847,@GaryMarcus,2022-06-11 15:50:12+00:00,https://twitter.com/GaryMarcus/status/1535650617112158208,"üôè‚ù§Ô∏è Amazing diagram!  ‚ù§Ô∏èüôè

I would pay a substantial monthly premium for a platform that obliged people to stick top 3/7 of this pyramid. 

@elonmusk @twitter 

üî•üî•üî•"
3848,@GaryMarcus,2022-06-11 15:44:30+00:00,https://twitter.com/GaryMarcus/status/1535649181318033408,"The plot of my next essay at https://t.co/8ir1xKvqt6 :)

Drops today! Subscribe to see it first."
3849,@GaryMarcus,2022-06-11 15:42:39+00:00,https://twitter.com/GaryMarcus/status/1535648717583159296,@tetraduzione @slatestarcodex @ylecun that does seem to be exactly the plot of what i just drafted :)
3850,@GaryMarcus,2022-06-11 14:19:41+00:00,https://twitter.com/GaryMarcus/status/1535627836324577280,"ooh boy, almost done my reply to @slatestarcodex and it‚Äôs practically a love letter to @ylecun.

who saw that coming?"
3851,@GaryMarcus,2022-06-11 05:09:35+00:00,https://twitter.com/GaryMarcus/status/1535489398212423681,@andyzhouu @EmmetPeppers @TeslaTydirium @NHTSAgov @goodsoilinvest @NaveenGRao @Tesla @elonmusk calling for fuller disclosure of data and truth in messaging does not equate to calling for the project to be canceled.
3852,@GaryMarcus,2022-06-11 05:08:15+00:00,https://twitter.com/GaryMarcus/status/1535489063985106944,"@andyzhouu @EmmetPeppers @TeslaTydirium @NHTSAgov @goodsoilinvest @NaveenGRao @Tesla @elonmusk they haven‚Äôt. by opting out of reporting CA intervention statistics &amp; failing to make clear details of their data, they have simply cast a cloud of suspicion around themselves, &amp; in no way established scientific credibility or superiority. 

&amp; issue of informed consent looms"
3853,@GaryMarcus,2022-06-11 03:01:37+00:00,https://twitter.com/GaryMarcus/status/1535457196472799232,I used to think it was just AI that exceeded his grasp
3854,@GaryMarcus,2022-06-11 02:58:26+00:00,https://twitter.com/GaryMarcus/status/1535456394320629760,@mosesjones yeah this was pretty problematic @kncukier
3855,@GaryMarcus,2022-06-11 01:59:42+00:00,https://twitter.com/GaryMarcus/status/1535441613689720832,"@calistoker123 @AlbertBridgeCap @EmmetPeppers @TeslaTydirium @NHTSAgov @goodsoilinvest @NaveenGRao @Tesla @elonmusk sure, once the engineering is mature. not there yet, but someday"
3856,@GaryMarcus,2022-06-11 01:58:44+00:00,https://twitter.com/GaryMarcus/status/1535441369509924864,@MatchasmMatt @NaveenGRao @EmmetPeppers thanks for listening with an open mind :) more on my views about AI (not yet specifically about cars) @ https://t.co/8ir1xKvqt6
3857,@GaryMarcus,2022-06-11 01:53:37+00:00,https://twitter.com/GaryMarcus/status/1535440084522020864,"The federal government‚Äôs Tesla Autopilot investigation is moving into a new phase - The Verge

(re the ongoing issues crashing into stopped vehicles that was mentioned in 2019, in https://t.co/Pt7HZbLIv5) https://t.co/Gxe5wF8RCr"
3858,@GaryMarcus,2022-06-11 01:31:24+00:00,https://twitter.com/GaryMarcus/status/1535434489912037383,@sl8rv @slatestarcodex pay no attention to the man behind the curtain?
3859,@GaryMarcus,2022-06-11 00:26:29+00:00,https://twitter.com/GaryMarcus/status/1535418155161600002,"@EmmetPeppers @TeslaTydirium @NHTSAgov @goodsoilinvest @NaveenGRao @Tesla @elonmusk there are such studies, i have posted. and yes i did raise these kinds of confounds in the interview saying you need to compare with other similar cars, similar mass, etc (eg i may have mentioned similar age of vehicle and types of moles). coarse statistics are very misleading."
3860,@GaryMarcus,2022-06-11 00:18:40+00:00,https://twitter.com/GaryMarcus/status/1535416186170662913,@EmmetPeppers @TeslaTydirium @NHTSAgov @goodsoilinvest @NaveenGRao @Tesla @elonmusk sorry but no. we explained why in the interview. soooo many confounds if you do it that way
3861,@GaryMarcus,2022-06-10 23:25:39+00:00,https://twitter.com/GaryMarcus/status/1535402847856078849,And people used to think Y2K was a problem
3862,@GaryMarcus,2022-06-10 23:22:24+00:00,https://twitter.com/GaryMarcus/status/1535402027487883264,typo: @NaveenGRao
3863,@GaryMarcus,2022-06-10 23:10:33+00:00,https://twitter.com/GaryMarcus/status/1535399044251406336,"@EmmetPeppers @NHTSAgov @goodsoilinvest @NaveenGRao Your clip cuts away before your guest could answer‚Ä¶ 

If edge cases are inevitable, we need to rethink our algorithms. Edge cases cost lives; very uncomfortable with this tweet."
3864,@GaryMarcus,2022-06-10 23:03:51+00:00,https://twitter.com/GaryMarcus/status/1535397359756054528,"@EmmetPeppers @LifeAt130BPM @goodsoilinvest @NaveenGRao as we said on the show, the data re your net-net assertion aren‚Äôt there. we hope that there will be fuller disclosure of what miles are driven, where, &amp; under what conditions, such that such claims might be properly investigated. for now, data presentation has been too selective."
3865,@GaryMarcus,2022-06-10 21:30:16+00:00,https://twitter.com/GaryMarcus/status/1535373806725787648,@jahendler @MelMitchell1 remind me your answer on how we would tell re paradigm shift?
3866,@GaryMarcus,2022-06-10 21:29:38+00:00,https://twitter.com/GaryMarcus/status/1535373649468829696,@sbrothers217 @sea_snell @slatestarcodex yes for sure. Kuhn owns the term; how we realize it here? @unsojo
3867,@GaryMarcus,2022-06-10 21:13:15+00:00,https://twitter.com/GaryMarcus/status/1535369524639244288,@unsojo
3868,@GaryMarcus,2022-06-10 21:11:43+00:00,https://twitter.com/GaryMarcus/status/1535369142160617472,@Pehdrew_ @slatestarcodex says above: mention in my reply to SSC.
3869,@GaryMarcus,2022-06-10 21:05:50+00:00,https://twitter.com/GaryMarcus/status/1535367657985216513,"if nobody steps up, I am putting you i charge @MelMitchell1 :)"
3870,@GaryMarcus,2022-06-10 20:55:13+00:00,https://twitter.com/GaryMarcus/status/1535364988776329216,@matthewcobb so much for the ‚Äútime flies‚Äù intepretation ü™∞
3871,@GaryMarcus,2022-06-10 20:52:16+00:00,https://twitter.com/GaryMarcus/status/1535364243570061312,@bradpwyble @ShlomoArgamon @slatestarcodex @ErnestSDavis the prompt ended at step by step
3872,@GaryMarcus,2022-06-10 20:40:50+00:00,https://twitter.com/GaryMarcus/status/1535361369381511168,"essay contest! what‚Äôs a paradigm shift? how can the field turn ‚Å¶@slatestarcodex‚Å©‚Äôs propositions 4 and 5 into something tangible?

winner(s) might get mention tomorrow in my substack reply to SSC https://t.co/enikL3cRvD"
3873,@GaryMarcus,2022-06-10 20:35:16+00:00,https://twitter.com/GaryMarcus/status/1535359969184333824,@neuroecology @slatestarcodex @ErnestSDavis @rogerkmoore put it well:
3874,@GaryMarcus,2022-06-10 20:13:10+00:00,https://twitter.com/GaryMarcus/status/1535354404395679745,@neuroecology @slatestarcodex @ErnestSDavis the problem is that it is always just sequences of words and never actual concepts
3875,@GaryMarcus,2022-06-10 20:01:10+00:00,https://twitter.com/GaryMarcus/status/1535351387651031040,"reader @slatestarcodex: what if you gave the cow a name, Blue Bell?

@ErnestSDavis: ok, let me try

GPT-3 [deadpan]: ‚ÄúIt is possible for a cow to be revived after it has died, but it is not something that happens often. It is more likely that Blue Bell will remain dead.‚Äù

YMMV https://t.co/oWF1dE1UwI"
3876,@GaryMarcus,2022-06-10 19:44:39+00:00,https://twitter.com/GaryMarcus/status/1535347230185508866,@NaveenGRao @calistoker123 @EmmetPeppers @MatchasmMatt @Tesla and Tesla lacks lidar which is an important potential source of information. unnecessary for humans but possible necessary in systems that lack human cognitive flexibility and common sense.
3877,@GaryMarcus,2022-06-10 19:09:14+00:00,https://twitter.com/GaryMarcus/status/1535338318295990273,@ChrSzegedy @MelMitchell1 @ChrSzegedy please follow back or dm me your email so we can iron out some details :)
3878,@GaryMarcus,2022-06-10 18:47:43+00:00,https://twitter.com/GaryMarcus/status/1535332901746683904,"Lots of people are asking for a sequel. What will it take @ylecun to get that project off the ground?

@slatestarcodex and I are certainly having fun :)"
3879,@GaryMarcus,2022-06-10 18:45:33+00:00,https://twitter.com/GaryMarcus/status/1535332358085148673,"@PaulTopping maybe when @ylecun sees how nice i am to him tomorrow on Substack, he will finally agree?"
3880,@GaryMarcus,2022-06-10 18:36:02+00:00,https://twitter.com/GaryMarcus/status/1535329961933869056,@bleepbeepbzzz @_mattbeard @slatestarcodex !
3881,@GaryMarcus,2022-06-10 18:33:38+00:00,https://twitter.com/GaryMarcus/status/1535329356846751745,"Deep in the heart of @tesla/TSLA fandom, @NaveenGRao and I raise some concerns about the current state of play in autonomous driving, and suggest what kinds of data we would really like to see.

cc @CadeMetz @lorakolodny @PeteButtigieg"
3882,@GaryMarcus,2022-06-10 18:30:07+00:00,https://twitter.com/GaryMarcus/status/1535328474113576960,"it was great! still relevant, too."
3883,@GaryMarcus,2022-06-10 15:23:36+00:00,https://twitter.com/GaryMarcus/status/1535281534797680641,and rising star @Abebab!
3884,@GaryMarcus,2022-06-10 15:23:02+00:00,https://twitter.com/GaryMarcus/status/1535281391415414784,"when A(G)I destroys civilization as we know it, whether through toxicity, polarization &amp; misinformation, the misuse of autonomous weapons, or by turning us all into paper clips, at least we will be take comfort in the improvements it made to our ... recommendation algorithms.
ü§Ø"
3885,@GaryMarcus,2022-06-10 15:18:06+00:00,https://twitter.com/GaryMarcus/status/1535280150291443712,@Brigadirk the whole second half of the book points to different directions and specific problems to be solved and explains why its hard
3886,@GaryMarcus,2022-06-10 15:16:57+00:00,https://twitter.com/GaryMarcus/status/1535279859131305984,"My substack reply to @slatestarcodex is going to be fun, with shoutouts to @MelMitchell1 @mmitchell_ai @timnitGebru @yudapearl @JanelleCShane @katecrawford @merbroussard @ErnestSDavis 

And to @ylecun, in which I quote him at length, and say Amen!

Who among us saw that coming?"
3887,@GaryMarcus,2022-06-10 15:07:23+00:00,https://twitter.com/GaryMarcus/status/1535277452745768960,"Slide from October 2017, when we were better friends. But I still think @ylecun and I would agree on most or all of this."
3888,@GaryMarcus,2022-06-10 05:56:19+00:00,https://twitter.com/GaryMarcus/status/1535138770785161217,@maartengm @Japskua through 2012? do you have that through 2022?
3889,@GaryMarcus,2022-06-10 05:48:08+00:00,https://twitter.com/GaryMarcus/status/1535136713374584832,"442 authors can‚Äôt be wrong: increasing scale alone won‚Äôt be enough (from new Big-Bench paper), especially in understanding long contexts https://t.co/CGEQ7Nlpt8"
3890,@GaryMarcus,2022-06-10 05:31:24+00:00,https://twitter.com/GaryMarcus/status/1535132500137111553,@rogerkmoore ‚Äòzacktly
3891,@GaryMarcus,2022-06-10 05:30:51+00:00,https://twitter.com/GaryMarcus/status/1535132361481809921,pay no attention to the costs behind the curtain
3892,@GaryMarcus,2022-06-10 04:05:06+00:00,https://twitter.com/GaryMarcus/status/1535110782731620354,"@MatthewJBar if we can operationalize #5 (agree: very hard), I am in"
3893,@GaryMarcus,2022-06-10 04:01:06+00:00,https://twitter.com/GaryMarcus/status/1535109775255605251,@maththrills @ErnestSDavis is mulling a challenge that would specifically revolves around trained experts
3894,@GaryMarcus,2022-06-10 03:36:36+00:00,https://twitter.com/GaryMarcus/status/1535103612656840706,"between the polls, inflation, the Russian invasion and so on, @VP may have 99 problems but a sociopathic boss ain‚Äôt one."
3895,@GaryMarcus,2022-06-10 03:20:27+00:00,https://twitter.com/GaryMarcus/status/1535099549017964544,"@slatestarcodex‚Äôa full blog: https://t.co/DfYEreWJeQ

attn @tamaybes @MatthewJBar surely more fodder for @metaculus 

end/"
3896,@GaryMarcus,2022-06-10 03:20:27+00:00,https://twitter.com/GaryMarcus/status/1535099547268968454,"Brave bet!  Continuing his friendly joust, @slatestarcodex offers w 40% confidence that AGI won‚Äôt require further paradigm shifts at all‚Äîcontra both my own position &amp; even that of @ylecun! 

My next Substack will explain why I am happy to take SSC‚Äôs odds‚Äîand why I care.

1/ https://t.co/Afy5Ad7Lyt"
3897,@GaryMarcus,2022-06-10 02:28:04+00:00,https://twitter.com/GaryMarcus/status/1535086364730851328,@jasonlarkin841 @miguelisolano @Plinz @JacobHHilton all three are lousy and absent further info i wouldn‚Äôt take the difference too seriously.
3898,@GaryMarcus,2022-06-10 01:33:39+00:00,https://twitter.com/GaryMarcus/status/1535072671594995714,@tamaybes https://t.co/y5qxtXWHAi
3899,@GaryMarcus,2022-06-10 01:32:22+00:00,https://twitter.com/GaryMarcus/status/1535072346700099585,@LiquidData or they just couldn‚Äôt make it work all that well?
3900,@GaryMarcus,2022-06-10 00:28:26+00:00,https://twitter.com/GaryMarcus/status/1535056258339729408,"@tamaybes i saw an LLM-related paper with 400 some authors yesterday, and a bunch with 80 some some wit over 100. and i have seen estimates of LM's at $20M, when a typical academic study is well &lt; $1m. so don't think your math is as clear as you think."
3901,@GaryMarcus,2022-06-09 23:58:16+00:00,https://twitter.com/GaryMarcus/status/1535048665005293568,@tamaybes you almost surely aren‚Äôt weighing by # of $ or authors
3902,@GaryMarcus,2022-06-09 22:08:11+00:00,https://twitter.com/GaryMarcus/status/1535020962810212352,@HappyAar mine is just a guess but landed in similar place as @etzioni
3903,@GaryMarcus,2022-06-09 21:43:44+00:00,https://twitter.com/GaryMarcus/status/1535014811662069761,"quite similar to my own estimate, and madness, from a portfolio  diversification perspective"
3904,@GaryMarcus,2022-06-09 21:38:20+00:00,https://twitter.com/GaryMarcus/status/1535013449998036993,@EmmetPeppers @MatchasmMatt
3905,@GaryMarcus,2022-06-09 21:17:38+00:00,https://twitter.com/GaryMarcus/status/1535008243226796032,@chris_jwala @dontmeanathing literally laughed out loud!
3906,@GaryMarcus,2022-06-09 21:06:44+00:00,https://twitter.com/GaryMarcus/status/1535005497392107520,@NaveenGRao @Tesla . @tesla itself might not enjoy it as much as we did :)
3907,@GaryMarcus,2022-06-09 21:05:50+00:00,https://twitter.com/GaryMarcus/status/1535005273072447488,2019. still true?
3908,@GaryMarcus,2022-06-09 21:04:59+00:00,https://twitter.com/GaryMarcus/status/1535005056893825025,@MichaelTrazzi @Tesla @NaveenGRao @raphaelmilliere if you first reissue your image without the goalpost legend?
3909,@GaryMarcus,2022-06-09 21:01:53+00:00,https://twitter.com/GaryMarcus/status/1535004279655657472,"@PlanetoidReader @aniketvartak @wadhwa fair point, though for some purposes one could envision, keyword search is all you need: https://t.co/gwdNL2U1u7"
3910,@GaryMarcus,2022-06-09 19:32:28+00:00,https://twitter.com/GaryMarcus/status/1534981774261923840,just recorded a super fun podcast on @tesla and self-driving with @NaveenGRao - will post a link when it is live.
3911,@GaryMarcus,2022-06-09 17:29:17+00:00,https://twitter.com/GaryMarcus/status/1534950776707026945,examples from new paper by @ErnestSDavis https://t.co/1Z0FirqtUx
3912,@GaryMarcus,2022-06-09 17:29:17+00:00,https://twitter.com/GaryMarcus/status/1534950774622388235,it‚Äôs not a good idea to post replies without context (of numerators and denominators and other pesky facts about reliability) https://t.co/dDSMIH1sni
3913,@GaryMarcus,2022-06-09 17:24:31+00:00,https://twitter.com/GaryMarcus/status/1534949577064714250,"@MichaelTrazzi name one goalpost that I ever moved, w possible exception of winograd"
3914,@GaryMarcus,2022-06-09 17:23:53+00:00,https://twitter.com/GaryMarcus/status/1534949414300553216,"what goalpost did i ever move? i was wrong about how easily Winograd was gamed but pretty much everything else i have said i think still stands.

so many accusations, so little evidence."
3915,@GaryMarcus,2022-06-09 16:51:03+00:00,https://twitter.com/GaryMarcus/status/1534941155309125632,"ü§£ü§£ü§£ from new report from @ErnestSDavis, responding in part  to anecdotal data from @plinz

Contrary to popular belief, AI Prompt Whisperer is probably not a profession with a future 

https://t.co/1Z0FirqtUx https://t.co/LP9wb8EG93"
3916,@GaryMarcus,2022-06-09 16:42:38+00:00,https://twitter.com/GaryMarcus/status/1534939033620533248,"@Whats_AI @discord @towards_AI see my reply, at https://t.co/8ir1xKvqt6"
3917,@GaryMarcus,2022-06-09 16:32:12+00:00,https://twitter.com/GaryMarcus/status/1534936410704076807,"@LucaAmb i would honestly want something like general intelligence in my medical system, yes, given the variety of potentially relevant information (eg circumstances in sustaining an injury)"
3918,@GaryMarcus,2022-06-09 14:38:52+00:00,https://twitter.com/GaryMarcus/status/1534907886484107267,"Difference between shouts of allegedly exponential AI progress in the lab, and the reality of making products in the real world, even with all the resources of Google:

#Singularity #AGI #RealityCheck"
3919,@GaryMarcus,2022-06-09 14:32:11+00:00,https://twitter.com/GaryMarcus/status/1534906206447226885,"here‚Äôs our original article: https://t.co/is6bHt9SPn

even with the explosion of large language models, there is apparently shockingly little progress on generalizing that project.

reminiscent of promise v reality on level 5 self-driving?"
3920,@GaryMarcus,2022-06-09 14:32:11+00:00,https://twitter.com/GaryMarcus/status/1534906204870176768,"2018 Marcus/Davis, NYT: ‚ÄúIf you read [about] Google Duplex..scope of..project is surprisingly limited. It encompasses just three tasks: helping users ‚Äúmake restaurant reservations, schedule hair salon appointments, and get holiday hours.‚Äù
2022 You can make movie reservations, too"
3921,@GaryMarcus,2022-06-09 14:03:32+00:00,https://twitter.com/GaryMarcus/status/1534898996426067968,"this link is old (2019), but what did ever become of Google Duplex? anyone know? demoware? actually in use? for what? any recent updates?"
3922,@GaryMarcus,2022-06-09 14:02:06+00:00,https://twitter.com/GaryMarcus/status/1534898634889646080,"@dontmeanathing @BierVicki @ErnestSDavis ‚Äúthe cow‚Äù implied it, and ernie replicated w some other wordings (and got a correct answer at least once, in perhaps 4 attempts?)"
3923,@GaryMarcus,2022-06-09 13:39:34+00:00,https://twitter.com/GaryMarcus/status/1534892963687301125,"@dxbarradas i will try to take that as a compliment, and yes it‚Äôs an exactly tweet (w a tiny bit of clarification from me underneath)"
3924,@GaryMarcus,2022-06-09 13:38:38+00:00,https://twitter.com/GaryMarcus/status/1534892731222200320,"shh, @BierVicki ! don‚Äôt ask too many questions! the funding might dry up!

and of course ‚Äústep by step‚Äù is not really universal, eg courtesy @ErnestSDavis: https://t.co/qKiqlf4o86"
3925,@GaryMarcus,2022-06-09 13:34:04+00:00,https://twitter.com/GaryMarcus/status/1534891581433532416,"to which @matthewcobb, riffing on my horse riding astronaut essay, added this"
3926,@GaryMarcus,2022-06-09 13:31:54+00:00,https://twitter.com/GaryMarcus/status/1534891037918760960,@lvalentgar oops somehow messed it up. will reply to my own reply in a second with rest of thread.
3927,@GaryMarcus,2022-06-09 13:18:12+00:00,https://twitter.com/GaryMarcus/status/1534887587239710720,"or imagine if your self-driving car only works with the right incantation, with ‚Äúdrive to the Grand Canyon‚Äù yielding tragically different results from ‚Äúdrive to the edge of the Grand Canyon‚Äù.

2/2"
3928,@GaryMarcus,2022-06-09 13:18:11+00:00,https://twitter.com/GaryMarcus/status/1534887585759100930,"imagine if your automated medical diagnosis system were highly sensitive to exact wording. correct answer if you remember include ‚Äúlet‚Äôs take this step by step‚Äù, but wrong answer otherwise?

1/2"
3929,@GaryMarcus,2022-06-09 13:06:33+00:00,https://twitter.com/GaryMarcus/status/1534884655790292993,"@nektariosmusic @ylecun @MelMitchell1 no. i think those are different questions. but in general we should aim beyond human cognition, which is deeply flawed"
3930,@GaryMarcus,2022-06-09 13:03:11+00:00,https://twitter.com/GaryMarcus/status/1534883808612261894,"everything that is fantastic about dall-e (mini edition) and everything that is less promising, in a short thread:"
3931,@GaryMarcus,2022-06-09 13:01:44+00:00,https://twitter.com/GaryMarcus/status/1534883444949282817,@matthewcobb @FossilLocator not so great. the first set is terrific though
3932,@GaryMarcus,2022-06-09 12:44:52+00:00,https://twitter.com/GaryMarcus/status/1534879198891810816,"@LucaAmb @aniketvartak @ErnestSDavis um, no, in this case we were looking for something that could order the temporal and causal sequence of events. hardly an unreasonable ask"
3933,@GaryMarcus,2022-06-09 12:39:54+00:00,https://twitter.com/GaryMarcus/status/1534877949324775424,"@ewanbirney @jankosinski @elonmusk @Alfons_Valencia @pedrobeltrao @ChristineOrengo partly a matter of intellectual taste, partly an empirical matter. to date narrow AI has trounced immature efforts at general AI, but some problems (eg getting machine to read with deep understanding) have basically proven insurmountable thus far with any known approach."
3934,@GaryMarcus,2022-06-09 12:36:17+00:00,https://twitter.com/GaryMarcus/status/1534877040939175937,"@ewanbirney @jankosinski @elonmusk @Alfons_Valencia @pedrobeltrao @ChristineOrengo oh, i didn‚Äôt say it was solved and in fact was inquiring about the opposite, viz how effective it was with novel families. (your point about how hard that is to nail down is of course well-taken)"
3935,@GaryMarcus,2022-06-09 12:24:23+00:00,https://twitter.com/GaryMarcus/status/1534874045790859265,"@Zergylord @Plinz for sure. it was a sendup of promptology as a scientific methodology, not GPT itself."
3936,@GaryMarcus,2022-06-09 12:19:47+00:00,https://twitter.com/GaryMarcus/status/1534872886703312897,@Zergylord viz this and @plinz‚Äôs efforts to get correct answer w different prompts
3937,@GaryMarcus,2022-06-09 12:18:14+00:00,https://twitter.com/GaryMarcus/status/1534872498390462465,@Zergylord but in this particular question it was basically multiple choice
3938,@GaryMarcus,2022-06-09 12:10:20+00:00,https://twitter.com/GaryMarcus/status/1534870510005145600,@jankosinski @ewanbirney @elonmusk @Alfons_Valencia @pedrobeltrao @ChristineOrengo &amp;
3939,@GaryMarcus,2022-06-09 12:08:46+00:00,https://twitter.com/GaryMarcus/status/1534870113454723072,@LucaAmb @ErnestSDavis seriously? show me the human being that would find sequence F to be plausible
3940,@GaryMarcus,2022-06-09 12:06:33+00:00,https://twitter.com/GaryMarcus/status/1534869557386412037,"@jankosinski @ewanbirney @elonmusk @Alfons_Valencia @pedrobeltrao @ChristineOrengo sure; i think AlphaFold is one do the most potentially useful bits of AI to date.

But ‚Äúnarrow AI‚Äù has a technical meaning, viz AI tailored to a specific problem, that contrasts with AGI which would be able to solve arbitrary problems on its own."
3941,@GaryMarcus,2022-06-09 06:31:56+00:00,https://twitter.com/GaryMarcus/status/1534785347711709184,"imagine how much deeper TwitterAI would be if people routinely did this simple thing I ask for below instead of posting random examples?

ok, i know, never gonna happen.  but a man can dream.

good night, all"
3942,@GaryMarcus,2022-06-09 06:28:40+00:00,https://twitter.com/GaryMarcus/status/1534784526479609858,@ben_j_radford @ErnestSDavis i wouldn‚Äôt say determinism is necessary but there is no way is it better than the average human across wordings at temporal sequencing.
3943,@GaryMarcus,2022-06-09 06:22:39+00:00,https://twitter.com/GaryMarcus/status/1534783011547295744,"‚Äúthe fact that, if you play around with prompts long enough, you can eventually get what you want, is relevant to some forms of human-in-the-loop AI but it won't cut the mustard for reliable AI.‚Äù‚Äî @ErnestSDavis 
in https://t.co/ZacV6jKxJ6"
3944,@GaryMarcus,2022-06-09 05:54:53+00:00,https://twitter.com/GaryMarcus/status/1534776025762045952,"@ewanbirney @elonmusk would love some quantitative sense here, though i understand your point about criteria. thanks for the thread!"
3945,@GaryMarcus,2022-06-09 05:46:23+00:00,https://twitter.com/GaryMarcus/status/1534773883391205376,@dileeplearning
3946,@GaryMarcus,2022-06-09 05:39:57+00:00,https://twitter.com/GaryMarcus/status/1534772266373767168,"Anybody remember the old Magic 8 Ball? you just keeping shaking it until you get the answer you want. Foolproof!

GPT-8‚Äôs gonna work in exactly the same way, except you prompt it, instead of shaking it, and you can set the temperature with a little dial.  https://t.co/04s5Rfa3FE"
3947,@GaryMarcus,2022-06-09 05:29:57+00:00,https://twitter.com/GaryMarcus/status/1534769748038197255,@Plinz üôÑ
3948,@GaryMarcus,2022-06-09 05:29:07+00:00,https://twitter.com/GaryMarcus/status/1534769537425453057,"Grade-grubbing 101,  for large language models

teacher: I am sorry, but you failed the exam. you got only 1 out of 3

student: But you asked the question in three different ways!

proud parent: And junior was correct once! he totally deserves an A for getting the answer right!"
3949,@GaryMarcus,2022-06-09 05:20:40+00:00,https://twitter.com/GaryMarcus/status/1534767413404741632,@Plinz i do miss real science
3950,@GaryMarcus,2022-06-09 05:17:51+00:00,https://twitter.com/GaryMarcus/status/1534766705162932224,"@Plinz want to try do some real science and try a few different variations and report everything you got positive and negative? 

my guess is it‚Äôs not super reliable"
3951,@GaryMarcus,2022-06-09 02:46:27+00:00,https://twitter.com/GaryMarcus/status/1534728604940050433,"Example from Ernest Davis, based on our book https://t.co/Pt7HZbLIv5. 

Would be fun to build a temporal reasoning benchmark like this, or maybe @YejinChoinka already has?"
3952,@GaryMarcus,2022-06-09 02:46:27+00:00,https://twitter.com/GaryMarcus/status/1534728603606216704,AGI‚Äôs gonna be wild https://t.co/cC7Kpm4bI6
3953,@GaryMarcus,2022-06-09 02:41:01+00:00,https://twitter.com/GaryMarcus/status/1534727237412323328,@fchollet we called this ‚Äúthe gullibility gap‚Äù in https://t.co/Pt7HZbLIv5
3954,@GaryMarcus,2022-06-09 01:14:59+00:00,https://twitter.com/GaryMarcus/status/1534705583135215617,@nutanc @jonathanrlarkin AGI gonna be wild üôÑ
3955,@GaryMarcus,2022-06-09 01:00:47+00:00,https://twitter.com/GaryMarcus/status/1534702009957376002,"given how many people mistake ‚Äúdeep learning‚Äù for learning conceptually deep things, I think names matter a lot."
3956,@GaryMarcus,2022-06-09 00:58:35+00:00,https://twitter.com/GaryMarcus/status/1534701457135616002,"@inquiringAImind @slatestarcodex and structured, and pre-organized, too"
3957,@GaryMarcus,2022-06-09 00:54:10+00:00,https://twitter.com/GaryMarcus/status/1534700345905098757,"the M Mitchells, @MelMitchell1 and @mmitchell_ai (no relation, to my knowledge) are raising all the right questions today."
3958,@GaryMarcus,2022-06-09 00:52:48+00:00,https://twitter.com/GaryMarcus/status/1534700001913339904,@MelMitchell1 indeed! model used to mean either an (explicit) model of the word or a model of a human cognitive process. now it mostly just means a particular network architecture.
3959,@GaryMarcus,2022-06-09 00:48:52+00:00,https://twitter.com/GaryMarcus/status/1534699010568642560,anybody disagree with this? why?
3960,@GaryMarcus,2022-06-09 00:42:19+00:00,https://twitter.com/GaryMarcus/status/1534697364476284928,"@ChrSzegedy @charleswangb @hardmaru @MelMitchell1 @fchollet puzzled by the word act. eg would any single proof or image label convince you of understanding, if you did not know what was in the training set?"
3961,@GaryMarcus,2022-06-08 23:42:50+00:00,https://twitter.com/GaryMarcus/status/1534682392337780736,"@NickRMorgan @mmitchell_ai solving through data is like a whack a mole, and not a great methodology"
3962,@GaryMarcus,2022-06-08 23:26:06+00:00,https://twitter.com/GaryMarcus/status/1534678183014014977,@raphaelmilliere @PolarBearby @mmitchell_ai Monster networks? ü§£
3963,@GaryMarcus,2022-06-08 23:24:50+00:00,https://twitter.com/GaryMarcus/status/1534677865689661440,".@mmitchell_ai is right: ‚Äúfoundational models‚Äù is a term that needs replacing
- they are not reliable enough to be solid bedrock https://t.co/qwExUL2VLg
- the term obscures their sensitivity to proprietary webscrapes of convenience that often perpetuate bias, misinfo &amp; toxicity"
3964,@GaryMarcus,2022-06-08 22:58:33+00:00,https://twitter.com/GaryMarcus/status/1534671250504695809,"@ewanbirney @elonmusk ü§£; meant in a technical sense: it‚Äôs a single (fiendishly complex) problem that requires a lot of chemistry and physics but eg no neuroscience psychology sociology economics or knowledge of current events 

curious your take on Alpha* with novel protein families"
3965,@GaryMarcus,2022-06-08 20:51:37+00:00,https://twitter.com/GaryMarcus/status/1534639307759050752,@igrgavilan @mmitchell_ai quote from the other day in on same point
3966,@GaryMarcus,2022-06-08 20:32:42+00:00,https://twitter.com/GaryMarcus/status/1534634547731890177,@mmitchell_ai agreed. and see our concerns on the term here: https://t.co/qwExUL3tAO
3967,@GaryMarcus,2022-06-08 20:25:39+00:00,https://twitter.com/GaryMarcus/status/1534632770592337922,@Abebab congrats ü•Ç
3968,@GaryMarcus,2022-06-08 20:15:48+00:00,https://twitter.com/GaryMarcus/status/1534630293919133696,@pabbeel @geoffreyhinton since you let him take a potshot at me maybe you should allow me to respond? see below https://t.co/EsTuzJ17I9
3969,@GaryMarcus,2022-06-08 19:48:52+00:00,https://twitter.com/GaryMarcus/status/1534623513864069120,@hankejh @OpenAI @slatestarcodex @gdb @sama it‚Äôs just embarassing
3970,@GaryMarcus,2022-06-08 19:20:29+00:00,https://twitter.com/GaryMarcus/status/1534616371853635584,"Yes, I am afraid it is true. @OpenAI is 100% as petty as @slatestarcodex portrayed them to be here. 

I give the receipts (and translation) to back up SSC‚Äôs statement, here in https://t.co/Gh51GFX4pu

For shame, @gdb @sama, that‚Äôs really no way to conduct ‚ÄúOpenAI‚Äù."
3971,@GaryMarcus,2022-06-08 19:07:41+00:00,https://twitter.com/GaryMarcus/status/1534613150481326080,"AI in a nutshell. Live tweeted coda to my Substack reply to @slatestarcodex:
- Davis &amp; Marcus point out a problem
- Someone says they have refuted problem
- Same someone misrepresents what we said
- A few minutes later, @ErnestSDavis figures out alleged solution isn‚Äôt reliable."
3972,@GaryMarcus,2022-06-08 18:58:30+00:00,https://twitter.com/GaryMarcus/status/1534610838648025088,"@jonathanrlarkin @ErnestSDavis few if any of the things we talked about can, so far as I know, now be done reliably. some can now be done a little bit, but mostly haphazardly."
3973,@GaryMarcus,2022-06-08 18:56:17+00:00,https://twitter.com/GaryMarcus/status/1534610283494117376,@bleepbeepbzzz @geoffreyhinton i didn‚Äôt make that clear in the original bet; certainly for AGI it should indeed be one.
3974,@GaryMarcus,2022-06-08 17:26:02+00:00,https://twitter.com/GaryMarcus/status/1534587570448785409,"@EvaSmartAI @bimedotcom @SubstackInc @slatestarcodex @nigewillson @andi_staub @mvollmer1 @Shi4Tech @tlloydjones @mikeflache @danfiehn @stratorob @globaliqx @wcrpaul @sonu_monika @TylerCohenWood @Khulood_Almani @TarakRindani @BetaMoroney @tobiaskintzel @JagersbergKnut @MiriamAsensi @RLDI_Lamy Two @hampshirecolg alumns,  speaking truth to bullshit"
3975,@GaryMarcus,2022-06-08 17:19:24+00:00,https://twitter.com/GaryMarcus/status/1534585898330861573,"@jonathanrlarkin read the substack and be systematic, or conversation is done; i wrote a long thoughtful reply to this argument, yesterday"
3976,@GaryMarcus,2022-06-08 17:14:48+00:00,https://twitter.com/GaryMarcus/status/1534584742053416960,"@jonathanrlarkin so if you are going to run them playground, keep track of all your successes and failures and report the full data, if you want the data to be meaningful, especially when working with a stochastic system"
3977,@GaryMarcus,2022-06-08 17:13:22+00:00,https://twitter.com/GaryMarcus/status/1534584382479925248,"@jonathanrlarkin that‚Äôs a more careful statement and more careful question. it‚Äôs very much addressed in my most recent entry, re @slatestarcodex in https://t.co/8ir1xKvqt6"
3978,@GaryMarcus,2022-06-08 17:11:57+00:00,https://twitter.com/GaryMarcus/status/1534584024588378113,"fabrication is the worst. i truly hate it when people put into quote marks things i didn‚Äôt say. 

literally nowhere in the entire book https://t.co/FLZ9VvNAQH did we say ‚ÄúAI could never do‚Äù anything. 

ü§Ø"
3979,@GaryMarcus,2022-06-08 16:55:40+00:00,https://twitter.com/GaryMarcus/status/1534579929509072896,"@iPrabhavKaula @geoffreyhinton i would be happy to discuss with him, since he was implicitly referring to me in the quote."
3980,@GaryMarcus,2022-06-08 16:53:03+00:00,https://twitter.com/GaryMarcus/status/1534579269573128193,@jonathanrlarkin nowhere in the book did we say ‚ÄúAI could never‚Äù do anything
3981,@GaryMarcus,2022-06-08 16:36:07+00:00,https://twitter.com/GaryMarcus/status/1534575007333879808,Open letter to @geoffreyhinton: https://t.co/fUjAg6CU1T
3982,@GaryMarcus,2022-06-08 16:34:35+00:00,https://twitter.com/GaryMarcus/status/1534574622070280192,@BrandonLive @CadeMetz @Tesla https://t.co/JpgRmxl1vR
3983,@GaryMarcus,2022-06-08 16:27:17+00:00,https://twitter.com/GaryMarcus/status/1534572783140605952,"@BrandonLive @CadeMetz @Tesla who (besides Tesla which featured its CEO on 60 Minutes driving L2 hands free). nobody should do that, certainly"
3984,@GaryMarcus,2022-06-08 16:20:26+00:00,https://twitter.com/GaryMarcus/status/1534571062100316161,"@BrandonLive @CadeMetz @Tesla few have made such strong claims, but i don‚Äôt expect to be roses for any"
3985,@GaryMarcus,2022-06-08 16:15:46+00:00,https://twitter.com/GaryMarcus/status/1534569884570378240,"üíØ, and indeed Twitter‚Äôs unsuitability to serious scientific discussions is precisely why i wrote a longer reply to @slatestarcodex and also precisely why I started https://t.co/8ir1xKvqt6 

Also why I run a series of debates with @ceobillionaire: https://t.co/Q9NsPRxZk4"
3986,@GaryMarcus,2022-06-08 15:55:35+00:00,https://twitter.com/GaryMarcus/status/1534564805431861248,My next Substack post is gonna be something *completely* different :)
3987,@GaryMarcus,2022-06-08 15:38:00+00:00,https://twitter.com/GaryMarcus/status/1534560383708434433,@BrandonLive @CadeMetz @Tesla $100 says its not going to look good for Tesla.
3988,@GaryMarcus,2022-06-08 13:10:57+00:00,https://twitter.com/GaryMarcus/status/1534523376907083776,"two paragraphs buried in @CadeMetz‚Äôs newest article on autonomous driving that should make @tesla shareholders pretty nervous:

source: https://t.co/xPR0oDRau1 https://t.co/fR5eBqXqlG"
3989,@GaryMarcus,2022-06-08 13:02:57+00:00,https://twitter.com/GaryMarcus/status/1534521362278010880,Sound bites and science don‚Äôt mix.
3990,@GaryMarcus,2022-06-08 13:02:31+00:00,https://twitter.com/GaryMarcus/status/1534521253502939136,"@FelixHill84 @peligrietzer ps this exchange gave me a really good idea for something I am planning to write that is about improving human thinking, rather than about  AI :)"
3991,@GaryMarcus,2022-06-08 12:57:44+00:00,https://twitter.com/GaryMarcus/status/1534520049406382081,"@FelixHill84 @peligrietzer facts tend to invite inferences, sometimes correctly sometimes not"
3992,@GaryMarcus,2022-06-08 12:57:09+00:00,https://twitter.com/GaryMarcus/status/1534519903020908544,"@FelixHill84 @peligrietzer as you well know, i call‚Äôem like I see‚Äôem :)

overall quality has improved significantly over time IMHO!"
3993,@GaryMarcus,2022-06-08 12:56:01+00:00,https://twitter.com/GaryMarcus/status/1534519616164069376,"It‚Äôs a disconcerting fact about modern intellectual life and to a lesser extent Twitter) that 800 people liked this pithy summary but only 20 bothered to look at the counter analysis linked lower in the thread.

Science reduced to sound bites."
3994,@GaryMarcus,2022-06-08 12:52:22+00:00,https://twitter.com/GaryMarcus/status/1534518698718810112,"@FelixHill84 @peligrietzer but much more experience with whatever it has (consider Gato) and still makes baffling mistakes with things it experiences. 

not your finest counterargument, tbh"
3995,@GaryMarcus,2022-06-08 12:42:02+00:00,https://twitter.com/GaryMarcus/status/1534516098577510400,"@hardmaru @MelMitchell1 @fchollet @ChrSzegedy completely agree; had to point out Ernie because he was so integral to the specifics of what were discussed, and should have made your point as well."
3996,@GaryMarcus,2022-06-08 12:39:26+00:00,https://twitter.com/GaryMarcus/status/1534515444563865600,"@patriciosimari @LechMazur @slatestarcodex in his defense it was presented as an inductive argument, not a deductive argument, and not presented as a proof but an intuition.

that said, as discussed I was not convinced."
3997,@GaryMarcus,2022-06-08 12:36:51+00:00,https://twitter.com/GaryMarcus/status/1534514792819326976,"@peligrietzer kids just don‚Äôt make that many massive semantic mistakes, and the ones they make are typically a function of less experience w the world (eg they ‚Äúconfuse‚Äù dogs and cats only briefly, if it all, probably because they just don‚Äôt have that much experience)"
3998,@GaryMarcus,2022-06-08 12:34:42+00:00,https://twitter.com/GaryMarcus/status/1534514252857282563,"@bbenzon @peligrietzer thanks. indeed most of my early work is in that field, and my 1992 monograph on children‚Äôs overregularization errors is still one of the most cited works on that topic :)"
3999,@GaryMarcus,2022-06-08 12:31:31+00:00,https://twitter.com/GaryMarcus/status/1534513453041274881,"@nektariosmusic @ylecun actually, I have never been comfortable making this argument. it is unfair to call ‚Äúneural‚Äù networks biologically plausible, but also to say that they couldn‚Äôt possibly be biologically plausible. right now we just know too little about the brain (even the right level of analysis)"
4000,@GaryMarcus,2022-06-08 03:01:07+00:00,https://twitter.com/GaryMarcus/status/1534369907030126592,@srikumarks @DrLaurenOR @ykilcher @huggingface the fact that no ethics approval was required is itself a further wake-up call
4001,@GaryMarcus,2022-06-08 02:57:40+00:00,https://twitter.com/GaryMarcus/status/1534369039069454340,"@srikumarks @DrLaurenOR @ykilcher @huggingface this has potential to scales hurtful uncivility to the nth degree, just as LLMs have likely already scaled misinformation"
4002,@GaryMarcus,2022-06-08 02:56:39+00:00,https://twitter.com/GaryMarcus/status/1534368780343812097,"@srikumarks @DrLaurenOR @ykilcher @huggingface i just don‚Äôt want to spell it all out to give people ideas but i think the same kind of hack in a different context could cause a lot of suffering to a lot of people, and the ease with which this hack was done is something that needs to be reckoned with."
4003,@GaryMarcus,2022-06-08 02:54:24+00:00,https://twitter.com/GaryMarcus/status/1534368217765801984,"@DrLaurenOR @srikumarks @ykilcher @huggingface the reason i am somewhere in between on this is that doing this in a controlled way on 4chan helps the community to predict‚Äîand maybe defend‚Äîagainst much worse things that one can imagine

it‚Äôs a clear warning."
4004,@GaryMarcus,2022-06-08 02:47:48+00:00,https://twitter.com/GaryMarcus/status/1534366553516523522,"@sl8rv @quaesita Darkness falls across the land
The AGI hour is close at hand
Robots crawl in search of blood
‚Ä¶

go, @sl8rv (&amp; @quaesita if you care to join"
4005,@GaryMarcus,2022-06-07 23:45:48+00:00,https://twitter.com/GaryMarcus/status/1534320751867748353,"game on :)

comment below, under my reply to @ChrSzegedy to help us formalize details :)"
4006,@GaryMarcus,2022-06-07 22:34:01+00:00,https://twitter.com/GaryMarcus/status/1534302686325055488,"@MMikeMMa @AI21Labs probably, but weighting recency seems to me like a half-baked, partial solution. eg you might want to know who the previous president was."
4007,@GaryMarcus,2022-06-07 22:20:19+00:00,https://twitter.com/GaryMarcus/status/1534299241350189056,"@MMikeMMa if you mean lose their freshness like the Preisdent example in the reply to SSC, i think it is hard to know. but it‚Äôs definitely an issue. @AI21Labs"
4008,@GaryMarcus,2022-06-07 21:43:44+00:00,https://twitter.com/GaryMarcus/status/1534290035675041793,"The AI hype cycle, as summed up by @slatestarcodex, and my reply: https://t.co/B5i2PVT56s https://t.co/gndqttSzIn"
4009,@GaryMarcus,2022-06-07 20:35:26+00:00,https://twitter.com/GaryMarcus/status/1534272846804881408,"@ChrSzegedy @MelMitchell1 Ok @ErnestSDavis &amp; I will take your action, up to $100. There is nothing yet we know that can read any kind of mathematical article or book with unformalized proofs and turn it into formalization. Gap between mathematics in English and mathematics in formal notation is enormous."
4010,@GaryMarcus,2022-06-07 18:58:29+00:00,https://twitter.com/GaryMarcus/status/1534248448806899712,"Impromptu online debate!

It's @slatestarcodex vs @garymarcus!
dueling Substacks! 
more bets!

his: https://t.co/fF83oNkmOm

mine: https://t.co/Gh51GFX4pu

subscribe to both :)

üçøoptional"
4011,@GaryMarcus,2022-06-07 18:37:14+00:00,https://twitter.com/GaryMarcus/status/1534243099404214275,@yoavgo @maxisawesome538 and in fact that is what he argues
4012,@GaryMarcus,2022-06-07 17:53:23+00:00,https://twitter.com/GaryMarcus/status/1534232063418638336,"@__dipam__ @ChrSzegedy @MelMitchell1 @ErnestSDavis @f_charton @MatthewJBar @Abel_TorresM excellent questions, open to suggestions."
4013,@GaryMarcus,2022-06-07 17:52:47+00:00,https://twitter.com/GaryMarcus/status/1534231911731585024,@begusgasper open to suggestions.
4014,@GaryMarcus,2022-06-07 17:38:50+00:00,https://twitter.com/GaryMarcus/status/1534228403842260993,@alanrew @vkrakovna as that is her list :)
4015,@GaryMarcus,2022-06-07 17:38:27+00:00,https://twitter.com/GaryMarcus/status/1534228304533671936,@alanrew @vkrakovna keeps such a list! (which we excerpt in https://t.co/Pt7HZbLIv5)
4016,@GaryMarcus,2022-06-07 17:36:06+00:00,https://twitter.com/GaryMarcus/status/1534227713904431104,@__dipam__ @ChrSzegedy @MelMitchell1 @ErnestSDavis @f_charton @MatthewJBar @Abel_TorresM what would you see as a fair elaboration of 4?
4017,@GaryMarcus,2022-06-07 17:34:33+00:00,https://twitter.com/GaryMarcus/status/1534227326191271937,"@patrickmesana @ylecun i think it‚Äôs an oversimplification, a shorthand. so maybe agree with @ylecun, depending on what he means."
4018,@GaryMarcus,2022-06-07 15:42:18+00:00,https://twitter.com/GaryMarcus/status/1534199074869551104,"@ChrSzegedy @MelMitchell1 @ErnestSDavis @f_charton @MatthewJBar @Abel_TorresM also, i have reposted Christian‚Äôs ranking to my followers, everyone welcome to participate:"
4019,@GaryMarcus,2022-06-07 15:39:13+00:00,https://twitter.com/GaryMarcus/status/1534198299581829121,"totally agree it depends on the effort put in. i think you are underestimating how hard language is, but interested to see your predictions, and I appreciate your engaging in the discussion!

if elon put his full fortune in, and spent it wisely, I think he could win the bet :)"
4020,@GaryMarcus,2022-06-07 15:32:06+00:00,https://twitter.com/GaryMarcus/status/1534196508270006272,"Add your predictions to this thread, ranking all five and feeling free to justify your answers.

Save your work; they will soon be up on https://t.co/LEReNmttru and you can post there."
4021,@GaryMarcus,2022-06-07 15:07:31+00:00,https://twitter.com/GaryMarcus/status/1534190323554930688,"@terrible_archer @ylecun (yann‚Äôs not on that one), starts 9am PT"
4022,@GaryMarcus,2022-06-07 14:22:39+00:00,https://twitter.com/GaryMarcus/status/1534179033839112192,"Not quite so. I recently wrote a detailed response to a post by @ylecun, outlining some specific areas of agreement &amp; disagreement: https://t.co/zISLebZk7A

and see also https://t.co/0TkGWSKVk2"
4023,@GaryMarcus,2022-06-07 14:18:19+00:00,https://twitter.com/GaryMarcus/status/1534177940333658112,"@OsherL @mrgreene1977 that could happen, he could lose in court and then pay the breakup fee (and possibly get sued on top for further damages)"
4024,@GaryMarcus,2022-06-07 14:09:54+00:00,https://twitter.com/GaryMarcus/status/1534175822789025792,@bsgallagher we may find out in court!
4025,@GaryMarcus,2022-06-07 14:09:17+00:00,https://twitter.com/GaryMarcus/status/1534175668681834497,@CACMmag @sciam thanks @CACMmag for sharing this with your audience!
4026,@GaryMarcus,2022-06-07 13:09:41+00:00,https://twitter.com/GaryMarcus/status/1534160668630188032,"Mercurial zillionaire aims to take 2nd largest social media company private, then to back out of deal. 

Legal case seems weak, since he waived due diligence.

üëâroot for him to find excuse he needs; keeping twitter public is greater good
üëâroot against him; legal case is shoddy"
4027,@GaryMarcus,2022-06-07 13:04:38+00:00,https://twitter.com/GaryMarcus/status/1534159398158733312,"@kleinsouza @ChrSzegedy @MelMitchell1 ‚Äúa proof about transcendental numbers, in the style of Gauss.‚Äù"
4028,@GaryMarcus,2022-06-07 12:56:45+00:00,https://twitter.com/GaryMarcus/status/1534157412646539264,"@ChrSzegedy @MelMitchell1 Note that my proposed Musk bet was about AGI, and required 3 of 5 (ideally all by a single system). 

I‚Äôm less interested in a narrow AI solution, but still intrigued, especially with language *included* as you suggest.

@ErnestSDavis @f_charton @MatthewJBar @Abel_TorresM"
4029,@GaryMarcus,2022-06-07 04:25:22+00:00,https://twitter.com/GaryMarcus/status/1534028720515584000,@rayerskins @DjAlkimi @hillel_art @arttank the bet is here https://t.co/lEal60e54Z
4030,@GaryMarcus,2022-06-07 03:41:05+00:00,https://twitter.com/GaryMarcus/status/1534017576069742594,"@srikumarks @slatestarcodex don‚Äôt know if the data gets added to training - it‚Äôs an interesting question!

i didn‚Äôt find it compelling, either. and have drafted a reply, likely will post tomorrow morning PT."
4031,@GaryMarcus,2022-06-07 02:16:28+00:00,https://twitter.com/GaryMarcus/status/1533996283089735680,"Coming soon, to https://t.co/8ir1xKvqt6, my reply to @slatestarcodex‚Äôs dissection of @garymarcus examples :)

As ever, subscribers see it first :)"
4032,@GaryMarcus,2022-06-07 01:13:27+00:00,https://twitter.com/GaryMarcus/status/1533980425005064192,". ‚Å¶@slatestarcodex‚Å© writes 3,600 words critiquing ‚Ä¶ @garymarcus!

My reply coming soon :)
  https://t.co/1GsPRQ7ZeT"
4033,@GaryMarcus,2022-06-07 00:27:32+00:00,https://twitter.com/GaryMarcus/status/1533968869315989505,"hey @slatestarcodex  interesting analysis; follow back so we can discuss?

also re bets, see the bet (&amp; criteria) i offered Elon last week @ https://t.co/8ir1xKdPBy, which now stands at $500k."
4034,@GaryMarcus,2022-06-06 20:54:55+00:00,https://twitter.com/GaryMarcus/status/1533915362219020288,"@DuaneJRich @ylecun thanks, but as a human being, i also care about the rampant and consistent misrepresentation of my position. portraying me as a late follower to something I myself pushed for years against resistance is both unfair and a distortion of intellectual history."
4035,@GaryMarcus,2022-06-06 20:52:16+00:00,https://twitter.com/GaryMarcus/status/1533914692988547072,"@miguelisolano @FelixHill84 @ylecun @ZoubinGhahrama1 @AliceAlbrecht I was thinking more eg of her work on the origins of discrete number counting systems and her book The Origin of Concepts, than fast mapping (also hers) per se. @StanDehaene has also thought a lot about such things."
4036,@GaryMarcus,2022-06-06 20:34:39+00:00,https://twitter.com/GaryMarcus/status/1533910261517602816,"‚ÄúPeople love spending time with a disruptor like me. At home, you‚Äôre just doing what you‚Äôre doing all day with no interruptions. At the office, I might see what you‚Äôre doing, tear it all up, and tell you to start over. You can‚Äôt put a price tag on‚Ä¶ that.‚Äù https://t.co/6rIMLcwmfM"
4037,@GaryMarcus,2022-06-06 20:16:25+00:00,https://twitter.com/GaryMarcus/status/1533905672990887936,@fjmendez @sciam but see the Musk piece at (and subscribe to) https://t.co/8ir1xKvqt6
4038,@GaryMarcus,2022-06-06 19:53:10+00:00,https://twitter.com/GaryMarcus/status/1533899823077699584,@rolisz @f_charton @ErnestSDavis @sameer_
4039,@GaryMarcus,2022-06-06 19:52:08+00:00,https://twitter.com/GaryMarcus/status/1533899559981658112,"@begusgasper but think what power Lisp got from linked lists.

i argue in the Birth of the Mind that recursion added to a primate genome takes you a huge way."
4040,@GaryMarcus,2022-06-06 19:33:21+00:00,https://twitter.com/GaryMarcus/status/1533894833789472768,"@nirsd @ylecun i have years of them, on that very point. that‚Äôs just a sample."
4041,@GaryMarcus,2022-06-06 19:13:01+00:00,https://twitter.com/GaryMarcus/status/1533889717804015616,"@ylecun Shaking my head; see some history in this mini thread for what you said before when I said exact same thing in 2018, and how dismissive you were then.   https://t.co/23s88x7AJP"
4042,@GaryMarcus,2022-06-06 19:11:15+00:00,https://twitter.com/GaryMarcus/status/1533889272448659457,receipt: https://t.co/B5dnM7LchH
4043,@GaryMarcus,2022-06-06 19:05:37+00:00,https://twitter.com/GaryMarcus/status/1533887856170528768,"2018:
@garymarcus: deep learning is only part of the solution; we need other tools for reasoning, etc.
@erikbryn: Very interesting‚Ä¶
@ylecun: ‚Äúbut mostly wrong‚Äù

2022:
@garymarcus: DL is still only part of solution; we need other tools
@ylecun 2022: ‚ÄúWelcome to my world!‚Äù

üôÑ"
4044,@GaryMarcus,2022-06-06 18:42:28+00:00,https://twitter.com/GaryMarcus/status/1533882027132350464,@JFPuget @skdh most definitely
4045,@GaryMarcus,2022-06-06 18:20:05+00:00,https://twitter.com/GaryMarcus/status/1533876395574579200,"on language, variables, and the origins of knowledge;  interesting conversation with @FelixHill84 of @DeepMind, sparked by @ylecun‚Äôs thoughts on @ch402‚Äôs ml/biology analogy (with an aside about my own position, &amp; a reminder that I think DL needs to be supplemented, not replaced)"
4046,@GaryMarcus,2022-06-06 18:13:38+00:00,https://twitter.com/GaryMarcus/status/1533874773507178497,@FelixHill84 @ylecun @ZoubinGhahrama1 or maybe just maybe that doesn‚Äôt have to be either/or
4047,@GaryMarcus,2022-06-06 18:11:49+00:00,https://twitter.com/GaryMarcus/status/1533874314096701440,but will we have the wisdom to recognize dead ends when we hit them?
4048,@GaryMarcus,2022-06-06 18:11:17+00:00,https://twitter.com/GaryMarcus/status/1533874182060027904,"@FelixHill84 @ylecun @ZoubinGhahrama1 if you can do the work that i want done (reasoning, including causal, temporal. physical and psychological reasoning) without variables, more power to you."
4049,@GaryMarcus,2022-06-06 18:07:56+00:00,https://twitter.com/GaryMarcus/status/1533873339709566976,@FelixHill84 @ylecun @ZoubinGhahrama1 that is exactly the right problem: where we do get the variables from? best work is maybe Susan Carey in cognitive development context; AI has not caught up
4050,@GaryMarcus,2022-06-06 17:50:57+00:00,https://twitter.com/GaryMarcus/status/1533869064828858368,"@FelixHill84 @ylecun @ZoubinGhahrama1 i think at the absolute least you need priors about there being persisting objects, places, agents in the world"
4051,@GaryMarcus,2022-06-06 17:50:10+00:00,https://twitter.com/GaryMarcus/status/1533868867918761984,@FelixHill84 @ylecun @sapinker we ran into each other on a plane in 2018 or so and had a great chat about old times :)
4052,@GaryMarcus,2022-06-06 17:38:44+00:00,https://twitter.com/GaryMarcus/status/1533865990173257728,@FelixHill84 @ylecun @sapinker how are his streams not dichotomous? i never understood why didn‚Äôt cite our well-known related work and compare and contrast‚Ä¶
4053,@GaryMarcus,2022-06-06 17:37:05+00:00,https://twitter.com/GaryMarcus/status/1533865576434610176,"@FelixHill84 @ylecun @ZoubinGhahrama1 now, just about anywhere in the world you can study large language models, which in a decade people will realize were not that useful for  natural language understanding, after all."
4054,@GaryMarcus,2022-06-06 17:18:11+00:00,https://twitter.com/GaryMarcus/status/1533860817384329217,@FilipoGiovanni @ylecun do i get to strawman ‚ÄúMarcus‚Äù or do I have to behave myself?
4055,@GaryMarcus,2022-06-06 17:13:16+00:00,https://twitter.com/GaryMarcus/status/1533859579812929536,"@FelixHill84 @ylecun on that I fully agree, the system is not remotely fair. genuinely novelty is rarely rewarded; much easier to get funded doing what everyone else is doing."
4056,@GaryMarcus,2022-06-06 17:12:20+00:00,https://twitter.com/GaryMarcus/status/1533859347444293633,"@FelixHill84 @ylecun and, brother, what academic has not faced a ton of rejections? certainly not me."
4057,@GaryMarcus,2022-06-06 17:11:27+00:00,https://twitter.com/GaryMarcus/status/1533859125657862145,"@FelixHill84 @ylecun that‚Äôs stuff is so exaggerated.  Hinton ran the huge Gatsby institute in London, with Dayan, @ZoubinGhahrama1 and other stars at his side."
4058,@GaryMarcus,2022-06-06 17:06:29+00:00,https://twitter.com/GaryMarcus/status/1533857871959511041,"@FelixHill84 @ylecun - transformers didn‚Äôt exist in 1992
- even today transformers have a lot of trouble generalizing in an across the board way (which was what the 1992 monograph was about), see @yasaman_razeghi and @sameer_ 2022 arXiv"
4059,@GaryMarcus,2022-06-06 17:04:15+00:00,https://twitter.com/GaryMarcus/status/1533857313961889794,"@FelixHill84 @ylecun also, i don‚Äôt know what CS departments per se were doing in 1992, but psychology and cogsci departments were certainly hiring lots of neural net people. People like Rumelhart, McClelland, Jordan (then doing neural nets), Elman, Seidenberg were employed by top departments, etc."
4060,@GaryMarcus,2022-06-06 17:00:50+00:00,https://twitter.com/GaryMarcus/status/1533856452929916931,"@FelixHill84 @ylecun but no to ‚Äúa bit‚Äù; that‚Äôs your wording, not mine. i think humans use a ton of symbolic knowledge."
4061,@GaryMarcus,2022-06-06 17:00:09+00:00,https://twitter.com/GaryMarcus/status/1533856281034797056,"@FelixHill84 @ylecun Yes, the conclusion of my monograph on overregularization with @sapinker (my first publication, 1992) was for a hybrid model, associative network for irregulars, symbolic rule for regulars.

https://t.co/3VeqRZB4RX

Also, it was the whole point of my 2001 book, The Algebraic Mind"
4062,@GaryMarcus,2022-06-06 16:55:46+00:00,https://twitter.com/GaryMarcus/status/1533855175143591937,"6/6 ‚ÄúIt‚Äôs time for artificial intelligence researchers to look up.  We can‚Äôt ‚Äòsolve AI‚Äô  with PR alone.‚Äù

Excerpt from my new oped, @sciam https://t.co/OFY9IPlR6F"
4063,@GaryMarcus,2022-06-06 16:55:45+00:00,https://twitter.com/GaryMarcus/status/1533855174208303104,"5/6 ‚ÄúCurrent engineering practice is far ahead of scientific skills, working harder to use tools that aren‚Äôt fully understood  than to develop new tools and a clearer theoretical ground. This is why basic research remains crucial.‚Äù"
4064,@GaryMarcus,2022-06-06 16:55:45+00:00,https://twitter.com/GaryMarcus/status/1533855173218512898,"4/6 ‚ÄúInstead of pursuing flashy straight-to-the-media demos, we need more people asking basic questions about how to build systems that can learn and reason at the same time.‚Äù"
4065,@GaryMarcus,2022-06-06 16:55:45+00:00,https://twitter.com/GaryMarcus/status/1533855172236935168,"3/6 ‚ÄúFor now, we are trapped in a ‚Äúlocal minimum‚Äù in which companies pursue benchmarks, rather than foundational ideas, eking out small improvements with the technologies they already have rather than pausing to ask more fundamental questions.‚Äù"
4066,@GaryMarcus,2022-06-06 16:55:45+00:00,https://twitter.com/GaryMarcus/status/1533855170928316417,"2/6 ‚Äúif core problems of reliability and coping with outliers are not resolved, investment will dry up. We will be left with ‚Ä¶ deepfake‚Ä¶ networks that emit immense amounts of carbon.. advances in machine translation, speech recognition &amp; object recognition, but too little else‚Äù"
4067,@GaryMarcus,2022-06-06 16:55:44+00:00,https://twitter.com/GaryMarcus/status/1533855169443598336,"1/6 ""Cold fusion may have sounded great, but you still can‚Äôt get it at the mall..the cost [of AI hype] is likely to be a winter of deflated expectations. Too many products, like driverless cars‚Ä¶ radiologists and..digital agents, have been demoed, publicized‚Äîand never delivered.‚Äù"
4068,@GaryMarcus,2022-06-06 16:43:26+00:00,https://twitter.com/GaryMarcus/status/1533852074550562816,"@ylecun That‚Äôs historical revisionism; the quote I gave you was from 2018, from a paper you called ‚Äúmostly wrong‚Äù, and I have been calling for same since 1992.  

The only thing late (‚Äúwelcome to my world‚Äù) is your recognition of what my position actually is."
4069,@GaryMarcus,2022-06-06 16:41:23+00:00,https://twitter.com/GaryMarcus/status/1533851557925531650,@m_misamore @ylecun i have been saying the same things since before I was old enough to drink but it‚Äôs nice of @ylecun to finally notice.
4070,@GaryMarcus,2022-06-06 16:32:05+00:00,https://twitter.com/GaryMarcus/status/1533849215251623936,"IMHO the real elegance in biology (which is not as elegant as physics) comes from the way in which developmental biology leverages small amount of info to structure great complexity.

@ch402 @DeWeeseLab @WiringTheBrain 

https://t.co/ozpe9LJf75"
4071,@GaryMarcus,2022-06-06 16:30:45+00:00,https://twitter.com/GaryMarcus/status/1533848879661166592,@JFPuget For clarity: I cited it as an example of what people seeking elegance strive for (but sympathetic to eg @skdh and Smolin‚Äôs concerns)
4072,@GaryMarcus,2022-06-06 16:27:07+00:00,https://twitter.com/GaryMarcus/status/1533847967953657856,"@DeWeeseLab by ‚Äúenough‚Äù I meant ‚Äúenough cognitive sophistication‚Äù or ‚Äúsufficiently structured cognitive systems as an endproduct, post-training‚Äù. we don‚Äôt get enough in that sense, even after setting a trillion parameters."
4073,@GaryMarcus,2022-06-06 16:25:32+00:00,https://twitter.com/GaryMarcus/status/1533847569335365632,"@DeWeeseLab CNN‚Äôs architecture is way simpler; low info to specify.

but

the point on innateness I have been making: unrealistic to expect sophistication of human cognition by using such minimal priors + data; rather than leveraging more prewired information to constrained what is learned"
4074,@GaryMarcus,2022-06-06 16:19:52+00:00,https://twitter.com/GaryMarcus/status/1533846140478574592,@ylecun https://t.co/X85vyfyEA7
4075,@GaryMarcus,2022-06-06 14:49:16+00:00,https://twitter.com/GaryMarcus/status/1533823343052222466,"e.g., slide from today‚Äôs keynote, in a few minutes https://t.co/4iWmfoouG0"
4076,@GaryMarcus,2022-06-06 14:46:21+00:00,https://twitter.com/GaryMarcus/status/1533822608658952192,"I feel strawmanned, again, @ylecun. Enclosed is the crux of my argument, used in literally every talk.

I have never called for the replacement of deep learning/gradient descent. What comes next is *other* tools, like symbol-manipulation operations, working together with SGD. https://t.co/zgHTfqJDoX"
4077,@GaryMarcus,2022-06-06 14:15:17+00:00,https://twitter.com/GaryMarcus/status/1533814788953804801,rehearsals for #AIDay2
4078,@GaryMarcus,2022-06-06 14:06:11+00:00,https://twitter.com/GaryMarcus/status/1533812498612117504,@cyberandy @mrgreene1977 @wadhwa @midjourney @lathropa
4079,@GaryMarcus,2022-06-06 13:53:11+00:00,https://twitter.com/GaryMarcus/status/1533809228560773121,image by DALL-E mini/@lathropa
4080,@GaryMarcus,2022-06-06 13:53:11+00:00,https://twitter.com/GaryMarcus/status/1533809226589425664,https://t.co/ETBnTQCR6c
4081,@GaryMarcus,2022-06-06 13:41:52+00:00,https://twitter.com/GaryMarcus/status/1533806381815345153,"@DeWeeseLab we do.  but do we get enough? biology (in human brain development), it is uses a tightly evolved set of 20k genes to constrain the trillions of parameters, rather than leaving entirely to chance.

which makes the system more robust and more efficient relative to data"
4082,@GaryMarcus,2022-06-06 02:39:54+00:00,https://twitter.com/GaryMarcus/status/1533639791991853056,@ylecun https://t.co/36cIo7Nb4W
4083,@GaryMarcus,2022-06-06 02:00:53+00:00,https://twitter.com/GaryMarcus/status/1533629973361135616,"stimulating conversation with @ch402, re biology and computation"
4084,@GaryMarcus,2022-06-06 01:57:35+00:00,https://twitter.com/GaryMarcus/status/1533629142003945473,@ch402 @stephen_wolfram @MelMitchell1 another way to think about minimal bridges might be in terms of a minimal primitives in a language like Lisp: https://t.co/URxFVoXQxD
4085,@GaryMarcus,2022-06-06 01:55:34+00:00,https://twitter.com/GaryMarcus/status/1533628634656669696,"@ch402 @stephen_wolfram @MelMitchell1 Great question! The Algebraic Mind proposed a possible minimal set that needed to be bridged:  operations over variables (including storage, retrieval, and comparison), a type-token distinction, and machinery for structured, hierarchical representations."
4086,@GaryMarcus,2022-06-06 01:51:47+00:00,https://twitter.com/GaryMarcus/status/1533627680343543808,@ChrSzegedy @iraphas13 @ch402 @stephen_wolfram @MelMitchell1 pandemic hasn‚Äôt helped‚Ä¶
4087,@GaryMarcus,2022-06-05 23:08:00+00:00,https://twitter.com/GaryMarcus/status/1533586462939258880,"just now, British Columbia: https://t.co/y6cJ1fNV3Z"
4088,@GaryMarcus,2022-06-05 22:29:02+00:00,https://twitter.com/GaryMarcus/status/1533576657130377216,"@ch402 @stephen_wolfram @MelMitchell1 i have started a longer essay on semantics and understanding; stay tuned, and DM if you would like to see a draft when it‚Äôs further along"
4089,@GaryMarcus,2022-06-05 22:28:11+00:00,https://twitter.com/GaryMarcus/status/1533576443950776320,"@ch402 @stephen_wolfram @MelMitchell1 100% support trying to identify specific hypothesized mechanisms, and will be curious to see how such mechanism relate to the classic operations of symbol-manipulation (which includes store-and-retrieve/copy and paste, as well as variable instantiation more generally)."
4090,@GaryMarcus,2022-06-05 22:16:39+00:00,https://twitter.com/GaryMarcus/status/1533573542700363777,"@santoroAI fair. but i would put it differently: parsimony might require a zillion parameters, but that doesn‚Äôt make it elegant."
4091,@GaryMarcus,2022-06-05 22:15:25+00:00,https://twitter.com/GaryMarcus/status/1533573231030018049,"@ch402 @stephen_wolfram yes this is excellent. (in my book i used topographic maps to make this point)

it‚Äôs the stuff of which innateness is made. 

when the cascades are rich enough, you have massive power, like writing Python with a bunch of awesome libraries.

then maybe you need a lot less data"
4092,@GaryMarcus,2022-06-05 22:11:21+00:00,https://twitter.com/GaryMarcus/status/1533572209477832706,"true. importantly though, unbelievable power ‚â† unlimited power, and progress will only come through appreciating the limits in order to understand what needs to come next."
4093,@GaryMarcus,2022-06-05 22:08:48+00:00,https://twitter.com/GaryMarcus/status/1533571565123682309,"@ch402 @stephen_wolfram pretty sure it is true :) @WiringTheBrain @Dr_SimonFisher 
(some of the argument is in my book The Birth of The Mind, which tries relate the cognitive science of innateness with the mechanisms of developmental biology)"
4094,@GaryMarcus,2022-06-05 22:06:12+00:00,https://twitter.com/GaryMarcus/status/1533570914041974785,@ch402 @stephen_wolfram @UriAlonWeizmann
4095,@GaryMarcus,2022-06-05 22:01:10+00:00,https://twitter.com/GaryMarcus/status/1533569645986426888,@ch402 @stephen_wolfram yes the question of how to acquire new abstract representation is key; I am with @MelMitchell1 in finding current ML solutions wanting in that regard.
4096,@GaryMarcus,2022-06-05 21:59:36+00:00,https://twitter.com/GaryMarcus/status/1533569250597785606,"@ch402 @stephen_wolfram there‚Äôs in my view a strong argument that each gene is like a (separate) cellular automaton, firing under certain conditions, in order to build a self-organized (but partly preprogrammed, partly sensitive to environment) structure (eg heart or brain)."
4097,@GaryMarcus,2022-06-05 21:54:07+00:00,https://twitter.com/GaryMarcus/status/1533567873133826048,"@santoroAI one thing to say a kajillion parameters are necessary for a given task, another to say that is an *elegant* solution 

CYC has a kajillon parameters of a different sort but people rarely proclaim it to be elegant."
4098,@GaryMarcus,2022-06-05 21:52:43+00:00,https://twitter.com/GaryMarcus/status/1533567520015372289,"@ch402 glad to hear you are *not* lumping yourself in with those who have framed deep learning etc as biologically plausible (when there are many important disanalogies as well).

but couldn‚Äôt you make the same argument wrt to cellular automata, as @stephen_wolfram has?"
4099,@GaryMarcus,2022-06-05 18:41:43+00:00,https://twitter.com/GaryMarcus/status/1533519452305649664,@ParejaAldo @ch402 https://t.co/xPSM87iD10
4100,@GaryMarcus,2022-06-05 18:39:13+00:00,https://twitter.com/GaryMarcus/status/1533518822266707968,@seanmcarroll
4101,@GaryMarcus,2022-06-05 18:37:22+00:00,https://twitter.com/GaryMarcus/status/1533518358968008704,"Gradient descent may boggle some minds, but its connection to biology has always been tenuous.   

(And since when are 100 billion parameters the picture of elegance? Some string theorists might want to have a word‚Ä¶)"
4102,@GaryMarcus,2022-06-05 18:34:05+00:00,https://twitter.com/GaryMarcus/status/1533517533201895425,@ParejaAldo @ch402 i don‚Äôt really see the connection to biology.
4103,@GaryMarcus,2022-06-04 16:26:38+00:00,https://twitter.com/GaryMarcus/status/1533123069321125889,"@lathropa is that Elon in the bottom row, center? ü§£"
4104,@GaryMarcus,2022-06-04 16:23:34+00:00,https://twitter.com/GaryMarcus/status/1533122298588307457,"Dall-E-style GIF generator (eg ‚Äúdancing chicken dressed as a robot‚Äù)

Reasonably reliable, widely used:"
4105,@GaryMarcus,2022-06-04 16:15:54+00:00,https://twitter.com/GaryMarcus/status/1533120366499057666,"dall-e fans, please help :)"
4106,@GaryMarcus,2022-06-04 16:05:51+00:00,https://twitter.com/GaryMarcus/status/1533117838264832000,@mrgreene1977 @wadhwa was expecting a chicken in a robot costume but close enough :)
4107,@GaryMarcus,2022-06-04 15:59:47+00:00,https://twitter.com/GaryMarcus/status/1533116311756230658,@wadhwa ü§£ @mrgreene1977 has a theory about that‚Ä¶
4108,@GaryMarcus,2022-06-04 14:32:23+00:00,https://twitter.com/GaryMarcus/status/1533094316549324800,"@IntuitMachine thanks you, Carlos; I really appreciate your kind words."
4109,@GaryMarcus,2022-06-04 14:14:00+00:00,https://twitter.com/GaryMarcus/status/1533089691762933766,‚ù§Ô∏è
4110,@GaryMarcus,2022-06-04 04:44:11+00:00,https://twitter.com/GaryMarcus/status/1532946294276165633,thought-provoking video on bots and social media by @ykilcher.
4111,@GaryMarcus,2022-06-03 22:59:24+00:00,https://twitter.com/GaryMarcus/status/1532859525874712579,@bleepbeepbzzz @nutanc no. the question is whether the system can reliably infer the meanings of sentences from their composition.
4112,@GaryMarcus,2022-06-03 19:50:43+00:00,https://twitter.com/GaryMarcus/status/1532812040888123392,"‚âà ‚ÄúHomeless rich guy living in friend‚Äôs Austin, Texas mansion just can‚Äôt admit he was wrong.‚Äù"
4113,@GaryMarcus,2022-06-03 19:17:07+00:00,https://twitter.com/GaryMarcus/status/1532803584332423168,"@BeebsMemes then again their technical advantage in this domain is mainly (massive) data and infrastructure that pertains specifically to driving, rather than algorithmic innovation per se (or eg large-scale common sense knowledge). so there may be less to transfer than one might think."
4114,@GaryMarcus,2022-06-03 19:11:33+00:00,https://twitter.com/GaryMarcus/status/1532802184135380992,@grbradsk biggest technical mistake in my view is eschewing lidar when the software isn‚Äôt likely to be smart enough to do without it
4115,@GaryMarcus,2022-06-03 18:43:39+00:00,https://twitter.com/GaryMarcus/status/1532795161188528128,"@BeebsMemes just want to point out that in principle maybe you could do all that and solve driverless cars and still perhaps not have AGI, beyond the one application."
4116,@GaryMarcus,2022-06-03 18:41:35+00:00,https://twitter.com/GaryMarcus/status/1532794644026691584,"@BrandonLive for reference his exact words were ‚Äúi‚Äôd be surprised if we don‚Äôt have AGI by then‚Äù, which sounds to me stronger than ‚Äúcould‚Äùand weaker than ‚Äúwill‚Äù"
4117,@GaryMarcus,2022-06-03 17:37:49+00:00,https://twitter.com/GaryMarcus/status/1532778593993957376,"Musk has been (presumably deliberately) overpromising about AI over and over for *years*; maybe it motivates his employees, maybe it drives up the stock price and his net worth. 

definitely it distorts the public understanding of AI and its limits."
4118,@GaryMarcus,2022-06-03 17:24:50+00:00,https://twitter.com/GaryMarcus/status/1532775329885892609,@tdietterich that‚Äôs fine for some cases but not others (eg point to point driving without human involvement); in mixed cases perhaps the key issue is maintaining human vigilance
4119,@GaryMarcus,2022-06-03 17:15:38+00:00,https://twitter.com/GaryMarcus/status/1532773012881014784,"@ElliotMurphy91 i think @cedricboeckx is exactly right here, even if we don‚Äôt have an enough causal understanding to prove it. my own similar statement: https://t.co/n1731uyzcZ"
4120,@GaryMarcus,2022-06-03 16:49:26+00:00,https://twitter.com/GaryMarcus/status/1532766418239860736,"@elonmusk @jack $500,000 says you are wrong about the future of AI, @FortuneMagazine: https://t.co/MZjzZS8cec"
4121,@GaryMarcus,2022-06-03 16:42:19+00:00,https://twitter.com/GaryMarcus/status/1532764628735864832,".@ElonMusk, these experts will bet you $500,000 that you‚Äôre wrong about the future of A.I. https://t.co/MZjzZS8cec"
4122,@GaryMarcus,2022-06-03 16:39:42+00:00,https://twitter.com/GaryMarcus/status/1532763970439827456,"@orenmatar if that‚Äôs all it can do, they shouldn‚Äôt show it!"
4123,@GaryMarcus,2022-06-03 16:30:58+00:00,https://twitter.com/GaryMarcus/status/1532761773656268800,Seems to be some of that going around.
4124,@GaryMarcus,2022-06-03 16:16:15+00:00,https://twitter.com/GaryMarcus/status/1532758069578412032,"Optimus predictions (for #AIDay2, September 30) are coming in. Add yours to the thread below :)
- teleop?
- another dancer in a costume?
- or the real deal?
and if the real deal, what do you think will be the smartest thing it might do, and how robust do you think its AI will be?"
4125,@GaryMarcus,2022-06-03 13:39:45+00:00,https://twitter.com/GaryMarcus/status/1532718684770213893,"@bleepbeepbzzz @TristanThrush incidentally Google image search does just fine on ‚Äúcity floating in the clouds‚Äù (but not on ‚Äúhorse riding astronaut‚Äù). 

What one really wants to know is how the system does on cases outside the training distribution, which unfortunately we don‚Äôt have access to. 

cc @hardmaru"
4126,@GaryMarcus,2022-06-03 12:45:38+00:00,https://twitter.com/GaryMarcus/status/1532705065063985152,@IgorBrigadir possibly posted by a bot. but the question is a good one!
4127,@GaryMarcus,2022-06-03 12:44:00+00:00,https://twitter.com/GaryMarcus/status/1532704652516397062,@richsignorelli @elonmusk eg I bet him a 100k his latest comment about AI was nonsense‚Ä¶ https://t.co/ygD2ohOQ5V
4128,@GaryMarcus,2022-06-03 12:41:35+00:00,https://twitter.com/GaryMarcus/status/1532704046376660993,"I‚Äôd like to understand the logic behind this tweet. What can we expect from this prototype, &amp; how long might it take for that robot prototype to be battle-hardened enough to be useful on Mars or in prepping a mission to Mars?"
4129,@GaryMarcus,2022-06-03 12:35:30+00:00,https://twitter.com/GaryMarcus/status/1532702514482556929,@bleepbeepbzzz @TristanThrush will sort this out systematically :)
4130,@GaryMarcus,2022-06-03 05:44:41+00:00,https://twitter.com/GaryMarcus/status/1532599129590796288,"@RWerpachowski @pmddomingos @TaliaRinger on a quick skim (as I am about to go bed) i dont see distribution shift even mentioned here, in this seminal 2015 paper. https://t.co/9sFkpSna0r"
4131,@GaryMarcus,2022-06-03 05:29:26+00:00,https://twitter.com/GaryMarcus/status/1532595291949371392,"@pmddomingos @TaliaRinger sure. i certainly think *some* people have been aware (yourself included!). I do think that the deep learning community for too long confused within-distribution generalization with generalization, period, and I still see that from time to time."
4132,@GaryMarcus,2022-06-03 05:21:51+00:00,https://twitter.com/GaryMarcus/status/1532593383398486016,"@pmddomingos @TaliaRinger when I first wrote about in 1997 I was accused of ‚Äúa terrorist attack‚Äù on neural networks.

when I stressed it as the key weakness of MLPs in 2001, I was ignored

when I pointed it out in 2018, LeCun said I was ‚Äúmostly wrong‚Äù

etc etc"
4133,@GaryMarcus,2022-06-03 05:17:27+00:00,https://twitter.com/GaryMarcus/status/1532592276471283712,"six years ago in AI history: Tay, the neo-Nazi millennial chatbot, gets autopsied | Ars Technica https://t.co/GUkpx1ft5v"
4134,@GaryMarcus,2022-06-03 04:26:20+00:00,https://twitter.com/GaryMarcus/status/1532579413421764608,@emilymbender @TaliaRinger and in-crowd vs disdain for everything else
4135,@GaryMarcus,2022-06-03 04:03:37+00:00,https://twitter.com/GaryMarcus/status/1532573697508143108,"@TaliaRinger know the feeling. eg pointing out for 20 years that generalization outside the training space was an issue, being ignored (or ridiculed), and then suddenly *Bengio* says the magic words ‚Äúdistribution shift‚Äù‚Ä¶"
4136,@GaryMarcus,2022-06-03 02:04:01+00:00,https://twitter.com/GaryMarcus/status/1532543598780104707,"@Plinz @sciam i was about to say i would only make one bet this week, but then Elon posted about Optimus ü§£"
4137,@GaryMarcus,2022-06-03 02:02:30+00:00,https://twitter.com/GaryMarcus/status/1532543216565764109,"@BethCarey12 guestimate based on authors, computation costs etc."
4138,@GaryMarcus,2022-06-03 02:01:09+00:00,https://twitter.com/GaryMarcus/status/1532542874243448844,"media friends, i would love to cover this :) dm me?"
4139,@GaryMarcus,2022-06-03 00:24:32+00:00,https://twitter.com/GaryMarcus/status/1532518560710463489,"‚ÄúWell then, Musk‚Äîdo you accept Marcus‚Äô challenge?‚Äù asks @AI_TechNews"
4140,@GaryMarcus,2022-06-02 23:04:49+00:00,https://twitter.com/GaryMarcus/status/1532498499060740096,source: https://t.co/wKAnzSbUMC
4141,@GaryMarcus,2022-06-02 23:04:48+00:00,https://twitter.com/GaryMarcus/status/1532498497605226496,https://t.co/gFBv53QTLM
4142,@GaryMarcus,2022-06-02 22:32:34+00:00,https://twitter.com/GaryMarcus/status/1532490386102374401,"‚ÄúHe's a grifter, he sells a vision in hopes that he can one day deliver what he's promising, but he doesn't know that... He's just really good at pretending he knows‚Äù https://t.co/hyy79FfZdi"
4143,@GaryMarcus,2022-06-02 21:39:45+00:00,https://twitter.com/GaryMarcus/status/1532477092847230977,"Coming Monday, @sciam, my riff on Don‚Äôt Look Up (the AI edition)"
4144,@GaryMarcus,2022-06-02 21:31:11+00:00,https://twitter.com/GaryMarcus/status/1532474936861724672,@mraginsky @IntuitMachine @TonyZador @davidpoeppel @cedricboeckx transformational or not (eg minimalist program) that‚Äôs the conventional use of generative grammar
4145,@GaryMarcus,2022-06-02 21:29:46+00:00,https://twitter.com/GaryMarcus/status/1532474579544776705,@raphaelmilliere @hardmaru @_lexfridman wrong lex  but you get the idea
4146,@GaryMarcus,2022-06-02 21:29:22+00:00,https://twitter.com/GaryMarcus/status/1532474480953393153,@raphaelmilliere @hardmaru weird! and i was blocked by @_lexfridman. some things make no sense
4147,@GaryMarcus,2022-06-02 21:18:59+00:00,https://twitter.com/GaryMarcus/status/1532471864274014208,@bkeithpayne @drbret odds are good though that the (purely observational version of the) study would come out exactly as you joke
4148,@GaryMarcus,2022-06-02 21:12:43+00:00,https://twitter.com/GaryMarcus/status/1532470289107255296,@TheDavidSJ discussed this issue in the article
4149,@GaryMarcus,2022-06-02 21:05:57+00:00,https://twitter.com/GaryMarcus/status/1532468587549511680,@raphaelmilliere @hardmaru
4150,@GaryMarcus,2022-06-02 21:05:13+00:00,https://twitter.com/GaryMarcus/status/1532468403713155072,"@mraginsky @IntuitMachine @TonyZador sorry but this is confused; the Chomsky hierarchy is not the same as generative grammar, and the goal of generative grammar *is* to capture natural languages. 

@davidpoeppel @cedricboeckx want to add to that?"
4151,@GaryMarcus,2022-06-02 21:00:10+00:00,https://twitter.com/GaryMarcus/status/1532467129093529600,"Indeed my very title was an homage to Pinker‚Äôs simple yet compelling example. Would be fun for people to try Imagen and Dall-E on Man Bites Dog.

No cherry-picking please, full results only :)"
4152,@GaryMarcus,2022-06-02 20:20:21+00:00,https://twitter.com/GaryMarcus/status/1532457110227030016,@TonyZador @IntuitMachine @mraginsky should i hold you to what you believed 40 years ago?
4153,@GaryMarcus,2022-06-02 20:17:32+00:00,https://twitter.com/GaryMarcus/status/1532456402962132992,"@TonyZador @IntuitMachine @mraginsky you are strawmanning chomsky. he is not big on semantics but even he has frequently given examples where meaning matters, eg john is easy to please v john is eager to please

and, man, if you want to infer what you think he might think rather than following a link to his words ü§∑‚Äç‚ôÇÔ∏è"
4154,@GaryMarcus,2022-06-02 20:13:25+00:00,https://twitter.com/GaryMarcus/status/1532455366625095680,"@Sams_Antics @prem_k better than human is fine, thank you. call me when we have it for cars, in openended driving"
4155,@GaryMarcus,2022-06-02 20:08:20+00:00,https://twitter.com/GaryMarcus/status/1532454085319720961,"some restructuring of AI at Meta, with the open-minded @an_open_mind departing. Joelle Pineau is assuming more responsibility. I am a fan of hers and hope that she can make her replicability checklist an industry standard: https://t.co/SqC8rSMn2a"
4156,@GaryMarcus,2022-06-02 19:58:07+00:00,https://twitter.com/GaryMarcus/status/1532451516178898944,"@ItalyHighTech i think you are defining a fair sense of generality, but your definition doesn‚Äôt fit with how i think the term AGI has conventionally been used."
4157,@GaryMarcus,2022-06-02 18:54:21+00:00,https://twitter.com/GaryMarcus/status/1532435465927680001,@TaliaRinger that would be a good thing!
4158,@GaryMarcus,2022-06-02 18:50:33+00:00,https://twitter.com/GaryMarcus/status/1532434511631245317,"Double bubble
(fine) tune and trouble"
4159,@GaryMarcus,2022-06-02 18:45:57+00:00,https://twitter.com/GaryMarcus/status/1532433352497590272,@Krauss_PK @maier_ak totally agree w @jaaanaru
4160,@GaryMarcus,2022-06-02 17:43:40+00:00,https://twitter.com/GaryMarcus/status/1532417679415332864,"then again, in some instances, eg driving, or potentially life-endangering medical advice. you just shouldn‚Äôt deploy if you are overwhelmed by edge cases"
4161,@GaryMarcus,2022-06-02 17:20:50+00:00,https://twitter.com/GaryMarcus/status/1532411935131455490,"Q: How do you make *sure* your large language model won‚Äôt cause harm?
A: You can‚Äôt. You just can‚Äôt.  https://t.co/pWRsMuEqU2"
4162,@GaryMarcus,2022-06-02 17:17:04+00:00,https://twitter.com/GaryMarcus/status/1532410987298467843,@raphaelmilliere @NatureComms what does it even mean? üò±
4163,@GaryMarcus,2022-06-02 17:08:59+00:00,https://twitter.com/GaryMarcus/status/1532408952008257538,@renatrigiorese it should make everyone queasy ü§¢
4164,@GaryMarcus,2022-06-02 17:08:23+00:00,https://twitter.com/GaryMarcus/status/1532408799931183106,@IntuitMachine @mraginsky @TonyZador not so much. that was the point of https://t.co/5menFc18c0
4165,@GaryMarcus,2022-06-02 16:20:13+00:00,https://twitter.com/GaryMarcus/status/1532396679395041283,. @wadhwa and I are most definitely not done talking about this :)
4166,@GaryMarcus,2022-06-02 16:16:26+00:00,https://twitter.com/GaryMarcus/status/1532395726734385156,"@AthenaAI2 I haven‚Äôt been allowed direct access, so this seems like a question for @hardmaru"
4167,@GaryMarcus,2022-06-02 16:12:28+00:00,https://twitter.com/GaryMarcus/status/1532394727718326272,"@TonyZador yep, it‚Äôs true that Chomsky‚Äôs first try, nearly 70 years ago, was naive about semantics.

 ü§∑‚Äç‚ôÇÔ∏è"
4168,@GaryMarcus,2022-06-02 16:11:08+00:00,https://twitter.com/GaryMarcus/status/1532394393562275840,"@TonyZador chomsky sees it very differently. we‚Äôve discussed a bunch lately, so i have that firsthand, and wrote about it here, essay by me with direct quote in the epilogue from him: https://t.co/tFxLDkQnms"
4169,@GaryMarcus,2022-06-02 16:08:26+00:00,https://twitter.com/GaryMarcus/status/1532393712617082880,"@mraginsky @TonyZador LLMs instantiate Harris, but vindicate Chomsky. That was the point of https://t.co/tFxLDkQnms"
4170,@GaryMarcus,2022-06-02 16:02:51+00:00,https://twitter.com/GaryMarcus/status/1532392306703142913,"‚Å¶@mrgreene1977‚Å© tells it like it is, ‚ÄúSomething I might say, and glad to see others saying it! ‚ÄúA versatile new AI is fueling speculation that machines will soon think like humans. It‚Äôs time for a reality check.‚Äù https://t.co/CmJmWuGLvR"
4171,@GaryMarcus,2022-06-02 13:10:55+00:00,https://twitter.com/GaryMarcus/status/1532349041287102465,thread on the messy realities of training large models (and see also the exceptionally candid logbooks of @MetaAI OPT on github)
4172,@GaryMarcus,2022-06-02 13:01:46+00:00,https://twitter.com/GaryMarcus/status/1532346738358464516,maybe InstructGPT will stand by *its* words? ü§£
4173,@GaryMarcus,2022-06-02 12:56:12+00:00,https://twitter.com/GaryMarcus/status/1532345337062428672,"@danbri never said it wasn‚Äôt charming, just don‚Äôt think it has anything to do with AGI."
4174,@GaryMarcus,2022-06-02 12:54:00+00:00,https://twitter.com/GaryMarcus/status/1532344783263649793,@OwainEvans_UK try ‚ÄúWhen will Donald Trump accept that he is not President‚Äù
4175,@GaryMarcus,2022-06-02 12:50:26+00:00,https://twitter.com/GaryMarcus/status/1532343884222672896,"more nonsense about AGI being nigh, this time in a leading journal, as spotted by @jaaanaru 

üôÑ"
4176,@GaryMarcus,2022-06-02 12:01:20+00:00,https://twitter.com/GaryMarcus/status/1532331527211606016,"@bengoertzel @elonmusk agree not sufficient, and maybe not even strictly necessary but also agree would likely represent real progress (vs another 0.1% on Imagenet or CIFAR)"
4177,@GaryMarcus,2022-06-02 11:54:44+00:00,https://twitter.com/GaryMarcus/status/1532329869157158917,"üëâ @bengoertzel has thought more about AGI than almost anyone ‚Äîand agrees that the criteria @ErnestSDavis &amp; I propose would represent real progress.

if you are serious about AGI, @elonmusk, you should both take the bet &amp; fund prizes around them

i might lose but field would win"
4178,@GaryMarcus,2022-06-02 03:15:02+00:00,https://twitter.com/GaryMarcus/status/1532199082789195776,"@david_picard @ZoubinGhahrama1 @Plinz and you really want clear info about confidence bounds, as @ZoubinGhahrama1 likes to stress"
4179,@GaryMarcus,2022-06-02 03:14:28+00:00,https://twitter.com/GaryMarcus/status/1532198940564549633,"@david_picard @ZoubinGhahrama1 @Plinz 1. in the end that it is hard to build adequate debuggability if you have no idea why your systems makes the specific mistakes that it does
2. if you can‚Äôt produce rich structured outputs, it‚Äôs hard to do rich cross-checking with other systems."
4180,@GaryMarcus,2022-06-02 02:46:57+00:00,https://twitter.com/GaryMarcus/status/1532192011825975297,@Abel_TorresM GPT-2
4181,@GaryMarcus,2022-06-02 01:56:21+00:00,https://twitter.com/GaryMarcus/status/1532179279751962624,"@pmddomingos cf ‚Äúthe toxic brew of easy access guns, gun culture, and hysteria‚Äù which i could accept"
4182,@GaryMarcus,2022-06-02 01:55:04+00:00,https://twitter.com/GaryMarcus/status/1532178956463460352,@pmddomingos only if you are standing by hysteria as largest factor.
4183,@GaryMarcus,2022-06-02 01:53:31+00:00,https://twitter.com/GaryMarcus/status/1532178566418288640,"@aromeromyt @khademinori @pmddomingos exactly. eg sitting here in BC i weep (literally) at what is happening in my homeland (US) but i don‚Äôt feel immediately hysterical that it will affect me here, given culture, history, and firearm distribution."
4184,@GaryMarcus,2022-06-02 01:47:05+00:00,https://twitter.com/GaryMarcus/status/1532176946741727234,@pmddomingos i mentioned canada because they hear largely same press coverage (eg incredibly moving CBC story yesterday); why doesn‚Äôt the hysteria then transfer?
4185,@GaryMarcus,2022-06-02 01:40:34+00:00,https://twitter.com/GaryMarcus/status/1532175309486706688,"@pmddomingos i think you are assuming some kind of linear function, and ignoring other factors like economic inequality"
4186,@GaryMarcus,2022-06-02 01:34:32+00:00,https://twitter.com/GaryMarcus/status/1532173791131906048,"@pmddomingos @khademinori use canada as your comparison, and things look different"
4187,@GaryMarcus,2022-06-02 01:33:35+00:00,https://twitter.com/GaryMarcus/status/1532173548994691072,"@pmddomingos i was responding to the word ‚Äúbiggest‚Äù; agree on need for multiple solutions, including thoughtful guidance to media."
4188,@GaryMarcus,2022-06-02 01:31:48+00:00,https://twitter.com/GaryMarcus/status/1532173101537951745,found someone! already we are crafting!
4189,@GaryMarcus,2022-06-02 01:27:29+00:00,https://twitter.com/GaryMarcus/status/1532172013854347264,@Plinz @dileeplearning @tyrell_turing underway! w guest star!
4190,@GaryMarcus,2022-06-02 01:14:38+00:00,https://twitter.com/GaryMarcus/status/1532168782667427841,@pmddomingos no i didn‚Äôt (but scanned just now). i am sure copycat syndrome explains *some* of the variance. the availability of guns surely does too. Canadians see the U.S. news but generally don‚Äôt have as many guns and don‚Äôt copy‚Ä¶
4191,@GaryMarcus,2022-06-02 01:09:37+00:00,https://twitter.com/GaryMarcus/status/1532167520890671106,@scottiev @bengoertzel and you would tell him to stay the hell off of Twitter. Same as Trump‚Äôs people told him. Endlessly.
4192,@GaryMarcus,2022-06-02 01:06:55+00:00,https://twitter.com/GaryMarcus/status/1532166839739944960,"who wants to help me co-write some straight talk about semantics? 

(candidates must have training in linguistics; specialization in semantics a plus)"
4193,@GaryMarcus,2022-06-02 01:03:02+00:00,https://twitter.com/GaryMarcus/status/1532165861829595136,@Plinz @dileeplearning @tyrell_turing illustrated the urgent need for a clear discussion about semantics
4194,@GaryMarcus,2022-06-02 01:01:55+00:00,https://twitter.com/GaryMarcus/status/1532165581276737536,"@pmddomingos i am sorry, did you give an actual argument for your claim? all i saw was an assertion.

-no data
-no proposed causal mechanism
-no consideration of alternatives"
4195,@GaryMarcus,2022-06-02 00:56:28+00:00,https://twitter.com/GaryMarcus/status/1532164207948406784,@scottiev @bengoertzel to stand behind his words? ü§∑‚Äç‚ôÇÔ∏è
4196,@GaryMarcus,2022-06-02 00:55:20+00:00,https://twitter.com/GaryMarcus/status/1532163924233056261,"@chrmanning @csabaveres @rogerkmoore i think this is a fair criticism and the interesting and unsolved question is what to do about it? how much goes into semantics, pragmatics, cognition etc as well idiom, stored cases of various sorts etc"
4197,@GaryMarcus,2022-06-02 00:53:27+00:00,https://twitter.com/GaryMarcus/status/1532163449714642944,@dileeplearning @Plinz @tyrell_turing @luislamb want to take this one?
4198,@GaryMarcus,2022-06-02 00:47:42+00:00,https://twitter.com/GaryMarcus/status/1532162003485069312,@Zergylord @tyrell_turing i mistook the referent for this is critics; you meant the article rather than my more general point
4199,@GaryMarcus,2022-06-02 00:47:01+00:00,https://twitter.com/GaryMarcus/status/1532161831262834688,"@Zergylord @tyrell_turing sure, and nicely nativist too ;) yum!"
4200,@GaryMarcus,2022-06-02 00:38:02+00:00,https://twitter.com/GaryMarcus/status/1532159569538916352,"@Zergylord @tyrell_turing GPS turn by turn is a fully symbolic, grounded system that (mostly) works in the real world, just fine. 

(albeit not a learning system)"
4201,@GaryMarcus,2022-06-02 00:25:13+00:00,https://twitter.com/GaryMarcus/status/1532156346161717249,@Plinz @dileeplearning @tyrell_turing this is clearly going to take a full Substack essay to unravel
4202,@GaryMarcus,2022-06-02 00:23:31+00:00,https://twitter.com/GaryMarcus/status/1532155919236075520,"@Plinz @dileeplearning @tyrell_turing no, you have a theory of mind and observe the world, through vision, hearing, touch; you build cognitive models and interact with other agents. 

I met you once and know this to be true."
4203,@GaryMarcus,2022-06-01 23:46:58+00:00,https://twitter.com/GaryMarcus/status/1532146719282044928,"@dileeplearning tomasello would argue against it. crain argued for a somewhat strong version in the 1990s, but he was certainly concerned w semantics, not just the pure syntactic version Chomsky used to emphasize.

and even Chomsky sometimes emphasized how meaning entered in."
4204,@GaryMarcus,2022-06-01 23:35:05+00:00,https://twitter.com/GaryMarcus/status/1532143729720582144,"It‚Äôs the only thing that works at scale *now*, but if my arguments are correct, it‚Äôs a local maximum.

the question then becomes, how can we promote solutions that lead us to a more fertile part of solution space."
4205,@GaryMarcus,2022-06-01 23:20:24+00:00,https://twitter.com/GaryMarcus/status/1532140032181653505,"if Optimus is what he says it will be, the kitchen helper should be no sweat. ü§∑‚Äç‚ôÇÔ∏è"
4206,@GaryMarcus,2022-06-01 23:13:44+00:00,https://twitter.com/GaryMarcus/status/1532138354287968257,"$500,000 &amp; not a word. On theory that Elon might have missed the proposed bet, and isn‚Äôt just chicken, could anybody friendly with him bring it to his attention?

longnow is ready to host, community like criteria; @bengoertzel thinks Elon has a chance.

Let‚Äôs get him to the table"
4207,@GaryMarcus,2022-06-01 23:07:27+00:00,https://twitter.com/GaryMarcus/status/1532136776910917633,just no.
4208,@GaryMarcus,2022-06-01 22:17:38+00:00,https://twitter.com/GaryMarcus/status/1532124238009843713,@bengoertzel @elonmusk what do you think of the criteria?
4209,@GaryMarcus,2022-06-01 21:44:08+00:00,https://twitter.com/GaryMarcus/status/1532115809018925056,@RWerpachowski @tdietterich of course
4210,@GaryMarcus,2022-06-01 21:08:44+00:00,https://twitter.com/GaryMarcus/status/1532106897133670400,"@tdietterich sure but some of the LLM papers have 80 authors, or more, and the $ of dollars for compute per paper is massively higher."
4211,@GaryMarcus,2022-06-01 20:32:08+00:00,https://twitter.com/GaryMarcus/status/1532097687134162944,"@ZoubinGhahrama1 @Plinz or other approaches altogether? #morereliabledeeplearning might or might not be an achievable thing, given the lack of interpretable and fully transportable representations."
4212,@GaryMarcus,2022-06-01 20:29:01+00:00,https://twitter.com/GaryMarcus/status/1532096905768886272,"@Plinz if you can refute it, go ahead. the sentence starting ‚Äúsimply‚Äù encapsulates, to my mind, why so much current research is off the mark."
4213,@GaryMarcus,2022-06-01 20:27:27+00:00,https://twitter.com/GaryMarcus/status/1532096510602555392,@Plinz i stand by it. it is truth.
4214,@GaryMarcus,2022-06-01 20:24:01+00:00,https://twitter.com/GaryMarcus/status/1532095644805963779,"memo to the machine learning community: read the final paragraph of this PNAS letter about language and meaning over and over until you have fully absorbed it. 

and then repeat. 

it‚Äôs the whole ballgame."
4215,@GaryMarcus,2022-06-01 20:13:31+00:00,https://twitter.com/GaryMarcus/status/1532093002742517760,@seanmcbride not true. all kinds of over promises have been made historically
4216,@GaryMarcus,2022-06-01 20:11:09+00:00,https://twitter.com/GaryMarcus/status/1532092409026256896,Exactly what i have been saying over and over. (eg as recently as an hour ago to @tyrell_turing)
4217,@GaryMarcus,2022-06-01 20:09:21+00:00,https://twitter.com/GaryMarcus/status/1532091956074930176,@tyrell_turing ‚âà i want to win *an* argument ü§£ and can‚Äôt be bothered to read three tweets
4218,@GaryMarcus,2022-06-01 19:30:58+00:00,https://twitter.com/GaryMarcus/status/1532082295040946177,"@tdietterich and very large fraction of OpenAO, large projects at DeepMind, Baidu, Microsoft, very large fraction of several well-funded recent startups etc.  just count how many authors are on these papers, and think about the training costs. it‚Äôs certainly not all, but majority, I suspect"
4219,@GaryMarcus,2022-06-01 19:13:36+00:00,https://twitter.com/GaryMarcus/status/1532077924534276098,"@tdietterich and ps differentiable programming is surely broad, but even within that broad umbrella, the majority of current $ and people (and hype) seem to be focused primarily around LLMs."
4220,@GaryMarcus,2022-06-01 19:04:37+00:00,https://twitter.com/GaryMarcus/status/1532075664261599232,"@ElijahYilma semantics ‚âà meaning. very very loosely: knowing who did what to whom, where, when, how etc

good starting point for a complex and controversial field: https://t.co/A4xVdqH8mV"
4221,@GaryMarcus,2022-06-01 19:02:04+00:00,https://twitter.com/GaryMarcus/status/1532075021958402048,Bet becomes meme
4222,@GaryMarcus,2022-06-01 18:58:38+00:00,https://twitter.com/GaryMarcus/status/1532074156056932353,"@kevin2kelly wrong test but @mkapor had the right idea :)

as to why wrong test: https://t.co/4KLe1bU1YY"
4223,@GaryMarcus,2022-06-01 18:56:11+00:00,https://twitter.com/GaryMarcus/status/1532073540970614785,"@tdietterich hence the top line, ‚ÄúAI research‚Äù (not eg deep learning or ML) is appropriately scoped, as phrased"
4224,@GaryMarcus,2022-06-01 18:47:50+00:00,https://twitter.com/GaryMarcus/status/1532071438462898176,thanks @MNewhouse73; not everyday that a Super Bowl champ likes one of my tweets about AI :) https://t.co/rvPFBWEj3Y
4225,@GaryMarcus,2022-06-01 18:44:53+00:00,https://twitter.com/GaryMarcus/status/1532070697006030850,"@dileeplearning is that the right metric? semantics isn‚Äôt taken seriously in most of AI, but it should be.

your own demos re the failures of DQN when Breakout changes a few pixels are an extensions of the POS argument - even w a ton of data, DQN fails to generalize adequately."
4226,@GaryMarcus,2022-06-01 18:21:04+00:00,https://twitter.com/GaryMarcus/status/1532064705002766337,"@tyrell_turing you didn‚Äôt read my whole thread? there‚Äôs perfectly reasonable version that almost 40 years old that you are ignoring- just so that you can score points attacking a 60 year old that inspired the more refined idea that still stands.

by some logic may i attack 2 layer perceptrons?"
4227,@GaryMarcus,2022-06-01 17:07:07+00:00,https://twitter.com/GaryMarcus/status/1532046092946132997,@tyrell_turing my take:
4228,@GaryMarcus,2022-06-01 17:04:45+00:00,https://twitter.com/GaryMarcus/status/1532045497879318528,3. I make a related argument here: https://t.co/5menFc18c0
4229,@GaryMarcus,2022-06-01 17:04:45+00:00,https://twitter.com/GaryMarcus/status/1532045496490946561,"2. Being careful about this, I think that Chomsky placed too much emphasis on syntax, and that there is an argument to be made against his formulation. 

But not against @sapinker‚Äôs more subtle 1984 argument on semantic bootstrapping &amp; the relation between syntax and semantics."
4230,@GaryMarcus,2022-06-01 17:04:44+00:00,https://twitter.com/GaryMarcus/status/1532045495186513920,"No. GPT-3 can‚Äôt disprove the poverty of the stimulus argument, at least not if you see learning language as being about learning a *mapping* between syntax and semantics. 

GPT-3  infers no semantics, only syntax. 

Its inability to develop a semantics is *support* for POS. üßµ"
4231,@GaryMarcus,2022-06-01 16:52:30+00:00,https://twitter.com/GaryMarcus/status/1532042415325859843,@WiringTheBrain read Mark Twain‚Äôs comments on the matter in That Awful German Language
4232,@GaryMarcus,2022-06-01 16:05:06+00:00,https://twitter.com/GaryMarcus/status/1532030488184881152,@davidad definitely not trivial.
4233,@GaryMarcus,2022-06-01 15:58:18+00:00,https://twitter.com/GaryMarcus/status/1532028773876391937,It could! That‚Äôs what I keep lobbying for. And all this DARPA money going into neurosymbolic could catalyze it!
4234,@GaryMarcus,2022-06-01 15:52:09+00:00,https://twitter.com/GaryMarcus/status/1532027230066339840,@JhendersonIMB woud be great if there maturation in both fields!
4235,@GaryMarcus,2022-06-01 13:53:20+00:00,https://twitter.com/GaryMarcus/status/1531997326583029760,"Have confirmed that this is a legit offer; the bet now stands at $500k. 

@sharongoldman"
4236,@GaryMarcus,2022-06-01 13:52:18+00:00,https://twitter.com/GaryMarcus/status/1531997065521205251,"GIF contest! We appear to be at half million dollars.

What best conveys something along the lines of, hey Elon, how about you step up to the plate and stand by your words? Or are you chicken?

(feel free to ixnay my clich√©s)
 
Still images from Dall-E, Imagen also acceptable :)"
4237,@GaryMarcus,2022-06-01 13:31:06+00:00,https://twitter.com/GaryMarcus/status/1531991730777489409,@davidmanheim @wadhwa @aniketvartak @kevin2kelly the essay explains why the bet is re a full package of five.
4238,@GaryMarcus,2022-06-01 07:04:08+00:00,https://twitter.com/GaryMarcus/status/1531894349427970049,"Doubt Elon will take the bet, but $350k is a pretty powerful commentary on people‚Äôs declining appetite for AI hype."
4239,@GaryMarcus,2022-06-01 06:56:58+00:00,https://twitter.com/GaryMarcus/status/1531892545017421824,"2023: Field grows up and finally faces compositionality, semantics, and knowledge representation"
4240,@GaryMarcus,2022-06-01 04:26:29+00:00,https://twitter.com/GaryMarcus/status/1531854676374609920,@RobKnight__ @MatthiasLalisse @Plinz @hardmaru yes and i discuss significance of that in my essay
4241,@GaryMarcus,2022-06-01 04:25:24+00:00,https://twitter.com/GaryMarcus/status/1531854402268434434,"piercing essay, by @mer__edith"
4242,@GaryMarcus,2022-06-01 04:24:32+00:00,https://twitter.com/GaryMarcus/status/1531854182608621569,‚Äúproposals to ‚Äúdemocratize‚Äù access to AI research infrastructures amount to calls to subsidize tech giants further by licensinginfrastructure from these firms in ways that allow them to continue defining the terms and conditions of AI and AI research.‚Äù üî• https://t.co/7ppBaHTEnB
4243,@GaryMarcus,2022-06-01 04:13:48+00:00,https://twitter.com/GaryMarcus/status/1531851481703256064,hmm. you really should Horse Rides Astronaut at https://t.co/8ir1xKvqt6;  I address possibilities like these
4244,@GaryMarcus,2022-06-01 03:59:34+00:00,https://twitter.com/GaryMarcus/status/1531847901764235264,no. shorting magical thinking.
4245,@GaryMarcus,2022-06-01 03:21:46+00:00,https://twitter.com/GaryMarcus/status/1531838389208510464,@filippie509 @gregeganSF @aniketvartak #5 and counting
4246,@GaryMarcus,2022-06-01 03:17:52+00:00,https://twitter.com/GaryMarcus/status/1531837407217086464,"still one of the best shows ever. 
RIP Michael K Williams https://t.co/LNLFvhoIVk"
4247,@GaryMarcus,2022-06-01 03:08:04+00:00,https://twitter.com/GaryMarcus/status/1531834940525928448,@Plinz @khademinori @hardmaru indeed although the interface is language it would be interesting see that dimensions the sliders would control
4248,@GaryMarcus,2022-06-01 03:07:22+00:00,https://twitter.com/GaryMarcus/status/1531834764549795841,@Plinz @khademinori @hardmaru how about shadows? song dynasty dragon made of glass casting a shadow on a rectangular grid? (or start with an opaque dragon)
4249,@GaryMarcus,2022-06-01 03:02:12+00:00,https://twitter.com/GaryMarcus/status/1531833463912812544,@Plinz @khademinori @hardmaru not perfect but still impressive
4250,@GaryMarcus,2022-06-01 03:01:28+00:00,https://twitter.com/GaryMarcus/status/1531833279573151746,@Plinz @khademinori @hardmaru not it‚Äôs best work tbh
4251,@GaryMarcus,2022-06-01 01:55:45+00:00,https://twitter.com/GaryMarcus/status/1531816740664946688,"@Plinz @hardmaru also ‚ÄúA song dynasty dragon breathing fire while typing on a laptop, seen from above‚Äù"
4252,@GaryMarcus,2022-06-01 01:55:16+00:00,https://twitter.com/GaryMarcus/status/1531816620129038336,"@Plinz @hardmaru hands are weird (lot of human hands in there) but otherwise very good. try some more. ‚ÄúA Song Dynastry dragon, typing on a laptop, shot from behind‚Äù or ‚Äúseen through binoculars‚Äù"
4253,@GaryMarcus,2022-06-01 01:48:51+00:00,https://twitter.com/GaryMarcus/status/1531815005166850048,"@hardmaru @Plinz the thing that impresses me the most is the consistency of perspective/camera angle. would be fun to test the robustness of that, and things like occlusion, noncanonical views, how specific you can be, etc."
4254,@GaryMarcus,2022-06-01 01:39:59+00:00,https://twitter.com/GaryMarcus/status/1531812772685631488,"@Plinz @hardmaru and let‚Äôs not forget that classic, ‚Äúhow many attempts did you try?‚Äù(Luckily @hardmaru gives part of the answer.)"
4255,@GaryMarcus,2022-06-01 01:18:10+00:00,https://twitter.com/GaryMarcus/status/1531807284518498304,I‚Äôm pretty confident that AI will be mainstream soon (and arguably in some respects it already is); my concern is that is being mainstreamed before it is reliably or trustworthy. https://t.co/K3a1Gyt8V6
4256,@GaryMarcus,2022-06-01 01:13:50+00:00,https://twitter.com/GaryMarcus/status/1531806190832787456,@gregeganSF @aniketvartak you are at least the fourth person to express concerns.
4257,@GaryMarcus,2022-06-01 01:11:42+00:00,https://twitter.com/GaryMarcus/status/1531805654993600513,"Two things I did not anticipate on my bingo card for today
- DALL-E speaking in tongues
- A quarter million dollars added to on my AGI bet."
4258,@GaryMarcus,2022-06-01 01:09:22+00:00,https://twitter.com/GaryMarcus/status/1531805067321298944,Plus $50k from @aniketvartak; $350k in total.
4259,@GaryMarcus,2022-06-01 01:05:22+00:00,https://twitter.com/GaryMarcus/status/1531804062135377920,"I double-checked; this is a serious offer. We are up to $300k, @ElonMusk, together with @wadhwa."
4260,@GaryMarcus,2022-06-01 00:47:43+00:00,https://twitter.com/GaryMarcus/status/1531799619767631872,"@sergeivolodinch @SpencrGreenberg @praeterpropter @ARGleave @timnitGebru @xriskology @louis_faucon @TaliaRinger @ruthstarkman @DaystarEld @TurEwelina also, i like moderating these kinds of things and am somewhere in between and would like to see both sides develop their arguments."
4261,@GaryMarcus,2022-06-01 00:47:04+00:00,https://twitter.com/GaryMarcus/status/1531799456944779264,@sergeivolodinch @SpencrGreenberg @praeterpropter @ARGleave @timnitGebru @xriskology @louis_faucon @TaliaRinger @ruthstarkman @DaystarEld @TurEwelina i think @Abebab is working on some interesting arguments (based on a slide she shared last week).
4262,@GaryMarcus,2022-06-01 00:33:41+00:00,https://twitter.com/GaryMarcus/status/1531796087840813056,@podehaye amended. glad you spotted the gap before his counsel did :)
4263,@GaryMarcus,2022-06-01 00:26:24+00:00,https://twitter.com/GaryMarcus/status/1531794253487087616,@podehaye all mine!
4264,@GaryMarcus,2022-06-01 00:11:37+00:00,https://twitter.com/GaryMarcus/status/1531790535282655232,"@marawanemara @elonmusk see @NandoDF‚Äôa ‚ÄúGame Over‚Äù remarks, maybe, and perhaps some things @ilyasut has said? certainly @sama‚Äôs Moore‚Äôs Law blog seemed to say that. 

but i think eg @ylecun or @demishassabis would be on my side of the bet."
4265,@GaryMarcus,2022-05-31 23:46:29+00:00,https://twitter.com/GaryMarcus/status/1531784208259104768,"that‚Äôs $200k to you, @elonmusk."
4266,@GaryMarcus,2022-05-31 23:45:03+00:00,https://twitter.com/GaryMarcus/status/1531783850342469632,"@wadhwa well, he does his have his own related bet with @mkapor"
4267,@GaryMarcus,2022-05-31 22:00:17+00:00,https://twitter.com/GaryMarcus/status/1531757482627899395,@pfau multiple people have raised this concern
4268,@GaryMarcus,2022-05-31 21:41:33+00:00,https://twitter.com/GaryMarcus/status/1531752767835938816,"@elonmusk @jack I am willing to bet you $100,000 that you are wrong about the timing of AGI, and have laid out detailed criteria for evaluating the bet, here: https://t.co/ygD2ohOQ5V 

@kevin2kelly has offered to host the bet at https://t.co/49YseodsoR; lots of people are already discussing."
4269,@GaryMarcus,2022-05-31 21:24:55+00:00,https://twitter.com/GaryMarcus/status/1531748584843972608,"Update: I offered to put down $100,000, here, and suggested some very specific rules; @kevin2kelly offered to host at https://t.co/gYO3sxWe7s: 
https://t.co/yfXycZeAd9"
4270,@GaryMarcus,2022-05-31 21:21:30+00:00,https://twitter.com/GaryMarcus/status/1531747722419527681,"@GjMcGowan @morphillogical @Miles_Brundage I don‚Äôt necessarily agree with each individual comment in this thread, but I am loving the discussion"
4271,@GaryMarcus,2022-05-31 21:20:48+00:00,https://twitter.com/GaryMarcus/status/1531747547424755714,That time I bet a multi-billionaire a hundred thousand dollars.
4272,@GaryMarcus,2022-05-31 21:17:20+00:00,https://twitter.com/GaryMarcus/status/1531746675680677888,"@S_OhEigeartaigh full disclosure: money is mine, essay is mine, challenges joint work w @ernestdavis leading the way, egged on by @MatthewJBar for @metaculus."
4273,@GaryMarcus,2022-05-31 21:15:31+00:00,https://twitter.com/GaryMarcus/status/1531746219101302784,@EthanJPerez @elonmusk @sleepinyourhat we should talk
4274,@GaryMarcus,2022-05-31 21:06:23+00:00,https://twitter.com/GaryMarcus/status/1531743919125385216,@rogerkmoore @vaishakbelle @DanRothNLP addressed this elsewhere; fair question to ask and i think there was more effort made than meets the eyes.
4275,@GaryMarcus,2022-05-31 21:04:46+00:00,https://twitter.com/GaryMarcus/status/1531743514190524416,@TaliaRinger @Miles_Brundage would be curious for an alternative that is somewhat in the same sphere; I can see your point. cc @ErnestSDavis
4276,@GaryMarcus,2022-05-31 21:03:53+00:00,https://twitter.com/GaryMarcus/status/1531743288570413057,@jekbradbury @elonmusk @MatthewJBar is on it (and MJB please note the edits and updates in the posted Substack article).
4277,@GaryMarcus,2022-05-31 21:02:24+00:00,https://twitter.com/GaryMarcus/status/1531742916233744384,"@TaliaRinger @Miles_Brundage I think most near-term AI will require human-in-the-loop, but eg driving really has to be reliable L5, not human pays attention once every hour. and chatbots need to be autonomous unless the triage is really good."
4278,@GaryMarcus,2022-05-31 21:00:24+00:00,https://twitter.com/GaryMarcus/status/1531742412623687680,@dgardner @elonmusk most of the credit to my frequent collaborator @ErnestSDavis
4279,@GaryMarcus,2022-05-31 20:24:09+00:00,https://twitter.com/GaryMarcus/status/1531733292327677952,"So cool, @elonmusk.  @kevinkelly, who co-founded https://t.co/gYO3sxWe7s, is in to help run the AGI in 2029 bet. 

Let‚Äôs do it!"
4280,@GaryMarcus,2022-05-31 19:52:26+00:00,https://twitter.com/GaryMarcus/status/1531725308591714305,"‚ÄúMusk‚Äôs pronouncements on AGI just hasten the all-in-rush on current technology, when we actually probably need to take a step back to understand where we are and face the difficult problems realistically,‚Äù Marcus told @VentureBeat"
4281,@GaryMarcus,2022-05-31 19:29:09+00:00,https://twitter.com/GaryMarcus/status/1531719449518088193,"@keerthanpg i saw them and already asked @Chitwan_Saharia i could try some less common phrases, but have not heard a reply."
4282,@GaryMarcus,2022-05-31 19:21:42+00:00,https://twitter.com/GaryMarcus/status/1531717573468835840,@keerthanpg would love to see it tested in same prompts; is there any systematic data?
4283,@GaryMarcus,2022-05-31 19:13:37+00:00,https://twitter.com/GaryMarcus/status/1531715540946849792,AGI is just around the corner!
4284,@GaryMarcus,2022-05-31 19:13:12+00:00,https://twitter.com/GaryMarcus/status/1531715436894490624,@MatthewMcAteer0 We are all totally .. um .. housed!
4285,@GaryMarcus,2022-05-31 19:10:40+00:00,https://twitter.com/GaryMarcus/status/1531714799746158592,Deep learning is hitting a Waffle House
4286,@GaryMarcus,2022-05-31 18:00:01+00:00,https://twitter.com/GaryMarcus/status/1531697017084186624,this wins the internet today.
4287,@GaryMarcus,2022-05-31 17:59:02+00:00,https://twitter.com/GaryMarcus/status/1531696773055467520,"@AlexGDimakis @giannis_daras but‚Ä¶ are you sure you guys that this isn‚Äôt April Fool‚Äôs, two months late? üòÇ"
4288,@GaryMarcus,2022-05-31 17:57:51+00:00,https://twitter.com/GaryMarcus/status/1531696472177057792,@AlexGDimakis @giannis_daras
4289,@GaryMarcus,2022-05-31 17:56:29+00:00,https://twitter.com/GaryMarcus/status/1531696131528282113,@AlexGDimakis ps i already rt‚Äôd it and thanks for the citation
4290,@GaryMarcus,2022-05-31 17:55:57+00:00,https://twitter.com/GaryMarcus/status/1531695995506917376,@AlexGDimakis it‚Äôs amazing and makes me want to know what the ___ is in the training set!
4291,@GaryMarcus,2022-05-31 17:35:22+00:00,https://twitter.com/GaryMarcus/status/1531690814690107392,"@Abel_TorresM my undergrad thesis @hampshirecolg was literally about exactly this phenomenon: how people stick to their beliefs, even when the evidence for them is directly undermined."
4292,@GaryMarcus,2022-05-31 17:31:27+00:00,https://twitter.com/GaryMarcus/status/1531689829720739840,humans are a definitely a low bar; no principled reason why AI can‚Äôt eventually do better
4293,@GaryMarcus,2022-05-31 17:27:05+00:00,https://twitter.com/GaryMarcus/status/1531688729294753792,"@Ana_Chubinidze_ @danbri @vaishakbelle @DanRothNLP that‚Äôs no longer true, but website may not be up to date. i complained,  and made suggestions, when i learned this, and got some of the back story. serious efforts had already been made, but a number of invitations had been declined."
4294,@GaryMarcus,2022-05-31 17:19:12+00:00,https://twitter.com/GaryMarcus/status/1531686745544089601,@sd_marlow @skdh fabulous suggestion
4295,@GaryMarcus,2022-05-31 17:16:20+00:00,https://twitter.com/GaryMarcus/status/1531686027458293761,"@AviMohan21 @luislamb @AvilaGarcez 2020 arxiv; recent @pascalhitzler book, with many papers free online, and my 2001 book for motivations"
4296,@GaryMarcus,2022-05-31 17:08:24+00:00,https://twitter.com/GaryMarcus/status/1531684029916848128,"@LiquidData @aniketvartak @lexfridman no idea. i did have a laugh about his suggestion that Austin would become the capital of AI, and I am certainly not a fan of Tesla. but that‚Äôs all I can think. 

and eg I follow @Plinz who jokes about me regularly; sometimes he is even funny :)"
4297,@GaryMarcus,2022-05-31 16:58:50+00:00,https://twitter.com/GaryMarcus/status/1531681620633128961,@IgorBrigadir @khanacademy @waitbutwhy @cgpgrey @lexfridman @ID_AA_Carmack @karpathy @slatestarcodex
4298,@GaryMarcus,2022-05-31 16:58:10+00:00,https://twitter.com/GaryMarcus/status/1531681452529618944,@aniketvartak @lexfridman Which is strange since we did a great episode of his podcast; not sure what is up with that.
4299,@GaryMarcus,2022-05-31 16:57:01+00:00,https://twitter.com/GaryMarcus/status/1531681164649320448,@DennisSoemers @meme_machines @MelMitchell1 @ylecun MAIR and Balanced
4300,@GaryMarcus,2022-05-31 16:31:23+00:00,https://twitter.com/GaryMarcus/status/1531674715311353857,@aniketvartak @lexfridman Lex blocked me!
4301,@GaryMarcus,2022-05-31 15:44:00+00:00,https://twitter.com/GaryMarcus/status/1531662788900184067,"@DavidSKrueger @Abel_TorresM not til we have clearer ideas about how to build ethical AI, but in the end it is likely to better than the mess we have now."
4302,@GaryMarcus,2022-05-31 15:43:13+00:00,https://twitter.com/GaryMarcus/status/1531662592065695744,@MelMitchell1 comes to mind.
4303,@GaryMarcus,2022-05-31 15:42:00+00:00,https://twitter.com/GaryMarcus/status/1531662287831937024,"I am thinking about putting up serious money, and the open letter will give a fairly specific set of criteria. 

Who would be a good, neutral adjudicator?"
4304,@GaryMarcus,2022-05-31 15:28:50+00:00,https://twitter.com/GaryMarcus/status/1531658973891309568,My 9-year-old is digging the draft of my open letter to the richest man in the world ‚ù§Ô∏è
4305,@GaryMarcus,2022-05-31 14:37:34+00:00,https://twitter.com/GaryMarcus/status/1531646071780233216,"@sl8rv @weissg1234 watch this if you haven‚Äôt, https://t.co/vHRNSXULVB"
4306,@GaryMarcus,2022-05-31 14:35:32+00:00,https://twitter.com/GaryMarcus/status/1531645559135621122,@sl8rv Oops on the spelling. I thought i bit modeling the first lines more closely :)
4307,@GaryMarcus,2022-05-31 12:50:19+00:00,https://twitter.com/GaryMarcus/status/1531619078296596481,"@FelixHill84 . @sir_deenicus nailed it: any theory can‚Äôt distinguish between cognitive capabilities of a person and a monkey isn‚Äôt all that powerful. 

side note: Turing equivalence assumes infinite tape, not small scratchpad, and human memory is hardly small (but surely not infinite)"
4308,@GaryMarcus,2022-05-31 04:28:45+00:00,https://twitter.com/GaryMarcus/status/1531492857181196290,"p.s. If you want to see ‚ÄúFive things @ElonMusk Should Know About AGI‚Äú first, subscribe to https://t.co/8ir1xKvqt6 :)"
4309,@GaryMarcus,2022-05-31 04:22:50+00:00,https://twitter.com/GaryMarcus/status/1531491368073187328,"Where two people a minute have voted to say that they want to hear this, I‚Äôve started writing. 

Almost done the first draft. I will post tomorrow :) https://t.co/RtnVuGDw7F"
4310,@GaryMarcus,2022-05-31 03:54:22+00:00,https://twitter.com/GaryMarcus/status/1531484203933528065,artwork for the top? https://t.co/z3vqr92hxJ
4311,@GaryMarcus,2022-05-31 03:30:56+00:00,https://twitter.com/GaryMarcus/status/1531478305718734848,"Potential topic for next Substack: Four things Elon Musk should know about AGI

Should I write it?"
4312,@GaryMarcus,2022-05-30 23:35:37+00:00,https://twitter.com/GaryMarcus/status/1531419088781811712,@TechRonic9876 @astralcodexten i will stick with @maayanvisuals :)
4313,@GaryMarcus,2022-05-30 23:32:06+00:00,https://twitter.com/GaryMarcus/status/1531418200554065921,@stevenbjohnson
4314,@GaryMarcus,2022-05-30 23:20:39+00:00,https://twitter.com/GaryMarcus/status/1531415319838965760,"excellent analysis from @slatestarcodex, consistent with what i speculated in https://t.co/ZacV6k297G"
4315,@GaryMarcus,2022-05-30 23:17:26+00:00,https://twitter.com/GaryMarcus/status/1531414512070443008,"‚ÄúDALL-E is clearly capable of incredible work. That having been said, I mostly couldn‚Äôt access it‚Ä¶.trying to get it to do anything at all unusual degrades the style until you end up picking the best of a bad lot and being grateful for it‚Äù -@astralcodexten https://t.co/aHTkG94y5p"
4316,@GaryMarcus,2022-05-30 22:53:53+00:00,https://twitter.com/GaryMarcus/status/1531408583421837312,"Cuddling, self-organizing geese (video)."
4317,@GaryMarcus,2022-05-30 22:43:45+00:00,https://twitter.com/GaryMarcus/status/1531406036644646920,Wake up! You will be late for training! https://t.co/QqCl3O4cCW
4318,@GaryMarcus,2022-05-30 22:14:06+00:00,https://twitter.com/GaryMarcus/status/1531398571374915585,@elonmusk @jack https://t.co/p2gicOktHe
4319,@GaryMarcus,2022-05-30 21:57:32+00:00,https://twitter.com/GaryMarcus/status/1531394405403308034,@jcrg_137 @elonmusk ain‚Äôt nobody here said ‚Äúimpossible‚Äù
4320,@GaryMarcus,2022-05-30 21:32:39+00:00,https://twitter.com/GaryMarcus/status/1531388142304931840,"@xzistor @aoargunsah I don‚Äôt think I can get him the mansion he deserves. 

But I agree that half the fun in the bet would be coming up with enforceable definitions."
4321,@GaryMarcus,2022-05-30 21:23:37+00:00,https://twitter.com/GaryMarcus/status/1531385868186882048,"@MelMitchell1 @elonmusk, I‚Äôm down for https://t.co/gYO3sxWe7s if you are."
4322,@GaryMarcus,2022-05-30 20:09:43+00:00,https://twitter.com/GaryMarcus/status/1531367272370958336,"@nearlydaniel Criticizing *is* helping. 

Zero chance we get there if we don‚Äôt take realistic look at current limits and understand the obstacles."
4323,@GaryMarcus,2022-05-30 19:39:54+00:00,https://twitter.com/GaryMarcus/status/1531359767066578944,How much are you willing to bet?
4324,@GaryMarcus,2022-05-30 16:45:38+00:00,https://twitter.com/GaryMarcus/status/1531315912657207299,"thanks so much the many of you who have signed up for https://t.co/8ir1xKdPBy; over 1,000 subscribers already üôè"
4325,@GaryMarcus,2022-05-30 16:40:28+00:00,https://twitter.com/GaryMarcus/status/1531314609495412740,"@FelixHill84 @mpshanahan @sir_deenicus @aniketvartak parrots have plenty of intelligence, just not a huge amount of language comprehension (though Irene Pepperberg has shown they can develop some, w extensive training).

building parrot-level cognition would certainly help w deep comprehension. LLMs, perhaps not so much."
4326,@GaryMarcus,2022-05-30 14:59:06+00:00,https://twitter.com/GaryMarcus/status/1531289102150012928,"I saw the best minds of my generation ‚Ä¶ 
spending hours upon hours
having fun with DALL-E
and taking things ‚Äústep by step‚Äù
instead of figuring how we might get
to artificial intelligence
that we could actually trust

[with apologies to Alan Ginsberg]"
4327,@GaryMarcus,2022-05-30 14:55:33+00:00,https://twitter.com/GaryMarcus/status/1531288208696147973,@sir_deenicus @aniketvartak @FelixHill84 @emilymbender
4328,@GaryMarcus,2022-05-30 14:46:19+00:00,https://twitter.com/GaryMarcus/status/1531285886582722560,"@kanishkamisra @FelixHill84 sometimes, but not always. that‚Äôs what the whole 1990s past tense debate was about, and in a certain sense what my Horse Rides Astronaut essay this week (https://t.co/8ir1xKvqt6) was about.

And it‚Äôs why distribution shift is a central challenge"
4329,@GaryMarcus,2022-05-30 14:30:07+00:00,https://twitter.com/GaryMarcus/status/1531281806804144128,"@spacepanty @FelixHill84 have been hearing the same fantasy thinking for 30 years; 10  or orders of magnitude increase hasn‚Äôt resolved the fundamental flaws. So I am not buying, as explained in my recent essays at https://t.co/8ir1xKvqt6 and @NautilusMag."
4330,@GaryMarcus,2022-05-30 14:21:14+00:00,https://twitter.com/GaryMarcus/status/1531279573416980480,@rolisz @HarshitTaneja18 there is a long continuum in between
4331,@GaryMarcus,2022-05-30 14:19:52+00:00,https://twitter.com/GaryMarcus/status/1531279229563723776,"@RWerpachowski @FelixHill84 hybrid AI does not exclude this possibility, but I remain concerned about the fundamental lack of reliability, comprehension, and explicit representation."
4332,@GaryMarcus,2022-05-30 14:14:58+00:00,https://twitter.com/GaryMarcus/status/1531277996375453698,"@rolisz @HarshitTaneja18 at collaging, yes; at comprehension, no"
4333,@GaryMarcus,2022-05-30 14:09:15+00:00,https://twitter.com/GaryMarcus/status/1531276555447480325,"@FelixHill84 right. and for sure the details are open. but LLM‚Äôs do not exhibit that behavior, so they aren‚Äôt the right solution."
4334,@GaryMarcus,2022-05-30 13:38:38+00:00,https://twitter.com/GaryMarcus/status/1531268850943074304,@FelixHill84 we know something from cognitive psychology (not neuroscience) about how flexible and general they are
4335,@GaryMarcus,2022-05-30 13:28:02+00:00,https://twitter.com/GaryMarcus/status/1531266183046914049,"@HarshitTaneja18 650M labeled image pairs is not that fast, and it is still missing a lot of language understanding and a good bit of common sense."
4336,@GaryMarcus,2022-05-30 13:18:14+00:00,https://twitter.com/GaryMarcus/status/1531263716427112449,"@justMathana current AI pretty much is a stochastic parrot (see all@my recent Substack writing, @emilymbender etc)

the internet is a lot sloppier than college but much more comprehensive. 

a true AI would learn an immense amount from it."
4337,@GaryMarcus,2022-05-30 13:13:08+00:00,https://twitter.com/GaryMarcus/status/1531262435054608385,"@FelixHill84 not so sure. it will still lack
a. proper knowledge structures for representing abstraction (independently of frequency and similarity)
b. real representations of the dynamically-changing world"
4338,@GaryMarcus,2022-05-30 13:10:07+00:00,https://twitter.com/GaryMarcus/status/1531261676204400641,@AnoopRKulkarni @GoogleAI @seanmcarroll @seanmcarroll this refers to my trilogy at https://t.co/8ir1xKvqt6 and all the recent models. i would be happy to discuss if you like
4339,@GaryMarcus,2022-05-30 13:04:18+00:00,https://twitter.com/GaryMarcus/status/1531260210341220352,"A human can learn a lot from college, a parrot, not so much."
4340,@GaryMarcus,2022-05-30 12:31:34+00:00,https://twitter.com/GaryMarcus/status/1531251973348921350,On prompt engineering: https://t.co/lta32VnXU4
4341,@GaryMarcus,2022-05-30 03:00:14+00:00,https://twitter.com/GaryMarcus/status/1531108192217837569,"from 2015, still cracks me up every timeü§£ü§£ü§£ https://t.co/ALEu4lJrIh"
4342,@GaryMarcus,2022-05-30 02:14:40+00:00,https://twitter.com/GaryMarcus/status/1531096726701953024,"@xriskology you did however interpolate the word ‚ÄúHolocaust‚Äù into a quote that you elided in order to give it that air. and you used it to misrepresent that person‚Äôs position, and make it specifically sound like the person minimized the world Holocaust.

but, true. you didn‚Äôt use word Nazi."
4343,@GaryMarcus,2022-05-29 22:48:16+00:00,https://twitter.com/GaryMarcus/status/1531044781949788161,@morungos of course not
4344,@GaryMarcus,2022-05-29 20:51:22+00:00,https://twitter.com/GaryMarcus/status/1531015366637256704,"The point that deep learning ‚â† deep understanding was also central to https://t.co/Pt7HZbLIv5. 

On this @yudapearl and I are in 100% agreement."
4345,@GaryMarcus,2022-05-29 20:48:00+00:00,https://twitter.com/GaryMarcus/status/1531014519379529728,"@HappyAar dishwashers and pool cleaners are fine as far as they go, but nothing like near-AGI nor do they relieve of most human work, handy as they are"
4346,@GaryMarcus,2022-05-29 20:32:52+00:00,https://twitter.com/GaryMarcus/status/1531010707734421505,"Also, essay question, everyone is welcome: can ‚Äúnear-AGI‚Äù that is applied to most human work actually *be* safe? 

Or is it a disaster waiting to happen?"
4347,@GaryMarcus,2022-05-29 20:29:23+00:00,https://twitter.com/GaryMarcus/status/1531009832085430272,"I won‚Äôt say this will *never* happen but it most certainly won‚Äôt happen in this decade. 

We are nowhere near ‚Äúsafe near-AGI‚Äù that can handle most human work."
4348,@GaryMarcus,2022-05-29 19:48:21+00:00,https://twitter.com/GaryMarcus/status/1530999505490825217,"In this sense, a lot of ML is like how people used to misuse statistic packages, applying the analyses, but without understanding the underlying assumptions."
4349,@GaryMarcus,2022-05-29 19:45:57+00:00,https://twitter.com/GaryMarcus/status/1530998902198980608,"@IntuitMachine it‚Äôs not the just science, but scientists who say stuff like ‚Äúput up or shut up‚Äù to others who might have good ideas, coming from other disciplines."
4350,@GaryMarcus,2022-05-29 19:10:09+00:00,https://twitter.com/GaryMarcus/status/1530989892364382208,"@KarlaParussel hmm maybe time for an essay: 
AI: 75 Years of Mistakes"
4351,@GaryMarcus,2022-05-29 18:31:39+00:00,https://twitter.com/GaryMarcus/status/1530980204541263876,@bbenzon mostly: no
4352,@GaryMarcus,2022-05-29 18:18:50+00:00,https://twitter.com/GaryMarcus/status/1530976980354613248,yes! and 3. the education and culture are insufficiently interdisciplinary.
4353,@GaryMarcus,2022-05-29 17:35:53+00:00,https://twitter.com/GaryMarcus/status/1530966168575483904,@Oireniar @ElijahYilma @pmddomingos good recent example is MRKL from @AI21Labs; read their blog and many other refs i have tweeted over last month or two
4354,@GaryMarcus,2022-05-29 17:34:44+00:00,https://twitter.com/GaryMarcus/status/1530965882255441920,@tdietterich @rogerkmoore and then we wake up and the frog has been fully boiled
4355,@GaryMarcus,2022-05-29 17:19:54+00:00,https://twitter.com/GaryMarcus/status/1530962149077463041,"@tdietterich @rogerkmoore people were much clearer (never perfect) about these distinctions in the ‚Äò90s‚Ä¶ i have never seen the current level of confusion, though"
4356,@GaryMarcus,2022-05-29 17:18:55+00:00,https://twitter.com/GaryMarcus/status/1530961900598546432,@ElijahYilma @pmddomingos yes (though other forms of hybrid AI might be developed too)
4357,@GaryMarcus,2022-05-29 16:10:58+00:00,https://twitter.com/GaryMarcus/status/1530944799913566208,thanks! perhaps the only thing that is truly exponential these days is hype?
4358,@GaryMarcus,2022-05-29 14:18:04+00:00,https://twitter.com/GaryMarcus/status/1530916387610234880,@rogerkmoore https://t.co/MLK3hei6uj
4359,@GaryMarcus,2022-05-29 14:15:41+00:00,https://twitter.com/GaryMarcus/status/1530915788994973696,"As @rogerkmoore notes ‚ÄúWe should never have called it ‚Äúlanguage modelling‚Äù ‚Ä¶ it was (and still is) ‚Äúword sequence modelling‚Äù.‚Äù

Only thing worse was calling ‚Äústacked perceptual classifiers‚Äù ‚Äúdeep learning‚Äù‚Äîimplying a conceptual depth that is &amp; remains entirely absent."
4360,@GaryMarcus,2022-05-29 13:13:02+00:00,https://twitter.com/GaryMarcus/status/1530900019527548928,@TaliaRinger The most serious problem in machine learning right now is its inability to reckon with serious criticism.
4361,@GaryMarcus,2022-05-29 05:30:58+00:00,https://twitter.com/GaryMarcus/status/1530783740250583040,@pmddomingos hybrid AI: many representations
4362,@GaryMarcus,2022-05-29 05:29:46+00:00,https://twitter.com/GaryMarcus/status/1530783435307880448,@Tweetermeyer ü§£ü§£ü§£
4363,@GaryMarcus,2022-05-29 03:57:35+00:00,https://twitter.com/GaryMarcus/status/1530760237874958336,@timnitGebru that‚Äôs very much like what Ernest Davis and I argued here: https://t.co/qwExULkwCO
4364,@GaryMarcus,2022-05-29 01:16:36+00:00,https://twitter.com/GaryMarcus/status/1530719724295929858,"this argument is not sound: ‚ÄúLanguage has powerful reasoning vocabulary.
This gives Language Models the ability to reason‚Äù 
First premise is true, but leap to second is not logically entailed, given that language models have known trouble w compositionality.
@guyvdb @luislamb"
4365,@GaryMarcus,2022-05-29 01:12:18+00:00,https://twitter.com/GaryMarcus/status/1530718644702945282,@soumithchintala how would you define reason? at best this sounds like a hypothesis not a proven fact. and see eg
4366,@GaryMarcus,2022-05-28 21:53:32+00:00,https://twitter.com/GaryMarcus/status/1530668623261339650,@Plinz https://t.co/xuAJC1YjdM
4367,@GaryMarcus,2022-05-28 19:27:54+00:00,https://twitter.com/GaryMarcus/status/1530631972607107072,@AR_Kareem_ @LucaAmb @GoogleAI discussed more here
4368,@GaryMarcus,2022-05-28 19:26:15+00:00,https://twitter.com/GaryMarcus/status/1530631558301773824,@bneyshabur addressed here:
4369,@GaryMarcus,2022-05-28 19:25:52+00:00,https://twitter.com/GaryMarcus/status/1530631461853749250,@yanndubs @DavidSKrueger @stanislavfort @freedguy @joe_shabadoo indeed. but see:
4370,@GaryMarcus,2022-05-28 19:25:25+00:00,https://twitter.com/GaryMarcus/status/1530631346749485056,"@LucaAmb @GoogleAI and it is the wrong explanation here, see:"
4371,@GaryMarcus,2022-05-28 18:37:11+00:00,https://twitter.com/GaryMarcus/status/1530619209847164928,now analyzed in further detail here: https://t.co/ZacV6jKxJ6
4372,@GaryMarcus,2022-05-28 18:18:37+00:00,https://twitter.com/GaryMarcus/status/1530614537308606464,"@DotCSV @GoogleAI ps next essay will end with a very different line, I promise :)"
4373,@GaryMarcus,2022-05-28 18:17:10+00:00,https://twitter.com/GaryMarcus/status/1530614170256674816,@DotCSV @GoogleAI ü§£ and thanks for the close read (now fixed)
4374,@GaryMarcus,2022-05-28 17:27:11+00:00,https://twitter.com/GaryMarcus/status/1530601590909829120,"Horse rides astronaut: What nearly everyone got wrong about @GoogleAI's #Imagen (and DALL-E), and why when it comes to AI hype, you still can't believe what you read. 

A #longread into evaluating claims about deep learning, with a cameo from Clever Hans. https://t.co/ZacV6jKxJ6"
4375,@GaryMarcus,2022-05-28 13:35:09+00:00,https://twitter.com/GaryMarcus/status/1530543200657559553,"If you enjoyed this essay on Noam Chomsky and GPT-3, I hope you will subscribe to https://t.co/8ir1xKvqt6 ‚Äì next essay coming today!"
4376,@GaryMarcus,2022-05-28 13:17:28+00:00,https://twitter.com/GaryMarcus/status/1530538747413995520,"@jordiae @GoogleAI you won‚Äôt agree, but i appreciate your graciousness :)"
4377,@GaryMarcus,2022-05-28 04:28:46+00:00,https://twitter.com/GaryMarcus/status/1530405696314847234,"This tweet, about @GoogleAI‚Äôs #Imagen, didn‚Äôt age so well, at least in my view. I will explain more, soon."
4378,@GaryMarcus,2022-05-27 20:11:36+00:00,https://twitter.com/GaryMarcus/status/1530280579538685952,"‚ÄúHorses, astronauts, and the bumpy road to General AI‚Äù

Coming Saturday May 28 to https://t.co/8ir1xKvqt6

With cameos from @sama, @googleAI, @plinz, @LucaAmb, @DeWeeseLab and more, and written in memory of Drew McDermott, who said it all better, and earlier, in 1976. https://t.co/JNX8VLi7E9"
4379,@GaryMarcus,2022-05-27 20:09:06+00:00,https://twitter.com/GaryMarcus/status/1530279951131258880,"@MadamePratolung published more or less at same time as your thread, and so relevant"
4380,@GaryMarcus,2022-05-27 20:04:40+00:00,https://twitter.com/GaryMarcus/status/1530278835777744897,@MadamePratolung @vinodg ha ha of course not; but it wasn‚Äôt a social question so much as convenience sample poll of some software developers i can quickly reach.
4381,@GaryMarcus,2022-05-27 19:02:16+00:00,https://twitter.com/GaryMarcus/status/1530263132974616577,"‚ÄúIn the past few years, our tolerance of sloppy thinking has led us to repeat many mistakes over and over.
‚Ä¶It is hard to say where [we] have gone wronger, in underestimating language or overestimating computer programs.‚Äù
‚Äî Drew McDermott, 1949-2022"
4382,@GaryMarcus,2022-05-27 18:11:00+00:00,https://twitter.com/GaryMarcus/status/1530250233061339136,"Artificial intelligence meets Natural Stupidity, written in 1976, an incredibly smart part that remains extremely relevant today.

*Everyone* in AI and ML should read it.

Drew McDermott, 1949-2022 RIP

https://t.co/I9ZQdwQ31c"
4383,@GaryMarcus,2022-05-27 18:01:19+00:00,https://twitter.com/GaryMarcus/status/1530247794924998656,"@BogdanIonutCir2 @Abebab one might eg look through a lens of prioritization and probabilities, trading off immediate suffering that would likely be disproportionately borne by 3rd world vs hard to quantify possible futures.

and see @TaNehisiCoats case for reparations, for historical background"
4384,@GaryMarcus,2022-05-27 17:34:46+00:00,https://twitter.com/GaryMarcus/status/1530241114409558016,"and, hey, if you are not already following her, today is a good day to start 

#ff @Abebab"
4385,@GaryMarcus,2022-05-27 17:26:58+00:00,https://twitter.com/GaryMarcus/status/1530239151349518336,@scottiev @Tesla they may yet
4386,@GaryMarcus,2022-05-27 17:26:44+00:00,https://twitter.com/GaryMarcus/status/1530239090800545792,@scottiev @Tesla show me *all* of the data
4387,@GaryMarcus,2022-05-27 17:23:36+00:00,https://twitter.com/GaryMarcus/status/1530238302057508864,@seaugust except by 45
4388,@GaryMarcus,2022-05-27 16:31:19+00:00,https://twitter.com/GaryMarcus/status/1530225143229734912,"And 
- A. Why won‚Äôt @Tesla be more forthcoming about the things?
- B. What will it take to pass laws that make public disclosure and tracking of autopilot involvement mandatory?"
4389,@GaryMarcus,2022-05-27 16:28:53+00:00,https://twitter.com/GaryMarcus/status/1530224532979523584,@TShevlane @gershbrain @PTetlock
4390,@GaryMarcus,2022-05-27 15:28:45+00:00,https://twitter.com/GaryMarcus/status/1530209401193213953,@hellosemy omg. link?
4391,@GaryMarcus,2022-05-27 15:17:24+00:00,https://twitter.com/GaryMarcus/status/1530206544494678017,Coming soon https://t.co/WDFhQ6PRJO
4392,@GaryMarcus,2022-05-27 15:12:07+00:00,https://twitter.com/GaryMarcus/status/1530205214128500737,"@BogdanIonutCir2 @sir_deenicus @DonaldClark @IntuitMachine this is a lousy question, because the term deep learning is too poorly defined. see eg discussion Bengio and I had here: https://t.co/U8GBFplk4n
cc @matthewjbar"
4393,@GaryMarcus,2022-05-27 15:02:07+00:00,https://twitter.com/GaryMarcus/status/1530202698842198022,@sir_deenicus @DonaldClark @IntuitMachine what if the only thing the survives is practice of using lots of data?
4394,@GaryMarcus,2022-05-27 15:00:54+00:00,https://twitter.com/GaryMarcus/status/1530202392863485953,@raphaelmilliere @Chitwan_Saharia @Chitwan_Saharia please try (&amp; share all outputs)
4395,@GaryMarcus,2022-05-27 14:57:45+00:00,https://twitter.com/GaryMarcus/status/1530201599347331073,Nobody has studied the behind-the-scenes tactics of Elon Musk more carefully than @Tweetermeyer:
4396,@GaryMarcus,2022-05-27 14:57:32+00:00,https://twitter.com/GaryMarcus/status/1530201542350888964,"@raphaelmilliere what were the prompts for the trees? was it ‚Äúliteral parse trees‚Äù?

would like to see @Chitwan_Saharia run the same on Imagen to compare the text."
4397,@GaryMarcus,2022-05-27 14:53:36+00:00,https://twitter.com/GaryMarcus/status/1530200553250205696,@qhardy @Abebab ü§£ü§£üò¢
4398,@GaryMarcus,2022-05-27 14:51:16+00:00,https://twitter.com/GaryMarcus/status/1530199964957102081,"Bravo, @Abebab nails the critique others have been trying to formulate,  but without any of the unfair ad hominem.

Looking forward to seeing how she develops the argument."
4399,@GaryMarcus,2022-05-27 14:44:19+00:00,https://twitter.com/GaryMarcus/status/1530198217882603521,"@MadamePratolung @francoisfleuret @doRadiology @geoffreyhinton exactly my experience when someone used GPT two weeks ago to ape me: parts got my style, but only of what i said before, not what was novel, and it lost the coherence. might be fine for an undergrad term paper.  but i can‚Äôt see any use for it in the essays i would actually write."
4400,@GaryMarcus,2022-05-27 13:54:00+00:00,https://twitter.com/GaryMarcus/status/1530185554465132544,or if you prefer graphs with your dose of reality:
4401,@GaryMarcus,2022-05-27 13:51:48+00:00,https://twitter.com/GaryMarcus/status/1530185000762560519,"Guns don‚Äôt kill people. Stupid policies kill people. 

First part of the above is false; second is true:"
4402,@GaryMarcus,2022-05-27 13:48:46+00:00,https://twitter.com/GaryMarcus/status/1530184237294313472,"to @MadamePratolung‚Äôs point, even tiny tasks like proctoring exams can be fraught when you try to replace humans: https://t.co/L0biwwJ8LP"
4403,@GaryMarcus,2022-05-27 06:11:54+00:00,https://twitter.com/GaryMarcus/status/1530069263574126592,"@yanndubs @DavidSKrueger @stanislavfort @freedguy @joe_shabadoo it will be here, first draft complete:"
4404,@GaryMarcus,2022-05-27 06:10:39+00:00,https://twitter.com/GaryMarcus/status/1530068948246405121,"Subscribers to https://t.co/8ir1xKvqt6 (free, as ever) will be first to see ‚ÄúHorses, astronauts, and the bumpy road to general AI‚Äù"
4405,@GaryMarcus,2022-05-27 04:11:08+00:00,https://twitter.com/GaryMarcus/status/1530038874097221632,Now there‚Äôs a benchmark!
4406,@GaryMarcus,2022-05-27 04:08:47+00:00,https://twitter.com/GaryMarcus/status/1530038282695811072,@AngeloDalli why is it so hard for so many people to see that?
4407,@GaryMarcus,2022-05-27 04:07:46+00:00,https://twitter.com/GaryMarcus/status/1530038023093514241,@danbri what is important about it?
4408,@GaryMarcus,2022-05-27 00:49:54+00:00,https://twitter.com/GaryMarcus/status/1529988231294423041,@yanndubs @DavidSKrueger @stanislavfort @freedguy @joe_shabadoo i think this is missing the point; i will explain in a short essay to come.
4409,@GaryMarcus,2022-05-26 21:53:03+00:00,https://twitter.com/GaryMarcus/status/1529943722380496896,"At this point, the machine learning community can be divided into two groups:
- those that crack jokes
- those that recognize reality."
4410,@GaryMarcus,2022-05-26 20:28:53+00:00,https://twitter.com/GaryMarcus/status/1529922544819548160,@santoroAI @ylecun btw i agree with what you say in this tweet; i just don‚Äôt think that‚Äôs the issue at hand. the issue at hand is that is important to consider different accounts of reasoning and to recognize that they in fact differ
4411,@GaryMarcus,2022-05-26 20:27:36+00:00,https://twitter.com/GaryMarcus/status/1529922222046838791,"@santoroAI @ylecun @HonghuaZhang2 @guyvdb in calling the debate :‚Äùvacuous‚Äù, he‚Äôs *not* putting his cards on the table (eg, symbols not required for reasoning), he‚Äôs kicking over the table, and telling other people to not even bother to place their bets. 

that‚Äôs what I am objecting to, not his particular views."
4412,@GaryMarcus,2022-05-26 18:57:34+00:00,https://twitter.com/GaryMarcus/status/1529899563808501760,"@santoroAI @ylecun I think that‚Äôs an empirical question, and a substantive one, and an important one. 

And that this @HonghuaZhang2/ @guyvdb study, for example, suggest/ that reasoning without hybrids is not likely to be effective."
4413,@GaryMarcus,2022-05-26 16:32:03+00:00,https://twitter.com/GaryMarcus/status/1529862940978864130,@patrickmesana @ylecun if you use a symbolic database to track a cognitive model is that ‚Äújust SWE‚Äù?
4414,@GaryMarcus,2022-05-26 16:10:19+00:00,https://twitter.com/GaryMarcus/status/1529857471308627968,@maartengm @ylecun i wrote a whole book in 2001 about my definitions and they have not changed.
4415,@GaryMarcus,2022-05-26 16:07:07+00:00,https://twitter.com/GaryMarcus/status/1529856665431859207,"@raphaelmilliere @mpshanahan @ylecun I explicitly asked LeCun for clarification, repeatedly, after he made that remark, and he did not respond."
4416,@GaryMarcus,2022-05-26 16:04:50+00:00,https://twitter.com/GaryMarcus/status/1529856093043556353,@maartengm @ylecun all of which were the direct subject of my monograph The Algebraic Mind
4417,@GaryMarcus,2022-05-26 16:04:02+00:00,https://twitter.com/GaryMarcus/status/1529855889947078657,@maartengm @ylecun no he is not naive on that. but eg these are real issues:
4418,@GaryMarcus,2022-05-26 15:59:45+00:00,https://twitter.com/GaryMarcus/status/1529854814653255682,@willknight
4419,@GaryMarcus,2022-05-26 15:59:20+00:00,https://twitter.com/GaryMarcus/status/1529854710231863297,"@raphaelmilliere @mpshanahan @ylecun fine, but that doesn‚Äôt mean the debate is ‚Äúvacuous‚Äù, it means that there are important substantive issues that need to be clarified.

I don‚Äôt mind if people have different views on these issues; i do mind if they try to stifle legitimate discussions that others are having."
4420,@GaryMarcus,2022-05-26 15:56:42+00:00,https://twitter.com/GaryMarcus/status/1529854045573173248,"Software developers, Wired says you are worried. True or False? 

‚ÄúBoth Codex and Copilot have stirred up some anxiety among developers, who fear they could be automated out of a job.‚Äù

https://t.co/f9cxPVoBG3"
4421,@GaryMarcus,2022-05-26 15:37:36+00:00,https://twitter.com/GaryMarcus/status/1529849240817573889,"@raphaelmilliere @mpshanahan @ylecun our differences are mostly that I see the following three things as essential
- research on how to build hybrids 
- greater attention to defining and implementing a broad range of innate priors
-explicit cognitive models &amp; ways of incorporating explicit large-scale knowledge"
4422,@GaryMarcus,2022-05-26 15:25:21+00:00,https://twitter.com/GaryMarcus/status/1529846155751723009,"@raphaelmilliere @mpshanahan @ylecun i am arguing for a strong interpretation, though open to listening to alternatives."
4423,@GaryMarcus,2022-05-26 15:23:21+00:00,https://twitter.com/GaryMarcus/status/1529845653085442049,"@pkghosh99 @Chitwan_Saharia @raphaelmilliere @TristanThrush misinformation, unfortunately"
4424,@GaryMarcus,2022-05-26 15:16:35+00:00,https://twitter.com/GaryMarcus/status/1529843950860718081,@raphaelmilliere @mpshanahan @ylecun ps i wrote a whole book defining these specific terms and their relevance and application
4425,@GaryMarcus,2022-05-26 15:15:16+00:00,https://twitter.com/GaryMarcus/status/1529843619502297089,"@raphaelmilliere @mpshanahan @ylecun i don‚Äôt see the problem with the terms or commitments here, but feel free to elaborate"
4426,@GaryMarcus,2022-05-26 14:43:28+00:00,https://twitter.com/GaryMarcus/status/1529835614622711808,"@mpshanahan @ylecun i don‚Äôt actually have a strong view about differentiability. i remain fully committed to the value of symbolic operations over variables, and to structured representations, but open (w mild but not absolute pessimism) to how deeply differentiation can go."
4427,@GaryMarcus,2022-05-26 14:40:33+00:00,https://twitter.com/GaryMarcus/status/1529834883530469376,"@TacoCohen @ylecun 2/ What we need
üëâ theory and practice about how to integrate the two traditions 
üëâ intellectual respect and humility, such that people on either side respect the strengths and weakness of the two approaches, and places for possible collaboration"
4428,@GaryMarcus,2022-05-26 14:38:26+00:00,https://twitter.com/GaryMarcus/status/1529834347922006018,"@TacoCohen @ylecun 1/ 

Is a classic expert system hybrid? no. 

Is a pure multilayer perception hybrid? no

is searching a symbolic tree and applying a neural net to each candidate a hybrid? yes

the fact that a beanbag chair is a non canonical chair doesn‚Äôt mean we can‚Äôt talk about chairs."
4429,@GaryMarcus,2022-05-26 14:21:12+00:00,https://twitter.com/GaryMarcus/status/1529830013335285760,@LivingOnStar9 bs. see https://t.co/ufbxCXeFOL
4430,@GaryMarcus,2022-05-26 14:13:12+00:00,https://twitter.com/GaryMarcus/status/1529827998794321920,first it was‚Äùcompletely obvious‚Äù that all the radiologists were going to be replaced ‚Ä¶
4431,@GaryMarcus,2022-05-26 14:09:51+00:00,https://twitter.com/GaryMarcus/status/1529827156074737664,@fchollet https://t.co/ufbxCXeFOL
4432,@GaryMarcus,2022-05-26 13:43:17+00:00,https://twitter.com/GaryMarcus/status/1529820470282883073,@ylecun https://t.co/Hpb1ymGx6h
4433,@GaryMarcus,2022-05-26 13:33:39+00:00,https://twitter.com/GaryMarcus/status/1529818046872756225,@KarlaParussel @JaumeTeixi @ShaneLegg everyone in AI should that paper. More than once.
4434,@GaryMarcus,2022-05-26 13:30:04+00:00,https://twitter.com/GaryMarcus/status/1529817144967323648,"How can you both say this and that discussions of hybrid, neurosymbolic models are ‚Äúvacuous debates‚Äù? 

Please help me understand your view, @ylecun."
4435,@GaryMarcus,2022-05-26 02:06:31+00:00,https://twitter.com/GaryMarcus/status/1529645124640178178,@hoskingc @Grady_Booch @TheNickBlizzard that tells us almost nothing
4436,@GaryMarcus,2022-05-26 01:50:06+00:00,https://twitter.com/GaryMarcus/status/1529640990503485440,@hoskingc @Grady_Booch @TheNickBlizzard it‚Äôs like saying that humans are like sea slugs because we both have DNA and share some genes and proteins. all true but not terribly informative as to causal mechanisms.
4437,@GaryMarcus,2022-05-26 00:39:41+00:00,https://twitter.com/GaryMarcus/status/1529623272261701632,@pmddomingos @ethanCaballero can hook you up
4438,@GaryMarcus,2022-05-26 00:39:04+00:00,https://twitter.com/GaryMarcus/status/1529623116414001152,example from @ErnestSDavis
4439,@GaryMarcus,2022-05-26 00:39:04+00:00,https://twitter.com/GaryMarcus/status/1529623114400681984,"with this one trick, GPT-3 can solve decades-old riddles of reasoning and commonsense!

nearly 2,000 people have already liked it!

try it now, while supplies last!

‚ÄúLet‚Äôs think step by step‚Äù! https://t.co/axJRJBq7nT"
4440,@GaryMarcus,2022-05-26 00:24:30+00:00,https://twitter.com/GaryMarcus/status/1529619448411619328,@kristintynski @NickRMorgan @prokraustinator that‚Äôs the illusion of large data;
4441,@GaryMarcus,2022-05-26 00:00:11+00:00,https://twitter.com/GaryMarcus/status/1529613331379929089,"@MaartenBosma but you as human can reread and correct your mistake, System 2 winning out over System 1"
4442,@GaryMarcus,2022-05-25 23:57:15+00:00,https://twitter.com/GaryMarcus/status/1529612591458226176,@pmddomingos touch√©
4443,@GaryMarcus,2022-05-25 23:55:04+00:00,https://twitter.com/GaryMarcus/status/1529612043975680000,"@pmddomingos a lot of people are rightly (IMHO) sensitive around the name, especially given the response of some when the issue was raised."
4444,@GaryMarcus,2022-05-25 23:50:03+00:00,https://twitter.com/GaryMarcus/status/1529610781204983808,@max_nlp @raphaelmilliere @TristanThrush That‚Äôs seems like a question for @TristanThrush
4445,@GaryMarcus,2022-05-25 23:46:43+00:00,https://twitter.com/GaryMarcus/status/1529609939995480064,@kristintynski i will DM you one that I can‚Äôt post for TOS reasons
4446,@GaryMarcus,2022-05-25 23:46:14+00:00,https://twitter.com/GaryMarcus/status/1529609818280931328,"should have mentioned that @ErnestSDavis ran this test, based on one of our examples in 2014."
4447,@GaryMarcus,2022-05-25 23:45:21+00:00,https://twitter.com/GaryMarcus/status/1529609598583586816,"@_jasonwei example from @ErnestSDavis, drawn from one of our 2014 articles:"
4448,@GaryMarcus,2022-05-25 23:43:12+00:00,https://twitter.com/GaryMarcus/status/1529609056805322752,@kristintynski @prokraustinator then hopefully you will take my last tweet w a sense of humor :)
4449,@GaryMarcus,2022-05-25 23:42:09+00:00,https://twitter.com/GaryMarcus/status/1529608793784557568,"‚ÄúLet‚Äôs think step by step.‚Äù 

Sometimes it keeps GPT on the rails.

Sometimes it doesn‚Äôt: https://t.co/JwwCWiqWDh"
4450,@GaryMarcus,2022-05-25 23:38:49+00:00,https://twitter.com/GaryMarcus/status/1529607954961678336,The real gallows humor joke here is that researchers used to ask each other challenging questions.
4451,@GaryMarcus,2022-05-25 23:34:19+00:00,https://twitter.com/GaryMarcus/status/1529606820620566533,@kristintynski @prokraustinator stay tuned :)
4452,@GaryMarcus,2022-05-25 23:32:24+00:00,https://twitter.com/GaryMarcus/status/1529606339520909312,"@kristintynski i don‚Äôt doubt this, but the problem lies in getting the right groove. if you want humans-in-the-loop, it might work to some degree; if you leave these machines to their own devices they aren‚Äôt going to recognize when a given prompt is leading the wrong way.

[examples to come]"
4453,@GaryMarcus,2022-05-25 23:30:01+00:00,https://twitter.com/GaryMarcus/status/1529605739324485633,@Abebab which is not to take away from the incredibly difficult challenges around formulating and implementing policy. but it‚Äôs not either/or in my view; it‚Äôs that we work on both-and.
4454,@GaryMarcus,2022-05-25 23:28:22+00:00,https://twitter.com/GaryMarcus/status/1529605324365131777,"@Abebab I guess I don‚Äôt really see that. it‚Äôs a disaster that current systems have no sense of equity, truth or avoiding harm, but I‚Äôm not sure why it would be a bad thing if they did.

compare with humans: we are better off interacting w humans with ethical values than with sociopaths"
4455,@GaryMarcus,2022-05-25 23:23:18+00:00,https://twitter.com/GaryMarcus/status/1529604050198482944,"@pmddomingos good joke, but call it NeurIPS, ‚Äòcause that‚Äôs what it is now."
4456,@GaryMarcus,2022-05-25 22:58:30+00:00,https://twitter.com/GaryMarcus/status/1529597808336318465,"@prokraustinator probably yes, for some, not all, problems"
4457,@GaryMarcus,2022-05-25 22:51:45+00:00,https://twitter.com/GaryMarcus/status/1529596110339117056,"@mwfulk i believe you got it, in one guess."
4458,@GaryMarcus,2022-05-25 22:47:40+00:00,https://twitter.com/GaryMarcus/status/1529595082512674817,"Anyone want to guess how robust this is, before I reveal the answer?"
4459,@GaryMarcus,2022-05-25 22:45:44+00:00,https://twitter.com/GaryMarcus/status/1529594593033035776,"Same wall, over and over and over and over

and same (false) accusation of goal post moving. 
every time."
4460,@GaryMarcus,2022-05-25 22:44:14+00:00,https://twitter.com/GaryMarcus/status/1529594218033061888,"@miguelisolano absolutely, eg 1994 book with his example man bites dog, and again (if memory serves) in 1997 How The Mind Words discussion of computation."
4461,@GaryMarcus,2022-05-25 22:43:15+00:00,https://twitter.com/GaryMarcus/status/1529593968014438400,@IntuitMachine here‚Äôs @ErnestSDavis‚Äôs first try: https://t.co/bVQO7DJQkU
4462,@GaryMarcus,2022-05-25 22:40:38+00:00,https://twitter.com/GaryMarcus/status/1529593310913802240,Look forward to seeing the Imagen results from Winoground!
4463,@GaryMarcus,2022-05-25 22:37:33+00:00,https://twitter.com/GaryMarcus/status/1529592535093772288,"So, @Chitwan_Saharia, first author of Imagen, are you going to let me and @ErnestSDavis try for ourselves?"
4464,@GaryMarcus,2022-05-25 22:03:44+00:00,https://twitter.com/GaryMarcus/status/1529584023806152704,"@realohtweets when you claim you have ‚Äúa deep understanding of language‚Äù, as the Imagen paper and PR did, or hint that your work relates to AGI, you are answerable to those questions"
4465,@GaryMarcus,2022-05-25 21:29:41+00:00,https://twitter.com/GaryMarcus/status/1529575455421919233,"In today‚Äôs episode of forgetting that Fodor and Pylyshyn pointed to *exactly* the same challenge in 1988 (then reemphasized by me in 2001, 2012, 2018, 2020, 2022‚Ä¶)

old goal: AI that could reason about world
new goal: pretty pictures involving not all the words in a sentence"
4466,@GaryMarcus,2022-05-25 19:58:03+00:00,https://twitter.com/GaryMarcus/status/1529552396593967104,Model of a great letter of recommendation for a very worthy recommendee.
4467,@GaryMarcus,2022-05-25 19:55:42+00:00,https://twitter.com/GaryMarcus/status/1529551804433723392,@timnitGebru this is a fantastic letter
4468,@GaryMarcus,2022-05-25 19:43:24+00:00,https://twitter.com/GaryMarcus/status/1529548709620461568,"@raphaelmilliere the broken link to ‚Äúcompositionality, whatever that means‚Äù or words to that effect is the particular bit that felt dismissive"
4469,@GaryMarcus,2022-05-25 19:35:06+00:00,https://twitter.com/GaryMarcus/status/1529546619305111552,"@raphaelmilliere I found the blog to be dismissive of the (linguistic) idea of compositionality (as opposed to compositing). See eg Zoltan Szabo‚Äôs definition ‚ÄúThe meaning of a complex expression is determined by its structure and the meanings of its constituents‚Äù, and tradition back to Frege."
4470,@GaryMarcus,2022-05-25 18:02:16+00:00,https://twitter.com/GaryMarcus/status/1529523256197230592,"@SteveCrowe hard to think of a reason to move to BC, other than the ones I just mentioned. and, e.g., these https://t.co/leCRU0HfJV"
4471,@GaryMarcus,2022-05-25 17:55:14+00:00,https://twitter.com/GaryMarcus/status/1529521488600121346,Not regretting my decision to move to Canada.
4472,@GaryMarcus,2022-05-25 17:49:38+00:00,https://twitter.com/GaryMarcus/status/1529520079284879360,@bneyshabur thanks for trying these. Could @ErnestSDavis and I give you some more to try?
4473,@GaryMarcus,2022-05-25 17:46:21+00:00,https://twitter.com/GaryMarcus/status/1529519251962286080,"@pmddomingos @AvilaGarcez Indeed (&amp; great paper, as I said yesterday). @AvilaGarcez was talking about best case; it can be worse in practice."
4474,@GaryMarcus,2022-05-25 15:34:07+00:00,https://twitter.com/GaryMarcus/status/1529485975033741312,@ShaneLegg @bengoertzel @bengoertzel @petervoss?
4475,@GaryMarcus,2022-05-25 15:26:02+00:00,https://twitter.com/GaryMarcus/status/1529483941501014021,"@ShaneLegg @bengoertzel and how would you define it, @ShaneLegg?"
4476,@GaryMarcus,2022-05-25 15:11:33+00:00,https://twitter.com/GaryMarcus/status/1529480294704631810,@raphaelmilliere but the horse riding an astronaut examples hint at further problems. we need a task like @TristanThrush‚Äôs. https://t.co/zR2ztuJB3r
4477,@GaryMarcus,2022-05-25 14:51:18+00:00,https://twitter.com/GaryMarcus/status/1529475200474984451,"@cgmooreauthor and see my conversation with Penn, https://t.co/mrSq5vydxY (and next episode)"
4478,@GaryMarcus,2022-05-25 14:48:58+00:00,https://twitter.com/GaryMarcus/status/1529474611766628353,"@luislamb @AvilaGarcez @pascalhitzler @Melleo54Sis @ykilcher @YouTube Thanks, @MLStreetTalk, for hosting, long before it was fashionable"
4479,@GaryMarcus,2022-05-25 14:38:48+00:00,https://twitter.com/GaryMarcus/status/1529472053840969728,@lathropa @XiaohuaZhai Matches @ErnestSDavis ‚Äòs 1-in-3
4480,@GaryMarcus,2022-05-25 14:37:12+00:00,https://twitter.com/GaryMarcus/status/1529471653092028416,@grsimari I actually asked him for clarification multiple times re his earlier claims and he refused to engage.
4481,@GaryMarcus,2022-05-25 14:34:38+00:00,https://twitter.com/GaryMarcus/status/1529471004539383808,"ü§≠
Marcus says ‚ÄúThese are like parlour tricks... They‚Äôre able to fool unsophisticated humans who aren‚Äôt trained to understand these things. But that doesn‚Äôt mean that they‚Äôre actually anywhere near AGI‚Äù
‚Ä¶
DeepMind wasn‚Äôt available for comment.
‚Äì @sparkes https://t.co/EQsjZ1y53R"
4482,@GaryMarcus,2022-05-25 14:26:31+00:00,https://twitter.com/GaryMarcus/status/1529468963477893121,"The problem with large language models, in a single poem"
4483,@GaryMarcus,2022-05-25 14:24:45+00:00,https://twitter.com/GaryMarcus/status/1529468517413556225,"@hangingnoodles @hangingnoodles, that was my next Substack! :)"
4484,@GaryMarcus,2022-05-25 14:21:10+00:00,https://twitter.com/GaryMarcus/status/1529467616175067136,"@XiaohuaZhai in fairness, Ernie ran a third, while I was typing, and your system got that right. but I am definitely not smelling ‚Äúdeep language understanding‚Äù

we‚Äôre happy to try more if you want to give us access to your largest model https://t.co/Ebelx4PXem"
4485,@GaryMarcus,2022-05-25 14:17:09+00:00,https://twitter.com/GaryMarcus/status/1529466603523301376,"Success on a single prompt does not ‚Äúdeep understanding of language make‚Äù. It‚Äôs great, though, that people are sending me links for models to try.

I often pass them to @ErnestSDavis; here‚Äôs what he found on his first (&amp; thus far only) two tries:

Folks, this is not AGI. https://t.co/c9TmVOP9CD"
4486,@GaryMarcus,2022-05-25 13:39:38+00:00,https://twitter.com/GaryMarcus/status/1529457162811936768,"I believe @ShaneLegg (also at DeepMind) coined the term AGI. 

Personally, I use it as a shorthand for any intelligence (there might be many) that is flexible and general, with resourcefulness and reliability comparable to (or beyond) human intelligence."
4487,@GaryMarcus,2022-05-25 13:29:44+00:00,https://twitter.com/GaryMarcus/status/1529454672498479106,‚Äúthe fact that DeepMind called Gato a ‚Äúgeneralist‚Äù might have made it a victim of the AI sector‚Äôs excessive hype around AGI.‚Äù -@melissahei
4488,@GaryMarcus,2022-05-25 13:11:26+00:00,https://twitter.com/GaryMarcus/status/1529450067043577856,"@pragmaticml @GoogleAI A few years ago people shared data; now they share only cherry-picked examples; skeptics can only report a subset of those cherry-picked examples, because they aren‚Äôt permitted to use the systems."
4489,@GaryMarcus,2022-05-25 13:09:25+00:00,https://twitter.com/GaryMarcus/status/1529449558870134784,@ykilcher @dionhaefner see also eg https://t.co/oS8uXbIFF3
4490,@GaryMarcus,2022-05-25 13:01:27+00:00,https://twitter.com/GaryMarcus/status/1529447555506970625,"@ykilcher @dionhaefner my core point is that neural nets often succeed for the wrong reasons, glomming onto accidental contingencies, and making them appear to reason (causally, or otherwise) more effectively and broadly than they actually can.  

 (‚ÄúSystem 1‚Äù does some of this in humans, to be sure.)"
4491,@GaryMarcus,2022-05-25 12:25:07+00:00,https://twitter.com/GaryMarcus/status/1529438410112241664,"sorry, but no. 

you don‚Äôt get to dismiss an entire field‚Äîhybrid, neurosymbolic models that seek to integrate reasoning with neural networks‚Äîas ‚Äúvacuous‚Äù and then two weeks later try to take credit for its core mission."
4492,@GaryMarcus,2022-05-25 12:10:39+00:00,https://twitter.com/GaryMarcus/status/1529434771838799872,@LucaAmb @GoogleAI not a defense nor explanation; lots of the successful examples are absurd
4493,@GaryMarcus,2022-05-25 03:33:39+00:00,https://twitter.com/GaryMarcus/status/1529304662607683584,"um, how about gun control?"
4494,@GaryMarcus,2022-05-25 03:21:52+00:00,https://twitter.com/GaryMarcus/status/1529301697146720256,"@_jasonwei reading this, my first thought was, ‚Äúis it robust‚Äù? my second was to look at the paper. answer is, ‚Äúsomewhat, but it depends‚Äù: https://t.co/Kb0OIRoW7S"
4495,@GaryMarcus,2022-05-25 03:16:18+00:00,https://twitter.com/GaryMarcus/status/1529300298597945344,"@pmddomingos and, like, I dunno, the whole brain was like, um, ‚Ä¶ linear algebra?"
4496,@GaryMarcus,2022-05-25 02:54:00+00:00,https://twitter.com/GaryMarcus/status/1529294683783897088,"@pmddomingos What if, like, neural networks were‚Ä¶ slightly conscious?"
4497,@GaryMarcus,2022-05-25 02:42:51+00:00,https://twitter.com/GaryMarcus/status/1529291880013320192,if only we‚Äôd known
4498,@GaryMarcus,2022-05-25 01:50:46+00:00,https://twitter.com/GaryMarcus/status/1529278772138188800,@NickRMorgan Imagen doesn‚Äôt understand the *mapping* between syntax and semantics
4499,@GaryMarcus,2022-05-25 01:49:57+00:00,https://twitter.com/GaryMarcus/status/1529278567221276672,@NickRMorgan i haven‚Äôt had any access to it whatsoever; the example is from their paper
4500,@GaryMarcus,2022-05-25 01:45:45+00:00,https://twitter.com/GaryMarcus/status/1529277508646051840,"@NickRMorgan it doesn‚Äôt, not fully. riding is a thing that an entity does relative to another entity, and it doesn‚Äôt get which is which"
4501,@GaryMarcus,2022-05-25 01:37:13+00:00,https://twitter.com/GaryMarcus/status/1529275360855986177,"@andrey_kurenkov @Miles_Brundage @GoogleAI @ErnestSDavis we already have asked for the raw outputs, in fact"
4502,@GaryMarcus,2022-05-25 01:36:53+00:00,https://twitter.com/GaryMarcus/status/1529275280077881344,"@andrey_kurenkov @Miles_Brundage @GoogleAI thanks. i really wish they would have supplied the actual outputs, at least from their own model, rather than just saying that relatively speaking people preferred theirs to DALl-E. (which wasn‚Äôt true for our stimuli, i‚Äôd you look at the figure)."
4503,@GaryMarcus,2022-05-25 01:33:26+00:00,https://twitter.com/GaryMarcus/status/1529274408673546240,@andrey_kurenkov @Miles_Brundage @GoogleAI interesting. who is in charge? can @ErnestSDavis and i add some more?
4504,@GaryMarcus,2022-05-25 01:26:22+00:00,https://twitter.com/GaryMarcus/status/1529272630980644864,"@Miles_Brundage @GoogleAI and it‚Äôs not my bar, in this case, but Fodor and Pylyshyn, 1988, from a third of century ago"
4505,@GaryMarcus,2022-05-25 01:15:07+00:00,https://twitter.com/GaryMarcus/status/1529269801809391616,https://t.co/RggGKwLklB
4506,@GaryMarcus,2022-05-25 01:13:38+00:00,https://twitter.com/GaryMarcus/status/1529269425928515584,"üôÑ @GoogleAI, ‚Äúa deep level understanding‚Äù? 

Seriously?!

Your system can‚Äôt distinguish ‚Äúa horse riding an astronaut‚Äù from ‚Äúan astronaut riding a horse‚Äù.  

üôÑ https://t.co/fyrDpPv6VL"
4507,@GaryMarcus,2022-05-25 01:01:20+00:00,https://twitter.com/GaryMarcus/status/1529266333082193921,"More will follow,  but yes Andrew Ng‚Äôs turnaround to hybrid neurosymbolic models was dramatic."
4508,@GaryMarcus,2022-05-24 23:31:51+00:00,https://twitter.com/GaryMarcus/status/1529243810982555648,and each of those guys thinks he is so clever‚Ä¶ (but see https://t.co/z5w4Czkjij)
4509,@GaryMarcus,2022-05-24 23:30:57+00:00,https://twitter.com/GaryMarcus/status/1529243586474086400,@jordiae @giffmana @ethanCaballero https://t.co/GviHPby1fo
4510,@GaryMarcus,2022-05-24 23:11:06+00:00,https://twitter.com/GaryMarcus/status/1529238590336602112,"honestly, if there is anything Game Over in AI lately, it is this:"
4511,@GaryMarcus,2022-05-24 21:18:45+00:00,https://twitter.com/GaryMarcus/status/1529210318718574592,"Dearest deep learning fan, may I ask, did you read the paper carefully, before you wrote your tweet?

Here‚Äôs your wall for you, page 33: compositionality with noncanonical scenarios, same place it‚Äôs been since Fodor and Pylyshyn, 1988. https://t.co/zd0KkH6RDQ"
4512,@GaryMarcus,2022-05-24 21:02:41+00:00,https://twitter.com/GaryMarcus/status/1529206273706582019,@MikeNashTech
4513,@GaryMarcus,2022-05-24 20:51:59+00:00,https://twitter.com/GaryMarcus/status/1529203579218669568,@HappyAar by scaling-√ºber-alles i mean ‚Äúsolving AI by simply adding more parameters and data to current AI systems without fundamentally changing the architecture‚Äù
4514,@GaryMarcus,2022-05-24 19:27:24+00:00,https://twitter.com/GaryMarcus/status/1529182296342814720,Fantastic study and bad news for the scaling-√ºber-alles crowd.
4515,@GaryMarcus,2022-05-24 19:26:02+00:00,https://twitter.com/GaryMarcus/status/1529181950270812160,"@AlexGDimakis but they don‚Äôt; see fab new work by @guyvdb for example, which i will tweet in a second"
4516,@GaryMarcus,2022-05-24 19:24:06+00:00,https://twitter.com/GaryMarcus/status/1529181465006600192,"@pmddomingos or maybe it‚Äôs a wild bull in a china shop, no cart"
4517,@GaryMarcus,2022-05-24 19:14:31+00:00,https://twitter.com/GaryMarcus/status/1529179050987573248,"this made my day, ‚Å¶@HochreiterSepp‚Å© https://t.co/uzMVBCVzLV"
4518,@GaryMarcus,2022-05-24 18:48:54+00:00,https://twitter.com/GaryMarcus/status/1529172606414295040,"First this year to join the hybrid AI revolution: Andrew Ng
Second: Sepp Hochreiter, LSTM pioneer
Many more will follow"
4519,@GaryMarcus,2022-05-24 18:30:04+00:00,https://twitter.com/GaryMarcus/status/1529167867161153536,@HonghuaZhang2 @LiLiunian @TaoMeng10 @kaiwei_chang @guyvdb fantastic work!
4520,@GaryMarcus,2022-05-24 18:25:42+00:00,https://twitter.com/GaryMarcus/status/1529166768031158272,@MadamePratolung @sir_deenicus @Ted_Underwood ha I just made that same point in an oped i am writing :)
4521,@GaryMarcus,2022-05-24 17:31:25+00:00,https://twitter.com/GaryMarcus/status/1529153106621059073,"@sir_deenicus @Ted_Underwood @MadamePratolung Agreed. I‚Äôve been starting to notice this, too
üëâno public access to models
üëâno disclosure of actual tests run
üëâno disclosure of results
üëâno denominators (!) for signature results
üëâsketchy discussion of limitations
üëâcherry-picking
@ZoubinGhahrama1"
4522,@GaryMarcus,2022-05-24 17:26:25+00:00,https://twitter.com/GaryMarcus/status/1529151846199066625,"@sir_deenicus @Ted_Underwood @MadamePratolung &amp; it seems to be *worse* on Marcus-Davis-Aaronson task. Though, as per usual, too little information is released to make sense of what‚Äôs been done. 

Starting to really miss peer review. 

AGI fans who rave about latest press releases without waiting for critical examination üôÑ"
4523,@GaryMarcus,2022-05-24 16:09:29+00:00,https://twitter.com/GaryMarcus/status/1529132485128335360,"@onurc @elonmusk only added, what, $1.5T in market cap?"
4524,@GaryMarcus,2022-05-24 15:42:30+00:00,https://twitter.com/GaryMarcus/status/1529125697226039296,"‚ÄúBarraza said Tesla's Fremont factory was home to ""rampant sexual harassment"" and the company operated like a ""frat house,""‚Äù

At what point will the Board consider replacing the CEO? https://t.co/TvyFDdwIWh"
4525,@GaryMarcus,2022-05-24 14:20:23+00:00,https://twitter.com/GaryMarcus/status/1529105029264617472,@emilymbender OMG where?
4526,@GaryMarcus,2022-05-24 14:08:01+00:00,https://twitter.com/GaryMarcus/status/1529101917787262976,"One never knows when @plinz is kidding, but we should all remember that DALL-E 2 doesn‚Äôt actually understand concepts like mass, density, or weight."
4527,@GaryMarcus,2022-05-24 14:05:52+00:00,https://twitter.com/GaryMarcus/status/1529101379335098368,"@cyberandy tweeted about this last night: if you look at the few tests they did of *noncanonical* low frequency events, like horses riding astronauts, it would appear that same old problems remain.

they tested our recent arXiv stimuli, but compared w Dall-E and didn‚Äôt show actual output."
4528,@GaryMarcus,2022-05-24 13:58:27+00:00,https://twitter.com/GaryMarcus/status/1529099511699607552,"Thoughts, @ylecun? I think Valiant is correct."
4529,@GaryMarcus,2022-05-24 13:25:02+00:00,https://twitter.com/GaryMarcus/status/1529091102547906560,only a Genius‚Ñ¢ would have been able to figure that out‚Ä¶
4530,@GaryMarcus,2022-05-24 13:22:31+00:00,https://twitter.com/GaryMarcus/status/1529090468264390657,"Anyone on the #Imagen team @google #brain want to share the actual results you got from this task? Any chance you would let us try the system?

Merely comparing to another proprietary system without making the actual output available doesn‚Äôt tell us much. @Chitwan_Saharia"
4531,@GaryMarcus,2022-05-24 12:57:08+00:00,https://twitter.com/GaryMarcus/status/1529084081656324096,Should i tell him?
4532,@GaryMarcus,2022-05-24 04:37:38+00:00,https://twitter.com/GaryMarcus/status/1528958377887354880,"@TheGradient @BlancheMinerva you cut, I choose
[https://t.co/o9SxliqxN4]"
4533,@GaryMarcus,2022-05-24 04:35:52+00:00,https://twitter.com/GaryMarcus/status/1528957932838105088,"that‚Äôs what ‚Äúscience‚Äù has become in 2022: cherrypicking the cherries in order to get some vague glimpse of what might actually be going on, and reducing it all to twitter soundbites and one-liners (my own wisecrack included!), because press releases are in &amp; peer review is dead."
4534,@GaryMarcus,2022-05-24 04:29:51+00:00,https://twitter.com/GaryMarcus/status/1528956417750622209,"@TheGradient but also: 35 years or more have emphasized low-frequency/non canonical items, and there is clearly trouble in the two examples they gave, and i am not surprised."
4535,@GaryMarcus,2022-05-24 04:27:32+00:00,https://twitter.com/GaryMarcus/status/1528955834830442503,"@TheGradient being more serious, i wish (a) I could try it and (b) I could more immediately understand the figure page 29, in which my name (among others) appears."
4536,@GaryMarcus,2022-05-24 04:23:12+00:00,https://twitter.com/GaryMarcus/status/1528954746798690304,@ethanCaballero can you make me a t-shirt with this one?
4537,@GaryMarcus,2022-05-24 04:21:01+00:00,https://twitter.com/GaryMarcus/status/1528954195528757249,"Deep learning has leapt over the wall! I was wrong about everything! @Plinz was right! @gdb, too!

Oh, wait."
4538,@GaryMarcus,2022-05-24 04:10:29+00:00,https://twitter.com/GaryMarcus/status/1528951545814867969,"The more things change, the more they stay the same. https://t.co/BNGTBizpMu"
4539,@GaryMarcus,2022-05-24 03:31:16+00:00,https://twitter.com/GaryMarcus/status/1528941677485780992,"@raphaelmilliere if you look at the non canonical examples in the end, a ma @TristanThrush, I am not so sure"
4540,@GaryMarcus,2022-05-24 02:44:58+00:00,https://twitter.com/GaryMarcus/status/1528930021951389703,"@aniketvartak what‚Äôs the scope of all that stuff? lots of fluent syntax,  no real semantics"
4541,@GaryMarcus,2022-05-23 21:09:39+00:00,https://twitter.com/GaryMarcus/status/1528845638313582593,"@Peterbart thanks. i was thinking about writing about work like this, perhaps in friendly adversarial collaboration w @JeanRemiKing."
4542,@GaryMarcus,2022-05-23 20:58:12+00:00,https://twitter.com/GaryMarcus/status/1528842758395674625,@Abebab might make more sense if it were anywhere near imminent.
4543,@GaryMarcus,2022-05-23 20:56:30+00:00,https://twitter.com/GaryMarcus/status/1528842328433115137,"like this, if you would like to see it happen"
4544,@GaryMarcus,2022-05-23 20:39:17+00:00,https://twitter.com/GaryMarcus/status/1528837997214543877,"Only the richest man in the world could forsake around $100 billion, in order to save face &amp; avoid paying a $1 billion fee. https://t.co/NOgt689jT0"
4545,@GaryMarcus,2022-05-23 18:51:56+00:00,https://twitter.com/GaryMarcus/status/1528810981991714816,"@kristintynski @ylecun @JefferyAGoldst1 @tdietterich @miguelisolano imagination is quite relevant. @peterfoldiak had a classic paper about this many years ago, and data augmentation is a modern version of his idea"
4546,@GaryMarcus,2022-05-23 18:50:51+00:00,https://twitter.com/GaryMarcus/status/1528810710058160128,"ü§£. but we really should have another debate. the first, at NYU, was terrific, and I think a second would be enlightening. lots to talk about, and a mutual disdain for certain recent overstated claims to bond over‚Ä¶"
4547,@GaryMarcus,2022-05-23 18:48:02+00:00,https://twitter.com/GaryMarcus/status/1528810000939769857,"@david_stillwell @AndrewKyngdon no, that‚Äôs not really right. essentially GPT uses a fancy version of synonymy to govern a pastische-like process. it really doesn‚Äôt have concepts. (see recent articles at https://t.co/8ir1xKvqt6)"
4548,@GaryMarcus,2022-05-23 18:43:01+00:00,https://twitter.com/GaryMarcus/status/1528808738248720384,"@ylecun @JefferyAGoldst1 @tdietterich @miguelisolano sure, but is all that data necessary?

blind children can form incredibly rich models of the world without any video at all. 

also: DALL-E had 650 million captioned images and still lacks understanding of basic conceptual relations."
4549,@GaryMarcus,2022-05-23 18:30:29+00:00,https://twitter.com/GaryMarcus/status/1528805582567661568,@PMistani @BostonDynamics why not? humans use a vast array of different techniques in the own intelligence; why restrict AI?
4550,@GaryMarcus,2022-05-23 18:29:41+00:00,https://twitter.com/GaryMarcus/status/1528805382906253312,"@ylecun @tdietterich @miguelisolano interesting question, @ylecun, if we had the right algorithms (including learning procedures) and the right data (including priors and background knowledge represented in machine interpretable form) would current hardware suffice? 

my guess is *yes*."
4551,@GaryMarcus,2022-05-23 18:26:06+00:00,https://twitter.com/GaryMarcus/status/1528804481558712320,"@MichaelBatavia @SubstackInc @OpenAI i am way less optimistic that LLMs can really solve thee problems; they are incredibly prone to generating misinformation, and because they lack any real representation of ground truth, they seem like a poor choice for solving those problems"
4552,@GaryMarcus,2022-05-23 13:51:23+00:00,https://twitter.com/GaryMarcus/status/1528735345474277377,"New evidence that deep learning is *still* hitting the wall of compositionality‚Äî35 years after Fodor and Pylyshyn first discussed, two decades after The Algebraic Mind. 

No, @openAi and @NandoDF @DeepMind, AGI is not nigh."
4553,@GaryMarcus,2022-05-23 13:41:24+00:00,https://twitter.com/GaryMarcus/status/1528732833543360512,@JefferyAGoldst1 @ylecun @tdietterich @miguelisolano you can‚Äôt even use that ground truth if you don‚Äôt have the right kind of mind; see old experiment with Nim Chimpsky
4554,@GaryMarcus,2022-05-23 13:38:25+00:00,https://twitter.com/GaryMarcus/status/1528732081785696257,"@ViditGoel7 @ylecun @tdietterich @miguelisolano innateness is indeed critical, but i don‚Äôt think pre-training is leading to rich enough innate priors, eg the quoted passage from @ronbrachman in my Chomsky essay at https://t.co/8ir1xKvqt6"
4555,@GaryMarcus,2022-05-23 13:31:58+00:00,https://twitter.com/GaryMarcus/status/1528730456987815938,"‚ÄúDespite recent advances, our findings challenge the systematicity and productivity of current models. ‚Ä¶generalization capacity and robustness remain a barrier to overcome‚Äù ‚Äî the wall that deep learning and scaling still face."
4556,@GaryMarcus,2022-05-23 13:25:01+00:00,https://twitter.com/GaryMarcus/status/1528728709372424192,"@ylecun @tdietterich @miguelisolano agree w @ylecun that scaling is not sufficient. but would go further and say that scaling is not *logically* necessary: children have a fairly thorough understanding of the world ‚Äîeven without massive data.

scaling is certainly necessary for current approaches, however"
4557,@GaryMarcus,2022-05-23 04:47:03+00:00,https://twitter.com/GaryMarcus/status/1528598358729924608,@rao2z and see https://t.co/ufbxCXwhdl for a related argument
4558,@GaryMarcus,2022-05-23 03:59:29+00:00,https://twitter.com/GaryMarcus/status/1528586390820225026,@EmmetPeppers @ValueDissenter @NaveenGRao be fun to do in tandem w @NaveenGRao. as background please read alt intelligence essay at https://t.co/8ir1xKdPBy
4559,@GaryMarcus,2022-05-23 02:52:51+00:00,https://twitter.com/GaryMarcus/status/1528569621300666369,@NaveenGRao @EmmetPeppers agreed; reasonable question. my guess is: not yet.
4560,@GaryMarcus,2022-05-22 21:25:56+00:00,https://twitter.com/GaryMarcus/status/1528487347779964928,@Ferdous_nayan @BostonDynamics i would argue that dynamics modeling is part of AI
4561,@GaryMarcus,2022-05-22 20:52:40+00:00,https://twitter.com/GaryMarcus/status/1528478975114108933,"@miguelisolano for some tasks. very little progress on truth, coherence,  reasoning etc except under constrained conditions"
4562,@GaryMarcus,2022-05-22 20:31:15+00:00,https://twitter.com/GaryMarcus/status/1528473586654117891,@JohnMeuser @nytimes @CadeMetz @Aiaddict1 @chemsafetyboard the parallel is clear. what is your specific suggestion?
4563,@GaryMarcus,2022-05-22 20:26:04+00:00,https://twitter.com/GaryMarcus/status/1528472281462218755,@JohnMeuser @nytimes @CadeMetz @Aiaddict1 @chemsafetyboard public outcry and media attention
4564,@GaryMarcus,2022-05-22 20:25:28+00:00,https://twitter.com/GaryMarcus/status/1528472133311012864,"@JohnMeuser @nytimes @CadeMetz @Aiaddict1 allowing that FSD Beta might be better‚Äîbut my guess is FSD Beta would fail a lot of what @Aiaddict1 tested. 

government should have trained drivers routinely test outliers as he did (but w medical professionals and trained drivers), for every new release.

no test, no beta."
4565,@GaryMarcus,2022-05-22 20:17:35+00:00,https://twitter.com/GaryMarcus/status/1528470146498576385,"@JohnMeuser @nytimes @CadeMetz @Aiaddict1 we need way stronger govt requirements but since most of the media says that AGI is night the government doesn‚Äôt realize how critical that is, or even what the question is"
4566,@GaryMarcus,2022-05-22 20:16:36+00:00,https://twitter.com/GaryMarcus/status/1528469899424702464,@JohnMeuser @nytimes @CadeMetz @Aiaddict1 they both made some interesting points. we will see If FSD Beta is a magic cure all but i would very strongly bet against it; the more so w Karparthy on leave
4567,@GaryMarcus,2022-05-22 20:11:55+00:00,https://twitter.com/GaryMarcus/status/1528468723757105152,"@HappyAar @nytimes @CadeMetz tesla doesn‚Äôt share much of what we need.

maybe @PeteButtigieg can force change there, starting w requiring intervention data for any car company that implies autonomy w phrases like ‚ÄúAutopilot‚Äù &amp;! requiring full disclosiee for accidents &amp; miles driven in various environments"
4568,@GaryMarcus,2022-05-22 19:59:28+00:00,https://twitter.com/GaryMarcus/status/1528465588980523008,@rfurlan one last tag @CadeMetz :)
4569,@GaryMarcus,2022-05-22 19:59:00+00:00,https://twitter.com/GaryMarcus/status/1528465470881513474,"too bad the media has not fully acknowledged this, which only leaves public and government employees deluded.

@cademetz, please dig deep on the AGI mythology, as you did with @tesla"
4570,@GaryMarcus,2022-05-22 19:57:18+00:00,https://twitter.com/GaryMarcus/status/1528465041917452288,@rfurlan concur. and elaborated here: https://t.co/ufbxCXwhdl
4571,@GaryMarcus,2022-05-22 19:55:57+00:00,https://twitter.com/GaryMarcus/status/1528464703109963777,"former Tesla employee bearing out what @nytimes and @cademetz reported about Tesla and safety, in lengthy thread 

lives are at stake"
4572,@GaryMarcus,2022-05-22 17:18:33+00:00,https://twitter.com/GaryMarcus/status/1528425091410714626,"rare case in which i disagree w @fchollet; i think he is too kind to Sutton‚Äôs Bitter Lesson. 

short version of the counter argument in tweet below, w link to slightly more detail"
4573,@GaryMarcus,2022-05-22 17:17:04+00:00,https://twitter.com/GaryMarcus/status/1528424719338246144,"@fchollet @AvilaGarcez i critiqued sutton‚Äôs bitter lesson, which i see as weak inductive argument, here: 

https://t.co/ufbxCXeFOL

it‚Äôs true of the past, in particular domains; there are many domains still unsolved where big data alone has been ineffective"
4574,@GaryMarcus,2022-05-22 17:11:15+00:00,https://twitter.com/GaryMarcus/status/1528423257430294530,"@moultano it would simply show the IQ test, when applied to nonhumans that can use a different set of resources than humans do, is a less valid measure of intelligence than we anticipated. (it was never great)

psychometric is hard; even harder across species and software architectures"
4575,@GaryMarcus,2022-05-22 00:58:28+00:00,https://twitter.com/GaryMarcus/status/1528178448316997632,"Seals and snowy peaks
British Columbia can‚Äôt be beat https://t.co/PF9HURoJon"
4576,@GaryMarcus,2022-05-21 21:40:34+00:00,https://twitter.com/GaryMarcus/status/1528128644815593473,@KordingLab and see also my essay on Chomsky today at https://t.co/8ir1xKvqt6
4577,@GaryMarcus,2022-05-21 20:33:38+00:00,https://twitter.com/GaryMarcus/status/1528111800235053056,@BrianWandell üíØ
4578,@GaryMarcus,2022-05-21 20:28:29+00:00,https://twitter.com/GaryMarcus/status/1528110502177607680,@R4_Unit oops: https://t.co/6dmkp16w0Q
4579,@GaryMarcus,2022-05-21 20:12:23+00:00,https://twitter.com/GaryMarcus/status/1528106452321292291,@vardi nonsense! for a different perspective: https://t.co/ufbxCXwhdl
4580,@GaryMarcus,2022-05-21 20:05:21+00:00,https://twitter.com/GaryMarcus/status/1528104680298934273,@pavel_soukenik @emshort @ronbrachman
4581,@GaryMarcus,2022-05-21 18:52:12+00:00,https://twitter.com/GaryMarcus/status/1528086274342633474,"this essay is now live, at https://t.co/8ir1xKdPBy"
4582,@GaryMarcus,2022-05-21 18:13:02+00:00,https://twitter.com/GaryMarcus/status/1528076415995850752,"Why Noam Chomsky is not a fan of GPT-3:

https://t.co/5menFc18c0"
4583,@GaryMarcus,2022-05-21 18:11:54+00:00,https://twitter.com/GaryMarcus/status/1528076130497941504,"@MadamePratolung @tangled_zans @xriskology @timnitGebru @Salon Well, together with the *imputed* diminishment of the Holocaust, which is roughly the opposite what Bostrom (who never mentioned the Holocaust per se) intended. 

Screenshot from an email he sent it to me attached; opposite of what Torres implied. https://t.co/xz8DQ4zV32"
4584,@GaryMarcus,2022-05-21 17:49:15+00:00,https://twitter.com/GaryMarcus/status/1528070430015205377,@HiFromMichaelV whereas i think it is time to print it and put it on my refrigerator :)
4585,@GaryMarcus,2022-05-21 17:12:00+00:00,https://twitter.com/GaryMarcus/status/1528061055334637573,"@yzilber hmm that‚Äôs a fair point. but i thought there on that point that T&amp;C pertained to what they share w law enforcement? do you have wording handy?

also, he ain‚Äôt exactly advertising for scrupulous lawyers if you read his whole thread."
4586,@GaryMarcus,2022-05-21 17:01:41+00:00,https://twitter.com/GaryMarcus/status/1528058459404480513,definitely not a good look
4587,@GaryMarcus,2022-05-21 17:01:03+00:00,https://twitter.com/GaryMarcus/status/1528058298657714176,"@yzilber if the company becomes private, all it data can can certainly be used by the management to investigate people; furthermore no public disclosure of how it is used will be required unless (i believe) new laws are written."
4588,@GaryMarcus,2022-05-21 16:09:07+00:00,https://twitter.com/GaryMarcus/status/1528045231966326784,"If you are not scared by the prospect of the world‚Äôs richest man buying Twitter‚Äôs data (including every DM you have ever written) and cranking up a team of hardcore gloves-off lawyers, you are not paying attention."
4589,@GaryMarcus,2022-05-21 16:06:29+00:00,https://twitter.com/GaryMarcus/status/1528044569866055680,"@JulespHamilton soon with unprecedented, warrant-free access!"
4590,@GaryMarcus,2022-05-21 16:01:14+00:00,https://twitter.com/GaryMarcus/status/1528043249104871430,"Will those hardcore Better Call, Saul lawyers be helping themselves to people‚Äôs private DMs, as evidence and as investigative tools?"
4591,@GaryMarcus,2022-05-21 14:54:43+00:00,https://twitter.com/GaryMarcus/status/1528026508496752640,"Coming later today: Noam Chomsky and GPT-3. 

Sign up on https://t.co/8ir1xKvqt6 (free!) if you want to be among the first to read it. (And catch up my essay on Alt Intelligence vs Artificial Intelligence, if you missed it.)"
4592,@GaryMarcus,2022-05-19 22:18:37+00:00,https://twitter.com/GaryMarcus/status/1527413445095612417,"See you in a few days :)

https://t.co/IHkhrSmyHf"
4593,@GaryMarcus,2022-05-19 20:30:47+00:00,https://twitter.com/GaryMarcus/status/1527386304903663632,This workshop on compositionality is going to be awesome. Excited to team up with @raphaelmilliere and our fabulous cast!
4594,@GaryMarcus,2022-05-19 20:06:20+00:00,https://twitter.com/GaryMarcus/status/1527380153453555712,"@tangled_zans @xriskology @timnitGebru @Salon no, the words are wrong, whether retracted or not. 

read for yourself what your source said about what sparrow said, and then read sparrow. 

people make mistakes, intentionally or otherwise. 

the facts here speak for themselves."
4595,@GaryMarcus,2022-05-19 20:04:07+00:00,https://twitter.com/GaryMarcus/status/1527379593165799424,"@tangled_zans @xriskology @timnitGebru @Salon i traced every source, and none said what was ascribed to it"
4596,@GaryMarcus,2022-05-19 20:03:47+00:00,https://twitter.com/GaryMarcus/status/1527379510399619074,"@tangled_zans @xriskology @timnitGebru @Salon If someone says ‚ÄúJohnny said the sky is purple‚Äù but Johnny never in reality said the sky is purple, what source can there be?"
4597,@GaryMarcus,2022-05-19 20:01:31+00:00,https://twitter.com/GaryMarcus/status/1527378940599226371,"@tangled_zans @xriskology @timnitGebru @Salon I searched for all references to Bostrom in all the papers we are discussing and traced their sources to find original quotes, as any professional would."
4598,@GaryMarcus,2022-05-19 20:00:07+00:00,https://twitter.com/GaryMarcus/status/1527378589603090442,"@tangled_zans @timnitGebru I cited facts
- Bostrom did not explicitly reference Holocaust
- Sparrow did not say Bostrom was a eugenicist; support for the claim that he was, in the paper you gave, came from a misrepresentation of Sparrow
- i gave a link to the original work by Sparrow.
urge you to read it."
4599,@GaryMarcus,2022-05-19 19:56:57+00:00,https://twitter.com/GaryMarcus/status/1527377792668553235,"@tangled_zans @xriskology @timnitGebru @Salon did you invent that quote, or did I miss something? is it actually from him? source?"
4600,@GaryMarcus,2022-05-19 19:56:15+00:00,https://twitter.com/GaryMarcus/status/1527377615056556035,"@xriskology @tangled_zans @timnitGebru @Salon That refers to this: https://t.co/CcItUuXXsI 

Where in that paper is any actual endorsement of *eugenics*? 

Some people have apparently *called* Bostrom a eugenicist, but is he? 

Not one of the 4 trails so amounts to anything other than that he is open to cognitive enhancement"
4601,@GaryMarcus,2022-05-19 19:51:28+00:00,https://twitter.com/GaryMarcus/status/1527376411241000967,@tangled_zans @xriskology @timnitGebru @Salon I just did rebut this; the source refers to a paper that says no such thing. Your paper is in error. End of story.
4602,@GaryMarcus,2022-05-19 19:50:24+00:00,https://twitter.com/GaryMarcus/status/1527376142247702563,"@tangled_zans @timnitGebru the paper you pointed to says ‚ÄúIn several works, Bostrom, Harris, and Savulescu admit to being ‚Äúnew‚Äù eugenicists (Sparrow 32)‚Äù 

But Sparrow just *doesn‚Äôt say that*.

Do the facts just not matter?"
4603,@GaryMarcus,2022-05-19 19:46:42+00:00,https://twitter.com/GaryMarcus/status/1527375210600509464,"@tangled_zans @timnitGebru and, worse, that source relies on Sparrow 2011, which is actually primarily about two other people (Harris and Savelscu), not Bostrom, and it never says or implies that Bostrom is a eugenicist. https://t.co/2PrSkynwQi 

i smell an unfair game of telephone, and see no smoking gun."
4604,@GaryMarcus,2022-05-19 19:41:13+00:00,https://twitter.com/GaryMarcus/status/1527373833291739144,"@tangled_zans @timnitGebru the source doesn‚Äôt give any quotes *from Bostrom* that actually say that. and it seems to conflate posthumanism (which could eg involving giving *everyone* memory enhancement chips) with eugenics (which would selectively weed out individuals).

1/2"
4605,@GaryMarcus,2022-05-19 18:59:25+00:00,https://twitter.com/GaryMarcus/status/1527363313306218508,"@xriskology @tangled_zans @timnitGebru @Salon this is Bostrom? isn‚Äôt he saying ‚Äúnone of that stuff matters at all for the larger argument I am making‚Äù? i think you are misreading him, unless i am missing something."
4606,@GaryMarcus,2022-05-19 18:53:01+00:00,https://twitter.com/GaryMarcus/status/1527361701066092550,@xriskology @tangled_zans @timnitGebru @Salon please send full sources
4607,@GaryMarcus,2022-05-19 18:49:28+00:00,https://twitter.com/GaryMarcus/status/1527360809344503823,"@xriskology @tangled_zans @timnitGebru @Salon it‚Äôs misrepresenting how he made the point and conflating your inference with what he said, using the most tendentious example possible. 

it just paints thing differently when it would have been so easy to be clear, and still make your point, without implying he was pro eugenics"
4608,@GaryMarcus,2022-05-19 18:43:06+00:00,https://twitter.com/GaryMarcus/status/1527359206898094089,"@xriskology @tangled_zans @timnitGebru @Salon he (literally) gave 16 examples; you chose one, ignored the other 15, and played games with the other.

that is not cricket."
4609,@GaryMarcus,2022-05-19 18:40:09+00:00,https://twitter.com/GaryMarcus/status/1527358463994580998,"@xriskology @tangled_zans @timnitGebru @Salon you should have said ‚Äúhis argument could be extended to the Holocaust‚Äù, making it clear that he himself did not do so. 

but you chose not to, apparently because you wanted to paint him in a particularly dark way.

others then took what you said to be a quote when it wasn‚Äôt."
4610,@GaryMarcus,2022-05-19 18:37:21+00:00,https://twitter.com/GaryMarcus/status/1527357758449733634,"@xriskology @tangled_zans @timnitGebru @Salon yes, by extension literally everything that is ever happened to humanity. but he (apparently deliberately) did not mention the Holocaust.

you misled your readers by abbreviating the argument and putting words in his mouth.

1/2"
4611,@GaryMarcus,2022-05-19 18:33:26+00:00,https://twitter.com/GaryMarcus/status/1527356773828481024,üôÑüôÑ (&amp; why i wrote: https://t.co/ufbxCXeFOL)
4612,@GaryMarcus,2022-05-19 17:31:56+00:00,https://twitter.com/GaryMarcus/status/1527341298591490048,"@tangled_zans @timnitGebru .@xriskology in  your @salon piece you imply that Bostrom explicitly ""includ[es]"" the Holocaust in the passage you quote when it did not in fact say that. 

yours below; actual quote above https://t.co/8gUHKHtSue"
4613,@GaryMarcus,2022-05-19 17:13:16+00:00,https://twitter.com/GaryMarcus/status/1527336599817576458,"@RWerpachowski @tangled_zans @timnitGebru I am really troubled by the word ""including"", here, when the Holocaust was not included in the actual quote. https://t.co/glld9nJ8AF"
4614,@GaryMarcus,2022-05-19 17:10:27+00:00,https://twitter.com/GaryMarcus/status/1527335889835155472,"@tangled_zans @timnitGebru another place where Gebru is more explicit, and also seems to misrepresent the same passage: https://t.co/glld9nJ8AF"
4615,@GaryMarcus,2022-05-19 16:57:08+00:00,https://twitter.com/GaryMarcus/status/1527332538498179079,"@adriancjr @notnaughtknot @timnitGebru i think there are lots of scenarios, some random, some not, many hard to anticipate (eg full-on nuclear war)."
4616,@GaryMarcus,2022-05-19 16:33:31+00:00,https://twitter.com/GaryMarcus/status/1527326594875809795,"@benbendc @SashaMTL Here's what @ErnestSDavis and I wrote in https://t.co/Pt7HZbLIv5, 6 questions for addressing AI hype, somewhat similar to what @emilymbender was pointing to in her op-ed. https://t.co/yV6moLMKcR"
4617,@GaryMarcus,2022-05-19 16:09:09+00:00,https://twitter.com/GaryMarcus/status/1527320465571647489,@benbendc @SashaMTL We make six specific recommendations in the first chapter of https://t.co/Pt7HZbLIv5. I will dig them up‚Ä¶
4618,@GaryMarcus,2022-05-19 15:56:06+00:00,https://twitter.com/GaryMarcus/status/1527317178982141953,"@tangled_zans @jasonintrator @TimothyDSnyder @timnitGebru respectfully, the ripple paraphrase (which I think you may have gotten secondhand from Torres) distorts Bostrom‚Äôs intent. If there are other quotes that support your interpretation of him, I would like to see them. The one you supplied does not."
4619,@GaryMarcus,2022-05-19 15:49:36+00:00,https://twitter.com/GaryMarcus/status/1527315544545763328,"@tangled_zans @jasonintrator @TimothyDSnyder but it seems to me like we just saw two examples in 30 minutes of her putting same kind of language in people‚Äôs mouths. that‚Äôs just not ok. Bostrom just didn‚Äôt (at least in the source I see) say what she says he said, and nor did Hilton."
4620,@GaryMarcus,2022-05-19 15:47:20+00:00,https://twitter.com/GaryMarcus/status/1527314975638728710,"@tangled_zans @timnitGebru i barely know him (on a panel together twice?), but am worried both by fascism and McCarthyism, and by mob mentality, in both directions. 

And feel for people who are misrepresented by loud voices, without due process."
4621,@GaryMarcus,2022-05-19 15:44:58+00:00,https://twitter.com/GaryMarcus/status/1527314376423641088,"@tangled_zans I have no problem calling people who advocate authoritarian policies fascists. That‚Äôs why I follow people like @jasonintrator and @TimothyDSnyder

I just don‚Äôt think that that a rational (if flawed) analysis of which problems to prioritize qualifies."
4622,@GaryMarcus,2022-05-19 15:42:52+00:00,https://twitter.com/GaryMarcus/status/1527313849572937728,"@tangled_zans @timnitGebru so is the time for calling people Nazi‚Äôs that aren‚Äôt. 

If the revolution is a new McCarthyism, I‚Äôm out."
4623,@GaryMarcus,2022-05-19 15:41:40+00:00,https://twitter.com/GaryMarcus/status/1527313549487263746,"@tangled_zans @timnitGebru It‚Äôs actually worse than I said.

@timnitgebru implies Bostrom dismissed the Holocaust, invoking a phrase re ‚Äúripples on the great sea of life‚Äù. I tracked down the source through a Torres paper. 

The original *doesn‚Äôt mention* the Holocaust. The retelling is miles from original: https://t.co/5E6Klxx0tO"
4624,@GaryMarcus,2022-05-19 15:27:46+00:00,https://twitter.com/GaryMarcus/status/1527310050015911937,"@tangled_zans @timnitGebru I am not here to defend EA as a whole, and certainly not eugenics even in part. 

i do think it is legit to weigh arguments about what we should prioritize. 

without calling each other Nazis."
4625,@GaryMarcus,2022-05-19 15:23:26+00:00,https://twitter.com/GaryMarcus/status/1527308958767058944,"@tangled_zans @timnitGebru fair enough, but even 19 minutes ago I see this, which elides a quote &amp; makes it sound like it was advocating eugenics when the original quote was broader and making a general point about existential vs nonexistential risk, rather than advocating genocide: https://t.co/qkpGKZOBgw"
4626,@GaryMarcus,2022-05-19 15:12:51+00:00,https://twitter.com/GaryMarcus/status/1527306297363730433,"@kausch @timnitGebru Neither you nor @timnitGebru has (at least here) actually made the argument that they inevitably amount to the same thing. 

As far as I can tell, advocates of this view weigh all lives, present and future, equally, &amp; are trying to save maximum of lives. (w problems I note above)"
4627,@GaryMarcus,2022-05-19 15:01:44+00:00,https://twitter.com/GaryMarcus/status/1527303499544788997,@timnitGebru Not fair.
4628,@GaryMarcus,2022-05-19 14:57:58+00:00,https://twitter.com/GaryMarcus/status/1527302551896412163,"‚Ä¢ argument assumes tiny chance of saving all of humanity outweighs potentially larger chances of great harm to large parts of humanity, potentially distributed inequitably
‚Ä¢ policy should not be indifferent to massive suffering nor unequal harm"
4629,@GaryMarcus,2022-05-19 14:57:58+00:00,https://twitter.com/GaryMarcus/status/1527302549367185408,"Please, @timnitGebru, you can‚Äôt go around calling everything you disagree with eugenics.

Nothing in the thread you attack is about selection or said with intent to try to create ‚Äúsuperior‚Äù human beings. 

Better IMHO to challenge its logic and assumptions instead:"
4630,@GaryMarcus,2022-05-19 13:26:37+00:00,https://twitter.com/GaryMarcus/status/1527279560579985410,"back in fashion: 2013 @newyorker essay that is still relevant. 

the names have changed; hype, not so much."
4631,@GaryMarcus,2022-05-19 02:40:20+00:00,https://twitter.com/GaryMarcus/status/1527116917017673729,"Please remember that you said that, the next time I offer constructive criticism."
4632,@GaryMarcus,2022-05-19 02:01:27+00:00,https://twitter.com/GaryMarcus/status/1527107134948708352,@qmihau @rajiinio ü§£ü§£üôÑüò¢
4633,@GaryMarcus,2022-05-19 01:40:37+00:00,https://twitter.com/GaryMarcus/status/1527101890562883584,"üî•: ‚ÄúBecause they are completely controlling what they are sharing, it‚Äôs only possible to get a skewed understanding of how the system works‚Äù - @rajiinio‚Å© on Google.

Much the same could be said for most of big tech‚Äôs recent hype-infused AI rollouts. https://t.co/2upmSnCcze"
4634,@GaryMarcus,2022-05-19 00:46:51+00:00,https://twitter.com/GaryMarcus/status/1527088359293612032,Also apparently said without irony
4635,@GaryMarcus,2022-05-18 23:58:37+00:00,https://twitter.com/GaryMarcus/status/1527076221267300352,"@Drokeby @Grady_Booch neither GPT-3 nor ELIZA develops a rich representation over time of its interlocutor; each pretends to know more than it does. 

both can give psychiatric advice; neither can do so in a trustworthy way.

the underlying mechanisms differ; the results are similar."
4636,@GaryMarcus,2022-05-18 21:28:27+00:00,https://twitter.com/GaryMarcus/status/1527038431284502528,"@SashaMTL or 2012, and see mention of Rosenblatt therein, 1957, https://t.co/VJO8RZZQEj and the gushing ‚ÄúPerceptron,  .. remarkable machine‚Ä¶capable of what amounts to thought.‚Äù"
4637,@GaryMarcus,2022-05-18 21:24:11+00:00,https://twitter.com/GaryMarcus/status/1527037355940384768,@SashaMTL hardly at all :(
4638,@GaryMarcus,2022-05-18 21:22:01+00:00,https://twitter.com/GaryMarcus/status/1527036810479607810,@SashaMTL and much earlier but also apropos: https://t.co/I3CMMvvO2p
4639,@GaryMarcus,2022-05-18 21:20:13+00:00,https://twitter.com/GaryMarcus/status/1527036360309489669,"@SashaMTL @emilymbender @mmitchell_ai @timnitGebru see also the first chapter of Rebooting AI, which makes a very similar point with a similar example."
4640,@GaryMarcus,2022-05-18 20:11:19+00:00,https://twitter.com/GaryMarcus/status/1527019017629642752,"agree with this. but just as we need to know if the submarine might sink, we need to know whether the AI will drown when it encounters edge cases."
4641,@GaryMarcus,2022-05-18 20:07:38+00:00,https://twitter.com/GaryMarcus/status/1527018092936581120,"@jasonintrator maybe not, if you would just pay the breakup fee"
4642,@GaryMarcus,2022-05-18 18:35:23+00:00,https://twitter.com/GaryMarcus/status/1526994877837287424,"‚Äú40 percent of consumers believed names like ""Autopilot"" indicated the vehicle was capable of fully autonomous driving.‚Äù but 100% of systems tested don‚Äôt warrant such names."
4643,@GaryMarcus,2022-05-18 17:05:32+00:00,https://twitter.com/GaryMarcus/status/1526972266558259200,@kareem_carr current AI is way too dumb to be trusted with something like that.
4644,@GaryMarcus,2022-05-18 16:38:44+00:00,https://twitter.com/GaryMarcus/status/1526965522415226880,"@robreich @percyliang @KathleenACreel @RishiBommasani it‚Äôs also a recipe for a replicability crisis, similar to other fields have seen. I highly recommend Joelle Pineau‚Äôs Replicability Checklist as a model."
4645,@GaryMarcus,2022-05-18 16:37:07+00:00,https://twitter.com/GaryMarcus/status/1526965114926030848,"@robreich @percyliang @KathleenACreel @RishiBommasani as long as the developer can arbitrarily refuse legitimate researchers access, we will continue to have a world driven by hype rather than science. 

i don‚Äôt think your proposal does enough to address that critical issue."
4646,@GaryMarcus,2022-05-18 16:27:22+00:00,https://twitter.com/GaryMarcus/status/1526962659072962560,@AVMiceliBarone @FelixHill84 not yet.
4647,@GaryMarcus,2022-05-18 14:02:29+00:00,https://twitter.com/GaryMarcus/status/1526926199401762816,"what priors should we start with? a possible sample from @ronbrachman‚Äôs new book in the image below, and see my book The Birth of the Mind for discussion about how genome can underwrite priors: https://t.co/G2Lk6Z1wv2"
4648,@GaryMarcus,2022-05-18 13:23:25+00:00,https://twitter.com/GaryMarcus/status/1526916368100036608,@ibreznik @trevorandersen @Aella_Girl @HabbaHill probably not existential but potentially very serious and quite plausible
4649,@GaryMarcus,2022-05-18 13:10:35+00:00,https://twitter.com/GaryMarcus/status/1526913136426553347,"@asusarla perhaps an hour late, tho?"
4650,@GaryMarcus,2022-05-18 13:09:05+00:00,https://twitter.com/GaryMarcus/status/1526912761111883776,"@ibreznik @trevorandersen @Aella_Girl @HabbaHill i think you underestimate the threat of chaotic, cognitively imperfect AI given too much power."
4651,@GaryMarcus,2022-05-18 13:06:12+00:00,https://twitter.com/GaryMarcus/status/1526912034964508672,apparently said without irony
4652,@GaryMarcus,2022-05-18 12:28:33+00:00,https://twitter.com/GaryMarcus/status/1526902560220585984,@alexkyllo @KerryLVaughan @David_desJ hence my pinned tweet. and see fab analysis by @Abebab
4653,@GaryMarcus,2022-05-18 12:06:19+00:00,https://twitter.com/GaryMarcus/status/1526896965501349890,like AI
4654,@GaryMarcus,2022-05-18 04:19:09+00:00,https://twitter.com/GaryMarcus/status/1526779400447963136,"@David_desJ now that i can agree with. my point is that the operational safety region for GPT-3 etc is basically nil, but that many people don‚Äôt understand its limitations and hence are going to be tempted to apply it to domains where it does not belong.

that is precisely what frightens me."
4655,@GaryMarcus,2022-05-18 04:17:30+00:00,https://twitter.com/GaryMarcus/status/1526778982993108992,"@David_desJ um, where did you say that? I see ‚ÄúMy impression is that Waymo's systems are already comparable in safety to human drivers and can easily improve by another couple of orders of magnitude‚Äù, no hedge for geo-fenced location."
4656,@GaryMarcus,2022-05-18 04:13:04+00:00,https://twitter.com/GaryMarcus/status/1526777867920584704,@David_desJ in the limit. but we are a long long way from there.
4657,@GaryMarcus,2022-05-18 04:12:43+00:00,https://twitter.com/GaryMarcus/status/1526777779651420160,"@David_desJ AFAIK, Waymo relies on carefully selected, heavily mapped roads and pretty decent weather, in part to deliberately reduce the outlier problem. Your impression is incorrect."
4658,@GaryMarcus,2022-05-18 04:08:51+00:00,https://twitter.com/GaryMarcus/status/1526776806501543936,"@Aella_Girl It is delusional to think that large language models can solve the alignment problem by having ethical, aligned machines ‚Äúemerge‚Äù from large data.  they can barely induce three digit addition.

to extent people genuinely care about alignment, we need to consider other solutions."
4659,@GaryMarcus,2022-05-18 04:05:00+00:00,https://twitter.com/GaryMarcus/status/1526775836992344064,"@David_desJ hasn‚Äôt worked with driving, empirically"
4660,@GaryMarcus,2022-05-18 04:04:42+00:00,https://twitter.com/GaryMarcus/status/1526775763562684417,"@David_desJ even so, in driving people are still (currently) better at noncanonical situations.

of course there are lots of narrow cases where carefully engineered machines exceed people. 

randomly throwing LLMs at arbitrary problems ‚â† good engineering"
4661,@GaryMarcus,2022-05-18 04:02:08+00:00,https://twitter.com/GaryMarcus/status/1526775115916054529,"@tdietterich @ESYudkowsky already happening, and double plus ungood"
4662,@GaryMarcus,2022-05-18 04:01:46+00:00,https://twitter.com/GaryMarcus/status/1526775024299847681,"@David_desJ yep, lots of problems with humans, likely compounded by LLM-generated misinformation"
4663,@GaryMarcus,2022-05-18 04:01:02+00:00,https://twitter.com/GaryMarcus/status/1526774839125475328,"@David_desJ far more confident in two highly trained, carefully selected military officers than a giant statistical correlation machine w unknown training set that is highly subject to distribution shift problems.

same for driving; for now (not forever) advantage in outliers goes to humans."
4664,@GaryMarcus,2022-05-18 03:58:05+00:00,https://twitter.com/GaryMarcus/status/1526774095362240513,@David_desJ not literally impossible but highly unlikely
4665,@GaryMarcus,2022-05-18 03:56:42+00:00,https://twitter.com/GaryMarcus/status/1526773749323661313,"@David_desJ OpenAI has made concerted effort to make its work sounds like it is approaching AGI (‚Äúslightly conscious‚Äù; ‚ÄúAGI is gonna be wild‚Äù, ‚ÄúMoore‚Äôs Law‚Äù, etc) in ways that confuse media &amp; hence public. 

There is active work to apply it as broadly as possible.  

This has risk involved."
4666,@GaryMarcus,2022-05-18 03:53:40+00:00,https://twitter.com/GaryMarcus/status/1526772987491323904,@KerryLVaughan @David_desJ that‚Äôs probably way harder to solve than AGI
4667,@GaryMarcus,2022-05-18 03:51:59+00:00,https://twitter.com/GaryMarcus/status/1526772561282969600,"@David_desJ this is exactly the thing I am concerned about. since you see that too, it‚Äôs possible I misunderstood what you are saying."
4668,@GaryMarcus,2022-05-18 03:51:17+00:00,https://twitter.com/GaryMarcus/status/1526772387017920517,@Pehdrew_ agreed
4669,@GaryMarcus,2022-05-18 03:50:34+00:00,https://twitter.com/GaryMarcus/status/1526772207505928192,@David_desJ @KerryLVaughan you said you think he doesn‚Äôt believe what he said. or maybe i misread you?
4670,@GaryMarcus,2022-05-18 03:49:59+00:00,https://twitter.com/GaryMarcus/status/1526772057001758720,"@Pehdrew_ what‚Äôs not possible, and why?"
4671,@GaryMarcus,2022-05-18 03:48:50+00:00,https://twitter.com/GaryMarcus/status/1526771767267631104,"@David_desJ powerful can mean ‚Äúdoes a lot of computation‚Äù or ‚Äúis efficacious‚Äù

GPT-3 is not *smart* but has (without any sort of intention) deluded many humans into thinking it is a more effective thinker than it actually is, and hence may be placed in (unwarranted) efficacious positions."
4672,@GaryMarcus,2022-05-18 03:46:13+00:00,https://twitter.com/GaryMarcus/status/1526771110112423936,"@David_desJ @KerryLVaughan why did you think he was misrepresenting himself? he certainly seems to me to believe that which you think he isn‚Äôt saying, based on what I can observe."
4673,@GaryMarcus,2022-05-18 03:45:17+00:00,https://twitter.com/GaryMarcus/status/1526770874803576832,@Pehdrew_ what‚Äôs to stop some startup from trying that?
4674,@GaryMarcus,2022-05-18 03:44:31+00:00,https://twitter.com/GaryMarcus/status/1526770685040656384,@JohnMeuser i am not even sure i see ‚Äúunlikely to‚Äù tbh given current trends
4675,@GaryMarcus,2022-05-18 03:40:42+00:00,https://twitter.com/GaryMarcus/status/1526769720677965826,"I think @ESYudkowsky might reasonably argue that my scenarios aren‚Äôt existential, but they are certainly potentially destructive.

And plausible. 

Maybe even imminent, given current trends."
4676,@GaryMarcus,2022-05-18 03:38:24+00:00,https://twitter.com/GaryMarcus/status/1526769145118765056,"@ntraft @ylecun I will continue to call them like I see them, agreeing with what I think is correct, disagreeing with what does not seem correct, and probing for deeper answers where I think they could help."
4677,@GaryMarcus,2022-05-18 03:32:17+00:00,https://twitter.com/GaryMarcus/status/1526767606031560704,"@David_desJ @KerryLVaughan why would that not be possible, and how can you be so sure what @KerryLVaughan is thinking? I certainly am thinking what you think he can‚Äôt be thinking."
4678,@GaryMarcus,2022-05-18 03:31:10+00:00,https://twitter.com/GaryMarcus/status/1526767323205447680,"@David_desJ @KerryLVaughan I don‚Äôt think they can build AGI this way. But I do think they can build unreliable AI this way that is potentially dangerous.  And I think @kerryLVaughan is correct to be concerned. I plan to write about this, myself, soon."
4679,@GaryMarcus,2022-05-18 02:12:50+00:00,https://twitter.com/GaryMarcus/status/1526747611197108225,"@Plinz @schulzb589 @IntuitMachine i dunno, sounds like i will be buying, and we will be drinking in Vancouver, peeking across the border, wondering what happens next, and how soon."
4680,@GaryMarcus,2022-05-18 01:41:26+00:00,https://twitter.com/GaryMarcus/status/1526739706959958016,"agree with @ylecun on nearly all of this thread.

Two things I would stress that he does not are:

üëâthe need for richer priors about the structure of the world 

üëâthe value in leveraging existing symbolic knowledge (eg unstructured text from the web)"
4681,@GaryMarcus,2022-05-17 22:43:11+00:00,https://twitter.com/GaryMarcus/status/1526694849088434176,@Grady_Booch @Plinz Indeed. I actually dissected a GPT-3 pastische of me yesterday elsewhere on Twitter; it was partly incoherent and lacked the recent analysis of results and politics that characterize my actual essays.
4682,@GaryMarcus,2022-05-17 22:39:48+00:00,https://twitter.com/GaryMarcus/status/1526693998705971200,"Are there any current AI systems that truly understand these things? 

Are there any normal children or adults that don‚Äôt?

Could you really have an AGI without them?

[From @ronbrachman and Hector Levesque‚Äôs new @mitpress book ‚ÄúMachines Like Us: Toward AI with Common Sense‚Äù] https://t.co/3jtX10DU7g"
4683,@GaryMarcus,2022-05-17 22:20:41+00:00,https://twitter.com/GaryMarcus/status/1526689188074074112,@jordiae It‚Äôs from @kate_m_collins @MITCoCoSci et al.: https://t.co/tv9BB1Wynq
4684,@GaryMarcus,2022-05-17 22:08:25+00:00,https://twitter.com/GaryMarcus/status/1526686100252553216,"Guess which gets more media attention?

A: ‚ÄúWe find this model shows more robust adaptation to out-of-distribution planning problems, demonstrating the promise of hybrid AI models for more human-like reasoning.‚Äù 
or
B ‚ÄúThe Game is Over. AGI is nigh‚Äù

No wonder public is clueless."
4685,@GaryMarcus,2022-05-17 21:56:36+00:00,https://twitter.com/GaryMarcus/status/1526683127166271488,@IainLJBrown https://t.co/9u0ur0aDZw
4686,@GaryMarcus,2022-05-17 21:56:09+00:00,https://twitter.com/GaryMarcus/status/1526683012213051392,üôÑ
4687,@GaryMarcus,2022-05-17 21:54:57+00:00,https://twitter.com/GaryMarcus/status/1526682710487363584,@mpshanahan maybe I won‚Äôt have to recalibrate :)
4688,@GaryMarcus,2022-05-17 20:40:19+00:00,https://twitter.com/GaryMarcus/status/1526663928377495552,@mpshanahan or describing blocks world type scenarios with actions that have consequences?
4689,@GaryMarcus,2022-05-17 20:38:25+00:00,https://twitter.com/GaryMarcus/status/1526663450935582721,@TShevlane did they run NarrativeQA?
4690,@GaryMarcus,2022-05-17 20:36:04+00:00,https://twitter.com/GaryMarcus/status/1526662859354259458,@mpshanahan have you tried transitive inference? any sort of constrain-satisfaction problem? how far can you push it?
4691,@GaryMarcus,2022-05-17 20:32:48+00:00,https://twitter.com/GaryMarcus/status/1526662035873882116,"@mpshanahan i think i would like to try it, and to understand how it works"
4692,@GaryMarcus,2022-05-17 20:23:18+00:00,https://twitter.com/GaryMarcus/status/1526659647926464512,@TShevlane how does it work? is it replicable? can i try? it‚Äôs very interesting.
4693,@GaryMarcus,2022-05-17 18:15:27+00:00,https://twitter.com/GaryMarcus/status/1526627473269530624,"maybe my next Substack should be called Unfinished Dialogs, questions posed but not answered. 

or 5 Questions the Deep Learning Community Doesn‚Äôt Want to Answer"
4694,@GaryMarcus,2022-05-17 17:34:20+00:00,https://twitter.com/GaryMarcus/status/1526617125170737152,"this is what is wrong with the field. 

you try to push people into substantive discussion (eg what does AGI consist of?) and they retreat into wisecracks (or disappear altogether)."
4695,@GaryMarcus,2022-05-17 17:20:51+00:00,https://twitter.com/GaryMarcus/status/1526613733375586310,@MadamePratolung @Plinz if *that* is AGI üôÑ
4696,@GaryMarcus,2022-05-17 17:08:20+00:00,https://twitter.com/GaryMarcus/status/1526610583352582144,@Plinz just a half joke? and no effort to definite your terms? not going to stand behind your words?
4697,@GaryMarcus,2022-05-17 16:53:36+00:00,https://twitter.com/GaryMarcus/status/1526606875071901697,@gregd_nlp @sir_deenicus @AlexGDimakis @katie_m_collins @egrefen @TomasKocisky
4698,@GaryMarcus,2022-05-17 16:50:19+00:00,https://twitter.com/GaryMarcus/status/1526606048513036289,"@gregd_nlp @sir_deenicus @AlexGDimakis @katie_m_collins !!! is there a current update on that? it is very much like the 2914 comprehension challenge i proposed and am working to implement 

cc: @egrefen 

https://t.co/4KLe1bU1YY"
4699,@GaryMarcus,2022-05-17 16:30:32+00:00,https://twitter.com/GaryMarcus/status/1526601068255191041,"@worldisall @IntuitMachine @8gene @AVMiceliBarone @FelixHill84 @PsychScientists which ones other than maybe Bengio *have* welcomed cognitive science? and even Bengio talks about compositionality without the least notice of the use of that term in linguistics. 

hassabis has cognitive scientists on staff, to his credit."
4700,@GaryMarcus,2022-05-17 16:10:33+00:00,https://twitter.com/GaryMarcus/status/1526596040907890688,@gregd_nlp @sir_deenicus @AlexGDimakis @katie_m_collins but how you would you know you had such a hole?
4701,@GaryMarcus,2022-05-17 16:03:35+00:00,https://twitter.com/GaryMarcus/status/1526594286438928386,"@MadamePratolung @Plinz or define them, definitively :)"
4702,@GaryMarcus,2022-05-17 16:02:41+00:00,https://twitter.com/GaryMarcus/status/1526594062123663360,@MadamePratolung @Plinz perhaps @plinz you can definite your terms?
4703,@GaryMarcus,2022-05-17 16:01:40+00:00,https://twitter.com/GaryMarcus/status/1526593806967066624,"@SuryaGanguli @Zergylord @NandoDF @AlexGDimakis fine line between satire and reality these days, dr strangelove"
4704,@GaryMarcus,2022-05-17 15:56:51+00:00,https://twitter.com/GaryMarcus/status/1526592591369621505,"care to bet, @plinz?"
4705,@GaryMarcus,2022-05-17 15:47:46+00:00,https://twitter.com/GaryMarcus/status/1526590307508244480,@gregd_nlp @sir_deenicus @AlexGDimakis @katie_m_collins what evidence if any would convince you otherwise?
4706,@GaryMarcus,2022-05-17 15:28:32+00:00,https://twitter.com/GaryMarcus/status/1526585467050659840,swap that *bot* (which pretend to be a boy)
4707,@GaryMarcus,2022-05-17 15:28:04+00:00,https://twitter.com/GaryMarcus/status/1526585347777253376,@TorrentTiago @8gene @IntuitMachine @AVMiceliBarone @FelixHill84 @PsychScientists https://t.co/SdbEolfoJP
4708,@GaryMarcus,2022-05-17 15:26:42+00:00,https://twitter.com/GaryMarcus/status/1526585003877863424,"8 years ago, it looked like an AI chatbot had almost cracked the Turing Test. Was that a sign of a real progress?

Swap that boy, Eugene Goostman, for GPT, and reconsider this essay. How much has changed?

https://t.co/1N4qeEE9wH"
4709,@GaryMarcus,2022-05-17 15:24:26+00:00,https://twitter.com/GaryMarcus/status/1526584436317335553,"@raphaelmilliere @AlexGDimakis @NandoDF eugene goostman might have been able to do that. so what?

https://t.co/1N4qeEE9wH"
4710,@GaryMarcus,2022-05-17 15:23:18+00:00,https://twitter.com/GaryMarcus/status/1526584149254934528,@IntuitMachine @8gene @AVMiceliBarone @FelixHill84 @PsychScientists again see @katie_m_collins; gpt-3 by itself has trouble using that ‚Äúknowledge‚Äù for planning and explanation. regurgitate is not actionable by itself.
4711,@GaryMarcus,2022-05-17 15:17:32+00:00,https://twitter.com/GaryMarcus/status/1526582698763902978,@IntuitMachine @8gene @AVMiceliBarone @FelixHill84 @PsychScientists but can it use all that eg in service of planning? see benchmark from @katie_m_collins et al. that i shared yesterday.
4712,@GaryMarcus,2022-05-17 15:16:03+00:00,https://twitter.com/GaryMarcus/status/1526582325668024320,"@raphaelmilliere @AlexGDimakis @NandoDF it‚Äôs just not a valid test, because of human gullibility."
4713,@GaryMarcus,2022-05-17 15:15:21+00:00,https://twitter.com/GaryMarcus/status/1526582149444276224,"@IntuitMachine @8gene @AVMiceliBarone @FelixHill84 @PsychScientists basic building block,
per argument of Algebraic Mind"
4714,@GaryMarcus,2022-05-17 15:13:55+00:00,https://twitter.com/GaryMarcus/status/1526581787169726464,"@IntuitMachine @8gene @AVMiceliBarone @FelixHill84 @PsychScientists evidently more of the same, per https://t.co/ufbxCXeFOL"
4715,@GaryMarcus,2022-05-17 15:12:18+00:00,https://twitter.com/GaryMarcus/status/1526581382545190912,Bingo! this is exactly why scaling alone is not going to be enough.
4716,@GaryMarcus,2022-05-17 14:50:35+00:00,https://twitter.com/GaryMarcus/status/1526575915802603521,"@IntuitMachine @8gene @AVMiceliBarone @FelixHill84 no, it recognizes talk about affordances. it doesn‚Äôt really understand affordances. @PsychScientists"
4717,@GaryMarcus,2022-05-17 14:25:05+00:00,https://twitter.com/GaryMarcus/status/1526569496911089665,"@AVMiceliBarone @jordiae and fine for him to try to achieve that differentiability, though @sir_deenicus wouldn‚Äôt buy it‚Ä¶"
4718,@GaryMarcus,2022-05-17 14:24:41+00:00,https://twitter.com/GaryMarcus/status/1526569398365921280,"@AVMiceliBarone @jordiae he didn‚Äôt at our 2019 debate, FWIW. super if he would now!"
4719,@GaryMarcus,2022-05-17 14:24:11+00:00,https://twitter.com/GaryMarcus/status/1526569270598987778,"@raphaelmilliere @NandoDF @AlexGDimakis in fairness @AlexGDimakis softened (or restated) his claim in our conversation last night, to (roughly) ‚ÄúI hope scaling isn‚Äôt true, but if I squint I could imagine it to be true‚Äù. i hope I talked him out of even that :)"
4720,@GaryMarcus,2022-05-17 14:22:45+00:00,https://twitter.com/GaryMarcus/status/1526568909934981121,"Another excellent @raphaelmilliere thread, this on what I recently called ‚Äúscaling-√ºber-alles‚Äù"
4721,@GaryMarcus,2022-05-17 14:11:23+00:00,https://twitter.com/GaryMarcus/status/1526566052619964416,"@sir_deenicus @AlexGDimakis @gregd_nlp @katie_m_collins I am waiting on precisely that update, @gregd_nlp"
4722,@GaryMarcus,2022-05-17 14:10:44+00:00,https://twitter.com/GaryMarcus/status/1526565886831644673,"@AVMiceliBarone @FelixHill84 I think pure deep learning so defined will fail at Comprehension Challenge, proposed here: https://t.co/1N4qeEE9wH and developed a bit further here: https://t.co/10JQeMpxP8. 

Working w some folks to try to implement for real."
4723,@GaryMarcus,2022-05-17 14:05:16+00:00,https://twitter.com/GaryMarcus/status/1526564513457139712,"@AlexGDimakis @scychan_brains @Zergylord @NandoDF yes, that‚Äôs why I used a trivial example in Algebraic Mind: to make the intution clear, when it‚Äôs actually hard to measure in the wild. 

real advances might conceivably be made there, but it is architecture dependent (which is part of what @scychan_brains‚Äôs work reflects)"
4724,@GaryMarcus,2022-05-17 14:02:21+00:00,https://twitter.com/GaryMarcus/status/1526563776027250688,"@ibreznik @ilyasut @ylecun a topic for a near-future substack post, i think."
4725,@GaryMarcus,2022-05-17 13:58:13+00:00,https://twitter.com/GaryMarcus/status/1526562737475575809,@scychan_brains @Zergylord @NandoDF @AlexGDimakis but also a semantics-syntax/meaning-form relationship.
4726,@GaryMarcus,2022-05-17 13:57:29+00:00,https://twitter.com/GaryMarcus/status/1526562552271863808,"@jordiae see my dialog with Bengio on Medium; you can call *anything* deep learning, if you like. there‚Äôs zero consensus on what would be excluded."
4727,@GaryMarcus,2022-05-17 13:55:32+00:00,https://twitter.com/GaryMarcus/status/1526562060695261184,"@AVMiceliBarone @FelixHill84 only if we can scope ‚Äúexisting architectures‚Äù; some (most not) actually incorporate external memory in ways that approximate or implement operations over variables, and those are very different from the rest."
4728,@GaryMarcus,2022-05-17 13:54:00+00:00,https://twitter.com/GaryMarcus/status/1526561676459249664,"@scychan_brains @Zergylord @NandoDF @AlexGDimakis Ps. a key point in The Algebraic Mind was to show that the nets that were popular then were *too* sensitive to distributions of data, eg failure to generalize identity to odd numbers if the data happen to even numbers. A lot of stuff about that in Chapter 3."
4729,@GaryMarcus,2022-05-17 13:52:47+00:00,https://twitter.com/GaryMarcus/status/1526561371747328007,"@scychan_brains @Zergylord @NandoDF @AlexGDimakis Really interesting thing about human cognition is how varied the distributions can be and still yield good results. This is especially true for human language, which is learned pretty robustly across a wide range of input."
4730,@GaryMarcus,2022-05-17 13:43:17+00:00,https://twitter.com/GaryMarcus/status/1526558980637569024,"@AVMiceliBarone @FelixHill84 predictions: whenever AGI comes:

üëâlarge-scale symbolic knowledge will be crucial

üëâexplicit cognitive models will be crucial

üëâoperations over variables (including storing, retrieving and comparing values) will be crucial

üëâan explicit type/token distinction will be crucial"
4731,@GaryMarcus,2022-05-17 04:56:54+00:00,https://twitter.com/GaryMarcus/status/1526426510999007232,forget deep learning for the night and read this thread and some of the replies.
4732,@GaryMarcus,2022-05-17 04:54:02+00:00,https://twitter.com/GaryMarcus/status/1526425788270006272,"untrained humans are not good judges of intelligence. 

we have known that since ELIZA, but people tend to forget."
4733,@GaryMarcus,2022-05-17 04:48:25+00:00,https://twitter.com/GaryMarcus/status/1526424376832274437,"@AlexGDimakis @gregd_nlp @katie_m_collins @AnthropicAI @yasaman_razeghi and @sameer_ recent arxiv is very relevant; frequency will continue to correlate (not what you would expect under genuine abstraction, as i argued in The Algebraic Mind)"
4734,@GaryMarcus,2022-05-17 04:40:13+00:00,https://twitter.com/GaryMarcus/status/1526422313305919489,@AlexGDimakis @tdietterich https://t.co/4KLe1bU1YY
4735,@GaryMarcus,2022-05-17 04:38:19+00:00,https://twitter.com/GaryMarcus/status/1526421832529608704,"@miguelisolano @Zergylord @NandoDF @AlexGDimakis and @ethancaballero had t-shirts made, long ago‚Ä¶."
4736,@GaryMarcus,2022-05-17 04:37:39+00:00,https://twitter.com/GaryMarcus/status/1526421667559247875,"@AlexGDimakis @ethancaballero @Zergylord @NandoDF it‚Äôs a lousy term. @frossi_t, Manuelo Veloso, and I recommended a Turing Olympics in AI Magazine in 2016 or so, to assess many different dimensions of intelligent."
4737,@GaryMarcus,2022-05-17 04:35:11+00:00,https://twitter.com/GaryMarcus/status/1526421044692537344,"@pfau @Zergylord @YejinChoinka this tweet, @pfau, aged well"
4738,@GaryMarcus,2022-05-17 04:34:11+00:00,https://twitter.com/GaryMarcus/status/1526420795483750400,@AlexGDimakis @gregd_nlp @katie_m_collins @AnthropicAI https://t.co/MyD9bQEFgv
4739,@GaryMarcus,2022-05-17 04:31:33+00:00,https://twitter.com/GaryMarcus/status/1526420131735228416,@AlexGDimakis @gregd_nlp @katie_m_collins it‚Äôs not that well.  @AnthropicAI did a study where it got to (only) 80% on 3 digit integer arithmetic with 100B parameters.
4740,@GaryMarcus,2022-05-17 04:30:12+00:00,https://twitter.com/GaryMarcus/status/1526419793183526912,reference:
4741,@GaryMarcus,2022-05-17 04:24:17+00:00,https://twitter.com/GaryMarcus/status/1526418300917276672,"@AlexGDimakis @gregd_nlp @katie_m_collins on dall-e, https://t.co/DLdgMIX1Gn"
4742,@GaryMarcus,2022-05-17 04:22:53+00:00,https://twitter.com/GaryMarcus/status/1526417948922941443,"Two months ago @Zergylord was telling me that the idea that anyone would think that ‚Äúscaling is all you need‚Äù was a strawperson.   

Saturday @NandoDF made the case explicitly, and now @alexgdimakis is arguing for the same."
4743,@GaryMarcus,2022-05-17 04:18:35+00:00,https://twitter.com/GaryMarcus/status/1526416870227595264,@AlexGDimakis @tdietterich the Turing test is obviously game-able and tells us little. see my discussion of Eugene Goostman in The New Yorker 2014 and tell us what that program added to AI in general. (Spoiler alert: nothing)
4744,@GaryMarcus,2022-05-17 04:16:38+00:00,https://twitter.com/GaryMarcus/status/1526416375882739714,"@AlexGDimakis on the general point or recurring challenges, see my discussion of alt intelligence at https://t.co/8ir1xKvqt6. 

on the specific point of reasoning see eg your colleague @gregd_nlp‚Äôs recent experiments, or the work on explanation posted today by @katie_m_collins et al."
4745,@GaryMarcus,2022-05-17 00:46:06+00:00,https://twitter.com/GaryMarcus/status/1526363395003252737,"@octonion no, but here is an essay i wrote several years ago on the topic, suggesting an alternative: https://t.co/1N4qeEE9wH"
4746,@GaryMarcus,2022-05-17 00:04:38+00:00,https://twitter.com/GaryMarcus/status/1526352959931502593,@octonion @NandoDF agreed
4747,@GaryMarcus,2022-05-16 23:59:46+00:00,https://twitter.com/GaryMarcus/status/1526351734041235456,"Large language models vs humans, planning and explanation

 New benchmark from @kate_m_collins @MITCoCoSci et al. https://t.co/YmxtKROdyY"
4748,@GaryMarcus,2022-05-16 23:53:04+00:00,https://twitter.com/GaryMarcus/status/1526350050577682437,"@octonion @NandoDF I‚Äôd be very glad to bet against AGI happening in next five years, if anyone is so bold as to go the other direction."
4749,@GaryMarcus,2022-05-16 23:48:07+00:00,https://twitter.com/GaryMarcus/status/1526348804911689728,@octonion and see the @mrgreene1977 essay on Nando‚Äôs current views vs mine/my substack essay linked there.
4750,@GaryMarcus,2022-05-16 23:46:31+00:00,https://twitter.com/GaryMarcus/status/1526348399267549184,"@octonion Just clarifying some history. What you wrote in 2018 was representative of a lot of pushback I got for my Deep Learning: A Critical Appraisal

Now @NandoDF and many others are very much viewing scaling deep learning as the path to AGI. 

Times change."
4751,@GaryMarcus,2022-05-16 23:39:26+00:00,https://twitter.com/GaryMarcus/status/1526346616155713536,The things people said in 2018
4752,@GaryMarcus,2022-05-16 23:35:12+00:00,https://twitter.com/GaryMarcus/status/1526345552119463936,"eg, 2018: https://t.co/CQfxtoaakA"
4753,@GaryMarcus,2022-05-16 23:29:11+00:00,https://twitter.com/GaryMarcus/status/1526344036981669888,@NickRMorgan saying AGI is here or that I am attacking a strawman? link?
4754,@GaryMarcus,2022-05-16 22:46:13+00:00,https://twitter.com/GaryMarcus/status/1526333226268205056,@KordingLab @IntuitMachine https://t.co/9F6IrXj2LV
4755,@GaryMarcus,2022-05-16 22:45:03+00:00,https://twitter.com/GaryMarcus/status/1526332932750721024,"‚ÄúNo, Gary, nobody is saying Deep Learning is supposed to be AGI.‚Äù 

Oh wait.  https://t.co/po2Ht6UkI4"
4756,@GaryMarcus,2022-05-16 21:36:44+00:00,https://twitter.com/GaryMarcus/status/1526315740101349378,"@ben11kehoe @patrickmineault if it came like a new framing (alt intelligence) as i did, or a new term as I did (discomprehension) they would be interesting. if or analyzed errors of most recent model, or recent argument.

this captured the part thet was familiar, but none of what was new."
4757,@GaryMarcus,2022-05-16 21:29:06+00:00,https://twitter.com/GaryMarcus/status/1526313817046515713,"@ben11kehoe @patrickmineault it‚Äôs not quite coherent, but it might be pastische. lots of literature has shown LLM ‚Äúleakage‚Äù, a polite word for verbatim reproduction, and then embedding lead to lots of synonymy/paraphrasing."
4758,@GaryMarcus,2022-05-16 21:24:10+00:00,https://twitter.com/GaryMarcus/status/1526312575582949376,@Eaterofsun @patrickmineault https://t.co/5fLFlEOmx5
4759,@GaryMarcus,2022-05-16 21:18:43+00:00,https://twitter.com/GaryMarcus/status/1526311203252756480,"wow -  Tenenbaum lab has quietly been on Twitter for last two years. 

Definitely worth following!"
4760,@GaryMarcus,2022-05-16 21:14:51+00:00,https://twitter.com/GaryMarcus/status/1526310231277330434,"@IntuitMachine @KordingLab @MuzafferKal_ @patrickmineault this passage looks a bit like me but without the coherence &amp; the updated analysis; eg Simon didn‚Äôt talk about large language models, and ‚Äúthese models‚Äù here should (given the prompt) refer to Simon‚Äôs models but doesn‚Äôt; likewise recent models not analyzed. 

*Mostly* harmless."
4761,@GaryMarcus,2022-05-16 21:09:39+00:00,https://twitter.com/GaryMarcus/status/1526308924869074945,@KordingLab @MuzafferKal_ @patrickmineault from my gpt-3 bloviator article
4762,@GaryMarcus,2022-05-16 21:08:30+00:00,https://twitter.com/GaryMarcus/status/1526308635738923009,"@patrickmineault ‚Äúit helps to think about what systems like GPT-3 do. They don‚Äôt learn about the world‚Äîthey learn about text and how people use words in relation to other words. What it does is something like a massive act of cutting and pasting, stitching variations on text that it has seen‚Äù"
4763,@GaryMarcus,2022-05-16 20:56:59+00:00,https://twitter.com/GaryMarcus/status/1526305736707346433,#hybrid #neurosymbolic - new work from @katie_m_collins
4764,@GaryMarcus,2022-05-16 20:54:32+00:00,https://twitter.com/GaryMarcus/status/1526305121021202432,@KordingLab @MuzafferKal_ @patrickmineault the kind of question a real scientist would ask
4765,@GaryMarcus,2022-05-16 19:38:50+00:00,https://twitter.com/GaryMarcus/status/1526286069288665088,@danbri @Plinz shhhh! don‚Äôt tell @sama
4766,@GaryMarcus,2022-05-16 19:07:49+00:00,https://twitter.com/GaryMarcus/status/1526278264884342784,"@Plinz i think they downscaled gpt-5 with some kind of noisy decoder, to make it convincing"
4767,@GaryMarcus,2022-05-16 18:44:45+00:00,https://twitter.com/GaryMarcus/status/1526272460080832512,@meme_machines Deep understanding is indeed on the list! (though not as episode 2).
4768,@GaryMarcus,2022-05-16 18:20:07+00:00,https://twitter.com/GaryMarcus/status/1526266257388949504,@LibertyRPF @Davichet_e but back up in March. so hard to know.
4769,@GaryMarcus,2022-05-16 18:16:48+00:00,https://twitter.com/GaryMarcus/status/1526265422802087936,@LibertyRPF @Davichet_e causality is a strange beast. are we sure that fears about consequences for Tesla didn‚Äôt drive down NASDAQ?
4770,@GaryMarcus,2022-05-16 18:15:16+00:00,https://twitter.com/GaryMarcus/status/1526265040390631425,Taking audience requests. Topic for next Substack post?
4771,@GaryMarcus,2022-05-16 17:35:03+00:00,https://twitter.com/GaryMarcus/status/1526254918176190464,"@Davichet_e tesla, since twitter acquisition offer"
4772,@GaryMarcus,2022-05-16 17:31:39+00:00,https://twitter.com/GaryMarcus/status/1526254062902968320,not too late to back out https://t.co/ht8YNFAigU
4773,@GaryMarcus,2022-05-16 16:18:30+00:00,https://twitter.com/GaryMarcus/status/1526235652135612416,@nirsd @bendee983 agreed
4774,@GaryMarcus,2022-05-16 13:07:19+00:00,https://twitter.com/GaryMarcus/status/1526187541249916930,@assadollahi @JL88811 @WiidDank working on a task around that
4775,@GaryMarcus,2022-05-16 13:06:30+00:00,https://twitter.com/GaryMarcus/status/1526187333988458496,@danbri @daxfz @EOblast @sir_deenicus @spacepanty it‚Äôs an example of distribution shift and yes symbols are better at that kind of distribution shift
4776,@GaryMarcus,2022-05-16 13:04:22+00:00,https://twitter.com/GaryMarcus/status/1526186799155929090,"people are free to do whatever they like‚Äîbut there is enormous opportunity cost to focusing 90% of a field‚Äôs resources into a single approach that has clear, recurring problem.

nobody rational would ‚Äúdiversify‚Äù a financial portfolio like that. 

ditto for a scientific portfolio."
4777,@GaryMarcus,2022-05-16 13:01:16+00:00,https://twitter.com/GaryMarcus/status/1526186019351015426,@JohnZerilli yes that is what he is saying (&amp; even clearer in his full email)
4778,@GaryMarcus,2022-05-16 01:37:12+00:00,https://twitter.com/GaryMarcus/status/1526013867691651072,"@MatthewJBar trust isn‚Äôt a policy, but rather a long term cultural thing that might derive from many policies. but you are welcome to read the article for yourself."
4779,@GaryMarcus,2022-05-16 01:26:52+00:00,https://twitter.com/GaryMarcus/status/1526011266019405825,"How trust in science and each other might have saved 900,000 lives in the US https://t.co/5CWJ3pnsAq"
4780,@GaryMarcus,2022-05-16 01:18:04+00:00,https://twitter.com/GaryMarcus/status/1526009052794597377,"@danbri @daxfz @EOblast @sir_deenicus @spacepanty maybe, maybe not. bees may we well generalize symbolic operations in computing the solar azimuth (ref in Algebraic Mind). 

maybe arbitrary compositionality is the late arrival."
4781,@GaryMarcus,2022-05-15 21:46:00+00:00,https://twitter.com/GaryMarcus/status/1525955684545703936,@AI4Code postscript: faster than my writing is Chomsky‚Äôs reading-and-responding; the quote of his re physics and GPT-3 that i just posted came from him 10 minutes after I sent him the essay.
4782,@GaryMarcus,2022-05-15 21:38:20+00:00,https://twitter.com/GaryMarcus/status/1525953752418557952,"‚ÄúYou can‚Äôt go to a physics conference and say: I‚Äôve got a great theory.  It accounts for everything and is so simple it can be captured in two words: ‚ÄúAnything goes.‚Äù""

- Noam Chomsky, in email re GPT-3 https://t.co/yo3KqKd4DW"
4783,@GaryMarcus,2022-05-15 21:13:36+00:00,https://twitter.com/GaryMarcus/status/1525947528348246017,@pkghosh99 @sapinker @NaveenGRao it probably can contribute to all but sufficient for few
4784,@GaryMarcus,2022-05-15 21:10:24+00:00,https://twitter.com/GaryMarcus/status/1525946723998126081,@AI4Code I hadn‚Äôt written that fast since the glorious days when I was writing on crazy but fun deadlines for @nxthompson at The New Yorker blog :)
4785,@GaryMarcus,2022-05-15 18:02:23+00:00,https://twitter.com/GaryMarcus/status/1525899410256715778,@eerac @mckbrando that tone was set when they refused me access. not kosher IMHO.
4786,@GaryMarcus,2022-05-15 04:50:29+00:00,https://twitter.com/GaryMarcus/status/1525700120754257921,great thread by @SumitGulwani @Microsoft on FlashFill &amp; how symbolic induction and domain knowledge has stood the test of time ‚Äîin a very different and very useful few-shot learning domain
4787,@GaryMarcus,2022-05-15 02:37:02+00:00,https://twitter.com/GaryMarcus/status/1525666536874078208,@ar_rothschild https://t.co/ITuoZWCf9e
4788,@GaryMarcus,2022-05-15 01:37:45+00:00,https://twitter.com/GaryMarcus/status/1525651618846257153,"@ylecun yes but  NLP systems have not really solved the core issues of compositionality Fodor &amp; Pylyshyn 1988 were concerned with; they have have solved a different set of issues,

likewise object detection is now good, but scene understanding still strugggles."
4789,@GaryMarcus,2022-05-14 22:08:29+00:00,https://twitter.com/GaryMarcus/status/1525598952262975488,"@__narfanar @pascalhitzler‚Äôs recent edited book and @luislamb and @AvilaGarcez‚Äôs 2020 arXiv, inter alia"
4790,@GaryMarcus,2022-05-14 18:39:28+00:00,https://twitter.com/GaryMarcus/status/1525546352565837824,@jscottwagner @NandoDF @DeepMind @SumitGulwani that‚Äôs you :)
4791,@GaryMarcus,2022-05-14 18:23:14+00:00,https://twitter.com/GaryMarcus/status/1525542267859046400,"@sir_deenicus @spacepanty @daxfz i discuss that aspect of evolution in The Birth of The Mind, cc @danbri"
4792,@GaryMarcus,2022-05-14 18:21:36+00:00,https://twitter.com/GaryMarcus/status/1525541856548823040,"@danbri @NandoDF I think it matters a ton! not sure we differ, there.

but I don‚Äôt think that merely approximating the nonsymbolic stuff means we actually have it right. the nonsymbolic stuff is fundamentally semantic, in way that current nets are not. 

wrong ladder for building cognition."
4793,@GaryMarcus,2022-05-14 18:01:05+00:00,https://twitter.com/GaryMarcus/status/1525536694107185153,@NandoDF a lengthy reply:
4794,@GaryMarcus,2022-05-14 17:59:10+00:00,https://twitter.com/GaryMarcus/status/1525536212965941249,@danbri @NandoDF try ‚ÄúA better ladder won‚Äôt get you to the moon‚Äù
4795,@GaryMarcus,2022-05-14 17:52:39+00:00,https://twitter.com/GaryMarcus/status/1525534569448976384,@danbri @NandoDF now we have a trillion!
4796,@GaryMarcus,2022-05-14 17:48:46+00:00,https://twitter.com/GaryMarcus/status/1525533595858702337,posted at
4797,@GaryMarcus,2022-05-14 17:48:16+00:00,https://twitter.com/GaryMarcus/status/1525533468268015616,"@dmonett w credit to @mpshanahan, whom I was paraphrasing"
4798,@GaryMarcus,2022-05-14 17:47:29+00:00,https://twitter.com/GaryMarcus/status/1525533270238109696,@danbri discussed here:
4799,@GaryMarcus,2022-05-14 17:46:57+00:00,https://twitter.com/GaryMarcus/status/1525533138058760192,"@danbri but eg @NandoDF thinks all this walking is not just on a path to AGI but a fait accompli.

he‚Äôs not alone."
4800,@GaryMarcus,2022-05-14 17:44:39+00:00,https://twitter.com/GaryMarcus/status/1525532558150144000,@Grady_Booch @NaveenGRao https://t.co/qwa9rri8Bo
4801,@GaryMarcus,2022-05-14 17:44:25+00:00,https://twitter.com/GaryMarcus/status/1525532501292113921,@hankejh @NaveenGRao https://t.co/qwa9rri8Bo
4802,@GaryMarcus,2022-05-14 17:43:42+00:00,https://twitter.com/GaryMarcus/status/1525532320052043776,@Abel_TorresM @danbri @tdietterich @fchollet reply posted:
4803,@GaryMarcus,2022-05-14 17:42:08+00:00,https://twitter.com/GaryMarcus/status/1525531924759924736,@danbri i have no issue with doing that but question the upper bound
4804,@GaryMarcus,2022-05-14 17:41:14+00:00,https://twitter.com/GaryMarcus/status/1525531699605405696,@CineraVerinia i see no reason to expect it to be true. and eg Alpha* all use hybrid architecture that beat their pure deep learning counterparts empirically
4805,@GaryMarcus,2022-05-14 17:40:30+00:00,https://twitter.com/GaryMarcus/status/1525531514678611968,@CineraVerinia see my reply to this point re Sutton at https://t.co/8ir1xKvqt6 (new/first post on Alt Intelligence)
4806,@GaryMarcus,2022-05-14 17:23:20+00:00,https://twitter.com/GaryMarcus/status/1525527191806566401,@terrible_archer and reached  a length limit warning!
4807,@GaryMarcus,2022-05-14 17:22:50+00:00,https://twitter.com/GaryMarcus/status/1525527069035143168,now posted:
4808,@GaryMarcus,2022-05-14 17:19:43+00:00,https://twitter.com/GaryMarcus/status/1525526284113104896,"Placing DALL-E, GPT-3, Flamingo, Gato, and more in the context of AI history, &amp; the debut of a new (free!) Substack, The Road to AI We Can Trust: A No Bullshit Look at AI Progress and Hype. https://t.co/3gACXGT2w9"
4809,@GaryMarcus,2022-05-14 17:14:34+00:00,https://twitter.com/GaryMarcus/status/1525524986256977920,@Abel_TorresM posted:
4810,@GaryMarcus,2022-05-14 17:08:21+00:00,https://twitter.com/GaryMarcus/status/1525523421257269248,@NandoDF @DeepMind credit to @naveengrao for formulating the term ‚Äúalt intelligence‚Äù
4811,@GaryMarcus,2022-05-14 17:07:45+00:00,https://twitter.com/GaryMarcus/status/1525523272745426944,"‚ÄúAlt Intelligence‚Äù, and why it is not (yet) Artificial General Intelligence, with thoughts on @NandoDF @DeepMind‚Äôs ‚Äúit‚Äôs all about scale‚Äù thread: https://t.co/ufbxCXeFOL
#AI #deeplearning"
4812,@GaryMarcus,2022-05-14 15:36:11+00:00,https://twitter.com/GaryMarcus/status/1525500230048763905,"But symbols are the heart of why we humans lead rather different lives; take away that icing, and we literally would not be having this conversation. 

Or any other conversation

Or any computers. Or cell phones. Or technology

Or complex culture

It‚Äôs some pretty powerful icing."
4813,@GaryMarcus,2022-05-14 15:14:49+00:00,https://twitter.com/GaryMarcus/status/1525494849712975874,@danbri @Abel_TorresM @tdietterich @fchollet @NandoDF @DeepMind in the  *word*? didja mean world?
4814,@GaryMarcus,2022-05-14 15:14:07+00:00,https://twitter.com/GaryMarcus/status/1525494676811239426,"Oh boy I am having a lot of fun writing this. Working title (with some thanks due to @NaveenGRao) is The New Science of Alt Intelligence.

Typing as fast as I can!"
4815,@GaryMarcus,2022-05-14 14:51:56+00:00,https://twitter.com/GaryMarcus/status/1525489094188404738,"Writng about this now, will be mentioned in my first https://t.co/8ir1xKvqt6 post‚Ä¶"
4816,@GaryMarcus,2022-05-14 14:22:59+00:00,https://twitter.com/GaryMarcus/status/1525481807864467456,"@LucaAmb Sophistry, not reality:
- Driverless cars aren‚Äôt nearly good enough; that‚Äôs why all the trials are very limited, and require constant human intervention
- Chatbots aren‚Äôt that great, which is why we always have humans in the loop eg for medical advice and even customer service"
4817,@GaryMarcus,2022-05-14 14:19:12+00:00,https://twitter.com/GaryMarcus/status/1525480855077998605,"@Abel_TorresM hey man, I just started a substack so I could say the same. don‚Äôt give away the punchline! :)"
4818,@GaryMarcus,2022-05-14 14:12:50+00:00,https://twitter.com/GaryMarcus/status/1525479252837036032,Coming soon https://t.co/N39FiZQF0S
4819,@GaryMarcus,2022-05-14 13:48:16+00:00,https://twitter.com/GaryMarcus/status/1525473069124399104,@Abel_TorresM @danbri @tdietterich @fchollet astounding. i will reply.
4820,@GaryMarcus,2022-05-14 13:47:11+00:00,https://twitter.com/GaryMarcus/status/1525472798595985408,"Maybe, maybe not. AI can master all the benchmarks and games, in the world, but if driverless cars fail, and chatbots continue to periodically say stupid and destructive things, AI winter could return.  

Tangible progress on benchmarks is no guarantee."
4821,@GaryMarcus,2022-05-14 13:36:12+00:00,https://twitter.com/GaryMarcus/status/1525470033484595201,"@maier_ak @SchmidhuberAI no, the idea arguably goes back to Rosenblatt and was central in the Rumelhart and McClelland past tense model debate."
4822,@GaryMarcus,2022-05-14 01:27:54+00:00,https://twitter.com/GaryMarcus/status/1525286752042176512,@jachiam0 we can‚Äôt all be as funny as @plinz. but we can try.
4823,@GaryMarcus,2022-05-14 00:59:33+00:00,https://twitter.com/GaryMarcus/status/1525279614729330688,DALL-E‚Äôa gonna save us from another AI winter. it‚Äôs true! I read it on the internet!
4824,@GaryMarcus,2022-05-13 21:03:40+00:00,https://twitter.com/GaryMarcus/status/1525220252262445056,"@DVHenkelWallace @gregmepstein i would settle in many cases for ‚Äúroughly as trustworthy as the humans to which we assign a given task‚Äù; 

In general we humans set a low bar, but current AI is often unable to reach or exceed that bar."
4825,@GaryMarcus,2022-05-13 21:02:01+00:00,https://twitter.com/GaryMarcus/status/1525219839765147649,nth in a @lcastricato inspired series
4826,@GaryMarcus,2022-05-13 21:02:00+00:00,https://twitter.com/GaryMarcus/status/1525219836502036480,semi-supervised learning https://t.co/5KtpGWqf8K
4827,@GaryMarcus,2022-05-13 19:22:30+00:00,https://twitter.com/GaryMarcus/status/1525194795815084032,"@therealcritiq @gregmepstein the government needs to be educated, and needs to be part of it"
4828,@GaryMarcus,2022-05-13 19:21:41+00:00,https://twitter.com/GaryMarcus/status/1525194589035892736,@TimSchrills @gregmepstein i think we need fundamental innovation there.
4829,@GaryMarcus,2022-05-13 19:00:07+00:00,https://twitter.com/GaryMarcus/status/1525189161652604928,@HappyAar @gregmepstein I like @weidingerlaura et al‚Äôs December arXiv on the scope of the problem; I have not seen anything on a solution that seems adequate. My pinned tweet gives some hints as to what I think is necessary‚Ä¶
4830,@GaryMarcus,2022-05-13 18:20:55+00:00,https://twitter.com/GaryMarcus/status/1525179296230191105,"@gregmepstein i actually think getting to trustworthy AI is hugely important, both near-term and long, as systems take on more and more control over our lives, but that current approaches are very unlikely to get us there, and that the space of hypotheses being considered is far too narrow."
4831,@GaryMarcus,2022-05-13 14:42:01+00:00,https://twitter.com/GaryMarcus/status/1525124208870555648,"@srikumarks a lot of solutions in search of problems, indeed"
4832,@GaryMarcus,2022-05-13 14:30:24+00:00,https://twitter.com/GaryMarcus/status/1525121287000973312,@michaelgarfield @mbnUNT @sfiscience @SantaFeMcShea send Dmitri my greetings!
4833,@GaryMarcus,2022-05-13 13:46:01+00:00,https://twitter.com/GaryMarcus/status/1525110115610656769,https://t.co/JhhGcxlOR7 has source code etc
4834,@GaryMarcus,2022-05-13 13:41:50+00:00,https://twitter.com/GaryMarcus/status/1525109061804560385,"Folks @deepmind, have you tried to test #Gato on the complete set of materials in Winograd‚Äôs classic 1968 SHRLDU Blocks World, in a robot arm plus image captioner + chat? 

A full report on that would be fascinating!

@scott_e_reed @NandoDF @RaiaHadsell @OriolVinyalsML"
4835,@GaryMarcus,2022-05-13 13:18:14+00:00,https://twitter.com/GaryMarcus/status/1525103125585022977,@ChombaBupe @hardmaru @pfau @danijarh @scott_e_reed all reasonable points and questions
4836,@GaryMarcus,2022-05-13 13:11:42+00:00,https://twitter.com/GaryMarcus/status/1525101478351843331,@hardmaru @pfau @danijarh @scott_e_reed dude blocked me; what‚Äôs he say @hardmaru
4837,@GaryMarcus,2022-05-13 13:07:33+00:00,https://twitter.com/GaryMarcus/status/1525100436885188609,@adamsafron @anilkseth icymi
4838,@GaryMarcus,2022-05-13 01:49:47+00:00,https://twitter.com/GaryMarcus/status/1524929870509142017,"@un1crom @DeepMind not A for artificial, but certainly some animals have some measure of general intelligence, and seem to build cognitive models of the world that they effectively interact with.

no intelligence is fully general; human intelligence the most general known."
4839,@GaryMarcus,2022-05-13 01:35:42+00:00,https://twitter.com/GaryMarcus/status/1524926326687137792,"I‚Äôm good with calling @DeepMind‚Äôs latest AI Gato an ‚Äúalt intelligence‚Äù, as long as nobody claims it
- works like the brain
- learns like a child
- understands language
- aligns with human values
- can be trusted in mission-critical tasks"
4840,@GaryMarcus,2022-05-12 23:51:14+00:00,https://twitter.com/GaryMarcus/status/1524900036068315138,"@Miles_Brundage am about to launch something new, with some folks i the deep learning community. dm if you want to help."
4841,@GaryMarcus,2022-05-12 23:43:05+00:00,https://twitter.com/GaryMarcus/status/1524897987020804096,"The deep learning community would desperately like for me to cry uncle, but I can only do that if:

a. They meet the criteria that I have defended over the last two decades 
or
b. Show that those criteria are irrelevant for intelligence

All I actually see is
c. Name calling"
4842,@GaryMarcus,2022-05-12 23:19:43+00:00,https://twitter.com/GaryMarcus/status/1524892106027741184,"@NaveenGRao if you want to call it approximative intelligence i am fine with that. 

basically every time i give a talk i show a figure like this because i think there are many aspects to intelligence, and we have made progress on some not others. https://t.co/Vy0fcnqN5W"
4843,@GaryMarcus,2022-05-12 23:16:18+00:00,https://twitter.com/GaryMarcus/status/1524891243305545728,@tejasdkulkarni not if you keep accusing me of delusions. i will pass. i am out.
4844,@GaryMarcus,2022-05-12 23:14:41+00:00,https://twitter.com/GaryMarcus/status/1524890838957887489,@tejasdkulkarni @terrible_archer ok bye now
4845,@GaryMarcus,2022-05-12 23:14:26+00:00,https://twitter.com/GaryMarcus/status/1524890775040843777,"@tejasdkulkarni red cube blue cube ain‚Äôt hard for a linguist, just for DALL-E etc. that‚Äôs the unification we need"
4846,@GaryMarcus,2022-05-12 23:13:41+00:00,https://twitter.com/GaryMarcus/status/1524890586754318336,"@tejasdkulkarni i think one can provisionally take words or morphemes as primitive and ignore most of your attached point. there are some edge cases, but dismissing 100 years of semantics with a tweet isn‚Äôt particularly convincing, esp when the alternative struggles w red cube on blue cube"
4847,@GaryMarcus,2022-05-12 23:10:59+00:00,https://twitter.com/GaryMarcus/status/1524889905502924800,@tejasdkulkarni so you are happy with being at chance for putting the blue cube on the red cube being at chance?
4848,@GaryMarcus,2022-05-12 23:08:45+00:00,https://twitter.com/GaryMarcus/status/1524889343650693121,"@NaveenGRao sure, but the errors tend to reflect an utter lack of comprehension. 

what do you think is the nature of the progress? do you anticipate that these systems will become reliable? how?"
4849,@GaryMarcus,2022-05-12 23:02:46+00:00,https://twitter.com/GaryMarcus/status/1524887840995221505,@tejasdkulkarni @terrible_archer just another evasion. they will be broken. but how? the walls i picked out in 2001 remain
4850,@GaryMarcus,2022-05-12 23:02:12+00:00,https://twitter.com/GaryMarcus/status/1524887696774033409,"@tejasdkulkarni show me where we have systems that genuinely have common sense or language understanding. the goal posting shifting is on your side, not mine"
4851,@GaryMarcus,2022-05-12 23:01:33+00:00,https://twitter.com/GaryMarcus/status/1524887531958939648,"@tejasdkulkarni they aren‚Äôt solving my tasks; i don‚Äôt see how to get to AGI that we can trust without them.

it‚Äôs not about my narrative; it‚Äôs about the fact that the problems remain unsolved."
4852,@GaryMarcus,2022-05-12 23:00:42+00:00,https://twitter.com/GaryMarcus/status/1524887318879907840,@tejasdkulkarni what on earth is the argument for that?
4853,@GaryMarcus,2022-05-12 22:40:34+00:00,https://twitter.com/GaryMarcus/status/1524882252471017473,@NaveenGRao if i had a day with any of these models i could show you deeper differences w humans but we have entered the full on press release era.
4854,@GaryMarcus,2022-05-12 22:39:31+00:00,https://twitter.com/GaryMarcus/status/1524881987458125824,"@NaveenGRao should we make our machines do lousy arithmetic because people do? the deeper problem is the lack of semantics and world models, which success on benchmarks doesn‚Äôt solve"
4855,@GaryMarcus,2022-05-12 20:26:55+00:00,https://twitter.com/GaryMarcus/status/1524848618481405952,"open challenge to deep learning community: go back to my @NautilusMag article &amp; read it line by line &amp; see which of challenges raised there have and have not been solved by DALL-E2, PaLM, Flamingo or Gato. 

it‚Äôs been a wild 8 weeks but IMHO the problems I pointed to remain."
4856,@GaryMarcus,2022-05-12 20:20:17+00:00,https://twitter.com/GaryMarcus/status/1524846949815316481,@PsudoMetaBot nope
4857,@GaryMarcus,2022-05-12 20:18:21+00:00,https://twitter.com/GaryMarcus/status/1524846461921308672,"mere rhetoric. I specified that the wall I was talking about was misinformation and reliable compositional understanding of language

getting good but unreliable performance on many different tasks is not ‚Äúannihilating‚Äù that wall.

period."
4858,@GaryMarcus,2022-05-12 20:03:24+00:00,https://twitter.com/GaryMarcus/status/1524842701090197505,@tejasdkulkarni may i ask what wall you think it has broken and how you think it has done one the walls that i have been trying to articulate?
4859,@GaryMarcus,2022-05-12 20:01:46+00:00,https://twitter.com/GaryMarcus/status/1524842286852415488,"@tejasdkulkarni most of the domains don‚Äôt include any kind of detailed error report; the ones that do are like i said.

it‚Äôs cool, yeah, but it‚Äôs not AGI and no it has not solved the issues i keep raising"
4860,@GaryMarcus,2022-05-12 19:58:52+00:00,https://twitter.com/GaryMarcus/status/1524841559098740736,@LucaAmb https://t.co/lrtjJmF14c
4861,@GaryMarcus,2022-05-12 19:57:11+00:00,https://twitter.com/GaryMarcus/status/1524841133687328798,@CadeMetz
4862,@GaryMarcus,2022-05-12 19:55:15+00:00,https://twitter.com/GaryMarcus/status/1524840646967631872,"before you post all those AGI is here and #Gato is breaking the wall memes, you mind looking carefully at page 10?

No matter how big the models get,  the unreliability and misinformation that have been the hallmark of large language models remain. https://t.co/lAeOoV6RiO"
4863,@GaryMarcus,2022-05-12 19:42:44+00:00,https://twitter.com/GaryMarcus/status/1524837498920181760,@alfairhall @maayanvisuals
4864,@GaryMarcus,2022-05-12 17:21:03+00:00,https://twitter.com/GaryMarcus/status/1524801845087985669,@Sara_Imari interesting conclusion. what‚Äôs the argument for it?
4865,@GaryMarcus,2022-05-12 16:10:45+00:00,https://twitter.com/GaryMarcus/status/1524784152611983360,@Zergylord 10 figure series B
4866,@GaryMarcus,2022-05-12 09:08:16+00:00,https://twitter.com/GaryMarcus/status/1524677831577403392,"this just popped up in my feed; i think it is fair to say that almost two years later, a fundamental lack of comprehension still plagues large language models‚Äîdespite massive investment and even as they have gotten considerably larger and improved somewhat on many benchmarks."
4867,@GaryMarcus,2022-05-12 08:59:51+00:00,https://twitter.com/GaryMarcus/status/1524675712283594752,"@ntraft not impossible, but it‚Äôs one thing for other companies to do it in a limited way in highly mapped &amp; carefully selected portions of a city, &amp; another to do it a truly point-to-point way more or less universally, capturing (in the upper estimate) essentially entire market for rides"
4868,@GaryMarcus,2022-05-12 08:53:28+00:00,https://twitter.com/GaryMarcus/status/1524674106465001474,"@rmarcilhoo @CathieDWood the estimates were about ride hails, not subscriptions to L2. I don‚Äôt doubt that people will continue to pay something for AI-assisted driving."
4869,@GaryMarcus,2022-05-12 04:04:15+00:00,https://twitter.com/GaryMarcus/status/1524601323684962305,".@CathieDWood 

i doubt these autonomous ride hailing projections &amp; wonder whether you'd put a friendly charitable wager on them:

10k to your favorite charity if Tesla's 2026 AV ride hailing income exceeds $50B

10k to my fave charity if &lt; 50B

rides w safety drivers don't count"
4870,@GaryMarcus,2022-05-12 03:56:32+00:00,https://twitter.com/GaryMarcus/status/1524599380019359745,@titudeadjust according to the report 25% of the Monte Carlo simulations were even higher.
4871,@GaryMarcus,2022-05-12 02:56:13+00:00,https://twitter.com/GaryMarcus/status/1524584202649305088,"Tesla might make $486B on autonomous ride hails in 2026, according to this study.

I don‚Äôt know what to say."
4872,@GaryMarcus,2022-05-12 01:00:48+00:00,https://twitter.com/GaryMarcus/status/1524555156876001280,"‚Äúthere‚Äôs a huge difference between raising a mind in the world, and raising one in a sea of data.‚Äù -@NGaylinn."
4873,@GaryMarcus,2022-05-12 00:25:59+00:00,https://twitter.com/GaryMarcus/status/1524546394463170560,"@Vortex_Egg what‚Äôs the distinction, for those unfamiliar?"
4874,@GaryMarcus,2022-05-11 23:18:17+00:00,https://twitter.com/GaryMarcus/status/1524529354344067073,What if the main consequence of Musk‚Äôs plan to buy Twitter was to recalibrate the value of Tesla?
4875,@GaryMarcus,2022-05-11 21:51:14+00:00,https://twitter.com/GaryMarcus/status/1524507450874814464,@TacoCohen that chapter might be online at the readings for the Bengio Marcus debate?
4876,@GaryMarcus,2022-05-11 21:50:38+00:00,https://twitter.com/GaryMarcus/status/1524507298726522880,"@TacoCohen no. i am sorry that the longest and most complex argument I made is not free, and was written before arxiv, but‚Äôs not a tweet."
4877,@GaryMarcus,2022-05-11 21:00:27+00:00,https://twitter.com/GaryMarcus/status/1524494668309798912,@TacoCohen @trunghlt there‚Äôs your mistake; it‚Äôs qualitative  issue and you are looking for some quantitative math
4878,@GaryMarcus,2022-05-11 20:59:16+00:00,https://twitter.com/GaryMarcus/status/1524494371898281985,"@TacoCohen did you read my discussion in The Algebraic Mind, Chapter 2, and have any issues with how I laid things out? I argued that all systems have symbols but not all represent and apply operations over variables."
4879,@GaryMarcus,2022-05-11 19:51:47+00:00,https://twitter.com/GaryMarcus/status/1524477387366313985,interesting work:
4880,@GaryMarcus,2022-05-11 19:41:54+00:00,https://twitter.com/GaryMarcus/status/1524474900882157569,@mmbronstein @charleswangb @andrewwhite01 @PetarV_93 can you say more about what you mean?
4881,@GaryMarcus,2022-05-11 17:14:07+00:00,https://twitter.com/GaryMarcus/status/1524437712043855872,"It is worse than that. 

Virtually everyone in the cognitive sciences recognizes that cognition revolves constructing best-guess models of an external world that we never directly grasp, whereas most contemporary ML tries to work directly from data, shortcutting that step."
4882,@GaryMarcus,2022-05-11 14:46:26+00:00,https://twitter.com/GaryMarcus/status/1524400543141040129,@andrewwhite01 @pascalhitzler @AvilaGarcez @luislamb @payel791 for sure (though I haven‚Äôt read that specific paper). but grammars are one of the most quintessential symbolic tools
4883,@GaryMarcus,2022-05-11 14:38:39+00:00,https://twitter.com/GaryMarcus/status/1524398585328304128,@andrewwhite01 @mmbronstein‚Äôs geometric deep learning stuff is also very relevant and he has some fabulous tutorials.
4884,@GaryMarcus,2022-05-11 14:37:52+00:00,https://twitter.com/GaryMarcus/status/1524398390796189696,"@andrewwhite01 Recent @pascalhitzler book; my Next Decade in AI arxiv, and @AvilaGarcez / @luislamb 2020 arXiv review"
4885,@GaryMarcus,2022-05-11 01:09:06+00:00,https://twitter.com/GaryMarcus/status/1524194857169739776,@samoalfred community standards for civility? the participants? the switch to online?
4886,@GaryMarcus,2022-05-11 01:03:11+00:00,https://twitter.com/GaryMarcus/status/1524193367206236161,Back when AI debates were civilized :)
4887,@GaryMarcus,2022-05-11 01:01:25+00:00,https://twitter.com/GaryMarcus/status/1524192922781900800,"‚ÄúLeveraging additional, already existing sources of knowledge is key to overcome the limitations of purely data-driven approaches‚Äù https://t.co/QFxiDodNhe

(exactly what Next Decade in AI argued)"
4888,@GaryMarcus,2022-05-11 00:22:58+00:00,https://twitter.com/GaryMarcus/status/1524183244433870850,"Parsing @elonmusk: ""I think if there are tweets that are wrong and bad, those should be either deleted or made invisible, and a suspension, a temporary suspension is appropriate.‚Äù

morally wrong?
factually wrong?

asking for a twitterverse"
4889,@GaryMarcus,2022-05-10 23:25:01+00:00,https://twitter.com/GaryMarcus/status/1524168664630530048,"@ClementDelangue thank you @ClementDelangue for speaking up, and for creating so much easy-to-use and elegant infrastructure, allowing people to see for themselves what is and isn‚Äôt currently viable."
4890,@GaryMarcus,2022-05-10 23:17:28+00:00,https://twitter.com/GaryMarcus/status/1524166762731778050,astonishing image
4891,@GaryMarcus,2022-05-10 21:33:19+00:00,https://twitter.com/GaryMarcus/status/1524140553700450310,"Emperor‚Äôs New Clothes, updated for social media era:

‚ÄúTownsfolk uncomfortably go along with the pretense, not wanting to appear stupid, until a child blurts out that emperor is wearing nothing. 

Townsfolk ridicule child on Twitter. Emperor raises Series B for new fashion line.‚Äù"
4892,@GaryMarcus,2022-05-10 19:48:36+00:00,https://twitter.com/GaryMarcus/status/1524114200976510976,@nlpnyc @MadamePratolung @maier_ak @ylecun @ykilcher @hardmaru @Krauss_PK @ancetetere @sama i think it is one thing for an individual to play around and report something fun they found and another for c suite executives to systematically cherry pick for days as part of a product introduction.
4893,@GaryMarcus,2022-05-10 17:03:51+00:00,https://twitter.com/GaryMarcus/status/1524072738918309888,"no. you can present ALL the data, from every test that you did, as Ernie Davis, Scott Aaronson and I did in our recent arXiv, and as many other scientists now routinely doing online.

As Joelle Pineau has pointed out, full disclosure should be the norm in AI as well."
4894,@GaryMarcus,2022-05-10 17:00:21+00:00,https://twitter.com/GaryMarcus/status/1524071856772292608,"@nlpnyc @RWerpachowski @karpathy actually seems like two bets: can it be done, at all, by the end of the decade, and can it be done with pure deep learning and no reasoning, explicit knowledge representation, explicit rules, etc.

i'm down for both. even odds on the first, and your $100 gets my $500 on second."
4895,@GaryMarcus,2022-05-10 16:29:50+00:00,https://twitter.com/GaryMarcus/status/1524064180214501377,"@nlpnyc @RWerpachowski on arbitrarily chosen roads in a variety of weather, etc? note that Tesla will likely be more 'hybrid"" by then, as MobileEye is now, so it's not a pure test of deep learning"
4896,@GaryMarcus,2022-05-10 15:55:20+00:00,https://twitter.com/GaryMarcus/status/1524055496931512323,"@RWerpachowski @nlpnyc no, deep learning suffers from hype. it's a valuable technique, but oversold, and pressed into service in domains where it's not appropriate."
4897,@GaryMarcus,2022-05-10 15:54:01+00:00,https://twitter.com/GaryMarcus/status/1524055162930688001,"@danbri @sd_marlow @mpshanahan @tdietterich @Abel_TorresM @fchollet i think the long piano piece is definitely not in the scope of common sense, and likely draws more on procedural memory than the others.
 
but these are great queries."
4898,@GaryMarcus,2022-05-10 15:40:13+00:00,https://twitter.com/GaryMarcus/status/1524051690906816513,ps it would still be fantastic if @ylecun would join the thread about hybrid models and answer the questions many of us posed there. https://t.co/huZslnGB7e
4899,@GaryMarcus,2022-05-10 15:37:56+00:00,https://twitter.com/GaryMarcus/status/1524051118157754375,"If you didn't learn anything from that debate with @ylecun, don't despair. This thread (launched by a @danbri, in discussion of a remark by @fchollet) goes deeper, into the mechanisms and representations of common sense."
4900,@GaryMarcus,2022-05-10 15:25:02+00:00,https://twitter.com/GaryMarcus/status/1524047868968927232,"@tdietterich @danbri @Abel_TorresM @fchollet right, and there is some question about whether that gives you the right level of abstraction, at least as currently done, but definitely on the table as a plausible part of the overall machinery"
4901,@GaryMarcus,2022-05-10 15:24:10+00:00,https://twitter.com/GaryMarcus/status/1524047651267694593,"@tdietterich @danbri @Abel_TorresM @fchollet How about ""Don't believe everything you hear""?  :)"
4902,@GaryMarcus,2022-05-10 15:18:12+00:00,https://twitter.com/GaryMarcus/status/1524046152240226306,"Great threads by @DeepMind's @mpshanahan and (linked) @jalayrac candidly looking at Flamingo's limitations.

Strengths and weaknesses should always be evaluated in tandem, if we are to be realistic about what needs to be done."
4903,@GaryMarcus,2022-05-10 15:14:57+00:00,https://twitter.com/GaryMarcus/status/1524045333981843456,@mpshanahan @DeepMind thanks - i hadn't seen that.
4904,@GaryMarcus,2022-05-10 14:59:30+00:00,https://twitter.com/GaryMarcus/status/1524041443244867585,@danbri @tdietterich @Abel_TorresM @fchollet some mix of the above but happy to expand the list
4905,@GaryMarcus,2022-05-10 14:53:47+00:00,https://twitter.com/GaryMarcus/status/1524040005076733952,"‚âà ‚Äúi don‚Äôt mind misleading the public, governments, or investors, because who cares?‚Äù

also: ‚Äúmy buddies can‚Äôt be taken in by vivid examples, because they are not subject to cognitive illusions, unlike other humans‚Äù"
4906,@GaryMarcus,2022-05-10 14:44:38+00:00,https://twitter.com/GaryMarcus/status/1524037702747754498,"@tdietterich @danbri @Abel_TorresM @fchollet ""common sense"" probably reflects a mixture of (reasoning and retrieval) mechanisms and knowledge."
4907,@GaryMarcus,2022-05-10 14:20:28+00:00,https://twitter.com/GaryMarcus/status/1524031620654583808,"@maier_ak @ylecun @ykilcher @hardmaru @Krauss_PK @ancetetere @sama, fyi"
4908,@GaryMarcus,2022-05-10 13:00:54+00:00,https://twitter.com/GaryMarcus/status/1524011598620217346,@xiye_nlp @WesleyYue @gregd_nlp would love more detail (stats and examples of errors) for O2‚Äôs performance
4909,@GaryMarcus,2022-05-10 04:28:08+00:00,https://twitter.com/GaryMarcus/status/1523882556973666304,"Ultimately, this argument is about one thing, and one thing only, ‚ÄúIs it ok to criticize a dominant paradigm even if your own remains unproven?‚Äù

Those in power believe that the answer is no."
4910,@GaryMarcus,2022-05-10 03:46:48+00:00,https://twitter.com/GaryMarcus/status/1523872152750936064,"@matthewputman @elonmusk @jeffholden @HenrikFiskerr @s_r_constantin The biggest revolution will come when we solve the problems of distribution shift and knowledge representation, so that we can move past stereotyped assembly and to dynamically creating bespoke innovation."
4911,@GaryMarcus,2022-05-10 03:41:16+00:00,https://twitter.com/GaryMarcus/status/1523870763513614337,And we were so close to becoming friends. #feelthelearn
4912,@GaryMarcus,2022-05-10 03:38:48+00:00,https://twitter.com/GaryMarcus/status/1523870139363446784,"@hey_tatie and I have no doubt that hybrid models will prevail in the end. As I often say, I am short-term pessimistic about science (because of politics and confirmation bias) but long-term optimistic. See my recent convo with @schrep about people mistakenly believing genes were proteins."
4913,@GaryMarcus,2022-05-10 03:35:20+00:00,https://twitter.com/GaryMarcus/status/1523869269271793664,"@hey_tatie CIFAR funding was really important, there, too."
4914,@GaryMarcus,2022-05-10 03:34:33+00:00,https://twitter.com/GaryMarcus/status/1523869070956761088,"@giffmana no now you are misrepresenting my claim, ciao"
4915,@GaryMarcus,2022-05-10 03:34:06+00:00,https://twitter.com/GaryMarcus/status/1523868958650028033,"@giffmana Godspeed to you, if you can propose hypotheticals, and I can‚Äôt."
4916,@GaryMarcus,2022-05-10 03:22:43+00:00,https://twitter.com/GaryMarcus/status/1523866092153700352,"@hey_tatie if literally everyone had ignored it, the conventional wisdom from the time that they didn‚Äôt work would have been accepted, nobody would have tried them on GPUs, etc, and the value of the tools would never have been discovered."
4917,@GaryMarcus,2022-05-10 02:57:51+00:00,https://twitter.com/GaryMarcus/status/1523859835778785280,imagine where we would be if *everyone* had ignored deep learning before 2011? if social media has been used to mock deep learning and politicize funding at that time?
4918,@GaryMarcus,2022-05-09 18:40:14+00:00,https://twitter.com/GaryMarcus/status/1523734605425115136,"""On Facebook, information and disinformation look the same; the only difference is that disinformation generates more revenue, so it gets better treatment.""

https://t.co/VxLEyMK9ct"
4919,@GaryMarcus,2022-05-09 16:39:39+00:00,https://twitter.com/GaryMarcus/status/1523704261908918272,@kvashee @Nitin_wysiwyg @RichardSocher
4920,@GaryMarcus,2022-05-09 15:35:42+00:00,https://twitter.com/GaryMarcus/status/1523688166300930048,@HappyAar @NoahGoodall @aniccia https://t.co/2bzEtdWpQ2
4921,@GaryMarcus,2022-05-09 15:21:26+00:00,https://twitter.com/GaryMarcus/status/1523684575737638918,"Very cool paper on evaluating crash statistics by @NoahGoodall, ht @aniccia"
4922,@GaryMarcus,2022-05-09 15:18:49+00:00,https://twitter.com/GaryMarcus/status/1523683918934728705,@scottiev @aniccia @NoahGoodall very interesting. and not exactly a clear reflection of exponential improvements following (presumably) exponential increases in data.
4923,@GaryMarcus,2022-05-09 15:16:46+00:00,https://twitter.com/GaryMarcus/status/1523683402867564549,@leonpalafox @maier_ak @ylecun @wjb_003 @Tesla ha ha ha a rare case where the headline was more accurate than the news story.
4924,@GaryMarcus,2022-05-09 15:15:42+00:00,https://twitter.com/GaryMarcus/status/1523683134977454081,"@scottiev @ntvll @Mobileye @Tesla i have a very well-informed, well-placed source and am fully confident that it is a highly-structured hybrid system, with both ‚Äúneural‚Äù (eg CNN) and symbolic components.  (But I don‚Äôt know all the details about what specific sensors are used etc.)"
4925,@GaryMarcus,2022-05-09 15:10:24+00:00,https://twitter.com/GaryMarcus/status/1523681800005947392,@ndaniilidis i assumed it was because they send everything through embeddings that are great for synonymy but lousy for precision. but it could be a bit of both?
4926,@GaryMarcus,2022-05-09 14:55:02+00:00,https://twitter.com/GaryMarcus/status/1523677932828254209,"@Plinz @luislamb @Garcez @hitzler @neurobongo @rossi @swarat @barneyp i‚Äôm suggesting handcrafting the possibility of symbol-manipulation, but certainly NOT suggesting handcrafting the entire system (a la Cyc). I‚Äôve been very clear about this, eg in Rebooting AI, Next Decade in AI, etc"
4927,@GaryMarcus,2022-05-09 14:53:46+00:00,https://twitter.com/GaryMarcus/status/1523677612698075137,@Plinz @luislamb @Garcez @hitzler @neurobongo @rossi @swarat @barneyp Hey hold on; my whole argument in some sense is that we need to add the possibility of symbol-manipulation as a prior; you‚Äôre attributing exactly the opposite to me.
4928,@GaryMarcus,2022-05-09 14:52:24+00:00,https://twitter.com/GaryMarcus/status/1523677270140854275,"@maier_ak @TimKietzmann @luislamb @Garcez @hitzler @neurobongo @rossi @swarat @barneyp @ylecun towards innateness, too, with his convolutional prior. As I mentioned in my recent @NautilusMag article, Hinton was once an advocate for neurosymbolic approaches, and retreated for reasons that have never been fully explained."
4929,@GaryMarcus,2022-05-09 14:49:08+00:00,https://twitter.com/GaryMarcus/status/1523676447927201792,"@giffmana @ylecun @wjb_003 @Tesla and monthly reminder that the field was wrong to disparage deep learning prematurely, and that going around call areas that you don‚Äôt understand ‚Äúvacuous‚Äù and ‚Äúa huge mistake‚Äù is not a great way to foster innovation. 

and that premature closure is a huge mistake."
4930,@GaryMarcus,2022-05-09 14:36:43+00:00,https://twitter.com/GaryMarcus/status/1523673325649547265,"@leonpalafox @maier_ak @ylecun @wjb_003 @Tesla No, that‚Äôs not correct. I was head of Uber AI Labs (a tiny research operation), not head of Uber AI‚Äôs operation as a whole. E.g, I had no authority over the large-scale driverless car division whatsoever, which at the time was run by Lewandoski."
4931,@GaryMarcus,2022-05-08 23:04:13+00:00,https://twitter.com/GaryMarcus/status/1523438651287298048,"sorry meant to tag @ylecun. these are i think my most substantive questions around his claims from today, and I hope we can focus here going forward:"
4932,@GaryMarcus,2022-05-08 21:13:25+00:00,https://twitter.com/GaryMarcus/status/1523410767151730690,@ylecun @ErnestSDavis also do you have a proof that classical and gradient approaches are incompatible? i would be very interested to see that.
4933,@GaryMarcus,2022-05-08 21:12:41+00:00,https://twitter.com/GaryMarcus/status/1523410582916849664,"1. would you count any system that mixes the two to be hybrid?
2. would you count systems that don‚Äôt mix the two as non hybrid? 
3. if some systems fall into (1) and others into (2) how can the distinction be vacuous?"
4934,@GaryMarcus,2022-05-08 21:12:40+00:00,https://twitter.com/GaryMarcus/status/1523410581230809088,"I am confused. Can you clarify @ylecu? earlier today you said that the question about hybrid models was vacuous. but here you state that you do not believe in mixing deep learning with classical symbolic modules. 

that raises three questions:"
4935,@GaryMarcus,2022-05-08 21:03:32+00:00,https://twitter.com/GaryMarcus/status/1523408280579575808,"@MuzafferKal_ @ChombaBupe @ylecun @RTomMcCoy @wjb_003 @Tesla it‚Äôs an excellent paper but not proof that these problems are solved, in my judgement, but rather (excellent) motivation to consider alternative directions."
4936,@GaryMarcus,2022-05-08 20:44:33+00:00,https://twitter.com/GaryMarcus/status/1523403504051654656,"@raphaelmilliere @ylecun @RTomMcCoy @MuzafferKal_ @wjb_003 @Tesla @AvilaGarcez @luislamb @barneyp @sir_deenicus @ChombaBupe @AllysonEttinger @_dieuwke_ @swarat @chrmanning @AI4Code which boils down to a mapping question: does any given architecture handle compositionality, and if yes does it do in an importantly different way?"
4937,@GaryMarcus,2022-05-08 20:42:58+00:00,https://twitter.com/GaryMarcus/status/1523403107589271552,"@RTomMcCoy @MuzafferKal_ @ylecun @wjb_003 @Tesla I argued that symbolic manipulation  (viz operations over variables, type-token distinction, structured hierarchical operations) were critical but that they were not sufficient, and that integrating them with neural level components was essential."
4938,@GaryMarcus,2022-05-08 20:18:33+00:00,https://twitter.com/GaryMarcus/status/1523396960513798145,@ylecun @RTomMcCoy @MuzafferKal_ @wjb_003 @Tesla @AvilaGarcez @luislamb @barneyp @sir_deenicus @ChombaBupe @AllysonEttinger @_dieuwke_ @swarat @chrmanning @AI4Code @raphaelmilliere
4939,@GaryMarcus,2022-05-08 20:05:57+00:00,https://twitter.com/GaryMarcus/status/1523393788827242497,"@RTomMcCoy @MuzafferKal_ @ylecun @wjb_003 @Tesla well, it remains to be seen if they can ‚Äúdiscover them‚Äù without important predisposing structure 

from cogsci perspective a key question is whether alternative systems *maps* perfectly on symbolic system, piggybacks on, or does something altogether different, etc."
4940,@GaryMarcus,2022-05-08 20:04:06+00:00,https://twitter.com/GaryMarcus/status/1523393324559699968,@RTomMcCoy @MuzafferKal_ @ylecun @wjb_003 @Tesla no that‚Äôs certainly not what i argued.
4941,@GaryMarcus,2022-05-08 20:03:33+00:00,https://twitter.com/GaryMarcus/status/1523393184998379520,@ylecun @RTomMcCoy @MuzafferKal_ @wjb_003 @Tesla tagging some others who have thought a lot about these issues: @AvilaGarcez @luislamb @barneyp @sir_deenicus @ChombaBupe @AllysonEttinger @_dieuwke_ @swarat @chrmanning @AI4Code
4942,@GaryMarcus,2022-05-08 20:01:33+00:00,https://twitter.com/GaryMarcus/status/1523392684781555712,"@ylecun @RTomMcCoy @MuzafferKal_ @wjb_003 @Tesla I agree on this too, to a point. compatibility is critical; gradients i would say are important but may not be the right tool in all situations, eg in handling quantification and negation."
4943,@GaryMarcus,2022-05-08 19:46:41+00:00,https://twitter.com/GaryMarcus/status/1523388942774505472,"@RTomMcCoy @MuzafferKal_ @ylecun @wjb_003 @Tesla how is that different from what I argued in the Algebraic Mind?  (not a rhetorical question)

I do think this line of discussion has potential to be productive."
4944,@GaryMarcus,2022-05-08 19:44:37+00:00,https://twitter.com/GaryMarcus/status/1523388419354759169,"@RTomMcCoy @MuzafferKal_ @ylecun @wjb_003 @Tesla if you have an explicit set of operations over variables (and some neural components) you have a hybrid system., consistent w @AvilaGarcez and @luislamb and how the Algebraic Mind was framed; one of my core arguments was that some systems lack those operations, at their peril."
4945,@GaryMarcus,2022-05-08 19:20:36+00:00,https://twitter.com/GaryMarcus/status/1523382376029581312,"@PBeekums @TheDailyShow I am here for you, @Trevornoah"
4946,@GaryMarcus,2022-05-08 19:19:50+00:00,https://twitter.com/GaryMarcus/status/1523382185629081600,"@filippie509 @ylecun As always, I would welcome substantive, ad hominem free debate moderated by a neutral party."
4947,@GaryMarcus,2022-05-08 18:09:32+00:00,https://twitter.com/GaryMarcus/status/1523364492029030401,@MuzafferKal_ @ylecun @wjb_003 @Tesla @RTomMcCoy i didn‚Äôt really read your paper as anti-hybrid.
4948,@GaryMarcus,2022-05-08 18:07:56+00:00,https://twitter.com/GaryMarcus/status/1523364092156596225,"@ak_panda @ylecun @wjb_003 @Tesla ad hominem, that is. autocorrect ain‚Äôt so good with Latin, despite the context."
4949,@GaryMarcus,2022-05-08 18:06:17+00:00,https://twitter.com/GaryMarcus/status/1523363676056481792,"@ak_panda @ylecun @wjb_003 @Tesla this is the key point: as hominem keeps us from discussing the substantive scientific issues, and that impairs progress"
4950,@GaryMarcus,2022-05-08 18:03:05+00:00,https://twitter.com/GaryMarcus/status/1523362870817304577,"@ylecun @wjb_003 @Tesla turning this into a string of ad hominem attacks in no way gets eg to the question of how one recognizes a hybrid system or distinguishes it from pure rules or pure deep learning.

it‚Äôs just a sideshow."
4951,@GaryMarcus,2022-05-08 18:01:48+00:00,https://twitter.com/GaryMarcus/status/1523362546463301632,"@ylecun @wjb_003 @Tesla i am under NDA but at least can say that what you say is factually incorrect, inasmuch as I didn‚Äôt have resources that are anything like what you have or apparently imagine that I had, and that I was in no way in charge."
4952,@GaryMarcus,2022-05-08 17:58:35+00:00,https://twitter.com/GaryMarcus/status/1523361735196889089,"in 2012, I predicted deep learning would need to be part of an ensemble &amp; have trouble with causal reasoning, abstraction, and language understanding https://t.co/Saj5BjkOwN 

in 2016, driverless cars would be far more difficult than generally assumed https://t.co/eLbmoHoQhm"
4953,@GaryMarcus,2022-05-08 17:53:00+00:00,https://twitter.com/GaryMarcus/status/1523360331367518208,"as ever, trying to bully me out of speaking up.

and again ignoring the literature that explains why the debate is not vacuous but in fact critical"
4954,@GaryMarcus,2022-05-08 17:51:04+00:00,https://twitter.com/GaryMarcus/status/1523359845373464578,"@ylecun @wjb_003 @Tesla you have all the resources in the world. I don‚Äôt.

but that doesn‚Äôt make your approach correct."
4955,@GaryMarcus,2022-05-08 17:22:00+00:00,https://twitter.com/GaryMarcus/status/1523352529144217600,"@AVMiceliBarone @ylecun @Tesla read my Next Decade in AI; i say that neurosymbolic is not enough. necessary, not sufficient 

mobileeye AEBS btw is hybrid and is perhaps best in class; Alpha* with MCTS (symbolic) better than without 

but loads of work left to do and realism is needed"
4956,@GaryMarcus,2022-05-08 17:17:27+00:00,https://twitter.com/GaryMarcus/status/1523351385579810816,"@scottiev exactly, misleading"
4957,@GaryMarcus,2022-05-08 17:16:56+00:00,https://twitter.com/GaryMarcus/status/1523351254583316483,"@ak_panda @SabulTheThief @ylecun @Tesla that‚Äôs the objective, for some"
4958,@GaryMarcus,2022-05-08 17:15:53+00:00,https://twitter.com/GaryMarcus/status/1523350989939478529,"@scottiev showing that Teslas are safer than the average, less expensive, older car doesn‚Äôt establish anything in particular."
4959,@GaryMarcus,2022-05-08 17:14:25+00:00,https://twitter.com/GaryMarcus/status/1523350623562829826,@ylecun @Tesla this is hugely dismissive a vast body of work from @luislamb @AvilaGarcez myself and many others. and also wrong.
4960,@GaryMarcus,2022-05-08 17:12:17+00:00,https://twitter.com/GaryMarcus/status/1523350085697826816,@AVMiceliBarone @ylecun @Tesla no doubt. that‚Äôs what is startling about all the pushback i get.
4961,@GaryMarcus,2022-05-08 17:07:58+00:00,https://twitter.com/GaryMarcus/status/1523348997259231232,"@scottiev 10x than what, at what? source? have yet to see proper scientific comparisons across broad range of conditions"
4962,@GaryMarcus,2022-05-08 17:04:42+00:00,https://twitter.com/GaryMarcus/status/1523348179051159554,and @frossi_t
4963,@GaryMarcus,2022-05-08 17:04:16+00:00,https://twitter.com/GaryMarcus/status/1523348069965701120,"@AvilaGarcez, that is"
4964,@GaryMarcus,2022-05-08 17:03:02+00:00,https://twitter.com/GaryMarcus/status/1523347756336644096,"nonsense.

a pure deep learning system with no symbol systems (eg for knowledge, rules, tree search) is not a hybrid system. 

a pure rule system is not a hybrid system.

neurosymbolic community understands this, eg @luislamb @garcez @hitzler @neurobongo @rossi @swarat @barneyp"
4965,@GaryMarcus,2022-05-08 16:57:13+00:00,https://twitter.com/GaryMarcus/status/1523346292595826690,@pgolding I will pass that to @togelius
4966,@GaryMarcus,2022-05-08 16:54:53+00:00,https://twitter.com/GaryMarcus/status/1523345707159105536,"@wjb_003 @ylecun @Tesla i have laid out definitions of neurosymbolic hybrids, but Yann has not engaged with them."
4967,@GaryMarcus,2022-05-08 16:52:17+00:00,https://twitter.com/GaryMarcus/status/1523345053384552449,"Substack, or Medium? something else?"
4968,@GaryMarcus,2022-05-08 16:52:17+00:00,https://twitter.com/GaryMarcus/status/1523345050620416000,"There is so much to say about this I think I need to start a blog. 

Please see poll below. (ps next release of @Twitter should allow polls inside of quote tweets, along with edit button)"
4969,@GaryMarcus,2022-05-08 16:47:15+00:00,https://twitter.com/GaryMarcus/status/1523343785219952643,@mosesjones what‚Äôs that mean here? hinton used that metaphor for radiology
4970,@GaryMarcus,2022-05-08 16:44:16+00:00,https://twitter.com/GaryMarcus/status/1523343033294413824,"@recursus @lathropa also even then it is far from straightforward. lidar helps but still lots of false alarms; fusing multiple streams isn‚Äôt trivial, etc"
4971,@GaryMarcus,2022-05-08 16:42:11+00:00,https://twitter.com/GaryMarcus/status/1523342508847075328,@recursus @lathropa but Tesla refuses to use lidar ü§∑‚Äç‚ôÇÔ∏è
4972,@GaryMarcus,2022-05-08 15:36:12+00:00,https://twitter.com/GaryMarcus/status/1523325906713948168,@pstAsiatech @nutanc @ylecun @Tesla @Meta @elonmusk see second pgh here:
4973,@GaryMarcus,2022-05-08 15:33:54+00:00,https://twitter.com/GaryMarcus/status/1523325327551782918,"@recursus @lathropa perhaps eg because otherwise they would be stopping excessively for a lot of leaves, random noise, birds, etc?"
4974,@GaryMarcus,2022-05-08 15:31:56+00:00,https://twitter.com/GaryMarcus/status/1523324832254857218,"@scottiev so many apples and oranges here i don‚Äôt know where to begin.
- best AEB I am told is from MobileEye, which takes a different approach
- automatic braking ‚â† L5 autonomy
- Tesla doesn‚Äôt release intervention numbers so hard to compare on full autonomy"
4975,@GaryMarcus,2022-05-08 15:27:46+00:00,https://twitter.com/GaryMarcus/status/1523323783750189056,@Eric__Brown__13 lot of that going round
4976,@GaryMarcus,2022-05-08 15:04:47+00:00,https://twitter.com/GaryMarcus/status/1523318000635420672,"that‚Äôs it, fight anecdotal data &amp; videos with ‚Ä¶ anecdotal data &amp; videos üôÑ

ps it is not AEB or AI research I object to, but names like AutoSteer, AutoPilot, and Full Self Driving, coupled with reality that these are still immature technologies that don‚Äôt merit such names."
4977,@GaryMarcus,2022-05-08 14:50:27+00:00,https://twitter.com/GaryMarcus/status/1523314391663276032,"@ylecun @Tesla You obviously never read a single one of the papers of mine that you have been criticizing. 

One thing for you to disagree, another to show a lack of awareness of what the person you disagree with is saying."
4978,@GaryMarcus,2022-05-08 14:48:01+00:00,https://twitter.com/GaryMarcus/status/1523313779240423425,"The case for hybrid AI: 

‚Äú*any* complete AI system, even one built around a big neural net, will have all kinds of other code around it. It's particularly true of systems designed to act in the real-world.‚Äù

Amazed @ylecun said this, after scolding me for years for saying same"
4979,@GaryMarcus,2022-05-08 14:39:17+00:00,https://twitter.com/GaryMarcus/status/1523311582071066624,@dcallahan2 california
4980,@GaryMarcus,2022-05-08 14:38:56+00:00,https://twitter.com/GaryMarcus/status/1523311492099051521,"@yzilber @chirping_ai @EvaSmartAI i agree, and at some point the systems will be reliable enough that this is *the* relevant argument. but we aren‚Äôt near that point yet."
4981,@GaryMarcus,2022-05-08 10:16:46+00:00,https://twitter.com/GaryMarcus/status/1523245519136456704,@ylecun @Tesla https://t.co/pNdFqEgp2B
4982,@GaryMarcus,2022-05-08 06:54:32+00:00,https://twitter.com/GaryMarcus/status/1523194623459401728,@BrandonLive @yzilber agree on all of these points
4983,@GaryMarcus,2022-05-08 06:51:04+00:00,https://twitter.com/GaryMarcus/status/1523193749387370496,"@Teejip @ykilcher @ylecun the stats themselves are misleading, eg they should compare Teslas w other late model luxury cars. 

and they don‚Äôt *support* the bit i quoted, since they show in fact that AI is far from reliably hitting obstacles."
4984,@GaryMarcus,2022-05-08 06:47:03+00:00,https://twitter.com/GaryMarcus/status/1523192739986169856,@yzilber @EvaSmartAI yes but for now they can‚Äôt be trusted
4985,@GaryMarcus,2022-05-08 06:46:31+00:00,https://twitter.com/GaryMarcus/status/1523192606435414016,"my take on whole thread: @brandonlive makes many good points about how Tesla‚Äôs software should be used (cautiously &amp; with detailed knowledge of the subsystems); 

@Aiaddict1 has made vivid why one needs to proceed w caution &amp; not listen to the hype.

Each has important lessons."
4986,@GaryMarcus,2022-05-08 06:40:35+00:00,https://twitter.com/GaryMarcus/status/1523191113804263424,"@yzilber @EvaSmartAI proper comparison data have not been published so far as i know; there are a zillion confounds and also very little. actually testing of level 5 without humans in the loop.

which is why intervention rates are still used as a mediocre proxy afaik"
4987,@GaryMarcus,2022-05-08 06:37:57+00:00,https://twitter.com/GaryMarcus/status/1523190450114285568,@Teejip @ykilcher @ylecun it‚Äôs a screenshot.
4988,@GaryMarcus,2022-05-08 06:35:23+00:00,https://twitter.com/GaryMarcus/status/1523189803532963840,"doubtful. companies that release intervention rates in CA have numbers that are nowhere near as good as humans. Tesla doesn‚Äôt release those rates, leading many to wonder.

driverless cars will some day exceed humans but for now face too many outlier problems to be on par."
4989,@GaryMarcus,2022-05-08 06:30:37+00:00,https://twitter.com/GaryMarcus/status/1523188605232959488,"üíØ. and ditto for any autonomous driving system that isn‚Äôt a monorail, for the near term future."
4990,@GaryMarcus,2022-05-08 06:28:34+00:00,https://twitter.com/GaryMarcus/status/1523188087118962688,@BrandonLive @MNWH @olcan that was the point üôÇ
4991,@GaryMarcus,2022-05-08 06:24:46+00:00,https://twitter.com/GaryMarcus/status/1523187132126220288,"@BrandonLive @MNWH @olcan i sure hope not. but what if he didn‚Äôt and he is showing that even an expert like you can overestimate the system in certain circumstances?
(eg off premapped roads etc)"
4992,@GaryMarcus,2022-05-08 06:21:58+00:00,https://twitter.com/GaryMarcus/status/1523186426656935937,"@BrandonLive @MNWH @olcan hmm how about calling it ‚ÄúHighway Lane Keeping‚Äù, then?"
4993,@GaryMarcus,2022-05-08 06:16:05+00:00,https://twitter.com/GaryMarcus/status/1523184948898766848,"@ykilcher @ylecun and lordy i have endless tapes of @ylecun attacking me without tagging me, etc."
4994,@GaryMarcus,2022-05-08 06:13:57+00:00,https://twitter.com/GaryMarcus/status/1523184410647879682,@ykilcher @ylecun he did; someone sent me a screenshot: https://t.co/1QAuXZf0O6
4995,@GaryMarcus,2022-05-08 06:07:26+00:00,https://twitter.com/GaryMarcus/status/1523182770079473664,@BrandonLive @Aiaddict1 @charleswangb is there a convenient diagram illustrating what is what?
4996,@GaryMarcus,2022-05-08 06:04:07+00:00,https://twitter.com/GaryMarcus/status/1523181937170386944,"@BrandonLive @Aiaddict1 @charleswangb you shouldn‚Äôt need a PhD to understand which systems are which. &amp; in fact I have a PhD and am finding the names vs capabilities hard to follow. 

many seem to imply full autonomy; none in fact deliver that.

and then you have @meta‚Äôs chief AI officer alleging AI never crashes üôÑ"
4997,@GaryMarcus,2022-05-08 05:58:40+00:00,https://twitter.com/GaryMarcus/status/1523180563116355585,@BrandonLive @Aiaddict1 @charleswangb the lay interpretation is that the car steers for you. period. per discussion above it‚Äôs actually scope is far more limited.
4998,@GaryMarcus,2022-05-08 05:51:42+00:00,https://twitter.com/GaryMarcus/status/1523178809985445889,@BrandonLive @Aiaddict1 @charleswangb pilots know that but most consumers don‚Äôt (&amp; lack the training pilots have)
4999,@GaryMarcus,2022-05-08 05:47:17+00:00,https://twitter.com/GaryMarcus/status/1523177698356436994,"@BrandonLive @Aiaddict1 @charleswangb hmm; the very name ‚Äúautopilot‚Äù implies a generality to the system that is lacking; likewise Musk‚Äôs 60 Minutrs hands-free demo invites users to have high expectations, to say nothing of the name FSD, and I am not sure consumers can be expected to track each component of the system"
5000,@GaryMarcus,2022-05-08 05:41:50+00:00,https://twitter.com/GaryMarcus/status/1523176326097563649,"This post of my mine, pointing to a video by @Aiaddict1, has led to lively discussion, worth reading. 
- the video does not assess the capacities of the not yet publicly released FSD beta
- it does vividly highlight importance of testing robustness of driving AI against outliers"
5001,@GaryMarcus,2022-05-08 04:57:38+00:00,https://twitter.com/GaryMarcus/status/1523165202849533953,"please note that this video is not made with the not-yet-publicly released FSD Beta, which could of course do better on some or all of these test (or not ‚Äì it‚Äôs a empirical question)."
5002,@GaryMarcus,2022-05-08 04:44:54+00:00,https://twitter.com/GaryMarcus/status/1523161998501900288,"@BrandonLive @charleswangb so if here not on a supported pre-mapped highway, that extra mode would not be available? important to get the facts clear here; ccing @Aiaddict1"
5003,@GaryMarcus,2022-05-08 04:43:06+00:00,https://twitter.com/GaryMarcus/status/1523161547677204480,"Not accurate, again. MobileEye system INCLUDES a camera and convnet, but it‚Äôs actually a complex hybrid model, which doesn‚Äôt come through in this characterization.

Deep learning needs some help, in other words."
5004,@GaryMarcus,2022-05-08 04:40:41+00:00,https://twitter.com/GaryMarcus/status/1523160941130444800,"@ylecun @Tesla i have confirmed through very knowledgeable sources that the Intel/MobileEye system is indeed a complex hybrid system, in which convnets are only part of what‚Äôs going on."
5005,@GaryMarcus,2022-05-08 03:58:23+00:00,https://twitter.com/GaryMarcus/status/1523150292790898689,"@dontmeanathing agree that all companies are struggling with the problem (though Tesla has presented some of the most aggressive claims about what they have, hence get more attention)"
5006,@GaryMarcus,2022-05-08 03:44:47+00:00,https://twitter.com/GaryMarcus/status/1523146873057415169,"@mattocko clearest test of outliers i have seen; results frightening. imagine if there 1000x cars with FSD daily, over-trusted by their users."
5007,@GaryMarcus,2022-05-08 03:40:21+00:00,https://twitter.com/GaryMarcus/status/1523145756516880384,if only the real Elon Musk were paying attention: https://t.co/bATKrtZ9OP
5008,@GaryMarcus,2022-05-08 03:24:47+00:00,https://twitter.com/GaryMarcus/status/1523141839338975232,"@nutanc @ylecun @Tesla yes, he really said that, mainly to score cheap points against my suggestion that deep learning is (with respect to compositionality and outliers) is hitting a wall. 

agree it is disturbing that a major executive at @Meta would say something that inaccurate, w lives at stake."
5009,@GaryMarcus,2022-05-08 03:16:27+00:00,https://twitter.com/GaryMarcus/status/1523139741784313859,@khademinori @jalalirs and add Lidar until the AI is far more robust
5010,@GaryMarcus,2022-05-08 03:10:33+00:00,https://twitter.com/GaryMarcus/status/1523138255427833856,"@khademinori precisely because @Aiaddict1 tested *outliers*, which is exactly what current AI struggles with. it was a public service to make that point clear."
5011,@GaryMarcus,2022-05-08 03:03:38+00:00,https://twitter.com/GaryMarcus/status/1523136516385505280,"@Adhiguna_AIaaS it‚Äôs the best test of outliers in FSD I have seen, by @Aiaddict1."
5012,@GaryMarcus,2022-05-08 02:53:49+00:00,https://twitter.com/GaryMarcus/status/1523134046129188864,"@ylecun @Tesla also, btw, is it a pure convnet or a hybrid system?"
5013,@GaryMarcus,2022-05-08 02:42:38+00:00,https://twitter.com/GaryMarcus/status/1523131230711025664,"@ylecun @Tesla don‚Äôt doubt that the particular statistic but this part is simply not factual: ‚Äúcars with AI-powered driving assistance aren't hitting walls, or anything else, either.‚Äù"
5014,@GaryMarcus,2022-05-08 02:37:36+00:00,https://twitter.com/GaryMarcus/status/1523129965591470080,"@schrep @ylecun @Tesla and also this: https://t.co/zXSxt6zQyg

look forward to a similar outlier test for the Mercedes."
5015,@GaryMarcus,2022-05-08 02:35:42+00:00,https://twitter.com/GaryMarcus/status/1523129485192667137,"What Objects Can Tesla Avoid? 

Obstacle avoidance with unusual object, in 2022 

Warning: Not for the faint of heart! https://t.co/zXSxt6zQyg"
5016,@GaryMarcus,2022-05-08 02:31:50+00:00,https://twitter.com/GaryMarcus/status/1523128514962026497,@alhallaj0 @ylecun @Tesla wow!
5017,@GaryMarcus,2022-05-07 20:46:56+00:00,https://twitter.com/GaryMarcus/status/1523041714247593984,@schrep @ylecun @Tesla any public data on performance during trials?
5018,@GaryMarcus,2022-05-07 19:46:04+00:00,https://twitter.com/GaryMarcus/status/1523026398176153600,"today, @ylecun: ‚ÄúNot only is AI not ""hitting a wall"", ¬†cars with AI-powered driving assistance aren't hitting walls, or anything else, either.‚Äù

@tesla, last week: oops"
5019,@GaryMarcus,2022-05-07 19:40:55+00:00,https://twitter.com/GaryMarcus/status/1523025101779730432,@crazyuddie @RWerpachowski it‚Äôs worse than that; i will explain in a future essay
5020,@GaryMarcus,2022-05-07 19:37:08+00:00,https://twitter.com/GaryMarcus/status/1523024150528348162,it attacked @danbri‚Äôs commentary on GPT-3 saying where‚Äôs your model and source code.
5021,@GaryMarcus,2022-05-07 18:24:40+00:00,https://twitter.com/GaryMarcus/status/1523005912201322496,Since 2012!
5022,@GaryMarcus,2022-05-07 16:59:29+00:00,https://twitter.com/GaryMarcus/status/1522984474979405829,"Prediction: the next decade will turn out to be filled with premature and unverified claims of achieving AGI, just like the last decade was filled with premature and unverified claims about imminent self-driving cars.

Question: What will be the ‚Äúsafety driver‚Äù of the 2020‚Äôs?"
5023,@GaryMarcus,2022-05-07 16:55:45+00:00,https://twitter.com/GaryMarcus/status/1522983537846087680,@cumulyst the two work together in very unfortunate ways
5024,@GaryMarcus,2022-05-07 16:53:05+00:00,https://twitter.com/GaryMarcus/status/1522982867365597184,"The aggression of people who don‚Äôt understand science, distilled.

No, nobody can say yet how to get AI to think about objects, forces, &amp; agents.

What we can say is that a field that hounds people for trying to isolate which problems needs to be solved is f__ked. https://t.co/CQEzd3SGHa"
5025,@GaryMarcus,2022-05-07 15:07:17+00:00,https://twitter.com/GaryMarcus/status/1522956241701531648,@tanepiper @AI4Code @oralassila @bengoertzel
5026,@GaryMarcus,2022-05-07 14:53:22+00:00,https://twitter.com/GaryMarcus/status/1522952740036435968,"Seriously, this is the future. current Ml *assumes* that large language models are key to building Safe AI‚Äîand focus w such narrowness they are missing many of the ideas we actually need. 

Few open themselves to alternatives.  

Kids like @AI4Code‚Äô daughter may be our best hope."
5027,@GaryMarcus,2022-05-07 14:24:38+00:00,https://twitter.com/GaryMarcus/status/1522945505583460352,"@danbri @alexmilowski I don‚Äôt think anybody is dismissing them fully as a technology, but many of us our advising caution in anything where is serious potential for harm. 

And I am very concerned about the narrowing of focus."
5028,@GaryMarcus,2022-05-07 13:29:18+00:00,https://twitter.com/GaryMarcus/status/1522931582222290944,fantastic!
5029,@GaryMarcus,2022-05-07 13:18:42+00:00,https://twitter.com/GaryMarcus/status/1522928913604702208,resist the temptation; therein madness lies.
5030,@GaryMarcus,2022-05-07 03:47:53+00:00,https://twitter.com/GaryMarcus/status/1522785265462304768,it‚Äôs gonna be wild when we hook this up to the air traffic control API
5031,@GaryMarcus,2022-05-07 03:43:40+00:00,https://twitter.com/GaryMarcus/status/1522784201040228352,"@Belisarius02139 @pmddomingos not saying it was Science‚Äôs finest hour, or above criticism, just that it was a reasonable topic to cover‚Ä¶"
5032,@GaryMarcus,2022-05-07 03:35:21+00:00,https://twitter.com/GaryMarcus/status/1522782108770439169,@sir_deenicus @isabellelle3490 @OpenAI nor like it is good thing to perpetuate historical bias.
5033,@GaryMarcus,2022-05-07 03:34:18+00:00,https://twitter.com/GaryMarcus/status/1522781843744993280,"@bengoertzel no doubt; but bigger ladders aren‚Äôt getting us to the moon, just to taller buildings‚Ä¶"
5034,@GaryMarcus,2022-05-07 00:43:06+00:00,https://twitter.com/GaryMarcus/status/1522738759514558464,"@rijulg @OpenAI bet it doesn‚Äôt work that well, and even if it did it is still problematic, as that requires manual intervention, and the default is bias."
5035,@GaryMarcus,2022-05-07 00:41:30+00:00,https://twitter.com/GaryMarcus/status/1522738359403114496,ha ha we already know the answer but this is actually a great interview
5036,@GaryMarcus,2022-05-06 22:32:39+00:00,https://twitter.com/GaryMarcus/status/1522705930525151232,"@MLOptBlog @terrible_archer you should ask @ylecun, who said that to me (and who was quoted here, with irony). many of his fans thought it was perfectly appropriate, admirable even. 

not a sign of health science, IMHO"
5037,@GaryMarcus,2022-05-06 22:25:29+00:00,https://twitter.com/GaryMarcus/status/1522704128979324928,@Plinz @jacobaustin132 @Miles_Brundage @OpenAI wouldn‚Äôt a word processor work better for that? ü§£
5038,@GaryMarcus,2022-05-06 21:41:55+00:00,https://twitter.com/GaryMarcus/status/1522693166192685056,Imagine if someone had thought to ask a hundred years ago why there weren‚Äôt more women in orchestras? Would this have been the response?
5039,@GaryMarcus,2022-05-06 21:38:09+00:00,https://twitter.com/GaryMarcus/status/1522692218296934401,"@Belisarius02139 @pmddomingos did you even read the contents? it‚Äôs a ‚Äúspecial news focus‚Äù, not the whole issue, and just once out of over a century of publishing as weekly magazine. üôÑ"
5040,@GaryMarcus,2022-05-06 20:05:36+00:00,https://twitter.com/GaryMarcus/status/1522668926135545856,@sd_marlow @Inoryy @karpathy it might be SOTA but it probably ain‚Äôt AGI :)
5041,@GaryMarcus,2022-05-06 19:29:28+00:00,https://twitter.com/GaryMarcus/status/1522659831487864833,@Inoryy @karpathy will you allow the community to try it out?
5042,@GaryMarcus,2022-05-06 19:28:47+00:00,https://twitter.com/GaryMarcus/status/1522659661207453697,"@jacobaustin132 @Miles_Brundage @OpenAI fact that community is making  progress on benchmarks doesn‚Äôt address what would count as evidence against/how community would come to accept it was making an error if it was. 

have yet to see a paper acknowledge the idea that LLMs are good tools for alignment is a *hypothesis*"
5043,@GaryMarcus,2022-05-06 19:25:38+00:00,https://twitter.com/GaryMarcus/status/1522658869339693056,"@jacobaustin132 @Miles_Brundage @OpenAI i meant ‚Äúgood tool for achieving alignment‚Äù.

they are a good testbed‚Äîif we accept the premise that LLMs are the only option, but if we don‚Äôt, we might be optimizing the wrong things, following wrong gradient and accepting an illusion of progress that is actually irrelevant. 1/"
5044,@GaryMarcus,2022-05-06 19:20:40+00:00,https://twitter.com/GaryMarcus/status/1522657619743227907,"@Plinz @jacobaustin132 @Miles_Brundage @OpenAI i agree @plinz, but eg i am comfortable w not wanting machines recommending genocide or suicide; slippery slope arguments can prove too mich, and the current architectures are a long way from anything that there might be strong consensus around"
5045,@GaryMarcus,2022-05-06 18:43:22+00:00,https://twitter.com/GaryMarcus/status/1522648233251590145,@Miles_Brundage @jacobaustin132 @OpenAI hybrid for the win
5046,@GaryMarcus,2022-05-06 18:42:13+00:00,https://twitter.com/GaryMarcus/status/1522647941076369413,@KwekuOA @TrendsCognSci @mldoing excited to read!
5047,@GaryMarcus,2022-05-06 18:05:53+00:00,https://twitter.com/GaryMarcus/status/1522638796629622785,"@Miles_Brundage @jacobaustin132 @OpenAI i will ask again: is the hypothesis that LLMs are a good tool for alignment falsifiable? what would evidence against that hypothesis look like, if it existed? 

‚â† has it been solved, but rather if LLMs were on wrong track, how would community recognize that fact?"
5048,@GaryMarcus,2022-05-06 18:03:23+00:00,https://twitter.com/GaryMarcus/status/1522638169593847809,"@jacobaustin132 @Miles_Brundage @OpenAI thanks, I am aware of all this work, but  left wondering how you define ‚Äúfairly safe‚Äù, and what the scope of fairly safe is. there is a very broad range of things to which LLMs can be applied and most of what I sees to consist of band-aids that may have little generality"
5049,@GaryMarcus,2022-05-06 17:52:26+00:00,https://twitter.com/GaryMarcus/status/1522635413130825728,"@Miles_Brundage @OpenAI well eg on honesty InstructGPT makes up experts with narratives about socks and meditation‚Ä¶ 

if it turned out that language models simply weren‚Äôt the right tool, would the LLM community admit this? what would lead them to do so?"
5050,@GaryMarcus,2022-05-06 17:50:22+00:00,https://twitter.com/GaryMarcus/status/1522634893414576129,@Miles_Brundage @OpenAI what do you think is the biggest progress? i haven‚Äôt seen anything that feels compelling.
5051,@GaryMarcus,2022-05-06 17:49:05+00:00,https://twitter.com/GaryMarcus/status/1522634571514327045,see my pinned tweet
5052,@GaryMarcus,2022-05-06 16:46:59+00:00,https://twitter.com/GaryMarcus/status/1522618944489590784,@kelkalot @danbri (my brief exploration: https://t.co/DLdgMIX1Gn)
5053,@GaryMarcus,2022-05-06 16:43:09+00:00,https://twitter.com/GaryMarcus/status/1522617980131045376,@kelkalot @danbri thanks!
5054,@GaryMarcus,2022-05-06 16:15:38+00:00,https://twitter.com/GaryMarcus/status/1522611053065949184,"@nlpnyc @danbri @gdb agreed, but also noting the same kind of ‚Äúuse a bunch of phrases without being particularly compositional‚Äù behavior that @benjamin_hilton and Davis, Aaronson, and I, a review on Less Wrong, all noted."
5055,@GaryMarcus,2022-05-06 16:13:59+00:00,https://twitter.com/GaryMarcus/status/1522610638433882113,"@kelkalot @danbri somewhat similar, the at women is represented more like with women"
5056,@GaryMarcus,2022-05-06 16:13:29+00:00,https://twitter.com/GaryMarcus/status/1522610510994104322,"@danbri @kelkalot though, note, it is salad laughing, but not so evidently salad laughing at women."
5057,@GaryMarcus,2022-05-06 16:12:04+00:00,https://twitter.com/GaryMarcus/status/1522610157087166464,@kelkalot @danbri can you show us the full output (10 guesses)?
5058,@GaryMarcus,2022-05-06 15:39:00+00:00,https://twitter.com/GaryMarcus/status/1522601833759268864,"@_serajuddin @OpenAI @Abebab @WIRED i think they certainly have tried, hard; my own view is that the problem is inherent to LLM‚Äôs and only solvable via carefully constructed external mechanisms that themselves will need a fair degree of intelligence."
5059,@GaryMarcus,2022-05-06 14:27:16+00:00,https://twitter.com/GaryMarcus/status/1522583781055492097,"#deeplepning hitting the wall of compositionality and distribution shift, yet again."
5060,@GaryMarcus,2022-05-06 14:24:51+00:00,https://twitter.com/GaryMarcus/status/1522583174550761473,@_serajuddin @OpenAI and see spot-on tweet from @Abebab 7 months ago that i just tweeted; even in the context of this specific model the issue has already been quite clear for a while.
5061,@GaryMarcus,2022-05-06 14:22:47+00:00,https://twitter.com/GaryMarcus/status/1522582654792593408,"from DALL-E‚Äôs 2 predecessor/underlying tech, as pointed out by @abebab 7 months ago. 

none of this is news."
5062,@GaryMarcus,2022-05-06 14:20:50+00:00,https://twitter.com/GaryMarcus/status/1522582164142919686,@_serajuddin @OpenAI and btw where were you when the CEO and CTO were demonizing me? just curious
5063,@GaryMarcus,2022-05-06 14:19:54+00:00,https://twitter.com/GaryMarcus/status/1522581929932902400,@_serajuddin @OpenAI the field has had seven years and billions of dollars; it‚Äôs time to consider alternative approaches - and to be realistic that big data alone will not solve these problems
5064,@GaryMarcus,2022-05-06 14:09:23+00:00,https://twitter.com/GaryMarcus/status/1522579281422929920,@_serajuddin @OpenAI nice thread on one facet of this:
5065,@GaryMarcus,2022-05-06 14:08:49+00:00,https://twitter.com/GaryMarcus/status/1522579138351038464,@jacobandreas @alexandersclark agreed: this is about function composition (which is not my particular focus but very important in its own right)
5066,@GaryMarcus,2022-05-06 14:05:25+00:00,https://twitter.com/GaryMarcus/status/1522578284852117505,@kharijohnson @wired
5067,@GaryMarcus,2022-05-06 14:03:07+00:00,https://twitter.com/GaryMarcus/status/1522577706117828610,"@_serajuddin @OpenAI it‚Äôs a much more generalized version of the original problem; to OpenAI credit they didn‚Äôt release into the wild, but from what I gather it‚Äôs rampant throughout the system."
5068,@GaryMarcus,2022-05-06 13:59:55+00:00,https://twitter.com/GaryMarcus/status/1522576897628008455,@jacobandreas @belindazli (&amp; @jacobandreas please follow back/DM)
5069,@GaryMarcus,2022-05-06 13:57:54+00:00,https://twitter.com/GaryMarcus/status/1522576393107693568,"@jacobandreas would be exciting if you would consider wrt to universally quantified one-to-one mappings, per discussion in Chapter 3 of The Algebraic Mind.

2/2"
5070,@GaryMarcus,2022-05-06 13:57:08+00:00,https://twitter.com/GaryMarcus/status/1522576196856287233,"@jacobandreas for clarity, would definitely call it function composition rather than (linguistic) compositionality, which is eg poor in DALL-E2 per my recent arxiv w Davis and Aaronson. But yes function composition is itself interesting.

1/2"
5071,@GaryMarcus,2022-05-06 13:44:54+00:00,https://twitter.com/GaryMarcus/status/1522573118182547456,"üëâRemember the 2015 Google gorilla scandal? This @OpenAI is worse
üëâ7 years on, big tech isn‚Äôt close to solving bias problems, &amp; there is still no framework for building values into machines
üëâInvestments &amp; hype far outstrip tangible progress in ethical AI
https://t.co/VCI87HOHKY"
5072,@GaryMarcus,2022-05-06 13:02:25+00:00,https://twitter.com/GaryMarcus/status/1522562429774827520,@jacobandreas what do you mean by compositional here?
5073,@GaryMarcus,2022-05-05 21:01:17+00:00,https://twitter.com/GaryMarcus/status/1522320551498244097,@omaruddin @ESYudkowsky @gregeganSF these are the moments in which i love twitter.  thanks @omarruddin @besttrousers!
5074,@GaryMarcus,2022-05-05 20:58:28+00:00,https://twitter.com/GaryMarcus/status/1522319843898232832,"Sci Fi fans, 
For an essay on AI risk, I am wondering if there any episodes/novels etc where  (eg) the Star Trek computer, if it were tampered with/malfunctioned, might have came close to making error, deliberate or accidental, with massive consequences.
@ESYudkowsky @gregeganSF"
5075,@GaryMarcus,2022-05-05 15:46:16+00:00,https://twitter.com/GaryMarcus/status/1522241275428175873,@ogibuntens not actually true. getting customers what they want as fast as possible has always been their goal. they‚Äôve just decided to accept the cost of this sort of error. which is fine for merchandise but not the other areas I mentioned.
5076,@GaryMarcus,2022-05-05 14:27:13+00:00,https://twitter.com/GaryMarcus/status/1522221382402150403,"Replicating Amazon‚Äôs semantic search fail, this time with ‚Äúalkaline c cell batteries‚Äù in quote marks (4 pages into Prime results).

What could possibly go wrong, when we start connecting this tech to mission-critical APIs, in defense, aviation, cybersecurity, infrastructure?

üò± https://t.co/JuvWxOW6Yu"
5077,@GaryMarcus,2022-05-05 14:19:38+00:00,https://twitter.com/GaryMarcus/status/1522219472676786178,"@EduardoCGarriM why: lack of semantics, lack of innateness. i have written extensively on these issues; 2018, 2020, 3 articles in Arxiv, several articles in @gradientpub, and 2019 book https://t.co/Pt7HZbLIv5"
5078,@GaryMarcus,2022-05-05 14:16:36+00:00,https://twitter.com/GaryMarcus/status/1522218711343529990,"@DylanoRepublic @maayanvisuals not really my area, alas"
5079,@GaryMarcus,2022-05-05 14:01:20+00:00,https://twitter.com/GaryMarcus/status/1522214867591000064,"Provocative new paper!
- engages deeply in substance of compositionality
- converges w my view that Transformers &amp; CNNs will not suffice
- outlines important neurosymbolic alternative that would make compositionality more explicit, but also require development of new architecture"
5080,@GaryMarcus,2022-05-05 04:30:01+00:00,https://twitter.com/GaryMarcus/status/1522071091513991168,"maybe large language models just shouldn‚Äôt be our future, @stevenbjohnson @DoronWeber"
5081,@GaryMarcus,2022-05-05 01:15:11+00:00,https://twitter.com/GaryMarcus/status/1522022058791608320,@DylanoRepublic @maayanvisuals (not sure your acronyms)
5082,@GaryMarcus,2022-05-04 22:58:49+00:00,https://twitter.com/GaryMarcus/status/1521987743223451648,"@cheeesio infants likely have strong bias, towards a language that maps syntax onto semantics w strong grammatical regularities, tied to a cognitive system biased towards representations of time, space, object, agency etc. 

literature on language and cognitive universals supports this."
5083,@GaryMarcus,2022-05-04 20:32:45+00:00,https://twitter.com/GaryMarcus/status/1521950982116036609,"‚ÄúShared Interest helped a dermatologist quickly see examples of a program‚Äôs ‚Ä¶ predictions ‚Ä¶ Ultimately, the dermatologist decided he could not trust the program because it made too many predictions based on unrelated details rather than actual lesions‚Äù https://t.co/fliPWonWCY"
5084,@GaryMarcus,2022-05-04 17:57:35+00:00,https://twitter.com/GaryMarcus/status/1521911933959516162,@jason_pontin @schrep @kareem_carr @WiringTheBrain @ProfSimonFisher the book had a huge and lasting influence on me.  might be time to get the 2nd ed!
5085,@GaryMarcus,2022-05-04 17:52:20+00:00,https://twitter.com/GaryMarcus/status/1521910612703338497,@Zergylord @LucaAmb what‚Äôs required?
5086,@GaryMarcus,2022-05-04 17:48:27+00:00,https://twitter.com/GaryMarcus/status/1521909637531897856,@jason_pontin @schrep @kareem_carr @WiringTheBrain @ProfSimonFisher a favorite book but sadly not with me at the moment‚Ä¶.
5087,@GaryMarcus,2022-05-04 16:18:29+00:00,https://twitter.com/GaryMarcus/status/1521886993361252353,@LucaAmb anything that passed my 2014 Comprehension Challenge would impress a lot of people very quickly.
5088,@GaryMarcus,2022-05-04 16:10:42+00:00,https://twitter.com/GaryMarcus/status/1521885034302504960,@LucaAmb and yet people gave us grief for even *asking* whether it was progress. https://t.co/omqcXPRCkl
5089,@GaryMarcus,2022-05-04 16:06:18+00:00,https://twitter.com/GaryMarcus/status/1521883927392047104,@matthewcobb @WiringTheBrain @schrep @kareem_carr @ProfSimonFisher @jason_pontin ha ha ha! the prize survived! the research didn‚Äôt.
5090,@GaryMarcus,2022-05-04 15:50:13+00:00,https://twitter.com/GaryMarcus/status/1521879883126755330,"@LucaAmb what‚Äôs the progress, and why does the progress extend beyond domain-specific techniques for image composition,into *general* intelligence?

metacomment: you can‚Äôt blame me for evaluating whether it is progress, and then think and say it is progress and also say nobody said it is!"
5091,@GaryMarcus,2022-05-04 15:43:45+00:00,https://twitter.com/GaryMarcus/status/1521878255585751041,"@nlpnyc @LucaAmb for sure; i will repeat, does DALL-E get us closer to AGI?

we got attacked for even *asking* that question, yet it is what you ask here."
5092,@GaryMarcus,2022-05-04 15:42:17+00:00,https://twitter.com/GaryMarcus/status/1521877886340194305,"@LucaAmb and, worse, progress by @AI21Labs  has gone largely unnoticed, amid the hype for DALL-E"
5093,@GaryMarcus,2022-05-04 15:39:51+00:00,https://twitter.com/GaryMarcus/status/1521877273409822720,@LucaAmb is DALLE progress towards AGI?
5094,@GaryMarcus,2022-05-04 15:39:13+00:00,https://twitter.com/GaryMarcus/status/1521877112667353089,@LucaAmb surely there was a causal connection implied
5095,@GaryMarcus,2022-05-04 15:37:03+00:00,https://twitter.com/GaryMarcus/status/1521876567080640512,"@LucaAmb and many at least temporarily recalibrated, thinking that DALL-E had implications for the future that it did not"
5096,@GaryMarcus,2022-05-04 15:36:19+00:00,https://twitter.com/GaryMarcus/status/1521876384309678080,@LucaAmb hype is the fuel by which to lock us into a local minimum
5097,@GaryMarcus,2022-05-04 15:35:56+00:00,https://twitter.com/GaryMarcus/status/1521876287547006979,@LucaAmb https://t.co/tfA5qvim44
5098,@GaryMarcus,2022-05-04 15:34:28+00:00,https://twitter.com/GaryMarcus/status/1521875918578364416,@LucaAmb https://t.co/7vNQQRNryF
5099,@GaryMarcus,2022-05-04 15:34:01+00:00,https://twitter.com/GaryMarcus/status/1521875805587984384,"@LucaAmb NYT headline, which we now know to be false, said DALL-E ‚Äúdraws anything at your command‚Äù (in truth it struggles with many complex requests)"
5100,@GaryMarcus,2022-05-04 15:32:21+00:00,https://twitter.com/GaryMarcus/status/1521875386426134528,@LucaAmb Zaremba: https://t.co/HDeAUdLmG4
5101,@GaryMarcus,2022-05-04 15:31:08+00:00,https://twitter.com/GaryMarcus/status/1521875079679725568,"@LucaAmb not so. 45 minutes after announcing it, Sam Altmann said ‚ÄúAGI is gonna be wild‚Äù; Greg Brockman posted DALL-E dreaming of AGI. Somebody posted (since retracted) an essay on how DALL-E and PaLM had shortened their AGI timelines; many on twitter snickered that wall had been broken"
5102,@GaryMarcus,2022-05-04 15:12:46+00:00,https://twitter.com/GaryMarcus/status/1521870455778410496,"John Doerr just gave about 10% of his fortune to climate change. ‚Å¶

Would love to see other wealthy individuals match that proportion.  https://t.co/Fac8oc5gFx"
5103,@GaryMarcus,2022-05-04 14:59:46+00:00,https://twitter.com/GaryMarcus/status/1521867186737872896,"@schrep @kareem_carr @LukeZettlemoyer ps the troubles thus far in shipping reliable Level 5 autonomous driving highlight the challenges in playing whack-a-mole with edge cases in open-ended domains. 

the more open-ended domain, the more the need for different approaches."
5104,@GaryMarcus,2022-05-04 14:36:39+00:00,https://twitter.com/GaryMarcus/status/1521861368516730880,"for more detail on the ‚Äúfiddly‚Äù training reality that @schrep is referring to, see new arxiv by @metaai @LukeZettlemoyer and others: https://t.co/EITWnqevnE especially section 2.5"
5105,@GaryMarcus,2022-05-04 14:31:23+00:00,https://twitter.com/GaryMarcus/status/1521860042592423937,"@schrep @kareem_carr @LukeZettlemoyer glad Meta isn‚Äôt all in, but it is clear that overall industry / investment / media hype is wildly asymmetric."
5106,@GaryMarcus,2022-05-04 14:28:51+00:00,https://twitter.com/GaryMarcus/status/1521859402868817923,"@schrep @kareem_carr @LukeZettlemoyer agreed, though with all the attendant problems of toxicity, bias, misinformation, unreliability, etc.

it‚Äôs a maximum-for now-but still a local maximum."
5107,@GaryMarcus,2022-05-04 14:27:01+00:00,https://twitter.com/GaryMarcus/status/1521858944225845250,"The fiddly nature of training large language models is rarely acknowledged out loud, but distilled beautifully here by @schrep, for many years CTO @ Facebook. 

Importantly, human children reliably learn language across wildly varying inputs."
5108,@GaryMarcus,2022-05-04 14:15:58+00:00,https://twitter.com/GaryMarcus/status/1521856163377123329,"@schrep @kareem_carr @LukeZettlemoyer ‚ÄúIn summary, we still believe this technology is premature for commercial deployment.‚Äù, https://t.co/EITWnqevnE, end of Section 5"
5109,@GaryMarcus,2022-05-04 14:13:09+00:00,https://twitter.com/GaryMarcus/status/1521855453684109312,@schrep @kareem_carr @LukeZettlemoyer was referring to the limits section of the OPT-175 report.
5110,@GaryMarcus,2022-05-04 14:10:11+00:00,https://twitter.com/GaryMarcus/status/1521854705453785089,"@schrep @kareem_carr imagine if people had said the same about deep learning and CIFAR had not continued to fund Hinton, Bengio and LeCun before they had SOTA results.

A121‚Äôs MRKL, the symbolic victory at NetHack, @nukkailab1‚Äôs victory in bridge are all good reasons to add serious fuel to hybrid AI"
5111,@GaryMarcus,2022-05-04 14:05:08+00:00,https://twitter.com/GaryMarcus/status/1521853434953039872,"@schrep @kareem_carr @WiringTheBrain @ProfSimonFisher can you help with the first question - what are the biggest things that came from the pee-Avery period in which people incorrectly thought that genes were made of proteins? 

(@jason_pontin can you channel Horace Judson here?)"
5112,@GaryMarcus,2022-05-04 14:01:33+00:00,https://twitter.com/GaryMarcus/status/1521852534834425856,"@schrep @kareem_carr Not pure wasted effort. But the value real, semantic AGI that could reason and build dynamic cognitive models would likely vastly exceed the (nontrivial) value of what we can get out of LLMs, which are unlikely ever to be trustworthy, interpretable, or reliable."
5113,@GaryMarcus,2022-05-04 13:55:15+00:00,https://twitter.com/GaryMarcus/status/1521850948770926592,@schrep @kareem_carr Given the $ investment and the conclusion of yesterday‚Äôs report from @LukeZettlemoyer and co‚Äî‚Äúnot ready for deployment‚Äù‚Äî a rational strategy would support more diversification. but investment is the least diverse/most assymetric it has been in a long time.
5114,@GaryMarcus,2022-05-04 13:50:38+00:00,https://twitter.com/GaryMarcus/status/1521849788060233728,@schrep @kareem_carr historical parallel is 4 decades trying to explain genes in terms of proteins; correct hypothesis (DNA) was dismissed for decades.
5115,@GaryMarcus,2022-05-04 13:48:37+00:00,https://twitter.com/GaryMarcus/status/1521849278104145922,"@schrep @kareem_carr we are getting to a position in which the asymmetry in the economics makes it essentially impossible for other approaches to compete, in terms of computational resources and access to talent.

we are thus fast climbing the LLM mountain but it may well prove a costly local minimum"
5116,@GaryMarcus,2022-05-04 00:19:28+00:00,https://twitter.com/GaryMarcus/status/1521645648948334592,"No reason to limit this (or AI research in general) to large language models, but this is a good new benchmark to consider, focusing on updating knowledge in a dynamic world."
5117,@GaryMarcus,2022-05-03 21:24:54+00:00,https://twitter.com/GaryMarcus/status/1521601720970743808,@sama https://t.co/OUG7rlc2mi
5118,@GaryMarcus,2022-05-03 21:24:33+00:00,https://twitter.com/GaryMarcus/status/1521601632101826560,"You have an example of this, @sama? 

I have pointed to same things for 20 years; my record is clear.

The redefined goalposts I see are moving to hard-to-evaluate jokes &amp; artworks‚Äîinstead of reliable language, scene comprehension &amp; reasoning, which were always the goal of A(G)I."
5119,@GaryMarcus,2022-05-03 21:18:48+00:00,https://twitter.com/GaryMarcus/status/1521600183632494592,Looks like this list is going to need to be updated.  https://t.co/rw1DVbRT7Z
5120,@GaryMarcus,2022-05-03 20:43:13+00:00,https://twitter.com/GaryMarcus/status/1521591228084621312,"@unixpickle @charleswangb @Plinz Indeed. From a cognitive (neuro)science perspective, the question is whether that stuff is infrastructure to build a simulation of  a system that itself doesn‚Äôt require symbolic computation, or whether that stuff is an essential part of the computation itself."
5121,@GaryMarcus,2022-05-03 18:42:14+00:00,https://twitter.com/GaryMarcus/status/1521560782017728512,"universally good advice, too rarely followed"
5122,@GaryMarcus,2022-05-03 17:55:43+00:00,https://twitter.com/GaryMarcus/status/1521549077724364800,@ImageSnippets @kevinabosch please rt the above for a machine v human comparison
5123,@GaryMarcus,2022-05-03 17:49:14+00:00,https://twitter.com/GaryMarcus/status/1521547443040505857,Game on!
5124,@GaryMarcus,2022-05-03 16:18:51+00:00,https://twitter.com/GaryMarcus/status/1521524698684682240,"üëá @charleswangb challenges @plinz‚Äôs claim that deep learning is a general problem solving mechanism

Wang is right; proudest accomplishments of deep learning (AlphaFold, AlphaStar, etc) *leverage symbolic tools* like Monte Carlo Tree Search, and would not succeed otherwise."
5125,@GaryMarcus,2022-05-02 20:55:14+00:00,https://twitter.com/GaryMarcus/status/1521231867499884544,"@drjwrae @benjamin_hilton ooh, sick burn! except that actually I *did* foresee these problems in 2001 in The Algebraic Mind, a 2012 New Yorker article, and my 2018 Deep Learning: A Critical Appraisal, among others. 

So spotting a typo isn‚Äôt much of answer."
5126,@GaryMarcus,2022-05-02 15:45:00+00:00,https://twitter.com/GaryMarcus/status/1521153790723772416,"Thoughts and prayers for the deep learning fanboys who believe every new press release &amp; lack initiative to be skeptical.

The idea that DALL-E shattered AGI wall of language understanding was nonsense

-thread by @benjamin_hilton
-https://t.co/b5blfHcwh3
-https://t.co/DLdgMIX1Gn"
5127,@GaryMarcus,2022-05-02 13:38:30+00:00,https://twitter.com/GaryMarcus/status/1521121956396822528,@knutson_brain @legalBA not to the same degree :)
5128,@GaryMarcus,2022-05-02 13:30:49+00:00,https://twitter.com/GaryMarcus/status/1521120022298464256,"How much does DALL-E have to do with AGI? Maybe not so much, after all‚Ä¶ A lesson in caveat emptor: https://t.co/DLdgMIX1Gn https://t.co/JHCJlA7a2e"
5129,@GaryMarcus,2022-05-02 13:12:54+00:00,https://twitter.com/GaryMarcus/status/1521115515111968774,@terrible_archer @ethancaballero @irinarish are you saying AGI will be here or that people will believe that it will come?
5130,@GaryMarcus,2022-05-02 03:18:18+00:00,https://twitter.com/GaryMarcus/status/1520965879667650561,@tdietterich @PyVitor ouch
5131,@GaryMarcus,2022-05-02 02:39:33+00:00,https://twitter.com/GaryMarcus/status/1520956126971383808,@tdietterich @PyVitor based on what evidence? i would be surprised if they can do so robustly.
5132,@GaryMarcus,2022-05-02 01:02:29+00:00,https://twitter.com/GaryMarcus/status/1520931700544471040,and also consistent with concerns I expressed to @sama @gdb @openAI and @plinz re compositionality and orthographic generalization
5133,@GaryMarcus,2022-05-02 00:58:21+00:00,https://twitter.com/GaryMarcus/status/1520930658079494144,also consistent with my earlier guesses: https://t.co/Hbyx5DwGNe
5134,@GaryMarcus,2022-05-02 00:54:34+00:00,https://twitter.com/GaryMarcus/status/1520929707545423872,@CadeMetz
5135,@GaryMarcus,2022-05-02 00:49:23+00:00,https://twitter.com/GaryMarcus/status/1520928402533797889,Very consistent with Benjamin Hilton‚Äôs independent analysis: https://t.co/VrVWmDKtlb
5136,@GaryMarcus,2022-05-02 00:47:38+00:00,https://twitter.com/GaryMarcus/status/1520927962593259520,"Preliminary analysis of the language and commonsense reasoning behind DALL-E 2,with @ErnestSDavis and Scott Aaronson. https://t.co/DLdgMIX1Gn, focusing on compositionality, commonsense and complex requests."
5137,@GaryMarcus,2022-05-01 21:00:29+00:00,https://twitter.com/GaryMarcus/status/1520870800240168960,"@Plinz @BerndPorr @charleswangb @dpwaters when you start using those external systems instead of deep learning alone, you‚Äôve got yourself a hybrid system, which is a step in the right direction. 

the wall is to be able to use those external systems seamlessly and reliably"
5138,@GaryMarcus,2022-05-01 20:33:50+00:00,https://twitter.com/GaryMarcus/status/1520864090184318976,"This is a great opportunity, because heart of doing science on deep learning models is understanding generalization, by comparing the results with training data, and #EleutherAI‚Äôs training data is open. 

@yasaman_razeghi and @sameer_‚Äòs key recent study relied on exactly that."
5139,@GaryMarcus,2022-05-01 18:05:05+00:00,https://twitter.com/GaryMarcus/status/1520826658567057408,"Look ma, no lidar!"
5140,@GaryMarcus,2022-05-01 16:03:11+00:00,https://twitter.com/GaryMarcus/status/1520795982786482176,"March 2015: ‚ÄúElon Musk Says Self-Driving Tesla Cars Will Be in the U.S. by Summer‚Äù
April 2022: Elon Musk say we may have driverless cars within a year.
Also April 2022: Tesla on autopilot crashes into parked jet in large, mostly empty parking lot."
5141,@GaryMarcus,2022-05-01 15:58:44+00:00,https://twitter.com/GaryMarcus/status/1520794860910833664,"@nirsd there may or may not be important innovation on the scene synthesis side; I do not see it as an advance towards general intelligence, and will say more about this soon."
5142,@GaryMarcus,2022-05-01 15:45:37+00:00,https://twitter.com/GaryMarcus/status/1520791560723439616,"i‚Äôll believe it when I can play with it. Everybody freaked out about DALL-E2, and it turns out to have lots of serious problems on the language side

Cherry-picked examples are never a proof of anything."
5143,@GaryMarcus,2022-05-01 15:40:22+00:00,https://twitter.com/GaryMarcus/status/1520790238288695296,"What do horses, airplanes, and humans carrying stop signs all have in common?"
5144,@GaryMarcus,2022-04-30 22:02:01+00:00,https://twitter.com/GaryMarcus/status/1520523895710703616,The edge cases just keep on coming‚Ä¶
5145,@GaryMarcus,2022-04-30 21:56:06+00:00,https://twitter.com/GaryMarcus/status/1520522407257145344,"@Plinz @BerndPorr Funny how almost all of that, eg ‚Äú represents a shift from generating solutions not via human reasoning but via automated search‚Äù could have been a quote from pretty much any one of the founders of AI, eg Herb Simon."
5146,@GaryMarcus,2022-04-30 21:04:04+00:00,https://twitter.com/GaryMarcus/status/1520509311167778816,for once @plinz and I fully agree.
5147,@GaryMarcus,2022-04-30 20:29:38+00:00,https://twitter.com/GaryMarcus/status/1520500648013312001,funny that‚Äôs exactly the same as the number of radiologists replaced.  and the number of taxi drivers replaced.
5148,@GaryMarcus,2022-04-30 19:20:57+00:00,https://twitter.com/GaryMarcus/status/1520483362418216960,"I have made the same argument for 21 years because the same problems remain. 

Ad hominem, name-calling, satire, and massively larger data have not solved them. 

Better and better ladders still aren‚Äôt getting deep learning to the moon."
5149,@GaryMarcus,2022-04-30 17:34:45+00:00,https://twitter.com/GaryMarcus/status/1520456636191498240,"@alyssamvance when there are billions being spent on A it‚Äôs very hard to generate enough $ to investigate anything else, because in short term 1000x investment will usually win; it‚Äôs a recipe for a local minimum.

closest historical parallel might be decades lost thinking genes were proteins."
5150,@GaryMarcus,2022-04-30 17:07:59+00:00,https://twitter.com/GaryMarcus/status/1520449900550389761,@alyssamvance https://t.co/Z7QIlo6AEB
5151,@GaryMarcus,2022-04-30 17:06:50+00:00,https://twitter.com/GaryMarcus/status/1520449609713156096,"yes! overinvestment in a single approach‚Äîlarge language models, with their demonstrable challenges with toxicity, misinformation, counseling harm, unreliability, etc‚Äîis shocking. 

i admire the goals of EA but spending billions on a single approach cannot be a good idea."
5152,@GaryMarcus,2022-04-30 16:30:13+00:00,https://twitter.com/GaryMarcus/status/1520440396295249920,@Roozbeh_Sanaei2 @Abel_TorresM @mpshanahan @fhuszar @BVLSingler @ylecun @DeepMind at generating hype.
5153,@GaryMarcus,2022-04-30 13:29:28+00:00,https://twitter.com/GaryMarcus/status/1520394908443430913,"#youhadjustonejob, C batteries with Amazon‚Äôs semantic search ü§¶‚Äç‚ôÇÔ∏è https://t.co/CKE3U3QjOW"
5154,@GaryMarcus,2022-04-30 13:11:18+00:00,https://twitter.com/GaryMarcus/status/1520390338786959360,"@_serajuddin @dontmeanathing No, the technology is not there yet. That‚Äôs just wrong."
5155,@GaryMarcus,2022-04-30 04:58:49+00:00,https://twitter.com/GaryMarcus/status/1520266398001336322,"@renatrigiorese @titudeadjust sure tools to assist, drivers, radiologists, programmers. 

replace? not anytime soon."
5156,@GaryMarcus,2022-04-30 04:57:33+00:00,https://twitter.com/GaryMarcus/status/1520266080349868034,@dontmeanathing if i had a nickel for every taxi driver and radiologist that was going to be replaced by machine by 2022‚Ä¶
5157,@GaryMarcus,2022-04-30 03:51:12+00:00,https://twitter.com/GaryMarcus/status/1520249381957427201,"Oh, come on."
5158,@GaryMarcus,2022-04-29 22:46:16+00:00,https://twitter.com/GaryMarcus/status/1520172644045590528,@idavidstout demo is cool but it‚Äôs hard to know what to make of it without trying it out.
5159,@GaryMarcus,2022-04-29 22:28:56+00:00,https://twitter.com/GaryMarcus/status/1520168283139604480,i wish we were ‚Äúonly‚Äù 580M away from AI we can trust.
5160,@GaryMarcus,2022-04-29 20:21:28+00:00,https://twitter.com/GaryMarcus/status/1520136202741075968,"@seth_stafford I am very familiar with that paper, and played an assist in its existence :)  

the reasons why LLM community disregards linguistics are complex and ultimately cause a lot of time and money to be wasted IMHO."
5161,@GaryMarcus,2022-04-29 19:54:27+00:00,https://twitter.com/GaryMarcus/status/1520129406429138945,"@seth_stafford Minds map syntax into semantics, exact mechanism still unknown. LLMs fake it, without really constructing an interrogable semantics, and that just can‚Äôt be right, and all their problems with truthiness, toxicity, harmful advice &amp; incoherence flow from that starting point."
5162,@GaryMarcus,2022-04-29 05:10:17+00:00,https://twitter.com/GaryMarcus/status/1519906898396426240,"@emilymbender not sure this is a fair characterization of @ericjang11‚Äôs post. 

he is entitled to want to spend his time on AGI, and to want to work with a company that has a good probability of succeeding; rational to assess likely obstacles (eg misaligned insurance incentives) along the way"
5163,@GaryMarcus,2022-04-28 23:48:40+00:00,https://twitter.com/GaryMarcus/status/1519825957984432128,@kevin2kelly @blakehounshell happy birthday and thanks for the great list!
5164,@GaryMarcus,2022-04-28 20:15:15+00:00,https://twitter.com/GaryMarcus/status/1519772250865500160,@benoitfrenay that‚Äôs exactly what i am arguing for; not duplication of humans but learning broadly from what the cognitive sciences etc have to offer.
5165,@GaryMarcus,2022-04-28 18:27:48+00:00,https://twitter.com/GaryMarcus/status/1519745213031346176,"@IntuitMachine they try to shortcut all these steps, w prediction as weak proxy, so wind up w toxicity, harmful advice, misinformation, etc, and no ability to reference or acquire stable ground truth.

there is nothing like a translation into a linguist‚Äôs logical form; no Gricean pragmatic, etc"
5166,@GaryMarcus,2022-04-28 18:21:35+00:00,https://twitter.com/GaryMarcus/status/1519743648732049408,and all of this is mediated through compositionality
5167,@GaryMarcus,2022-04-28 18:18:10+00:00,https://twitter.com/GaryMarcus/status/1519742786584473600,@IntuitMachine @stanislavfort https://t.co/8NQeFTti3O
5168,@GaryMarcus,2022-04-28 18:16:23+00:00,https://twitter.com/GaryMarcus/status/1519742336598564864,"@benoitfrenay if you don‚Äôt take the time to understand natural intelligence, how are you even going to understand the user‚Äôs needs, assuming your users are humans? it‚Äôs a pipe dream to think that current approaches are ever going to achieve reliable alignment."
5169,@GaryMarcus,2022-04-28 18:13:37+00:00,https://twitter.com/GaryMarcus/status/1519741643129188352,"Syntax maps onto meaning; meaning is mapped onto (imperfect) representations of the world. Common ground with interlocutors is fundamental to interpreting meaning in context.

= foundational ideas from linguistics that are largely omitted in the large language model approach."
5170,@GaryMarcus,2022-04-28 18:07:01+00:00,https://twitter.com/GaryMarcus/status/1519739982398644224,@stanislavfort ps ‚Äúcare deeply‚Äù ‚â†¬†slavish mimicry
5171,@GaryMarcus,2022-04-28 18:04:19+00:00,https://twitter.com/GaryMarcus/status/1519739303219277824,"@stanislavfort i don‚Äôt doubt that the details will differ, but the Wright brothers learned something from avian control, and the LLM community is listening way too little to linguistics‚Ä¶"
5172,@GaryMarcus,2022-04-28 17:53:03+00:00,https://twitter.com/GaryMarcus/status/1519736466858905600,"@LucaAmb agreed, and quote tweeted with another dichotomy in the same spirit :)"
5173,@GaryMarcus,2022-04-28 17:52:40+00:00,https://twitter.com/GaryMarcus/status/1519736369022521344,"There are two kinds of AI researchers, those who care deeply about how natural intelligence works, and those who think that they don‚Äôt need to, so long as they have enough data and compute."
5174,@GaryMarcus,2022-04-28 16:53:16+00:00,https://twitter.com/GaryMarcus/status/1519721421236170756,"even from his own perspective, this is a mistake."
5175,@GaryMarcus,2022-04-28 14:21:16+00:00,https://twitter.com/GaryMarcus/status/1519683170752339970,Exactly why I keep saying ‚Äúit will take a village to create AI we can trust‚Äù:
5176,@GaryMarcus,2022-04-27 12:52:52+00:00,https://twitter.com/GaryMarcus/status/1519298534826160129,@loretoparisi not surprised. did you collect any systematic data?
5177,@GaryMarcus,2022-04-27 12:52:12+00:00,https://twitter.com/GaryMarcus/status/1519298366626181120,@meme_machines would be curious to see the demos
5178,@GaryMarcus,2022-04-26 22:23:26+00:00,https://twitter.com/GaryMarcus/status/1519079736428793857,@yudapearl @luislamb @emilymbender @AvilaGarcez @plevy @kerstingAIML what i wrote about this recently:
5179,@GaryMarcus,2022-04-26 19:05:04+00:00,https://twitter.com/GaryMarcus/status/1519029812576194560,@yudapearl @AthenaAI2 @anilkseth @_pierreblanc @ylecun @StanDehaene @ach3d @lau_devil @Quecalcoatle @Aurelie_JEAN @ygourven @hubertguillaud @olivez @KirkDBorne @le_science4all @freakonometrics @nntaleb @tunguz @IntuitMachine @babgi @EvanKirstel @USBEKetRICA @ycaseau logically possible but not available now or in the next decade or two at any price
5180,@GaryMarcus,2022-04-26 18:50:45+00:00,https://twitter.com/GaryMarcus/status/1519026210155638784,"@yudapearl @IntuitMachine @_pierreblanc @ylecun @StanDehaene @ach3d @lau_devil @Quecalcoatle @Aurelie_JEAN @ygourven @hubertguillaud @olivez @KirkDBorne @le_science4all @freakonometrics @nntaleb @tunguz @babgi @EvanKirstel @USBEKetRICA @ycaseau ok, if by blueprint you mean ‚Äúhas partial access to a cognitive characterization of some of its internal states‚Äù (but not eg a flowchart or schematic), i can agree with that."
5181,@GaryMarcus,2022-04-26 18:00:42+00:00,https://twitter.com/GaryMarcus/status/1519013617189801984,"@yudapearl @IntuitMachine @_pierreblanc @ylecun @StanDehaene @ach3d @lau_devil @Quecalcoatle @Aurelie_JEAN @ygourven @hubertguillaud @olivez @KirkDBorne @le_science4all @freakonometrics @nntaleb @tunguz @babgi @EvanKirstel @USBEKetRICA @ycaseau surely not sufficient. modern chips are designed by algorithms that surely don‚Äôt feel compassion for the chips they design.

not sure it is necessary; most humans know little or nothing about their blueprints. that doesn‚Äôt preclude emotion and feeling."
5182,@GaryMarcus,2022-04-26 17:20:20+00:00,https://twitter.com/GaryMarcus/status/1519003457453133825,@sergeykarayev https://t.co/XPJGh7tWAh
5183,@GaryMarcus,2022-04-26 17:15:43+00:00,https://twitter.com/GaryMarcus/status/1519002296385871872,"Whether this is true depends on how much you value reliability and interpretability.

(And also the extent to which you might encounter edge cases and the amount of data you can collect, and the risks of bias, toxicity, and misinformation, among other factors.)"
5184,@GaryMarcus,2022-04-26 16:36:41+00:00,https://twitter.com/GaryMarcus/status/1518992472675799040,How a Shopping Mall Trip Inspired Me to Work in Neuro-Symbolic AI | Communications of the ACM by Asim Munawar ‚Å¶@IBMResearch‚Å©  https://t.co/HglRETDwcD
5185,@GaryMarcus,2022-04-26 13:56:29+00:00,https://twitter.com/GaryMarcus/status/1518952154588876801,@_rockt @DeepMind a coup for deepmind!
5186,@GaryMarcus,2022-04-26 07:53:27+00:00,https://twitter.com/GaryMarcus/status/1518860796272386049,@anilkseth @yudapearl @_pierreblanc @ylecun @StanDehaene @ach3d @lau_devil @Quecalcoatle @Aurelie_JEAN @ygourven @hubertguillaud @olivez @KirkDBorne @le_science4all @freakonometrics @nntaleb @tunguz @IntuitMachine @babgi @EvanKirstel @USBEKetRICA @ycaseau agreed
5187,@GaryMarcus,2022-04-26 07:37:19+00:00,https://twitter.com/GaryMarcus/status/1518856737612197888,"@ach3d @yudapearl @_pierreblanc @ylecun @StanDehaene @lau_devil @Quecalcoatle @Aurelie_JEAN @ygourven @hubertguillaud @olivez @KirkDBorne @le_science4all @freakonometrics @nntaleb @tunguz @IntuitMachine @babgi @EvanKirstel @USBEKetRICA @ycaseau fooling people for a few minutes isn‚Äôt much, because you can evade questions, but accurately and non evasive responses to a wide range of questions might indicate real progress in machine comprehension, per the 2014 New Yorker article I just linked."
5188,@GaryMarcus,2022-04-26 07:35:30+00:00,https://twitter.com/GaryMarcus/status/1518856278818271232,@yudapearl @_pierreblanc @ylecun @StanDehaene @ach3d @lau_devil @Quecalcoatle @Aurelie_JEAN @ygourven @hubertguillaud @olivez @KirkDBorne @le_science4all @freakonometrics @nntaleb @tunguz @IntuitMachine @babgi @EvanKirstel @USBEKetRICA @ycaseau that would be an immense leap forward in AI (extremely close to what I suggested here: https://t.co/4KLe1bU1YY) but I am still not sure it would get a machine to feeling anything.
5189,@GaryMarcus,2022-04-26 07:16:37+00:00,https://twitter.com/GaryMarcus/status/1518851528198529025,"@yudapearl @_pierreblanc @ylecun @StanDehaene @ach3d @lau_devil @Quecalcoatle @Aurelie_JEAN @ygourven @hubertguillaud @olivez @KirkDBorne @le_science4all @freakonometrics @nntaleb @tunguz @IntuitMachine @babgi @EvanKirstel @USBEKetRICA @ycaseau @anilkseth, thoughts?"
5190,@GaryMarcus,2022-04-26 07:00:42+00:00,https://twitter.com/GaryMarcus/status/1518847519500898304,@yudapearl @_pierreblanc @ylecun @StanDehaene @ach3d @lau_devil @Quecalcoatle @Aurelie_JEAN @ygourven @hubertguillaud @olivez @KirkDBorne @le_science4all @freakonometrics @nntaleb @tunguz @IntuitMachine @babgi @EvanKirstel @USBEKetRICA @ycaseau a machine recognizing that a person is happy or sad (somewhat plausible within limits with currently technology) is a long way from machine feeling happy or sad.
5191,@GaryMarcus,2022-04-25 20:04:05+00:00,https://twitter.com/GaryMarcus/status/1518682279626694656,@yudapearl @luislamb @emilymbender @AvilaGarcez @plevy @kerstingAIML no
5192,@GaryMarcus,2022-04-25 15:47:19+00:00,https://twitter.com/GaryMarcus/status/1518617662510682112,"@loretoparisi the architecture itself does not directly or adequately represent compositionality, for roughly the reasons anticipated in my 2001 book. the dataset is (presumably) vast."
5193,@GaryMarcus,2022-04-25 13:49:22+00:00,https://twitter.com/GaryMarcus/status/1518587979098255360,"With respect to misinformation and hate speech, Twitter should"
5194,@GaryMarcus,2022-04-23 19:31:11+00:00,https://twitter.com/GaryMarcus/status/1517949220816269313,"@Patapom2 British Columbia, not far from Vancouver"
5195,@GaryMarcus,2022-04-23 17:24:47+00:00,https://twitter.com/GaryMarcus/status/1517917414389739520,"@jasonlarkin841 ah i missed that, seeing it in a trending stream of unfair potshots at Gates."
5196,@GaryMarcus,2022-04-23 17:20:30+00:00,https://twitter.com/GaryMarcus/status/1517916335031824384,@SamTwits Funny how people dumping on Gates can play the irony card but people who think his net impact in last decade is positive can‚Äôt.
5197,@GaryMarcus,2022-04-23 17:09:20+00:00,https://twitter.com/GaryMarcus/status/1517913524487417856,"4,000 people liked this tweet. And can‚Äôt do math for sh_t."
5198,@GaryMarcus,2022-04-23 15:57:37+00:00,https://twitter.com/GaryMarcus/status/1517895475839569921,Bridge to Middle Earth? https://t.co/8rZEW6Tgbp
5199,@GaryMarcus,2022-04-23 13:26:40+00:00,https://twitter.com/GaryMarcus/status/1517857489542209536,love this thread and fully agree: the tide is about to change!
5200,@GaryMarcus,2022-04-23 00:48:44+00:00,https://twitter.com/GaryMarcus/status/1517666748941492224,excited to hear @seanmcarroll on the arrow of time!
5201,@GaryMarcus,2022-04-22 05:32:25+00:00,https://twitter.com/GaryMarcus/status/1517375751426744320,@wahid3111 @DrJasBerry @mohebial
5202,@GaryMarcus,2022-04-21 19:32:31+00:00,https://twitter.com/GaryMarcus/status/1517224782940442625,"all is fun and games until GPT-3 writes actual code.

oh wait, thats already happening."
5203,@GaryMarcus,2022-04-21 17:56:33+00:00,https://twitter.com/GaryMarcus/status/1517200631437561856,"@titudeadjust @asusarla @erikbryn @digitalarun @k_mcelheran @avicgoldfarb @GurbaxaniVijay @danielrock @SarahHBana a lone cherry-picked answer teaches us nothing, positive or negative‚Ä¶"
5204,@GaryMarcus,2022-04-21 17:18:55+00:00,https://twitter.com/GaryMarcus/status/1517191161579851777,"@_dieuwke_ Online alas, details coming shortly."
5205,@GaryMarcus,2022-04-21 17:18:01+00:00,https://twitter.com/GaryMarcus/status/1517190934202437644,Which is roughly how Elon Musk sees Twitter
5206,@GaryMarcus,2022-04-21 17:10:17+00:00,https://twitter.com/GaryMarcus/status/1517188986787139594,@agrover112 @Nikki_Tonks @stanfordnlp +1
5207,@GaryMarcus,2022-04-21 17:04:46+00:00,https://twitter.com/GaryMarcus/status/1517187598355075092,"This talk today by @_dieuwke_ Hupkes looks great, and by coincidence I will also be giving a talk at Stanford later today, touching on some of the same issues. 

Generalization is THE key issue in language and intelligence. 

[link for mine, 4:30PT https://t.co/6wuttkfXyv]"
5208,@GaryMarcus,2022-04-21 15:34:23+00:00,https://twitter.com/GaryMarcus/status/1517164853013540865,"@adelegoldberg1 @Ken_Goldberg @FelixHill84 @EmilyBender @CoulsonSeana @odessasgoldberg So far: Purely anecdotal. No replication.

There is a numerator but no denominator &amp; a lack of clear, full exposition.  It‚Äôs not first time a large language model has explained a joke; real question is whether it can do so reliably &amp; how far it can generalize from training."
5209,@GaryMarcus,2022-04-21 14:08:13+00:00,https://twitter.com/GaryMarcus/status/1517143169732800518,@Raza_Habib496 i suspect that in the range of covered domains it will be much better but that it is still a long way from AGI.
5210,@GaryMarcus,2022-04-21 14:04:18+00:00,https://twitter.com/GaryMarcus/status/1517142185786834944,@LucaAmb not inevitable but hard to avoid?
5211,@GaryMarcus,2022-04-21 06:57:49+00:00,https://twitter.com/GaryMarcus/status/1517034856244383744,i have been thinking a lot about mass delusion. this thread is truly a must-read.
5212,@GaryMarcus,2022-04-21 00:08:39+00:00,https://twitter.com/GaryMarcus/status/1516931885200338944,Ingesting foraging data. (video version!) @lcastricato https://t.co/Yx9PwY53dF
5213,@GaryMarcus,2022-04-20 19:11:18+00:00,https://twitter.com/GaryMarcus/status/1516857057441239040,"‚Äúbeta-frequency neural coherence transiently inhibits multiregional communication to flexibly coordinate natural behaviour.‚Äù - intriguing new paper from @pesaranlab. 

neural coordination across regions is critical for human cognition, language, perception, and motor control."
5214,@GaryMarcus,2022-04-20 18:16:55+00:00,https://twitter.com/GaryMarcus/status/1516843367396626438,terrific thread
5215,@GaryMarcus,2022-04-20 18:13:00+00:00,https://twitter.com/GaryMarcus/status/1516842383723274244,"@tribbloid @OriolVinyalsML will read, and welcome @yudapearl @eliasbareinboim @todd_gureckis to share theirs"
5216,@GaryMarcus,2022-04-20 16:56:12+00:00,https://twitter.com/GaryMarcus/status/1516823054466265090,"@BigAmeya the essence of operations over variables, which I keep harping on, is indeed just that: separating external memory (instantiating variables) from operations thereon, allow abstract logic, rather than just pure function approximation"
5217,@GaryMarcus,2022-04-20 16:54:41+00:00,https://twitter.com/GaryMarcus/status/1516822675498299395,"@BigAmeya puzzled by the word ""emergent"" in your title but in general this is consistent with what I advocated in The Algebraic Mind and I like the direction."
5218,@GaryMarcus,2022-04-20 16:09:24+00:00,https://twitter.com/GaryMarcus/status/1516811278114689026,"@oferron yes i agree on both points: we need a clearer explanation, and there is still a gap there"
5219,@GaryMarcus,2022-04-20 15:59:50+00:00,https://twitter.com/GaryMarcus/status/1516808871746039809,"What if there was a major step forward in the reliability of AI and it didn't fit the narrative of those in power? 

Would anyone notice?"
5220,@GaryMarcus,2022-04-20 14:04:52+00:00,https://twitter.com/GaryMarcus/status/1516779936962383874,"this new system from AI21 is *exactly* what I have been arguing for: Deep Learning as one tool among many, and it looks like it may signal a huge victory for Neurosymbolic hybrids over pure Large Language Models."
5221,@GaryMarcus,2022-04-20 02:14:05+00:00,https://twitter.com/GaryMarcus/status/1516601062873993216,"@Grady_Booch @IBM exactly the theme of my book Kluge, about human cognitive limitations"
5222,@GaryMarcus,2022-04-19 18:50:18+00:00,https://twitter.com/GaryMarcus/status/1516489382043078656,@jcbaillie @nukkailab1 I know!
5223,@GaryMarcus,2022-04-17 19:40:23+00:00,https://twitter.com/GaryMarcus/status/1515777212590354433,@raphaelmilliere @rgblong @OwainEvans_UK right: they aren‚Äôt literally stochastic parrots but they literally lack a semantics that can reasoned over.
5224,@GaryMarcus,2022-04-17 19:00:26+00:00,https://twitter.com/GaryMarcus/status/1515767156234862593,@raphaelmilliere @rgblong @OwainEvans_UK sure but there still ain‚Äôt a semantics that you can reason over
5225,@GaryMarcus,2022-04-17 17:19:20+00:00,https://twitter.com/GaryMarcus/status/1515741712768909315,"@OwainEvans_UK this is a narrow view of grammar, that ignores many traditions in linguistics that map form to meaning. 

matching the superficial syntax does not entail a grammar that relates syntax to meanings"
5226,@GaryMarcus,2022-04-17 17:17:37+00:00,https://twitter.com/GaryMarcus/status/1515741284106858498,"@rgblong @OwainEvans_UK because you can do pastiche a la a more sophisticated version of n-grams with an enormous window; as noted, this does not give you comprehension."
5227,@GaryMarcus,2022-04-17 14:25:16+00:00,https://twitter.com/GaryMarcus/status/1515697910708674560,@byed_it @DoronWeber @SloanPublic @stevenbjohnson @mer__edith @Wikipedia typo. large language model. sorry
5228,@GaryMarcus,2022-04-17 14:24:31+00:00,https://twitter.com/GaryMarcus/status/1515697720614342663,"@OwainEvans_UK and what remains unsolved? let‚Äôs ask both sides of the coin. 

in language, fluency has been solved, comprehension not."
5229,@GaryMarcus,2022-04-17 13:34:39+00:00,https://twitter.com/GaryMarcus/status/1515685169256022017,"@stevenbjohnson @DoronWeber @SloanPublic @mer__edith @Wikipedia Agree @stevenbjohnson that the single greatest problem with large language models is their tendency towards misinformation.

Such a challenge is likely fundamentally unsolvable within systems that lack stable databases and a model of the world."
5230,@GaryMarcus,2022-04-17 13:11:25+00:00,https://twitter.com/GaryMarcus/status/1515679323268603905,"@DoronWeber @SloanPublic @stevenbjohnson @mer__edith @Wikipedia you are presuming that they *can* be trained to be good citizens; because of inherent limits, i don‚Äôt think that they can be. 95% of current investment is in late language models; if it is good citizens we want, we need to invest in other architectures."
5231,@GaryMarcus,2022-04-16 17:02:15+00:00,https://twitter.com/GaryMarcus/status/1515375029172670466,"We have to ask ourselves, is this the AI we want?"
5232,@GaryMarcus,2022-04-16 16:48:01+00:00,https://twitter.com/GaryMarcus/status/1515371445836148741,"‚ÄúIf you spend enough time with GPT-3..you end up feeling as if you are interacting with a..prodigy whose brilliance is shadowed by.. limitations..clueless about many basic facts; prone to strange, senseless digressions; unencumbered by‚Ä¶social norms.‚Äú https://t.co/t2AByE4W8T"
5233,@GaryMarcus,2022-04-16 04:27:37+00:00,https://twitter.com/GaryMarcus/status/1515185119522443265,"@irinarish @sd_marlow nobody is remotely close to AGI, and one approach has had a cumulative investment of 1,000x all others put together. 

if that approach were actually at a local maximum, would we know, under such circumstances? or would the politics of the empowered shout down all else?"
5234,@GaryMarcus,2022-04-15 14:16:25+00:00,https://twitter.com/GaryMarcus/status/1514970907462098946,@_SilkeHahn @JonasAndrulis @Aleph__Alpha um the whole point of my @nautilusmag article was that we needed hybrid architectures
5235,@GaryMarcus,2022-04-15 13:28:22+00:00,https://twitter.com/GaryMarcus/status/1514958812901359618,@Zergylord @raphaelmilliere @kaushikpatnaik @OpenAI @GoogleAI @DeepMind @TristanThrush @mohitban47 @yasaman_razeghi @sameer_ wonder if people had conversations like these in the days of ELIZA
5236,@GaryMarcus,2022-04-15 13:27:42+00:00,https://twitter.com/GaryMarcus/status/1514958645993218052,"@jacyanthis Geoff Hinton, Yoshua Bengio etc have all publicly resisted symbols; i take @irinarish to think scaling is all we need. Everyone would agree we need curation."
5237,@GaryMarcus,2022-04-15 04:33:52+00:00,https://twitter.com/GaryMarcus/status/1514824302230589442,@Plinz @jscottwagner guaranteed way of getting stuck in a local minimum
5238,@GaryMarcus,2022-04-15 01:37:39+00:00,https://twitter.com/GaryMarcus/status/1514779955074273287,@raphaelmilliere @kaushikpatnaik @OpenAI @GoogleAI @DeepMind @TristanThrush @mohitban47 @yasaman_razeghi @sameer_ no argument can strongly be supported without denominators.
5239,@GaryMarcus,2022-04-14 21:08:13+00:00,https://twitter.com/GaryMarcus/status/1514712149536378887,@JoinAndrewNow no but it is certainly a nice argument for hybrid AI :)
5240,@GaryMarcus,2022-04-14 21:07:43+00:00,https://twitter.com/GaryMarcus/status/1514712023489155085,"@raphaelmilliere @kaushikpatnaik @OpenAI @GoogleAI @DeepMind @TristanThrush @mohitban47 @yasaman_razeghi @sameer_ it seems rather doubtful that memorization isn‚Äôt quite important, given the results i just cited and the failures on (the very few) systematic tests of binding.

and absurd that we are reduced to arguing over mainly cherry-picked examples."
5241,@GaryMarcus,2022-04-14 20:59:55+00:00,https://twitter.com/GaryMarcus/status/1514710064145207298,@raphaelmilliere @kaushikpatnaik @OpenAI @GoogleAI @DeepMind @TristanThrush @mohitban47 eg is there a ‚Äúthree dogs‚Äù with an associate picture? what if we try ‚Äú21 dogs‚Äù and there is no phrase directly represented in the training set? how much is compositing memorized images associated with specific phrased? what extends beyond that? see @yasaman_razeghi @sameer_ arXiv
5242,@GaryMarcus,2022-04-14 20:34:30+00:00,https://twitter.com/GaryMarcus/status/1514703664941731867,@raphaelmilliere @kaushikpatnaik @OpenAI @GoogleAI @DeepMind @TristanThrush @mohitban47 i might be more (or less) impressed if i had any idea what was in the training set.
5243,@GaryMarcus,2022-04-14 20:09:04+00:00,https://twitter.com/GaryMarcus/status/1514697263850819589,"@raphaelmilliere @kaushikpatnaik @OpenAI @GoogleAI @DeepMind @TristanThrush @mohitban47 this is where anecdotal cherry-picking really stands in the way of science. is this *reliable*? we don't know. 

but what the paper says about binding suggests it probably isn't."
5244,@GaryMarcus,2022-04-14 18:46:38+00:00,https://twitter.com/GaryMarcus/status/1514676518701580299,@raphaelmilliere @kaushikpatnaik @OpenAI @GoogleAI @DeepMind @TristanThrush @mohitban47 the red cube on blue cube example involves both semantic and syntactic compositionality. failure on both.
5245,@GaryMarcus,2022-04-14 18:03:14+00:00,https://twitter.com/GaryMarcus/status/1514665597983870977,"@raphaelmilliere @kaushikpatnaik @OpenAI @GoogleAI @DeepMind not in the linguistic sense of the word ‚Äúcompositionality‚Äù; DALL-E performance on ‚Äòred ball on blue cube‚Äù is pretty clearly lacking. 

@TristanThrush @mohitban47"
5246,@GaryMarcus,2022-04-14 16:53:53+00:00,https://twitter.com/GaryMarcus/status/1514648144969052160,@ericjang11 @tdietterich @raphaelmilliere @OpenAI @GoogleAI don‚Äôt really follow your logic
5247,@GaryMarcus,2022-04-14 16:52:47+00:00,https://twitter.com/GaryMarcus/status/1514647871122907150,"@raphaelmilliere @tdietterich @OpenAI @GoogleAI a correlate can be a proxy rather than an actual encoding, that fails with distribution shift."
5248,@GaryMarcus,2022-04-14 15:11:54+00:00,https://twitter.com/GaryMarcus/status/1514622481092341768,"Thoughtful, balanced thread on compositionality by @raphaelmilliere"
5249,@GaryMarcus,2022-04-14 14:32:17+00:00,https://twitter.com/GaryMarcus/status/1514612512804593665,"Welcome to the hybrid, neurosymbolic fold, Andrew Ng!

Per this article, in effort to achieve reliability he is ‚Äúpointing more ‚Ä¶ towards the type of knowledge-based, symbolic AI that preceded machine learning in the AI pendulum motion.‚Äù https://t.co/XVW2561z2V"
5250,@GaryMarcus,2022-04-13 03:48:44+00:00,https://twitter.com/GaryMarcus/status/1514088167753732101,I was today years old when I noticed that the word ‚Äúsanction‚Äù is its own antonym.
5251,@GaryMarcus,2022-04-13 03:24:51+00:00,https://twitter.com/GaryMarcus/status/1514082158318555139,@Ayoubberrada3 @bzor the dog doesn‚Äôt speak fluent english; read some of my recent posts. its recognize keyword  but has trouble with the grammar and semantics.
5252,@GaryMarcus,2022-04-13 01:48:45+00:00,https://twitter.com/GaryMarcus/status/1514057975387750400,"Just curious: anyone remember the hype around OpenAI‚Äôs one-handed Rubik‚Äôs solving robot, and the fuss I made?  

And what happened to that project, in the end?"
5253,@GaryMarcus,2022-04-13 00:19:07+00:00,https://twitter.com/GaryMarcus/status/1514035417565253640,I ‚ù§Ô∏èBC https://t.co/XHJdjQeXpU
5254,@GaryMarcus,2022-04-13 00:17:32+00:00,https://twitter.com/GaryMarcus/status/1514035019676798982,@BlancheMinerva @rao2z @OpenAI @Google game on! i am not sure; maybe if you do a lot of pre-segmentation?
5255,@GaryMarcus,2022-04-12 23:30:34+00:00,https://twitter.com/GaryMarcus/status/1514023198198669312,"@sd_marlow @rao2z the real issue here is the claims made vs the evidence and degree of scrutiny allowed. 

if the community sanctions this sort of thing, replicability crises are inevitable."
5256,@GaryMarcus,2022-04-12 23:29:09+00:00,https://twitter.com/GaryMarcus/status/1514022841997438978,"@sd_marlow @rao2z that‚Äôs an unusual case worth considering in which science is (initially) done internally for national security, but your facts aren‚Äôt quite correct; lots of tests were conducted for many years: https://t.co/BluNzimp14."
5257,@GaryMarcus,2022-04-12 23:22:49+00:00,https://twitter.com/GaryMarcus/status/1514021247499137024,"@rao2z @OpenAI @Google as a side note cc @BlancheMinerva if you read between the lines, Dall-E may heavily depend on high-quality and expensive to license art, and so public domain versions may be harder to construct than with text analogues; will be interesting to see."
5258,@GaryMarcus,2022-04-12 23:17:25+00:00,https://twitter.com/GaryMarcus/status/1514019891342307333,"@rao2z @OpenAI @Google heading towards more and more flashy demos that still lack reliability, basic comprehension, debuggability, etc. 

a taller local minimum is still a local minimum."
5259,@GaryMarcus,2022-04-12 23:16:14+00:00,https://twitter.com/GaryMarcus/status/1514019592611397639,"@rao2z @OpenAI @Google shown that *what* is feasible? already becoming clear for example that DALL-E2 has a very poor model of language, and can‚Äôt really represent basic differences; we have no idea how vast training set is. The graphics are cool, but what is that you think has been demonstrated?"
5260,@GaryMarcus,2022-04-12 22:27:45+00:00,https://twitter.com/GaryMarcus/status/1514007392458928130,@MelMitchell1 @rao2z great quote. and very depressing in current context. i had some hope when Joelle Pineau was making waves on replicability. last week was really something else.
5261,@GaryMarcus,2022-04-12 22:12:39+00:00,https://twitter.com/GaryMarcus/status/1514003591849160705,"@rao2z it‚Äôs not science if
- you don‚Äôt report your training set
- you present a new phenomenon by anecdotal example without giving a denominator or any scope on what was tried.
- don‚Äôt let other scientists replicate or verify your work"
5262,@GaryMarcus,2022-04-12 21:23:26+00:00,https://twitter.com/GaryMarcus/status/1513991204240707588,@izzyz @bzor that‚Äôs what he is saying in the thread
5263,@GaryMarcus,2022-04-12 18:08:56+00:00,https://twitter.com/GaryMarcus/status/1513942255421181954,@georgebaily sorry i got so much incoming like this that i missed you were kidding
5264,@GaryMarcus,2022-04-12 18:08:09+00:00,https://twitter.com/GaryMarcus/status/1513942058511192070,@Zergylord sufficiency: my next Decade in AI essay plus comprehension challenge in New Yorker re turing test
5265,@GaryMarcus,2022-04-12 18:07:07+00:00,https://twitter.com/GaryMarcus/status/1513941801991737344,@Zergylord yes they are necessary but not sufficient. and yes they can be done with classical programming languages; the question is hot to integrate with adequate learning frameworks
5266,@GaryMarcus,2022-04-12 17:22:24+00:00,https://twitter.com/GaryMarcus/status/1513930546966978564,@_ericrosen @geoffreyhinton @andrewmccallum
5267,@GaryMarcus,2022-04-12 17:12:45+00:00,https://twitter.com/GaryMarcus/status/1513928119308095489,@MadamePratolung @punkstrategy not sure if it was meant in jest but it references @ilyasut who made the original remark
5268,@GaryMarcus,2022-04-12 17:11:33+00:00,https://twitter.com/GaryMarcus/status/1513927814705123329,@FellowHominid I would be shocked if it can be done at scale and want to know more. I certainly don‚Äôt think it is impossible.
5269,@GaryMarcus,2022-04-12 17:10:55+00:00,https://twitter.com/GaryMarcus/status/1513927655850082306,"This man just insulted a *lot* of human artists, who are perfectly capable of distinguishing ‚Äúblue ball on top of red ball‚Äù from ‚Äúred ball on blue ball‚Äù, and other details. My 7-year old included."
5270,@GaryMarcus,2022-04-12 16:33:56+00:00,https://twitter.com/GaryMarcus/status/1513918348043640843,"Nor, in fact, until AI can reliably do the things I asked for in 2001:

‚Ä¢¬†freely generalize operations over variables
‚Ä¢¬†treat distinctions between types and tokens appropriately
‚Ä¢ represent and interpret structured and compositional relationships

So far, they still can‚Äôt."
5271,@GaryMarcus,2022-04-12 16:01:26+00:00,https://twitter.com/GaryMarcus/status/1513910171407323136,"@BecomingCritter I saw the thread, thanks. What‚Äôs their provenance/methodology? Would love to know what happens with small variations in wording."
5272,@GaryMarcus,2022-04-12 15:21:14+00:00,https://twitter.com/GaryMarcus/status/1513900054095953922,@terrible_archer @TristanThrush yep tweeted it!
5273,@GaryMarcus,2022-04-12 15:19:47+00:00,https://twitter.com/GaryMarcus/status/1513899690596528131,@MaxALittle @bzor @vectorpark details are (partly) in the paper; diversity of images is a major in goal.
5274,@GaryMarcus,2022-04-12 14:41:33+00:00,https://twitter.com/GaryMarcus/status/1513890068213211140,@TristanThrush can‚Äôt wait to see you extend WinoGround to DALL-E2
5275,@GaryMarcus,2022-04-12 14:38:40+00:00,https://twitter.com/GaryMarcus/status/1513889343886217229,"@PyVitor memory is crucial, and deeply related to operations over variables (ad discussed in my book The Algebraic Mind); right form of it is an open question."
5276,@GaryMarcus,2022-04-12 14:37:32+00:00,https://twitter.com/GaryMarcus/status/1513889055464951819,@CadeMetz
5277,@GaryMarcus,2022-04-12 14:31:51+00:00,https://twitter.com/GaryMarcus/status/1513887624615940096,"Emerging picture of DALL-E2:

‚Ä¢¬†Produces fabulous, high quality graphics
‚Ä¢¬†Easy to get something in general ballpark of what is desired
‚Ä¢ Difficult to fine-tune output to specific needs
‚Ä¢ Understanding of language is very superficial
‚Ä¢¬†Fails tests of compositionality"
5278,@GaryMarcus,2022-04-12 13:58:17+00:00,https://twitter.com/GaryMarcus/status/1513879180814991360,"@yotamvaknin software. see my @nautilusmag piece on Deep Learning hitting a wall (viz. compositionality, etc)"
5279,@GaryMarcus,2022-04-12 13:50:21+00:00,https://twitter.com/GaryMarcus/status/1513877183256801280,"Who would have guessed? A clever new benchmark, Winoground, shows that a whole bunch of vision-and-language models are at chance on compositionality."
5280,@GaryMarcus,2022-04-12 13:14:23+00:00,https://twitter.com/GaryMarcus/status/1513868129943785480,"@_DataStrategies look at @sama‚Äôs timeline, 45 minutes after he introduces DALL-E2‚Ä¶"
5281,@GaryMarcus,2022-04-12 13:11:57+00:00,https://twitter.com/GaryMarcus/status/1513867520125546499,"interesting! could that‚Äîa lack of systematic editability‚Äîbe why @openai won‚Äôt have an open demo, or allow access to skeptics? 

#blackboxAI without #compositionality"
5282,@GaryMarcus,2022-04-12 03:11:14+00:00,https://twitter.com/GaryMarcus/status/1513716344725725188,"ü§∑‚Äç‚ôÇÔ∏è

It's been 616 days since @gdb promised me GPT-3 access that he never delivered (""special priority, because fair criticism...helps drive progress"")

4 since he trolled me on Twitter w his #deeplepning post

4 since I asked if he had the guts to let me try out DALL-E2

No reply https://t.co/TpqTNx3AEq"
5283,@GaryMarcus,2022-04-12 02:59:30+00:00,https://twitter.com/GaryMarcus/status/1513713391759548419,@rasbt $
5284,@GaryMarcus,2022-04-11 23:26:53+00:00,https://twitter.com/GaryMarcus/status/1513659882657902598,"@jeffrey_bowers yes that specific case can be solved with the right prior, but i don‚Äôt think you can solve the general form of the UQOTM challenge I posed in 2001.

and it‚Äôs really striking that DALL-E botches it so thoroughly."
5285,@GaryMarcus,2022-04-11 20:44:23+00:00,https://twitter.com/GaryMarcus/status/1513618988319739908,"@mehdiesadri how about ‚Äúto do list with the words ‚ÄúMy funny list of stuff I gotta do‚Äù on top‚Äù; human artists would be at 100%; DALL-E2 close to zero.

anyone with access wanna try and post their (full) results?"
5286,@GaryMarcus,2022-04-11 20:32:06+00:00,https://twitter.com/GaryMarcus/status/1513615899487453185,"@sama I‚Äôm not doubling down, @sama, I am asking for the field to solve the same problems I‚Äôve always asked, because they are vital to true intelligence. 

Here‚Äôs an example where progress has not been exponential, not even linear."
5287,@GaryMarcus,2022-04-11 20:27:04+00:00,https://twitter.com/GaryMarcus/status/1513614631540957189,"To be sure, there are many amazing things about the output. But
üëâ We have no idea what the training set is, hence how much of the output is just compositing memorized examples
üëâ We have no idea how robust output is across variations in wording
üëâCore component of identity is ü§∑‚Äç‚ôÇÔ∏è"
5288,@GaryMarcus,2022-04-11 20:27:04+00:00,https://twitter.com/GaryMarcus/status/1513614630018449410,"You ask for benchmarks?

üëâ21 years ago I presented a simple one: universally-quantified one-to-one mappings, such as identity &amp; string reversal
üëâMultilayer perceptrons then had lots of trouble
üëâHere's DALL-E2, 2022, on a closely-related task:

Twenty. One. Years. Later.

[1/2]"
5289,@GaryMarcus,2022-04-11 20:08:10+00:00,https://twitter.com/GaryMarcus/status/1513609873526689796,"@Skiminok or for that matter see the identity and UQOTM challenge I proposed in 2001, which DALL-E 2 fails with respect to text."
5290,@GaryMarcus,2022-04-11 20:06:38+00:00,https://twitter.com/GaryMarcus/status/1513609489760591872,"@Skiminok or see my 2014 deep comprehension challenge, which the field hasn‚Äôt tried to address, because it doesn‚Äôt know how. (see New Yorker article on Beyond Turing Test, and AI magazine article with Praveen Paritosh)."
5291,@GaryMarcus,2022-04-11 19:39:27+00:00,https://twitter.com/GaryMarcus/status/1513602647822983174,"@TalkRLPodcast eg. Hinton's ""Aetherial symbols talk"": https://t.co/7wNV9zzMTk

but its not just about the needs for incorporating symbols; it's about how to conduct science in the face of limits."
5292,@GaryMarcus,2022-04-11 18:48:21+00:00,https://twitter.com/GaryMarcus/status/1513589787088850952,@rkarmani source?
5293,@GaryMarcus,2022-04-11 18:30:54+00:00,https://twitter.com/GaryMarcus/status/1513585396386467840,"@AVMiceliBarone see the many things I point to the @NautilusMag article, all funded, but modestly, at maybe .1% of the funding that LLMs receive."
5294,@GaryMarcus,2022-04-11 17:41:55+00:00,https://twitter.com/GaryMarcus/status/1513573069473792000,"@AVMiceliBarone diversify it‚Äôs portfolio and choose hard problems to work together collectively on, instead of constantly looking under same streetlights"
5295,@GaryMarcus,2022-04-11 16:38:47+00:00,https://twitter.com/GaryMarcus/status/1513557181693513735,"7\ A ""put up or shut up"" attitude favors the powerful‚Äîin the short term‚Äîbut it is bad for science."
5296,@GaryMarcus,2022-04-11 16:38:47+00:00,https://twitter.com/GaryMarcus/status/1513557180737212420,"6\ Scientific scrutiny? Treated as optional.

When flashy new systems fit the narrative but regress on Joelle Pineau's replicability checklist, failing to report basics like training data and even (on certain flashy new discoveries) percent correct, nobody speaks up."
5297,@GaryMarcus,2022-04-11 16:38:46+00:00,https://twitter.com/GaryMarcus/status/1513557179726409733,"5\  Some questions discussed too rarely:

Why did symbolic models beat deep learning at NetHack?
Why did hybrid models become first to win (simplified) bridge?
Why, if LLM's are so good, is comprehension still so poor?
If DL is so powerful, where's AGI?"
5298,@GaryMarcus,2022-04-11 16:38:46+00:00,https://twitter.com/GaryMarcus/status/1513557178560376838,"4\ Those currently in power in AI have done everything in in their power to disregard looming weaknesses.

Implications of multiyear delays in driverless cars: ignored
(Ditto for reliable chatbots)
Challenges in compositionality: brushed aside
Public debate of limits: Scorned"
5299,@GaryMarcus,2022-04-11 16:38:46+00:00,https://twitter.com/GaryMarcus/status/1513557177541160960,3\ The lesson of history is that popularity and economic power do not by any stretch ensure AGI. Nor do flashy short-term results‚Äîif there are fundamental problems looming.
5300,@GaryMarcus,2022-04-11 16:38:45+00:00,https://twitter.com/GaryMarcus/status/1513557176194781187,"2\  In the very near-term, large language models will win most battles, because investment in them massively outstrips competing approaches. 

As the collapse of expert systems shows, that‚Äôs proof of nothing."
5301,@GaryMarcus,2022-04-11 16:38:45+00:00,https://twitter.com/GaryMarcus/status/1513557173095129088,"1\ Not so long ago, expert systems were all the rage, and deep learning barely got funded.  Expert systems rose and rose and rose ‚Äì and finally fell. 

Ditto for SVMs.

A thread on science, power, and intellectual rigor."
5302,@GaryMarcus,2022-04-11 02:49:38+00:00,https://twitter.com/GaryMarcus/status/1513348519897157633,"@MatthiasLalisse hard to say; certainly doesn‚Äôt have language to vision mapping with a proper compositional semantics. since I have not played with it and have no idea of what the training set is, I leave the rest of the causal details open."
5303,@GaryMarcus,2022-04-10 18:20:21+00:00,https://twitter.com/GaryMarcus/status/1513220353278951427,#OpenAI?
5304,@GaryMarcus,2022-04-10 18:01:11+00:00,https://twitter.com/GaryMarcus/status/1513215530366234625,"Is the chance of someone from OpenAI debating a knowledgeable skeptic higher or lower than their chance of allowing me 24 hours to explore DALL-E2? 

ü§∑‚Äç‚ôÇÔ∏è"
5305,@GaryMarcus,2022-04-10 13:46:11+00:00,https://twitter.com/GaryMarcus/status/1513151358039326721,"‚Äúbecause general AI will have such vast responsibility resting on it, it must be like stainless steel, stronger and more reliable‚Äù 

‚Å¶@justinhendrix‚Å© and I talk AI policy, in an era in which AI *lacks* reliability https://t.co/2U5Jn2xW7h"
5306,@GaryMarcus,2022-04-10 00:14:53+00:00,https://twitter.com/GaryMarcus/status/1512947186845175808,"@jonathanrlarkin also if you look at the only comparisons w prior models, compositionality is worse, and overall images are better, but only incrementally relative to last year‚Äôs work."
5307,@GaryMarcus,2022-04-10 00:08:41+00:00,https://twitter.com/GaryMarcus/status/1512945625775546368,"@MatthiasLalisse no, not without playing with it, and not without having the slightest clue what the training set is."
5308,@GaryMarcus,2022-04-09 23:14:24+00:00,https://twitter.com/GaryMarcus/status/1512931965472714754,"Um‚Ä¶DALL-E and PaLM may seem magical based on demos, but we‚Äôre still talking about systems that stumble on simple instructions like ‚Äúput the red cube on the blue cube‚Äù [DALL-2], and in solving word problems [PaLM]. 

Toxicity, misinformation, &amp; bias all remain.

Humility advised."
5309,@GaryMarcus,2022-04-09 20:20:31+00:00,https://twitter.com/GaryMarcus/status/1512888208853331972,"@un1crom Alas, judging by the twitter, I do think a lot of *researchers* seem to think DALL-E broke the wall. 

The graphics are great, but certainly it has not broken any of the wall I have been writing about for two decades."
5310,@GaryMarcus,2022-04-09 17:40:18+00:00,https://twitter.com/GaryMarcus/status/1512847887020875777,"@coecke it has to something like the work Frege wanted, but mechanism remains unknown"
5311,@GaryMarcus,2022-04-09 17:39:33+00:00,https://twitter.com/GaryMarcus/status/1512847700550512643,"@Plinz often correct, rarely reliable. and usually amnesic"
5312,@GaryMarcus,2022-04-09 16:36:32+00:00,https://twitter.com/GaryMarcus/status/1512831841450954755,üî•
5313,@GaryMarcus,2022-04-09 16:35:31+00:00,https://twitter.com/GaryMarcus/status/1512831582729486337,@CSProfKGD @chriswolfvision https://t.co/g56sllJkdA
5314,@GaryMarcus,2022-04-09 16:35:18+00:00,https://twitter.com/GaryMarcus/status/1512831529138868224,@adnancagri @chriswolfvision https://t.co/g56sllJkdA
5315,@GaryMarcus,2022-04-09 16:35:12+00:00,https://twitter.com/GaryMarcus/status/1512831506607050754,@Neurotronic67 @chriswolfvision https://t.co/g56sllJkdA
5316,@GaryMarcus,2022-04-09 16:34:24+00:00,https://twitter.com/GaryMarcus/status/1512831301593669632,@ericjang11 https://t.co/g56sllJkdA
5317,@GaryMarcus,2022-04-09 16:33:48+00:00,https://twitter.com/GaryMarcus/status/1512831152238735360,@akbirthko https://t.co/g56sllJkdA
5318,@GaryMarcus,2022-04-09 16:33:00+00:00,https://twitter.com/GaryMarcus/status/1512830950832422912,@Ted_Underwood https://t.co/g56sllJkdA
5319,@GaryMarcus,2022-04-09 16:32:55+00:00,https://twitter.com/GaryMarcus/status/1512830930167099396,@drjwrae https://t.co/g56sllJkdA
5320,@GaryMarcus,2022-04-09 16:30:21+00:00,https://twitter.com/GaryMarcus/status/1512830286060744704,"To those gloating about Dall-E &amp; the wall, you might read some of my work (not just titles) and the DALL-E2 paper (not just pictures).

You will discover 3 things:
‚Ä¢ The wall for AGI is compositionality, not graphics
‚Ä¢¬†DALL-E2 fails on that wall
‚Ä¢¬†It does worse than 2021 GLIDE"
5321,@GaryMarcus,2022-04-09 13:02:55+00:00,https://twitter.com/GaryMarcus/status/1512778082267979778,@kleptid can you try the longer prompt in the message above you are replying to?
5322,@GaryMarcus,2022-04-09 04:35:09+00:00,https://twitter.com/GaryMarcus/status/1512650300154265606,@johnsontoddr4 DeepMind tried but I have not heard any reports of success
5323,@GaryMarcus,2022-04-09 04:34:37+00:00,https://twitter.com/GaryMarcus/status/1512650166326628355,"Dear @sama @gdb @plinz @ylecun, 

Each of you ridiculed my recent title,  but this is what the article was actually about: compositionality.

Yes, there are many kinds of progress in other directions. 

But compositionality is at the core of intelligence. 

No AGI without it."
5324,@GaryMarcus,2022-04-09 04:25:57+00:00,https://twitter.com/GaryMarcus/status/1512647983317151747,"Compositionality *is* the wall. 

Even ‚Äúred cube‚Äù and ‚Äúblue cube‚Äù on their own are represented unreliably; not one of ten images correctly captures the full phrasal description.

The images are beautiful, but no match for the precision of language."
5325,@GaryMarcus,2022-04-09 00:57:08+00:00,https://twitter.com/GaryMarcus/status/1512595430940368899,"if you are interested in advancing natural language understanding, check out this conference. 

As @ErnestSDavis &amp; I emphasized in https://t.co/Pt7HZbLIv5 many of the open,  unsolved problems in language revolve around context &amp; inferring that which is not explicit."
5326,@GaryMarcus,2022-04-08 23:22:17+00:00,https://twitter.com/GaryMarcus/status/1512571564285304835,"@mErfangh @sama least PaLM could have done: an appendix with a full disclosure of everything they tried, including both correct &amp; incorrect answers, &amp; prompts used, for the jokes &amp; arithmetical reasoning. selecting post hoc cases where new model succeeds and previous model fails is inexcusable."
5327,@GaryMarcus,2022-04-08 23:11:38+00:00,https://twitter.com/GaryMarcus/status/1512568883508441091,@charleswangb @Plinz @tdietterich breaks my heart
5328,@GaryMarcus,2022-04-08 23:10:42+00:00,https://twitter.com/GaryMarcus/status/1512568647507578887,"Exactly. The reason I said that this week was a step back was because *big corporates are regressing from full disclosure*; as Joelle Pineau has pointed out, that‚Äôs a royal road to replicability crisis. 

Compare DALL-E 2 and PaLM data presentation w this: https://t.co/SqC8rSMn2a"
5329,@GaryMarcus,2022-04-08 23:04:38+00:00,https://twitter.com/GaryMarcus/status/1512567122810920965,Change the word ‚Äúcompositionality‚Äù [which has a technical linguistics sense that is lacking here] to ‚Äúcompositing‚Äù and I am in agreement with this:
5330,@GaryMarcus,2022-04-08 23:01:56+00:00,https://twitter.com/GaryMarcus/status/1512566443497295872,"Great to see some engagement in my comprehension challenge. I will be surprised if it is solved soon; happy to put a wager on it.

Want to explain the near-term path you see to getting to a solution?

btw the Scrolls Benchmark by  @Uri_Shaham et al is a step in this direction."
5331,@GaryMarcus,2022-04-08 22:58:14+00:00,https://twitter.com/GaryMarcus/status/1512565510491107328,"@Plinz @tdietterich like vision, in a summer :)"
5332,@GaryMarcus,2022-04-08 22:56:05+00:00,https://twitter.com/GaryMarcus/status/1512564968910045192,@tejasdkulkarni @OpenAI nor what I pointed to as challenging in The Algebraic Mind; interesting in its own right but not progress on the specific problems I have been raising
5333,@GaryMarcus,2022-04-08 22:55:19+00:00,https://twitter.com/GaryMarcus/status/1512564774655053825,"@tejasdkulkarni @OpenAI ok, but that‚Äôs not what Frege and a century of linguists meant by the term."
5334,@GaryMarcus,2022-04-08 22:54:50+00:00,https://twitter.com/GaryMarcus/status/1512564656421842944,@tejasdkulkarni @OpenAI not arguing for abandoning; arguing for hybrids
5335,@GaryMarcus,2022-04-08 22:54:28+00:00,https://twitter.com/GaryMarcus/status/1512564561634680849,@tejasdkulkarni @OpenAI retrieval mechanisms - are these like the operations over variables I have been lobby for? or different in some way?
5336,@GaryMarcus,2022-04-08 21:49:04+00:00,https://twitter.com/GaryMarcus/status/1512548104716754949,"Am really really tired of being accused of moving goalposts, without evidence. Show what my goalposts were and how they changed, or be blocked.

See my goalposts as defined here https://t.co/1N4qeEE9wH

and in the The Algebraic Mind 

Still haven't been met; haven't changed."
5337,@GaryMarcus,2022-04-08 21:48:03+00:00,https://twitter.com/GaryMarcus/status/1512547849698906115,"@himbodhisattva @moultano @OpenAI @gdb my goalposts were defined here https://t.co/1N4qeEE9wH

and in the The Algebraic Mind 

still haven't been met; haven't changed."
5338,@GaryMarcus,2022-04-08 21:47:55+00:00,https://twitter.com/GaryMarcus/status/1512547814194049026,"@moultano @OpenAI @gdb my goalposts were defined here https://t.co/1N4qeEE9wH

and in the The Algebraic Mind 

still haven't been met; haven't changed."
5339,@GaryMarcus,2022-04-08 21:42:01+00:00,https://twitter.com/GaryMarcus/status/1512546329272061957,"@tejasdkulkarni @OpenAI what do you mean by compositionality? in  linguistic sense, minimal definition would be understanding a whole in terms of the structure of its parts; only thing in the paper that direct tests  that is a failure to distinguish ""blue cube on red cube"" from ""red cube on blue cube"""
5340,@GaryMarcus,2022-04-08 17:05:22+00:00,https://twitter.com/GaryMarcus/status/1512476707025874948,"@sd_marlow @sama BD has mostly focused on motor control; replicating their whole impressive body of work wouldn‚Äôt get you far in what needs to be solved in cognition, interface w humans etc."
5341,@GaryMarcus,2022-04-08 17:00:30+00:00,https://twitter.com/GaryMarcus/status/1512475482863800320,@dambsky @Plinz it‚Äôs literally the only data that speak to the idea portrayed in the cartoon.
5342,@GaryMarcus,2022-04-08 16:36:40+00:00,https://twitter.com/GaryMarcus/status/1512469485038440451,@MelMitchell1 @DrRJCarter I ‚ù§Ô∏è@Powells
5343,@GaryMarcus,2022-04-08 16:35:40+00:00,https://twitter.com/GaryMarcus/status/1512469236542713857,@MatthewJBar @sama read the timeline; the connection is obvious.
5344,@GaryMarcus,2022-04-08 16:34:19+00:00,https://twitter.com/GaryMarcus/status/1512468893364744192,"@MatthewJBar @sama no quantitative data on the joke stuff, which is the hallmark of the paper; none."
5345,@GaryMarcus,2022-04-08 16:32:36+00:00,https://twitter.com/GaryMarcus/status/1512468462408327173,@rezajamei5 @elonmusk @CNBC just responding to what he said
5346,@GaryMarcus,2022-04-08 16:28:56+00:00,https://twitter.com/GaryMarcus/status/1512467539892133893,"@MatthewJBar you have documented no such thing. @sama explicitly raised AGI, so it is fair game.

i rarely block but you are on thin ice"
5347,@GaryMarcus,2022-04-08 16:27:43+00:00,https://twitter.com/GaryMarcus/status/1512467235146674177,"@DanielFein7 @enemiesnet @OpenAI @gdb if you had seen the picture without the prompt (&amp; without the background context on Ml discussion), that would not be in your top 5 descriptions"
5348,@GaryMarcus,2022-04-08 16:24:29+00:00,https://twitter.com/GaryMarcus/status/1512466419166105601,@DrRJCarter @MelMitchell1 we had dinner not long before the pandemic :)
5349,@GaryMarcus,2022-04-08 16:07:30+00:00,https://twitter.com/GaryMarcus/status/1512462147120377856,". @plinz‚Äôs satires of me are becoming more and more misleading.

Let‚Äôs compare reality, 4 models incrementally improving over last year [DALL-E 2 at bottom], with his cartoon, which implies a recent stair-step change, which didn‚Äôt actually happen: https://t.co/bRojZTfse1"
5350,@GaryMarcus,2022-04-08 15:57:14+00:00,https://twitter.com/GaryMarcus/status/1512459562145632258,"@Plinz just wondering, did you actually read the paper?"
5351,@GaryMarcus,2022-04-08 15:21:32+00:00,https://twitter.com/GaryMarcus/status/1512450577195626499,@Krauss_PK https://t.co/ekDiArTdO0
5352,@GaryMarcus,2022-04-08 15:17:32+00:00,https://twitter.com/GaryMarcus/status/1512449572609527808,@enemiesnet @OpenAI @gdb you are being too charitable. please read the paper; it appears to consistently have trouble w text strings regardless of context
5353,@GaryMarcus,2022-04-08 14:50:16+00:00,https://twitter.com/GaryMarcus/status/1512442710375862273,"This Week in AI Hype

Google releases PaLM, says it explains jokes. 
üëâno quantitative data

OpenAI releases DALL-E2; @sama says AGI's ""gonna be wild""
üëâcan't tell blue cube on red from red cube on blue

Elon Musk: human-level robots are imminent
üëâOnly demo=human wearing costume"
5354,@GaryMarcus,2022-04-08 13:21:19+00:00,https://twitter.com/GaryMarcus/status/1512420324410683398,"@philipcball @MolemanPeter 2032 would be very surprising, but maybe remotely possible. but not at all what Musk was on about."
5355,@GaryMarcus,2022-04-08 13:19:02+00:00,https://twitter.com/GaryMarcus/status/1512419750038568961,"wow, @openAI never gave access to GPT-3  to one the world‚Äôs leading experts on chatbot creation. 

wonder why not."
5356,@GaryMarcus,2022-04-08 13:10:17+00:00,https://twitter.com/GaryMarcus/status/1512417546669985794,@smakelainen @elonmusk @CNBC happy to make a bet on 2030 with even odds. but that‚Äôs not what Musk was saying.
5357,@GaryMarcus,2022-04-08 13:05:40+00:00,https://twitter.com/GaryMarcus/status/1512416384982028296,"fellow scientists/AI researchers, if you asked for access to GPT-3 in 2020/early 2021, how long did it take? 

were you able to get access before the waiting list ended in November?"
5358,@GaryMarcus,2022-04-08 11:43:53+00:00,https://twitter.com/GaryMarcus/status/1512395804643786752,"@TacoCohen @Zergylord i really have no earthly idea why you think i favor tribalism, when i am favoring inclusive hybrid models and have said it will take a village to raise AI."
5359,@GaryMarcus,2022-04-08 11:36:17+00:00,https://twitter.com/GaryMarcus/status/1512393891764264961,"@Zergylord @TacoCohen for sure, but for the most part (not entirely) an unreasonably allergy to symbols and innateness, that has limited the search space, sometimes in negative ways."
5360,@GaryMarcus,2022-04-08 11:34:46+00:00,https://twitter.com/GaryMarcus/status/1512393511559065600,"@TacoCohen @Zergylord more generally i am not sure i hold the positions @tacocohen attributes to me, but i agree with most of the rest of his thread; he knows i have been a fan of his work for years."
5361,@GaryMarcus,2022-04-08 11:31:18+00:00,https://twitter.com/GaryMarcus/status/1512392637256396800,"@TacoCohen @Zergylord just to be clear, I never said that zero $ should go into scaling, just that it is not likely to suffice on its own, that too much attention and money is focused on it, and that it was struggling with compositionality, semantics, reasoning, etc. 

All that continues to be true."
5362,@GaryMarcus,2022-04-08 11:22:50+00:00,https://twitter.com/GaryMarcus/status/1512390507967655942,"@xsteenbrugge I presume you have no data for that assertion. replication of my rule learning studies with newborns, by Gervain and Werker suggests rule learning at birth."
5363,@GaryMarcus,2022-04-08 10:57:01+00:00,https://twitter.com/GaryMarcus/status/1512384008654450689,"@anderssandberg but are they achieved (or faked) *reliably* enough?

look at how far behind full level five self driving has been relative to expectations.

easy to fake progress in each area, but getting them right is another matter."
5364,@GaryMarcus,2022-04-08 07:07:18+00:00,https://twitter.com/GaryMarcus/status/1512326198348582915,"Agree with @sama that ‚ÄúAGI is gonna be wild‚Äù. Meanwhile, back on earth, in 2022, here is DALL-E v2, trying to figure out how to stack a red cube on top of a blue cube. https://t.co/xVBCCuVBxB"
5365,@GaryMarcus,2022-04-08 06:56:09+00:00,https://twitter.com/GaryMarcus/status/1512323393776807937,"Great Q. Any system that could reliably pass the comprehension challenge that I proposed at the end of this 2014 @NewYorker would change my mind: https://t.co/1N4qeEE9wH

Someday, some system will pass that challenge; DALL-E can‚Äôt tell a red cube on a blue cube from blue on red. https://t.co/1QEBds24et"
5366,@GaryMarcus,2022-04-08 05:47:47+00:00,https://twitter.com/GaryMarcus/status/1512306189547175938,@gdb https://t.co/ekDiArTdO0
5367,@GaryMarcus,2022-04-08 05:46:30+00:00,https://twitter.com/GaryMarcus/status/1512305868489912322,". @openAI‚Äôs @gdb unintentionally shows exactly how ‚Äúdeep lepning‚Äù continues to struggle w compositionality &amp; abstraction.

üëâDALL-E‚Äôs omission of the word ‚Äúhitting‚Äù reflects ongoing problem in compositionality

üëâ‚Äúlepning‚Äù extends identity failures central to The Algebraic Mind"
5368,@GaryMarcus,2022-04-08 05:28:02+00:00,https://twitter.com/GaryMarcus/status/1512301219112398851,"so @gdb @openAI do you have the guts to let me try it for a day?  

btw, where is the ‚Äúhitting‚Äù and what happened to the word ‚Äúlearning‚Äù?"
5369,@GaryMarcus,2022-04-08 02:04:42+00:00,https://twitter.com/GaryMarcus/status/1512250050231283714,@sir_deenicus @ardit266 @tangled_zans @mgubrud maybe the connection to ELIZA was deeper than we thought‚Ä¶
5370,@GaryMarcus,2022-04-08 00:08:31+00:00,https://twitter.com/GaryMarcus/status/1512220810685009924,@xsteenbrugge https://t.co/dhze6YpyTO
5371,@GaryMarcus,2022-04-08 00:08:06+00:00,https://twitter.com/GaryMarcus/status/1512220706859208704,@lambdaloop interesting claim
5372,@GaryMarcus,2022-04-08 00:07:05+00:00,https://twitter.com/GaryMarcus/status/1512220449333121024,and neither represents progress on what i have for decades argued are the deepest challenges:
5373,@GaryMarcus,2022-04-08 00:03:45+00:00,https://twitter.com/GaryMarcus/status/1512219611680313350,"What is the wall that stymies deep learning?

Reasoning, reliably, about causality &amp;  complex, compositionally structured language &amp; abstraction

Same wall I described in 2001, 2012, 2018, &amp; again in 2022

Wasn't breached then, hasn't been breached now. Not by PaLM, not by DALL-E"
5374,@GaryMarcus,2022-04-08 00:01:19+00:00,https://twitter.com/GaryMarcus/status/1512218999513239556,@tangled_zans @sir_deenicus @mgubrud @ardit266 the lack of queryability has been a. key problem throughout Deep learning‚Äôs history
5375,@GaryMarcus,2022-04-07 23:50:25+00:00,https://twitter.com/GaryMarcus/status/1512216253959598082,"@sir_deenicus @tangled_zans @mgubrud @ardit266 proofwriter eg tries to reason w transformers, w mixed success?"
5376,@GaryMarcus,2022-04-07 23:49:24+00:00,https://twitter.com/GaryMarcus/status/1512216000644624386,@sir_deenicus @tangled_zans @mgubrud @ardit266 how does the calculator part tie in?
5377,@GaryMarcus,2022-04-07 23:05:43+00:00,https://twitter.com/GaryMarcus/status/1512205003947094016,@advadnoun would appreciate links to posts from people outside openAI who have directly accessed the system
5378,@GaryMarcus,2022-04-07 23:04:02+00:00,https://twitter.com/GaryMarcus/status/1512204583229042710,"@tangled_zans @mgubrud @ardit266 unfortunately it is somewhat unclear what they actually did, but see the part on chain of reasoning."
5379,@GaryMarcus,2022-04-07 22:58:27+00:00,https://twitter.com/GaryMarcus/status/1512203176547561491,"@advadnoun aren‚Äôt which answers to respond to selected by human openAI staff? 

bet you they won‚Äôt give me an hour to try 20 examples reporting unedited results."
5380,@GaryMarcus,2022-04-07 22:56:32+00:00,https://twitter.com/GaryMarcus/status/1512202696404611093,"@tangled_zans @mgubrud @ardit266 PaLM is at 58% on some word problems, with calculator."
5381,@GaryMarcus,2022-04-07 22:55:19+00:00,https://twitter.com/GaryMarcus/status/1512202389754851368,@xsteenbrugge it‚Äôs not the wall i was talking about in the article. if people would maybe read past the title?
5382,@GaryMarcus,2022-04-07 21:03:57+00:00,https://twitter.com/GaryMarcus/status/1512174362358546448,"Hey, it‚Äôs true, I *am* desperate. Desperate for AI that can represent and reason causally about the world, rather than using statistics as an unreliable proxy to deeper representation and reasoning.

As cool as all these new demos are, they aren‚Äôt on the right track."
5383,@GaryMarcus,2022-04-07 17:15:33+00:00,https://twitter.com/GaryMarcus/status/1512116881703854080,"@Zergylord people said similar things about GPT-3 and have found it challenging to use for most use cases in practice.

it may well be genuinely useful, but it may be eg that getting the image you actually want for many cases is hard (vs something in the general ballpark), so it may depend"
5384,@GaryMarcus,2022-04-07 17:09:21+00:00,https://twitter.com/GaryMarcus/status/1512115322920132651,"@ParejaAldo @OpenAI again, with no sense whatsoever of either the training set or how well it generalizes, i just don‚Äôt know."
5385,@GaryMarcus,2022-04-07 17:06:11+00:00,https://twitter.com/GaryMarcus/status/1512114528254787584,"Good question. Some issues w cherry-picking:
1. Distorts public perception of how close we are to AGI.
2. Sends possibly misleading shock-and-awe signal to those who might work on more robust solutions.
3. Gives perception of universality in use cases that may be exaggerated."
5386,@GaryMarcus,2022-04-07 14:37:12+00:00,https://twitter.com/GaryMarcus/status/1512077032645046286,"@ImageSnippets @OpenAI to my knowledge, you can‚Äôt run DALL-E 2 in reverse."
5387,@GaryMarcus,2022-04-07 14:21:40+00:00,https://twitter.com/GaryMarcus/status/1512073122991681557,@brain_juices PR
5388,@GaryMarcus,2022-04-07 14:03:17+00:00,https://twitter.com/GaryMarcus/status/1512068500256296962,@nlpnyc @OpenAI no idea‚Äîand that‚Äôs the problem.
5389,@GaryMarcus,2022-04-07 14:00:04+00:00,https://twitter.com/GaryMarcus/status/1512067689908375556,"This week seems like win for AI, but it's actually a step back:
‚Ä¢ No info about training set [Dall-E]
‚Ä¢ Sparse disclosure of methods and errors [both]
‚Ä¢ Anecdotal data only [PaLM jokes]
‚Ä¢ Cherry-picking [both]
‚Ä¢ No access for scientific community [both]"
5390,@GaryMarcus,2022-04-07 13:53:49+00:00,https://twitter.com/GaryMarcus/status/1512066116985581591,@jingle__belle @OpenAI @sama tries it out; if the answer seems cool he posts. What happens if the answer is embarassing. Does he post that?
5391,@GaryMarcus,2022-04-07 13:46:27+00:00,https://twitter.com/GaryMarcus/status/1512064263443034127,"This whole thread is weaponized cherry-picked PR; the antithesis of science.

Please stop calling yourself @OpenAI if this is your way of doing business."
5392,@GaryMarcus,2022-04-07 13:44:47+00:00,https://twitter.com/GaryMarcus/status/1512063843601555456,"but I missed the fact that there is zero disclosure of the training data and am appalled by the cherrypicking via tweets, rather than an opportunity for the community to test systematically.

perhaps a new low for @OpenAI"
5393,@GaryMarcus,2022-04-07 13:02:28+00:00,https://twitter.com/GaryMarcus/status/1512053194448199680,this whole thread is üî•
5394,@GaryMarcus,2022-04-06 18:56:07+00:00,https://twitter.com/GaryMarcus/status/1511779804143501312,"@JarnoDuursma @jad_kabbara https://t.co/WkYfKxFSiQ; no section on limits or illustration of errors (cf DALL-E 2, which is more candid); hard to tell if appendices are cherry picked."
5395,@GaryMarcus,2022-04-06 16:38:35+00:00,https://twitter.com/GaryMarcus/status/1511745190930702339,"@KordingLab yes, because it pushes science towards populism rather than meritocracy. (analogous: is Tesla  &gt; Waymo in reliable self-driving? Twitterverse tilts that way, but not clear on what data it does so; might have more to do with Musk‚Äôs use of the medium rather than science.)"
5396,@GaryMarcus,2022-04-06 09:47:49+00:00,https://twitter.com/GaryMarcus/status/1511641819796283396,"@RWerpachowski @MadamePratolung @Plinz Given a large enough corpus, an LLM will get at least some items right, but what‚Äôs the numerator and what‚Äôs denominator? Is there actual progress from this: https://t.co/33GO3q9z4Q in 2020? Or just more hype? 

Without full disclosure of what was done, it‚Äôs actually hard to tell."
5397,@GaryMarcus,2022-04-06 09:27:47+00:00,https://twitter.com/GaryMarcus/status/1511636778398064644,"@MadamePratolung @RWerpachowski @Plinz Doubt that the Palm explanation of jokes would be at 58% eg if you fed in the transcript eg of any Netflix special. 

I am flabbergasted that the paper reported a numerator (number of successes) with no indication whatsoever of what the denominator was.

Hype turned up to 11"
5398,@GaryMarcus,2022-04-06 03:35:12+00:00,https://twitter.com/GaryMarcus/status/1511548048677093376,@lsi1123 no; that‚Äôs fundamentally why reliability is lacking. maybe i should have had a top 6
5399,@GaryMarcus,2022-04-06 03:23:11+00:00,https://twitter.com/GaryMarcus/status/1511545024869064705,"@PreetumNakkiran @rajiinio @databoydg you don‚Äôt have a denominator, just a numerator.

(and non deep learning has been used in humor for a long time, eg https://t.co/vHEvcCZBro, and any number of Turing chatbots)"
5400,@GaryMarcus,2022-04-06 02:16:44+00:00,https://twitter.com/GaryMarcus/status/1511528299201105923,@PreetumNakkiran @rajiinio @databoydg we have known since eliza that phenomena by themselves tell us nothing
5401,@GaryMarcus,2022-04-06 01:43:58+00:00,https://twitter.com/GaryMarcus/status/1511520055888158729,"@PreetumNakkiran @rajiinio @databoydg we‚Äôre there any that didn‚Äôt make sense? what were the fins like? how different were the tested jokes from the trained jokes? we have zero presentation of data, correct? 

doesn‚Äôt look like science to me"
5402,@GaryMarcus,2022-04-06 01:27:37+00:00,https://twitter.com/GaryMarcus/status/1511515938901970944,@PreetumNakkiran @rajiinio @databoydg unless i missed it the only evidence for this is anecdotal data
5403,@GaryMarcus,2022-04-05 22:08:26+00:00,https://twitter.com/GaryMarcus/status/1511465814402031620,"@JanetAdamsAI My book Kluge is all about human limitations and how they evolved. My point was not that humans are without cognitive limits, but that there is something wrong with how the AI community is currently approaching the problem. A healthy science is more open w data and criticism."
5404,@GaryMarcus,2022-04-05 22:04:46+00:00,https://twitter.com/GaryMarcus/status/1511464889851600900,"@BierVicki Gentleman‚Äôs C, for deep learning. Open book, with calculator."
5405,@GaryMarcus,2022-04-05 21:20:40+00:00,https://twitter.com/GaryMarcus/status/1511453791727468546,"@JanetAdamsAI only auditable if the big companies share their big models, including training data and test sets and errors. Google‚Äôs paper yesterday is not auditable. But that didn‚Äôt stop deep learning community from crowing about it."
5406,@GaryMarcus,2022-04-05 21:12:07+00:00,https://twitter.com/GaryMarcus/status/1511451641865670657,@TobyWalsh @SilverJacket i haven‚Äôt read the article yet but agree with Toby that the opening sounds really off to me.
5407,@GaryMarcus,2022-04-05 21:05:49+00:00,https://twitter.com/GaryMarcus/status/1511450056439709696,"@jad_kabbara yes field has come along way, but it also still hypes up results like yesterday‚Äôs from Google that doesn‚Äôt make anything available. same thing a week ago with a big Facebook synthetic image paper. 

healthy field would protest more loudly."
5408,@GaryMarcus,2022-04-05 21:03:48+00:00,https://twitter.com/GaryMarcus/status/1511449550392729603,"@AiSimonThompson it‚Äôs hundred of cases, that i have been documenting for years"
5409,@GaryMarcus,2022-04-05 21:01:31+00:00,https://twitter.com/GaryMarcus/status/1511448974611279879,@peterevoss no data. no chance to experiment with it to see for ourselves.
5410,@GaryMarcus,2022-04-05 19:21:20+00:00,https://twitter.com/GaryMarcus/status/1511423762087899140,"Top 5 reasons AI is not healthy 
‚Ä¢ few techniques guarantee reliability
‚Ä¢¬†no solution to bias, toxicity, misinformation
‚Ä¢ publishing without sharing model/training/test data
‚Ä¢ idea that scoring 58% is breaking through a wall
‚Ä¢ 85%+ of funding goes to a single approach"
5411,@GaryMarcus,2022-04-05 18:51:42+00:00,https://twitter.com/GaryMarcus/status/1511416306423140352,No amount of hype is going to get us to AGI.
5412,@GaryMarcus,2022-04-05 18:50:22+00:00,https://twitter.com/GaryMarcus/status/1511415970245488644,@maartengm @Plinz surely you can see the difference?
5413,@GaryMarcus,2022-04-05 18:49:44+00:00,https://twitter.com/GaryMarcus/status/1511415811495235585,"@Plinz Sorry but no. Breaking a wall ‚â† a bunch of anecdotal examples (jokes) with no quantitative data, and 58% performance on a task that should be a gimme for a real AGI. 

The wall is (a) comprehension and (b) *reliable performance*.  

Not broken. Not really approached."
5414,@GaryMarcus,2022-04-05 18:43:05+00:00,https://twitter.com/GaryMarcus/status/1511414136025976832,"Breaking through the wall on reasoning over arithmetic would mean *reliably* solving reasoning problems over arithmetic‚Äînot scoring  58% on word problems, with 540B parameters and 780B tokens‚Äîand the aid of a calculator.

Am guessing jokes are no more robust.

Science ‚â†¬†PR."
5415,@GaryMarcus,2022-04-05 18:29:55+00:00,https://twitter.com/GaryMarcus/status/1511410824564248576,"@amolk ‚Äúread the results‚Äù, viz on word problems 58% ‚Äì with aid of a calculator"
5416,@GaryMarcus,2022-04-05 16:35:26+00:00,https://twitter.com/GaryMarcus/status/1511382010945683458,@mosesjones ü§£ü§£ü§£ @stephen_wolfram does way way better.
5417,@GaryMarcus,2022-04-05 16:34:01+00:00,https://twitter.com/GaryMarcus/status/1511381655251947520,Hybrid neurosymbolic system beats end-to-end deep learning in autonomous driving study from Caltech.
5418,@GaryMarcus,2022-04-04 18:39:52+00:00,https://twitter.com/GaryMarcus/status/1511050937397174272,@KordingLab ever try criticizing deep learning?
5419,@GaryMarcus,2022-04-04 14:02:34+00:00,https://twitter.com/GaryMarcus/status/1510981155721416705,"‚Äúreal-time translation is still in its infancy‚Ä¶One of the solutions is to introduce symbolic reasoning, which can not only improve the comprehensibility of the model ‚Ä¶ [and maybe reduce] translation consistency errors.‚Äù
- ACL Fellow Qun Lu in @jjding99 ChinAI interview"
5420,@GaryMarcus,2022-04-02 17:15:57+00:00,https://twitter.com/GaryMarcus/status/1510305044100395012,Regulation and innovation. Sage words from @vardi. https://t.co/asE7uDxVLw
5421,@GaryMarcus,2022-04-02 09:50:54+00:00,https://twitter.com/GaryMarcus/status/1510193046117265411,@ImageSnippets @PatHaye67745536 @ErnestSDavis @georgiagkioxari And desperately missing. even Hinton sees that (it‚Äôs the key motivation for his Glom paper)
5422,@GaryMarcus,2022-04-02 09:49:41+00:00,https://twitter.com/GaryMarcus/status/1510192738519584768,"@ImageSnippets @ErnestSDavis @georgiagkioxari eg we know that it is unlikely that we will see perfectly aligned but detached parts of separate elephants, a la Gestalt principles and extensive related work w human infants. and we know about occluders, parsimony, and partial visibility."
5423,@GaryMarcus,2022-04-02 03:50:48+00:00,https://twitter.com/GaryMarcus/status/1510102421304872963,"@ImageSnippets @ErnestSDavis @georgiagkioxari - missed the tree
- not (i think?) trying to segment the scene, so doing different task (picking overarching caption vs parsing into multiple objects)"
5424,@GaryMarcus,2022-04-01 18:22:08+00:00,https://twitter.com/GaryMarcus/status/1509959311232962561,@naivebayesian that‚Äôs the subject of my book Kluge :)
5425,@GaryMarcus,2022-04-01 17:12:37+00:00,https://twitter.com/GaryMarcus/status/1509941819395633153,@lmoroney https://t.co/0FweJXvFt1
5426,@GaryMarcus,2022-04-01 16:38:59+00:00,https://twitter.com/GaryMarcus/status/1509933352479965184,"@erichammy @ErnestSDavis @georgiagkioxari an even better, since as @mpshanahan points out, the elephant (and not just the tree) has a trunk :)"
5427,@GaryMarcus,2022-04-01 16:30:35+00:00,https://twitter.com/GaryMarcus/status/1509931239528026117,correction: example was from @georgiagkioxari (raised in the course of a conversation with @ErnestSDavis)
5428,@GaryMarcus,2022-04-01 16:18:46+00:00,https://twitter.com/GaryMarcus/status/1509928265720352777,@jasonintrator @roddreher one man‚Äôs joke is another man‚Äôs @billmaher
5429,@GaryMarcus,2022-04-01 15:44:53+00:00,https://twitter.com/GaryMarcus/status/1509919738511585286,"Fantastic example of the need for common sense in computer vision.  Leading neural net sees two elephants, zero trees. What do you see?

Mask R-CNN trained on COCO dataset for instance segmentation. Shout-out to @ErnestSDavis for the example, @georgiagkioxari for testing. #AI #ML https://t.co/OylZI3CqS4"
5430,@GaryMarcus,2022-04-01 14:55:01+00:00,https://twitter.com/GaryMarcus/status/1509907188835266562,"@joshelman ha ha,or more likely the opposite."
5431,@GaryMarcus,2022-04-01 14:30:24+00:00,https://twitter.com/GaryMarcus/status/1509900997111414788,"Twitter today is mind-bending. 

Can barely tell what is April Fool‚Äôs and what is just 2022."
5432,@GaryMarcus,2022-04-01 14:25:07+00:00,https://twitter.com/GaryMarcus/status/1509899666426638341,"@KordingLab @neuromatch know it‚Äôs joke, but the only time I saw Bono up close was at an entrepreneur conference, pitching startup culture :)"
5433,@GaryMarcus,2022-04-01 14:12:13+00:00,https://twitter.com/GaryMarcus/status/1509896417233436686,@VisionBernie @elonmusk @DrVeronikaCH @TaliaRinger @neurobongo @RaquelUrtasun @CSProfKGD @MCHammer @BMW @AudiOfficial @MercedesBenz @Toyota @VW @Honda @Ford @Tesla ha ha @georgiagkioxari
5434,@GaryMarcus,2022-04-01 04:20:15+00:00,https://twitter.com/GaryMarcus/status/1509747444065583107,"@petitegeek all natural! (no flash, just available light)"
5435,@GaryMarcus,2022-03-31 19:30:13+00:00,https://twitter.com/GaryMarcus/status/1509614057904476204,Close Encounters of the Corvid Kind https://t.co/zeCftYmUNq
5436,@GaryMarcus,2022-03-30 23:23:51+00:00,https://twitter.com/GaryMarcus/status/1509310467121946633,@marktenenholtz medicine is an example of a large industry in which unstructured notes contain hugely valuable data that current systems struggle with.
5437,@GaryMarcus,2022-03-30 23:21:11+00:00,https://twitter.com/GaryMarcus/status/1509309796947693569,"@RHartsuiker @fernandaedi alas, there is a stack overflow error in the citation counter"
5438,@GaryMarcus,2022-03-30 20:39:22+00:00,https://twitter.com/GaryMarcus/status/1509269074022264833,"@andokal that's the technical sense in which the word is being used, yes, just as ""deep"" technically means a number of layers in ""deep learning""; but throwing around the word deep in these technical uses ‚â† the conceptual depth that is often implied and that is desperately needed."
5439,@GaryMarcus,2022-03-30 15:33:30+00:00,https://twitter.com/GaryMarcus/status/1509192099245158402,"State of the art in neuro-symbolic AI, new collection edited by @pascalhitzler and MK Sarker with contributions from @FrankVanHarmele @PMinervini @AvilaGarcez @_rockt @hoifungpoon @vaishakbelle  @luislamb and many more 

https://t.co/TgcG9k3mag"
5440,@GaryMarcus,2022-03-30 15:16:02+00:00,https://twitter.com/GaryMarcus/status/1509187704415686658,@NajmehTaleb I fully stand by what I have been saying. most recently discussed here: https://t.co/ze8DtZuHwR
5441,@GaryMarcus,2022-03-30 15:15:37+00:00,https://twitter.com/GaryMarcus/status/1509187599423848449,"@IntuitMachine read the sentence in context; they were saying ‚Äúwould‚Äù with respect to some new set of problems, but presupposing that the rest of the sentence is true."
5442,@GaryMarcus,2022-03-30 14:50:55+00:00,https://twitter.com/GaryMarcus/status/1509181384270573576,"@IntuitMachine that was not expressed as an aspiration, but as a declaration of (allegedly known, but in fact untrue) fact"
5443,@GaryMarcus,2022-03-29 23:54:57+00:00,https://twitter.com/GaryMarcus/status/1508955904523137024,@matthewhurley85 @emilymbender @AllysonEttinger @JudeaPearl it ain‚Äôt all that reliable or robust. see my recent @NautilusMag article
5444,@GaryMarcus,2022-03-29 23:44:41+00:00,https://twitter.com/GaryMarcus/status/1508953321863712769,"@matthewhurley85 i think they have lost the plot. these models are deeper than superficial topic-based architectures they compare, but a long way from being conceptually deep, as https://t.co/C6XodPts1W, @emilymbender, @AllysonEttinger, @judeapearl &amp; larger literature on semantics make clear."
5445,@GaryMarcus,2022-03-29 23:13:22+00:00,https://twitter.com/GaryMarcus/status/1508945439575273472,"Marcus: Neural networks don‚Äôt really understand language deeply.
Twitterverse: Nobody said neural networks understand language deeply.
Meta AI (new blog): ‚ÄúNeural models would be the natural solution because of their ability to understand language deeply"""
5446,@GaryMarcus,2022-03-29 17:06:41+00:00,https://twitter.com/GaryMarcus/status/1508853159556395009,üíØ
5447,@GaryMarcus,2022-03-29 03:46:49+00:00,https://twitter.com/GaryMarcus/status/1508651867911655428,@ImageSnippets @jackclarkSF is that the crux of it?
5448,@GaryMarcus,2022-03-29 03:44:12+00:00,https://twitter.com/GaryMarcus/status/1508651210097631233,@ImageSnippets i think the Gary Smith essay misunderstands what is involved in fine-tuned.
5449,@GaryMarcus,2022-03-29 03:43:21+00:00,https://twitter.com/GaryMarcus/status/1508650994128744455,"@IAmSamFin @jackclarkSF @StatModeling from a different Gary, to be clear; not my article, not my correction"
5450,@GaryMarcus,2022-03-29 03:20:40+00:00,https://twitter.com/GaryMarcus/status/1508645286020755464,"@jackclarkSF @IAmSamFin @StatModeling um, it would be much more helpful if you explained"
5451,@GaryMarcus,2022-03-29 03:18:38+00:00,https://twitter.com/GaryMarcus/status/1508644775204847621,@jackclarkSF @IAmSamFin @StatModeling the same comment that (merely) says that is wildly inaccurate? or one that clears up whichever confusions there are?
5452,@GaryMarcus,2022-03-28 20:01:55+00:00,https://twitter.com/GaryMarcus/status/1508534872326868993,"Trump thought he was the state; Biden knows that he is not and understands the difference. 

A subtle but powerful distinction."
5453,@GaryMarcus,2022-03-27 15:47:33+00:00,https://twitter.com/GaryMarcus/status/1508108471681499136,Hybrid models for the win! Congrats to @nukkailab1 for their decisive victory against 9 leading human bridge players!
5454,@GaryMarcus,2022-03-25 23:40:51+00:00,https://twitter.com/GaryMarcus/status/1507502803454881793,"@johannes_hage Maybe, but GLIDE presented their errors, and this paper doesn‚Äôt have a comparable figure or discussion."
5455,@GaryMarcus,2022-03-25 20:08:03+00:00,https://twitter.com/GaryMarcus/status/1507449253907468290,@timohear @arankomatsuzaki @MetaAI @ylecun Have they? The quantitative data are slightly better; on a very quick skim I didn‚Äôt see discussion or illustration of errors.
5456,@GaryMarcus,2022-03-25 15:27:40+00:00,https://twitter.com/GaryMarcus/status/1507378690816032773,. @NukkAI‚Äôs (mostly?) symbolic AI system is doing very well at this Bridge competition with human experts. ILP pioneer Stephen Muggleton will wrap up 4pm UK time: https://t.co/xJeJCytHdG
5457,@GaryMarcus,2022-03-24 23:27:40+00:00,https://twitter.com/GaryMarcus/status/1507137097827643418,wow. just wow.
5458,@GaryMarcus,2022-03-24 21:33:59+00:00,https://twitter.com/GaryMarcus/status/1507108489524494351,@robosherpa @assadollahi https://t.co/GhrQaleGPb
5459,@GaryMarcus,2022-03-24 20:27:29+00:00,https://twitter.com/GaryMarcus/status/1507091754708713477,"6.5 years later - has AI crushed these problems, or are the same core issues largely unsolved?"
5460,@GaryMarcus,2022-03-24 14:32:59+00:00,https://twitter.com/GaryMarcus/status/1507002543536107522,Super important question.
5461,@GaryMarcus,2022-03-23 21:50:02+00:00,https://twitter.com/GaryMarcus/status/1506750141960654850,@vardi if only we had been drones in the evolutionary environment of adaptation @primalpoly
5462,@GaryMarcus,2022-03-23 21:46:57+00:00,https://twitter.com/GaryMarcus/status/1506749363812384768,"@StevenQuartz @tdietterich for sure, i remember the last chapter well. and we still don‚Äôt have an answer."
5463,@GaryMarcus,2022-03-23 21:43:45+00:00,https://twitter.com/GaryMarcus/status/1506748559147773952,@davheld it‚Äôs all about history; a decade of my life where NN‚Äôs pushed in the opposite direction.
5464,@GaryMarcus,2022-03-23 21:43:07+00:00,https://twitter.com/GaryMarcus/status/1506748402406551553,"@AlexGDimakis @davheld @tdietterich thanks for the private discussion, clarifying"
5465,@GaryMarcus,2022-03-23 21:42:29+00:00,https://twitter.com/GaryMarcus/status/1506748240481333250,"@AlexGDimakis @davheld Fair enough &amp; sorry I misread your tweet; I was attacked (personally) for over a decade for advocating modularity so I was genuinely startled‚Äîbut it is great that the NN community has begun to embrace modularity, and (as you point out) found some means to incorporate it."
5466,@GaryMarcus,2022-03-23 21:21:41+00:00,https://twitter.com/GaryMarcus/status/1506743007613112327,"@tdietterich Fodor was talking about why cognitive agents needed to borrow something from software engineering; the PDP books, aimed both at cognition and software engineering, were arguing you didn‚Äôt need to borrow that thing."
5467,@GaryMarcus,2022-03-23 21:02:49+00:00,https://twitter.com/GaryMarcus/status/1506738258314620928,@LucaAmb @Tkaraletsos your take?
5468,@GaryMarcus,2022-03-23 20:42:18+00:00,https://twitter.com/GaryMarcus/status/1506733095843614720,"@Zergylord @SchmidhuberAI Jay is way under cited, too."
5469,@GaryMarcus,2022-03-23 20:41:31+00:00,https://twitter.com/GaryMarcus/status/1506732900024131584,"@LucaAmb i can see that argument; is it logically necessary, or just a fact about how people have done things?"
5470,@GaryMarcus,2022-03-23 20:36:42+00:00,https://twitter.com/GaryMarcus/status/1506731686154825728,@Zergylord @SchmidhuberAI man you weren‚Äôt there in the 1990s is all i can say.
5471,@GaryMarcus,2022-03-23 20:35:50+00:00,https://twitter.com/GaryMarcus/status/1506731467165999105,"@RemivanTrijp - for sure, modularity goes back much further
- modularity doesn‚Äôt need to be entirely black box; you can have a rich but constrained API in the symbolic world that goes far beyond what deep learning currently allows at interfaces"
5472,@GaryMarcus,2022-03-23 20:29:10+00:00,https://twitter.com/GaryMarcus/status/1506729789087965184,@davheld can show me that deep learning work in modularity that acknowledges the history of work outside the deep learning perspective? is it fair to other scholars if it does not?
5473,@GaryMarcus,2022-03-23 20:24:54+00:00,https://twitter.com/GaryMarcus/status/1506728718374354951,@davheld see discussion w @Zergylord
5474,@GaryMarcus,2022-03-23 20:24:08+00:00,https://twitter.com/GaryMarcus/status/1506728524228399105,"@Zergylord I can see your perspective, but then again I have never once seen an ML paper reference Fodor (etc) on this point; the self-contained and ahistorical nature of how much of ML literature is written is in itself problematic, as @SchmidhuberAI has pointed out in other contexts."
5475,@GaryMarcus,2022-03-23 20:16:58+00:00,https://twitter.com/GaryMarcus/status/1506726721617162241,"@Zergylord sure, if they gave a nod to Fodor."
5476,@GaryMarcus,2022-03-23 20:09:59+00:00,https://twitter.com/GaryMarcus/status/1506724964799373313,"@davheld yes, I realize that. But it still misses the facts

1. that symbolic models have been concerned with modularity for multiple decades
2. many ML people in the 1990s defined themselves against that modularity.

typical of that time was this 2002 summary by McClelland https://t.co/mNynCwDClE"
5477,@GaryMarcus,2022-03-23 20:01:10+00:00,https://twitter.com/GaryMarcus/status/1506722744653606913,"@tdietterich Tom, I can bring dozens of receipts. Here‚Äôs a typical example, from Jay McClelland and Karalyn Patterson, 2002, recapping 15 years of well-known opposition to symbols and modularity: https://t.co/jz3evp8chY"
5478,@GaryMarcus,2022-03-23 19:53:01+00:00,https://twitter.com/GaryMarcus/status/1506720693978746880,"@overlordayn depends on what you want to compose. deep learning has no good way to compose representations of whole (such as sentences or images) out of parts, and generally is weak on between-domain transfer of knowledge."
5479,@GaryMarcus,2022-03-23 19:00:17+00:00,https://twitter.com/GaryMarcus/status/1506707421074403331,"Startling to read this, since symbolic models were modular decades before neural networks were, and a lot of the discussion in the 1980s (eg the past tense debate) was symbol and hybrid people calling for modularity.

Does deep learning really want to take credit for modularity?!"
5480,@GaryMarcus,2022-03-23 18:56:20+00:00,https://twitter.com/GaryMarcus/status/1506706429767344130,"@terrible_archer @NautilusMag @sd_marlow i gave a bunch of pointers to interesting work, outside the current limited box, at the end of @nautilusmag article. and (despite the vocal comments of a small few) most of the feedback on the article was very positive, which suggests a hunger for something new."
5481,@GaryMarcus,2022-03-23 18:24:06+00:00,https://twitter.com/GaryMarcus/status/1506698315450105857,"If you missed this scathing indictment of current AI/ML culture, have a look.

I take a (slightly) more optimistic view, but tried to get at some of the issues in my @NautilusMag article &amp; think @sd_marlow makes some good points. 

The current sociology of AI is not optimal."
5482,@GaryMarcus,2022-03-23 17:55:54+00:00,https://twitter.com/GaryMarcus/status/1506691221304983554,@Abebab thank you for speaking up.
5483,@GaryMarcus,2022-03-23 15:59:58+00:00,https://twitter.com/GaryMarcus/status/1506662046485471232,"@markdhumphries @MikeStuchbery_ I never heard of guy, and won‚Äôt be following. good writer, bad thinker."
5484,@GaryMarcus,2022-03-23 03:50:10+00:00,https://twitter.com/GaryMarcus/status/1506478386025156612,"@JulespHamilton @juicetradesalgo https://t.co/hEugejZWID gives the basic notion, and https://t.co/YytqIg4Bk1 gives some reasonably recent data"
5485,@GaryMarcus,2022-03-23 03:23:25+00:00,https://twitter.com/GaryMarcus/status/1506471651130499072,"@JulespHamilton @juicetradesalgo as an education exercise I urge you to look at the statistics, and consider the probabilities of mild symptoms for vaccinated vs unvaccinated individuals"
5486,@GaryMarcus,2022-03-23 03:21:37+00:00,https://twitter.com/GaryMarcus/status/1506471200012206083,@jon_forsyth @billmaher
5487,@GaryMarcus,2022-03-23 03:20:42+00:00,https://twitter.com/GaryMarcus/status/1506470968897662978,@juicetradesalgo perhaps you might study the statistics before posting?
5488,@GaryMarcus,2022-03-23 03:17:18+00:00,https://twitter.com/GaryMarcus/status/1506470112294891535,which is presumably why she has mild symptoms. how do people with a million followers have such a dismal understanding of biology?
5489,@GaryMarcus,2022-03-22 14:38:32+00:00,https://twitter.com/GaryMarcus/status/1506279164311064576,"Symbolic model beats deep net in modeling human mind‚Äîintriguing recent study by @StanDehaene, discussed in fascinating @sioroberts @nytimes essay.

Consistent with evolution chapter in The Birth of The Mind."
5490,@GaryMarcus,2022-03-22 02:52:37+00:00,https://twitter.com/GaryMarcus/status/1506101512195428359,"goose chronicles, continued

@lcastricato https://t.co/1loOfahqnC"
5491,@GaryMarcus,2022-03-21 21:31:23+00:00,https://twitter.com/GaryMarcus/status/1506020671427547138,neurosymbolic robotics
5492,@GaryMarcus,2022-03-21 21:28:26+00:00,https://twitter.com/GaryMarcus/status/1506019930394660868,excellent language&amp; cognition lab @ stanford seeks research coordinator
5493,@GaryMarcus,2022-03-21 21:09:56+00:00,https://twitter.com/GaryMarcus/status/1506015276298502148,@DrBrianKeating How children learn language
5494,@GaryMarcus,2022-03-21 20:12:32+00:00,https://twitter.com/GaryMarcus/status/1506000829534203905,"not just for me, for the whole field! :)"
5495,@GaryMarcus,2022-03-20 20:27:15+00:00,https://twitter.com/GaryMarcus/status/1505642145545265152,"@pfau @MadamePratolung @Zergylord @YejinChoinka for the record, i wrote a position piece. didn‚Äôt engage Yann. he trolled me multiples times in multiple venues. i asked him directly and politely to engage substantively. 

only after he continued to troll after that did i respond in kind."
5496,@GaryMarcus,2022-03-20 18:51:15+00:00,https://twitter.com/GaryMarcus/status/1505617984278040577,"@MadamePratolung @pfau @Zergylord @YejinChoinka I personally learned a bunch from the debate, and know that I several points that most people weren‚Äôt aware of. anyone who thinks they learned nothing just wasn‚Äôt really paying attention, and missed a lot of the nuance. 

the LeCun-Marcus debate is also worth rewatching."
5497,@GaryMarcus,2022-03-20 18:48:30+00:00,https://twitter.com/GaryMarcus/status/1505617292758986752,"by the way, @jcbaillie is the first winner of my essay contest! hope there will be more :)"
5498,@GaryMarcus,2022-03-20 18:47:13+00:00,https://twitter.com/GaryMarcus/status/1505616969495552001,@sd_marlow @jcbaillie that‚Äôs right - if you don‚Äôt have the right underlying abilities (some but not all symbolic) you don‚Äôt get very far in acquiring culture
5499,@GaryMarcus,2022-03-20 18:39:19+00:00,https://twitter.com/GaryMarcus/status/1505614982209163266,"""to get to human-level intelligence, you need an agent that is actively learning while being immersed in a physical and cultural environment which is strongly influencing the developmental trajectory.""

Interesting discussion on gradient descent and knowledge by @jcbaillie"
5500,@GaryMarcus,2022-03-20 18:18:38+00:00,https://twitter.com/GaryMarcus/status/1505609776276803585,"@jscottwagner @jcbaillie @ylecun i am trying to correct it so i can tweet in good faith without it adding to distortioon of my position, but thanks for your moralizing"
5501,@GaryMarcus,2022-03-20 16:14:46+00:00,https://twitter.com/GaryMarcus/status/1505578607346954242,"@Zergylord @pfau @YejinChoinka what do you mean ‚Äúnot granular enough‚Äù?

there is something much deeper to written, but i couldn‚Äôt even get people to engage in the basics."
5502,@GaryMarcus,2022-03-20 16:00:40+00:00,https://twitter.com/GaryMarcus/status/1505575055186612226,@Zergylord @YejinChoinka @irinarish i‚Äôd be curious what the 81.5 think about what would be adequate.
5503,@GaryMarcus,2022-03-20 15:53:58+00:00,https://twitter.com/GaryMarcus/status/1505573369294512131,"@Zergylord @pfau @YejinChoinka much better version :)

but what of those who ridicule symbols, even in conjunction with deep learning?"
5504,@GaryMarcus,2022-03-20 15:52:03+00:00,https://twitter.com/GaryMarcus/status/1505572889050988547,"@Zergylord @pfau @YejinChoinka it took 80 people to write Gopher; where was the innovation in that paper, architecturally? scaling and measuring the results of scaling takes many PhDs; it‚Äôs a labor intensive work."
5505,@GaryMarcus,2022-03-20 15:50:07+00:00,https://twitter.com/GaryMarcus/status/1505572401513390085,@Zergylord @YejinChoinka my point and yejin‚Äôs is precisely that there is important work to be done orthogonal from scaling.
5506,@GaryMarcus,2022-03-20 15:48:38+00:00,https://twitter.com/GaryMarcus/status/1505572030581821449,"@Zergylord @YejinChoinka megatron, gpt-3 vs gpt-2, gopher, etc. GPT-3 won a best paper award for scaling alone."
5507,@GaryMarcus,2022-03-20 15:44:47+00:00,https://twitter.com/GaryMarcus/status/1505571058908385284,@Zergylord @YejinChoinka and see this workshop and its swag:
5508,@GaryMarcus,2022-03-20 15:43:32+00:00,https://twitter.com/GaryMarcus/status/1505570746990485510,@Zergylord @YejinChoinka it will news to 18.5% of @irinarish‚Äôs poll that you think the their view does not exist.
5509,@GaryMarcus,2022-03-20 15:18:20+00:00,https://twitter.com/GaryMarcus/status/1505564402409484288,@Zergylord @YejinChoinka it is perfectly accurate statement to say that the emphasis on much of the high profile work recently has been primarily on scaling and that that particular technique is inadequate.
5510,@GaryMarcus,2022-03-20 14:19:07+00:00,https://twitter.com/GaryMarcus/status/1505549502396055555,@Zergylord @YejinChoinka this fair to neither Yejin nor me
5511,@GaryMarcus,2022-03-20 14:18:32+00:00,https://twitter.com/GaryMarcus/status/1505549352399347712,@assadollahi it is possible to believe that AI is decades away without being able to produce it. I see no technology on the current horizon that can live up to our current expectations.
5512,@GaryMarcus,2022-03-19 21:52:22+00:00,https://twitter.com/GaryMarcus/status/1505301175830126596,The one algorithm to rule them all.
5513,@GaryMarcus,2022-03-19 20:48:57+00:00,https://twitter.com/GaryMarcus/status/1505285219514867713,"@NaveenGRao says he, calmly and reasonably"
5514,@GaryMarcus,2022-03-19 20:24:48+00:00,https://twitter.com/GaryMarcus/status/1505279141163065345,"Great quote. If you really believe it to be true, maybe you shouldn't tell people to ""shut up""? 

Better would be to engage with the ideas you disagree with, and patiently explain where you think they go wrong. https://t.co/KxL3lIKNyx"
5515,@GaryMarcus,2022-03-19 19:51:18+00:00,https://twitter.com/GaryMarcus/status/1505270709387292672,"@guylevy123 @yoavgo no, that‚Äôs OpenAI."
5516,@GaryMarcus,2022-03-19 19:48:36+00:00,https://twitter.com/GaryMarcus/status/1505270032397336576,"retweeting this @YejinChoinka quote again, because it‚Äôs still true, even a year later with vastly bigger models, and it also important to see that a wide range of researchers with different perspectives all see this reality."
5517,@GaryMarcus,2022-03-19 19:45:17+00:00,https://twitter.com/GaryMarcus/status/1505269195910443009,"@GOFAI_ @RVAwonk motivated reasoning + confirmed bias (discussed in my book Kluge, and throughout the social psychology literature)"
5518,@GaryMarcus,2022-03-19 19:12:04+00:00,https://twitter.com/GaryMarcus/status/1505260835756646402,"The sad thing about misinformation is that is travels faster than more thoughtful attempts to clarify. 

The Yuri Gagarin rumor that is circulating is spreading fast, because it provokes outrage, but quite misleading.  

Kudos to @RVAwonk for tracking down what actually happened."
5519,@GaryMarcus,2022-03-19 14:52:06+00:00,https://twitter.com/GaryMarcus/status/1505195414286311435,best &amp; deepest analysis of my recent essay thus far
5520,@GaryMarcus,2022-03-19 00:47:54+00:00,https://twitter.com/GaryMarcus/status/1504982965922656260,"@rupspace as a field, about 90% of investment in language is currently in large language models; that is a good example of overcommitment. 

ireminds of the fMRI craze in early 2000s, which was very expensive and drew away enormous amounts of talent but not super fruitful in final analysis"
5521,@GaryMarcus,2022-03-18 23:20:22+00:00,https://twitter.com/GaryMarcus/status/1504960937446424576,"@rupspace per my next decade arXiv, I think having hybrid techniques is just the start, though a critical prereq; needs to be combined with rich knowledge bases, rich cognitive models, and flexible reasoning. 

no one algorithm is going to solve this overnight."
5522,@GaryMarcus,2022-03-18 23:18:59+00:00,https://twitter.com/GaryMarcus/status/1504960587054280707,"@paulfkrause ancestors had cue-dependent memory to remember general trends. we evolved human cognition on top of that, rather than starting from scratch with location-addressable memory. when you forget your keys, you retrieve multiple conflicting matches (and lack direct addressable buffers)"
5523,@GaryMarcus,2022-03-18 23:15:54+00:00,https://twitter.com/GaryMarcus/status/1504959810277572610,@rupspace don‚Äôt think we want to replicate human abilities so much as learn from them in cases (eg language and real-world reasoning) in which they exceed our current techniques.
5524,@GaryMarcus,2022-03-18 22:39:48+00:00,https://twitter.com/GaryMarcus/status/1504950728367910912,"That‚Äôs strange. I actually wrote a whole book (Kluge) about why people lose their keys, and why human memory is as lousy as it is."
5525,@GaryMarcus,2022-03-18 16:54:46+00:00,https://twitter.com/GaryMarcus/status/1504863897345413121,@cigitalgem no worries! glad you enjoyed.
5526,@GaryMarcus,2022-03-18 16:36:02+00:00,https://twitter.com/GaryMarcus/status/1504859180947021824,@MadamePratolung @irinarish @abombayboy @ylecun or @irinarish to represent the scaling arguments. I would welcome both a 1:1 (a la #AIDebate1) and/or a broader discussion (a la #AIDebate2).
5527,@GaryMarcus,2022-03-18 16:08:13+00:00,https://twitter.com/GaryMarcus/status/1504852183442857987,"That would be great. if you can bring Yoshua to the table, I am sure @Montreal_AI would be glad to host, and @MLStreetTalk would be glad to turn it into a podcast."
5528,@GaryMarcus,2022-03-18 15:54:57+00:00,https://twitter.com/GaryMarcus/status/1504848842302246918,"@pfau @MadamePratolung @ylecun David that is not fair. I posted the article, but did not point to anyone individually. LeCun was not even mentioned in the article &amp; I did not try to interact w him at all, until he repeatedly posted dismissive remarks on Facebook (that were forwarded to me)"
5529,@GaryMarcus,2022-03-18 15:32:14+00:00,https://twitter.com/GaryMarcus/status/1504843125667217412,"essay contest: if anyone has a substantive, long-form critique of my @NautilusMag contention that deep learning is approaching a wall in language comprehension &amp; scene understanding, please send a link, and I will RT

my key points are recapped below, to give you a starting point"
5530,@GaryMarcus,2022-03-18 15:21:39+00:00,https://twitter.com/GaryMarcus/status/1504840463957647365,"@pfau @MadamePratolung @ylecun i wrote a substantive long form piece engaging a large swathe of the recent literature; i would heartily welcome anyone on the other side to mount the arguments their for shifting resources from scaling to hybrids, in a comparable long form piece."
5531,@GaryMarcus,2022-03-18 15:16:21+00:00,https://twitter.com/GaryMarcus/status/1504839129179193346,"would prefer substantive engagement around key points to üî•:
üëâsymbol system win in #nethack
üëâfailures in scaling in some areas
üëâerratic deep learning performance
üëâgrowing literature on neurosymbolic success in some tasks
üëâcould language comprehension be solved, w hybrids?"
5532,@GaryMarcus,2022-03-18 15:06:05+00:00,https://twitter.com/GaryMarcus/status/1504836546599407619,"@overlordayn @primrecur @BlancheMinerva @ylecun excellent question. one could make that argument, and eg ask whether you could actually get a transformer to work without such components. i wrote a related remark on symbols yesterday that is relevant here: https://t.co/vSyahr0ngu"
5533,@GaryMarcus,2022-03-18 14:49:55+00:00,https://twitter.com/GaryMarcus/status/1504832478153826305,"Study of the day: ‚Äúscholars .. surveyed 26 studies of internet ‚Äútrolling,‚Äù cyberbullying, and related antisocial online behaviors. They found significant associations with psychopathy, Machiavellianism, sadism, and narcissism, in that order.‚Äù https://t.co/HwZYX3znx8"
5534,@GaryMarcus,2022-03-18 14:39:47+00:00,https://twitter.com/GaryMarcus/status/1504829925114621955,"@irinarish @abombayboy @ylecun i would be glad to have a public, substantive debate with the two of you."
5535,@GaryMarcus,2022-03-18 12:39:05+00:00,https://twitter.com/GaryMarcus/status/1504799550027939843,"@ylecun @jingle__belle i think you can expect an interesting modeling paper soon, thanks."
5536,@GaryMarcus,2022-03-18 01:43:14+00:00,https://twitter.com/GaryMarcus/status/1504634501044977670,@christian_moerk not even his mother
5537,@GaryMarcus,2022-03-17 23:14:49+00:00,https://twitter.com/GaryMarcus/status/1504597152667893766,"@pfau @ylecun it‚Äôs not about making my point, it‚Äôs about engaging a broader community in solutions to the real problems of synthetic intelligence. 

if eg some student were to realize how deeply important the type-token problem is, it would all be worthwhile

1-liners reduces that chance"
5538,@GaryMarcus,2022-03-17 23:08:19+00:00,https://twitter.com/GaryMarcus/status/1504595515475857409,"@pfau @ylecun honestly i would welcome anyone in the field to address the collection of points, beyond ‚Äúwe‚Äôve heard it before‚Äù; they all need to be tackled directly, which is hard to do when people don‚Äôt recognize their importance.

so, no."
5539,@GaryMarcus,2022-03-17 23:03:18+00:00,https://twitter.com/GaryMarcus/status/1504594252252151816,@pfau @ylecun these:
5540,@GaryMarcus,2022-03-17 23:02:52+00:00,https://twitter.com/GaryMarcus/status/1504594144152354825,"@pfau @ylecun not once has he engaged in the arguments that I recapped this morning. i think it would actually be of considerable value if he did. 

so I keep trying."
5541,@GaryMarcus,2022-03-17 22:52:15+00:00,https://twitter.com/GaryMarcus/status/1504591470384218126,‚ÄúStudents were told that they would not receive passing grades unless they built the author a CNN‚Äù ü§£
5542,@GaryMarcus,2022-03-17 22:37:29+00:00,https://twitter.com/GaryMarcus/status/1504587753802985480,"@BlancheMinerva @lovetheusers @ylecun as I said last week and at more length in The Algebraic Mind, embeddings *are* symbols. so are labels on inputs and outputs‚Äîbut that alone is not enough to yield humanlike cognition; the debate isn‚Äôt really about symbols but symbol *manipulation*"
5543,@GaryMarcus,2022-03-17 22:31:58+00:00,https://twitter.com/GaryMarcus/status/1504586366927007753,"@BlancheMinerva @lovetheusers @ylecun i wouldn‚Äôt claim it in general form. they do not supply the 3 things that I identified in 2001 as üîë
üëâ way to represent &amp; compute operations over symbolic variables
üëâ mean to represent/track instances distinctly from kinds
üëâ means to represent wholes in terms of their parts"
5544,@GaryMarcus,2022-03-17 22:25:13+00:00,https://twitter.com/GaryMarcus/status/1504584666619080719,"My vote for the most important call of the century of so far, with lasting impact on everything to follow."
5545,@GaryMarcus,2022-03-17 21:22:33+00:00,https://twitter.com/GaryMarcus/status/1504568896581300231,"Upcoming competition, human-in-the-loop bridge, sponsored by @nukkailab1. Should be interesting!"
5546,@GaryMarcus,2022-03-17 20:51:28+00:00,https://twitter.com/GaryMarcus/status/1504561076574175234,"Read this elsewhere, but seems to have some relevance for AI ü§î"
5547,@GaryMarcus,2022-03-17 20:42:23+00:00,https://twitter.com/GaryMarcus/status/1504558790758187014,"Yes, I am willing to bet that neurosymbolic (or some more tractable successor there to) will dominate https://t.co/q5S7RiEaXz in 5 years."
5548,@GaryMarcus,2022-03-17 20:11:24+00:00,https://twitter.com/GaryMarcus/status/1504550990602649602,@BlancheMinerva @ylecun @AvilaGarcez @luislamb @swarat @kerstingAIML also @animesh_garg @maier_ak @frossi_t (and many people not on twitter; i gave an incomplete list of research groups in the Nautilus piece)
5549,@GaryMarcus,2022-03-17 20:06:44+00:00,https://twitter.com/GaryMarcus/status/1504549818642808833,"@sir_deenicus @BlancheMinerva @ylecun it‚Äôd be really fantastic if someone would read the lengthy and careful discussion I had of this in Chapter 2 of the Algebraic Mind, and either agree or come up with an alternative."
5550,@GaryMarcus,2022-03-17 20:05:48+00:00,https://twitter.com/GaryMarcus/status/1504549581874368514,"@primrecur @BlancheMinerva @ylecun neurosymbolic, because of the tree search; AlphaFold2 also has very carefully handcrafted symbolic representations."
5551,@GaryMarcus,2022-03-17 20:04:53+00:00,https://twitter.com/GaryMarcus/status/1504549353259634688,@BlancheMinerva @ylecun @AvilaGarcez @luislamb @swarat @kerstingAIML
5552,@GaryMarcus,2022-03-17 20:04:10+00:00,https://twitter.com/GaryMarcus/status/1504549173311418369,"@BlancheMinerva @ylecun in 2004, dl led on nothing; NS day will come. in my piece I pointed to Alpha* models that rely partly on symbolic tree search&amp;Tenenbaum group on scene understanding

Benchmarks favor near-term gaming that plays towards deep learning‚Äôs strength but may put field in a local maximum"
5553,@GaryMarcus,2022-03-17 18:57:37+00:00,https://twitter.com/GaryMarcus/status/1504532423370960910,"@BlancheMinerva @ylecun Imagine if we had asked his question about deep learning in 2002, and decided to put all our eggs into SVMs?"
5554,@GaryMarcus,2022-03-17 18:56:08+00:00,https://twitter.com/GaryMarcus/status/1504532049117409282,"not sure this bears on the what I meant. e.g., keeping track of your specific mugs amid many similar looking mugs, or learning an individual-level property of a particular person without generalizing to all (similar) people, or tracking properties of individuals over time."
5555,@GaryMarcus,2022-03-17 18:50:56+00:00,https://twitter.com/GaryMarcus/status/1504530742587518988,"indeed, great work @rockt and @egrefen and colleagues in putting https://t.co/q5S7RiEaXz together. 

Symbols emerged victorious this year, hybrids next? üôÇ"
5556,@GaryMarcus,2022-03-17 17:25:37+00:00,https://twitter.com/GaryMarcus/status/1504509271165194250,@olcan I am still waiting for @Ylecun to explain why he said Deep Learning: A  Critical Appraisal was ‚Äúmostly wrong‚Äù‚Ä¶
5557,@GaryMarcus,2022-03-17 17:23:48+00:00,https://twitter.com/GaryMarcus/status/1504508812841013261,@stanislavfort @tyrell_turing @LucaAmb Answered here;I would welcome your thoughts and from your colleagues at @AnthropicAI:
5558,@GaryMarcus,2022-03-17 17:21:46+00:00,https://twitter.com/GaryMarcus/status/1504508301576327169,"@grsimari that said i actually read this particular person‚Äôs post as a bona fide question, rather than a game of burden tennis that some others are playing."
5559,@GaryMarcus,2022-03-17 17:19:55+00:00,https://twitter.com/GaryMarcus/status/1504507835920490497,@grsimari https://t.co/iJnvaG6TYg
5560,@GaryMarcus,2022-03-17 17:17:45+00:00,https://twitter.com/GaryMarcus/status/1504507294008037402,"@LucaAmb @tyrell_turing @bradpwyble could be profitable, may turn out to have a neurosymbolic structure"
5561,@GaryMarcus,2022-03-17 17:16:13+00:00,https://twitter.com/GaryMarcus/status/1504506906693423107,"@Zergylord @ylecun nor acknowledging that a symbolic system won, is he? (haven‚Äôt seen it reflected in his rhetoric if he has)"
5562,@GaryMarcus,2022-03-17 14:45:31+00:00,https://twitter.com/GaryMarcus/status/1504468981867900937,@tyrell_turing @LucaAmb @egrefen
5563,@GaryMarcus,2022-03-17 14:38:31+00:00,https://twitter.com/GaryMarcus/status/1504467218347614216,"2001 prediction: we would not be able to create a human-like general intelligence without solving those problems.

2012 @NewYorker prediction: DEEP LEARNING would face problems with  reasoning, causality, language understanding.

2016 Edge prediction: driverless cars v. hard"
5564,@GaryMarcus,2022-03-17 14:38:30+00:00,https://twitter.com/GaryMarcus/status/1504467217089409030,"Goalposts, unchanged since 2001:

1. freely generalizing universally-quantified one-to-one mappings in and out of distribution 
2. understanding compositional wholes in terms of parts
3. distinguishing tokens from types &amp; building cognitive models accordingly

-The Algebraic Mind"
5565,@GaryMarcus,2022-03-17 14:13:08+00:00,https://twitter.com/GaryMarcus/status/1504460833585176581,@ylecun i responded to this here: https://t.co/cDLthvjuLW
5566,@GaryMarcus,2022-03-17 14:10:39+00:00,https://twitter.com/GaryMarcus/status/1504460206100545537,"Come on @YLeCun, you didn‚Äôt engage in the actual argument:
üëâsymbol system winning #nethack
üëâfailures in scaling in some areas
üëâerratic deep learning performance
üëâgrowing literature on neurosymbolic succeeding in some tasks
üëâidea that wall could be overcome, cooperatively"
5567,@GaryMarcus,2022-03-17 13:50:21+00:00,https://twitter.com/GaryMarcus/status/1504455099770310659,@tyrell_turing @LucaAmb sure; when i originally posted about it i said i expect hybrids to overtake both next year. still do
5568,@GaryMarcus,2022-03-17 13:17:26+00:00,https://twitter.com/GaryMarcus/status/1504446814606430208,@tyrell_turing @LucaAmb and when those successes are reported (eg the Nethack competition that was literally at the climax of my article) the deep learning community focuses on the title rather than engaging.
5569,@GaryMarcus,2022-03-17 03:06:26+00:00,https://twitter.com/GaryMarcus/status/1504293053128867846,"@norpadon my whole argument is that *neither side* has made the advances that we need and that we need to try to work together.

sorry that doesn‚Äôt fit your straw person rhetoric but maybe you should read what i actually said
in the @nautilusmag essay?"
5570,@GaryMarcus,2022-03-17 02:58:52+00:00,https://twitter.com/GaryMarcus/status/1504291146129829894,"here is @ylecun, perfectly exemplifying my claim that leaders in deep learning aggressive dichotomize the world and bully those holding other views.

not a good look for science."
5571,@GaryMarcus,2022-03-17 02:50:12+00:00,https://twitter.com/GaryMarcus/status/1504288966744322051,@LucaAmb @AngeloDalli https://t.co/43filMNrld
5572,@GaryMarcus,2022-03-17 02:46:28+00:00,https://twitter.com/GaryMarcus/status/1504288027509592065,"who is talking about reverting entirely to pure symbolic models, abandoning deep learning? certainly not me, not once in anything I have written in 30 years.

I call rhetorical straw person bullshit."
5573,@GaryMarcus,2022-03-16 21:54:16+00:00,https://twitter.com/GaryMarcus/status/1504214493210955780,+1!
5574,@GaryMarcus,2022-03-16 21:34:27+00:00,https://twitter.com/GaryMarcus/status/1504209503276789760,"Just discovered that @HumanCenteredAI is on Twitter (and plans to become more active here, soon); in the meantime, see also their Google Group."
5575,@GaryMarcus,2022-03-16 19:16:35+00:00,https://twitter.com/GaryMarcus/status/1504174809252466690,sure @filippie509 but how big was the training set?
5576,@GaryMarcus,2022-03-16 16:41:48+00:00,https://twitter.com/GaryMarcus/status/1504135856860266498,"@maier_ak though to be clear, my concerns also included (a) the relation between things that are scaleable and things that might not be and (b) that scaling might cease to return value even before resources limits are reached."
5577,@GaryMarcus,2022-03-16 05:54:58+00:00,https://twitter.com/GaryMarcus/status/1503973077473931269,@rao2z https://t.co/hS1EkVBgfV
5578,@GaryMarcus,2022-03-16 03:36:29+00:00,https://twitter.com/GaryMarcus/status/1503938226641416194,@Plinz https://t.co/hS1EkVSREv
5579,@GaryMarcus,2022-03-16 03:34:16+00:00,https://twitter.com/GaryMarcus/status/1503937668371021825,"for the avoidance of doubt, I think all of the below are important advances. 

But also that none adequately address the basic challenges in reasoning,  compositionally and broad generalization that I raised in my 2001 book, and that I see as critical for cognition and AGI."
5580,@GaryMarcus,2022-03-16 03:24:28+00:00,https://twitter.com/GaryMarcus/status/1503935200253800453,"on the need for a new paradigm that is less static, less offline and more sample-efficient, @plinz and I are in 100% agreement. 

my guess is that that will happen in the next 33 years, and dwarf the last 33."
5581,@GaryMarcus,2022-03-16 03:20:41+00:00,https://twitter.com/GaryMarcus/status/1503934250566836226,@tdietterich i am genuinely concerned about being misrepresented
5582,@GaryMarcus,2022-03-16 03:19:13+00:00,https://twitter.com/GaryMarcus/status/1503933881174540292,"@marktenenholtz here is an example, be sure to watch the second piece in the replies: https://t.co/iMyPzukdJy"
5583,@GaryMarcus,2022-03-16 03:17:27+00:00,https://twitter.com/GaryMarcus/status/1503933434963525632,"@marktenenholtz 97% of research $ go in that direction , and the leaders in deep learning try to extinguish other work"
5584,@GaryMarcus,2022-03-16 03:15:58+00:00,https://twitter.com/GaryMarcus/status/1503933061276131330,"@marktenenholtz because they are so dismissive of symbols. it‚Äôs not that i think symbols alone suffice; i don‚Äôt. it‚Äôs because they are dismissive of hybrids and I can‚Äôt see any other way to succeed. 

that said, hybrids are not sufficient either; just necessary. see https://t.co/9Gh30uZzok"
5585,@GaryMarcus,2022-03-16 03:11:00+00:00,https://twitter.com/GaryMarcus/status/1503931814275997699,@marktenenholtz also we will look back and think wow the discoveries from 2022-2027 were essential in weaning us from needing truly massive data for most problems.
5586,@GaryMarcus,2022-03-16 03:09:43+00:00,https://twitter.com/GaryMarcus/status/1503931488433188864,"@marktenenholtz and yes of course there 6 millions ways to solve MNIST - and zero to solve AGI.

not of course saying that there hasn‚Äôt been any progress at all."
5587,@GaryMarcus,2022-03-16 03:08:22+00:00,https://twitter.com/GaryMarcus/status/1503931151051681799,"@marktenenholtz what‚Äôs the twitter handle for remind me in 5 years? i don‚Äôt doubt deep learning will still be part of things but think in five years we will have much better tools for integrating symbolic priors into the mix, &amp; wonder why in 2022 the vast majority of models didn‚Äôt use such tools"
5588,@GaryMarcus,2022-03-16 03:02:44+00:00,https://twitter.com/GaryMarcus/status/1503929730789109767,"if you misrepresent me as anti-deep learning when every article I write is *pro* deep learning (hybridized with other techniques), you are being political

reality is that I am pro deep learning; Hinton is anti-symbol.

nobody in pure deep learning wants to acknowledge that fact"
5589,@GaryMarcus,2022-03-16 02:50:27+00:00,https://twitter.com/GaryMarcus/status/1503926641050804224,"Hinton and @ylecun like to pretend that the only person who disagrees with them is me; reality is quite different, as expressed here by @bengoertzel &amp; eg by Tenenbaum (https://t.co/nw2SIX1AOC), @AvilaGarcez,  @luislamb, @frossi_t, @swarat, Anima Anandkumar, @YejinChoinka etc"
5590,@GaryMarcus,2022-03-16 02:30:40+00:00,https://twitter.com/GaryMarcus/status/1503921662172884995,"@Plinz @bengoertzel you are either naive about funding, reviewing etc or pretending to be naive"
5591,@GaryMarcus,2022-03-16 02:29:37+00:00,https://twitter.com/GaryMarcus/status/1503921400167350272,@ethancaballero @Plinz @plazehodler thanks - that‚Äôs interesting.
5592,@GaryMarcus,2022-03-16 02:20:06+00:00,https://twitter.com/GaryMarcus/status/1503919001595875333,"@Plinz @bengoertzel astonished that you don‚Äôt think that politics plays a role. there is a feedback cycle where certain people have pushed massive investments in their own students, making it impossible for others to keep up, prematurely sucking oxygen  from other approaches, per @emilymbender"
5593,@GaryMarcus,2022-03-16 02:14:58+00:00,https://twitter.com/GaryMarcus/status/1503917711469920257,"@Plinz wasn‚Äôt it you just a moment ago crowing about how recognizable it all was? incremental innovations, sure."
5594,@GaryMarcus,2022-03-16 02:04:26+00:00,https://twitter.com/GaryMarcus/status/1503915062318145540,@Plinz https://t.co/FmOpb9RzKQ
5595,@GaryMarcus,2022-03-16 02:04:13+00:00,https://twitter.com/GaryMarcus/status/1503915004281511946,"@Plinz @plazehodler except when it is ‚Äúreliable performance‚Äù, ‚Äúcatastrophic interference‚Äù, or ‚Äúavoiding ridiculous errors‚Äù, to take 3 examples that have been around for 33 years and not solved"
5596,@GaryMarcus,2022-03-16 01:59:02+00:00,https://twitter.com/GaryMarcus/status/1503913702944243714,"‚Äúlook at how great we are! we haven‚Äôt had a fundamentally new idea in 33 years!‚Äù 

not a sign of healthy field."
5597,@GaryMarcus,2022-03-16 01:48:08+00:00,https://twitter.com/GaryMarcus/status/1503910958032306176,"As long as focus almost entirely on neural networks, as ‚Äúonly path of success‚Äù, you are unlikely to find the success you seek, young warrior."
5598,@GaryMarcus,2022-03-16 01:09:42+00:00,https://twitter.com/GaryMarcus/status/1503901285497524225,@roschler @OpenAI @Merzmensch @NoelleSilver_ valiantly fought off with cartoons and facebook posts
5599,@GaryMarcus,2022-03-16 00:22:42+00:00,https://twitter.com/GaryMarcus/status/1503889457732210691,@roschler @OpenAI @Merzmensch @NoelleSilver_ any progress since that 12/20 demo?
5600,@GaryMarcus,2022-03-15 22:17:18+00:00,https://twitter.com/GaryMarcus/status/1503857901232091137,"Q: ‚ÄúRussia‚Äôs invasion of Ukraine may also have dealt a severe blow to our hopes of tackling the climate crisis, at least in this decade. Do you have any comments?‚Äù

Chomsky: ‚ÄúThe blow is not only severe, but it may also be terminal for organized human life on earth‚Äù"
5601,@GaryMarcus,2022-03-15 20:44:54+00:00,https://twitter.com/GaryMarcus/status/1503834647813234689,"@RomainBrette and if invert the order of touching fingers and toes, have I not dealt with arbitrary reprogrammability?"
5602,@GaryMarcus,2022-03-15 20:43:58+00:00,https://twitter.com/GaryMarcus/status/1503834412965715968,"@RomainBrette I guess on a skim that I don‚Äôt quite see those replies. By ‚Äúbrain is a computer, one must demonstrate that there is a way
in which the brain‚Äôs programs can be changed arbitrarily‚Äù you are entailing that an FPGA is no longer a computer once it is burned in, no?"
5603,@GaryMarcus,2022-03-15 20:06:04+00:00,https://twitter.com/GaryMarcus/status/1503824873818255360,@RomainBrette https://t.co/UO1oP6ZTXv
5604,@GaryMarcus,2022-03-15 20:05:02+00:00,https://twitter.com/GaryMarcus/status/1503824616074080259,"@KordingLab hmm; says brain is not a programmable computer, wrong in at least some sense (‚Äútouch your fingers, now touch your toes‚Äù) and narrow in another (FPGAs are computers, but they don‚Äôt download programs in the canonical sense).

i anticipated some of this here: https://t.co/2eyQc2x9ol"
5605,@GaryMarcus,2022-03-15 18:59:57+00:00,https://twitter.com/GaryMarcus/status/1503808237375660036,"@nutanc @filippie509 @guru_ai how much cherry-picking do you do? what‚Äôs the prompt? also would be interesting to know which are straight from the training set, or just modified with synonymy"
5606,@GaryMarcus,2022-03-15 18:57:11+00:00,https://twitter.com/GaryMarcus/status/1503807541733564416,"@davis_yoshida @Jonatha46333329 @j_br__ @hxt55 Am willing to let it go, since your species has state-of-the-art language, cognitive modeling and reasoning capabilities. though the reasoning capabilities in particular could definitely be radically improved‚Ä¶"
5607,@GaryMarcus,2022-03-15 16:25:40+00:00,https://twitter.com/GaryMarcus/status/1503769408224653312,@filippie509 you forgot PR. They are exceptionally good at that.
5608,@GaryMarcus,2022-03-15 14:49:52+00:00,https://twitter.com/GaryMarcus/status/1503745300887916555,Tucker Carlson
5609,@GaryMarcus,2022-03-15 04:36:19+00:00,https://twitter.com/GaryMarcus/status/1503590895987294213,@lizardcry ‚àö cause massive refugee crisis
5610,@GaryMarcus,2022-03-15 04:27:36+00:00,https://twitter.com/GaryMarcus/status/1503588701410004992,"March 2022 To Do List
‚àö destroy reputation
‚àö destroy banking system
‚àö alienate tech industry
‚àö alienate airline industry
‚àö kill civilians
‚àö crash currency
‚àö freeze stock market
‚àö end free speech
‚àö humiliate military
‚àö induce brain drain
‚àö alienate most nations"
5611,@GaryMarcus,2022-03-15 02:32:01+00:00,https://twitter.com/GaryMarcus/status/1503559616386404352,"@christian_moerk me, too"
5612,@GaryMarcus,2022-03-15 02:15:44+00:00,https://twitter.com/GaryMarcus/status/1503555516974346242,"@christian_moerk another week like this, and they will be down to flint knives and smoke signals."
5613,@GaryMarcus,2022-03-15 01:58:52+00:00,https://twitter.com/GaryMarcus/status/1503551270790975490,"good luck getting parts, again. ever."
5614,@GaryMarcus,2022-03-15 01:57:16+00:00,https://twitter.com/GaryMarcus/status/1503550869584769025,‚âà üá∫üá¶ defends NATO
5615,@GaryMarcus,2022-03-15 01:52:36+00:00,https://twitter.com/GaryMarcus/status/1503549696081465344,"@irinarish i still recommend you remind my essay; I am well aware of the sort of argument you are making, but think it is deeply flawed."
5616,@GaryMarcus,2022-03-15 00:11:18+00:00,https://twitter.com/GaryMarcus/status/1503524203051462657,"@Plinz @Prim8Substr8 @majodali ‚âà auto accidents kill people, so nothing wrong with guns. 

but aside from that, who uses Excel to run their chatbots?"
5617,@GaryMarcus,2022-03-14 23:41:34+00:00,https://twitter.com/GaryMarcus/status/1503516717309313026,. @rgoodlaw is always worth reading. Model prosecution memo for Russian Dictator Vladimir Putin.
5618,@GaryMarcus,2022-03-14 23:14:24+00:00,https://twitter.com/GaryMarcus/status/1503509883114516482,"@punkstrategy @Plinz no, but it‚Äôs subtle, and best explained in chapter 2 of the algebraic mind. not twitter-sized argument."
5619,@GaryMarcus,2022-03-14 23:00:48+00:00,https://twitter.com/GaryMarcus/status/1503506461879521280,@punkstrategy @Plinz in the canonical cases there are symbols on the input and output; but not operations over variables in between
5620,@GaryMarcus,2022-03-14 22:49:50+00:00,https://twitter.com/GaryMarcus/status/1503503700131663873,"@majodali @Plinz this is nonsense, and dangerous inasmuch/insofar as anyone uses the stuff IRL"
5621,@GaryMarcus,2022-03-14 22:49:05+00:00,https://twitter.com/GaryMarcus/status/1503503511090200577,"@majodali @Plinz GPT has no intention, ever &amp; that‚Äôs the core to the problem

most computational production work is about creating a sentence from an intention; GPT sidesteps &amp; just predicts stuff‚Äîwhich means you can‚Äôt constrain the intention, and that‚Äôs where trouble begins. downhill from there"
5622,@GaryMarcus,2022-03-14 22:38:32+00:00,https://twitter.com/GaryMarcus/status/1503500855504367617,"the deep learning edition of ‚Äúguns don‚Äôt kill people, people kill people‚Äù

any use of GPT-3 should certainly contain a warning label: ‚Äúthis system is unreliable and has been known to make stuff up, to offend people, and to encourage harm‚Äù

but is that enough?"
5623,@GaryMarcus,2022-03-14 22:32:21+00:00,https://twitter.com/GaryMarcus/status/1503499301502152706,@majodali @Plinz Of course it makes stuff up. I gave an example above with the socks.
5624,@GaryMarcus,2022-03-14 21:09:36+00:00,https://twitter.com/GaryMarcus/status/1503478476455567361,"@VishalGulati_ sure, and inadvertently mobilizing the opposition, with adverse consequences for all of us."
5625,@GaryMarcus,2022-03-14 21:08:36+00:00,https://twitter.com/GaryMarcus/status/1503478225569140737,"@Plinz no doubt. but systems like GPT-3 make up stuff regularly; it‚Äôs a well-documented in the literature, and easily replicated.  

Your argument is like trying to argue against a connection between cigarettes and lung cancer because some people get lung cancer without smoking."
5626,@GaryMarcus,2022-03-14 20:14:59+00:00,https://twitter.com/GaryMarcus/status/1503464730828050432,"I am prepared to believe that a 4th shot may at some point be necessary, and prepared to take one if data clearly suggest it. 

But it was counterproductive &amp; tone deaf for the Pfizer CEO to say so prematurely, prior to a full presentation of the data.

https://t.co/hiAQHyb8rg"
5627,@GaryMarcus,2022-03-14 19:57:00+00:00,https://twitter.com/GaryMarcus/status/1503460203563401218,@sanjaykalra how about knowingly using an inadequate tool that might cause harm?
5628,@GaryMarcus,2022-03-14 19:55:52+00:00,https://twitter.com/GaryMarcus/status/1503459917931364352,"@terrible_archer in other words: Ignorance of the law, and well, literally everything else, is no excuse"
5629,@GaryMarcus,2022-03-14 19:43:40+00:00,https://twitter.com/GaryMarcus/status/1503456849063919617,"@AlexKan04442434 ‚Äúcan‚Äôt possibly‚Äù *on its own*; certainly deep learning can contribute in useful ways 

i think you are quite right in your analysis"
5630,@GaryMarcus,2022-03-14 19:40:52+00:00,https://twitter.com/GaryMarcus/status/1503456145209323520,"What?! Totally false to claim that statistical methods don‚Äôt fabricate or generate misinformation 

People may fabricate maliciously; GPT literally doesn‚Äôt know any better, because it can‚Äôt differentiate between truth and stats. 

Samples below, some created whole cloth. https://t.co/VnmescOiXb"
5631,@GaryMarcus,2022-03-14 16:09:46+00:00,https://twitter.com/GaryMarcus/status/1503403018129080325,@yourauntemma
5632,@GaryMarcus,2022-03-14 16:04:17+00:00,https://twitter.com/GaryMarcus/status/1503401641185320965,"[Movie Preview Voiceover]

Two world-class narcissists square off, fighting for the fate of the world."
5633,@GaryMarcus,2022-03-14 16:00:38+00:00,https://twitter.com/GaryMarcus/status/1503400722133528577,"@ChrSzegedy @TheSaddlePoint @GuillaumeLample @f_charton do the scope and reliability matter? does ELIZA count, becomes sometimes you can talk to in NL and get reasonable advice?"
5634,@GaryMarcus,2022-03-14 15:45:19+00:00,https://twitter.com/GaryMarcus/status/1503396865659662338,"@AndrewLampinen @sd_marlow I‚Äôm saying that deep learning must be supplemented, eg with symbolic operations. Like scratchpads!

I‚Äôm not saying it‚Äôs failing; I am saying it can‚Äôt work on its own."
5635,@GaryMarcus,2022-03-14 15:43:08+00:00,https://twitter.com/GaryMarcus/status/1503396316226850822,"Deep learning, on its own, cannot be trusted. It is capable of epic feats of math, but utterly lacks judgment; it cannot compute whether its math leads to a good outcome for humans, and it cannot even represent a good outcome would be.

This is why we so badly need hybrid models."
5636,@GaryMarcus,2022-03-14 15:43:07+00:00,https://twitter.com/GaryMarcus/status/1503396314876313600,"No, @plinz, deep learning is not inherently toxic, evil, or biased; but it *is* inherently clueless, difficult to control, &amp; incapable of representing &amp; reflecting human values‚Äîhence prone to fabrication, toxic language, harmful advice &amp; perpetuating bias &amp; misinformation.

1/2"
5637,@GaryMarcus,2022-03-14 15:10:51+00:00,https://twitter.com/GaryMarcus/status/1503388194515021824,"and then suddenly {narrator intones} to the surprise of everyone, even their own creators, Transformers become (slightly) conscious..."
5638,@GaryMarcus,2022-03-14 15:07:45+00:00,https://twitter.com/GaryMarcus/status/1503387412084404226,"@AiSimonThompson @khademinori @Plinz if that's all they were used for, and all that was claimed for them, i woukd have zero objection"
5639,@GaryMarcus,2022-03-14 14:35:00+00:00,https://twitter.com/GaryMarcus/status/1503379169572372480,"actually, that was the entire point of my essay, @plinz: that there is no binary choice between deep learning and symbolic approaches, and that we must join forces. https://t.co/DiMFADDjqP"
5640,@GaryMarcus,2022-03-14 13:45:03+00:00,https://twitter.com/GaryMarcus/status/1503366601474682881,"@AndrewLampinen @sd_marlow how can you say the architecture doesn‚Äôt matter if you need a scratchpad, which is basically a place to store and retrieve the value of a variable?"
5641,@GaryMarcus,2022-03-14 13:43:42+00:00,https://twitter.com/GaryMarcus/status/1503366261157244933,@ChrSzegedy @TheSaddlePoint @GuillaumeLample @f_charton what is your definition of intelligence? there is certainly a role for deep learning but I am surprised by your phrasing.
5642,@GaryMarcus,2022-03-14 02:41:00+00:00,https://twitter.com/GaryMarcus/status/1503199488218857473,@irinarish @gollum77 @Montreal_AI @markcannon5 @ceobillionaire @francoisfleuret @Plinz @Mila_Quebec and it‚Äôs exactly the point that I closed my @NautilusMag and #AIdebate2 with‚Ä¶ https://t.co/iXKMxYlC39
5643,@GaryMarcus,2022-03-13 23:44:30+00:00,https://twitter.com/GaryMarcus/status/1503155067876089856,"@Miles_Brundage @NautilusMag have you folks at OpenAI tried SCROLLS yet? https://t.co/Gd4kpowiV1 @Uri_Shaham @maorivg @JonathanBerant 

I haven‚Äôt studied it carefully yet but I think it comes closer to what we need. Most existing benchmarks are superficial and too easily gamed."
5644,@GaryMarcus,2022-03-13 23:39:17+00:00,https://twitter.com/GaryMarcus/status/1503153754819813377,"@Miles_Brundage @NautilusMag blunt question: do you think we are scaling on actual comprehension, or just on benchmarks?"
5645,@GaryMarcus,2022-03-13 23:37:43+00:00,https://twitter.com/GaryMarcus/status/1503153362572783616,"@rasbt @irinarish @NautilusMag I would say no towards AGI, and yes it depends on what you care about."
5646,@GaryMarcus,2022-03-13 23:35:16+00:00,https://twitter.com/GaryMarcus/status/1503152745221541889,"@Miles_Brundage @NautilusMag this is mostly about power consumption, which while relevant, is not the issue I was raising, which is about saturation on accuracy/reliability"
5647,@GaryMarcus,2022-03-13 23:34:39+00:00,https://twitter.com/GaryMarcus/status/1503152590913097729,"@Miles_Brundage @NautilusMag yes, but mostly not in the context of the critical question of whether scaling on the things we can measure actually get us where we want to be. 

I pulled together quotes etc  from places that discuss briefly in passing, haven‚Äôt seen any effort to wrestle with the implications."
5648,@GaryMarcus,2022-03-13 23:31:58+00:00,https://twitter.com/GaryMarcus/status/1503151913704906755,"@Miles_Brundage @NautilusMag I think this is actually the crux; a large fraction of the field is running around as if they assume that they *are* laws that we can count on.  

discussions about what might happen if they run out are thin on the ground."
5649,@GaryMarcus,2022-03-13 23:19:47+00:00,https://twitter.com/GaryMarcus/status/1503148850592112643,"@Miles_Brundage @NautilusMag As I said earlier elsewhere, I gave some arguments, both theoretical and empirical, against the scaling ‚Äúlaw‚Äù hype that I haven‚Äôt seen before, and nobody is engaging them (nor wrt putative novelty pointed to other literature that has made similar arguments or refuted them)."
5650,@GaryMarcus,2022-03-13 21:09:30+00:00,https://twitter.com/GaryMarcus/status/1503116062111412224,@mpshanahan it‚Äôs a very cool animation
5651,@GaryMarcus,2022-03-13 20:55:36+00:00,https://twitter.com/GaryMarcus/status/1503112563831164933,"Flashback to 2018: anyone remember Deep Learning: A Critical Appraisal? 

@Ylecun said it was mostly wrong; the field was hopping mad.

Which of the 10 concerns raised there have stood the test of time? https://t.co/oQIIxJKa16"
5652,@GaryMarcus,2022-03-13 20:45:30+00:00,https://twitter.com/GaryMarcus/status/1503110023613874176,@irinarish the one thing we can agree on 100%: the need for a twitter edit button :)
5653,@GaryMarcus,2022-03-13 20:11:56+00:00,https://twitter.com/GaryMarcus/status/1503101575987810306,"@mpshanahan changed allegiances to the great god of scaling, have we?"
5654,@GaryMarcus,2022-03-13 19:28:38+00:00,https://twitter.com/GaryMarcus/status/1503090678569467906,"To assert ‚Äúscaling is the [sole] answer‚Äù without evidence is to ignore a large swathe of evolution. There is an immense work on other mechanisms, such as duplication and divergence, that have been critical. 

(*Sometimes* D&amp;D drives scaling)

@GeschwindLab @WiringTheBrain"
5655,@GaryMarcus,2022-03-13 19:20:42+00:00,https://twitter.com/GaryMarcus/status/1503088683217346562,@ceobillionaire @irinarish @francoisfleuret @Plinz the digital computer; location-addressable memory; pocket calculators
5656,@GaryMarcus,2022-03-13 19:19:48+00:00,https://twitter.com/GaryMarcus/status/1503088454560731136,"Sorry, but (a) you can‚Äôt assume that all evolution is a function of scaling and (b) if evolution developed critical things that current models lack, we are still at a wall as a field that we need to overcome.  

To pretend otherwise is to become the coyote over the cliff. https://t.co/Q5aRjxcgVv"
5657,@GaryMarcus,2022-03-13 19:15:48+00:00,https://twitter.com/GaryMarcus/status/1503087451031543809,@tamaybes @NautilusMag ‚Äúit is important to emphasize that the construction of LC is entirely dependent on the pre-existing symbolic processors developed over the last 50 years by experts in symbolic mathematics.‚Äù see: https://t.co/dRe1ZN5ptY by @ErnestSDavis
5658,@GaryMarcus,2022-03-13 19:03:26+00:00,https://twitter.com/GaryMarcus/status/1503084338631495682,"@francoisfleuret @ceobillionaire @irinarish @Plinz I stand by the title, for reasons explained in the article. 

On a different day, even LeCun realizes it; it‚Äôs the whole reason he is working on world models‚Äîand whole reason Bengio now works on System 2. Recent splashy results don‚Äôt change the fact that we need better answers."
5659,@GaryMarcus,2022-03-13 18:59:40+00:00,https://twitter.com/GaryMarcus/status/1503083390177714176,@DrMJoyner @NautilusMag üò•
5660,@GaryMarcus,2022-03-13 18:50:21+00:00,https://twitter.com/GaryMarcus/status/1503081042483179521,"% of the pushback from the deep learning community on my recent @nautilusmag article that has been about the title: 100

% of the pushback that has addressed the substantive arguments: 0"
5661,@GaryMarcus,2022-03-13 18:36:18+00:00,https://twitter.com/GaryMarcus/status/1503077508802965505,"3. I didn‚Äôt say the wall was insurmountable; if you had actually read the essay you would know that.  

I also didn‚Äôt argue that deep learning will play no role go forward; again if you had read the essay, you‚Äôd know that.

Attacking a paper on its title ‚â† good science

3/3"
5662,@GaryMarcus,2022-03-13 18:36:18+00:00,https://twitter.com/GaryMarcus/status/1503077507372752900,"2. Scaling has issues; I wrote about them @Nautilusmag. You, @plinz, &amp; @ylecun all criticize title, but nobody has addressed the arguments.

Elsewhere, @ylecun seems quite aware of current challenges; e.g., deep learning has not yet found a good way to construct world models

2/3"
5663,@GaryMarcus,2022-03-13 18:36:17+00:00,https://twitter.com/GaryMarcus/status/1503077506093510656,"Let‚Äôs get realistic: 

1. Field of AI safety and alignment is rapidly expanding precisely because large language models are toxic, biased, unreliable, &amp; difficult to control

@weidingerlaura‚Äôs great recent review @deepmind outlines 21 problems, but nobody has clear solutions

1/3"
5664,@GaryMarcus,2022-03-13 18:23:25+00:00,https://twitter.com/GaryMarcus/status/1503074267151298569,@NaveenGRao #neurosymbolic FTW
5665,@GaryMarcus,2022-03-13 18:19:17+00:00,https://twitter.com/GaryMarcus/status/1503073226209239040,@Bill_Gardner @peteratmsr
5666,@GaryMarcus,2022-03-13 18:15:04+00:00,https://twitter.com/GaryMarcus/status/1503072163812630529,"@Bill_Gardner i didn‚Äôt mean that a single error would constitute reason for rejecting, but rather that the current results as a whole are not good enough to use on their own hence the refs"
5667,@GaryMarcus,2022-03-13 18:11:53+00:00,https://twitter.com/GaryMarcus/status/1503071362268622849,"@irinarish @Plinz but then again it‚Äôs not clear that either of you actually read beyond the title, because you in no case have addressed the actual arguments in the article"
5668,@GaryMarcus,2022-03-13 17:50:03+00:00,https://twitter.com/GaryMarcus/status/1503065871073173505,@irinarish @NautilusMag and i am sure you carefully reviewed the argument and evidence in the essay and didn‚Äôt just respond to the title.
5669,@GaryMarcus,2022-03-13 16:40:46+00:00,https://twitter.com/GaryMarcus/status/1503048433178869763,"@danbri @kenneth0stanley @gamlambard hmm. genetic evolution is the *only* technique (in its real world version) that has thus far created a reasonably general (though still flawed) intelligence.

i wouldn‚Äôt be so quick to knock it."
5670,@GaryMarcus,2022-03-13 16:38:32+00:00,https://twitter.com/GaryMarcus/status/1503047871955824643,@Sriraam_UTD @HappyAar @barneyp @davpoole also very good! tagging @AlanMackworth
5671,@GaryMarcus,2022-03-13 15:53:23+00:00,https://twitter.com/GaryMarcus/status/1503036509888253956,@danbri @gamlambard @kenneth0stanley ‚ÄúI still haven‚Äôt found what I am looking for‚Äù - Bono
5672,@GaryMarcus,2022-03-13 15:21:12+00:00,https://twitter.com/GaryMarcus/status/1503028409286356993,@BrainSpectrum @mnitabach someone died in a tesla-related accident recently; complex case revolving around a known issue that i detailed on twitter about 3 days ago
5673,@GaryMarcus,2022-03-13 15:19:55+00:00,https://twitter.com/GaryMarcus/status/1503028085125378051,"@Simeon_Cps @drjwrae @NautilusMag not adequately, but see"
5674,@GaryMarcus,2022-03-13 15:18:37+00:00,https://twitter.com/GaryMarcus/status/1503027760754700293,"@barneyp @akatzzzzz @ChrSzegedy @GuillaumeLample @f_charton @ErnestSDavis also relevant, but I meant this one: https://t.co/AaluBpBgbc"
5675,@GaryMarcus,2022-03-13 15:00:42+00:00,https://twitter.com/GaryMarcus/status/1503023252913864705,"Indeed! Informing the large public about the limitations of current tools for AI was one of the major goals of my last book (Rebooting,AI, with @ErnestSDavis ) andof  @MelMitchell1‚Äôs last book, as well."
5676,@GaryMarcus,2022-03-13 14:58:00+00:00,https://twitter.com/GaryMarcus/status/1503022569363890178,"Sorry - did I miss someone else‚Äôs critical analysis of the popular but problematic idea scaling ‚Äúlaws‚Äù as a solution to AI? Where did it appear? 

Would love a reference."
5677,@GaryMarcus,2022-03-13 14:49:37+00:00,https://twitter.com/GaryMarcus/status/1503020461130616836,"One reason why most language benchmarks aren‚Äôt that useful is that they rarely look at comprehension across anything like an actual discourse, as argued in https://t.co/C6XodPts1W

Great thread summarizing a recent effort to do better by @Uri_Shaham: https://t.co/o0AQULA6wr"
5678,@GaryMarcus,2022-03-13 14:42:42+00:00,https://twitter.com/GaryMarcus/status/1503018721123528708,"@tdietterich @ylecun @Twitter Don‚Äôt think anyone else summed up challenges to the scaling law hypothesis before (certainly I hadn‚Äôt), so maybe you only skimmed.

Anyhoo, I didn‚Äôt say I touched *your* nerves :)"
5679,@GaryMarcus,2022-03-13 14:29:20+00:00,https://twitter.com/GaryMarcus/status/1503015357149171717,"I appear to have touched a nerve. 

@ylecun I no longer actively use Facebook, but if you‚Äôd like to post a substantive critique of my recent essay here on @Twitter, going beyond the title, I‚Äôm all ears.

Am sure many others would like to hear from you, as well. https://t.co/hIPjFmyGye"
5680,@GaryMarcus,2022-03-13 13:27:43+00:00,https://twitter.com/GaryMarcus/status/1502999852065558530,@drjwrae @NautilusMag see same book for critique of symbolic approaches btw
5681,@GaryMarcus,2022-03-13 13:27:12+00:00,https://twitter.com/GaryMarcus/status/1502999719139680257,@drjwrae @NautilusMag no; Gopher halved the gap on some benchmarks. actual comprehension is nil; see chapter on reading in https://t.co/C6XodPts1W
5682,@GaryMarcus,2022-03-13 13:24:35+00:00,https://twitter.com/GaryMarcus/status/1502999060466216961,@danbri @gamlambard genetic algorithms themselves are always implemented as@oped tons over variables but most of them don‚Äôt build phenotypes that operate over variables. best work here is by @kenneth0stanley who might comment‚Ä¶
5683,@GaryMarcus,2022-03-13 13:22:08+00:00,https://twitter.com/GaryMarcus/status/1502998443983220741,@Abel_TorresM @AndrewLampinen @yudapearl @rosemary_ke @DaniloJRezende @Abel_TorresM‚Äôs point isn‚Äôt that people aren‚Äôt interested but rather that they are using the wrong tools for the job.  he‚Äôs right.
5684,@GaryMarcus,2022-03-13 13:17:49+00:00,https://twitter.com/GaryMarcus/status/1502997359445250048,@lisavation @Bill_Gardner thank you for that link!
5685,@GaryMarcus,2022-03-13 13:09:02+00:00,https://twitter.com/GaryMarcus/status/1502995151018336266,@akatzzzzz @ChrSzegedy @GuillaumeLample @f_charton Very interesting work but I would love to hear the authors respond to @ErnestSDavis‚Äôs reply to their work that appeared in Arxiv.
5686,@GaryMarcus,2022-03-13 06:04:10+00:00,https://twitter.com/GaryMarcus/status/1502888228164046848,"@sandyasm @iamtrask so close to what i said in The Algebraic Mind, where in 2001 i called for 
- variable binding
- hierachical representation
- representation of specific instances distinct from kinds
all in integration with neural networks"
5687,@GaryMarcus,2022-03-13 06:02:30+00:00,https://twitter.com/GaryMarcus/status/1502887809870225409,"@iamtrask exactly - which is to say when it fully embraces symbol-manipulation, pretty much along the lines of what I laid out in The Algebraic Mind"
5688,@GaryMarcus,2022-03-13 05:52:29+00:00,https://twitter.com/GaryMarcus/status/1502885288422481924,"@DanielPeterson If I found an AI that smart, I‚Äôd have to retire."
5689,@GaryMarcus,2022-03-13 02:15:13+00:00,https://twitter.com/GaryMarcus/status/1502830611387453444,@jakubzavrel @Grady_Booch and it wasn‚Äôt what he said
5690,@GaryMarcus,2022-03-13 02:14:58+00:00,https://twitter.com/GaryMarcus/status/1502830549471141889,@jakubzavrel @Grady_Booch i wouldn‚Äôt endorse that one
5691,@GaryMarcus,2022-03-13 02:08:36+00:00,https://twitter.com/GaryMarcus/status/1502828947687452675,"@rodriguezzz78 @Plinz you would trust it to write an app? suggest you first read Stassa‚Äôs and my commentaries, on Scott Aaronson‚Äôs blog."
5692,@GaryMarcus,2022-03-13 02:06:48+00:00,https://twitter.com/GaryMarcus/status/1502828492655783944,"@Zergylord @tdietterich @Jonatha46333329 @j_br__ @hxt55 come on. i predicted 21 years ago that mutlilayer nets would have trouble freely generalizing universally
quantified one one one mappings; they did then, and they still do, with billions times more  resources.

this is a distribution shift problem, same as it was in 2001."
5693,@GaryMarcus,2022-03-13 00:29:23+00:00,https://twitter.com/GaryMarcus/status/1502803978374975493,@gamlambard https://t.co/ze8DtZuHwR
5694,@GaryMarcus,2022-03-12 23:21:39+00:00,https://twitter.com/GaryMarcus/status/1502786932807397378,@Grady_Booch it will appear in a future essay‚Ä¶ :)
5695,@GaryMarcus,2022-03-12 22:13:58+00:00,https://twitter.com/GaryMarcus/status/1502769896588947456,"@Pittampalli old story: 
A: What do you think Ty Cobb would bat today? 
B: Maybe .350
A: That low?
B: Well, you have take into account he‚Äôs 70 years old."
5696,@GaryMarcus,2022-03-12 22:06:19+00:00,https://twitter.com/GaryMarcus/status/1502767971931881472,"I will always stand in awe of Noam Chomsky. I just sent him my recent essay; 12 minutes later he replied with smart comments, including a point I should have thought to include. He‚Äôs 93."
5697,@GaryMarcus,2022-03-12 20:46:31+00:00,https://twitter.com/GaryMarcus/status/1502747889461694464,@Plinz https://t.co/fPa7Hi1PWj
5698,@GaryMarcus,2022-03-12 20:40:44+00:00,https://twitter.com/GaryMarcus/status/1502746435460116482,@neuralreckoning @NatureComms @NicolasPerezNi1 @worldwideneuro and see https://t.co/lnr3lD7E1z
5699,@GaryMarcus,2022-03-12 20:34:18+00:00,https://twitter.com/GaryMarcus/status/1502744817477902338,"@an1lam @krishnanrohit thanks for tagging me, since @plinz didn‚Äôt. I just subtweeted his with my own thoughts:"
5700,@GaryMarcus,2022-03-12 20:32:06+00:00,https://twitter.com/GaryMarcus/status/1502744263867600896,"Hilarious cartoon that captures more than it intends to, missing the fact that deep learning, with its toxic language, bias, unreliability, and tendency towards fabricating misinformation, runs roughshod over human values.

Thanks @plinz for capturing the situation so well!"
5701,@GaryMarcus,2022-03-12 20:14:31+00:00,https://twitter.com/GaryMarcus/status/1502739837333299200,"@emilymbender @yudapearl @luislamb mayeb you meant AGI here? as i am sure you would agree, we many tools for human use wouod he best served with proper semantic representation"
5702,@GaryMarcus,2022-03-12 20:12:11+00:00,https://twitter.com/GaryMarcus/status/1502739251011600386,@an1lam @krishnanrohit and yet it can't learn addition
5703,@GaryMarcus,2022-03-12 18:53:44+00:00,https://twitter.com/GaryMarcus/status/1502719506812088324,@BierVicki !
5704,@GaryMarcus,2022-03-12 18:35:57+00:00,https://twitter.com/GaryMarcus/status/1502715031804276738,"this thread is pretty much as much fun as I was hoping it would be. but @ChombaBupe‚Äôs dissection of an LLM that does 5 digit arithmetic is üî•.

bring üçø and watch for symbols hiding behind the curtain."
5705,@GaryMarcus,2022-03-12 18:27:11+00:00,https://twitter.com/GaryMarcus/status/1502712827957563394,@ChombaBupe @mkualquiera @anmarmil @statsepi ü§£ü§£ü§£
5706,@GaryMarcus,2022-03-12 18:26:04+00:00,https://twitter.com/GaryMarcus/status/1502712546226176007,@ElijahYilma @yudapearl @luislamb @emilymbender both. see inter alia my next decade in AI on arxiv
5707,@GaryMarcus,2022-03-12 17:43:51+00:00,https://twitter.com/GaryMarcus/status/1502701920468680705,"@AndrewLampinen @glupyan sure. the model here is @stephen_wolfram‚Äôs Mathematica, which exceeds the best symbolic performance of nearly all humans, using (mostly) symbolic techniques without human limits of memory and computation.

Imagine Mathematica *entirely* with end-to-end deep learning."
5708,@GaryMarcus,2022-03-12 17:41:17+00:00,https://twitter.com/GaryMarcus/status/1502701273337921541,"üëâThe difference between strong AI &amp; current ML is the difference between *constructing a causal interpretation of the world* &amp; merely *replicating the distribution*

It is why @yudapearl &amp; I argue current ML is not enough &amp; why @luislamb, @emilymbender &amp; I emphasize semantics"
5709,@GaryMarcus,2022-03-12 17:32:16+00:00,https://twitter.com/GaryMarcus/status/1502699004202606592,"@AndrewLampinen exactly. but the distribution between strong intelligence and current  ML is the difference between constructing a causal interpretation the world and merely copying it.

which is what @yudapearl and I keep coming back to."
5710,@GaryMarcus,2022-03-12 17:30:09+00:00,https://twitter.com/GaryMarcus/status/1502698475045081089,"@AndrewLampinen true but weak, IMHO. the point is that the system NEVER derives the rule, which would empower it to overcome a small bit of noise."
5711,@GaryMarcus,2022-03-12 17:22:30+00:00,https://twitter.com/GaryMarcus/status/1502696546944503809,@AndrewLampinen sure
5712,@GaryMarcus,2022-03-12 17:06:17+00:00,https://twitter.com/GaryMarcus/status/1502692467056865281,"@BjarturTomas check my 2012 New Yorker challenging deep learning, and long interview at @edge in 2016"
5713,@GaryMarcus,2022-03-12 17:04:58+00:00,https://twitter.com/GaryMarcus/status/1502692134406668289,@lcastricato ps this whole thread is your fault :)
5714,@GaryMarcus,2022-03-12 17:02:37+00:00,https://twitter.com/GaryMarcus/status/1502691546323304448,"@lcastricato well, at least it got some of your geese. it didn‚Äôt get *any* of mine :("
5715,@GaryMarcus,2022-03-12 17:00:52+00:00,https://twitter.com/GaryMarcus/status/1502691105451565061,"@AndrewLampinen sure, but in this case the model presumably is being trained on the full data set, and at 100 billion parameters ought to have adequate resources. your argument is correct in the general, but not relevant in the specific case"
5716,@GaryMarcus,2022-03-12 16:59:58+00:00,https://twitter.com/GaryMarcus/status/1502690879303168000,@AndrewLampinen per my tweet that you screenshotted above. are you trying to make a case that GPT is like a person? or that it is a good basis for AI? a good basis for AI shouldn‚Äôt be some random person‚Äôs atrophied math skills.
5717,@GaryMarcus,2022-03-12 16:57:35+00:00,https://twitter.com/GaryMarcus/status/1502690275625357313,"@AndrewLampinen @glupyan Agree to som extent, but it‚Äôs important to look at expert performance to the extent that people make silly arguments claiming brains can‚Äôt (even in the limit) manipulate symbols, when in reality at least some brains clearly can do so routinely (eg in computer programming)."
5718,@GaryMarcus,2022-03-12 16:52:16+00:00,https://twitter.com/GaryMarcus/status/1502688939106131968,"@krishnanrohit and of how much deep learning still relies on pure texture.

@anh_ng8"
5719,@GaryMarcus,2022-03-12 16:51:46+00:00,https://twitter.com/GaryMarcus/status/1502688814942154754,"it goes both ways. I spoke at NIPS c 2015 (before renamed) in a packed-room panel with Yann LeCun c 2015 &amp; asked people to raise their hands if they had heard of Cyc. &lt; 5% knew what it was.  

One thing not to like it, another to be working in AI and ignorant of its existence"
5720,@GaryMarcus,2022-03-12 16:48:04+00:00,https://twitter.com/GaryMarcus/status/1502687881822760961,@krishnanrohit i tried; got exactly same result
5721,@GaryMarcus,2022-03-12 16:45:20+00:00,https://twitter.com/GaryMarcus/status/1502687193877258240,"Really, @Apple?"
5722,@GaryMarcus,2022-03-12 16:42:07+00:00,https://twitter.com/GaryMarcus/status/1502686387178405889,"@adriancjr oh yes, he had a plan. it didn‚Äôt work. NOW he has no plan."
5723,@GaryMarcus,2022-03-12 16:41:00+00:00,https://twitter.com/GaryMarcus/status/1502686105283411977,"@barneyp @hangingnoodles no, that was my line, retweeting your tweet"
5724,@GaryMarcus,2022-03-12 16:40:39+00:00,https://twitter.com/GaryMarcus/status/1502686017744080896,"three of my actual geese photos, all missed in Apple Photos Search. 
cc @lcastricato https://t.co/o3OZnJOwwd"
5725,@GaryMarcus,2022-03-12 16:40:34+00:00,https://twitter.com/GaryMarcus/status/1502685995115823104,"hereby retracting the vaguely positive things I recently said about Apple Photos #ML search, after typing in ‚Äúgoose‚Äù and retrieving not one of my actual goose photos (see next tweet for examples of those that were missed): https://t.co/vrRjYeXU2J"
5726,@GaryMarcus,2022-03-12 16:20:47+00:00,https://twitter.com/GaryMarcus/status/1502681015143497731,@adriancjr for one he wouldn‚Äôt be making it so big tech never works there again
5727,@GaryMarcus,2022-03-12 16:20:01+00:00,https://twitter.com/GaryMarcus/status/1502680824650510337,@HappyAar @barneyp russell and norvig
5728,@GaryMarcus,2022-03-12 15:54:24+00:00,https://twitter.com/GaryMarcus/status/1502674378454028291,@scagliarini @barneyp hype has made it worse
5729,@GaryMarcus,2022-03-12 15:52:45+00:00,https://twitter.com/GaryMarcus/status/1502673962760740866,"Pretty bit of neuroscience, elegantly explained in this thread:"
5730,@GaryMarcus,2022-03-12 15:45:24+00:00,https://twitter.com/GaryMarcus/status/1502672112917483520,"Not just ironic, but actually tragic. Trenchant mini-thread by AI games pioneer/entrepreneur/investor @barneyp"
5731,@GaryMarcus,2022-03-12 15:37:34+00:00,https://twitter.com/GaryMarcus/status/1502670141485584387,@tdverstynen i dearly hope we are both wrong.
5732,@GaryMarcus,2022-03-12 15:30:17+00:00,https://twitter.com/GaryMarcus/status/1502668306787942401,Does this guy have any long term plan whatsoever?
5733,@GaryMarcus,2022-03-12 15:11:53+00:00,https://twitter.com/GaryMarcus/status/1502663675940724736,"@glupyan @tdietterich @Jonatha46333329 @j_br__ @hxt55 True! People are lousy at arithmetic &amp; GPT is too!
üëâ But that doesn‚Äôt mean we should use GPT for our AI (which ought exceed humans in reliability, just as calculators do)
üëâ Nor that people &amp; GPT follow identical principles.  Overlap in some respects ‚â† overlap in all respects."
5734,@GaryMarcus,2022-03-12 15:03:37+00:00,https://twitter.com/GaryMarcus/status/1502661595188531201,"@glupyan @tdietterich @Jonatha46333329 @j_br__ @hxt55 larger answer to come, but I think there are task demands and funny pragmatics in these kinds of tasks, and certainly experts would be at ceiling."
5735,@GaryMarcus,2022-03-12 15:01:32+00:00,https://twitter.com/GaryMarcus/status/1502661071730974722,"@Zergylord @tdietterich @Jonatha46333329 @j_br__ @hxt55 @AnthropicAI @yasaman_razeghi @sameer_ which is why eg carefully controlled arithmetic work of @yasaman_razeghi and @sameer_ is so important.

Without #eleuther we wouldn‚Äôt be able to address the training=&gt;generalization relationship at all, since OpenAI refuses to share training set

üôè@BlancheMinerva 

@yoavgo"
5736,@GaryMarcus,2022-03-12 14:57:24+00:00,https://twitter.com/GaryMarcus/status/1502660032785121280,"@Zergylord @tdietterich @Jonatha46333329 @j_br__ @hxt55 @AnthropicAI @yasaman_razeghi @sameer_ Fab question. My guess: 

GPT3 produces flawless prose not by deriving rules, but via pastiche (enhanced by synonymy via embeddings) over huge windows.

Because we can‚Äôt force them to produce particular outputs, we can‚Äôt assess troubles they would have w low-frequency words."
5737,@GaryMarcus,2022-03-12 14:47:20+00:00,https://twitter.com/GaryMarcus/status/1502657500637986817,"@IntuitMachine no doubt; it‚Äôs just a benchmark, but a nicely controlled one that tells you about a system‚Äôs capacity for abstraction."
5738,@GaryMarcus,2022-03-12 14:45:39+00:00,https://twitter.com/GaryMarcus/status/1502657074169192459,"and see the @emilymbender thread that my @NautilusMag article links to, with her quote on the oxygen being sucked from the room."
5739,@GaryMarcus,2022-03-12 14:43:37+00:00,https://twitter.com/GaryMarcus/status/1502656563588214785,"Fun to contemplate how much has‚Äîand has not changed.  

Link below is from 2018; have LLMs and scaling answered the concerns I raised then, re deep learning being brittle, greedy, opaque, showing difficulty with abstraction and extrapolation? ü§î"
5740,@GaryMarcus,2022-03-12 14:15:15+00:00,https://twitter.com/GaryMarcus/status/1502649424052305920,bingo
5741,@GaryMarcus,2022-03-12 03:34:16+00:00,https://twitter.com/GaryMarcus/status/1502488115973292033,"@oliver_batch @BartWronsk @TechRonic9876 @Patapom2 @NautilusMag all depends on your goals. it was a great year for protein folding, as well as deep fakes and large language model PR, not so great for deep understanding or AGI."
5742,@GaryMarcus,2022-03-12 03:31:36+00:00,https://twitter.com/GaryMarcus/status/1502487444712669187,"@adamcrussell @tdietterich @Jonatha46333329 @j_br__ @hxt55 @AnthropicAI @yasaman_razeghi @sameer_ Be careful, @adamcrussell, of your moral choices.

If you reimplement your ILP in parallel on a GPU it might easily become slightly conscious.

With great power comes great responsibility."
5743,@GaryMarcus,2022-03-12 03:24:11+00:00,https://twitter.com/GaryMarcus/status/1502485578310316032,"@tdietterich @Jonatha46333329 @j_br__ @hxt55 I‚Äôll remember the next time I drop a ball and it goes flying to the ceiling, as it does, oh, 3.14159 % of the time."
5744,@GaryMarcus,2022-03-12 03:21:07+00:00,https://twitter.com/GaryMarcus/status/1502484806923288577,"@tdietterich @Jonatha46333329 @j_br__ @hxt55 And no, the comparison here is not fully fair, but c‚Äômon, if you can‚Äôt learn 3 digit addition reliably, with perfect data, do you really think you are going to master everyday physics in a noisy world?"
5745,@GaryMarcus,2022-03-12 03:19:43+00:00,https://twitter.com/GaryMarcus/status/1502484455704842243,"@tdietterich @Jonatha46333329 @j_br__ @hxt55 What‚Äôs actually interesting about this result is that for 30 years I keep being told that neural networks ‚Äúlearn the rule‚Äù in this or that set of data. 

If you do well-controlled expts like this new one from @AnthropicAI or recent @yasaman_razeghi and @sameer_ you see otherwise."
5746,@GaryMarcus,2022-03-12 03:09:51+00:00,https://twitter.com/GaryMarcus/status/1502481972488155140,"@lcastricato ü§£ My models, trained and untrained
Stanley Park, Vancouver, 2021
# of parameters not recorded. https://t.co/H2l3lFyuc9"
5747,@GaryMarcus,2022-03-12 00:18:52+00:00,https://twitter.com/GaryMarcus/status/1502438944293593090,"Just noticed that @SumitGulwani is on Twitter! You may not recognize his name, but his Flash Fill in Microsoft Excel is brilliant. 

For a few sentences on why the extrapolation it does is in some ways ahead of deep learning, see #9 in my FAQ:  https://t.co/mndiMYhBLQ"
5748,@GaryMarcus,2022-03-11 23:41:58+00:00,https://twitter.com/GaryMarcus/status/1502429657131413505,"@mjs2342 Don‚Äôt have a full list of active cases but a quick websearch for Tesla lawsuit autopilot reveals some cases (some of which may have been resolved). They are also under NHTSA investigation, eg for the specific issue of rear-ending stopped vehicles mentioned above."
5749,@GaryMarcus,2022-03-11 22:16:26+00:00,https://twitter.com/GaryMarcus/status/1502408132315672576,"A. A Tesla on Autopilot runs into a stopped vehicle on highway‚Äîa recurring, known issue already under investigation, discovered in 2018, never fixed
B. Safety worker goes to set up traffic cones to secure scene
C. Safety worker is killed by separate vehicle crashing into scene"
5750,@GaryMarcus,2022-03-11 22:05:03+00:00,https://twitter.com/GaryMarcus/status/1502405266305806336,"@kdkeck @Plinz now you are putting words in mouth and ignoring the detailed presentation of my argument. goodbye, sir."
5751,@GaryMarcus,2022-03-11 21:41:53+00:00,https://twitter.com/GaryMarcus/status/1502399437355642880,@ChombaBupe well it‚Äôs more like they make in error 1 in 5 times. with small numbers! worse as the numbers get bigger. many angry customers and a lot of huge losses.
5752,@GaryMarcus,2022-03-11 20:54:27+00:00,https://twitter.com/GaryMarcus/status/1502387498244136961,"@kdkeck @Plinz I addressed this yesterday; Tesla has not been forthcoming with the data, and I assume they would be if the results were favorable.

Certainly I agree in principle that some driverless cars at some point will be safer than human drivers. But Tesla FSD doesn‚Äôt appear to be that."
5753,@GaryMarcus,2022-03-11 20:52:55+00:00,https://twitter.com/GaryMarcus/status/1502387114410856448,"@kdkeck @Plinz possible, but the worker still would not have been standing on the highway, unprotected if Tesla had paused until sorting the bug, which has been known since 2018 (if not earlier).

I highlighted exactly this bug in my 2019 book, because it was already a clear, repeated issue."
5754,@GaryMarcus,2022-03-11 20:41:40+00:00,https://twitter.com/GaryMarcus/status/1502384282873913344,"@khademinori @punkstrategy @Plinz how would work, for say arithmetic? would you use a calculator to check the neural net? what work would the net being doing, then?

and if that‚Äôs not a fair case, what‚Äôs a better example?"
5755,@GaryMarcus,2022-03-11 19:31:51+00:00,https://twitter.com/GaryMarcus/status/1502366713236520962,"@jmac_ai @MaxALittle if you can‚Äôt do something as orderly and basic as addition, how you are going to reach AGI?"
5756,@GaryMarcus,2022-03-11 19:17:37+00:00,https://twitter.com/GaryMarcus/status/1502363132236165123,"Arithmetic Smackdown! ü•ä

üëâ Worst fiasco in CPU in history 
vs 
üëâ Deep learning‚Äôs greatest hit!

And the winner is ‚Ä¶ https://t.co/lj9OLl4Y4k"
5757,@GaryMarcus,2022-03-11 18:46:56+00:00,https://twitter.com/GaryMarcus/status/1502355409838829574,"@paklnet am pretty worried about the 80%, too, tbh."
5758,@GaryMarcus,2022-03-11 18:36:11+00:00,https://twitter.com/GaryMarcus/status/1502352701874573318,"@Plinz I am genuinely worried that these systems can get to a measly 80% correct even when you give them 100 billion parameters to learn a million basic arithmetic problems. 

That really does not look like intelligence to me. 

[source below]"
5759,@GaryMarcus,2022-03-11 18:29:02+00:00,https://twitter.com/GaryMarcus/status/1502350902656524290,cc @yasaman_razeghi and @sameer_ - your 2022 arxiv on memorization is once again highly relevant
5760,@GaryMarcus,2022-03-11 18:27:52+00:00,https://twitter.com/GaryMarcus/status/1502350612293296130,Am I the only one worried about systems that take a hundred billion parameters to get to 80% correct on 1 million distinct 3-digit addition problems?   #ecology
5761,@GaryMarcus,2022-03-11 17:06:24+00:00,https://twitter.com/GaryMarcus/status/1502330106613669888,"This paper by @abebab &amp; @vinayprabhu is üî•.

As a teaser, here's Table 1, re informed consent in large image sets.

Love to see a similar table wrt  # pedestrians signing informed consent for participating in @tesla's FSD program.

h/t @emilymbender https://t.co/BsoMTxazS6"
5762,@GaryMarcus,2022-03-11 16:09:16+00:00,https://twitter.com/GaryMarcus/status/1502315729382621184,@gbildson @Plinz hints here: https://t.co/9Gh30uZzok
5763,@GaryMarcus,2022-03-11 14:09:33+00:00,https://twitter.com/GaryMarcus/status/1502285603122991110,this has become an excellent thread:
5764,@GaryMarcus,2022-03-11 13:37:17+00:00,https://twitter.com/GaryMarcus/status/1502277480958152705,@wellingmax @ChombaBupe @AvilaGarcez @luislamb @PMinervini @egrefen @mpshanahan @AnimaAnandkumar @YejinChoinka @ylecun @_rockt @Kordjamshidi @pmddomingos @yudapearl also; consider Larry Barsalou‚Äôs example of ad hoc categories like ‚Äúthings you would take with you in the event of a fire‚Äù; discrete and instantly interpretable intension; fuzzy extension.
5765,@GaryMarcus,2022-03-11 13:32:48+00:00,https://twitter.com/GaryMarcus/status/1502276354712035332,@samc0hen @Plinz surely when we do logic or computer programming are brains are manipulating symbols. ditto for language
5766,@GaryMarcus,2022-03-11 13:31:42+00:00,https://twitter.com/GaryMarcus/status/1502276076394860547,@ArletOttens @PaulJBlazek @wellingmax @NautilusMag humans are hybrids! maybe AI should take note?
5767,@GaryMarcus,2022-03-11 13:30:25+00:00,https://twitter.com/GaryMarcus/status/1502275753542504451,@MikePFrank @NautilusMag @swarat and joshua tenenbaum are headed in the right direction
5768,@GaryMarcus,2022-03-11 13:16:49+00:00,https://twitter.com/GaryMarcus/status/1502272334018723840,@kdkeck @Plinz now you have libeled me; i gave full details of what happened and why it was a known issue (now at least a dozen times) that led to the victim get killed by the BMW.
5769,@GaryMarcus,2022-03-11 13:12:27+00:00,https://twitter.com/GaryMarcus/status/1502271232355422210,@MikePFrank @NautilusMag it‚Äôs no accident that systems with pointers have been doing well of late.
5770,@GaryMarcus,2022-03-11 07:26:06+00:00,https://twitter.com/GaryMarcus/status/1502184069278289922,@samc0hen @Plinz still does monte carlo tree search
5771,@GaryMarcus,2022-03-11 07:24:46+00:00,https://twitter.com/GaryMarcus/status/1502183736204410881,@samc0hen @Plinz a stack is an organization of symbols; ditto a tree. CS 101
5772,@GaryMarcus,2022-03-11 07:23:32+00:00,https://twitter.com/GaryMarcus/status/1502183424001413120,"@danbri @kvashee the key word is replace (without even a single phrase of intellectual justification) rather than complement  ; gauntlet declared, not explained."
5773,@GaryMarcus,2022-03-11 07:19:43+00:00,https://twitter.com/GaryMarcus/status/1502182464315277313,"neural networks then (1986) &amp; now

the graphics are better; the bizarre failures with low frequency and out of distribution items are not. https://t.co/PedRq5MpB5"
5774,@GaryMarcus,2022-03-11 06:49:12+00:00,https://twitter.com/GaryMarcus/status/1502174786746601475,@primalpoly
5775,@GaryMarcus,2022-03-11 06:42:49+00:00,https://twitter.com/GaryMarcus/status/1502173176960147461,"@samc0hen @Plinz hybrid for the win, per my article and discussed here:"
5776,@GaryMarcus,2022-03-11 06:32:24+00:00,https://twitter.com/GaryMarcus/status/1502170557562851331,"you are welcome. @berent_iris and I have noticed an anti-nativist bias again and again, in psychology, in AI, and now here in discussions of covid-19 risk factors, where genetic factors were simply ignored, without any justification, and counter to growing evidence."
5777,@GaryMarcus,2022-03-11 06:25:17+00:00,https://twitter.com/GaryMarcus/status/1502168764778835971,@samc0hen @Plinz perhaps that‚Äôs what rapidly climbing towards a local maximum looks like?
5778,@GaryMarcus,2022-03-11 06:22:24+00:00,https://twitter.com/GaryMarcus/status/1502168040753954819,"@Plinz there is a lot of orderliness in the world that they are piggybacking onto, but that doesn‚Äôt make them comprehend the world that they are leveraging.
  
they may exceed your expectations but I still believe they are a local maximum on the road to AGI."
5779,@GaryMarcus,2022-03-11 06:14:43+00:00,https://twitter.com/GaryMarcus/status/1502166107418861576,"I respect Joscha Bach deeply, but thinking that Deep Learning has overcome its tendency to create bizarre errors, first documented in 1988, is mistaken. 

Examples from the very work he cites showing that gigantic datasets etc don‚Äôt overcome the fundamental lack of comprehension: https://t.co/ZCQszTVbWB"
5780,@GaryMarcus,2022-03-11 06:06:50+00:00,https://twitter.com/GaryMarcus/status/1502164124062478337,@Plinz from the same paper: https://t.co/aqfI14teQR
5781,@GaryMarcus,2022-03-11 04:44:56+00:00,https://twitter.com/GaryMarcus/status/1502143510543142912,"@MarkusSchacher it happened yesterday, in Taiwan. somebody died."
5782,@GaryMarcus,2022-03-11 01:30:46+00:00,https://twitter.com/GaryMarcus/status/1502094647698464774,@KarenLeeAlex https://t.co/JIHa73YCgr
5783,@GaryMarcus,2022-03-11 00:30:35+00:00,https://twitter.com/GaryMarcus/status/1502079503895465985,Luckily this specific statistic is already under investigation: https://t.co/1uEEOjiH9A
5784,@GaryMarcus,2022-03-11 00:28:13+00:00,https://twitter.com/GaryMarcus/status/1502078907914227718,"@Plinz @elonmusk @Tesla it‚Äôs way harder than that, because you have to factor in
- fact that the Tesla‚Äôs fleet is much newer than avg
- safer for other reasons (eg no engine in front)
- more expensive and well-built than average car
- has more mass 
and you have to factor in when FSD is engaged, etc"
5785,@GaryMarcus,2022-03-11 00:24:52+00:00,https://twitter.com/GaryMarcus/status/1502078062942306310,ü§¶‚Äç‚ôÇÔ∏è all the Tesla fans retweet this without realizing that we *can‚Äôt* properly calculate it‚Äîbecause @tesla won‚Äôt fully disclose data. eg Tesla‚Äúavoid[s CA] state regulatory oversight by telling the Department of Motor Vehicles that its FSD features do not make its cars autonomous.‚Äù
5786,@GaryMarcus,2022-03-11 00:19:55+00:00,https://twitter.com/GaryMarcus/status/1502076817414696960,"@Plinz @elonmusk @Tesla When @tesla makes its data fully available for academic inspection, permitting us to examine interventions and deconfound variables like age of fleet and type of miles driven while engaged etc, I will be delighted to consider precisely that calculation."
5787,@GaryMarcus,2022-03-11 00:05:15+00:00,https://twitter.com/GaryMarcus/status/1502073126561062913,"I keep receipts. Here are 11 previous times in which @elonmusk‚Äôs premature FSD crashed into stopped emergency vehicles on a highway‚Äîbefore somebody was killed yesterday, trying to clean up similar mess.

I will say it again: beta testing @tesla FSD on public roads endangers lives"
5788,@GaryMarcus,2022-03-10 23:51:05+00:00,https://twitter.com/GaryMarcus/status/1502069562665226240,@sanjanasinghx bonobos might beg to differ. https://t.co/0BDiLYV2A5
5789,@GaryMarcus,2022-03-10 23:40:40+00:00,https://twitter.com/GaryMarcus/status/1502066940428582912,"Key technical question from @wellingmax that I hope will lead to enlightening thread; neurosymbolic, deep learning etc views all welcome @AvilaGarcez @luislamb @PMinervini @egrefen @mpshanahan @AnimaAnandkumar @YejinChoinka @ylecun @_rockt @Kordjamshidi @pmddomingos @yudapearl"
5790,@GaryMarcus,2022-03-10 23:29:08+00:00,https://twitter.com/GaryMarcus/status/1502064036783214593,"@wellingmax @NautilusMag I gave some criteria:
‚Äì can you represent &amp; compute over compositional structures?
‚Äì can you generalize operations (eg multiplication) uniformly across a domain (eg integers) reliably?

more detail in The Algebraic Mind

not opposed to differential symbols if you can make it work"
5791,@GaryMarcus,2022-03-10 22:03:03+00:00,https://twitter.com/GaryMarcus/status/1502042375652315142,@berilsirmacek completely misleading. they were awkwardly laughing about the mild interpersonal conflict about who goes first to answer the question.
5792,@GaryMarcus,2022-03-10 21:21:04+00:00,https://twitter.com/GaryMarcus/status/1502031808908595207,"@kerstingAIML fully agree, and was wondering whether those who have an aversion to symbols would engage ‚Ä¶"
5793,@GaryMarcus,2022-03-10 18:18:43+00:00,https://twitter.com/GaryMarcus/status/1501985918386769930,@emilymbender you will enjoy this example
5794,@GaryMarcus,2022-03-10 18:11:39+00:00,https://twitter.com/GaryMarcus/status/1501984143160143872,Prize to the first AI system that can read this tweet and explain the punchline.
5795,@GaryMarcus,2022-03-10 18:00:41+00:00,https://twitter.com/GaryMarcus/status/1501981379923349511,"genes matter, too. weird that their potential to predispose people to having or avoiding covid-19 isn‚Äôt even mentioned (cf  eg prelim evidence at  https://t.co/HsOL2qs4EE). so many things have roots in bth genes and environment but possible genetic role is often overlooked."
5796,@GaryMarcus,2022-03-10 17:57:00+00:00,https://twitter.com/GaryMarcus/status/1501980454718607369,"@HuffPost Strange that you omit the possibility of genetic factors, eg https://t.co/HsOL2qs4EE"
5797,@GaryMarcus,2022-03-10 16:49:54+00:00,https://twitter.com/GaryMarcus/status/1501963569424113664,"Fully agree with @emilymbender here; in the Nautilus essay had a narrow use case in mind for expository purposes, but I total agree that real harm can come from a wide variety of AI systems, including photo tagging; see eg Dr Bender‚Äôs links to @abebab‚Äôs important work."
5798,@GaryMarcus,2022-03-10 15:10:14+00:00,https://twitter.com/GaryMarcus/status/1501938484465967104,@KathrynECramer @NautilusMag that would be a wild goose chase in my long considered opinion
5799,@GaryMarcus,2022-03-10 14:53:47+00:00,https://twitter.com/GaryMarcus/status/1501934344616644610,"@rmarcilhoo @Tesla i started forming companies in 2014, but have been advocating for hybrid models since 1992. i work on what i believe in."
5800,@GaryMarcus,2022-03-10 14:52:15+00:00,https://twitter.com/GaryMarcus/status/1501933961936662530,Still waiting on an answer for this question.
5801,@GaryMarcus,2022-03-10 14:50:39+00:00,https://twitter.com/GaryMarcus/status/1501933556255260684,"@KathrynECramer @NautilusMag they are collage, factored through embedding, as far as i can tell"
5802,@GaryMarcus,2022-03-10 14:49:53+00:00,https://twitter.com/GaryMarcus/status/1501933367024971785,"@KathrynECramer @NautilusMag we said so in the @techreview article where we introduced the example, but by now i am comfortable that this kind of error is not uncommon.  other work by @yasaman_razeghi, @yoavgo etc have pointed out similar errors more systematically"
5803,@GaryMarcus,2022-03-10 14:48:06+00:00,https://twitter.com/GaryMarcus/status/1501932917731127311,@rmarcilhoo @Tesla they know where to find me :)
5804,@GaryMarcus,2022-03-10 14:41:57+00:00,https://twitter.com/GaryMarcus/status/1501931367830937611,@rmarcilhoo @Tesla tesla won‚Äôt allow academics access to the data so we don‚Äôt know
5805,@GaryMarcus,2022-03-10 14:38:41+00:00,https://twitter.com/GaryMarcus/status/1501930546586263555,@emilymbender @Abebab @vinayprabhu @abebab please follow or dm
5806,@GaryMarcus,2022-03-10 14:36:56+00:00,https://twitter.com/GaryMarcus/status/1501930106599604226,"@KathrynECramer @NautilusMag example, please"
5807,@GaryMarcus,2022-03-10 14:36:10+00:00,https://twitter.com/GaryMarcus/status/1501929914986946566,"@KathrynECramer @NautilusMag sure, but openai refused to give me access so others did systematic studies. a great one to consider is @yasaman_razeghi and @sameer_‚Äôs recent arxiv, which i linked elsewhere in the article."
5808,@GaryMarcus,2022-03-10 14:34:37+00:00,https://twitter.com/GaryMarcus/status/1501929522014294017,"@KathrynECramer @NautilusMag no specific example with GPT is ever reliable across parameters. but there is a large body of literature now that supports each type of example i gave, some of which i link."
5809,@GaryMarcus,2022-03-10 14:32:36+00:00,https://twitter.com/GaryMarcus/status/1501929016772620295,@BartWronsk @TechRonic9876 @Patapom2 @NautilusMag but they were wrong and your were right :)
5810,@GaryMarcus,2022-03-10 14:30:14+00:00,https://twitter.com/GaryMarcus/status/1501928418220261381,@emilymbender @Abebab fair point (though my key example was a rabbit): https://t.co/FA1ajBnpyk
5811,@GaryMarcus,2022-03-10 14:28:17+00:00,https://twitter.com/GaryMarcus/status/1501927928019386376,excellent commentary by @emilybender who was an important influence on my @NautilusMag essay on the science and sociology of AI and deep learning.
5812,@GaryMarcus,2022-03-10 14:24:12+00:00,https://twitter.com/GaryMarcus/status/1501926899877961735,@emilymbender @Abebab totally agreed. very fair point that i botched somewhere in the edit. finding photos in my personal photo library is low stakes but photo labeling in other contexts can be much more serious.  thanks for the link and clarification
5813,@GaryMarcus,2022-03-10 14:06:48+00:00,https://twitter.com/GaryMarcus/status/1501922524870807552,@Raza_Habib496 read the past tense. bye for now
5814,@GaryMarcus,2022-03-10 14:05:42+00:00,https://twitter.com/GaryMarcus/status/1501922247807672320,"@Raza_Habib496 perhaps my last one, because i think you are carelessly bending over backwards to be unfair and uncharitable.  i didn‚Äôt say openai didn‚Äôt *care* about understanding; i said and showed that scaling on x doesn‚Äôt guarantee scaling on Y"
5815,@GaryMarcus,2022-03-10 14:02:04+00:00,https://twitter.com/GaryMarcus/status/1501921333755609095,"@Raza_Habib496 it is the most well known benchmark and most well known to have been abandoned. you are trying to pick holes that aren‚Äôt there, missing the forest for a misread tree."
5816,@GaryMarcus,2022-03-10 13:56:59+00:00,https://twitter.com/GaryMarcus/status/1501920052819292161,@Raza_Habib496 sock example.
5817,@GaryMarcus,2022-03-10 13:54:29+00:00,https://twitter.com/GaryMarcus/status/1501919423791198208,@Raza_Habib496 perhaps if you are more careful.
5818,@GaryMarcus,2022-03-10 13:49:55+00:00,https://twitter.com/GaryMarcus/status/1501918273708834817,@boborado @chazfirestone see my new essay ;)
5819,@GaryMarcus,2022-03-10 13:42:33+00:00,https://twitter.com/GaryMarcus/status/1501916419448918017,@Raza_Habib496 they once did; i certainly didn‚Äôt say they do now. your commentary is very misleading
5820,@GaryMarcus,2022-03-10 13:41:43+00:00,https://twitter.com/GaryMarcus/status/1501916209133932544,@Raza_Habib496 that is precisely what the kaplan paper i was referring to did; you are misrepresenting me
5821,@GaryMarcus,2022-03-10 13:41:04+00:00,https://twitter.com/GaryMarcus/status/1501916047393189891,"@Raza_Habib496 best recent example was from openai‚Äôs own paper! their prompt, their training"
5822,@GaryMarcus,2022-03-10 13:39:44+00:00,https://twitter.com/GaryMarcus/status/1501915711664316424,@Raza_Habib496 the tension is real and your examples don‚Äôt address it. there are many examples similar to the ones i gave and i gave multiple links to other research reports pointing to the same.
5823,@GaryMarcus,2022-03-10 13:37:44+00:00,https://twitter.com/GaryMarcus/status/1501915210038145030,@Raza_Habib496 show one place that anybody said that out loud
5824,@GaryMarcus,2022-03-10 13:36:16+00:00,https://twitter.com/GaryMarcus/status/1501914839244963841,@aricaroline @elonmusk @NautilusMag @PeteButtigieg too much of the data is closed and confounded eg w age of vehicles
5825,@GaryMarcus,2022-03-10 13:34:59+00:00,https://twitter.com/GaryMarcus/status/1501914515394285569,"clarifying, the worker was killed by a separate vehicle but was attending to an accident caused by Tesla that crashed into a stopped vehicle, a well-known @tesla FSD issue.
 
had you taken your betas off the road, until you had solved this issue, this would not have happened."
5826,@GaryMarcus,2022-03-10 13:18:50+00:00,https://twitter.com/GaryMarcus/status/1501910453147951106,"This death is on you @elonmusk, an innocent bystander killed by your inadequate AI.
 
I gave several examples EXACTLY like this in https://t.co/Pt7HZbLIv5 in 2019, and another just yesterday in @NautilusMag. This was a known issue.

@PeteButtigieg"
5827,@GaryMarcus,2022-03-10 05:32:34+00:00,https://twitter.com/GaryMarcus/status/1501793112179437570,@LucaAmb @hardmaru @NautilusMag i cited specific evidence in the section on scaling
5828,@GaryMarcus,2022-03-10 04:25:12+00:00,https://twitter.com/GaryMarcus/status/1501776158458744832,@NaveenGRao @NautilusMag to *not* use. where‚Äôs that twitter edit button when we need it? :)
5829,@GaryMarcus,2022-03-10 03:26:35+00:00,https://twitter.com/GaryMarcus/status/1501761407406075904,@tejasdkulkarni what you are doing sounds very reasonable; imagining that everything is going to emerge from a slightly larger LLM is not‚Ä¶
5830,@GaryMarcus,2022-03-10 03:20:14+00:00,https://twitter.com/GaryMarcus/status/1501759810017976322,"@ankurhandos yes, i think that‚Äôs fair. the point of the essay is that pure end-to-end deep learning is hitting a wall (eg starting to saturate on some scaling, and not really improving on common sense), but that hybrid systems (which include plenty of deep learning) are more promising."
5831,@GaryMarcus,2022-03-10 03:10:45+00:00,https://twitter.com/GaryMarcus/status/1501757421932331010,"@tejasdkulkarni but (from your description) you are *starting* with a hybrid model, and still keeping aspects of symbols; you haven‚Äôt replaced your system with end-to-end deep learning. correct?"
5832,@GaryMarcus,2022-03-10 02:08:30+00:00,https://twitter.com/GaryMarcus/status/1501741757230288896,@drsxr @NautilusMag Thanks - I put my heart and soul into it!
5833,@GaryMarcus,2022-03-10 01:39:45+00:00,https://twitter.com/GaryMarcus/status/1501734523628707845,"Deep Learning Is Hitting a Wall. What would it take for artificial intelligence to make real progress?

#longread in ‚Å¶@NautilusMag‚Å© on one of the key technical questions in AI. https://t.co/ze8DtZuHwR"
5834,@GaryMarcus,2022-03-10 00:20:15+00:00,https://twitter.com/GaryMarcus/status/1501714516920311808,"Dropping soon @NautilusMag, a #longread on why #AI can‚Äôt and won‚Äôt advance until deep learning brings symbol-manipulation on board."
5835,@GaryMarcus,2022-03-07 19:04:19+00:00,https://twitter.com/GaryMarcus/status/1500910231034810369,@cocoweixu @NSF Controllable text sounds like the the opposite of LLMs :) Congrats!
5836,@GaryMarcus,2022-03-07 18:05:49+00:00,https://twitter.com/GaryMarcus/status/1500895510466478080,"Alexa, go h#ck yourself. 

‚ÄúWhat could go wrong?‚Äù, indeed.

‚Å¶@dangoodin001‚Å© reports a disturbing new #mlsec vulnerability. https://t.co/x4h5kXIEM1"
5837,@GaryMarcus,2022-03-07 05:26:21+00:00,https://twitter.com/GaryMarcus/status/1500704384358879232,"Give it up, Vladimir, go home. 

The internet is here and your troops are getting wise to your lies."
5838,@GaryMarcus,2022-03-06 23:04:46+00:00,https://twitter.com/GaryMarcus/status/1500608354393100289,@attilacsordas @seanmcarroll am fine thanks (&amp; it was recorded a month ago).
5839,@GaryMarcus,2022-03-06 18:43:43+00:00,https://twitter.com/GaryMarcus/status/1500542661731573760,"resources for people fleeing from Ukraine into Hungary: https://t.co/AdPcH9bgjN

please spread the word"
5840,@GaryMarcus,2022-03-06 01:53:16+00:00,https://twitter.com/GaryMarcus/status/1500288371951751171,@DevPsyOps @SwiftOnSecurity yep i just retracted a few moments ago.
5841,@GaryMarcus,2022-03-06 01:47:45+00:00,https://twitter.com/GaryMarcus/status/1500286985423896578,"@tdietterich @KutiFehler @HappyAar i am now convinced, and am retracting the original tweet."
5842,@GaryMarcus,2022-03-06 01:27:22+00:00,https://twitter.com/GaryMarcus/status/1500281854523416579,@EibrielBot @CDisillusion is the Telegraph HD the same moment in the video? I would find that convincing (and it may be)
5843,@GaryMarcus,2022-03-06 01:11:51+00:00,https://twitter.com/GaryMarcus/status/1500277950700085251,"Is there any footage of this Putin speech that is HD but longer than the brief excerpt from this higher-quality HD video at the Telegraph? https://t.co/sRL499lRoe 

Trying to figure out whether the Telegraph and mic-crossing moments portray the same moment in the speech."
5844,@GaryMarcus,2022-03-06 01:06:34+00:00,https://twitter.com/GaryMarcus/status/1500276619352498176,@tdietterich @KutiFehler @HappyAar Do we know @tdietterich that the HD Telegraph video (which I have now watched) is capturing the same moment? there are only a few seconds footage in both clips. Does anybody have the full speech from that angle?
5845,@GaryMarcus,2022-03-05 23:35:32+00:00,https://twitter.com/GaryMarcus/status/1500253711213289473,source (with further discussion in thread):
5846,@GaryMarcus,2022-03-05 01:05:48+00:00,https://twitter.com/GaryMarcus/status/1499914036443443202,"@yourauntemma also conspicuously absent (since he wasn‚Äôt yet a world leader in ‚Äò15 when the article is written) is the orange-haired one.

p.s. thanks for posting the article."
5847,@GaryMarcus,2022-03-05 00:55:40+00:00,https://twitter.com/GaryMarcus/status/1499911486461788160,"This 2015 paper on war and antisocial personality disorder is even more relevant today than it was when it was published. 

But Table 2 sure could use some updates. https://t.co/gLNDfNNFfl"
5848,@GaryMarcus,2022-03-04 23:29:02+00:00,https://twitter.com/GaryMarcus/status/1499889685497200643,‚ÄúNever underestimate Putin‚Äôs barbarism. But it‚Äôs doubtful that Putin can ever extinguish Ukrainian resistance ‚Äî or resurrect the myth of Russian military competence.‚Äù
5849,@GaryMarcus,2022-03-04 04:24:43+00:00,https://twitter.com/GaryMarcus/status/1499601709764538370,a nuclear plant is *literally* under attack in this clip with @JDVance1 and he can‚Äôt get off his terminally myopic talking points for two seconds to think about the world outside his own backyard.
5850,@GaryMarcus,2022-03-04 01:15:45+00:00,https://twitter.com/GaryMarcus/status/1499554155706216453,The world was very directly warned.
5851,@GaryMarcus,2022-03-03 19:02:29+00:00,https://twitter.com/GaryMarcus/status/1499460219704791061,"@Benambridge @wzuidema @NoraNewcombe @tallinzen @rgalhama thanks, and i agree that it is a debate that is both important and unresolved; appreciate your sharing both sides!"
5852,@GaryMarcus,2022-03-03 18:09:56+00:00,https://twitter.com/GaryMarcus/status/1499446995051712512,"@wzuidema @NoraNewcombe @tallinzen @Benambridge @rgalhama FYI you have retweeted a tweet that says something doesn‚Äôt replicate without recognizing a larger body that goes in the opposite direction. I hope that you will RT my reply above as well, for balanced presentation."
5853,@GaryMarcus,2022-03-03 17:43:56+00:00,https://twitter.com/GaryMarcus/status/1499440449504747584,@wzuidema completely agreed in the value of preregistered studies; that preregistration has become routine is a significant methodological advance for the field.
5854,@GaryMarcus,2022-03-03 17:41:24+00:00,https://twitter.com/GaryMarcus/status/1499439812998144005,"@alexandersclark @wzuidema good question. I don't follow this work closely any more, but personally tried more than once, before it was feasible to publish nonreplications, to replicate https://t.co/9uapjkxUln, without success. don't know if that's been replicated by others."
5855,@GaryMarcus,2022-03-03 17:28:30+00:00,https://twitter.com/GaryMarcus/status/1499436569433829376,@wzuidema @rgalhama you are writing this as if a single null result decisively overrides a much larger body of work; the jury is still out but the post-mortem is perhaps premature.
5856,@GaryMarcus,2022-03-03 16:13:07+00:00,https://twitter.com/GaryMarcus/status/1499417597372088321,every word https://t.co/9PhMgr4Yia
5857,@GaryMarcus,2022-03-03 14:25:22+00:00,https://twitter.com/GaryMarcus/status/1499390481712627720,"‚ÄúPutin basically has four choices: lose early, lose late, lose big or lose small.‚Äù https://t.co/J9y7ZSiwe5"
5858,@GaryMarcus,2022-03-03 02:40:03+00:00,https://twitter.com/GaryMarcus/status/1499212981845970944,@neal_katyal https://t.co/jzd2LVHSrx
5859,@GaryMarcus,2022-03-02 03:23:35+00:00,https://twitter.com/GaryMarcus/status/1498861551033339909,"‚ÄúYouTube's Captions Insert Explicit Language in Kids' Videos
The AI that transcribes spoken dialog on the platform's standard version can render ‚Äúcorn‚Äù as ‚Äúporn,‚Äù ‚Äúbeach‚Äù as ‚Äúb‚Ä¶‚Äù‚Äù etc‚Ä¶  

@tsimonite https://t.co/wvai0hIU0A"
5860,@GaryMarcus,2022-03-01 18:26:00+00:00,https://twitter.com/GaryMarcus/status/1498726262465916933,@mattstern2 @Muffin_Chips @MLStreetTalk appears to be from here:
5861,@GaryMarcus,2022-03-01 18:25:00+00:00,https://twitter.com/GaryMarcus/status/1498726011340394497,"@mattstern2 @Muffin_Chips @MLStreetTalk it‚Äôs probably hard to trace but but pretty plausible that a bot would generate that, given the pattern of errors"
5862,@GaryMarcus,2022-03-01 18:16:28+00:00,https://twitter.com/GaryMarcus/status/1498723863999311872,"Sorry not sorry you ran out of food and fuel. 

Suggest you turn around and go home."
5863,@GaryMarcus,2022-03-01 17:59:50+00:00,https://twitter.com/GaryMarcus/status/1498719675743498240,"@WorldSummitAI @SColesPorter @Inspired__Minds @IntHealthAI @pjbarden @nordicgeo @vdignum @Tokyo_gov @ZoubinGhahrama1 @saimaqr @RutaDanny @BVLSingler @drkatedevlin @GoyenM @EffyVayena Vancouver, BC!"
5864,@GaryMarcus,2022-03-01 16:19:42+00:00,https://twitter.com/GaryMarcus/status/1498694476629377028,Honored to see https://t.co/Pt7HZbLIv5 in this Forbes list of 7 must-read books in Artificial Intelligence!
5865,@GaryMarcus,2022-03-01 14:30:38+00:00,https://twitter.com/GaryMarcus/status/1498667031905767425,@KordingLab ‚ÄúOur results provide robust evidence that pre-stimulus alpha frequency as a dynamic neural state and an individual‚Äôs trait index do not influence observers‚Äô perceptual sensitivity or bias‚Äù
5866,@GaryMarcus,2022-02-28 16:54:48+00:00,https://twitter.com/GaryMarcus/status/1498340922643255297,@KordingLab @neuro_data
5867,@GaryMarcus,2022-02-28 15:59:22+00:00,https://twitter.com/GaryMarcus/status/1498326972908273664,"@KordingLab necessary: probably. sufficient: clearly not, there are ways of (to some degree) doing all in AI, but (current) AI is not particularly intelligent.

minimally missing: compositionality, which may be assumed but isn‚Äôt explicit; core knowledge around space, time, causality, etc"
5868,@GaryMarcus,2022-02-28 15:32:52+00:00,https://twitter.com/GaryMarcus/status/1498320302232662017,"Master class in explaining urgently relevant economics,  @PatcohenNYT &amp; @jeannasmialek"
5869,@GaryMarcus,2022-02-26 22:23:40+00:00,https://twitter.com/GaryMarcus/status/1497698909841334275,"‚ùóÔ∏è280B parameters and still a total fail on a multiple choice Truthfulness task. Excellent thread/research by @OwainEvans_UK 

Echoes what @ErnestSDavis &amp; I said in 2018 about AI &amp; fake news: https://t.co/QSGTKTkrIt"
5870,@GaryMarcus,2022-02-25 23:46:26+00:00,https://twitter.com/GaryMarcus/status/1497357350755188736,@NaveenGRao @MaxALittle fully agreed (though i think it is hard)
5871,@GaryMarcus,2022-02-25 21:04:57+00:00,https://twitter.com/GaryMarcus/status/1497316709564227589,"@elonmusk @WholeMarsBlog This logic still makes no sense @elonmusk

üëâBirds flap their wings, but that does not mean that wings are the only way to achieve flight.
üëâCurrent neural nets lack the cognitive depth and robustness that would be necessary to support reliable L5 self-driving form vision alone."
5872,@GaryMarcus,2022-02-25 21:04:42+00:00,https://twitter.com/GaryMarcus/status/1497316648230944768,"Your logic makes no sense, @elonmusk

üëâBirds flap their wings, but that does not mean that wings are the only way to achieve flight.
üëâCurrent neural nets lack the cognitive depth and robustness that would be necessary to support reliable L5 self-driving form vision alone."
5873,@GaryMarcus,2022-02-25 20:59:46+00:00,https://twitter.com/GaryMarcus/status/1497315408684064769,"@WholeMarsBlog @elonmusk yeah, like Larry Page."
5874,@GaryMarcus,2022-02-25 19:52:43+00:00,https://twitter.com/GaryMarcus/status/1497298533958909953,"@yoavgo i don‚Äôt know, and think that he from his own self-interest miscalculated. but here is another theory: https://t.co/YUpWUoWUw6"
5875,@GaryMarcus,2022-02-25 19:46:54+00:00,https://twitter.com/GaryMarcus/status/1497297068804620290,@NaveenGRao @MaxALittle @JFPuget
5876,@GaryMarcus,2022-02-25 19:20:23+00:00,https://twitter.com/GaryMarcus/status/1497290397810237442,@JFPuget https://t.co/hkl8EvkWwG
5877,@GaryMarcus,2022-02-25 19:05:28+00:00,https://twitter.com/GaryMarcus/status/1497286643413241860,@JFPuget general suggestion: please read the other replies and replies to those replies before posting; you'll see my answer is already there.
5878,@GaryMarcus,2022-02-25 19:03:54+00:00,https://twitter.com/GaryMarcus/status/1497286246627823617,Just imagine how much different the world would be right now had this 2020 @nypost rumor been true. https://t.co/9heElONAsZ
5879,@GaryMarcus,2022-02-25 17:11:34+00:00,https://twitter.com/GaryMarcus/status/1497257978604359681,"@HappyAar as of late 2019, w @maxalittle: https://t.co/rxTTNxrPtl"
5880,@GaryMarcus,2022-02-25 17:10:53+00:00,https://twitter.com/GaryMarcus/status/1497257807103479808,@NaveenGRao here's what @MaxALittle and I wrote a while ago: https://t.co/rxTTNxrPtl
5881,@GaryMarcus,2022-02-25 14:52:17+00:00,https://twitter.com/GaryMarcus/status/1497222928206688259,"@jd87 that is an interesting question, but when a heavy-hitter erroneously tells a whole field to stop training its students, that's of interest to. 

https://t.co/bzemVpin0H"
5882,@GaryMarcus,2022-02-25 14:48:47+00:00,https://twitter.com/GaryMarcus/status/1497222046446600192,"@MsalehiSadegh the tweet is a reference to a famous 2016 quote, which suggested radiologists were all going to lose their jobs and that we may as well stop training them."
5883,@GaryMarcus,2022-02-25 14:44:43+00:00,https://twitter.com/GaryMarcus/status/1497221023057412106,Fast forward to 2022. Actual number of radiologists replaced ... still holding steady at ... zero.
5884,@GaryMarcus,2022-02-24 18:00:16+00:00,https://twitter.com/GaryMarcus/status/1496907845022863362,"See this long thread that anticipated many recent discoveries on LLM limits, and the combative tone you took throughout.

3/3"
5885,@GaryMarcus,2022-02-24 18:00:15+00:00,https://twitter.com/GaryMarcus/status/1496907843789737989,"2019:
@GaryMarcus: key problem w GPT models: ‚Äúthey don‚Äôt develop robust representations of how events unfold over time‚Äù
@ylecun : ‚Äúyou are fighting a rear-guard battle‚Äù

2022:
@Meta  PR: LeCun says ‚Äúability to learn ‚Äúworld models‚Äù may be the key to building human-level AI‚Äù

2/3"
5886,@GaryMarcus,2022-02-24 18:00:15+00:00,https://twitter.com/GaryMarcus/status/1496907842221068292,". @ylecun I fully agree with your critics here about the misrepresentation of decades of history of world models in Meta PR blitz‚Äîespecially where you attacked me in 2019 when I said in that the key issue w GPT was that it lacked world models.

1/3"
5887,@GaryMarcus,2022-02-24 16:45:33+00:00,https://twitter.com/GaryMarcus/status/1496889041844772865,"Wait a second. Showing that memory may be operative in some unknown way in one patient at the time of death doesn‚Äôt show that we actually see our lives flash before our eyes when we die.

Maybe the poor guy was just trying to remember where he put his phone? 

ü§∑‚Äç‚ôÇÔ∏è"
5888,@GaryMarcus,2022-02-24 16:12:58+00:00,https://twitter.com/GaryMarcus/status/1496880843838529536,@sanjanasinghx https://t.co/Sns5EuOJyP
5889,@GaryMarcus,2022-02-24 15:51:55+00:00,https://twitter.com/GaryMarcus/status/1496875545929256965,@lizadixon What‚Äôs going on?
5890,@GaryMarcus,2022-02-24 15:14:17+00:00,https://twitter.com/GaryMarcus/status/1496866074851037191,"@greglinden As it happens I was talking about consciousness, but the point is general!"
5891,@GaryMarcus,2022-02-24 10:47:03+00:00,https://twitter.com/GaryMarcus/status/1496798822424453121,"@erikbryn @guyi @dlowd Scale might matter if you have the right kind of stuff organized in right kind of way. 

But:
üëâscale does not matter in a rock
üëâI see no reason to think that scale is going to matter in a bunch of largely homogeneous matrix multiplies in a GPU that lack a stable cognitive model"
5892,@GaryMarcus,2022-02-24 00:46:51+00:00,https://twitter.com/GaryMarcus/status/1496647778008633353,"@guyi @erikbryn @dlowd one aspect of ‚Äúright way‚Äù is (perhaps, depending on your definition of consciousness) having a stable mental representation of the world around you, which GPT lacks.  

I riffed a bunch on this earlier today for an upcoming episode on @MLStreetTalk"
5893,@GaryMarcus,2022-02-23 20:00:09+00:00,https://twitter.com/GaryMarcus/status/1496575626656063489,"for a different but also enthusiastic argument for world models, see my 2020 Next Decade in AI. https://t.co/9Gh30vhaMU"
5894,@GaryMarcus,2022-02-23 19:03:26+00:00,https://twitter.com/GaryMarcus/status/1496561354265792521,"@MadamePratolung @jrking0 partial convergence doesn't entail comparable mechanisms even for the partial convergence, it only raises the possibility. very provocative study but there is lots more work to be done before we get clear answers..."
5895,@GaryMarcus,2022-02-23 19:01:22+00:00,https://twitter.com/GaryMarcus/status/1496560834558177280,@MadamePratolung @jrking0 https://t.co/0xT9A5AOgz and some back and forth below that (and his thread above)
5896,@GaryMarcus,2022-02-23 17:13:33+00:00,https://twitter.com/GaryMarcus/status/1496533703144652807,"@jrking0 Yes, but some modules could be computationally distinct even if they physically distributed. Or localized but draw on global resources. Or you could have two modular stages &amp; then one that is processed more broadly. (On Fodor‚Äôs view, some processes were modular and some central)"
5897,@GaryMarcus,2022-02-23 17:00:37+00:00,https://twitter.com/GaryMarcus/status/1496530447869825035,"@MadamePratolung ‚Äúpartially converge‚Äù is about right; brain and the nets are sensitive to same input statistics. but there is more to language than prediction, and we need to understand the divergence as well as convergence.

also i made a comment re modularity @ end of @jrking0‚Äôs thread"
5898,@GaryMarcus,2022-02-23 16:49:44+00:00,https://twitter.com/GaryMarcus/status/1496527709450928132,"@jrking0 fascinating result that is reminiscent of the modularity hypothesis, since you find (best) correlations shifting over time between three distinct architectures."
5899,@GaryMarcus,2022-02-23 12:21:11+00:00,https://twitter.com/GaryMarcus/status/1496460127276535812,"@maorivg @JonathanBerant The zeitgeist in current ML rests on the premise that returns will not diminish before we reach AGI/NLU/reasoning/self-driving, etc"
5900,@GaryMarcus,2022-02-23 04:58:18+00:00,https://twitter.com/GaryMarcus/status/1496348671797088257,"@ID_AA_Carmack @SpaceTimeAlien @seanmcarroll very hard to prove non-equivalence of something that doesn‚Äôt yet exist and that we can‚Äôt really even yet characterize, so premature to rule out symbol-manipulation‚Ä¶"
5901,@GaryMarcus,2022-02-23 04:56:18+00:00,https://twitter.com/GaryMarcus/status/1496348166496878594,"@ID_AA_Carmack @SpaceTimeAlien @seanmcarroll in the limit of equivalence ‚Ä¶ you can build Turing machines out of connectionist models, per McCulloch and Pitts, Siegelmann and Sontag, etc. 

chapter 2 of my book The Algebraic Mind lays out some of this landscape"
5902,@GaryMarcus,2022-02-23 04:20:08+00:00,https://twitter.com/GaryMarcus/status/1496339063628271616,@KordingLab @ID_AA_Carmack @SpaceTimeAlien @seanmcarroll @WiringTheBrain @YiotaPoirazi @recursus @AdamMarblestone that paper should be required reading!
5903,@GaryMarcus,2022-02-23 04:15:20+00:00,https://twitter.com/GaryMarcus/status/1496337857715265537,@ID_AA_Carmack @SpaceTimeAlien @seanmcarroll @WiringTheBrain @YiotaPoirazi @KordingLab @recursus @AdamMarblestone
5904,@GaryMarcus,2022-02-23 03:49:42+00:00,https://twitter.com/GaryMarcus/status/1496331408633171970,"@ID_AA_Carmack @SpaceTimeAlien @seanmcarroll Our only existence proof is a brain system that we don‚Äôt understand, that doesn‚Äôt have a lot to do with current connectionist networks:
- brains have 1000ish kinds of neurons, not 1
- bio-neurons are much more complex than network nodes
- brains have loads more prior structure"
5905,@GaryMarcus,2022-02-23 02:53:36+00:00,https://twitter.com/GaryMarcus/status/1496317290471739399,"@sanjanasinghx + Newton, Darwin, Turing."
5906,@GaryMarcus,2022-02-22 20:59:44+00:00,https://twitter.com/GaryMarcus/status/1496228236082171906,"@DrMJoyner @maorivg @JonathanBerant there are lots of scaling laws that probably reliable enough to use in many ways; but the point here is that many people are now inferring we can get to reliable AI with a certain model size, and that extrapolation may  or may not be correct."
5907,@GaryMarcus,2022-02-22 20:52:34+00:00,https://twitter.com/GaryMarcus/status/1496226431785140224,"@DrMJoyner @maorivg @JonathanBerant interesting, eg https://t.co/QUxaqQAwjQ"
5908,@GaryMarcus,2022-02-22 20:50:47+00:00,https://twitter.com/GaryMarcus/status/1496225981924880384,"@EdwardLockhart @maorivg @JonathanBerant A lot rests on when; eg in driving if adding data scales us to 99% but not 99.9999% reliability, we will need another approach beyond scaling to get us to L5 driving. Same thing with a NLU crisis counselor. 1% error would be too costly, so limits on scale really matter"
5909,@GaryMarcus,2022-02-22 20:44:06+00:00,https://twitter.com/GaryMarcus/status/1496224302953566208,@HappyAar @maorivg @JonathanBerant saturate: get to a certain level of performance (as a function of model size or data size) and then stop improving (or improve at a much slower pace)
5910,@GaryMarcus,2022-02-22 19:36:40+00:00,https://twitter.com/GaryMarcus/status/1496207329926209540,"@maorivg @JonathanBerant Are scaling laws really ‚Äúlaws‚Äù, or more like empirical observations, that may eventually saturate?"
5911,@GaryMarcus,2022-02-22 04:15:53+00:00,https://twitter.com/GaryMarcus/status/1495975608505225216,"@luislamb @frossi_t @VKordoni I was way ahead of these guys, in 2012: https://t.co/RHYA2bpv5O"
5912,@GaryMarcus,2022-02-20 23:33:37+00:00,https://twitter.com/GaryMarcus/status/1495542183851888641,"@spiantado Thinking about it some more, I wrote a longer thread on the review:"
5913,@GaryMarcus,2022-02-20 22:14:06+00:00,https://twitter.com/GaryMarcus/status/1495522175935123458,"Beyond all this, Chomsky should be a model to every scientist in at least one respect: he has repeatedly shown a genuine willingness to challenge and revise his own beliefs, periodically tossing aside even his most successful ideas, in effort to come up with deeper explanations."
5914,@GaryMarcus,2022-02-20 22:14:06+00:00,https://twitter.com/GaryMarcus/status/1495522174769111043,"But Chomsky was right
- to refute behaviorism
‚ÅÉ to emphasize universals
- to emphasize mental representation
- to turn linguistics into a science
- that language cannot be learned without innateness
‚ÅÉ that input statistics alone can‚Äôt capture language
(3/4)"
5915,@GaryMarcus,2022-02-20 22:14:06+00:00,https://twitter.com/GaryMarcus/status/1495522173389135875,"I disagree with Chomsky on many points:
‚ÅÉHe undervalues semantics &amp; overvalues syntax
‚ÅÉHis view about evolution of lg is doubtful
‚ÅÉLanguage probably not as modular as he once thought
‚ÅÉ1980s-era theories had too much lg-specific innateness
‚ÅÉLanguage is not perfect
(2/4)"
5916,@GaryMarcus,2022-02-20 22:14:05+00:00,https://twitter.com/GaryMarcus/status/1495522172038569984,"This is an appallingly one-sided hit job on Noam Chomsky that gives readers no idea of why so many have been so influenced by Chomsky‚Äôs ideas.  

Thread (1/4)"
5917,@GaryMarcus,2022-02-20 21:55:32+00:00,https://twitter.com/GaryMarcus/status/1495517501853093890,@memarkelliottme @pascalefung @anilkseth any human with this level of challenge would be rushed to a neurologist
5918,@GaryMarcus,2022-02-20 21:01:46+00:00,https://twitter.com/GaryMarcus/status/1495503969262927872,"@spiantado I have some similar concerns about the Minimalist Program, but that‚Äôs overstated. When Pullum writes ‚ÄúToday Chomsky has a new view on syntax‚Äù about something Chomsky first discussed 30 years ago you know you are in for an out-of-touch hit job."
5919,@GaryMarcus,2022-02-20 18:16:21+00:00,https://twitter.com/GaryMarcus/status/1495462342674444288,@AnnieDuke so say we all. ‚ù§Ô∏è
5920,@GaryMarcus,2022-02-20 17:45:24+00:00,https://twitter.com/GaryMarcus/status/1495454552912392195,"The late, truly great Lila Gleitman anticipating the immense outlier difficulties of driverless cars, December 2016.

cc @AnnieDuke https://t.co/55Pkyqhrrp"
5921,@GaryMarcus,2022-02-19 11:28:00+00:00,https://twitter.com/GaryMarcus/status/1494997191315755008,also extends @LakeBrenden‚Äôs important extension of The Algebraic Mind
5922,@GaryMarcus,2022-02-19 11:24:41+00:00,https://twitter.com/GaryMarcus/status/1494996356745752578,"ps quote and result from this excellent  paper on few-shot performance on numerical tasks like arithmetic

https://t.co/ID0DkK4Wlz
by @yasaman_razeghi @rloganiv @nlpmattg @sameer_ 

h/t @AlexTamkin‚Äôs excellent thread"
5923,@GaryMarcus,2022-02-19 11:21:33+00:00,https://twitter.com/GaryMarcus/status/1494995567637762048,"incredibly important result: ‚Äúour results raise the question of how much [large language] models actually generalize beyond pretraining data‚Äù

Bravo to #EleutherAI for making an LLM with truly open training data available!

Confirms the key claim of The Algebraic Mind."
5924,@GaryMarcus,2022-02-19 01:45:10+00:00,https://twitter.com/GaryMarcus/status/1494850513690451975,@BerndPorr @jvoigts the story has been developing for a while and is more and more persuasive. cc @YiotaPoirazi @mattlark icymi
5925,@GaryMarcus,2022-02-18 19:25:54+00:00,https://twitter.com/GaryMarcus/status/1494755069438283781,"@zacharylipton @RobustAI Anthony is now CEO for all practical purposes; I am moving to Executive Chairman. But it's not official yet, so I haven't yet updated my LinkedIn bio or website."
5926,@GaryMarcus,2022-02-18 19:17:27+00:00,https://twitter.com/GaryMarcus/status/1494752942989086720,"@rodneyabrooks @RobustAI Anthony is now CEO for all practical purposes; I am moving to Executive Chairman. But it's not official yet, so I haven't yet updated my LinkedIn bio or website."
5927,@GaryMarcus,2022-02-17 16:50:43+00:00,https://twitter.com/GaryMarcus/status/1494353630417149974,@rcalo same :(
5928,@GaryMarcus,2022-02-16 21:42:01+00:00,https://twitter.com/GaryMarcus/status/1494064547379892229,@lizadixon @NIH but ultimately the particular wording in the letter could be applied either in ways that are reasonable or in ways that are devastating. i don‚Äôt trust congress to distinguish the two.
5929,@GaryMarcus,2022-02-16 21:33:10+00:00,https://twitter.com/GaryMarcus/status/1494062323543072768,"@lizadixon ""calling on the @NIH to phase-out animal experiments"" in tweet seems to push towards a total ban, and I am concerned that eg 10% success rate will be taken as a ""poor outcome""; in drug discovery that is actually hugely positive but I don‚Äôt see that nuance represented here."
5930,@GaryMarcus,2022-02-16 20:08:43+00:00,https://twitter.com/GaryMarcus/status/1494041068182011912,"@lizadixon I fully support legislation to do animal testing only very thoughtfully, balancing cost as as benefits (same as human testing); this particular proposal is to ban *all* animal testing, irrespective of potential benefits; I cannot support that."
5931,@GaryMarcus,2022-02-16 17:20:21+00:00,https://twitter.com/GaryMarcus/status/1493998696614166530,"Without animal research we would not have heart medicines, cancer treatments or vaccines.

Frequent failure accompanied by occasional success is the best we have got-and has saved millions of lives.

Medical science is already hard;
making it nearly impossible is not a good idea."
5932,@GaryMarcus,2022-02-15 00:35:13+00:00,https://twitter.com/GaryMarcus/status/1493383360466460674,Fully agree with @ylecun; there is no sound reason to think that current neural nets have anything to do with consciousness.
5933,@GaryMarcus,2022-02-14 19:26:18+00:00,https://twitter.com/GaryMarcus/status/1493305618471346180,"@filippie509 Geoff Hinton said earlier today ‚ÄúMany AI researchers are very unclear about what consciousness is and also very sure that GPT-3 doesn‚Äôt have it. It‚Äôs a strange combination‚Äù. 

Since I don‚Äôt know much about warp speed, I can‚Äôt really speak to your transmission."
5934,@GaryMarcus,2022-02-14 18:43:36+00:00,https://twitter.com/GaryMarcus/status/1493294872987529216,if only the AI world had only stuck to its early openness to neurosymbolic approaches‚Ä¶
5935,@GaryMarcus,2022-02-14 18:41:38+00:00,https://twitter.com/GaryMarcus/status/1493294379540172802,@sd_marlow @atscmc i didn‚Äôt invent the term. eg https://t.co/S4q0FzPiBz but on AGI we are more like linear with small slope
5936,@GaryMarcus,2022-02-14 16:06:44+00:00,https://twitter.com/GaryMarcus/status/1493255394587648006,"Physicist/philosopher/polymath @seanmcarroll pushed me hard, and it shows in this deep dive on #AI, #ML, and #CommonSense."
5937,@GaryMarcus,2022-02-13 23:39:03+00:00,https://twitter.com/GaryMarcus/status/1493006836269662208,@luislamb @frossi_t @AvilaGarcez @vardi for sure; i am working on an essay that mentions this. the unfortunate division between schools didn‚Äôt seem to arise until some time the 50s
5938,@GaryMarcus,2022-02-13 18:08:03+00:00,https://twitter.com/GaryMarcus/status/1492923540148006913,BC https://t.co/IuVx35kEdD
5939,@GaryMarcus,2022-02-12 04:52:52+00:00,https://twitter.com/GaryMarcus/status/1492361035314958339,"I have been trying to tell you this since 2016, @elonmusk. Glad you are finally starting to get it.

https://t.co/eLbmoHoQhm"
5940,@GaryMarcus,2022-02-12 00:10:20+00:00,https://twitter.com/GaryMarcus/status/1492289933909839872,"OK, so I thought this was proof that GPT was clueless, but @ilyasut thinks it is a sign of consciousness ü§∑‚Äç‚ôÇÔ∏è"
5941,@GaryMarcus,2022-02-11 22:22:21+00:00,https://twitter.com/GaryMarcus/status/1492262758238212096,Maybe something like this? https://t.co/oM21sWo1Nb
5942,@GaryMarcus,2022-02-11 13:57:02+00:00,https://twitter.com/GaryMarcus/status/1492135593869918210,@DrMJoyner @BierVicki @zakkohane and sure to follow @MaxALittle too
5943,@GaryMarcus,2022-02-11 01:47:03+00:00,https://twitter.com/GaryMarcus/status/1491951887842566147,‚ÄòFull Self-Driving‚Äô clips show Teslas on train tracks and fighting for control. Experts see deep flaws.  ‚Ä¶ with no quick fix  https://t.co/9oSdPnVu3D
5944,@GaryMarcus,2022-02-10 23:33:47+00:00,https://twitter.com/GaryMarcus/status/1491918348564590594,"@DGBassani So sorry! Grief is indeed not linear. It‚Äôs periodic, and of the biggest challenges in being human. Carry on as best you can and allow you and your children the space you need."
5945,@GaryMarcus,2022-02-10 05:01:18+00:00,https://twitter.com/GaryMarcus/status/1491638381058555905,"@tyrell_turing guess you didn‚Äôt get to sentences like ‚ÄúBut the idea that computers are strictly serial is woefully out of date‚Äù in my oped? 

or the one where I said ‚Äúwhether the brain is a computer is partly a matter of definition.‚Äù

or the paragraph in which I made a specific proposal?"
5946,@GaryMarcus,2022-02-10 04:32:18+00:00,https://twitter.com/GaryMarcus/status/1491631086819889155,"GPT-NeoX-20B, 20 billion parameter large language model made freely available to public, with candid report on strengths, limits, ecological costs, etc. 

Genuinely Open AI"
5947,@GaryMarcus,2022-02-10 00:56:26+00:00,https://twitter.com/GaryMarcus/status/1491576760109993987,‚ÄúYou should think of [AphaCode] as something that could be an assistant to a programmer in the way that a calculator might once have helped an accountant‚Ä¶ not one-stop shopping that would replace an actual human programmer. We are decades away from that.‚Äù https://t.co/cacXrPaAa5
5948,@GaryMarcus,2022-02-09 19:12:03+00:00,https://twitter.com/GaryMarcus/status/1491490092426285058,"The difference between a person treating a genuinely self-driving car and (eg) a current Tesla as a genuinely self-driving car could easily be life or death. 

Terms below may sound jargony but @nytimes screwed this one up.

See also @lizadixon‚Äôs pinned tweet on #autonowashing"
5949,@GaryMarcus,2022-02-09 18:01:07+00:00,https://twitter.com/GaryMarcus/status/1491472242873495552,"@filippie509 i just borrowed your example, @ #177"
5950,@GaryMarcus,2022-02-09 16:21:42+00:00,https://twitter.com/GaryMarcus/status/1491447224207015936,how important is AlphaCode? terrific back and forth thread on Scott Aaronson‚Äôs blog re https://t.co/zXttj9f7gr
5951,@GaryMarcus,2022-02-09 15:46:50+00:00,https://twitter.com/GaryMarcus/status/1491438450071191552,@andrewagill You should feel dirty. There is a difference between noting that the decision was ill-constructed &amp; recognizing the intuition is correct: free speech should be well protected but Holmes was correct in anticipating that we cannot turn an entirely blind eye to social consequences.
5952,@GaryMarcus,2022-02-08 20:45:59+00:00,https://twitter.com/GaryMarcus/status/1491151345587732482,"On the perils in chasing the state of the art, by @kchurch4 and @KordoniN 

https://t.co/5KJH7uR7RX"
5953,@GaryMarcus,2022-02-08 18:17:04+00:00,https://twitter.com/GaryMarcus/status/1491113866595475456,@Grady_Booch i knew you would get the reference :)
5954,@GaryMarcus,2022-02-08 17:55:49+00:00,https://twitter.com/GaryMarcus/status/1491108521022455808,example drawn from interesting new paper by @EthanJPerez /@deepmindAI https://t.co/zre1E5jGwW
5955,@GaryMarcus,2022-02-08 17:55:49+00:00,https://twitter.com/GaryMarcus/status/1491108519340560387,"AI researchers, please don‚Äôt let your large language models trained on the internet grow up to be personal assistants: https://t.co/ZeD7n8KVj9"
5956,@GaryMarcus,2022-02-08 01:28:34+00:00,https://twitter.com/GaryMarcus/status/1490860070237736964,@andrewagill @BeecherDenys we can argue the right formulation but I stand by the overall notion that inciting imminent violence should not be protected.
5957,@GaryMarcus,2022-02-08 01:26:19+00:00,https://twitter.com/GaryMarcus/status/1490859506082848769,"@andrewagill @BeecherDenys popehat has blocked me but even he says ‚ÄúThings we call ‚Äúhate speech‚Äù might occasionally fall into an existing 1st Amendment exception: a racist speech might seek to incite imminent violence against a group, or might be reasonably interpreted as an immediate threat to do harm‚Äù"
5958,@GaryMarcus,2022-02-08 00:55:00+00:00,https://twitter.com/GaryMarcus/status/1490851622804619265,"Wow, in suggesting that Joe Rogan should not have had a guest who actively advocated for violence, I really touched a nerve. ü§∑‚Äç‚ôÇÔ∏è"
5959,@GaryMarcus,2022-02-07 21:35:25+00:00,https://twitter.com/GaryMarcus/status/1490801398627254274,"‚ÄúMachine Values: Oxymoron or Moral Imperative?‚Äù

Make your argument here - and help me prepare my next talk :)

Reading suggestions most welcome!"
5960,@GaryMarcus,2022-02-07 19:48:51+00:00,https://twitter.com/GaryMarcus/status/1490774579807014915,"If you haven‚Äôt read Oliver Wendell Holmes, please don‚Äôt come to me about free speech. 

Every word of the below is still 100% relevant. https://t.co/ZZClhsXjIF"
5961,@GaryMarcus,2022-02-07 19:42:29+00:00,https://twitter.com/GaryMarcus/status/1490772974856638464,"@HappyAar @martin_dinov it‚Äôs not censorship, because we are talking about inciting of personal harm, and any reasonable free speech policy does not extent to the incitement of personal harm."
5962,@GaryMarcus,2022-02-07 19:41:45+00:00,https://twitter.com/GaryMarcus/status/1490772791896854536,"@martin_dinov no. read Oliver Wendell Holmes and learn whereof you speak.
eg
https://t.co/yKuglmuy0I"
5963,@GaryMarcus,2022-02-07 19:30:15+00:00,https://twitter.com/GaryMarcus/status/1490769898351448067,Why are we even still talking about this guy?
5964,@GaryMarcus,2022-02-07 16:23:09+00:00,https://twitter.com/GaryMarcus/status/1490722812297826304,@sanjanasinghx https://t.co/IoRhtBhT9s
5965,@GaryMarcus,2022-02-05 21:32:53+00:00,https://twitter.com/GaryMarcus/status/1490075983134687234,"@austinvhuang @rasbt that‚Äôs the argument i have been making for 30 years, and constantly vilified for. 

tide is definitely turning though"
5966,@GaryMarcus,2022-02-05 20:59:44+00:00,https://twitter.com/GaryMarcus/status/1490067643360899072,@sanjanasinghx ?
5967,@GaryMarcus,2022-02-05 20:57:28+00:00,https://twitter.com/GaryMarcus/status/1490067070570012674,"@austinvhuang @rasbt and yet symbol-manipulation still gets regularly derided for being unworkable, not biologically plausible, etc."
5968,@GaryMarcus,2022-02-05 20:01:38+00:00,https://twitter.com/GaryMarcus/status/1490053019970408448,". @billmaher if you're going to attack science, you need to read it.  
 
Science on outdoor transmission says it's 8-18x times safer, not 1,000x or 10,000x.  

JHU lockdown study you cited isn't even peer reviewed

&amp; cheap shot against Biden, since quote was pre Omicron discovery"
5969,@GaryMarcus,2022-02-05 19:36:54+00:00,https://twitter.com/GaryMarcus/status/1490046794893385729,@marktenenholtz @rasbt @swarat early but more promising than most altenatives
5970,@GaryMarcus,2022-02-05 19:32:37+00:00,https://twitter.com/GaryMarcus/status/1490045719524245504,@marktenenholtz @rasbt @swarat comes closer IMHO
5971,@GaryMarcus,2022-02-05 19:29:21+00:00,https://twitter.com/GaryMarcus/status/1490044897633521666,"ü§îReading @rasbt‚Äôs lucid #PyTorch tutorial I had this thought:

Why use symbol-manipulation at every step‚Äîpreparing, cleaning, augmenting, &amp; plotting data, constructing neural nets, etc‚Äî and then exclude same techniques of concatenation, compositionality, iteration, etc, from AI?"
5972,@GaryMarcus,2022-02-05 16:42:54+00:00,https://twitter.com/GaryMarcus/status/1490003008825876491,"@Andrea__M This doesn‚Äôt make sense to me, given the No Free Lunch theorem. 

Deep learning doesn‚Äôt work in an absolute sense; it works relative to certain assumptions, with certain architectures, and certain training regimes; it also frequently fails (though not all failures are published)."
5973,@GaryMarcus,2022-02-04 18:50:18+00:00,https://twitter.com/GaryMarcus/status/1489672679216930817,"Happy Orwell Day! 
https://t.co/lNOAGiITI5"
5974,@GaryMarcus,2022-02-04 17:34:26+00:00,https://twitter.com/GaryMarcus/status/1489653586803888131,"@sanjanasinghx my books Kluge, Birth of the Mind, and Rebooting AI all try to hit that philosophy and cognitive science intersection."
5975,@GaryMarcus,2022-02-04 15:39:58+00:00,https://twitter.com/GaryMarcus/status/1489624781993377794,"@s_r_constantin a limited trial in a narrow pre-mapped area without snow, late at night to avoid pedestrians, bikes, other vehicles etc, is a step, but there‚Äôs still a long, long way to go."
5976,@GaryMarcus,2022-02-04 15:18:49+00:00,https://twitter.com/GaryMarcus/status/1489619459807481857,@filippie509 no sweat!
5977,@GaryMarcus,2022-02-04 15:07:30+00:00,https://twitter.com/GaryMarcus/status/1489616611015200768,"@ethancaballero care to put money on it? not just for toy problems, and assistanance. but real apps, operating systems, and more?"
5978,@GaryMarcus,2022-02-03 21:14:27+00:00,https://twitter.com/GaryMarcus/status/1489346567442075649,"@kdkeck it‚Äôs not a microscandal to attack critics and unleash goons that issue death threats. 

there hundreds of things Musk does that i don‚Äôt comment on. 

i will to continue on comment on those tactics that deceive or move people to aggression."
5979,@GaryMarcus,2022-02-03 19:51:23+00:00,https://twitter.com/GaryMarcus/status/1489325665425920000,"@adamcrussell in this case, the work is fine; it‚Äôs the press that‚Äôs ridiculous"
5980,@GaryMarcus,2022-02-03 18:12:05+00:00,https://twitter.com/GaryMarcus/status/1489300674776944646,"@dervish_candela @Grady_Booch well, no. it‚Äôs what the designer wants the program to do, not the code"
5981,@GaryMarcus,2022-02-03 17:54:02+00:00,https://twitter.com/GaryMarcus/status/1489296131532079105,üòß @elonmusk‚Äôs attacks on reputable scientists and journalists are an abuse of power. his latest is dissected in this thread by @Tweetermeyer
5982,@GaryMarcus,2022-02-03 16:42:47+00:00,https://twitter.com/GaryMarcus/status/1489278200614031362,"For more, see this new discussion from Ernest Davis https://t.co/fCG0IhkdOR"
5983,@GaryMarcus,2022-02-03 16:41:39+00:00,https://twitter.com/GaryMarcus/status/1489277918647767043,@HappyAar nonlinear is ok. unpredictable is disconcerting.
5984,@GaryMarcus,2022-02-03 16:41:02+00:00,https://twitter.com/GaryMarcus/status/1489277759838822400,"More media nonsense. AI may increasingly support programming, but it's not one-stop shopping that would replace an actual human programmer anytime soon. 
We have no idea how to specify the intent of a software architect in enough detail to make that work. 
https://t.co/xvX1UzGHpe"
5985,@GaryMarcus,2022-02-03 12:03:06+00:00,https://twitter.com/GaryMarcus/status/1489207819412795392,interesting analysis: ‚ÄúElon Musk's 'science fiction': Top analyst calculates Tesla's true worth is just $138 a share - FORTUNE‚Äù https://t.co/FwKtyJJbI3
5986,@GaryMarcus,2022-02-03 00:13:19+00:00,https://twitter.com/GaryMarcus/status/1489029194675744771,@danbri @WiringTheBrain i just posted something related by @jfkominsky that is mildly related; I imagine he would be more current than I on this.
5987,@GaryMarcus,2022-02-02 22:44:11+00:00,https://twitter.com/GaryMarcus/status/1489006763206582274,@khademinori exactly the point i have been trying to make
5988,@GaryMarcus,2022-02-02 22:43:42+00:00,https://twitter.com/GaryMarcus/status/1489006642800648194,"now imagine the same kind of unexpected and inexplicable response, but in your 5‚Äô8‚Äù humanoid Optimus home robot. 

oops."
5989,@GaryMarcus,2022-02-02 22:29:32+00:00,https://twitter.com/GaryMarcus/status/1489003076753059840,‚ÄúTeslas are unexpectedly slamming on their brakes in response to imagined hazards ‚Äî such as oncoming traffic on two-lane roads ‚Äî which has prompted their terrified owners to lodge a surge of complaints‚Äù https://t.co/IOq1r9MIqL
5990,@GaryMarcus,2022-02-02 14:40:28+00:00,https://twitter.com/GaryMarcus/status/1488885033490599937,real world ethics question. good or bad idea? https://t.co/LuG61926B9
5991,@GaryMarcus,2022-02-02 14:30:42+00:00,https://twitter.com/GaryMarcus/status/1488882573040230400,@DrMJoyner @rickberke @EricLander46 @statnews @zakkohane https://t.co/ocILW6BjOd
5992,@GaryMarcus,2022-02-02 14:06:07+00:00,https://twitter.com/GaryMarcus/status/1488876387528101893,@martisamuser @MaxALittle @weidingerlaura @DeepMind I think you misread my sentence but I could have been clearer; I was saying that the LLM produces lies and fabrications. turns out the specific examples were only ‚Äúillustrative‚Äù but there are plenty of other examples out there that could have made the same point.
5993,@GaryMarcus,2022-02-02 14:03:47+00:00,https://twitter.com/GaryMarcus/status/1488875800451420163,"ü§¶‚Äç‚ôÇÔ∏è, I missed the most important line in the 64 page DeepMind review: the examples were fictitious. since I have seen similar examples I mistook them for real examples. 

I have accordingly deleted my tweet, but believe that the types of problems they raise are quite real."
5994,@GaryMarcus,2022-02-01 03:30:44+00:00,https://twitter.com/GaryMarcus/status/1488354100949372928,"Excellent postmortem on Zillow‚Äôs AI fiasco, by ‚Å¶‚Å¶‚Å¶@etzioni‚Å©  https://t.co/WiSY8zmZF7"
5995,@GaryMarcus,2022-01-31 18:15:46+00:00,https://twitter.com/GaryMarcus/status/1488214439698604032,"even in infancy, causality is not a single homogenous thing. insightful new baby studies that should be of interest to the AI community. 

cc: @yudapearl"
5996,@GaryMarcus,2022-01-31 13:32:37+00:00,https://twitter.com/GaryMarcus/status/1488143182114144258,"@wintermoat @lizadixon no indication that it recognizes this as a large or abnormal or funny cheeseburger. you found a meme  in which you can count a naive identification of the largest object ass ‚Äú‚Äúthe meme‚Äù, not a meme that the network actually groks."
5997,@GaryMarcus,2022-01-31 01:18:45+00:00,https://twitter.com/GaryMarcus/status/1487958497866092544,"@nicholdav @tristanbergh @timnitGebru @Abebab @cloudquistador or, more likely, we will have autonomous weapons that lack such algorithms, and probably sooner rather than later."
5998,@GaryMarcus,2022-01-31 01:16:52+00:00,https://twitter.com/GaryMarcus/status/1487958024597630976,"@NM_Wilkinson @elmobronowski Of course I am also interested in foreseeable work, and mean to generate interest in the problem‚Ä¶"
5999,@GaryMarcus,2022-01-31 00:32:11+00:00,https://twitter.com/GaryMarcus/status/1487946778477416450,@vineettiruvadi @WiringTheBrain if you count ‚Äúmimic past data‚Äù as a value.
6000,@GaryMarcus,2022-01-30 23:22:53+00:00,https://twitter.com/GaryMarcus/status/1487929338523652101,"@vineettiruvadi @WiringTheBrain it's s subtle question, but eg. Amazon spent years trying to build a nondiscriminatory job hiring algorithm, but couldn't figure out how to get the algorithm to match their values. Instead the systems would always perpetuate past biases that the coders want to avoid."
6001,@GaryMarcus,2022-01-30 23:19:45+00:00,https://twitter.com/GaryMarcus/status/1487928552498421762,"I don't think anybody has an idea how you would *train* any current AI architecture how to behave ethically, so I think is important to think about alternatives that explicitly encompass values."
6002,@GaryMarcus,2022-01-30 19:58:34+00:00,https://twitter.com/GaryMarcus/status/1487877922304135168,"@Abel_TorresM right, but how?"
6003,@GaryMarcus,2022-01-30 18:02:18+00:00,https://twitter.com/GaryMarcus/status/1487848660163465216,@tristanbergh @timnitGebru i am not aware of any specific computational/algorithmic proposal of hers that would do what is described but please link anything relevant
6004,@GaryMarcus,2022-01-30 17:36:23+00:00,https://twitter.com/GaryMarcus/status/1487842138192637952,"üôè Hive Mind, is there any existing work on AI ethics that comes close to what I am calling for below?"
6005,@GaryMarcus,2022-01-30 14:48:56+00:00,https://twitter.com/GaryMarcus/status/1487799999429693442,@eschneider see my book Kluge if you want to know my thoughts on humans
6006,@GaryMarcus,2022-01-29 22:04:25+00:00,https://twitter.com/GaryMarcus/status/1487547202893344769,"Bullshit. Thinking that Joe Rogan doesn‚Äôt really spread misinformation? That he‚Äôs got a bad rap? That nobody ever actually laid out that case? 

Start here: https://t.co/ivgv2BCwiV

I‚Äôll be listening to Neil and Joni tonight."
6007,@GaryMarcus,2022-01-29 19:56:21+00:00,https://twitter.com/GaryMarcus/status/1487514976377995265,@nanowellbeing it‚Äôs from the latest paper from OpenAI: https://t.co/t4MKJwstlp
6008,@GaryMarcus,2022-01-29 19:33:03+00:00,https://twitter.com/GaryMarcus/status/1487509110773796864,@DavidBeniaguev @mikilon @Segev_Lab @YiotaPoirazi ICYMI
6009,@GaryMarcus,2022-01-29 19:30:29+00:00,https://twitter.com/GaryMarcus/status/1487508466180624384,@DavidBeniaguev @sapir_shap @mikilon @Segev_Lab Very cool!
6010,@GaryMarcus,2022-01-29 18:32:59+00:00,https://twitter.com/GaryMarcus/status/1487493993990483968,@BradenTierney ü§£üòÇü§£üòÇ
6011,@GaryMarcus,2022-01-29 18:25:25+00:00,https://twitter.com/GaryMarcus/status/1487492090917388290,"Why is it important to eat socks after meditating? 

GPT-3 is hilarious, but, um, ‚Ä¶ 72 years after The Turing Test, and we are still in a heap of trouble: https://t.co/nBuiSyvmhW"
6012,@GaryMarcus,2022-01-27 05:52:54+00:00,https://twitter.com/GaryMarcus/status/1486577940087271428,@peacemaker991 @Bob_Wachter +1 to @peacemaker991‚Äôs suggestion that the CA pattern might be an artifact of averaging over different jurisdictions with different onsets
6013,@GaryMarcus,2022-01-26 20:17:38+00:00,https://twitter.com/GaryMarcus/status/1486433168748019714,"@chrmanning @irinarish @tdietterich interesting! but tracking correlates ‚â† capturing explanation

paper lacks a serious assessment of competing accounts in terms of attention, semantics etc (eg https://t.co/ztKDysEv3H)

could well be that the ML picks up on trends in the data that are driven by cognitive factors"
6014,@GaryMarcus,2022-01-26 19:03:58+00:00,https://twitter.com/GaryMarcus/status/1486414630196957185,@fernandaedi congratulations!!
6015,@GaryMarcus,2022-01-25 22:17:28+00:00,https://twitter.com/GaryMarcus/status/1486100938888601606,"@irinarish because there already exist some data contradicting your claim and more will come. 

your claim 2 is also problematic re some existing data that i have posted about"
6016,@GaryMarcus,2022-01-25 22:14:19+00:00,https://twitter.com/GaryMarcus/status/1486100143304634368,@irinarish want to place a bet on that?
6017,@GaryMarcus,2022-01-25 21:03:18+00:00,https://twitter.com/GaryMarcus/status/1486082273984217088,@irinarish @ethancaballero @tdietterich if you think these problems are already solved or are trivially solved i suggest you read the literature more carefully.
6018,@GaryMarcus,2022-01-25 19:38:56+00:00,https://twitter.com/GaryMarcus/status/1486061042702581763,"@irinarish @tdietterich there has been progress on grammatical fluency, but not on truth or cumulative cognitive models"
6019,@GaryMarcus,2022-01-25 19:37:57+00:00,https://twitter.com/GaryMarcus/status/1486060794622066689,"@irinarish @ethancaballero @tdietterich Math is not one-size-fits all; such reductionism predicts &amp; proves nothing. e.g., Math alone predicts little about nature of human natural semantics or compositionality; the math of scaling has not thus far explained how to solve ML's challenges with out-of-domain generalization"
6020,@GaryMarcus,2022-01-25 17:02:43+00:00,https://twitter.com/GaryMarcus/status/1486021727259807744,"@schulzb589 yes, will be interesting to see how this goes."
6021,@GaryMarcus,2022-01-25 15:37:26+00:00,https://twitter.com/GaryMarcus/status/1486000265908129799,"Beware graphs alleging current deep learning techniques will soon outperform humans ‚Äúat most‚Ä¶work‚Äù

It‚Äôs flawed to assume that
üëâ increases in performance won‚Äôt saturate
üëâ all tasks will follow same trends
üëâ success on current AI benchmarks will translate into actual work"
6022,@GaryMarcus,2022-01-25 14:51:41+00:00,https://twitter.com/GaryMarcus/status/1485988753579679752,"@ethancaballero @tdietterich @irinarish all math and no cognition  

and zero engagement with recent literature showing signs of saturation"
6023,@GaryMarcus,2022-01-25 01:12:35+00:00,https://twitter.com/GaryMarcus/status/1485782619446861824,it is a spectacular testament to the inadequacy of the current regime that any of the below even needs be said.
6024,@GaryMarcus,2022-01-24 22:50:00+00:00,https://twitter.com/GaryMarcus/status/1485746735603339266,"@HappyAar @carlzimmer there are also some physical independence questions. it‚Äôs not that hard to figure out up to those limits, it‚Äôs just a very rare coincidence"
6025,@GaryMarcus,2022-01-24 22:01:52+00:00,https://twitter.com/GaryMarcus/status/1485734624651202562,"This @CarlZimmer essay on origins of Omicron gave me chills

Premise is that radical virus came into being only when a stunning accident of many rare mutations occurred simultaneously

I have long thought that humans‚Äîno less dramatic‚Äîcame about in same way https://t.co/z2PA74vHKy"
6026,@GaryMarcus,2022-01-24 21:50:00+00:00,https://twitter.com/GaryMarcus/status/1485731636293472257,"@TheShoeLady33 humans might similarly be the result of a bunch of unlikely mutations happening at the same time, with no less effect on the planet."
6027,@GaryMarcus,2022-01-24 19:31:40+00:00,https://twitter.com/GaryMarcus/status/1485696822865641474,"@jackclarkSF @FLIxrisk +1000 for all efforts towards a positive, aspirational future for strong AI."
6028,@GaryMarcus,2022-01-24 15:59:41+00:00,https://twitter.com/GaryMarcus/status/1485643476775538688,"@irinarish AlphaFold2 is a clear counterexample; it wouldn‚Äôt work without detailed domain engineered representations, even with massive data."
6029,@GaryMarcus,2022-01-24 14:22:08+00:00,https://twitter.com/GaryMarcus/status/1485618926809583616,"Win $ and help design the future world! What could a ‚Äúplausible, aspirational future that includes strong artificial intelligence‚Äù look like? 

Terrific contest sponsored by ‚Å¶@FLIxrisk‚Å©; h/t ‚Å¶@jackclarkSF‚Å©  https://t.co/N1YGMuvNYb"
6030,@GaryMarcus,2022-01-24 13:47:31+00:00,https://twitter.com/GaryMarcus/status/1485610217039564802,"@Durbangash we should not give up on medical AI, but will need much better integration of learning and abstract knowledge"
6031,@GaryMarcus,2022-01-24 13:45:31+00:00,https://twitter.com/GaryMarcus/status/1485609711441362946,"@anumsarmadmalik no current AI is up the job, &amp; IBM oversold what they had"
6032,@GaryMarcus,2022-01-24 06:07:48+00:00,https://twitter.com/GaryMarcus/status/1485494525069955075,"@irinarish you‚Äôre joking, right? you don‚Äôt really think scale alone is going to solve AGI, do you?"
6033,@GaryMarcus,2022-01-24 01:43:32+00:00,https://twitter.com/GaryMarcus/status/1485428021368549377,"@pmddomingos @ShunryuGarvey one of the first reports on the latter, April 2013: https://t.co/qX48NkOPyd"
6034,@GaryMarcus,2022-01-23 21:31:22+00:00,https://twitter.com/GaryMarcus/status/1485364558361358336,"Anyone who reads this feed will know how much I love British Columbia, but why why why do we have the worst public health policy in all of Canada?

@jjhorgan, neither history nor science will be kind to you."
6035,@GaryMarcus,2022-01-23 21:27:46+00:00,https://twitter.com/GaryMarcus/status/1485363654996365313,@schubertcarvalh precisely the bottom line of Rebooting AI
6036,@GaryMarcus,2022-01-23 15:26:21+00:00,https://twitter.com/GaryMarcus/status/1485272699295334402,@khademinori see the section in my next decade arxiv
6037,@GaryMarcus,2022-01-23 15:25:52+00:00,https://twitter.com/GaryMarcus/status/1485272577220100096,@wayneholmes please elaborate (here or by DM)
6038,@GaryMarcus,2022-01-23 14:39:00+00:00,https://twitter.com/GaryMarcus/status/1485260784703705091,"Great question. What I wrote in The Next Decade is that neurosymbolic approaches are necessary but neither sufficient nor fully developed, and that rich cognitive models are also required. Fom what I have seen Watson lacked those, which in turn limited its capacity for inference."
6039,@GaryMarcus,2022-01-23 03:11:16+00:00,https://twitter.com/GaryMarcus/status/1485087711455105025,@DrMJoyner am also not surprised‚Ä¶
6040,@GaryMarcus,2022-01-23 02:47:47+00:00,https://twitter.com/GaryMarcus/status/1485081798908334082,‚Äúthe staggering collapse of its ambitious artificial intelligence effort that failed to live up to its promises to transform everything from drug discovery to cancer care.‚Äù https://t.co/WmqcvNMugt
6041,@GaryMarcus,2022-01-22 21:44:50+00:00,https://twitter.com/GaryMarcus/status/1485005561171218434,"an hour east of Vancouver

 (city visible in the distance if you zoom in) https://t.co/ucRqxIa3jJ"
6042,@GaryMarcus,2022-01-22 04:32:42+00:00,https://twitter.com/GaryMarcus/status/1484745817982263300,Insanity.
6043,@GaryMarcus,2022-01-20 04:46:43+00:00,https://twitter.com/GaryMarcus/status/1484024567567826949,no words.
6044,@GaryMarcus,2022-01-20 04:35:58+00:00,https://twitter.com/GaryMarcus/status/1484021862203936769,"@sanjanasinghx Ha ha. So far, as far I can tell, Optimus is someone dancing around in a costume."
6045,@GaryMarcus,2022-01-20 04:30:45+00:00,https://twitter.com/GaryMarcus/status/1484020549495836675,@sandyasm get well soon!
6046,@GaryMarcus,2022-01-19 15:55:38+00:00,https://twitter.com/GaryMarcus/status/1483830520236494849,"Even so, @vkhosla, please don't take your hands off the wheel or your eyes off the road."
6047,@GaryMarcus,2022-01-19 14:57:07+00:00,https://twitter.com/GaryMarcus/status/1483815792055439361,@chaloelikesthis @itsdrenthe Tesla is long on hype and short on taking responsibility.
6048,@GaryMarcus,2022-01-18 23:11:13+00:00,https://twitter.com/GaryMarcus/status/1483577748048154626,"@lizadixon so sorry to hear it, Liza."
6049,@GaryMarcus,2022-01-16 19:38:06+00:00,https://twitter.com/GaryMarcus/status/1482799340905058304,@tdverstynen when bitcoin isn‚Äôt enough
6050,@GaryMarcus,2022-01-16 19:32:32+00:00,https://twitter.com/GaryMarcus/status/1482797937977544705,the credit default swaps of 2022
6051,@GaryMarcus,2022-01-15 15:23:13+00:00,https://twitter.com/GaryMarcus/status/1482372808315338757,@joedotfaith @tomgoldsteincs thanks!
6052,@GaryMarcus,2022-01-14 02:52:59+00:00,https://twitter.com/GaryMarcus/status/1481821618699526145,‚ù§Ô∏è BC https://t.co/HUFke9uDih
6053,@GaryMarcus,2022-01-13 01:36:55+00:00,https://twitter.com/GaryMarcus/status/1481440087242014721,"GPT-3 powered Rytr‚Äôs truthfulness pprblem: ‚Äúthe more technical the content ‚Ä¶ the greater the risk that the text the AI produces will contain statements that are flat-out wrong. While its grammar is solid, its facts aren‚Äôt as reliable‚Äù https://t.co/ls6pyYBmiR"
6054,@GaryMarcus,2022-01-12 01:47:17+00:00,https://twitter.com/GaryMarcus/status/1481080308779069446,"Is there such a thing as an ""illusion of progress bar?"""
6055,@GaryMarcus,2022-01-12 01:01:38+00:00,https://twitter.com/GaryMarcus/status/1481068822484627458,"@ruchowdh it's been hard, no question. I spent the first 9 days of the year struggling with the many ways in which '22 thus far resembles '21.  I am just now finally finding my footing

YMMV but for me some calls reconnecting with old friends that I lost touch with has helped, tremendously"
6056,@GaryMarcus,2022-01-11 14:45:24+00:00,https://twitter.com/GaryMarcus/status/1480913742711844865,"bravo! ""spew"" is the perfect verb."
6057,@GaryMarcus,2022-01-11 02:51:35+00:00,https://twitter.com/GaryMarcus/status/1480734101086748676,"Everything you always wanted to know about the Winograd Scheme Challenge but were afraid to ask. 

LLMs have beaten it, yet common sense remains unsolved... 

New paper in Arxiv by Kocijan, Davis, Lukasiewicz, Morgenstern and myself. https://t.co/8HYGT8lYaH"
6058,@GaryMarcus,2022-01-10 18:44:56+00:00,https://twitter.com/GaryMarcus/status/1480611632459890691,@uzves_tiriato i just read up on it a few minutes ago :) and you can try 'em all here: https://t.co/r3pmCSuFkk
6059,@GaryMarcus,2022-01-10 18:21:57+00:00,https://twitter.com/GaryMarcus/status/1480605851366801408,@Pseudomanifold cool! and see also: https://t.co/DiVEj2TyOZ
6060,@GaryMarcus,2022-01-10 17:56:26+00:00,https://twitter.com/GaryMarcus/status/1480599427400101888,"Brainfuck, a programming language for the COVID era, when everything is harder than it needs to be ...  https://t.co/ae0Oc3xuEq"
6061,@GaryMarcus,2022-01-08 21:20:51+00:00,https://twitter.com/GaryMarcus/status/1479926093322674177,"Howe Sound, How Beautiful
Winter Hiking in BC https://t.co/l5S7CJhEZ9"
6062,@GaryMarcus,2022-01-08 05:32:58+00:00,https://twitter.com/GaryMarcus/status/1479687551858315266,@filippie509 @sd_marlow @lizadixon
6063,@GaryMarcus,2022-01-08 05:27:16+00:00,https://twitter.com/GaryMarcus/status/1479686118270406656,@ethancaballero ü§£
6064,@GaryMarcus,2022-01-08 01:49:22+00:00,https://twitter.com/GaryMarcus/status/1479631283512766466,ü§£
6065,@GaryMarcus,2022-01-07 15:02:31+00:00,https://twitter.com/GaryMarcus/status/1479468498606649349,"üîë challenge for AI right now:  ‚Äúfind a good way of combining all the world‚Äôs immense knowledge of science and technology [with] deep learning, [which can‚Äôt yet] leverage all that knowledge and instead is stuck again and again trying to learn everything from scratch‚Äù Marcus said"
6066,@GaryMarcus,2022-01-06 02:50:57+00:00,https://twitter.com/GaryMarcus/status/1478922002790453250,@yudapearl @tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat the relevant symbols (if any) are of course something that is determined by the situation/task.
6067,@GaryMarcus,2022-01-06 01:19:44+00:00,https://twitter.com/GaryMarcus/status/1478899048199249921,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat finding the right symbols with which to describe a situation is a key unsolved problem, IMHO"
6068,@GaryMarcus,2022-01-06 01:18:35+00:00,https://twitter.com/GaryMarcus/status/1478898759656345600,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat yes, it's mostly beyond argument now but I was treated hostilely for nearly two decades for saying them, &amp; even now people like Hinton continue to ridicule symbols."
6069,@GaryMarcus,2022-01-06 00:50:30+00:00,https://twitter.com/GaryMarcus/status/1478891690232463360,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat human infants don't have language,  but they can learn abstract rules, as I showed in 1999, experimentally (since replicated several times):

https://t.co/kaRKz6SIHS"
6070,@GaryMarcus,2022-01-06 00:49:32+00:00,https://twitter.com/GaryMarcus/status/1478891447101186048,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat My opening bid =the inventory I proposed in The Algebraic Mind:

üëâ symbols
üëâ variables
üëâ operations over variables
üëâ structured representations
üëâ a distinction between types &amp; tokens

20 years later I still haven't seen a serious counterargument to those minimal requirements"
6071,@GaryMarcus,2022-01-06 00:44:20+00:00,https://twitter.com/GaryMarcus/status/1478890139073929216,@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat for human cognition: yes we need at least some subset of that
6072,@GaryMarcus,2022-01-06 00:42:51+00:00,https://twitter.com/GaryMarcus/status/1478889766389096450,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat i dunno. we can recognize images after all kinds of filter transformations. in interpreting a typical line drawing, i don‚Äôt think low level sensory perception is the real issue"
6073,@GaryMarcus,2022-01-06 00:40:34+00:00,https://twitter.com/GaryMarcus/status/1478889191383601156,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat who or what is this directed at? for sure we can do some low level sensory perception without language, as is clear from animals, human infants, etc.

but you can have symbolic representations without language"
6074,@GaryMarcus,2022-01-06 00:38:01+00:00,https://twitter.com/GaryMarcus/status/1478888550095417344,@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat we do need world models for scene perception
6075,@GaryMarcus,2022-01-06 00:37:04+00:00,https://twitter.com/GaryMarcus/status/1478888312727244804,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @swarat who said we do for lowest level sensory knowledge? 

then again, the retina has 70+ different kinds of neurons and maybe there are lessons to be learned from that‚Ä¶"
6076,@GaryMarcus,2022-01-06 00:32:09+00:00,https://twitter.com/GaryMarcus/status/1478887073276854272,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg also, saying that gradients will play a role is not the same as saying that are universal solvent that will be ubiquitious, with no room for other types of statistical computation.

&amp; we are a long way from being able to properly leverage structured representations in neural nets"
6077,@GaryMarcus,2022-01-06 00:29:54+00:00,https://twitter.com/GaryMarcus/status/1478886506227855361,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg Well, no.
1. We have not even scratched the surface of architectural choices, especially wrt more structured models that might eg incorporate an element of programming a la @swarat's recent review.
2. I strongly believe we need to leverage existing knowledge far more than we do."
6078,@GaryMarcus,2022-01-05 23:44:43+00:00,https://twitter.com/GaryMarcus/status/1478875136312819715,"@tejasdkulkarni @ylecun @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg That's all I have been calling for, since 2001; the whole point of The Algebraic Mind was to call for the development of architectures exactly like that."
6079,@GaryMarcus,2022-01-05 23:09:39+00:00,https://twitter.com/GaryMarcus/status/1478866310796746752,"@ylecun @tejasdkulkarni @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg &amp; as I have said repeatedly, the challenge is to bring together symbolic operations (like copy, compare, etc) and symbolic knowledge with learning systems :)  

gradient-based learning surely will play some role.

our biggest differences are on what ought to be innate."
6080,@GaryMarcus,2022-01-05 22:28:43+00:00,https://twitter.com/GaryMarcus/status/1478856010919931904,"@tejasdkulkarni @_WEEXIAO @Vlad_S @drfeifei @yudapearl @neurobongo @TimKietzmann @demishassabis @sama @ilyasut @koraykv @AndrewYNg @ylecun I also emphasized the critical need for world models in my Next Decade in AI arxiv; it‚Äôs one point that LeCun and I agree on. Although I think symbolic representations have a critical role to play there, and he may not."
6081,@GaryMarcus,2022-01-05 21:13:05+00:00,https://twitter.com/GaryMarcus/status/1478836978481184768,"General Motors pulls a Musk, and overpromises. https://t.co/69X2LTpES6"
6082,@GaryMarcus,2022-01-05 20:21:59+00:00,https://twitter.com/GaryMarcus/status/1478824119181275136,"@Horganism @DrBonnieHenry oops wrong Horgan, sorry!"
6083,@GaryMarcus,2022-01-05 03:51:16+00:00,https://twitter.com/GaryMarcus/status/1478574797122465792,Brilliant set by @bscomedian.
6084,@GaryMarcus,2022-01-05 02:48:18+00:00,https://twitter.com/GaryMarcus/status/1478558947648819201,"BC's wildly overrated public health officer is basically giving up.

@dexamethasones called it, with this new song: https://t.co/vcEc2QqLDk

cc: @DrEricDing  cc: @BabaBrinkman"
6085,@GaryMarcus,2022-01-05 01:28:46+00:00,https://twitter.com/GaryMarcus/status/1478538935085133825,https://t.co/Oi3eEbBtjk
6086,@GaryMarcus,2022-01-04 15:31:35+00:00,https://twitter.com/GaryMarcus/status/1478388647166627847,@MishiChoudhary hope you feel better soon!
6087,@GaryMarcus,2022-01-04 15:09:44+00:00,https://twitter.com/GaryMarcus/status/1478383149369462789,@yoavgo @RealBeatlesUke
6088,@GaryMarcus,2022-01-04 15:09:23+00:00,https://twitter.com/GaryMarcus/status/1478383059250651138,"Fluent, confident and utterly confused. Great example."
6089,@GaryMarcus,2022-01-04 05:08:33+00:00,https://twitter.com/GaryMarcus/status/1478231857841901568,"@sanjanasinghx It is rough going, but AI researchers would do well to read it."
6090,@GaryMarcus,2022-01-03 15:37:16+00:00,https://twitter.com/GaryMarcus/status/1478027688585547781,"and what, pray tell, are the other 38% thinking?"
6091,@GaryMarcus,2022-01-01 22:34:24+00:00,https://twitter.com/GaryMarcus/status/1477407889312550913,"There is a tremendous difference between ""less severe"" and ""less likely"" to be severe.  This is a terrific thread by @math_rachel.

@nxthompson please consider this for The Atlantic"
6092,@GaryMarcus,2022-01-01 16:45:57+00:00,https://twitter.com/GaryMarcus/status/1477320199980261376,"Happy New Year! 

I ‚ù§Ô∏è Vancouver https://t.co/nVWJWSiBdf"
6093,@GaryMarcus,2021-12-30 13:26:05+00:00,https://twitter.com/GaryMarcus/status/1476545127715946500,"@maxcoltheart @bobehayes @amazon if those are our choices, we are &lt;expletive deleted&gt;"
6094,@GaryMarcus,2021-12-29 22:08:37+00:00,https://twitter.com/GaryMarcus/status/1476314236196425735,Game on!
6095,@GaryMarcus,2021-12-29 16:40:49+00:00,https://twitter.com/GaryMarcus/status/1476231742147158023,@neilturkewitz exactly what we said in Rebooting AI
6096,@GaryMarcus,2021-12-29 15:14:30+00:00,https://twitter.com/GaryMarcus/status/1476210020924772356,"""No current AI is remotely close to understanding the everyday physical or psychological world,‚Äù Marcus told ‚Å¶@CNBC‚Å© ‚ÄúWhat we have now is an approximation to intelligence, not the real thing, and as such it will never really be trustworthy."" https://t.co/OltDWhhVQz"
6097,@GaryMarcus,2021-12-29 12:57:46+00:00,https://twitter.com/GaryMarcus/status/1476175610800181248,"yep this @alexa fiasco is a reminder that these systems are long way from understanding basic linguistic like negation‚Äîa ‚Äúknown issue‚Äù that becomes more and more urgent as we accord more power to clueless statistical approximators.

cc @AllysonEttinger"
6098,@GaryMarcus,2021-12-28 23:30:31+00:00,https://twitter.com/GaryMarcus/status/1475972461166538753,"FFS! ""Alexa tells 10-year-old girl to touch live plug with penny""

üò± üò± üò± üò± üò± üò± üò± 

#commonsense is still 
seriously lacking in AI 
           in 2021 https://t.co/NO3PyrVvPr"
6099,@GaryMarcus,2021-12-28 14:11:27+00:00,https://twitter.com/GaryMarcus/status/1475831768242601986,"@jasonintrator it‚Äôs important goes well beyond philosophy; so much of interhuman squabble and failed communication rests on presuppositional failure‚Ä¶ (great literature, too)"
6100,@GaryMarcus,2021-12-28 00:42:27+00:00,https://twitter.com/GaryMarcus/status/1475628175329832972,@vurnt22 @Shaolinfilms happy anniversary!
6101,@GaryMarcus,2021-12-26 23:43:15+00:00,https://twitter.com/GaryMarcus/status/1475250888939696128,"@vrandezo compare with this which is less pretty but actually teaches the beginner something real about the taxonomy of different architectures, and how they relate:"
6102,@GaryMarcus,2021-12-26 23:38:52+00:00,https://twitter.com/GaryMarcus/status/1475249785900867591,@artydea @PMinervini still problematic but immensely better
6103,@GaryMarcus,2021-12-26 21:00:58+00:00,https://twitter.com/GaryMarcus/status/1475210048934711300,"@vrandezo üëâdiagram gives false sense of understanding
üëânetworks that work in differently are portrayed graphically as if they function similarly
üëâfuzzes distinctions between SVMs, Markov Chains, neural networks
üëâobscures what actually distinguishes architectures
üëâmisleading colors"
6104,@GaryMarcus,2021-12-26 20:05:07+00:00,https://twitter.com/GaryMarcus/status/1475195996023971840,"Hey @pmdomingos, here's your master algorithm, all color-coded and ready for use. AGI has been solved! ü§£"
6105,@GaryMarcus,2021-12-24 07:18:49+00:00,https://twitter.com/GaryMarcus/status/1474278373912371240,"It‚Äôs nice to see someone so deserving finally get the recognition she deserves. 

Anyone with any doubts can watch the video for a sampling of her greatest hits."
6106,@GaryMarcus,2021-12-23 20:00:31+00:00,https://twitter.com/GaryMarcus/status/1474107673130024962,"Good thread (and review) on neurosymbolic programming, very much in line with The Algebraic Mind, which I hope will get the attention it deserves."
6107,@GaryMarcus,2021-12-22 19:49:18+00:00,https://twitter.com/GaryMarcus/status/1473742461105287174,@PaulJBlazek exactly
6108,@GaryMarcus,2021-12-22 17:52:19+00:00,https://twitter.com/GaryMarcus/status/1473713024464822277,"with due respect, nobody, least of all me, is calling for AI  to be a straight replication of biology

we are calling for a respect for what nature has to teach us, and for humility in accepting what we have not yet discovered

as the Wright Brothers knew: https://t.co/hyizJPnbkG"
6109,@GaryMarcus,2021-12-22 13:14:28+00:00,https://twitter.com/GaryMarcus/status/1473643101055070208,üíØagree: a serious mistake &amp; the height of arrogance
6110,@GaryMarcus,2021-12-20 18:49:37+00:00,https://twitter.com/GaryMarcus/status/1473002666859114496,"@IntuitMachine @TonyZador @ylecun as noted elsewhere in thread, all known systems have symbols, but not all leverage operations over variables. the failure of  transformers to eg generalize math far beyond a space of training examples is instructive."
6111,@GaryMarcus,2021-12-20 17:51:02+00:00,https://twitter.com/GaryMarcus/status/1472987922332798978,@StevenQuartz @KennethHayworth @TonyZador @WiringTheBrain @ylecun some of both. https://t.co/t9ZiiKcOjb
6112,@GaryMarcus,2021-12-20 17:49:19+00:00,https://twitter.com/GaryMarcus/status/1472987490558660614,@WiringTheBrain @TonyZador @ylecun only some. which part of why i have for so long been a firm believer in hybrid architectures. it‚Äôs all about having the right tools for many different jobs
6113,@GaryMarcus,2021-12-20 17:29:03+00:00,https://twitter.com/GaryMarcus/status/1472982392856055808,"@KennethHayworth @TonyZador @WiringTheBrain @ylecun that would take us a long way. you need some structure data structures too. and probably some representations of space, time. causality, and object"
6114,@GaryMarcus,2021-12-20 17:24:57+00:00,https://twitter.com/GaryMarcus/status/1472981360637841411,@KennethHayworth @TonyZador @WiringTheBrain @ylecun and quite possible even for bee-level intelligence.
6115,@GaryMarcus,2021-12-20 17:09:23+00:00,https://twitter.com/GaryMarcus/status/1472977441698332675,@StevenQuartz @WiringTheBrain @TonyZador @ylecun glad someone around here remembers the history :)
6116,@GaryMarcus,2021-12-20 16:52:01+00:00,https://twitter.com/GaryMarcus/status/1472973071690739722,"@TonyZador @WiringTheBrain @ylecun yes it‚Äôs 100% about having the right architecture; the point of The Algebraic Mind book was to ask what are the absolute minimal requirements on having the right architecture. 

20 years and billions of $ of R&amp;D later I stand by the claims I made then about minimal necessity."
6117,@GaryMarcus,2021-12-20 16:45:57+00:00,https://twitter.com/GaryMarcus/status/1472971543957360642,"@WiringTheBrain @TonyZador @ylecun Think about what you do with algebraic equation or function in a programming language. You have a set of steps that apply to instances of variables; the program or equation is the operation over variables.

You can apply that operation to any instance, regardless of similarity."
6118,@GaryMarcus,2021-12-20 16:31:26+00:00,https://twitter.com/GaryMarcus/status/1472967893969219592,"@TonyZador @ylecun 1. I don‚Äôt think it is inpossible; I think that certain architectures aren‚Äôt well suited. 

2. please read the chapter on Variables in The Algebraic Mind, and the notion of training independence, which has correctly anticipated much of what has happened for last two decades."
6119,@GaryMarcus,2021-12-20 16:29:17+00:00,https://twitter.com/GaryMarcus/status/1472967351381499908,"@andregraubner @ylecun @Montreal_AI @WorldSummitAI @AvilaGarcez and @luislamb‚Äôs work and refs in recent review; refs in ny Next Decade in AI arxiv; @PMinervini, Josh Tenenbaum‚Äôs lab, @GadiSinger‚Äôs lab at Intel, @neurobongo, @AnimaAnandkumar and many others."
6120,@GaryMarcus,2021-12-20 16:26:09+00:00,https://twitter.com/GaryMarcus/status/1472966560847478792,"@WiringTheBrain @TonyZador @ylecun *every* system I know has symbols, which are just bits/nodes that represent equivalence classes. 

real distinction is about representing &amp; manipulating operation over variables‚Äîcentral to hybrid systems &amp; programming but absent in many neural nets

The Algebraic Mind elaborates."
6121,@GaryMarcus,2021-12-20 16:08:10+00:00,https://twitter.com/GaryMarcus/status/1472962034849435657,"Fun, still evolving thread on symbols, neural networks, and animal cognition w @ylecun.

@ylecun please join us to discuss further, at #AIDebate3 in Montreal, May 4, w @Montreal_AI and @WorldSummitAI"
6122,@GaryMarcus,2021-12-20 16:04:59+00:00,https://twitter.com/GaryMarcus/status/1472961236669247493,"@TonyZador @ylecun current ANNs have little to do w brains. brains are vastly more structured &amp; far less uniform than ANNs, with far more innate structure.
 
in the limit (eg mathematics, programming, &amp; logic) we know that brains can make use of symbols. 

only serious question is about their scope"
6123,@GaryMarcus,2021-12-20 15:53:24+00:00,https://twitter.com/GaryMarcus/status/1472958320390594568,"@ylecun @JoinAndrewNow my view on this is spelled out at great length in The Algebraic Mind, differentiating discussion of symbols per se (which are ubiquitous even in deep learning) from key related concepts: operations over variables, structured representations, and type/token distinctions."
6124,@GaryMarcus,2021-12-20 15:51:09+00:00,https://twitter.com/GaryMarcus/status/1472957754759421953,"Work by @LakeBrenden and others shows that current architectures still face challenges  in extrapolation along precise lines I suggested.

Stunning #Nethack2021 symbolic upset over deep learning confirms what you already know: dismissing technology prematurely is risky business."
6125,@GaryMarcus,2021-12-20 15:51:09+00:00,https://twitter.com/GaryMarcus/status/1472957753350135816,"@ylecun I wrote an entire book on this, in 2001 (The Algebraic Mind); so far its predictions have held true. 

Trainable deep networks accumulate statistics between features; they don‚Äôt induce operations over variables or structured representations, they approximate them. 1/2"
6126,@GaryMarcus,2021-12-20 15:02:08+00:00,https://twitter.com/GaryMarcus/status/1472945418380136450,"Good and evil: ethics and fairness in AI, who makes the rules? @AnjaKasp of @carnegiecouncil asks tough questions @CERN: 

https://t.co/KgQ0ZCDiaP"
6127,@GaryMarcus,2021-12-20 01:46:04+00:00,https://twitter.com/GaryMarcus/status/1472745080398266368,@ylecun why assume that dogs can't manipulate symbols?
6128,@GaryMarcus,2021-12-20 01:19:04+00:00,https://twitter.com/GaryMarcus/status/1472738286318026753,@michael_byers true to her unscientific form.
6129,@GaryMarcus,2021-12-19 21:12:05+00:00,https://twitter.com/GaryMarcus/status/1472676131304316939,"@tdietterich A prediction I have heard every year for the last 20 years. I predict I will hear the prediction again, in 5 years."
6130,@GaryMarcus,2021-12-19 21:06:19+00:00,https://twitter.com/GaryMarcus/status/1472674679752167426,"It's not all about the data. Agreed that ""the representations learned by current LLMs are‚Ä¶inadequate for‚Ä¶deeper understanding""‚Äîbut the deeper problem, per The Algebraic Mind, remains lack of adequate substrate for structured representations, individuals &amp; abstract variables."
6131,@GaryMarcus,2021-12-19 18:40:29+00:00,https://twitter.com/GaryMarcus/status/1472637980133236739,"yes. but a third question is even more important: how can we wean ourselves from reliance on scaling and towards deeper representational systems, allowing us to better reason about and leverage existing knowledge?"
6132,@GaryMarcus,2021-12-18 22:17:02+00:00,https://twitter.com/GaryMarcus/status/1472330087332782089,"the key finding in AI 2021:

""increasing‚Ä¶scale continues to boost performance [in areas] like reading comprehension, fact-checking, ID of toxic language‚Ä¶
[in others] scale does not significantly improve results‚Äî [e.g.] logical reasoning &amp; common-sense""

https://t.co/hSkhZxrnZt"
6133,@GaryMarcus,2021-12-16 16:31:47+00:00,https://twitter.com/GaryMarcus/status/1471518428859142145,"AI Debate 3, postponed til May: https://t.co/B4zV03IS4K"
6134,@GaryMarcus,2021-12-15 13:53:35+00:00,https://twitter.com/GaryMarcus/status/1471116228915695617,"@CantlonLab @timnitGebru @mer__edith I am sorry but now I feel like you are misrepresenting me. A better AI is about both the technical side of things (language, intelligence, and innateness) and the ethical side of things."
6135,@GaryMarcus,2021-12-15 13:27:22+00:00,https://twitter.com/GaryMarcus/status/1471109631174799365,"@CantlonLab @timnitGebru @mer__edith he‚Äôs not there to talk about ethics; that is a false presumption (I invited Timnit, Meredith, Deb and Joy to do so) ; I invited him to talk about language and innateness. (I also invited Liz Spelke, re innateness. though she has not responded)."
6136,@GaryMarcus,2021-12-15 01:42:39+00:00,https://twitter.com/GaryMarcus/status/1470932283301322754,@timnitGebru @mer__edith I can confirm that he was my advisor. I would not have worked with him nor maintained a relationship with him if he were the man he is portrayed to be. He is not.
6137,@GaryMarcus,2021-12-15 00:00:17+00:00,https://twitter.com/GaryMarcus/status/1470906520313352192,@yudapearl @AlisonGopnik please add a link and enjoy my example above :)
6138,@GaryMarcus,2021-12-14 22:54:46+00:00,https://twitter.com/GaryMarcus/status/1470890035436158983,"My 7 yr-old daughter continues to utterly outpace AI 

Last night, I explained a bug I encountered while coding. Before I could finish, she interrupted, &amp; said, ""Let me guess,  A  intervened on B"". Dead on!

Causal reasoning about novel ideas;  no AI can match it

@yudapearl"
6139,@GaryMarcus,2021-12-14 21:34:34+00:00,https://twitter.com/GaryMarcus/status/1470869849903562756,"@pmddomingos the problems lie in the approximation, not in being a function."
6140,@GaryMarcus,2021-12-14 14:32:58+00:00,https://twitter.com/GaryMarcus/status/1470763749820616704,@PMinervini @egrefen thanks for the tip! and cool competition!
6141,@GaryMarcus,2021-12-14 14:31:11+00:00,https://twitter.com/GaryMarcus/status/1470763300761714690,"Wow - symbolic systems, much maligned in recent years, crushed deep learning by a 3:1 margin‚ùóÔ∏è

#nethackchallenge21 reminds us that the quest for AGI ain‚Äôt over yet, and that there is more than one pony still in the race. 

my bet: hybrid models will pull ahead next year."
6142,@GaryMarcus,2021-12-13 23:17:13+00:00,https://twitter.com/GaryMarcus/status/1470533294466867201,"@hb_cell @demishassabis @elonmusk the paper is perfectly fine, it is the headline that‚Äôs ridiculous."
6143,@GaryMarcus,2021-12-13 20:45:26+00:00,https://twitter.com/GaryMarcus/status/1470495097808637962,"ü§£üòÇü§£‚ÄúDeepMind debuts massive language A.I. that approaches human-level reading comprehension‚Äù 

When will headline editors ever learn that scoring well on a benchmark does not true natural understanding make? https://t.co/Ullf0XPL64"
6144,@GaryMarcus,2021-12-09 05:26:01+00:00,https://twitter.com/GaryMarcus/status/1468814166404513793,‚Äúthe significance and novelty of this application of [deep learning] to mathematics is significantly overstated in the paper under review and has been wildly overstated in some of the accounts in the popular science press.‚Äù - critique by Ernie Davis https://t.co/DeV2Ff5DV1
6145,@GaryMarcus,2021-12-08 03:17:49+00:00,https://twitter.com/GaryMarcus/status/1468419519097946113,"@AlisonWants @kostea12 PhD in IX, with Pinker"
6146,@GaryMarcus,2021-12-08 00:49:22+00:00,https://twitter.com/GaryMarcus/status/1468382156615340032,"@AlisonWants @kostea12 i know, i wrote it. the posted date is wrong though, it was actually december 7 of 2012."
6147,@GaryMarcus,2021-12-07 15:16:27+00:00,https://twitter.com/GaryMarcus/status/1468237978153664525,"Happy Birthday, Noam Chomsky! https://t.co/JN3eloZ0qj"
6148,@GaryMarcus,2021-12-07 02:35:48+00:00,https://twitter.com/GaryMarcus/status/1468046556465033217,@zakkohane @Grady_Booch @DrMJoyner low bar that we still can't exceed :(
6149,@GaryMarcus,2021-12-06 00:50:23+00:00,https://twitter.com/GaryMarcus/status/1467657637693050883,"Astonishing that @tribelaw‚Äôs tweet here does NOT refer to the scandal discussed by @AshleyRParker immediately above it. And no less astonishing that the Individual at the center of both scandals remains a viable force in American politics.

What the hell has happened to the US? https://t.co/WRQTUGYy7F"
6150,@GaryMarcus,2021-12-04 18:44:36+00:00,https://twitter.com/GaryMarcus/status/1467203199555629057,"üöÄ Coming Sunday: names of some of this year's AI Debate 3 superstars! üöÄ

Please save the date - December 23, 4pm Eastern Time, and don't forget to RSVP:
https://t.co/rfiG78OqBP"
6151,@GaryMarcus,2021-12-03 18:44:08+00:00,https://twitter.com/GaryMarcus/status/1466840694908088320,"@rajiinio please dm, thanks"
6152,@GaryMarcus,2021-11-22 23:35:42+00:00,https://twitter.com/GaryMarcus/status/1462927803163103238,@BlancheMinerva @ethancaballero @stanislavfort @xiang_lorraine ugh
6153,@GaryMarcus,2021-11-22 22:30:38+00:00,https://twitter.com/GaryMarcus/status/1462911426230579204,@stanislavfort @xiang_lorraine @BlancheMinerva seeing how OpenAI refused to give me access to GPT-3 I can't go test for myself... so I hope someone with access will investigate.
6154,@GaryMarcus,2021-11-20 01:39:45+00:00,https://twitter.com/GaryMarcus/status/1461871858249179140,"@daanish_khazi @tarantulae @MelMitchell1 there is a huge literature on this, eg https://t.co/opVzD7FMI7

current 'neural network' models have too little to do with the brain to be particularly relevant"
6155,@GaryMarcus,2021-11-19 22:18:14+00:00,https://twitter.com/GaryMarcus/status/1461821144105844738,"@tarantulae @MelMitchell1 Kantian exegsesis aside, no system I have ever seen *learns* to represent time. it's insane not to build in some representation of time."
6156,@GaryMarcus,2021-11-19 22:16:36+00:00,https://twitter.com/GaryMarcus/status/1461820730157326339,"@tarantulae @LittleBimble want to weigh in? I realize I am ""psychologizing"" Kant a bit, but surely the thrust of the Critique of Pure Reason was towards the a priori of space and time etc."
6157,@GaryMarcus,2021-11-19 22:15:27+00:00,https://twitter.com/GaryMarcus/status/1461820441123864581,@tdietterich @MelMitchell1 humans have priors. your argument proves too much and doesn't really make sense. molecules can (through various processes) be organized into systems that have priors.
6158,@GaryMarcus,2021-11-19 22:13:18+00:00,https://twitter.com/GaryMarcus/status/1461819902247915521,"@tyrell_turing @MelMitchell1 @WiringTheBrain the paper by Whitelam at all is misleading in this regard, missing the richness of what real evolution can do."
6159,@GaryMarcus,2021-11-19 22:10:05+00:00,https://twitter.com/GaryMarcus/status/1461819092768276485,"@tyrell_turing @MelMitchell1 @WiringTheBrain evolution in biology surely is an optimization process but one that optimizes over hard-won subroutines, whereas much neural net evolution starts w too little structure &amp; too little capacity for hierarchical structure building‚Äì so isn't cumulative enough and hence too slow"
6160,@GaryMarcus,2021-11-19 22:05:43+00:00,https://twitter.com/GaryMarcus/status/1461817993462124547,"@primrecur @MelMitchell1 why wait? it took a billion years of evolution. sure, you could build an airplane by random chance, but it's not likely in any reasonable amount of time. so you try to engineer, using your best priors of the world."
6161,@GaryMarcus,2021-11-19 18:42:17+00:00,https://twitter.com/GaryMarcus/status/1461766799448371200,@WiringTheBrain @MelMitchell1 @MaharriT @seanmcarroll size isn‚Äôt everything
6162,@GaryMarcus,2021-11-19 18:41:49+00:00,https://twitter.com/GaryMarcus/status/1461766681143898118,"@danbri @MelMitchell1 where do you think we diverge? i think language is built on that stuff, for sure"
6163,@GaryMarcus,2021-11-19 18:37:21+00:00,https://twitter.com/GaryMarcus/status/1461765557225541633,"@MelMitchell1 @WiringTheBrain @MaharriT @seanmcarroll the propensity itself however presumably is encoded in the genes. learning doesn‚Äôt come for free. and not all learning is created equally.

humans can (i have argued) innately learn complex, abstract relationships between hierarchically-conceived entities.

most creatures can‚Äôt"
6164,@GaryMarcus,2021-11-19 18:27:04+00:00,https://twitter.com/GaryMarcus/status/1461762967242887170,"@tyrell_turing @WiringTheBrain @MelMitchell1 come on now, all engineering involves engineers using priors to make stuff work."
6165,@GaryMarcus,2021-11-19 18:26:14+00:00,https://twitter.com/GaryMarcus/status/1461762758429462530,@MelMitchell1 @WiringTheBrain @seanmcarroll a modern update of The Birth of the Mind would be swell
6166,@GaryMarcus,2021-11-19 18:25:24+00:00,https://twitter.com/GaryMarcus/status/1461762549595082752,"@WiringTheBrain @MelMitchell1 @seanmcarroll ha ha i  wrote a book about that question, The Birth of the Mind"
6167,@GaryMarcus,2021-11-19 18:24:35+00:00,https://twitter.com/GaryMarcus/status/1461762341586935808,@MelMitchell1 @seanmcarroll and then there is the Xu and Carey (1995) paper that I titled: Infant Metaphysics
6168,@GaryMarcus,2021-11-19 18:23:12+00:00,https://twitter.com/GaryMarcus/status/1461761994772549632,"@VishalGulati_ @Tesla the less stressful thing to do is to drive, and not believe in magic"
6169,@GaryMarcus,2021-11-19 17:38:06+00:00,https://twitter.com/GaryMarcus/status/1461750643870212102,"Indeed, and I will go further, @MelMitchell1, and go full Kant, and wonder why anyone would think that machines could ever learn common sense without prior representations of time, space, causality, and enduring objects."
6170,@GaryMarcus,2021-11-19 17:32:54+00:00,https://twitter.com/GaryMarcus/status/1461749337474568196,"Yikes, @tesla: ""what full self-driving"" could do well was impressive, but ‚Ä¶ultimately unnerving... I noticed I was reluctant to ever look down at the Model 3's dashboard, such as for checking our speed, because I didn't want to take my eyes off the road.‚Äù https://t.co/9BK1hXf59J"
6171,@GaryMarcus,2021-11-18 21:40:25+00:00,https://twitter.com/GaryMarcus/status/1461449237409849346,"Still more trouble in GPT-3 paradise: the ""impressive zero-shot performance of large language models is mostly due to existence of dataset bias in ... benchmarks.""

‚Äì @xiang_lorraine et al, new Arxiv:  ""A Systematic Investigation of Commonsense Understanding [in LLMS]"""
6172,@GaryMarcus,2021-11-17 14:58:38+00:00,https://twitter.com/GaryMarcus/status/1460985739366178818,"‚Äúdeep nets have an arbitrary relevance landscape.‚Äù   

superrb encapsulation!"
6173,@GaryMarcus,2021-11-16 18:43:59+00:00,https://twitter.com/GaryMarcus/status/1460680061028159491,@danbri @ylecun one would hope not. but it is misleading to equate human errors on eg Muller-Lyer with mistaking a cake for a fire hydrant.
6174,@GaryMarcus,2021-11-16 15:47:21+00:00,https://twitter.com/GaryMarcus/status/1460635609983160325,"@EvaSmartAI how about among others The Future of the Brain, edited by myself and @thefreemanlab"
6175,@GaryMarcus,2021-11-16 15:19:23+00:00,https://twitter.com/GaryMarcus/status/1460628574067564549,"ü§£ @ylecun!  But adversarial examples &amp; optical illusions differ:

Optical illusions show human minds expect the world to be orderly

Adversarial examples show neural nets don't understand compositional structure of the physical world

In open-ended tasks (eg driving) humans win."
6176,@GaryMarcus,2021-11-15 21:08:16+00:00,https://twitter.com/GaryMarcus/status/1460353982438645760,"Happy birthday deep neural nets! You are (in your celebrated rebirth) nearly 10 years old now, and still utterly fooled by images like this.

Nice work from @savvyRL @scaleAI/ @allen_ai https://t.co/2nSTFP6tJ7, redoubling @anh_ng8
 @jeffclune @jasonyo  https://t.co/FdCiSBWOZn https://t.co/dnhqYjo5Hu"
6177,@GaryMarcus,2021-11-14 14:25:46+00:00,https://twitter.com/GaryMarcus/status/1459890302043312128,"More trouble in GPT-3 country: Review of commonsense benchmarks finds ‚Äú that most‚Ä¶ are problematic, with models resorting to non-robust features and appearing not to be learning and generalizing‚Äù common sense.  

 https://t.co/Q8yIgHH247"
6178,@GaryMarcus,2021-11-12 00:35:41+00:00,https://twitter.com/GaryMarcus/status/1458956630976913413,"Want to know why it's risky to assume that your ML is going to continue work if the test regime changes from your training data? Just ask Zillow.

 https://t.co/EUH71gZspy"
6179,@GaryMarcus,2021-11-05 18:02:07+00:00,https://twitter.com/GaryMarcus/status/1456683259870334976,"@ID_AA_Carmack Could we stuff today's not-at-all-intelligent AI into a gym locker, if we wanted to? Not sure I understand where your confidence is coming from. 

Of course I think the biggest immediate threat is mediocre AI."
6180,@GaryMarcus,2021-11-04 05:07:09+00:00,https://twitter.com/GaryMarcus/status/1456125844313632770,@bradpwyble @databoydg @Miles_Brundage see eg my 2016 interview @edge: https://t.co/eLbmoHoQhm
6181,@GaryMarcus,2021-11-01 18:38:37+00:00,https://twitter.com/GaryMarcus/status/1455242891819765760,"RIP Aaron Beck, developer of cognitive therapy https://t.co/rEU4mMlvIE"
6182,@GaryMarcus,2021-10-28 18:45:50+00:00,https://twitter.com/GaryMarcus/status/1453795156478414848,@paulraphel Let me know when I can next be of help to your astronaut friend üöÄ
6183,@GaryMarcus,2021-10-28 18:44:31+00:00,https://twitter.com/GaryMarcus/status/1453794828353896448,"Metacomment: I never met a Meta I didn‚Äôt like. 

Until now. 

üò±"
6184,@GaryMarcus,2021-10-25 22:26:04+00:00,https://twitter.com/GaryMarcus/status/1452763417807183872,"@wired on ""Facebook‚Äôs repeated failings:
üëâ...employees identified potential solutions to deep-seated problems and went unheard
üëâ... the downsides of growth at all costs were felt most acutely in developing nations."" https://t.co/tv7VIA7Qkz"
6185,@GaryMarcus,2021-10-22 13:52:14+00:00,https://twitter.com/GaryMarcus/status/1451546945420345353,"@IntuitMachine @mpshanahan Machines are very good at raw calculation, very poor at judgment.

Wisdom is knowing how you can and can‚Äôt use your tools."
6186,@GaryMarcus,2021-10-22 13:50:09+00:00,https://twitter.com/GaryMarcus/status/1451546421253922821,"@EvaSmartAI For fun,  up who wrote a commentary on that 2006 study, in same issue :)"
6187,@GaryMarcus,2021-10-22 13:48:19+00:00,https://twitter.com/GaryMarcus/status/1451545957263237124,"@mpshanahan Ok, but we wouldn‚Äôt entrust parrots with our lives and major decisions, etc, and it‚Äôs still a long way from there, even though I agree that parrot intelligence would be a step up."
6188,@GaryMarcus,2021-10-22 13:13:57+00:00,https://twitter.com/GaryMarcus/status/1451537308944003073,"Pigeons and parrots learn, too. 

Merely parroting past data is not enough."
6189,@GaryMarcus,2021-10-22 01:06:14+00:00,https://twitter.com/GaryMarcus/status/1451354174587768875,@mosesjones @JFPuget See my book Kluge for some discussion of why we suffer from so many cognitive imperfections
6190,@GaryMarcus,2021-10-21 19:07:11+00:00,https://twitter.com/GaryMarcus/status/1451263815786500099,"Tech and AI for Wildfires - people who are interested in helping, please join the thread below:"
6191,@GaryMarcus,2021-10-21 17:19:28+00:00,https://twitter.com/GaryMarcus/status/1451236706976288769,@interintel @SurviveThrive2 @Patapom2 @connectedregio1 @NoFreeCompute @walter4096 @peremayol @markcannon5 @IvanVegner @RebelScience @stuz5000 @Built2T @Korrelan_AI @elonmusk @Tesla let me know if you make progress on this. @SColesPorter is also interested in how AI can help with wildfires.
6192,@GaryMarcus,2021-10-21 01:56:18+00:00,https://twitter.com/GaryMarcus/status/1451004385400553474,@PatrikMuncaster @elonmusk @Twitter @missy_cummings @SecretaryPete @jack https://t.co/cCYf87peNb
6193,@GaryMarcus,2021-10-21 01:52:52+00:00,https://twitter.com/GaryMarcus/status/1451003522380488707,"@pmddomingos Or because eg they were born to poor parents in places with little social mobility. @pmddomingos take this one down, it‚Äôs foolish."
6194,@GaryMarcus,2021-10-21 01:49:54+00:00,https://twitter.com/GaryMarcus/status/1451002774469050372,"@BitcoinBling @elonmusk @Twitter @missy_cummings @SecretaryPete @jack @Tesla Also, @elonmusk didn‚Äôt ‚Äúdefend himself‚Äù by offering a substantive reply to @missy_cummings‚Äôs thoughtful arguments, but rather tried to rule up a crowd with ad hominem attack. 

Nothing cool about someone in power doing that."
6195,@GaryMarcus,2021-10-21 01:48:09+00:00,https://twitter.com/GaryMarcus/status/1451002333442154496,"@BitcoinBling @elonmusk @Twitter @missy_cummings @SecretaryPete @jack It is misleading to call a carefully researched view that goes back to her days flying F18s and looking at human error ‚Äúbias‚Äù

And I happen to hold pretty much the same views, and have  criticized this general approach to AI since 1992, long before @Tesla"
6196,@GaryMarcus,2021-10-21 01:22:18+00:00,https://twitter.com/GaryMarcus/status/1450995829964095488,"@BitcoinBling @elonmusk @Twitter @missy_cummings @SecretaryPete @jack I have no financial interest in LIDAR but fully agree with @missy_cummings that it is foolish not to use it given the weaknesses of current AI (as discussed in my book  https://t.co/Pt7HZbLIv5). 

Humans don‚Äôt need LIDAR but our cognitive systems are far more robust."
6197,@GaryMarcus,2021-10-21 01:01:54+00:00,https://twitter.com/GaryMarcus/status/1450990695590760449,"I call foul on @elonmusk.

His approach to AV safety is problematic; it is even more problematic that he is using @Twitter to attack college professors like @missy_cummings for blowing the whistle.

@SecretaryPete I stand with @missy_cummings and hope you will, too.

cc @jack https://t.co/0wuRCpk3yM"
6198,@GaryMarcus,2021-10-20 20:18:21+00:00,https://twitter.com/GaryMarcus/status/1450919338794315776,@grbradsk True that. https://t.co/hQ7ihgjwLw
6199,@GaryMarcus,2021-10-20 18:40:01+00:00,https://twitter.com/GaryMarcus/status/1450894593075994628,"@ceobillionaire @elonmusk @MatchasmMatt @NHTSAgov @MissyCummings @karpathy @missy_cummings, that is"
6200,@GaryMarcus,2021-10-19 23:46:54+00:00,https://twitter.com/GaryMarcus/status/1450609433294299136,"@AcmeAviation @BLSmith2112 @missy_cummings @lizadixon What‚Äôs your source? @AcmeAviation laid down a challenge, and can‚Äôt help  but notice that you responded without any further data."
6201,@GaryMarcus,2021-10-19 23:43:50+00:00,https://twitter.com/GaryMarcus/status/1450608660573560833,Fantastic to see growing interest in neurosymbolic approached to AI!
6202,@GaryMarcus,2021-10-19 17:01:00+00:00,https://twitter.com/GaryMarcus/status/1450507285466271752,"on why it matters that current AI is mindless, and on what we should be aspiring for: https://t.co/WgsssF3FeU"
6203,@GaryMarcus,2021-10-19 04:38:28+00:00,https://twitter.com/GaryMarcus/status/1450320419114807296,"@Plinz indeed what I have said is that current AI is pretty mindless, and that it mindlessly perpetuates stereotypes."
6204,@GaryMarcus,2021-10-19 02:16:57+00:00,https://twitter.com/GaryMarcus/status/1450284807519232004,I can‚Äôt even https://t.co/COTFfvjKjo
6205,@GaryMarcus,2021-10-19 01:04:22+00:00,https://twitter.com/GaryMarcus/status/1450266541128179713,@amahabal @grrosegr @Facebook @WSJ For sure
6206,@GaryMarcus,2021-10-19 01:02:19+00:00,https://twitter.com/GaryMarcus/status/1450266022762582023,AI should aspire to be least as good at the most competent people and ideally better than all of us.
6207,@GaryMarcus,2021-10-19 00:18:13+00:00,https://twitter.com/GaryMarcus/status/1450254924789420033,"@BlancheMinerva @ykilcher @percyliang It is indeed damning. The reception that I have been given for raising criticism -- much of which has ultimately become widely recognized-- is startling. 

Anyone who has followed this feed over the last several years will know what I mean."
6208,@GaryMarcus,2021-10-18 23:33:46+00:00,https://twitter.com/GaryMarcus/status/1450243741055258625,"@BlancheMinerva @ykilcher @percyliang Never said I agreed with his reply. But he has given a place where people can read the replies (mine included) &amp; his rejoinder and *decide for themselves*. 

That's so far above current standards that it's the start of a revolution, and I want to encourage that revolution."
6209,@GaryMarcus,2021-10-18 21:48:51+00:00,https://twitter.com/GaryMarcus/status/1450217335051087872,And the whole thread (include replies that are in part to me) is worth reading.
6210,@GaryMarcus,2021-10-18 21:47:50+00:00,https://twitter.com/GaryMarcus/status/1450217082981797889,"Big shoutout to @percyliang for welcoming discussion, rather than evading or dismissing those with differing views. 

Open discussion is part of what we need to get AI to a better place.

Multiple commentaries on the Stanford CRFM report:"
6211,@GaryMarcus,2021-10-18 13:48:37+00:00,https://twitter.com/GaryMarcus/status/1450096481558351872,@rajiinio you might like this piece from 2018
6212,@GaryMarcus,2021-10-18 13:40:05+00:00,https://twitter.com/GaryMarcus/status/1450094334657761288,"I tried to warn you, Mark Zuckerberg ‚Å¶@Facebook‚Å©, in October, 2018.

You didn‚Äôt listen.

Small wonder ‚Å¶@WSJ‚Å© said now,‚ÄúFacebook Says AI Will Clean Up the Platform. Its Own Engineers Have Doubts‚Äù
 
Advise you to read the below and reconsider.  https://t.co/QSGTKTkrIt"
6213,@GaryMarcus,2021-10-18 13:26:18+00:00,https://twitter.com/GaryMarcus/status/1450090866677219332,@pheras Indeed i tweeted almost exactly the same!
6214,@GaryMarcus,2021-10-18 02:32:50+00:00,https://twitter.com/GaryMarcus/status/1449926416947036165,Wow. a scary real life version of @AllysonEttinger‚Äôs great demo of the failure of current ML to understand negation.
6215,@GaryMarcus,2021-10-18 00:32:33+00:00,https://twitter.com/GaryMarcus/status/1449896144738291713,"@BethCarey12 @ykilcher fair point, most of the comprehension in these systems is illusory."
6216,@GaryMarcus,2021-10-18 00:29:09+00:00,https://twitter.com/GaryMarcus/status/1449895291260342277,"@Love2Code evolutionary psychologists have certainly thought about this, eg this and some papers suited here. https://t.co/xVHJJnDxNo @primalpoly might know."
6217,@GaryMarcus,2021-10-17 22:06:19+00:00,https://twitter.com/GaryMarcus/status/1449859344309182465,"thinking about the talk I will give tomorrow at #AGI21 
https://t.co/r9TtAX7Fox https://t.co/eaEkaC8ljQ"
6218,@GaryMarcus,2021-10-17 18:45:41+00:00,https://twitter.com/GaryMarcus/status/1449808853911048193,"There's no doubt that machine-learning QA systems are getting better and better, but no matter how much data there is, a residue of incomprehension always seems to remain: https://t.co/0pPwHpP9n5"
6219,@GaryMarcus,2021-10-17 18:40:49+00:00,https://twitter.com/GaryMarcus/status/1449807628104650752,"@beltsbear @mkguitar @utkarshojha12 @elonmusk @Tesla 1. thanks
but
2. a single anecdotal example isn't really data.
3. it's not actually clear what happened."
6220,@GaryMarcus,2021-10-17 18:07:39+00:00,https://twitter.com/GaryMarcus/status/1449799282635149312,"@beltsbear @mkguitar @utkarshojha12 @elonmusk @Tesla ""all the time"" is obviously an exaggeration. ""hardly ever"" might be more accurate, but if you have data, share them"
6221,@GaryMarcus,2021-10-17 17:59:11+00:00,https://twitter.com/GaryMarcus/status/1449797151186305029,"@HappyAar @elonmusk IMHO it's both government (which should do more) and Tesla (which should cut the BS, and held liable for their actions)."
6222,@GaryMarcus,2021-10-17 17:52:52+00:00,https://twitter.com/GaryMarcus/status/1449795563910664197,@AcmeAviation
6223,@GaryMarcus,2021-10-17 17:52:20+00:00,https://twitter.com/GaryMarcus/status/1449795426874396673,@AcmeAviation @sd_marlow @missy_cummings @lizadixon It's oxymoronic to call Level 2 autonomy Full Self-Driving.
6224,@GaryMarcus,2021-10-17 17:50:29+00:00,https://twitter.com/GaryMarcus/status/1449794960572567560,@AcmeAviation @BobMuir @missy_cummings @lizadixon gotta love the dodge?
6225,@GaryMarcus,2021-10-17 17:49:41+00:00,https://twitter.com/GaryMarcus/status/1449794762148511745,"@kmvanh @AdamJosephCook @elonmusk @Tesla agreed, we should move towards this for all manufacturers cc: @lizadixon"
6226,@GaryMarcus,2021-10-17 17:48:48+00:00,https://twitter.com/GaryMarcus/status/1449794539716104194,"ü§¶‚Äç‚ôÇÔ∏è #Teslanuts who blame everyone but #Tesla ü§¶‚Äç‚ôÇÔ∏è 

Unfair to put blame entirely on vehicle owners, when Tesla:

1. Featured CEO @elonmusk on 60 Minutes driving hands-free, when  tech for safe hands-free driving  does not yet exist

2. Hypes unreliable self-driving as ""Full"" SD"
6227,@GaryMarcus,2021-10-17 15:21:35+00:00,https://twitter.com/GaryMarcus/status/1449757489172402179,@missy_cummings @lizadixon @AcmeAviation
6228,@GaryMarcus,2021-10-16 14:48:30+00:00,https://twitter.com/GaryMarcus/status/1449386778276683777,@rcalo You‚Äôll be back
6229,@GaryMarcus,2021-10-16 14:35:39+00:00,https://twitter.com/GaryMarcus/status/1449383543432310791,"Thrilled to finally see serious efforts towards commonsense based moral reasoning (as Davis and I urged in https://t.co/Pt7HZbLIv5) by @liweijianglw @etzioni @YejinChoinka and others at @allen_ai.   

Highly recommended!"
6230,@GaryMarcus,2021-10-15 13:32:57+00:00,https://twitter.com/GaryMarcus/status/1449005377748496392,@bimedotcom @EvaSmartAI @balajis @matthen2 @InertialObservr @Shi4Tech @enricomolinari @Khulood_Almani @LavaletteAstrid @BetaMoroney @CurieuxExplorer @pchamard @voinageo @SimplyH @paulhayes55 Ditto!
6231,@GaryMarcus,2021-10-15 04:18:48+00:00,https://twitter.com/GaryMarcus/status/1448865921137733633,"@Jess_Riedel @missy_cummings This is wise but also needs to be recalled later, when stats are discussed, since they are only allowing the most trustworthy drivers access, whereas actual self-driving shouldn‚Äôt depend on any human‚Äôs skills."
6232,@GaryMarcus,2021-10-14 16:23:14+00:00,https://twitter.com/GaryMarcus/status/1448685839249121291,@IntuitMachine @danbri @sfiscience @MelMitchell1 @ZDNet @geoffreyhinton nobody sensible would doubt this.
6233,@GaryMarcus,2021-10-14 04:05:50+00:00,https://twitter.com/GaryMarcus/status/1448500268899790853,@robinc @leonpalafox @tdietterich @oyvinht you are very welcome to write your own book.
6234,@GaryMarcus,2021-10-14 02:10:23+00:00,https://twitter.com/GaryMarcus/status/1448471214846996481,"@robinc @tdietterich @oyvinht For AI sophisticated sure; for Kaye readers, who have never heard the terms, that‚Äôs just jargon. And it‚Äôs narrower, too. planning subsumes multiple possible approaches, including those yet to be invented."
6235,@GaryMarcus,2021-10-14 01:55:19+00:00,https://twitter.com/GaryMarcus/status/1448467420910211074,"@tdietterich @oyvinht No, it was the right thing in the context, IMHO, especially as an antidote to the ML = AI that most lay people have incorrectly absorbed."
6236,@GaryMarcus,2021-10-13 18:55:39+00:00,https://twitter.com/GaryMarcus/status/1448361809132462083,"Wow. This is truly uncanny.  If you are a Robin Williams fan, as I am, check this out."
6237,@GaryMarcus,2021-10-13 18:09:44+00:00,https://twitter.com/GaryMarcus/status/1448350255397761025,@jordanbateman @PennyDaflos @ianrausten please consider
6238,@GaryMarcus,2021-10-13 17:35:15+00:00,https://twitter.com/GaryMarcus/status/1448341578339143680,"I stand w @math_rachel, @dgurdasani1, &amp; @jeremyphoward all who have done great work for humanity during the pandemic.

And all this credentialism and ad hominem has to stop. 

Science advances through good ideas, good data, and thoughtful critiques, not schoolyard taunts."
6239,@GaryMarcus,2021-10-13 16:46:02+00:00,https://twitter.com/GaryMarcus/status/1448329191338876931,"@tdietterich @oyvinht yes, but this comes from a book that tries to make these things accessible to a nontechnical audience; making it perfect with every nuance would be like Mark Twain's line on jokes being like frogs. The explanation would die in the clarification process."
6240,@GaryMarcus,2021-10-12 23:33:29+00:00,https://twitter.com/GaryMarcus/status/1448069341484814339,"Want to know what astronaut @WilliamShatner thinks about AI? 

Here's our fascinating conversation from earlier this year.
 
https://t.co/aJG9YwV4BG"
6241,@GaryMarcus,2021-10-12 23:23:10+00:00,https://twitter.com/GaryMarcus/status/1448066745286074370,"@haltakov stir, per xkcd: https://t.co/vOMzBO0wKL"
6242,@GaryMarcus,2021-10-12 21:34:21+00:00,https://twitter.com/GaryMarcus/status/1448039360952082434,"@chazfirestone Now, now. Mashable deserves the ribbing but the design might conceivably make for a more efficient, more maintainable, or more automatable sailboat, with less demands for humans to climb to really high perches."
6243,@GaryMarcus,2021-10-12 04:26:36+00:00,https://twitter.com/GaryMarcus/status/1447780719997042688,"‚ÄúWe cannot expect good public health to be valued and nurtured if political health is poor.‚Äù some lessons from the pandemic for science and society, by @philipcball"
6244,@GaryMarcus,2021-10-12 02:24:54+00:00,https://twitter.com/GaryMarcus/status/1447750093508014080,@AcmeAviation I have decided that this is one of my favorite tweets ever. Follow back?
6245,@GaryMarcus,2021-10-12 01:55:49+00:00,https://twitter.com/GaryMarcus/status/1447742771276619776,@Love2Code @vhranger @Tesla @lexfridman @AcmeAviation I haven‚Äôt written much extensively about the driving domain but re conceptual thinness see the analogous arguments I have made for language in https://t.co/FLZ9VvNAQH and my articles in gradientpub and arXiv.
6246,@GaryMarcus,2021-10-12 01:53:26+00:00,https://twitter.com/GaryMarcus/status/1447742173433131009,"@_NicT_ I have played a big role in championing hybrid models, as @luislamb and @AvilaGarcez will attest."
6247,@GaryMarcus,2021-10-12 01:20:27+00:00,https://twitter.com/GaryMarcus/status/1447733871944994819,"@Love2Code @vhranger @Tesla @lexfridman @AcmeAviation We do, but the fatality rate is nonetheless on the order of 1 in 100 millions miles.  How? we leverage stability &amp; prediction over time, &amp; unify many different representations, conceptual and perceptual

Current neural neural are too thin on conceptual side to use same strategy."
6248,@GaryMarcus,2021-10-11 22:21:51+00:00,https://twitter.com/GaryMarcus/status/1447688925334622210,@grbradsk @AbstractionPhys @elonmusk I fully agree with this but the pipelines are of course different. Tesla‚Äôs challenge is not in sticking to a lane (a visual-motor mapping analogous to catching a fly ball) but in high-stakes decision-making around a vast and open-ended set of perceptual input.
6249,@GaryMarcus,2021-10-11 20:10:15+00:00,https://twitter.com/GaryMarcus/status/1447655810071470082,"@rocos_basilisk @MatthewLennig @elonmusk that is manifestly false. I founded, led,  and sold a startup to Uber, have a PhD from MIT. was professor for 20 years, got tenure for my scientific work at age 30, published in Science and Nature, etc. please do not spread misinformation about me."
6250,@GaryMarcus,2021-10-11 20:00:39+00:00,https://twitter.com/GaryMarcus/status/1447653391111438347,"@Love2Code @vhranger @Tesla @lexfridman i don‚Äôt know a systematic analysis but eg @AcmeAviation just posted an example where construction signs were ignored. 

The real problem is that ‚Äúgenerally quite good‚Äù isn‚Äôt nearly good enough for driving; 99.999% won‚Äôt cut it for L5."
6251,@GaryMarcus,2021-10-11 19:06:31+00:00,https://twitter.com/GaryMarcus/status/1447639769375203328,@grbradsk @elonmusk The street poles will be self. Not sure about the pedestrians.
6252,@GaryMarcus,2021-10-11 17:13:21+00:00,https://twitter.com/GaryMarcus/status/1447611289958768640,"@AcmeAviation @elonmusk @WholeMarsBlog Totally agree, and also:"
6253,@GaryMarcus,2021-10-11 17:11:52+00:00,https://twitter.com/GaryMarcus/status/1447610917538107395,"This logic makes no sense @elonmusk. 

1. Birds flap their wings, but that does not mean that wings are the only way to achieve flight.

2. Current neural nets lack the cognitive depth and robustness that would be necessary to support reliable L5 self-driving form vision alone."
6254,@GaryMarcus,2021-10-11 16:49:54+00:00,https://twitter.com/GaryMarcus/status/1447605388409507842,@ahmetmeleq @ceobillionaire @Love2Code @Tesla @ceobillionaire and I share a love for fostering good debate!
6255,@GaryMarcus,2021-10-11 16:48:55+00:00,https://twitter.com/GaryMarcus/status/1447605141767692301,"@smithstock @vhranger @Love2Code @Tesla @lexfridman One hopes the situation will someday improve, but this is indeed where we are now, and perhaps where we will remain until there are advances in neurosymbolic integration. Cc @luislamb @AvilaGarcez"
6256,@GaryMarcus,2021-10-11 14:26:56+00:00,https://twitter.com/GaryMarcus/status/1447569411351711752,@vhranger @Love2Code @Tesla @lexfridman Indeed that‚Äôs been basically why I worry about the value of all their lidarless miles. Humans use knowledge to compensate; remains to be seen whether Tesla can manage L5 in the absence of LiDAR.
6257,@GaryMarcus,2021-10-11 14:06:37+00:00,https://twitter.com/GaryMarcus/status/1447564295185879047,"@vhranger @Love2Code @Tesla @lexfridman Based on the limited info that is publicly disclose, I have the same impression."
6258,@GaryMarcus,2021-10-11 14:05:49+00:00,https://twitter.com/GaryMarcus/status/1447564096182816770,"@vhranger @Love2Code @Tesla @lexfridman 1. Which flaws?
2. I have many in the industry say Waymo is more solid than Tesla, but specifics that can be said publicly would be helpful here."
6259,@GaryMarcus,2021-10-11 13:47:28+00:00,https://twitter.com/GaryMarcus/status/1447559478107332609,"@Love2Code @Tesla @lexfridman That‚Äôs the best answer here, but Google, Amazon and Facebook have done a lot of ML at scale too, though not on the same problems."
6260,@GaryMarcus,2021-10-11 13:45:35+00:00,https://twitter.com/GaryMarcus/status/1447559003362537472,"@Love2Code @Tesla @lexfridman Are they better at deploying ML in the wild than Google, Facebook, and Amazon? Maybe at vision, not overall."
6261,@GaryMarcus,2021-10-11 13:43:09+00:00,https://twitter.com/GaryMarcus/status/1447558391048589314,@lsi1123 Nothing on the list was. The context for the list was an overblown claim that suggested that Tesla was the (not a) leading force in AI.
6262,@GaryMarcus,2021-10-11 00:51:36+00:00,https://twitter.com/GaryMarcus/status/1447364224376885249,@pmddomingos That‚Äôs exactly how I ended #AIDebate2
6263,@GaryMarcus,2021-10-11 00:50:24+00:00,https://twitter.com/GaryMarcus/status/1447363921338318852,"@tejasdkulkarni @karpathy i will stand corrected, if so."
6264,@GaryMarcus,2021-10-11 00:46:24+00:00,https://twitter.com/GaryMarcus/status/1447362914415960067,@tejasdkulkarni @karpathy Contrarians can of course be right; I would love to see the field build vision-only L5. Not the bet I would place but let‚Äôs see!
6265,@GaryMarcus,2021-10-11 00:42:54+00:00,https://twitter.com/GaryMarcus/status/1447362036531449862,"@tejasdkulkarni @karpathy It‚Äôs also foundational if lots of other teams to follow the same path, even if it doesn‚Äôt succeed.  success is too high a bar, particularly for this thread, which is really about influence. Interesting question whether others will abandon LiDAR and focus on vision-only."
6266,@GaryMarcus,2021-10-10 23:28:57+00:00,https://twitter.com/GaryMarcus/status/1447343423745400835,"@tejasdkulkarni @karpathy If he can get it to work for Level 5 in a generalizable way (see tweet elsewhere), my hat is off to him. Obviously humans can do it without LiDAR but current AI lacks the cognitive sophistication of ordinary humans."
6267,@GaryMarcus,2021-10-10 22:04:05+00:00,https://twitter.com/GaryMarcus/status/1447322068484251650,"@pmddomingos Yes, I wrote about this in Kluge. We don‚Äôt have the memory to represent Leibniz‚Äôs language. Loglan never took off, because it doesn‚Äôt actually fit with our idiosyncratic brains."
6268,@GaryMarcus,2021-10-10 21:28:12+00:00,https://twitter.com/GaryMarcus/status/1447313038856556549,"@pmddomingos Name one. 

It‚Äôs actually pretty good as way of leveraging shared knowledge in a low bandwidth channel."
6269,@GaryMarcus,2021-10-10 19:47:59+00:00,https://twitter.com/GaryMarcus/status/1447287814966628358,@Frank37004246 https://t.co/vnWxUXrOTn
6270,@GaryMarcus,2021-10-10 16:26:03+00:00,https://twitter.com/GaryMarcus/status/1447236998394118148,"@Love2Code @Tesla @lexfridman all true but does that come close to putting Tesla in front of DeepMind, FAIR, Google Brain, MILA, Stanford, etc?"
6271,@GaryMarcus,2021-10-10 16:14:04+00:00,https://twitter.com/GaryMarcus/status/1447233981842219010,"@SuryaGanguli my mission, since 1992, has always been about integrating. 

by in large I have felt that the ML community has been dismissive of the tools listed that are on the symbolic side of the spectrum."
6272,@GaryMarcus,2021-10-10 14:56:55+00:00,https://twitter.com/GaryMarcus/status/1447214569290489859,@smithstock &amp; a lot of the top search hits for Tesla and slam look like this: https://t.co/ITIPYxYPFQ and
6273,@GaryMarcus,2021-10-10 14:53:43+00:00,https://twitter.com/GaryMarcus/status/1447213763019431940,@msaquibsarfraz I am old enough to remember when they said they would give away their IP for free....
6274,@GaryMarcus,2021-10-10 14:52:51+00:00,https://twitter.com/GaryMarcus/status/1447213544391405568,"@smithstock Nope. Strictly speaking SLAM is a problem, with a set of techniques associated, most of which predate Tesla. https://t.co/aeY8WXGqPL"
6275,@GaryMarcus,2021-10-10 14:26:41+00:00,https://twitter.com/GaryMarcus/status/1447206961045336066,"Which of these widely-used AI technologies originated at Tesla?

DNNs
CNNs
LSTMs
SVMs
TPUs
Transformers
TensorFlow
PyTorch
GPUs
RL
Deep RL
Model-based RL
LISP
SAT solvers
NLTK
WordNet
StanfordNLP
MCTS
SLAM
Hybrid models 
Kaggle
Knowledge graphs
Causal models 
Probabilistic models"
6276,@GaryMarcus,2021-10-09 23:39:03+00:00,https://twitter.com/GaryMarcus/status/1446983578328260609,"@Jess_Riedel i am challenging the specificity of your statistic, not the idea that Tesla etc should work on the problem."
6277,@GaryMarcus,2021-10-09 23:12:42+00:00,https://twitter.com/GaryMarcus/status/1446976947272118278,"Almost 10,000 people signed up for our 3rd annual #AIdebate and we haven‚Äôt even announced the first speakers yet! Thank you for your support! üôè 

Please feel free to reply below with suggested participants, with a special emphasis on diversity and people working on AI for good."
6278,@GaryMarcus,2021-10-09 19:57:57+00:00,https://twitter.com/GaryMarcus/status/1446927939136753665,@matthewcobb ü§£
6279,@GaryMarcus,2021-10-09 19:57:32+00:00,https://twitter.com/GaryMarcus/status/1446927830923706369,"Well maybe, but only relative to a technology that does not yet exist. 

Which means that this number is, for now, make-believe economics."
6280,@GaryMarcus,2021-10-09 19:53:43+00:00,https://twitter.com/GaryMarcus/status/1446926871837298694,"@dileeplearning, game on"
6281,@GaryMarcus,2021-10-09 19:52:36+00:00,https://twitter.com/GaryMarcus/status/1446926590659620865,"GPT-3, in a nutshell https://t.co/nR0FVR0fWD"
6282,@GaryMarcus,2021-10-09 18:18:37+00:00,https://twitter.com/GaryMarcus/status/1446902939268759552,"@Jess_Riedel @AdamJosephCook @missy_cummings let's split the difference and say that (given the public impact) the least you need is a clearly and publicly-presented safety case, in which experts have an opportunity to comment and ask questions.

has Tesla done that much?"
6283,@GaryMarcus,2021-10-09 18:16:35+00:00,https://twitter.com/GaryMarcus/status/1446902429392375809,"@svpino @siponza @kittylyst @KeshTFE @elonmusk Lots of experts place Waymo and possibly others in front of them. 

Tesla has most miles driven, but lacks lidar, which lessens the value of the data. 

I don't know any broad, careful, systematic comparisons."
6284,@GaryMarcus,2021-10-09 18:00:08+00:00,https://twitter.com/GaryMarcus/status/1446898287022264328,"@svpino @siponza @kittylyst @KeshTFE @elonmusk i have  talked only about 3 (plus #4, but only in connection to the specific claim about what it takes to be an AI capital). 

cars have driven themselves for decades. issue is safety."
6285,@GaryMarcus,2021-10-09 17:58:12+00:00,https://twitter.com/GaryMarcus/status/1446897801565114370,"@svpino @KeshTFE @elonmusk the tweet at top was about mainly Lex's overblown statement, but I do have concerns about Tesla that I have posted here before, including overhype and making L2 driving sound like it is L5, putting people at risk. (eg Elon hands free on 60 Minutes sent an unsafe signal)."
6286,@GaryMarcus,2021-10-09 17:41:41+00:00,https://twitter.com/GaryMarcus/status/1446893644254879746,"@utkarshojha12 @Tesla @lexfridman Sorry, the AI world is not going to flock to Austin and make it the AI ""capital"" if @tesla moves some offices there but doesn't create a lot valuable ideas and tools that other people regularly build on."
6287,@GaryMarcus,2021-10-09 16:49:30+00:00,https://twitter.com/GaryMarcus/status/1446880513394823170,"@Jess_Riedel @missy_cummings main issue is that eg a lot of suburban miles in good light and good weather may not tell you much about Boston in a snowstorm, etc. miles are not all equivalent"
6288,@GaryMarcus,2021-10-09 16:44:10+00:00,https://twitter.com/GaryMarcus/status/1446879170710044672,@emilymbender @sandyasm and quite likely important architectural changes as well
6289,@GaryMarcus,2021-10-09 16:22:14+00:00,https://twitter.com/GaryMarcus/status/1446873649441509378,"@ergunah1 @Tesla @lexfridman nothing to do with politics. he's just plain wrong. 

happy to place a 10 year bet on that, for a large sum of money."
6290,@GaryMarcus,2021-10-09 16:17:06+00:00,https://twitter.com/GaryMarcus/status/1446872358728331265,"@sidk_ @svpino @MontesdeOcaMA @Grady_Booch yes, Tesla is very visible. but where are the ideas/techniques/code that they have introduced that others actually build on?"
6291,@GaryMarcus,2021-10-09 16:14:11+00:00,https://twitter.com/GaryMarcus/status/1446871625291341824,"Um, the key word was ""foundational""

Not one of the replies below to my challenge to @Tesla &amp; @lexfridman has pointed to a *specific piece of work by Tesla* that other companies/researchers regularly build upon.

Tesla may be a player in AI, but that doesn't make them the leader."
6292,@GaryMarcus,2021-10-09 14:12:20+00:00,https://twitter.com/GaryMarcus/status/1446840961359769606,"#Savetheearth, by any means necessary. 

Watch to the end, and please consider retweeting. https://t.co/BYmpGmOxe8"
6293,@GaryMarcus,2021-10-09 02:38:08+00:00,https://twitter.com/GaryMarcus/status/1446666260045918209,@filippie509 @bwwgpro1 @pmddomingos kind of like promising Level 5 driving when you are still regularly running into stopped vehicles on the highway ü§∑‚Äç‚ôÇÔ∏è
6294,@GaryMarcus,2021-10-09 02:27:55+00:00,https://twitter.com/GaryMarcus/status/1446663689583542272,"@hgaur_com he is not there any more; it is not part of Tesla, and it is not moving to Texas."
6295,@GaryMarcus,2021-10-09 02:17:53+00:00,https://twitter.com/GaryMarcus/status/1446661164557946884,@bwwgpro1 @filippie509 @pmddomingos mutatatis mutandis Mars is?
6296,@GaryMarcus,2021-10-09 02:11:54+00:00,https://twitter.com/GaryMarcus/status/1446659658869972992,"@svpino @MontesdeOcaMA @Grady_Booch Powerhouse: maybe? if they start sharing more of what they do and it turns out to be broadly applicable, perhaps. Capital, as @lexfridman said? I sincerely doubt it."
6297,@GaryMarcus,2021-10-09 01:54:55+00:00,https://twitter.com/GaryMarcus/status/1446655381892046848,@robinc @DeepMind @demishassabis @koraykv that means you!
6298,@GaryMarcus,2021-10-09 01:54:15+00:00,https://twitter.com/GaryMarcus/status/1446655214606434304,@dan_biderman is there something specific that they have published or shared that you build upon?
6299,@GaryMarcus,2021-10-09 01:53:30+00:00,https://twitter.com/GaryMarcus/status/1446655026584117253,"@MontesdeOcaMA @svpino @Grady_Booch have they shared any ideas or tools with respect to AI that other people regular build on? if so, which? what other work has built on it?

my feed isn‚Äôt exactly overflowing with specifics."
6300,@GaryMarcus,2021-10-09 01:50:43+00:00,https://twitter.com/GaryMarcus/status/1446654323975278594,@svpino @MontesdeOcaMA @Grady_Booch i asked for a list. what goes on the list?
6301,@GaryMarcus,2021-10-09 01:50:02+00:00,https://twitter.com/GaryMarcus/status/1446654153455927298,"@KeshTFE @elonmusk IF they are the first to solve self driving in a generalizeable way that matches or exceeds human performance, I will publicly apologize for having underestimated them. 

IF"
6302,@GaryMarcus,2021-10-08 23:53:46+00:00,https://twitter.com/GaryMarcus/status/1446624894351929345,"@HappyAar @beltsbear people can of course make these distinctions easily, without Lidar, but we perceive the world in a much more conceptual/world-model based way."
6303,@GaryMarcus,2021-10-08 23:51:24+00:00,https://twitter.com/GaryMarcus/status/1446624298404171777,"@robinc Favorite so far is probably AlphaFold2 by @DeepMind, well-engineered model-based RL that may well have considerable positive impact."
6304,@GaryMarcus,2021-10-08 23:21:48+00:00,https://twitter.com/GaryMarcus/status/1446616851467759620,"@NC_Matthews @lexfridman they are basically working on a single application and I am not convinced that they are leading even there, nor that they have some foundational technology that will give them great leverages in the other great challenges AI faces."
6305,@GaryMarcus,2021-10-08 23:17:55+00:00,https://twitter.com/GaryMarcus/status/1446615871061827586,@utkarshojha12 I honestly haven‚Äôt seen the innovation on foundations of AI. and I have seen years of deceptive overclaiming from @elonmusk.
6306,@GaryMarcus,2021-10-08 23:13:25+00:00,https://twitter.com/GaryMarcus/status/1446614740021616643,@NC_Matthews they have built very good infrastructure but I don‚Äôt think that alone is enough to make @lexfridman‚Äôs claim plausible.
6307,@GaryMarcus,2021-10-08 23:11:53+00:00,https://twitter.com/GaryMarcus/status/1446614355068346371,"@beltsbear so will the lack of LIDAR, but in the opposite direction."
6308,@GaryMarcus,2021-10-08 23:11:16+00:00,https://twitter.com/GaryMarcus/status/1446614198780239872,@TheScottLove @NHTSAgov @SamAardvark
6309,@GaryMarcus,2021-10-08 23:10:10+00:00,https://twitter.com/GaryMarcus/status/1446613921566101505,@utkarshojha12 I didn‚Äôt make a summary; I made a joke and asked a question.
6310,@GaryMarcus,2021-10-08 22:56:05+00:00,https://twitter.com/GaryMarcus/status/1446610379358949378,"@BrianWandell agreed on all, @BrianWandell. but that doesn‚Äôt mean Tesla is going to make Austin an AI superpower."
6311,@GaryMarcus,2021-10-08 03:50:31+00:00,https://twitter.com/GaryMarcus/status/1446322087308652544,"more evidence for key predictions of The Algebraic Mind (2001):  ‚Äúchallenges in achieving robustness, compositionality, and out-of-distribution generalization‚Äù for neural network models, this time in Symbolic Mathematics. from ‚Å¶@YejinChoinka‚Å© lab https://t.co/CdzoIKYvJW"
6312,@GaryMarcus,2021-10-05 19:32:53+00:00,https://twitter.com/GaryMarcus/status/1445472075741757442,"lies, damn lies, and bullshit visualization. terrific essay by @Birdbassador, now available on arXiv."
6313,@GaryMarcus,2021-10-05 15:24:08+00:00,https://twitter.com/GaryMarcus/status/1445409475494563852,"A triumph of innate architecture :) And a stunning video of a mind-blowing 240-year old automaton. 

H/t Doug Hofstadter https://t.co/FHJwx0krK6 via @YouTube"
6314,@GaryMarcus,2021-10-04 17:06:30+00:00,https://twitter.com/GaryMarcus/status/1445072851736805379,"@joedotfaith @roydanroy @josephdviviano absolutely, those are important cross-domain competencies. there will be no single magical master algorithm, but having good machinery for dealing with these sort if things is imperative; that was a central claim of https://t.co/C6XodPts1W"
6315,@GaryMarcus,2021-10-02 19:27:30+00:00,https://twitter.com/GaryMarcus/status/1444383559150604289,"@JohnDRutledge @DFisman thanks! as a scientist, I have serious qualms about @DrBonnieHenry. She was late to appreciate value of masks, late to recognize airborne transmission, &amp;  her comment on children ignores delta. 

She seems more concerned with economics &amp; people‚Äôs anxieties than with their safety."
6316,@GaryMarcus,2021-10-02 16:20:42+00:00,https://twitter.com/GaryMarcus/status/1444336550578475023,@xSerafinii i fear that Horgan would replace her with more of of these same.
6317,@GaryMarcus,2021-10-02 15:52:32+00:00,https://twitter.com/GaryMarcus/status/1444329458966614023,important thread about government-led misinformation in Western Canada.
6318,@GaryMarcus,2021-10-02 14:55:03+00:00,https://twitter.com/GaryMarcus/status/1444314993835532290,"Misinfo is the BC Public Health Office‚Äôs m.o., as @PennyDaflos proved. 

@NewYorkTimes sainted @DrBonnieHenry early in the pandemic, but as @DFisman &amp; @vb_jens etc have repeatedly pointed out, her choices &amp; science have been consistently wrong

I ‚ù§Ô∏è BC but Dr. Henry has got to go"
6319,@GaryMarcus,2021-10-02 05:54:28+00:00,https://twitter.com/GaryMarcus/status/1444178954580107264,"@JHowardBrainMD @JohnDRutledge @DFisman please note also that Henry didn‚Äôt say a little less than influenza; she said unlike influenza. that is not defensible, no matter how you interpret the data (&amp; very hard to defend once you take delta into account)."
6320,@GaryMarcus,2021-10-02 05:53:00+00:00,https://twitter.com/GaryMarcus/status/1444178585321885696,"@DFisman @JohnDRutledge and this study is PRE-delta. and it is clear that Delta has put children at greater risk, in BC as in many other places"
6321,@GaryMarcus,2021-10-01 20:00:56+00:00,https://twitter.com/GaryMarcus/status/1444029587017674754,@mark_riedl i look forward to blurbing it
6322,@GaryMarcus,2021-10-01 16:01:10+00:00,https://twitter.com/GaryMarcus/status/1443969243708526593,"@MadamePratolung @Ted_Underwood @ErnestSDavis i approve of the democratization but certainly don‚Äôt think this is the way to deeper AI, per https://t.co/Pt7HZc3jTF and https://t.co/qwExUL2VLg"
6323,@GaryMarcus,2021-09-30 22:49:10+00:00,https://twitter.com/GaryMarcus/status/1443709533491130400,best thread i have seen on current techniques for treating covid ‚Äì and also a really good advertisement for getting vaccinated.
6324,@GaryMarcus,2021-09-30 16:04:21+00:00,https://twitter.com/GaryMarcus/status/1443607660746530816,Aye. And even less does modern ML have anything to do with what we know about cognitive science and cognitive development.
6325,@GaryMarcus,2021-09-30 14:14:26+00:00,https://twitter.com/GaryMarcus/status/1443579998045032451,"@ChombaBupe a problem that has been around, unsolved, for decades!"
6326,@GaryMarcus,2021-09-30 13:22:47+00:00,https://twitter.com/GaryMarcus/status/1443566999334912005,"@wellingmax @randalljellis it is fine to wish for inspiration but our current understanding of neuroscience is fairly limited and we shouldn‚Äôt count on it. we know many facts but few principles. 

I suspect we will figure out AI before the brain, and need AI‚Äôs help to decipher the brain."
6327,@GaryMarcus,2021-09-29 15:50:41+00:00,https://twitter.com/GaryMarcus/status/1443241830615687171,"Um, no. We are definitely not ""about to hit"" a singularity.

Our real challenge, near term, is not smart AI (which doesn't yet exist) but mindless AI, which already exists, is widespread, and is often problematic."
6328,@GaryMarcus,2021-09-28 19:02:01+00:00,https://twitter.com/GaryMarcus/status/1442927593460699150,@cto_maverick @plevy @luislamb yes. @luislamb @AvilaGarcez and @plevy have all been gracious in pointing to my relevant early work (especially my 2001 book)
6329,@GaryMarcus,2021-09-28 13:15:58+00:00,https://twitter.com/GaryMarcus/status/1442840510301802502,"We now know what we long suspected: the BC Government has been playing games with the numbers. 

‚ÄúB.C. government's systematic withholding of information may serve a political purpose of making B.C.‚Äôs record look better than it is‚Äù https://t.co/O8Hfq1iKIl"
6330,@GaryMarcus,2021-09-27 21:21:52+00:00,https://twitter.com/GaryMarcus/status/1442600400872296456,@paulraphel thank you so much for including me @paulraphel!
6331,@GaryMarcus,2021-09-27 21:21:08+00:00,https://twitter.com/GaryMarcus/status/1442600218319417345,@DrMJoyner @pkedrosky i posted it a few days ago and there is a thread around it
6332,@GaryMarcus,2021-09-27 16:28:27+00:00,https://twitter.com/GaryMarcus/status/1442526561974972418,Oh my Darwin. https://t.co/MQLtY0ncsX
6333,@GaryMarcus,2021-09-27 15:48:05+00:00,https://twitter.com/GaryMarcus/status/1442516402057846792,"@GillTripat @WilliamShatner i only get 1/2 credit as a Canadian, by residence not birth :)"
6334,@GaryMarcus,2021-09-27 14:31:41+00:00,https://twitter.com/GaryMarcus/status/1442497175783497733,"@wellingmax @randalljellis first sentence is a great clarification. last sentence: not sure i follow your double negative. personally, I think it is worth considering what brains do, but that we don‚Äôt yet understand the brain well enough to count on neuroscience in solving the challenges we face in AII."
6335,@GaryMarcus,2021-09-27 14:27:43+00:00,https://twitter.com/GaryMarcus/status/1442496175110721543,@tyrell_turing @neuralreckoning @KordingLab that sounds exactly right: some have a fair bit of support.
6336,@GaryMarcus,2021-09-27 02:18:42+00:00,https://twitter.com/GaryMarcus/status/1442312713502277634,"@tyrell_turing @neuralreckoning we have, at best, some good theories about these things might work, in some contexts.  @KordingLab feel free to jump in."
6337,@GaryMarcus,2021-09-26 23:40:43+00:00,https://twitter.com/GaryMarcus/status/1442272956420218880,"William Shatner, at the age of 90, cutting to the heart of AI. If you haven't already seen our interview, check it out."
6338,@GaryMarcus,2021-09-26 23:11:33+00:00,https://twitter.com/GaryMarcus/status/1442265615083851777,"@ahmetmeleq @wellingmax you had me until here. we will need to build better AI in order to understand the brain, and in the term will learn more from doing good cognitive science rather than through bottom up neuroscience"
6339,@GaryMarcus,2021-09-26 23:09:51+00:00,https://twitter.com/GaryMarcus/status/1442265187290021900,"@ahmetmeleq @wellingmax I concur; humans have intelligence that is significantly more general than that of current machines, but still far from fully general."
6340,@GaryMarcus,2021-09-26 23:07:51+00:00,https://twitter.com/GaryMarcus/status/1442264683994517505,@ahmetmeleq @wellingmax a low bar that hopefully we can eventually exceed ü§∑‚Äç‚ôÇÔ∏è
6341,@GaryMarcus,2021-09-26 23:07:04+00:00,https://twitter.com/GaryMarcus/status/1442264488518897666,"@BlancheMinerva @MadamePratolung @wellingmax @IEEESpectrum the cost of one training run is a fraction of the total $ spent in the pursuit; it ignores for example the salaries of the many authors that contributed to the work, the costs of training for related models that weren‚Äôt published, the work @ Google that set the stage, etc"
6342,@GaryMarcus,2021-09-26 22:52:50+00:00,https://twitter.com/GaryMarcus/status/1442260906415562755,"@wellingmax for sure, it can be done. but possibly with very different architecture than we are currently entertaining."
6343,@GaryMarcus,2021-09-26 20:28:21+00:00,https://twitter.com/GaryMarcus/status/1442224546367504384,@BlancheMinerva @MadamePratolung @wellingmax @IEEESpectrum I too take your point @BlancheMinerva and also agree w @madamepratolung that it is time to consider alternatives.
6344,@GaryMarcus,2021-09-26 19:09:48+00:00,https://twitter.com/GaryMarcus/status/1442204776268111876,@punkstrategy @wellingmax that may well be how history sees it
6345,@GaryMarcus,2021-09-26 17:27:56+00:00,https://twitter.com/GaryMarcus/status/1442179143861346305,@CameronBrick @SMBCComics cute tweet but this definitely more neuropsychology than psychology
6346,@GaryMarcus,2021-09-26 17:24:31+00:00,https://twitter.com/GaryMarcus/status/1442178281508270091,"@dan_biderman @wellingmax sure, absolutely, but the thread was about GPT-7. i totally agree we should be advancing ML in part by looking for better ways to encode inductive bias, and @wellingmax has done some of the most interesting work in that connection."
6347,@GaryMarcus,2021-09-26 17:09:29+00:00,https://twitter.com/GaryMarcus/status/1442174497872748544,@_NicT_ @wellingmax the systems can surely be compressed but that doesn‚Äôt get you to semantics
6348,@GaryMarcus,2021-09-26 15:54:53+00:00,https://twitter.com/GaryMarcus/status/1442155727242547212,@Blackberu @wellingmax it‚Äôs a mistake that extends from that wrong idea. i should write about that
6349,@GaryMarcus,2021-09-26 15:36:37+00:00,https://twitter.com/GaryMarcus/status/1442151127235981320,"Fact that  ""our brains do the job just fine on different hardware"" doesn't mean we can get to AGI by scaling GPT-3, @wellingmax

Humans learn very differently, driven by semantics, leveraging rich prior structure sculpted by evolution.

Brains &amp; GPT have almost nothing in common."
6350,@GaryMarcus,2021-09-26 14:40:53+00:00,https://twitter.com/GaryMarcus/status/1442137101961764865,@yoavgo @wellingmax @IEEESpectrum there are many criticisms to be made; this is a good report on just one of them.
6351,@GaryMarcus,2021-09-26 14:40:01+00:00,https://twitter.com/GaryMarcus/status/1442136885959315458,@wellingmax @IEEESpectrum but with vastly different hardware/firmware/cultureware that is likely organized on very different principles
6352,@GaryMarcus,2021-09-26 00:50:12+00:00,https://twitter.com/GaryMarcus/status/1441928053928587266,"scary how similar BC and Trumplandia have been, in their disrespect for candor and frank data. screenshot is of two tweets, by @tribelaw and @WestcoastBCLife, that just appeared back to back in my feed and hit hard. https://t.co/qUJRvEYF5f"
6353,@GaryMarcus,2021-09-26 00:41:59+00:00,https://twitter.com/GaryMarcus/status/1441925985645907972,@nlpnyc &amp; what could be more symbolic than concatenation? i spent my graduate career arguing with an entire field about whether such operations were psychologically real. the cogsci neural net community argued such things weren‚Äôt necessary and weren‚Äôt essential.
6354,@GaryMarcus,2021-09-26 00:35:35+00:00,https://twitter.com/GaryMarcus/status/1441924373900771332,"@nlpnyc is there anything that could be more symbolic than recursively breaking a text into chunks, with a nonlearned algorithm?"
6355,@GaryMarcus,2021-09-25 22:38:58+00:00,https://twitter.com/GaryMarcus/status/1441895028469682180,@nlpnyc i am sure you can read the paper @nlpnyc
6356,@GaryMarcus,2021-09-25 17:35:05+00:00,https://twitter.com/GaryMarcus/status/1441818553171124224,@tdietterich @IEEESpectrum agreed ‚Äî if that‚Äôs how you are going to try solve the problem
6357,@GaryMarcus,2021-09-25 15:53:34+00:00,https://twitter.com/GaryMarcus/status/1441793006076563461,"To boldly go where no AI has gone before!

An amazing chat with *William Shatner* about the future of #AI. 

A truly special moment in my life; wish my dad were here.  https://t.co/AFWXfmazeM"
6358,@GaryMarcus,2021-09-25 15:46:47+00:00,https://twitter.com/GaryMarcus/status/1441791298080436233,@ibreznik had exactly the same thought
6359,@GaryMarcus,2021-09-25 13:44:56+00:00,https://twitter.com/GaryMarcus/status/1441760634882846731,"@thejimjams this is a deeply misleading headline. 

Report of poll put words in respondents‚Äô mouths that they didn‚Äôt actually say or approve."
6360,@GaryMarcus,2021-09-25 05:33:56+00:00,https://twitter.com/GaryMarcus/status/1441637068149444609,@grbradsk fair point: self-report should never be trusted. particularly when on Page Six.
6361,@GaryMarcus,2021-09-24 23:38:35+00:00,https://twitter.com/GaryMarcus/status/1441547643000295425,"@MuzafferKal_ @michael_muller a fine question. my guess is no, but i would certainly be interested in any evidence to the contrary."
6362,@GaryMarcus,2021-09-24 23:21:57+00:00,https://twitter.com/GaryMarcus/status/1441543458766811146,"Why GPT-6 or 7 may never come. Great essay on ""Deep Learning‚Äôs Diminishing Returns"" ‚Å¶@IEEESpectrum‚Å©  https://t.co/VJDXjBejDZ"
6363,@GaryMarcus,2021-09-24 23:03:01+00:00,https://twitter.com/GaryMarcus/status/1441538693940973570,"@vrandezo if you announce your breakup on Page Six, I think you are kind of soliciting public comment, no?"
6364,@GaryMarcus,2021-09-24 22:45:13+00:00,https://twitter.com/GaryMarcus/status/1441534213996515333,Who knew Elon and Grimes would split before Tesla solved self-driving?
6365,@GaryMarcus,2021-09-24 21:51:59+00:00,https://twitter.com/GaryMarcus/status/1441520817393704965,"@michael_muller come now, ‚Äúnot learned‚Äù is a quote from the paper, and a synonym for innate."
6366,@GaryMarcus,2021-09-24 00:52:33+00:00,https://twitter.com/GaryMarcus/status/1441203871397781504,"@mattturck @gdibner and david pakman left Venrock, also this week"
6367,@GaryMarcus,2021-09-22 23:19:42+00:00,https://twitter.com/GaryMarcus/status/1440818114044706819,"""Can Language Models be Biomedical Knowledge Bases?"" 

The answer, per this new paper, is no. 

https://t.co/7Ey8hctX7I"
6368,@GaryMarcus,2021-09-22 19:58:06+00:00,https://twitter.com/GaryMarcus/status/1440767382507560966,@bodonoghue85 @kylewadegrove @mchammer. see: https://t.co/em9TLcszyM
6369,@GaryMarcus,2021-09-22 17:08:41+00:00,https://twitter.com/GaryMarcus/status/1440724746098724875,@BobGoffer both. it‚Äôs from this paper: https://t.co/Cfl1c4Gbwq
6370,@GaryMarcus,2021-09-22 15:24:46+00:00,https://twitter.com/GaryMarcus/status/1440698593656983553,"the correct answer is ‚Äúyes, but not with current technology‚Äù"
6371,@GaryMarcus,2021-09-21 23:48:12+00:00,https://twitter.com/GaryMarcus/status/1440462898371825664,"Innate (in the sense of developing in the absence of external experience) pretraining, for optic flow."
6372,@GaryMarcus,2021-09-21 22:12:33+00:00,https://twitter.com/GaryMarcus/status/1440438828674654221,"@rcalo ‚ÄúOutside of a dog, a book is a man's best friend. Inside of a dog it's too dark to read.‚Äù"
6373,@GaryMarcus,2021-09-21 15:35:18+00:00,https://twitter.com/GaryMarcus/status/1440338857384288258,@shiraeis @kylemarieb metrics?
6374,@GaryMarcus,2021-09-21 15:07:00+00:00,https://twitter.com/GaryMarcus/status/1440331735816814607,"@kylemarieb @shiraeis i personally would never trust GPT on its own for anything high stakes. even with lots of examples, there will always be outliers, and the whole thing is superficial."
6375,@GaryMarcus,2021-09-21 14:46:51+00:00,https://twitter.com/GaryMarcus/status/1440326664798425089,"@shiraeis i would be wary eg of the customer service apps, or anything where there is a serious cost for error. i am sure you have seen this example: https://t.co/dtXDM8vC5o"
6376,@GaryMarcus,2021-09-21 14:34:09+00:00,https://twitter.com/GaryMarcus/status/1440323468554162182,"@shiraeis but that itself is a consequence of the hype. the proper place for GPT is chitchat, but the coordinating marketing has led to a lot of unreasonable aspirations that need to be evaluated"
6377,@GaryMarcus,2021-09-21 14:13:50+00:00,https://twitter.com/GaryMarcus/status/1440318354141564929,@shiraeis it‚Äôs only surprising relative to the hype.
6378,@GaryMarcus,2021-09-21 01:12:08+00:00,https://twitter.com/GaryMarcus/status/1440121635034464263,"2016: Mark Zuckerberg rejects ‚Äúnotion that fake news on Facebook influenced the outcome of the US election, describing it as a ‚Äúpretty crazy idea‚Äù""

2021: Zuckerberg rejects notion that he cut a deal with Donald Trump, calls it ""pretty ridiculous"" https://t.co/XWKHvxlhz5"
6379,@GaryMarcus,2021-09-20 15:03:26+00:00,https://twitter.com/GaryMarcus/status/1439968451225812997,"is the jig for GPT up yet? here are two new reports of what happens when you take it beyond chit chat: ""GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain"": https://t.co/saLOecDzLL

and, no surprise, they write buggy code: https://t.co/IdPZ0mtmLj"
6380,@GaryMarcus,2021-09-19 22:49:19+00:00,https://twitter.com/GaryMarcus/status/1439723306064613376,". @kaifulee's new book, #AI2041 is terrific, and I am thrilled to get a chance to discuss it with him in a few minutes (4pm PT), @Clubhouse."
6381,@GaryMarcus,2021-09-18 14:48:22+00:00,https://twitter.com/GaryMarcus/status/1439239881796980738,@peachblvd Vancouver BC https://t.co/liJxP9oOOO
6382,@GaryMarcus,2021-09-18 14:03:33+00:00,https://twitter.com/GaryMarcus/status/1439228602772455432,@j_mcelroy unvaccinated kids 0-9 are up 12.4% in a single week. it‚Äôs too early to say whether that‚Äôs significant or not.
6383,@GaryMarcus,2021-09-17 18:59:29+00:00,https://twitter.com/GaryMarcus/status/1438940689660723201,"Truly damning: Facebook repeatedly ""employs teams of people to study its own ugly underbelly, only to ignore, downplay and suppress the results of their research when it proves awkward or troubling"" https://t.co/cnEuVAaCze"
6384,@GaryMarcus,2021-09-16 19:39:40+00:00,https://twitter.com/GaryMarcus/status/1438588414572572677,"@nathalie_k1 @bcndp @CDCofBC minimize now, pay more later."
6385,@GaryMarcus,2021-09-16 02:29:26+00:00,https://twitter.com/GaryMarcus/status/1438329148729016321,"BC‚Äôs public health experts are indeed dangerously out of touch with science.  The latest nonsense--about withholding vaccines from younger children--is next-level, and risks causing needless and serious  harm to children, teachers, and parents. 

We must speak out."
6386,@GaryMarcus,2021-09-16 02:21:18+00:00,https://twitter.com/GaryMarcus/status/1438327100021248000,"@lcastricato @DanTrueTech @irinarish @sama @JaredKaplan a blind child knows more about language than GPT-3 will ever know. see Landau and Gleitman‚Äôs classic book, summarized briefly here:

https://t.co/DWa2iQMGMa"
6387,@GaryMarcus,2021-09-16 00:13:05+00:00,https://twitter.com/GaryMarcus/status/1438294834817630208,@rebecca_saxe it is appalling that such measures were required.
6388,@GaryMarcus,2021-09-15 23:55:11+00:00,https://twitter.com/GaryMarcus/status/1438290329166233600,@irinarish @DanTrueTech @sama @JaredKaplan I mentioned work by @AllysonEttinger. don‚Äôt know if it‚Äôs been tried on GPT-3
6389,@GaryMarcus,2021-09-15 13:40:10+00:00,https://twitter.com/GaryMarcus/status/1438135556358037509,@danielleboccell more like anticipation. read this from 2016 to see how good my track record is: https://t.co/eLbmoHoQhm
6390,@GaryMarcus,2021-09-14 20:18:42+00:00,https://twitter.com/GaryMarcus/status/1437873461360164865,@ethancaballero thanks! added to my todo list.
6391,@GaryMarcus,2021-09-14 20:17:24+00:00,https://twitter.com/GaryMarcus/status/1437873133294215172,@ethancaballero can you remind the source on the figure? an OpenAI paper if i recall.
6392,@GaryMarcus,2021-09-14 20:16:49+00:00,https://twitter.com/GaryMarcus/status/1437872988011991042,"@ethancaballero common argument, but doesn't make it true. might be time for me to write a piece explaining why..."
6393,@GaryMarcus,2021-09-14 20:07:55+00:00,https://twitter.com/GaryMarcus/status/1437870749180514305,@shiraeis GPT-3 can play the part of Jim Jones: https://t.co/YEFZZNTHuq
6394,@GaryMarcus,2021-09-14 20:05:49+00:00,https://twitter.com/GaryMarcus/status/1437870218500395011,a joke that nicely captures the delusion of mainstream AI as it was in the early 2020‚Äôs:
6395,@GaryMarcus,2021-09-14 00:57:08+00:00,https://twitter.com/GaryMarcus/status/1437581143692374021,Interesting interview on some thorny questions in semantics with Paul Pietroski https://t.co/rAumlqwqeT
6396,@GaryMarcus,2021-09-13 20:02:57+00:00,https://twitter.com/GaryMarcus/status/1437507111856926720,"@EvaSmartAI @bimedotcom @edge @andi_staub @sallyeaves @Shi4Tech @mvollmer1 @nigewillson @enilev @Ym78200 @Nicochan33 @gerald_bader @tlloydjones @Corix_JC @MikeNashTech @WhiteheartVic @pierrepinna @BetaMoroney @tobiaskintzel @MiriamAsensi @MariaFariello1 @RLDI_Lamy @Analytics_699 wow i just looked this link, figuring it was a reprint of yesterday‚Äôs article @gradientpub. 

instead i this is from 2016 and dead on as a description of 2021 despite all the massive investments and improvements in computation."
6397,@GaryMarcus,2021-09-13 15:44:03+00:00,https://twitter.com/GaryMarcus/status/1437441954657148934,"@rao2z @Google One year‚Äôs gold rush is the next year‚Äôs ghost town ü§£ 

also: a: AlphaFold2 may prove extremely useful. b: Embeddings are great for synonymy but I don‚Äôt think Google has replaced the whole pipeline with them. lots of classical AI still critical for search AFAIK"
6398,@GaryMarcus,2021-09-13 14:03:39+00:00,https://twitter.com/GaryMarcus/status/1437416690728386565,"Agreed, @rao2z, shallow but broad is valid for many purposes (eg recommendation, photo tagging,  rough translation, etc). 

But we won't get to general AI that way.

What I keep stressing is that we need greater conceptual depth for *reliability* and *trustworthy* reasoning."
6399,@GaryMarcus,2021-09-12 23:42:10+00:00,https://twitter.com/GaryMarcus/status/1437199890602397696,"@RWerpachowski @MadamePratolung @yoavgo @emilymbender the language chapter of https://t.co/C6XodPbRao gives a ton of examples, written pre GPT-2. you can see whether any have since been handled. some more examples in the chapter on common sense."
6400,@GaryMarcus,2021-09-12 20:51:28+00:00,https://twitter.com/GaryMarcus/status/1437156934046605322,@titudeadjust done
6401,@GaryMarcus,2021-09-12 02:09:43+00:00,https://twitter.com/GaryMarcus/status/1436874636160028678,@emilymbender fixed
6402,@GaryMarcus,2021-09-12 01:24:27+00:00,https://twitter.com/GaryMarcus/status/1436863245013426177,"@emilymbender will fix, and not sure how that slipped through."
6403,@GaryMarcus,2021-09-11 20:10:56+00:00,https://twitter.com/GaryMarcus/status/1436784342357921798,@jmugan @thiteanish @jackclarkSF these are indeed interesting and I agree that anything that tries to better leverage explicit symbolic knowledge is a step in the right direction
6404,@GaryMarcus,2021-09-11 00:07:45+00:00,https://twitter.com/GaryMarcus/status/1436481555321470976,amazing that this even needs to be said.
6405,@GaryMarcus,2021-09-10 20:18:38+00:00,https://twitter.com/GaryMarcus/status/1436423894471110657,"Castles made of sand? Ernie Davis and I examine the latest rage in AI, so-called ""Foundation"" models, tomorrow (Saturday) @gradientpub. 

Watch this space for a link."
6406,@GaryMarcus,2021-09-05 23:22:13+00:00,https://twitter.com/GaryMarcus/status/1434658155603144708,@HappyAar @MattNiessner https://t.co/C6XodPbRao
6407,@GaryMarcus,2021-09-05 23:05:18+00:00,https://twitter.com/GaryMarcus/status/1434653897377861635,"@HappyAar @MattNiessner ‚Äúconpletely fails‚Äù is your words, not mine or @MattNiessner‚Äôs. if you are genuinely interested, Ernie Davis and I have a long discussion of the difference between translation &amp; language understanding in Rebooting AI, + many examples of failure at language understanding."
6408,@GaryMarcus,2021-09-05 16:02:06+00:00,https://twitter.com/GaryMarcus/status/1434547397573627909,"@jryandx @bradpwyble well, no. the system as such probably doesn‚Äôt know anything about taxonomy and it apparently is picking different ‚Äúbest answers‚Äù in a way that it at least partly tied to race. 

extending @bradeyble‚Äôs point, ‚Äúprimate and human‚Äù for all humans would be fine."
6409,@GaryMarcus,2021-09-04 22:50:15+00:00,https://twitter.com/GaryMarcus/status/1434287720629739523,@yudapearl @Montreal_AI happy birthday! üéâ
6410,@GaryMarcus,2021-09-04 21:43:22+00:00,https://twitter.com/GaryMarcus/status/1434270892717117445,no words https://t.co/paAoTKmCOW
6411,@GaryMarcus,2021-08-27 02:35:21+00:00,https://twitter.com/GaryMarcus/status/1431082881376342018,outstanding and important thread by @emilymbender on how hype around ‚Äúlarge language models‚Äù is pushing out other research that is badly needed.
6412,@GaryMarcus,2021-08-26 01:24:47+00:00,https://twitter.com/GaryMarcus/status/1430702734496256006,@rao2z @filippie509 though it may get old the 10th time you ask TBot not to put the cat in the dishwasher.
6413,@GaryMarcus,2021-08-25 23:23:05+00:00,https://twitter.com/GaryMarcus/status/1430672108653142018,@rao2z @filippie509 it‚Äôs the unbidden ones that frighten me.
6414,@GaryMarcus,2021-08-25 20:36:21+00:00,https://twitter.com/GaryMarcus/status/1430630148643069953,@filippie509 i didn‚Äôt want to dignify the nonsense.
6415,@GaryMarcus,2021-08-14 19:57:39+00:00,https://twitter.com/GaryMarcus/status/1426634141068627969,"my 1993 dissertation was (partly) about some surprising challenges that neural networks models faced in generalizing linguistic morphology. @rtsarfaty and @omerNLP show that morphology remains harder than it looks. 

h/t @ryandcotterell, with arxiv link below"
6416,@GaryMarcus,2021-08-13 11:55:16+00:00,https://twitter.com/GaryMarcus/status/1426150359110758402,@DrMJoyner @zakkohane @DavidEpstein @cragcrest fascinating article!
6417,@GaryMarcus,2021-08-13 11:50:01+00:00,https://twitter.com/GaryMarcus/status/1426149038227865601,@MaxALittle exactly as expected
6418,@GaryMarcus,2021-08-13 11:49:22+00:00,https://twitter.com/GaryMarcus/status/1426148872062177280,"@cHHillee @OpenAI which is to say they stacked the deck towards what it could do, making it less representative of real world coding?"
6419,@GaryMarcus,2021-08-11 23:00:38+00:00,https://twitter.com/GaryMarcus/status/1425593028060745728,"@kevin_nejad @mervenoyann @_arohan_ @OpenAI did you *use* it, or just watch a carefully produced demo?"
6420,@GaryMarcus,2021-08-11 21:48:24+00:00,https://twitter.com/GaryMarcus/status/1425574848886034437,@aricaroline fair question; too early to tell.
6421,@GaryMarcus,2021-08-11 21:23:27+00:00,https://twitter.com/GaryMarcus/status/1425568569329295363,@aricaroline time will tell. i think the stakes with programming can sometimes be higher. let hope that nuclear power plants don't trust Codex-written code.
6422,@GaryMarcus,2021-08-11 20:26:13+00:00,https://twitter.com/GaryMarcus/status/1425554166978539522,"@nlpnyc @OpenAI also your premise is false. i called codex ‚Äúamazing‚Äù in the very thread you are responding to, tweet #2."
6423,@GaryMarcus,2021-08-11 20:16:15+00:00,https://twitter.com/GaryMarcus/status/1425551657111232517,"@Moha__niang @OpenAI @elonmusk glad he finally joined the skeptics club, after many years of underestimating the difficult of level 5 driving."
6424,@GaryMarcus,2021-08-11 19:57:01+00:00,https://twitter.com/GaryMarcus/status/1425546820147507202,"@nlpnyc @OpenAI I agree that it will be interesting to see how it is adopted into programmer's workflow, after the novelty wears off.  NB right now it isn't (yet?) 95% useful code, 3/4 relatively easy problems with properly written units tests elicited n&gt;=1 adequate solutions, in many attempts."
6425,@GaryMarcus,2021-08-11 18:07:33+00:00,https://twitter.com/GaryMarcus/status/1425519268280487936,"It would be ironic indeed if the company that was formed as a nonprofit around AI safety got rich making the world's least reliable, hence most dangerous, programming tools."
6426,@GaryMarcus,2021-08-11 17:46:26+00:00,https://twitter.com/GaryMarcus/status/1425513956056047619,"What do I think of @OpenAI's new 1st grade math video?

No published results, no peer review. We don't know what the training set is, what the accuracy is, nor how robust results would be to slight changes in wording.

PR ‚â† Science

3/3"
6427,@GaryMarcus,2021-08-11 17:46:26+00:00,https://twitter.com/GaryMarcus/status/1425513955313602563,"OpenAI #Codex livestream worked because execs pre-tested &amp; knew what Codex is good for (bite-sized tasks), steering clear of what it is weak at (understanding programming task as a whole). 

Codex is amazing, but like current self-driving systems, it may never be reliable. 

2/3"
6428,@GaryMarcus,2021-08-11 17:46:25+00:00,https://twitter.com/GaryMarcus/status/1425513953291952128,". @OpenAI's #Codex is to programming as Tesla's FSD 2021 is to driving.

Read the paper (esp Appendix B) carefully and you will realize there is a gap between the slick videos &amp; reality: it is often correct on simple tasks, but frequently lost on more complex challenges. 

1/3 https://t.co/9VNRIj1wYw"
6429,@GaryMarcus,2021-08-11 16:21:22+00:00,https://twitter.com/GaryMarcus/status/1425492546604568577,"Great takedown of a dubious and oversold #ivermectin review, by @GidMK"
6430,@GaryMarcus,2021-08-11 13:53:29+00:00,https://twitter.com/GaryMarcus/status/1425455334097784835,"üéµThere must be 50 ways to fool your automated driver üéµ

Just slip out the back, Jack
Take your hand of the wheel, Neal

and watch your car ‚Ä¶ crash"
6431,@GaryMarcus,2021-08-10 00:07:25+00:00,https://twitter.com/GaryMarcus/status/1424885056036773915,"@AIHammer @katiepatrick watch the video in the tweet of hers that i shared, atop this thread"
6432,@GaryMarcus,2021-08-09 19:42:20+00:00,https://twitter.com/GaryMarcus/status/1424818348357914632,"Stop all the clocks; the great Lila Gleitman is gone

People in AI may not know her work, but it should be essential reading for anyone trying to understand how any creature could learn a language

A nice summary in her own words, written as she turned 90: https://t.co/ORQ9wJgMxp"
6433,@GaryMarcus,2021-08-09 18:13:30+00:00,https://twitter.com/GaryMarcus/status/1424795993707487233,"@katiepatrick add me to to the list, please"
6434,@GaryMarcus,2021-08-06 16:50:30+00:00,https://twitter.com/GaryMarcus/status/1423687939209453570,@jana_thorn @adriandix @jjhorgan this is terrible. i hope that @PennyDaflos @RenuBakshi and @realreporter will look into it.
6435,@GaryMarcus,2021-08-06 15:42:35+00:00,https://twitter.com/GaryMarcus/status/1423670849610059776,I ‚ù§Ô∏è British Columbia https://t.co/2HMSDqd8MI
6436,@GaryMarcus,2021-08-04 23:03:47+00:00,https://twitter.com/GaryMarcus/status/1423057103896211457,"@erikphoel synonyms are GPT‚Äôs forte (via word embeddings). then again Roget‚Äôs thesaurus and a 1-line classical program could handle this, too."
6437,@GaryMarcus,2021-08-04 20:31:19+00:00,https://twitter.com/GaryMarcus/status/1423018735946764290,"the three inevitabilities: death, taxes, and the use of passive voice to evade responsibility"
6438,@GaryMarcus,2021-08-04 20:04:50+00:00,https://twitter.com/GaryMarcus/status/1423012069960417283,"important thread by @Bob_Wachter on how Delta is changing everything.

attached image is mid-thread but a good summary."
6439,@GaryMarcus,2021-08-04 13:31:41+00:00,https://twitter.com/GaryMarcus/status/1422913130133221376,"@ricardobalk wow, what kind of algorithm made that recommendation?"
6440,@GaryMarcus,2021-08-02 19:35:01+00:00,https://twitter.com/GaryMarcus/status/1422279789436489728,@mervenoyann so sorry and glad that you are cat are ok.
6441,@GaryMarcus,2021-08-02 02:24:22+00:00,https://twitter.com/GaryMarcus/status/1422020421142999046,"@BlancheMinerva @eleuther @huggingface @LakeBrenden but i will have a thought about what fun things could be done with your adaptations, where presumably we could analyze output relative to a more open training set."
6442,@GaryMarcus,2021-08-02 02:23:21+00:00,https://twitter.com/GaryMarcus/status/1422020163948322817,"@BlancheMinerva @eleuther @huggingface @LakeBrenden thanks. the issue is that we aren't told (for GPT-3) what is in the training set (except at a very abstract level), so it is hard to distinguish generalization from regurgitation."
6443,@GaryMarcus,2021-08-01 01:16:13+00:00,https://twitter.com/GaryMarcus/status/1421640879371079680,"@chazfirestone i know, because you are in @elonmusk‚Äôs simulation of me."
6444,@GaryMarcus,2021-07-31 23:50:09+00:00,https://twitter.com/GaryMarcus/status/1421619222556332049,"@chazfirestone stuck inside a hydraulic fax machine, inside a reality simulator?"
6445,@GaryMarcus,2021-07-31 20:33:20+00:00,https://twitter.com/GaryMarcus/status/1421569689130504192,@ChomskyDigital @WiringTheBrain and @ProfSimonFisher are busy people but you could try them if you have a specific question.
6446,@GaryMarcus,2021-07-30 15:52:15+00:00,https://twitter.com/GaryMarcus/status/1421136565389209600,"@rgblong partial credit?
a. they added more innate structure to AlphaZero to get the result.
b. still used very different architecture for protein folding. 
c. @ptsividis got far more efficient Atari results in 2021 arXiv using more innate structure. 
letter of my prediction ‚ùé
spirit ‚úÖ"
6447,@GaryMarcus,2021-07-30 15:46:10+00:00,https://twitter.com/GaryMarcus/status/1421135036515069959,"@artificialnix @rgblong got evidence for that? i have been making essentially the same argument for 30 years, the core of which - the challenges in out of domain generalization -  now become received wisdom."
6448,@GaryMarcus,2021-07-30 05:45:49+00:00,https://twitter.com/GaryMarcus/status/1420983951619919872,"@tejasdkulkarni @ylecun @OriolVinyalsML symbols may be late in human evolution but they are critical to our cognitive niche. 

i refer you to your colleague @ptsividis‚Äôs new paper for an example of how adding the right symbols to RL can be a game changer."
6449,@GaryMarcus,2021-07-28 16:28:23+00:00,https://twitter.com/GaryMarcus/status/1420420882585907200,"Terrific new paper by Pedro Tsividis,  @gershbrain and others, in which symbolic, knowledge rich, model-based RL crushes pure deep RL. 

Looks good for the predictions I made in 2020 in The Next Decade in AI."
6450,@GaryMarcus,2021-07-22 21:29:11+00:00,https://twitter.com/GaryMarcus/status/1418322254937477126,"@MaxALittle @SMBrocklehurst as you probably know baker lab (UW) has results almost as good, published same time, w much less attention."
6451,@GaryMarcus,2021-07-22 19:19:51+00:00,https://twitter.com/GaryMarcus/status/1418289708887511041,excellent thread
6452,@GaryMarcus,2021-07-22 00:10:28+00:00,https://twitter.com/GaryMarcus/status/1418000455192387586,"neural networks aren‚Äôt fit for natural language understanding ‚Äì ‚Å¶@bendee983‚Å© on new book by Mcshane &amp; Nirenberg, consistent w what Ernest Davis and I have been arguing. https://t.co/EvtxUHbJ7x"
6453,@GaryMarcus,2021-07-21 03:16:09+00:00,https://twitter.com/GaryMarcus/status/1417684797317468168,@yudapearl so sorry to hear the news.
6454,@GaryMarcus,2021-07-21 00:21:49+00:00,https://twitter.com/GaryMarcus/status/1417640925543628800,"""Videos of FSD beta 9 in action don‚Äôt show a system that makes driving safer or even less stressful,‚Äù says Jake Fisher ... ‚ÄúConsumers are simply paying to be test engineers for developing technology without adequate safety protection.‚Äù

https://t.co/ulxlRlMumu"
6455,@GaryMarcus,2021-07-18 13:58:05+00:00,https://twitter.com/GaryMarcus/status/1416759179965046789,@AmineKorchiMD @ArashVahdat @suzatweet from Cypress Mountain (where i was snowboarding)
6456,@GaryMarcus,2021-07-18 04:23:19+00:00,https://twitter.com/GaryMarcus/status/1416614538032648196,@ArashVahdat @suzatweet +1 for Vancouver.  i took this photo &lt; 1 hour from downtown: https://t.co/vxTf6bpJpC
6457,@GaryMarcus,2021-07-17 14:43:49+00:00,https://twitter.com/GaryMarcus/status/1416408302657970182,"@GeorgiaChal &amp; don‚Äôt forget reasoning, knowledge, world models, and other bits of cognitive goodness, too."
6458,@GaryMarcus,2021-07-17 04:43:01+00:00,https://twitter.com/GaryMarcus/status/1416257107373051910,"powerful thread, re Danish Siddiqui. If you don‚Äôt know who he is, read it. If you, read it."
6459,@GaryMarcus,2021-07-17 02:48:57+00:00,https://twitter.com/GaryMarcus/status/1416228399513751554,"october 2019: @openAI trumpets Rubik‚Äôs cube demo as major progress (‚Äòreinforcement learning isn‚Äôt just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.‚Äô)

july 2021: @openAI shuts down their robotics division."
6460,@GaryMarcus,2021-07-15 19:42:23+00:00,https://twitter.com/GaryMarcus/status/1415758662384033793,"@chaloelikesthis @berilsirmacek The Smurfs made it eventually, and smarter AI will someday arrive. 

Godot, maybe never."
6461,@GaryMarcus,2021-07-10 17:53:35+00:00,https://twitter.com/GaryMarcus/status/1413919341850943491,@PaulTopping @HemangPurohit i certainly don‚Äôt agree with that part
6462,@GaryMarcus,2021-07-07 15:47:53+00:00,https://twitter.com/GaryMarcus/status/1412800546176598017,@IntuitMachine @WiringTheBrain @peremayol precisely!
6463,@GaryMarcus,2021-07-05 16:33:16+00:00,https://twitter.com/GaryMarcus/status/1412087192436969472,@IntuitMachine @Plinz agree w @intuitMachine - Turing Completeness says nothing about learning.
6464,@GaryMarcus,2021-07-05 16:22:47+00:00,https://twitter.com/GaryMarcus/status/1412084554261696516,"@bpshashi1 @HakanErdoganPhD @ylecun humans, even infants, do something really different: https://t.co/5iTwf5lpei and review in The  Algebraic Mind plus later work by Berent and Marcus"
6465,@GaryMarcus,2021-07-05 12:46:01+00:00,https://twitter.com/GaryMarcus/status/1412030004255498242,"@chrisantha_f @ylecun see my 1999 Science article, 2001 book The Algebraic Mind, and articles in Cognition with Iris Berent"
6466,@GaryMarcus,2021-07-04 22:21:14+00:00,https://twitter.com/GaryMarcus/status/1411812372570906627,@MNWH @Plinz lots of ‚Äòem
6467,@GaryMarcus,2021-07-04 22:11:06+00:00,https://twitter.com/GaryMarcus/status/1411809821951762440,@Plinz @yaobviously @yudapearl there may well be room for unification but i would not put my money on emergence
6468,@GaryMarcus,2021-07-04 22:09:21+00:00,https://twitter.com/GaryMarcus/status/1411809383915339776,@Plinz @yaobviously @yudapearl nor am i
6469,@GaryMarcus,2021-07-04 21:50:41+00:00,https://twitter.com/GaryMarcus/status/1411804684692733954,"@Plinz @yaobviously i was complaining about curve fitting since before Chollet was born, but @yudapearl says it better.

when you ask for something that can‚Äôt be formalized with current tools, you ought lower your expectations. 

or surprise us all, &amp; do the work yourself rather than throwing stones"
6470,@GaryMarcus,2021-07-04 21:26:59+00:00,https://twitter.com/GaryMarcus/status/1411798721134727169,@titudeadjust @_barra_o mostly harmless. mostly.
6471,@GaryMarcus,2021-07-04 21:09:30+00:00,https://twitter.com/GaryMarcus/status/1411794319305027591,"@Plinz @95thoughts gradient descent can be seen as a fallback, when don‚Äôt have a good innate prior üòÇ"
6472,@GaryMarcus,2021-07-04 21:01:09+00:00,https://twitter.com/GaryMarcus/status/1411792218696962055,"@robinc not in the general case that is described in the algebraic mind, viz universally quantified one-to-one mappings. but yes in certain specific cases, the innate prior of convolution does well"
6473,@GaryMarcus,2021-07-04 20:50:40+00:00,https://twitter.com/GaryMarcus/status/1411789582291640340,@_barra_o ha ha. all geological formations adapt :)
6474,@GaryMarcus,2021-07-04 20:37:12+00:00,https://twitter.com/GaryMarcus/status/1411786191050059777,"@vo_d_p read my 1999 Science paper on infant rule learning, and compare."
6475,@GaryMarcus,2021-07-04 19:50:03+00:00,https://twitter.com/GaryMarcus/status/1411774326962073602,@peremayol @WiringTheBrain evidence for this claim?
6476,@GaryMarcus,2021-07-04 19:49:20+00:00,https://twitter.com/GaryMarcus/status/1411774147466829831,@AndrewLampinen prediction: it will come but it will take years; statistical approximation is the hare that will eventually lose to the tortoise.
6477,@GaryMarcus,2021-07-04 19:46:16+00:00,https://twitter.com/GaryMarcus/status/1411773372971814917,"@AndrewLampinen @recursus @FelixHill84 but they don‚Äôt great job of rapidly incorporating discrete information, so as to update internal cognitive models (as discussed in my Next Decade arXiv)"
6478,@GaryMarcus,2021-07-04 19:44:48+00:00,https://twitter.com/GaryMarcus/status/1411773005555015684,"agreed; needless polarization has really undermined people‚Äôs understanding of the way innateness and learning work togetherness (btw. this is what my 2004 book The Birth of The Mind, was about)"
6479,@GaryMarcus,2021-07-04 19:42:43+00:00,https://twitter.com/GaryMarcus/status/1411772479547248640,@robinc glad you like the critiques. but i am with @yudapearl in seeing a lot of current function approximation as a kind of curve fitting that isn‚Äôt getting us towards deeper understanding.
6480,@GaryMarcus,2021-07-04 18:38:51+00:00,https://twitter.com/GaryMarcus/status/1411756406072614913,Bingo!
6481,@GaryMarcus,2021-07-04 18:27:45+00:00,https://twitter.com/GaryMarcus/status/1411753615685980162,"@KL_Div @ylecun and yet humans have no trouble drawing such generalizations; see eg Marcus et al, 1999, Science experiments with infants."
6482,@GaryMarcus,2021-07-04 18:26:10+00:00,https://twitter.com/GaryMarcus/status/1411753217172639753,"@HolgerHoos indeed, there is an important review paper to write summarizing why extrapolation is key and how people are trying to address it."
6483,@GaryMarcus,2021-07-04 18:22:19+00:00,https://twitter.com/GaryMarcus/status/1411752249127227395,"it‚Äôs not zero-sum. 

more innateness = better learning"
6484,@GaryMarcus,2021-07-04 18:19:40+00:00,https://twitter.com/GaryMarcus/status/1411751580915929090,@SarvagyaGupta i discussed this (20 years ago!) in The Algebraic Mind
6485,@GaryMarcus,2021-07-04 18:17:41+00:00,https://twitter.com/GaryMarcus/status/1411751082263560193,@robinc it‚Äôs not a straw man it‚Äôs crystallized illustration.
6486,@GaryMarcus,2021-07-04 03:04:19+00:00,https://twitter.com/GaryMarcus/status/1411521225403338752,"@ChrisGPotts that was intended to illustrate the conceptual distinction and its relation to high dimensionality, not to exhaust the complex universe of discussion :)"
6487,@GaryMarcus,2021-07-04 00:30:43+00:00,https://twitter.com/GaryMarcus/status/1411482570492157962,"@ChrisGPotts that‚Äôs too strong. you had a partial solution to some toy examples, but nobody has a real world solution to complex domains like natural language understand or driverless cars. sometimes distributed representations with real world data can help you cover the space, sometimes not."
6488,@GaryMarcus,2021-07-03 19:08:41+00:00,https://twitter.com/GaryMarcus/status/1411401527181418498,"The good news is that Yoshua Bengio has begun to recognize the foundational nature of this challenge of extrapolation (he calls it ""out of distribution generalization:). 

The rest of the field would do well to follow his lead.
(9)"
6489,@GaryMarcus,2021-07-03 19:08:40+00:00,https://twitter.com/GaryMarcus/status/1411401525210062849,"*Because the training set is not publicly available, it is not possible to test this conjecture directly. @eleuther or @huggingface might want to give it a shot with their GPT+like models. (8/9) cc @LakeBrenden who has valuable, related evidence."
6490,@GaryMarcus,2021-07-03 19:08:40+00:00,https://twitter.com/GaryMarcus/status/1411401523410747397,"Systems like GPT-3 behave erratically, I conjecture, precisely because some test items are far in n-dimensional space from the training set, hence not solvable with interpolation; failures occur when extrapolation is required. (7/9)"
6491,@GaryMarcus,2021-07-03 19:08:39+00:00,https://twitter.com/GaryMarcus/status/1411401520919220226,"Again, you will find some interpolation to withheld even numbers,  but you still won't get reliable extrapolation to odd numbers. (6/9)"
6492,@GaryMarcus,2021-07-03 19:08:38+00:00,https://twitter.com/GaryMarcus/status/1411401515416367105,"There are any number fo workarounds to this.

But adding more dimensions per se does not help. Try for example to train the neural net on a randomlly drawn subset of the even numbers up to 2^16.Or 2^256, if you like. (5/9)"
6493,@GaryMarcus,2021-07-03 19:08:38+00:00,https://twitter.com/GaryMarcus/status/1411401513335992332,"What you will find is that the network can often interpolate ‚Äì generalizing from some set of even numbers to some other even numbers, but never reliably extrapolate to odd numbers, which lie outside the trading space. (4/9)"
6494,@GaryMarcus,2021-07-03 19:08:37+00:00,https://twitter.com/GaryMarcus/status/1411401511473664011,"Train a basic multilayer perceptron on the identity function (ie mulltiplying the input  times one) on a random subset of 10% of the the even numbers, from 2 to 1024, representing each number as a standard distributed representation of nodes encoding binary digits. (3/9)"
6495,@GaryMarcus,2021-07-03 19:08:37+00:00,https://twitter.com/GaryMarcus/status/1411401509682753538,"Let's start with a simple example drawn from my 2001 book The Algebraic Mind, that anyone can try at home:  (2/9)"
6496,@GaryMarcus,2021-07-03 18:09:47+00:00,https://twitter.com/GaryMarcus/status/1411386705932914692,". @missy_cummings and I have been trying to tell you this for years, @elonmusk."
6497,@GaryMarcus,2021-07-01 02:51:56+00:00,https://twitter.com/GaryMarcus/status/1410430943588872192,@unixpickle the model‚Äôs only intention is to predict what is likely to come next in a sequence of sentences. lies and truths are beyond its reckoning.
6498,@GaryMarcus,2021-07-01 00:46:43+00:00,https://twitter.com/GaryMarcus/status/1410399434928640006,The Great American Novel Will Not be Written by a Computer | Mind Matters https://t.co/8ULIVU0BM9
6499,@GaryMarcus,2021-06-28 13:24:27+00:00,https://twitter.com/GaryMarcus/status/1409502960900579329,@TheScottLove @yudapearl @eric_lander @iraflatow @robertlufkinmd i tweeted about this in January 2020; it‚Äôs great work.
6500,@GaryMarcus,2021-06-22 12:20:38+00:00,https://twitter.com/GaryMarcus/status/1407312572466925573,@DrMJoyner @CMichaelGibson @venkmurthy @statnews @mer__edith @karaswisher @MaxALittle @DrHughHarvey @DrLukeOR
6501,@GaryMarcus,2021-06-17 17:31:02+00:00,https://twitter.com/GaryMarcus/status/1405578748276056064,@Love2Code üíØ
6502,@GaryMarcus,2021-06-17 14:18:32+00:00,https://twitter.com/GaryMarcus/status/1405530302466859011,"‚ÄúA popular explanation of the human ability for physical reasoning is that it depends on a sophisticated ability to perform mental simulations.‚Äù

But is that explanation correct?  

3 new experiments raise important challenges.  https://t.co/EK5FbwdhzA"
6503,@GaryMarcus,2021-06-15 02:55:01+00:00,https://twitter.com/GaryMarcus/status/1404633513517744129,@AriKatz20 @TaliaRinger absolutely. see eg my arXiv The Next Decade in AI
6504,@GaryMarcus,2021-06-10 03:13:17+00:00,https://twitter.com/GaryMarcus/status/1402826174737256453,"@liweijianglw @ABosselut @_csBhagav @YejinChoinka 624k if-then rules,@YejinChoinka!"
6505,@GaryMarcus,2021-06-09 15:40:29+00:00,https://twitter.com/GaryMarcus/status/1402651822142083073,@berilsirmacek ü§£
6506,@GaryMarcus,2021-06-09 13:27:32+00:00,https://twitter.com/GaryMarcus/status/1402618367232466948,@jrking0 would it be wrong to instead say that predictability captures 10% of the variance in your measure of understanding?
6507,@GaryMarcus,2021-06-08 19:32:41+00:00,https://twitter.com/GaryMarcus/status/1402347870401880064,"""Hundreds of studies flooded onto preprint servers &amp; into medical journals claiming to demonstrate AI‚Äôs ability... Many months later a research team from the University of Cambridge...reached...different conclusion: Every single one was fatally flawed. "" https://t.co/j3hbwenpGA"
6508,@GaryMarcus,2021-06-05 16:57:59+00:00,https://twitter.com/GaryMarcus/status/1401221776479338499,@Abel_TorresM @MLStreetTalk @luislamb we absolutely are pre-newtonian in our AI
6509,@GaryMarcus,2021-06-03 21:21:00+00:00,https://twitter.com/GaryMarcus/status/1400563192523223044,@kerstingAIML @welt and see https://t.co/nj4tAJwVHT for a similar proposal
6510,@GaryMarcus,2021-06-03 17:32:51+00:00,https://twitter.com/GaryMarcus/status/1400505775131217923,@MaxALittle @missy_cummings @lizadixon
6511,@GaryMarcus,2021-06-03 14:43:37+00:00,https://twitter.com/GaryMarcus/status/1400463185564495879,I tried to warn everyone‚Ä¶
6512,@GaryMarcus,2021-06-02 16:09:29+00:00,https://twitter.com/GaryMarcus/status/1400122406543314945,@PeterWolfTW look forward to seeing the english edition
6513,@GaryMarcus,2021-06-02 13:26:22+00:00,https://twitter.com/GaryMarcus/status/1400081358525894659,"ü§£&amp; no wonder ""Open"" AI is still too chicken to give me access to GPT-3."
6514,@GaryMarcus,2021-06-01 12:34:53+00:00,https://twitter.com/GaryMarcus/status/1399706012156796930,"@Miles_Brundage people also got overly optimistic about chatbots. and not every expert thought that closed-domain games were a measure of very much. as i have been saying since 2012, the real challenge for deep learning is reasoning, generalization and comprehension. 

that remains true."
6515,@GaryMarcus,2021-05-24 19:38:53+00:00,https://twitter.com/GaryMarcus/status/1396913615223939072,"shocking! @elonmusk was wrong about lidar.  

https://t.co/fRPPIbv0F7"
6516,@GaryMarcus,2021-05-24 18:50:28+00:00,https://twitter.com/GaryMarcus/status/1396901430292664322,"@Foone great thread. somewhat apropos, my book Kluge is about cognitive remnants that exist only because of our evolutionary path."
6517,@GaryMarcus,2021-05-24 17:13:02+00:00,https://twitter.com/GaryMarcus/status/1396876907665264648,"@mikeolson @amcafee Sutton's  Bitter Lesson pertains to things we have partly solved, but may not hold for many other challenges, such as reasoning and language, on which we have made far less progress. 

Big Data has been our best tool so far, but in the long run it is only part of the solution."
6518,@GaryMarcus,2021-05-24 17:10:00+00:00,https://twitter.com/GaryMarcus/status/1396876147237941248,"@lizadixon @staringispolite Naming can help. but crows, primates, preverbal humans, etc can do creative things with tools,  motor planning, etc that still elude our smartest robots, even absent language."
6519,@GaryMarcus,2021-05-24 02:16:09+00:00,https://twitter.com/GaryMarcus/status/1396651202440568833,@adamsafron @dileeplearning @ykilcher https://t.co/qX48NkxeGF
6520,@GaryMarcus,2021-05-23 12:19:10+00:00,https://twitter.com/GaryMarcus/status/1396440567115096069,"@partha_mitra @KriegeskorteLab @neuro_data @SebastianSeung @HassonUri exactly the issue that i discussed in the 1998 article and 2001 book and 1999 Science article. humans generalize many types of patterns outside the training distribution; some generalizations are within a space of training examples, and some aren‚Äôt."
6521,@GaryMarcus,2021-05-23 04:12:15+00:00,https://twitter.com/GaryMarcus/status/1396318029038895105,@partha_mitra @neuro_data @KriegeskorteLab @SebastianSeung extrapolating beyond the distribution surely remains a problem
6522,@GaryMarcus,2021-05-22 23:06:48+00:00,https://twitter.com/GaryMarcus/status/1396241160797102082,"@partha_mitra @neuro_data @KriegeskorteLab @SebastianSeung i have been arguing that literally since 1998, in article called Rethinking Eliminative Connectionism."
6523,@GaryMarcus,2021-05-22 23:04:40+00:00,https://twitter.com/GaryMarcus/status/1396240625356447749,"@ak_panda no, not fine. eg confirmation bias and motivated reasoning are bugs that cause no end of trouble."
6524,@GaryMarcus,2021-05-22 13:06:48+00:00,https://twitter.com/GaryMarcus/status/1396090168403185668,"Of course humans are buggy (I wrote a whole book about that) but even so @lizadixon &amp; @missy_cummings are correct: no current ‚Äúself-driving‚Äù car is as good as a typical human driver.

No matter what @tesla calls it, keep your hands on the wheel and your eyes on the road."
6525,@GaryMarcus,2021-05-19 18:24:13+00:00,https://twitter.com/GaryMarcus/status/1395082884399079425,"Great to see BC journalists like @RenuBakshi and @PennyDaflos tell it like it is, when so many others don‚Äôt have the guts."
6526,@GaryMarcus,2021-05-17 20:28:44+00:00,https://twitter.com/GaryMarcus/status/1394389443314733056,the only mystery is why it took so long
6527,@GaryMarcus,2021-05-14 22:02:27+00:00,https://twitter.com/GaryMarcus/status/1393325865774116866,@Lazer OMG. @CarissaVeliz
6528,@GaryMarcus,2021-05-14 13:32:17+00:00,https://twitter.com/GaryMarcus/status/1393197476874620931,"On Monday @WSJ claimed that British Columbia ‚ÄúContained the Brazilian Covid-19 Variant‚Äù

Reality is somewhat different:"
6529,@GaryMarcus,2021-05-14 12:38:16+00:00,https://twitter.com/GaryMarcus/status/1393183881713487874,@yudapearl congratulations @vardi!!!
6530,@GaryMarcus,2021-05-13 22:05:18+00:00,https://twitter.com/GaryMarcus/status/1392964191896543232,Apple‚Äôs AirTags Are a Gift to Stalkers  https://t.co/3xFoK92stw
6531,@GaryMarcus,2021-05-12 21:48:09+00:00,https://twitter.com/GaryMarcus/status/1392597491523080195,@Kasparov63 count me in
6532,@GaryMarcus,2021-05-12 16:26:11+00:00,https://twitter.com/GaryMarcus/status/1392516465761296384,"OMG. And yet in some ways one of the most interesting articles I have ever read. 

Fighting misinformation with misinformation.  https://t.co/Fy3Ck3yDlG"
6533,@GaryMarcus,2021-05-12 15:39:16+00:00,https://twitter.com/GaryMarcus/status/1392504657331712001,"a history of AI hype from @elonmusk and Andrew Ng, skillfully dissected. @filippie509 brings receipts."
6534,@GaryMarcus,2021-05-12 14:21:51+00:00,https://twitter.com/GaryMarcus/status/1392485176379281415,"one thing that distinguishes biological brains from artificial networks is the high degree of precise internal structure in the former. 

there‚Äôs still an enormous amount that we don‚Äôt know about that internal structure, but this new paper is an important clue."
6535,@GaryMarcus,2021-05-11 22:18:33+00:00,https://twitter.com/GaryMarcus/status/1392242751706570754,"‚ÄúSpin is dangerous in a public health emergency‚Äù - incisive dissection of a prematurely celebrated government leader who began to believe her own press clippings and lost her way, by @RenuBakshi"
6536,@GaryMarcus,2021-05-09 19:38:24+00:00,https://twitter.com/GaryMarcus/status/1391477675554787330,@Lazer a lot like the old levitating street performer trick!
6537,@GaryMarcus,2021-05-08 16:02:34+00:00,https://twitter.com/GaryMarcus/status/1391060971368509442,"Why can't we trust you to help us survive?
Don't you want to keep the whole province alive?

Covid is Airborne. 

Why did it take so many powerful people so long to get this?

Brilliant musical takedown by the ‚Å¶@dexamethasones‚Å©

#bcpoli #covid19 https://t.co/aU3Fo5QiAx"
6538,@GaryMarcus,2021-05-07 15:06:46+00:00,https://twitter.com/GaryMarcus/status/1390684540700479492,@rao2z ü§£
6539,@GaryMarcus,2021-05-07 14:04:54+00:00,https://twitter.com/GaryMarcus/status/1390668968281591808,"‚ÄúTesla tells regulator that full self-driving cars may not be achieved by year-end‚Äù- Reuters

No shit. https://t.co/lZNaW6stsJ"
6540,@GaryMarcus,2021-05-05 21:39:21+00:00,https://twitter.com/GaryMarcus/status/1390058558696222720,GPT-3 and toxic language. The adventure continues.  https://t.co/nhxzmwiEEM
6541,@GaryMarcus,2021-05-05 02:12:39+00:00,https://twitter.com/GaryMarcus/status/1389764949304438785,frightening and likely 100% correct  https://t.co/QLa2qzsR12
6542,@GaryMarcus,2021-05-03 21:54:46+00:00,https://twitter.com/GaryMarcus/status/1389337664231395330,@KordingLab More for me! https://t.co/Y3CVVD8A3t
6543,@GaryMarcus,2021-05-03 20:46:11+00:00,https://twitter.com/GaryMarcus/status/1389320405802831872,"@Sundae_Gurl either count me in, or explain how you got to be so funny, or better yet, both."
6544,@GaryMarcus,2021-05-03 20:12:37+00:00,https://twitter.com/GaryMarcus/status/1389311955882569729,"fantastic workshop on neural ensembles, May 5:"
6545,@GaryMarcus,2021-05-02 13:24:45+00:00,https://twitter.com/GaryMarcus/status/1388846927748288512,@MadamePratolung @NewYorker it‚Äôs garbage. @ErnestSDavis and I have submitted a response.
6546,@GaryMarcus,2021-04-29 19:34:45+00:00,https://twitter.com/GaryMarcus/status/1387852877977165824,"@Love2Code that's pretty good, yes."
6547,@GaryMarcus,2021-04-29 18:35:42+00:00,https://twitter.com/GaryMarcus/status/1387838014701768704,@Grady_Booch i used a bag of them to teach my daughter fractions. does that count? ü§£
6548,@GaryMarcus,2021-04-29 18:31:10+00:00,https://twitter.com/GaryMarcus/status/1387836873318404098,"@SMBrocklehurst AFAIK they had not before; that‚Äôs what it makes it significant. it‚Äôs always been true, but maybe not previously acknowledged"
6549,@GaryMarcus,2021-04-29 18:01:20+00:00,https://twitter.com/GaryMarcus/status/1387829365849788418,"@ProfData for sure, easier because of well behaved pedestrians, lack of precipitation, etc. 

Krafcik's recent departure was not a vote of confidence."
6550,@GaryMarcus,2021-04-29 17:08:18+00:00,https://twitter.com/GaryMarcus/status/1387816023156400132,‚ÄúTesla admits it may never achieve full-self-driving cars‚Äù https://t.co/ZeQGdKOPX5
6551,@GaryMarcus,2021-04-28 21:23:41+00:00,https://twitter.com/GaryMarcus/status/1387517904497766401,".@zeynep ‚Å¶@TheAtlantic‚Å© plz be careful
1. this event seems to contradict claims re outdoor parties not being a documented cause of covid-19 transmission. 
2. variants may have elevated risk, even if risk was initially low.
3. outdoor = hard to trace https://t.co/3DaCxUmnRa"
6552,@GaryMarcus,2021-04-28 20:53:53+00:00,https://twitter.com/GaryMarcus/status/1387510401303158784,"@philipcball @chaloelikesthis @NewYorker Loved the quote about the dolphins living in ""a gravity free ... vast and alien soundscape.""  I am with Magnasco in his skepticism about how commensurable dolphin's systems might be with people's, but it does remind me of a favorite Far Side cartoon: 

https://t.co/CuyI8ZNDtJ"
6553,@GaryMarcus,2021-04-28 19:33:28+00:00,https://twitter.com/GaryMarcus/status/1387490167288565760,"Cuomo needs to step down, today.  https://t.co/tccBcbJh61"
6554,@GaryMarcus,2021-04-28 14:01:30+00:00,https://twitter.com/GaryMarcus/status/1387406625003118599,"@trylks @Love2Code @lizadixon @missy_cummings targets = hype, Musk, and systems that may be too superficial to reliably reach their goals"
6555,@GaryMarcus,2021-04-28 13:59:33+00:00,https://twitter.com/GaryMarcus/status/1387406133292244997,"@Love2Code @trylks @lizadixon @missy_cummings in no way i am arguing for a purely symbolic system; i have argued for hybrid systems since 1992. 

but yes knowing what a railroad track is would be helpful."
6556,@GaryMarcus,2021-04-28 00:28:18+00:00,https://twitter.com/GaryMarcus/status/1387201975435988993,"@Love2Code @lizadixon @missy_cummings @lizadixon already posted the full video, but i would be really disconcerted by a human driver who did that, even with the correction."
6557,@GaryMarcus,2021-04-27 20:47:49+00:00,https://twitter.com/GaryMarcus/status/1387146487411347458,"@PaulTopping @lizadixon @missy_cummings in driving as in many domains, humans are a low and problematic bar that we ought eventually to be able exceed with machines. 

but in driving we are still fairly far from that bar."
6558,@GaryMarcus,2021-04-27 20:35:34+00:00,https://twitter.com/GaryMarcus/status/1387143405608738819,"Viscerally terrifying Tesla moment that reflects a lack of commonsense understanding of the world.
 
h/t @lizadixon cc @missy_cummings"
6559,@GaryMarcus,2021-04-26 03:18:53+00:00,https://twitter.com/GaryMarcus/status/1386520127756111873,"Congrats to @nomadlandfilm!

Now please go out and read @jessbruder's book, on which the film was based!"
6560,@GaryMarcus,2021-04-24 18:02:26+00:00,https://twitter.com/GaryMarcus/status/1386017703098343426,@ncweaver not if you read the fine print = ‚Äúfor simple tasks‚Äù
6561,@GaryMarcus,2021-04-23 23:12:50+00:00,https://twitter.com/GaryMarcus/status/1385733432135716864,"@alinekaeri hmm. what i have seen is usually a few lines of code, not more."
6562,@GaryMarcus,2021-04-23 22:20:00+00:00,https://twitter.com/GaryMarcus/status/1385720137253195785,"@alinekaeri i have no problem with autocomplete, but the article promises more."
6563,@GaryMarcus,2021-04-23 20:48:07+00:00,https://twitter.com/GaryMarcus/status/1385697011853193216,"@Grady_Booch it's actually ""80% to 90%"" for simple tasks, if you read carefully.  for an email client, it'd probably be &lt; %1"
6564,@GaryMarcus,2021-04-23 20:24:08+00:00,https://twitter.com/GaryMarcus/status/1385690975931027458,"Ugh, just what the world needs: ""[software that] works 80 to 90 percent of the time"" https://t.co/PIvP1FGOhf 

#gpt3"
6565,@GaryMarcus,2021-04-22 03:47:25+00:00,https://twitter.com/GaryMarcus/status/1385077755880960005,This is a stunning film.
6566,@GaryMarcus,2021-04-20 16:57:11+00:00,https://twitter.com/GaryMarcus/status/1384551732995182592,@AvilaGarcez certainly that‚Äôs the right avenue to pursue but i haven‚Äôt seen any compelling instantiation yet. great research problem!
6567,@GaryMarcus,2021-04-19 20:00:22+00:00,https://twitter.com/GaryMarcus/status/1384235444049571842,"100% agree. The government BC has abdicated its leadership. Today's press conference is last chance to step up.

#BCpoli #BCed"
6568,@GaryMarcus,2021-04-19 19:46:55+00:00,https://twitter.com/GaryMarcus/status/1384232059057557511,"@leonpalafox No, what it does is to say we don't yet know how to change them in the right way."
6569,@GaryMarcus,2021-04-19 18:19:44+00:00,https://twitter.com/GaryMarcus/status/1384210117432807427,"2/2  Re #1, really? There is no thorough rebuttal of the many demonstrations of past bias. To simply declare they are all flawed is hardly convincing. A few may have methodological flaws, but many of them are readily replicated.  And new ones keep popping up. The problem is real."
6570,@GaryMarcus,2021-04-19 18:19:43+00:00,https://twitter.com/GaryMarcus/status/1384210115889270796,"Learning from past data *alone* does imply repeating the mistakes of the past. 

What we need are systems that can take the past *in the context of what we want the future to look like.*

We don't have that yet. That's what we should be focusing on. 

1/2"
6571,@GaryMarcus,2021-04-19 17:42:51+00:00,https://twitter.com/GaryMarcus/status/1384200837103177739,"British Columbia has been hacked by Cambridge Analytica disinformation. 

Not a joke."
6572,@GaryMarcus,2021-04-19 15:54:19+00:00,https://twitter.com/GaryMarcus/status/1384173526148476929,"Don't mistake that which is theoretically possible for the reality of current AI/ML systems, which are broken.

6/6"
6573,@GaryMarcus,2021-04-19 15:54:19+00:00,https://twitter.com/GaryMarcus/status/1384173525368393736,"Let us invent then a new breed of AI systems that mix an awareness of the past with values that represent the future that we aspire to.

Our focus should be on figuring on how to build AI that can represent and reason about *values*,  rather than simply perpetuating past data."
6574,@GaryMarcus,2021-04-19 15:54:19+00:00,https://twitter.com/GaryMarcus/status/1384173524621824003,"Some humans (now) can look past historical injustice and try to do better; no current algorithm can. 

4/6"
6575,@GaryMarcus,2021-04-19 15:54:19+00:00,https://twitter.com/GaryMarcus/status/1384173523652923420,"The way current machine learning algorithms are built is to look at historical data, and predict a future that is, by design, expected to look like the past

You can't move a society that has a history of injustice towards justice by repeating the statistics of the past.

3/6"
6576,@GaryMarcus,2021-04-19 15:54:19+00:00,https://twitter.com/GaryMarcus/status/1384173522830778372,"Current algorithms *do* perpetuate historical biases, and have done so repeatedly, as  @LatanyaSweeney, @timnitGebru, @jovialjoy, @mathbabedotorg &amp; others have shown over and over.

These failings are not a coincidence; it's inherent in how current algorithms are built.

2/6"
6577,@GaryMarcus,2021-04-19 15:54:18+00:00,https://twitter.com/GaryMarcus/status/1384173521245376520,"Sure, it is  easier to swap algorithms than to change human minds, but the rest of this @pmdomingos argument is flawed. 

Here's a mini-thread on why. 
(1/6)"
6578,@GaryMarcus,2021-04-18 18:32:10+00:00,https://twitter.com/GaryMarcus/status/1383850861432958977,"‚Äúfull safety driving‚Äù, my eye. this is what you get when you overhype your AI."
6579,@GaryMarcus,2021-04-18 02:41:32+00:00,https://twitter.com/GaryMarcus/status/1383611627354791941,"@glupyan you know that‚Äôs ignoring large parts of Gallistel‚Äôs arguments. And you did indeed start this by calling him ‚Äúconspiratorial‚Äù at the beginning of this thread, without a whiff of evidence. i am out."
6580,@GaryMarcus,2021-04-17 21:42:52+00:00,https://twitter.com/GaryMarcus/status/1383536464575668228,@glupyan would he be wrong if he thought that?
6581,@GaryMarcus,2021-04-17 16:29:06+00:00,https://twitter.com/GaryMarcus/status/1383457502742794252,"@glupyan um, where does Gallistel say that the result has been *suppressed*? as opposed to ignored?"
6582,@GaryMarcus,2021-04-17 01:51:20+00:00,https://twitter.com/GaryMarcus/status/1383236603498229765,"After @kasparov63 humiliated me at an exhibition, I dare not try :)

And be real. @MagnusCarlsen was playing Norwegian nationals when he was 8.  I wouldn't stand a chance."
6583,@GaryMarcus,2021-04-16 23:50:42+00:00,https://twitter.com/GaryMarcus/status/1383206246564593666,@andrewshvv @drmichaellevin and this is a good summary of Gallistel‚Äôs argument as a whole: https://t.co/O6IXupEQl4
6584,@GaryMarcus,2021-04-16 23:28:46+00:00,https://twitter.com/GaryMarcus/status/1383200725405077506,@andrewshvv @drmichaellevin i think it is this one: https://t.co/547jxCReXM
6585,@GaryMarcus,2021-04-16 21:52:09+00:00,https://twitter.com/GaryMarcus/status/1383176411683332096,@barbarikon @bradpwyble @spiantado @glupyan @davidadger @D_Casasanto @BenPitt they aren‚Äôt logically exclusive but he does have some interesting arguments around invariants &amp; association that i have not seen refuted.
6586,@GaryMarcus,2021-04-16 20:40:16+00:00,https://twitter.com/GaryMarcus/status/1383158320542875652,@iamknighton @bradpwyble @davidadger @spiantado @glupyan @D_Casasanto @BenPitt good evidence might look like the mappings between chemistry and physics or Mark Konishi‚Äôs mappings between barn owls behavior and putative computational mechanisms.
6587,@GaryMarcus,2021-04-16 20:38:53+00:00,https://twitter.com/GaryMarcus/status/1383157974974144513,@bradpwyble @spiantado @glupyan @davidadger @D_Casasanto @BenPitt yes. that would be overstated. ‚Äúhas much weaker support than most people assume‚Äù would be more reasonable
6588,@GaryMarcus,2021-04-16 20:35:20+00:00,https://twitter.com/GaryMarcus/status/1383157082556297217,"@bradpwyble @davidadger @spiantado @glupyan @D_Casasanto @BenPitt not saying that‚Äôs impossible, but evidence is surprisingly thin in the ground."
6589,@GaryMarcus,2021-04-16 20:34:18+00:00,https://twitter.com/GaryMarcus/status/1383156822157103104,@iamknighton @bradpwyble @davidadger @spiantado @glupyan @D_Casasanto @BenPitt any evidence of mappings between that and actual bits of neural machinery?
6590,@GaryMarcus,2021-04-16 20:31:49+00:00,https://twitter.com/GaryMarcus/status/1383156196446638080,much the same might be sad for the parallel disaster in BC
6591,@GaryMarcus,2021-04-16 20:30:34+00:00,https://twitter.com/GaryMarcus/status/1383155880342949891,"@bradpwyble @spiantado @glupyan @davidadger @D_Casasanto @BenPitt extrapolation for math has been poor within neural networks, better in the animal world. that‚Äôs gallistel‚Äôs (&amp; my) point"
6592,@GaryMarcus,2021-04-16 20:29:16+00:00,https://twitter.com/GaryMarcus/status/1383155552306356227,@bradpwyble @davidadger @spiantado @glupyan @D_Casasanto @BenPitt care to be more specific?
6593,@GaryMarcus,2021-04-16 20:08:45+00:00,https://twitter.com/GaryMarcus/status/1383150390502252544,"@bradpwyble @spiantado @glupyan @davidadger @D_Casasanto @BenPitt if we can‚Äôt get from A to B after several decades, we can‚Äôt just assume that the path actually flows from A to B."
6594,@GaryMarcus,2021-04-16 20:07:49+00:00,https://twitter.com/GaryMarcus/status/1383150155906441216,"@bradpwyble @davidadger @glupyan as i recall, his argument is not that it‚Äôs impossible but that (a) he has asked thousands of scientists and none has ever given an account (most don‚Äôt even engage with the problem) and (b) that it would likely be highly energetically inefficient, therefore not super plausible."
6595,@GaryMarcus,2021-04-16 20:02:56+00:00,https://twitter.com/GaryMarcus/status/1383148926031720449,"@glupyan @spiantado @davidadger @D_Casasanto @BenPitt and dead reckoning. if you have a non symbolic account of dead reckoning, that can fit the data Gallistel synthesizes, feel free to present it."
6596,@GaryMarcus,2021-04-16 19:23:26+00:00,https://twitter.com/GaryMarcus/status/1383138985409617921,"@glupyan @spiantado @davidadger @D_Casasanto @BenPitt things like dead reckoning, celestial navigation, etc not to mention language are good examples of things that may be symbolic. i would urge you to read Gallistel‚Äôs books, if you have not."
6597,@GaryMarcus,2021-04-16 19:21:23+00:00,https://twitter.com/GaryMarcus/status/1383138470420377601,@spiantado @glupyan @davidadger @D_Casasanto @BenPitt have you read his books? that‚Äôs not really his argument. his argument is that (a) animals can in fact add numbers and (b) the known mechanisms don‚Äôt explain how this can be done and (c) intraneural mechanisms might be a more efficient means.
6598,@GaryMarcus,2021-04-16 16:03:10+00:00,https://twitter.com/GaryMarcus/status/1383088588380786690,"Has neuroscience completely misunderstood the basis of memory? 

Great interview with one of my favorite scientists, Randy Gallistel. https://t.co/tG8y3FMCYT"
6599,@GaryMarcus,2021-04-16 15:01:20+00:00,https://twitter.com/GaryMarcus/status/1383073025755471877,"Leaving covid policy in the hands of a narcissist in the US led to disaster.

residents of BC increasingly feel that they too are suffering at the hands of a narcissist, apparently more interested in optics than solving problems. 

@JustinTrudeau please help. 

#bcpoli"
6600,@GaryMarcus,2021-04-16 05:11:08+00:00,https://twitter.com/GaryMarcus/status/1382924497880162304,"Bonnie Henry has jumped the Trump Shark, spinning dubious truths to improve her optics, by telling 1/2 truths about testing. And people are starting to notice. 

By the time the US got rid of Trump an enormous damage was done.  

The sooner BC @jjhorgan wakes up, the better."
6601,@GaryMarcus,2021-04-16 01:22:44+00:00,https://twitter.com/GaryMarcus/status/1382867017762414599,"why are we prioritizing political optics over saving lives?

important analysis of underreported covid deaths in BC and elsewhere in Canada.

#bcpoli"
6602,@GaryMarcus,2021-04-15 23:47:20+00:00,https://twitter.com/GaryMarcus/status/1382843010740719621,"If only someone in the government in British Columbia were smart enough to understand point 2.
#bcpoli @adriandix @jjhorgan"
6603,@GaryMarcus,2021-04-15 11:35:44+00:00,https://twitter.com/GaryMarcus/status/1382658896817319942,"we were told the same lies in British Columbia, with the same consequences."
6604,@GaryMarcus,2021-04-14 22:58:37+00:00,https://twitter.com/GaryMarcus/status/1382468361733345283,"What‚Äôs worse than a public health disaster? One in which the people empowered to take action stand by doing nothing, while ignoring all advice.

hint: wringing hands is not taking action

Cartoon from ‚Å¶@DFisman‚Å©, Ontario, but totally fits BC

#bcpoli #bced ‚Å¶@jjhorgan‚Å© https://t.co/5ZLuOEs99Z"
6605,@GaryMarcus,2021-04-14 17:37:59+00:00,https://twitter.com/GaryMarcus/status/1382387672807743490,@WestcoastBCLife @DrKarinaZeidler disgusting the way economics rather than health appears to be the number one driver of our public health office
6606,@GaryMarcus,2021-04-14 14:17:15+00:00,https://twitter.com/GaryMarcus/status/1382337158581678083,@NikhilKrishnasw @JesParent @_KarenHao ü§£üò¢
6607,@GaryMarcus,2021-04-14 13:54:53+00:00,https://twitter.com/GaryMarcus/status/1382331526579318789,"Playing games with words to get ethical cover.  

Dark AI/Ml goodness from ‚Å¶@_KarenHao‚Å©.  https://t.co/nes6uR9MEp"
6608,@GaryMarcus,2021-04-13 22:59:48+00:00,https://twitter.com/GaryMarcus/status/1382106274855149568,TEMPORARILY SHUT DOWN SCHOOLS IN B‚Äã.‚ÄãC DUE TO COVID - Sign the Petition! https://t.co/UzImsJH9Ag via @CdnChange
6609,@GaryMarcus,2021-04-13 14:12:38+00:00,https://twitter.com/GaryMarcus/status/1381973608226951173,"Some people have a drinking problem. 

AI has a hype problem.

I will be talking about that problem at @nvidia #GTC2021 at 8:45am PT. https://t.co/elfFHKO055"
6610,@GaryMarcus,2021-04-13 13:51:30+00:00,https://twitter.com/GaryMarcus/status/1381968288951898131,@JSEllenberg ü§£
6611,@GaryMarcus,2021-04-13 13:43:33+00:00,https://twitter.com/GaryMarcus/status/1381966287908208645,"@JSEllenberg sure. i have made that point many times, usually by saying that intelligence is not a one dimensional variable"
6612,@GaryMarcus,2021-04-13 13:36:10+00:00,https://twitter.com/GaryMarcus/status/1381964430179635214,"Very much confirming the point of my 1999 Science article on infant rule learning. 

Over two decades later, neural networks are still struggling with notions that are obvious to babies."
6613,@GaryMarcus,2021-04-13 00:18:01+00:00,https://twitter.com/GaryMarcus/status/1381763567918059522,"Clearly BC‚Äôs mild ‚Äúcircuit breaker‚Äù is not enough. BC needs to go essential services only, &amp; remote schooling, immediately. 

Reporting higher numbers without taking stricter measures is not a solution @adriandix @jjhorgan  

#bcpoli #bced"
6614,@GaryMarcus,2021-04-12 18:52:34+00:00,https://twitter.com/GaryMarcus/status/1381681667128049664,@dlevenstein @KordingLab @dileeplearning @stochastician Seems a bit narrow to me. There are a plenty of innate circuits across the animal world that we don't yet understand and that wouldn't quite fit in that specific box.
6615,@GaryMarcus,2021-04-12 15:57:18+00:00,https://twitter.com/GaryMarcus/status/1381637558543675392,"@dileeplearning Agreed with 1-3 but see those in part as flowing from @KordingLab and @stochastician‚Äôs point, rather than as a refutation."
6616,@GaryMarcus,2021-04-11 19:30:14+00:00,https://twitter.com/GaryMarcus/status/1381328759303794688,"Ugh! More disturbing dialog from Natural Language AI that has no idea what it's talking about. (In this case, @replikaAI). 

h/t @mervenoyann"
6617,@GaryMarcus,2021-04-10 18:30:36+00:00,https://twitter.com/GaryMarcus/status/1380951363895455745,"Evergreen tweet, at least so far."
6618,@GaryMarcus,2021-04-09 15:05:49+00:00,https://twitter.com/GaryMarcus/status/1380537441090555910,"‚ÄúThe data economy has to go because it is at odds with free, equal, stable, and liberal democracies.‚Äù 

-@CarissaVeliz, speaking an important truth that few have had the courage to say out loud."
6619,@GaryMarcus,2021-04-09 04:06:16+00:00,https://twitter.com/GaryMarcus/status/1380371459739017217,truly appalling.
6620,@GaryMarcus,2021-04-08 22:20:18+00:00,https://twitter.com/GaryMarcus/status/1380284392543645698,@IntuitMachine https://t.co/qHed6ExlzI
6621,@GaryMarcus,2021-04-08 21:51:35+00:00,https://twitter.com/GaryMarcus/status/1380277166441521154,@IntuitMachine we don't have nearly enough here
6622,@GaryMarcus,2021-04-08 21:45:24+00:00,https://twitter.com/GaryMarcus/status/1380275608689643529,"All of N America is now threatened by British Columbia's anemic response to COVID. Cases are nearly double two weeks ago, and there are so many variants BC has given up sequencing them. 

Yet restrictions are milder than they were a year ago.  

This puts a continent at risk."
6623,@GaryMarcus,2021-04-08 19:14:33+00:00,https://twitter.com/GaryMarcus/status/1380237646836854786,U.S. expert says Canada is missing the chance to fight the P.1 COVID-19 variant | https://t.co/4OQ29s1gIB https://t.co/DIzDhOUcLN
6624,@GaryMarcus,2021-04-07 17:50:08+00:00,https://twitter.com/GaryMarcus/status/1379854015299657731,@lrvarshney @CarissaVeliz @wooldridgemike @WSJ @jackiesnow @TaraChk what limits?
6625,@GaryMarcus,2021-04-07 13:58:53+00:00,https://twitter.com/GaryMarcus/status/1379795820648652800,"@MonicaGandhi9 @katzish aren‚Äôt you ignoring the 20% with unknown transmission, @MonicaGandhi9? 

the figure you cite is a lower bound, but could easily be an underestimate, perhaps by an order of magnitude, if a small fraction of the unknown cases do turn out to be difficult to trace outdoor contacts."
6626,@GaryMarcus,2021-04-07 02:51:08+00:00,https://twitter.com/GaryMarcus/status/1379627776764874752,this is absolutely insane. perhaps @DrZoeHyde or @dgurdasani1 could comment.
6627,@GaryMarcus,2021-04-07 00:26:44+00:00,https://twitter.com/GaryMarcus/status/1379591437361106945,"Hospitalizations are nearly 2x last spring, cases/day are 20x what they were then. And we now have worst P.1 in N America.

We are not doing enough to slow the spread, and w 2nd doses of vaccines for most adults 5-6 months away, and no plan at all for kids, situation is perilous."
6628,@GaryMarcus,2021-04-07 00:26:44+00:00,https://twitter.com/GaryMarcus/status/1379591436438446081,"Weak response to COVID in British Columbia threatens *all of North America* 

The so-called ""circuit breaker"" that we have now is much weaker than last spring when we had schools and most nonessential services closed. 

But the situation is far worse.  [thread. 1/2]"
6629,@GaryMarcus,2021-04-06 13:20:04+00:00,https://twitter.com/GaryMarcus/status/1379423662483283968,"‚ÄúWidespread surveillance is incompatible with free, democratic, and liberal societies in which human rights are respected. It has to go. Do not settle for anything less.‚Äù

-@CarissaVeliz, calling for a revolution, in her new powerful new book #privacyispower, published today."
6630,@GaryMarcus,2021-04-05 20:26:18+00:00,https://twitter.com/GaryMarcus/status/1379168541375533060,"Wait, what? BC is sending teachers back to school, in the midst of exponential P.1, without having vaccinated them?"
6631,@GaryMarcus,2021-04-05 19:58:13+00:00,https://twitter.com/GaryMarcus/status/1379161474937942017,"hard agree. and this isn‚Äôt just a BC issue. if BC is too passive here, P1 will spread more broadly throughout North America."
6632,@GaryMarcus,2021-04-05 19:25:54+00:00,https://twitter.com/GaryMarcus/status/1379153340697702400,"@strat19 @freespiritus @ianhanomansing The specific debate that @ianhanomansing &amp; I had was re variants.

Do we need to put more dramatic restrictions in place given the proliferation of variants in BC, or not? My view was yes; at the time Henry said no. 

She has since partially changed her tune, closing dining etc."
6633,@GaryMarcus,2021-04-05 17:54:30+00:00,https://twitter.com/GaryMarcus/status/1379130338849423361,"@ianhanomansing As an MIT-trained scientist, I approached you &amp; tried to have a conversation about BC policy &amp; media coverage. When I DM'd you told me that a lot of scientists support Henry's approach to variants. 

When I asked if you could point me to some, you bailed. 

That's not dialogue."
6634,@GaryMarcus,2021-04-05 16:05:47+00:00,https://twitter.com/GaryMarcus/status/1379102979593138180,"@wzuidema Key question is what sort of approximation could get the right work done, and how would it be doing the work? eg GPT-3 is an approximation, but an inadequate one, because its representations are too superficial to support [world] model-building and reasoning over those models."
6635,@GaryMarcus,2021-04-04 23:19:39+00:00,https://twitter.com/GaryMarcus/status/1378849777232736258,"@wzuidema you might find interesting what i say about language and memory in my book Kluge, which suggests one way in which humans may fall short of full representation of compositionality (for performance reasons). longer version in my chapter here: https://t.co/OINXXrStAj"
6636,@GaryMarcus,2021-04-04 20:03:44+00:00,https://twitter.com/GaryMarcus/status/1378800474460094473,"@hb_cell that‚Äôs part of the point of the interview, which is worth reading"
6637,@GaryMarcus,2021-04-04 03:02:25+00:00,https://twitter.com/GaryMarcus/status/1378543449738076169,@luislamb we called them transportables. my dad had a Kaypro.
6638,@GaryMarcus,2021-04-02 18:54:47+00:00,https://twitter.com/GaryMarcus/status/1378058347614638083,@teh_aimee Teaching Robots To Be Moral https://t.co/0KJKCW85rI (2015)
6639,@GaryMarcus,2021-04-02 17:58:28+00:00,https://twitter.com/GaryMarcus/status/1378044173874425863,@GosiaGasperoPhD @zerocovidcanada thanks to the whole @zerocovidcanada team üëè
6640,@GaryMarcus,2021-04-02 17:47:25+00:00,https://twitter.com/GaryMarcus/status/1378041392044204033,"It‚Äôs long past time for a #ZeroCovid strategy in Canada, where half-measures have failed.

Please sign and share this petition by ‚Å¶@GosiaGasperoPhD‚Å©. https://t.co/NgO9Ww2MKp"
6641,@GaryMarcus,2021-04-02 14:17:38+00:00,https://twitter.com/GaryMarcus/status/1377988600545955846,@teh_aimee you might enjoy https://t.co/C6XodPts1W
6642,@GaryMarcus,2021-04-02 14:16:14+00:00,https://twitter.com/GaryMarcus/status/1377988244906733568,@danbri @ian @cydharrell what‚Äôs the alternative that you see?
6643,@GaryMarcus,2021-04-02 14:15:46+00:00,https://twitter.com/GaryMarcus/status/1377988128233811973,"@danbri @ian @cydharrell @ThePatHayes ps has duplex improved? ernie david and i critiqued it the moment it arrived:  

https://t.co/87z1mOXnih"
6644,@GaryMarcus,2021-04-02 14:14:08+00:00,https://twitter.com/GaryMarcus/status/1377987718781620226,"@danbri @ian @cydharrell @ThePatHayes well, either we need to combine them in deeper ways, or come up with something altogether different. surely neither cut it on their own. and that we can agree on."
6645,@GaryMarcus,2021-04-02 14:08:30+00:00,https://twitter.com/GaryMarcus/status/1377986299383058434,"@danbri @ian @cydharrell surely https://t.co/Pt7HZbLIv5 makes all of these remarks, in detail."
6646,@GaryMarcus,2021-04-01 19:16:52+00:00,https://twitter.com/GaryMarcus/status/1377701514471337984,"""The contrast between today‚Äôs privacy landscape and that of the 1990s is stark."" 

@CarissaVeliz's terrifying dissection of what has happened to your privacy drops tomorrow in the US."
6647,@GaryMarcus,2021-04-01 14:33:41+00:00,https://twitter.com/GaryMarcus/status/1377630250792718340,"‚ÄúFor the foreseeable future, computers will not be able to match humans in their ability to reason abstractly about real-world situations‚Äù https://t.co/36XsaVvyFk"
6648,@GaryMarcus,2021-03-31 21:31:09+00:00,https://twitter.com/GaryMarcus/status/1377372919781711872,@krzysztofwos @lewbel @yudapearl @BitPlayerMovie
6649,@GaryMarcus,2021-03-31 21:27:30+00:00,https://twitter.com/GaryMarcus/status/1377372004282560512,"@lewbel @yudapearl one of my great experiences in life was visiting Shannon once in his later years, as part of the MIT juggling club. thank you @lewbel for that very special memory!"
6650,@GaryMarcus,2021-03-30 19:58:49+00:00,https://twitter.com/GaryMarcus/status/1376987298097598469,@karaswisher @scagliarini @sama pity!
6651,@GaryMarcus,2021-03-30 19:46:51+00:00,https://twitter.com/GaryMarcus/status/1376984283701682179,"@karaswisher @scagliarini @sama yes i know.  to the table *for a debate with me*, over his preposterous technohype. (see my tweet above)"
6652,@GaryMarcus,2021-03-30 19:45:23+00:00,https://twitter.com/GaryMarcus/status/1376983918457409537,@scagliarini @karaswisher can you bring @sama to the table?
6653,@GaryMarcus,2021-03-30 19:18:42+00:00,https://twitter.com/GaryMarcus/status/1376977199987712000,"woah, @sama do you seriously believe this? ‚Äúcomputer programs that can think will read [and understand] legal documents in 5 years?‚Äù 

utter rubbish. 

ready to debate you, anytime."
6654,@GaryMarcus,2021-03-30 14:00:42+00:00,https://twitter.com/GaryMarcus/status/1376897175846744064,@Grady_Booch the seminal semantics joke!
6655,@GaryMarcus,2021-03-30 01:38:53+00:00,https://twitter.com/GaryMarcus/status/1376710489422454787,"Indeed. Unmistakable evidence that the over-celebrated Bonnie Henry doesn't understand the single most important piece of math in all of this --  in her own words. 

Frightening."
6656,@GaryMarcus,2021-03-29 16:30:16+00:00,https://twitter.com/GaryMarcus/status/1376572424536293378,@C4COMPUTATION gorgeous photos!
6657,@GaryMarcus,2021-03-28 22:12:37+00:00,https://twitter.com/GaryMarcus/status/1376296192846401536,"sure you might, if you were a person. if you were a mindless data mimic, the choice wouldn‚Äôt even occur to you."
6658,@GaryMarcus,2021-03-28 20:48:27+00:00,https://twitter.com/GaryMarcus/status/1376275010092814338,"AI can be part of solution. Or it can exacerbate the problem. 

As long the models du jour do little more than parrot historical data, with no conceptual understanding, they will make things worse.

Let‚Äôs strive for deeper AI, rather than just excusing business as usual."
6659,@GaryMarcus,2021-03-26 21:09:31+00:00,https://twitter.com/GaryMarcus/status/1375555536352014336,@tired_elle and our media mostly remains quiet about it all
6660,@GaryMarcus,2021-03-26 19:54:16+00:00,https://twitter.com/GaryMarcus/status/1375536601116372998,@TalkerTeacher @ianhanomansing truly appalling.  my publisher @penguinrandom should not be advertising her book in the midst of this.
6661,@GaryMarcus,2021-03-26 19:31:20+00:00,https://twitter.com/GaryMarcus/status/1375530830458716162,"British Columbia has lost its way. Dr Henry‚Äôs statements are out of touch with scientific reality. It‚Äôs not that her analysis is ‚Äúcontentious‚Äù as @ianhanomansing too politely puts it.

It‚Äôs that we have an uncontrolled explosion of variants and Henry is doing essentially nothing."
6662,@GaryMarcus,2021-03-25 23:47:56+00:00,https://twitter.com/GaryMarcus/status/1375233018915299332,"@mvortizr @svogel so the main tweet replicates in Turkish? yes, you could do a similar workaround for every single sentence, and do it in the full paragraph as well, for each sentence.  interesting that they choose not to."
6663,@GaryMarcus,2021-03-25 22:49:13+00:00,https://twitter.com/GaryMarcus/status/1375218240029302784,@mvortizr @svogel please try with the full paragraph rather than a single sentence.
6664,@GaryMarcus,2021-03-25 21:08:50+00:00,https://twitter.com/GaryMarcus/status/1375192977664958466,"Some systematic data re machine translation below. 

Other things being equal, current AI systems tend to perpetuate and exacerbate historical bias.

Best way to combat this is to develop systems with deeper understanding.

Patching up individual datasets won't solve the problem."
6665,@GaryMarcus,2021-03-25 18:11:59+00:00,https://twitter.com/GaryMarcus/status/1375148472408547334,"@quaesita and trust algorithms that aren't really up to the job, because they lack representations of human goals and values. 

it's all of these things."
6666,@GaryMarcus,2021-03-25 16:39:03+00:00,https://twitter.com/GaryMarcus/status/1375125084206063617,"@chaloelikesthis yes, it's partly the data. but a human translator in 2021 would know better."
6667,@GaryMarcus,2021-03-25 16:20:52+00:00,https://twitter.com/GaryMarcus/status/1375120507498950661,"No. The model *is* at fault because it is simplistic; as a data aggregator and nothing more it is unable to represent &amp; reason about human goals (such as avoiding sexism). As Ernie Davis and I argued in https://t.co/C6XodPts1W, the field should aspire to build deeper models."
6668,@GaryMarcus,2021-03-25 16:17:26+00:00,https://twitter.com/GaryMarcus/status/1375119646412533760,"@Love2Code apoligical and without any sense of human goals in society and and in translation. that's the point, and why these tools are (in their current form) dangerous."
6669,@GaryMarcus,2021-03-25 15:41:07+00:00,https://twitter.com/GaryMarcus/status/1375110505388417025,"wow. and not in a good way.  striking example of how gender bias can emerge from blind data dredging.

example via Andriy Burkov. https://t.co/cRGBX0oVXv"
6670,@GaryMarcus,2021-03-23 22:04:21+00:00,https://twitter.com/GaryMarcus/status/1374482175223951363,"@jackclarkSF how about a sci-fi story about a government that records every bit of conversation, allegedly for improving AI, and then misuses the data to destroy its enemies?"
6671,@GaryMarcus,2021-03-23 20:58:44+00:00,https://twitter.com/GaryMarcus/status/1374465659732566019,AI/machine learning ahead of its skis yet again: Major flaws found in machine learning for COVID-19 diagnosis ‚Å¶@VentureBeat‚Å©  https://t.co/d5mYQEkBwI
6672,@GaryMarcus,2021-03-23 18:36:44+00:00,https://twitter.com/GaryMarcus/status/1374429926351269904,@munterluggauer ü§£
6673,@GaryMarcus,2021-03-23 17:12:34+00:00,https://twitter.com/GaryMarcus/status/1374408743509659658,"‚ÄúTesla‚Äôs Autopilot Technology Faces Fresh Scrutiny

Federal regulators are investigating 23 recent accidents in which drivers were, or may have been, using the automatic steering and braking system.‚Äù https://t.co/jodiuFf4bj"
6674,@GaryMarcus,2021-03-21 02:49:51+00:00,https://twitter.com/GaryMarcus/status/1373466858062368775,"@taubamush There are many details I don't know, but from what I can see I am skeptical. I don't think that their current approach, weighted heavily towards deep learning, is likely to reach human level safety across a full range of environments, particularly given Musk's aversion to Lidar."
6675,@GaryMarcus,2021-03-21 02:31:55+00:00,https://twitter.com/GaryMarcus/status/1373462346014683137,"Ah, Tesla. ""to think this constitutes anything close to ""full self-driving"" is ludicrous."" 

Road and Track reports. https://t.co/YAlkT6KitB"
6676,@GaryMarcus,2021-03-20 16:05:13+00:00,https://twitter.com/GaryMarcus/status/1373304633083326466,https://t.co/3dx2H7vrDL
6677,@GaryMarcus,2021-03-20 14:13:20+00:00,https://twitter.com/GaryMarcus/status/1373276473776168961,@BNuseibeh @arosha guess you replied before getting to the word ‚Äúcurrent‚Äù
6678,@GaryMarcus,2021-03-19 22:29:33+00:00,https://twitter.com/GaryMarcus/status/1373038962491617283,"@filippie509 @lizadixon most people have very little access as to how they comprehend sentences beyond that they look for nouns and verbs.  

having studied linguistics off and on since the late 1980's I am  confident that there is an enormous amount of complexity that isn't remotely being addressed."
6679,@GaryMarcus,2021-03-19 21:50:05+00:00,https://twitter.com/GaryMarcus/status/1373029031516327938,"what‚Äôs a success bar for me? how about what I proposed in this 2014 @NewYorker piece? 

essentially zero progress since.

What Comes After the Turing Test? https://t.co/1N4qeEE9wH"
6680,@GaryMarcus,2021-03-19 21:34:22+00:00,https://twitter.com/GaryMarcus/status/1373025074928709635,@dakami 48% on the *easy questions* ‚Äîin a highly restricted domain.
6681,@GaryMarcus,2021-03-19 19:54:54+00:00,https://twitter.com/GaryMarcus/status/1373000046648553472,@dakami paraphrasing a sentence is not the same thing as deriving a cognitive model from a discourse. near zero progress there AFAIK.
6682,@GaryMarcus,2021-03-19 19:53:39+00:00,https://twitter.com/GaryMarcus/status/1372999732310671362,"@filippie509 @lizadixon on-road driving is more closed-end than language. stylized roads, restricted access (roads not sidewalks), not a lot of metaphor, limited generativity, etc

still enough edge cases to sink deep learning, though

we have 99% accuracy for driving, nothing close for open-ended NLU"
6683,@GaryMarcus,2021-03-19 19:38:43+00:00,https://twitter.com/GaryMarcus/status/1372995974038126593,@dakami the language chapter in my recent book https://t.co/Pt7HZbLIv5 (w  Ernie Davis) is about the difference between the two.
6684,@GaryMarcus,2021-03-17 03:46:05+00:00,https://twitter.com/GaryMarcus/status/1372031460610252802,i rest my case
6685,@GaryMarcus,2021-03-15 16:41:44+00:00,https://twitter.com/GaryMarcus/status/1371501881999028227,"Congrats to @jessbruder and Chlo√© Zhao for the huge success of Nomadland, including 6 Academy Award nominations üëè"
6686,@GaryMarcus,2021-03-12 00:44:36+00:00,https://twitter.com/GaryMarcus/status/1370173849094877188,"honored to be in such elite company, as a 2021 top AI influencer."
6687,@GaryMarcus,2021-03-10 17:14:56+00:00,https://twitter.com/GaryMarcus/status/1369698296390848515,@tdietterich @titudeadjust @JimDMiller @davidiach this one sounds like a mission for Stephen Kosslyn
6688,@GaryMarcus,2021-03-09 21:27:13+00:00,https://twitter.com/GaryMarcus/status/1369399398694854661,"@anderssandberg ha ha.  but the human error is about failing to inhibit a strong prepotent response, and the AI system‚Äôs error about completely failing to understand the world."
6689,@GaryMarcus,2021-03-08 19:01:18+00:00,https://twitter.com/GaryMarcus/status/1369000290981089280,"Love @geoffreyHinton's new GLOM paper.  Young students would do well to understand what he's trying to achieve.

First person who manages to meet his desiderata &amp; mine (Algebraic Mind/Next Decade in AI) will revolutionize the field. https://t.co/CLB8kVESZ6"
6690,@GaryMarcus,2021-03-08 01:11:10+00:00,https://twitter.com/GaryMarcus/status/1368730983244075010,@DavisSawyer2 @RikTalo @Facebook bingo
6691,@GaryMarcus,2021-03-07 19:14:58+00:00,https://twitter.com/GaryMarcus/status/1368641341203173376,"@AravSrinivas @Facebook yes. but the whole thing is a lot of apples and oranges. it's less direct labeled data, way more indirect data and training, and 512 GPUs for 8 days. 

what that means for the real world remains to be seen."
6692,@GaryMarcus,2021-03-07 19:09:04+00:00,https://twitter.com/GaryMarcus/status/1368639854725132289,"@Abdo_Eldesokey @Facebook subtitle of the immodest SEER paper: ""The start of a more powerful, flexible, and accessible era for computer vision"""
6693,@GaryMarcus,2021-03-07 19:08:19+00:00,https://twitter.com/GaryMarcus/status/1368639666572779521,@AravSrinivas @Facebook got tired of scrolling down here to see where 78% would place: https://t.co/TKKyqlBq0v
6694,@GaryMarcus,2021-03-07 19:03:45+00:00,https://twitter.com/GaryMarcus/status/1368638518012997633,"@RikTalo @Facebook No, I don't think they are all that helpful; useful but not focused on key challenges. 

To advance, we have to focus on a framework for deeper conceptual understanding, per https://t.co/Pt7HZbLIv5 and my Next Decade arXiv."
6695,@GaryMarcus,2021-03-07 19:02:44+00:00,https://twitter.com/GaryMarcus/status/1368638264018538498,"@Abdo_Eldesokey @Facebook ""good contribution"", sure. but the blog says it is ""a major breakthrough""

also blog treats (genuine) progress on object labeling as major  progress towards computer vision in general, ignoring unsolved problems like adversarial examples, 3d scene understanding etc."
6696,@GaryMarcus,2021-03-07 18:52:31+00:00,https://twitter.com/GaryMarcus/status/1368635691656044544,@erich_elsen @Facebook good question.
6697,@GaryMarcus,2021-03-07 18:52:16+00:00,https://twitter.com/GaryMarcus/status/1368635626925387777,"@RikTalo @Facebook meh. even if had a quadrillion images, it may still have trouble with adversarial examples. and it's still just context-free image labeling, which we already have good solutions too. It's chasing a number, not going after harder questions about 3d-perception, cognition, etc."
6698,@GaryMarcus,2021-03-07 18:35:06+00:00,https://twitter.com/GaryMarcus/status/1368631306930692098,"Want to make your results look ""incredible""? Turn a modest improvement into a WIRED story? Step 1: run y axis from 62 to 78 (rather than 0 to 100). Step 2: help yourself to an extra billion parameters. Step 3: congratulate yourself.  

New SEER paper @facebook https://t.co/y64IXuPy9f"
6699,@GaryMarcus,2021-03-05 15:13:44+00:00,https://twitter.com/GaryMarcus/status/1367855855643729925,"excellent dissertation thesis on a critical  topic, by Martin Arjovsky."
6700,@GaryMarcus,2021-03-05 02:07:30+00:00,https://twitter.com/GaryMarcus/status/1367657994922565635,‚ÄúI would take with a pinch of salt the claim that self-supervised learning alone can lead us to machines that have common sense understanding‚Äù -‚Å¶@nikitaggarwal‚Å©  https://t.co/JWNlO9HPPy
6701,@GaryMarcus,2021-03-02 14:11:46+00:00,https://twitter.com/GaryMarcus/status/1366753099449176067,@IntuitMachine scientific realist
6702,@GaryMarcus,2021-02-04 21:14:24+00:00,https://twitter.com/GaryMarcus/status/1357437373764706304,@JSEllenberg yes. it seems like the klu(d)gier way to spell it :)
6703,@GaryMarcus,2021-02-03 16:10:58+00:00,https://twitter.com/GaryMarcus/status/1356998624647938050,"OpenAI's GPT-3‚Äòs toxic language problem, ‚Å¶@IEEESpectrum‚Å©. 

Bigger and bigger data is not the answer.  Per https://t.co/C6XodPts1W, the answer is deeper comprehension, reasoning, and values.  https://t.co/tbyb0l9etq"
6704,@GaryMarcus,2021-01-29 16:33:13+00:00,https://twitter.com/GaryMarcus/status/1355192286137573376,"‚ÄúThe current zeal to spurn hard-won explicit (and often causal) knowledge, only to try to (re)learn it from examples and traces as tacit knowledge, is quixotic at best.‚Äù 

excellent essay by ‚Å¶@rao2z‚Å© on how current AI has lost its bearings.  https://t.co/O3qPfq8NYg"
6705,@GaryMarcus,2021-01-28 01:19:41+00:00,https://twitter.com/GaryMarcus/status/1354599999313645568,@victorstorchan and i borrowed image from @DrHughHarvey
6706,@GaryMarcus,2021-01-26 03:43:10+00:00,https://twitter.com/GaryMarcus/status/1353911332030963712,"will we see many commercial applications of GPT-3? interesting, skeptical analysis by @bendee983"
6707,@GaryMarcus,2021-01-21 15:03:18+00:00,https://twitter.com/GaryMarcus/status/1352270554888241155,@_RobToews @KenForbus
6708,@GaryMarcus,2021-01-21 03:23:50+00:00,https://twitter.com/GaryMarcus/status/1352094526274342916,"@_RobToews it‚Äôs just a bunch of anecdotal examples at the moment; there‚Äôs no statistical analysis, and thus far no paper. it is certainly not reliable."
6709,@GaryMarcus,2021-01-20 17:36:43+00:00,https://twitter.com/GaryMarcus/status/1351946773783224320,Jimmy Cliff - I Can See Clearly Now (Official Video) https://t.co/M1aqa21Uot via @YouTube
6710,@GaryMarcus,2021-01-15 23:07:05+00:00,https://twitter.com/GaryMarcus/status/1350217972363640832,@fernandaedi @AthenaAkrami might know the data here
6711,@GaryMarcus,2021-01-15 22:15:03+00:00,https://twitter.com/GaryMarcus/status/1350204879608848384,"this is tone deaf, batshit crazy, incredibly dangerous, and a perfect encapsulation of a catastrophic presidency."
6712,@GaryMarcus,2021-01-15 20:20:20+00:00,https://twitter.com/GaryMarcus/status/1350176008607993857,@MichaelSchwandt @DFisman @imgrund absolutely 100% false. here‚Äôs Horgan for example saying there is no risk: https://t.co/ZwnNnzV1UW
6713,@GaryMarcus,2021-01-15 18:51:20+00:00,https://twitter.com/GaryMarcus/status/1350153613780295680,"magical thinking has led to the unnecessary loss of lives over and over throughout the covid-19 pandemic. 

here, epidemiologist @dfisman deconstructs a particular version of that magical thinking that had infected parts of Canada.  

the lesson is general."
6714,@GaryMarcus,2021-01-15 15:24:09+00:00,https://twitter.com/GaryMarcus/status/1350101471346348035,"beautiful new paper from @LittleBimble and others @deepmind, unafraid of symbols and innateness and going after deep questions."
6715,@GaryMarcus,2021-01-15 15:06:20+00:00,https://twitter.com/GaryMarcus/status/1350096990307184640,"As detailed below, Pence came startlingly close to being lynched, yet never invoked the 25th. Why? 

Historians will argue over this literally for centuries."
6716,@GaryMarcus,2021-01-15 15:01:43+00:00,https://twitter.com/GaryMarcus/status/1350095826685550594,@dataBiryani @rcsaxe @metasemantic sorry i didn‚Äôt pose it more sharply at first but i think we have converged now. interesting to see what comes from next steps.
6717,@GaryMarcus,2021-01-15 14:38:30+00:00,https://twitter.com/GaryMarcus/status/1350089983965577217,"@rcsaxe @dataBiryani @metasemantic ps i am not saying people shouldn‚Äôt use those embeddings, just trying to figure out how good the result is and what is driving it."
6718,@GaryMarcus,2021-01-15 14:37:05+00:00,https://twitter.com/GaryMarcus/status/1350089629085491203,"@_Pete0_ @NoahShachtman but ‚Äúsuccessful‚Äù only in the sense that it is what Thiel wanted, not in the sense that the Presidency was successful."
6719,@GaryMarcus,2021-01-15 14:36:22+00:00,https://twitter.com/GaryMarcus/status/1350089448671703041,"@_Pete0_ @NoahShachtman donald trump, inasmuch as Peter Thiel used his billions and power to help get Trump installed."
6720,@GaryMarcus,2021-01-15 14:35:08+00:00,https://twitter.com/GaryMarcus/status/1350089136829415427,thrilled to see @deepmind take up the challenge
6721,@GaryMarcus,2021-01-15 14:33:14+00:00,https://twitter.com/GaryMarcus/status/1350088657965785088,"@rcsaxe @dataBiryani @metasemantic putting it different way, you could do keyword search against the photo databases tags and report results that might look interesting. part of what‚Äôs happening is the photos themselves are gorgeous. how much does CLIP help here?"
6722,@GaryMarcus,2021-01-15 14:31:59+00:00,https://twitter.com/GaryMarcus/status/1350088343413932033,@rcsaxe @dataBiryani @metasemantic eg LSA
6723,@GaryMarcus,2021-01-15 14:25:12+00:00,https://twitter.com/GaryMarcus/status/1350086636898381824,"@rcsaxe @dataBiryani @metasemantic alternatively, maybe i don‚Äôt really understand what claim you are even making."
6724,@GaryMarcus,2021-01-15 14:24:37+00:00,https://twitter.com/GaryMarcus/status/1350086489791582210,@rcsaxe @dataBiryani @metasemantic i am saying if you want to make an assertion about the value of deep learning you should have a baseline.
6725,@GaryMarcus,2021-01-15 14:20:39+00:00,https://twitter.com/GaryMarcus/status/1350085494399410180,@kumar_amit on the plus side it‚Äôs not obvious that the result would replicate widely
6726,@GaryMarcus,2021-01-15 03:26:45+00:00,https://twitter.com/GaryMarcus/status/1349920934644252672,"an inadvertent admission that #bced and the citizens of BC aren‚Äôt getting straight information about the spread of covid in schools, because the truth would upset people. #bcpoli"
6727,@GaryMarcus,2021-01-15 01:16:19+00:00,https://twitter.com/GaryMarcus/status/1349888108548931585,@rcsaxe @metasemantic see eg https://t.co/EydNlbP7UZ for inspiration.
6728,@GaryMarcus,2021-01-14 19:27:43+00:00,https://twitter.com/GaryMarcus/status/1349800379064610816,"Will all of them flee the country, or only he who was twice impeached?"
6729,@GaryMarcus,2021-01-14 19:25:01+00:00,https://twitter.com/GaryMarcus/status/1349799701558640640,"@joedotfaith i don‚Äôt think that‚Äôs fair actually.  but my whole premise was that neither side had developed the conceptual breakthroughs we need, and i stand by that."
6730,@GaryMarcus,2021-01-14 18:28:38+00:00,https://twitter.com/GaryMarcus/status/1349785513650126848,"@joedotfaith the basic idea of perceptrons goes back to the 40s and 50s. mainly we just have more data, more memory, and more processing power. there‚Äôs relatively little that Rosenblatt wouldn‚Äôt have immediately recognized."
6731,@GaryMarcus,2021-01-14 17:29:15+00:00,https://twitter.com/GaryMarcus/status/1349770566023016449,"@owl_machina in part, and a broader emphasis on short-term low hanging fruit in industry as well. not that these are the only factors, but they are a serious problem."
6732,@GaryMarcus,2021-01-14 16:50:20+00:00,https://twitter.com/GaryMarcus/status/1349760774953082880,"Could this help explain why AI is still basically recycling the same ideas as it started with over six decades ago, and why so little progress has been made towards building machines that genuinely understand the world around them?"
6733,@GaryMarcus,2021-01-14 16:08:11+00:00,https://twitter.com/GaryMarcus/status/1349750167910506501,"@metasemantic no, i am saying skip the neural networks and the training. use Euclidean space and nearest neighbor on those."
6734,@GaryMarcus,2021-01-14 15:58:17+00:00,https://twitter.com/GaryMarcus/status/1349747677156708353,@metasemantic eg nearest image as located in text label space to poetry in text space.
6735,@GaryMarcus,2021-01-14 15:41:50+00:00,https://twitter.com/GaryMarcus/status/1349743536753635331,@metasemantic @OpenAI @unsplash have you tried nearest neighbor as more efficient baseline?
6736,@GaryMarcus,2021-01-14 15:16:04+00:00,https://twitter.com/GaryMarcus/status/1349737052296732672,"@IntuitMachine as Kahneman argued at #AIdebate2, there is likely to be symbol-manipulation even within System 1."
6737,@GaryMarcus,2021-01-14 15:15:08+00:00,https://twitter.com/GaryMarcus/status/1349736817101217792,"@un1crom @vardi they typically eschew representing explicit symbolic variables over which they could perform binding open-ended operations. see my book The Algebraic Mind, chapter 3. the problems stem from that choice."
6738,@GaryMarcus,2021-01-14 15:12:37+00:00,https://twitter.com/GaryMarcus/status/1349736184151306242,"@IntuitMachine (maybe it depends what you mean by on top of, but i am encouraging a broad look at hybrids)"
6739,@GaryMarcus,2021-01-14 15:12:04+00:00,https://twitter.com/GaryMarcus/status/1349736044673921026,@IntuitMachine did i assume that?
6740,@GaryMarcus,2021-01-14 14:54:49+00:00,https://twitter.com/GaryMarcus/status/1349731701509918724,"exactly so. and,
conversely, pure GPT doesn‚Äôt get you to reliable reasoning. 

This is exactly why we so urgently need to focus on developing hybrid approaches to AI."
6741,@GaryMarcus,2021-01-14 14:38:23+00:00,https://twitter.com/GaryMarcus/status/1349727568014897152,"With all the hype around neural networks, it‚Äôs important to understand why logic is actually at the core of modern computer science and still likely to be a key player in the next AI revolution. 

This talk by @vardi (recorded but you need to register) should be great background."
6742,@GaryMarcus,2021-01-14 14:24:47+00:00,https://twitter.com/GaryMarcus/status/1349724144758185984,@luislamb @vardi will there be a recording?
6743,@GaryMarcus,2021-01-14 00:57:06+00:00,https://twitter.com/GaryMarcus/status/1349520886051704833,of course he is
6744,@GaryMarcus,2021-01-12 16:20:30+00:00,https://twitter.com/GaryMarcus/status/1349028491858042882,"@Love2Code we talk about this sort of thing in https://t.co/FLZ9VvNAQH, giving google translate and wikipedia as an example"
6745,@GaryMarcus,2021-01-12 15:47:17+00:00,https://twitter.com/GaryMarcus/status/1349020133117800453,has anyone in history shown less remorse?
6746,@GaryMarcus,2021-01-12 02:07:28+00:00,https://twitter.com/GaryMarcus/status/1348813817325633537,"‚ÄºÔ∏è if this is true and Trump understands that his lawyers are correct that he can‚Äôt safely pardon himself, then the conversation Trump just had with Pence may have been about Pence pardoning Trump if Trump resigns."
6747,@GaryMarcus,2021-01-11 21:58:02+00:00,https://twitter.com/GaryMarcus/status/1348751044499525632,"‚Äúi called...my closest contact at the White House to urge ...president .. [to] tell the rioters to stop their violence... But...Trump completely undercut that message ... This was terrible, especially since he incited them in the first place.‚Äù  

‚Äî@SenatorCollins 

and see: https://t.co/YMZ4OQroCx"
6748,@GaryMarcus,2021-01-11 21:51:00+00:00,https://twitter.com/GaryMarcus/status/1348749274197102593,"@titudeadjust @ylecun @tdietterich this is a great discovery, from just over a year ago."
6749,@GaryMarcus,2021-01-11 16:22:10+00:00,https://twitter.com/GaryMarcus/status/1348666520059088896,"when early research suggested‚Äîbut did yet not prove‚Äîcigarettes caused cancer in humans, execs emphasized incompleteness of science to avoid reckoning with the problem. smokers dismissed research by saying other things could kill you. 

in this thread a @facebook exec tries both:"
6750,@GaryMarcus,2021-01-10 17:35:02+00:00,https://twitter.com/GaryMarcus/status/1348322469753458688,@victorf13 agreed: lack of clear mechanism plus high media factor -&gt; reason for suspicion
6751,@GaryMarcus,2021-01-10 15:31:40+00:00,https://twitter.com/GaryMarcus/status/1348291424584826882,I certainly hope that every American will watch this personal and powerful video.
6752,@GaryMarcus,2021-01-10 14:57:02+00:00,https://twitter.com/GaryMarcus/status/1348282709152387077,"@victorf13 i don‚Äôt buy that one, but broadening from that one to denying all possible social priming seems too broad, and even to all goals seems be too broad. ‚Äúdouble object dative‚Äù is a low level goal, no?"
6753,@GaryMarcus,2021-01-10 05:40:40+00:00,https://twitter.com/GaryMarcus/status/1348142695554813953,@bradpwyble for sure
6754,@GaryMarcus,2021-01-10 05:40:22+00:00,https://twitter.com/GaryMarcus/status/1348142620799688705,"@victorf13 1. i think to some lay eyes it‚Äôs (incorrectly) all been tarnished. 2. though i am skeptical of some of the social work, social things are semantic, no? i would expect there to be some real effects, at least of modest magnitude. no?"
6755,@GaryMarcus,2021-01-10 02:22:16+00:00,https://twitter.com/GaryMarcus/status/1348092766589313026,@smickdougle Rudy is a less funny version of Saul.
6756,@GaryMarcus,2021-01-10 02:19:53+00:00,https://twitter.com/GaryMarcus/status/1348092167563091969,@pfau that‚Äôs covered under ‚Äúruse to throw off Nancy‚Äù
6757,@GaryMarcus,2021-01-10 02:16:42+00:00,https://twitter.com/GaryMarcus/status/1348091366476185600,"Even Breaking Bad never got this tense. In the episode leading up to the season finale, Mike Veep suddenly strong arms his good buddy Don the Con, after Don tries to take a hit out on Mike. Is it just a ruse to throw off Nancy, or The Real Deal, as he tries to save his own life?"
6758,@GaryMarcus,2021-01-09 20:39:07+00:00,https://twitter.com/GaryMarcus/status/1348006410026553344,@RogerFrigola @GuillermoPuebl6 @OpenAI it‚Äôs hard to fully review something you don‚Äôt have access to
6759,@GaryMarcus,2021-01-09 18:59:20+00:00,https://twitter.com/GaryMarcus/status/1347981296908251138,@filippie509 ü§£
6760,@GaryMarcus,2021-01-09 17:03:03+00:00,https://twitter.com/GaryMarcus/status/1347952034977234944,"ps they also said essentially nothing about the composition of the training set, which makes what was learned almost impossible to evaluate."
6761,@GaryMarcus,2021-01-09 17:00:44+00:00,https://twitter.com/GaryMarcus/status/1347951449964040192,"sure, sure, this is certainly a terrific xkcd cartoon about how statistics can be misused. 

But @openAI‚Äôs DALL-E blog post *didn‚Äôt even report statistics*

ü§¶‚Äç‚ôÇÔ∏è"
6762,@GaryMarcus,2021-01-09 16:35:46+00:00,https://twitter.com/GaryMarcus/status/1347945169010626564,"@bradpwyble as i argued in my book Kluge, I think it is all mediated by the dynamics of content-addressable memory."
6763,@GaryMarcus,2021-01-09 16:27:45+00:00,https://twitter.com/GaryMarcus/status/1347943150585663490,"@bradpwyble what you hear is not under volitional control; the word you choose to attend to is, and that mediates the percept."
6764,@GaryMarcus,2021-01-09 16:21:12+00:00,https://twitter.com/GaryMarcus/status/1347941504560418822,"@bradpwyble that‚Äôs an artifact of how the demo is presented; it could be done more artfully,such that viewer wasn‚Äôt aware; the viewer is made aware for expository purposes"
6765,@GaryMarcus,2021-01-09 16:20:10+00:00,https://twitter.com/GaryMarcus/status/1347941241825083393,@vineettiruvadi @bradpwyble i am sure it could be done with some other words but not all. the stimulus is clearly designed to be ambiguous.
6766,@GaryMarcus,2021-01-09 16:19:17+00:00,https://twitter.com/GaryMarcus/status/1347941020529422336,"@andpru @bradpwyble priming is vague, but this is about as clean a demo of it as i can imagine. in the (appropriate) replicability crisis i think the baby sometimes has been disregarded, in an overreaction relative to the bathwater."
6767,@GaryMarcus,2021-01-09 15:56:13+00:00,https://twitter.com/GaryMarcus/status/1347935214165639168,@bradpwyble that‚Äôs priming too
6768,@GaryMarcus,2021-01-09 15:39:43+00:00,https://twitter.com/GaryMarcus/status/1347931064799354881,an amazing demo shows that the psychological finding of ‚Äúpriming‚Äù does (still) have some genuine validity.
6769,@GaryMarcus,2021-01-09 03:12:06+00:00,https://twitter.com/GaryMarcus/status/1347742919927734274,@MaxALittle ernie davis and I went through another very similar example in the opening pages of https://t.co/Pt7HZc3jTF...
6770,@GaryMarcus,2021-01-08 22:52:45+00:00,https://twitter.com/GaryMarcus/status/1347677650903392259,@azeem I keep thinking about writing a piece called Terminator v Bloviator {=GPT}
6771,@GaryMarcus,2021-01-08 22:45:09+00:00,https://twitter.com/GaryMarcus/status/1347675740318232578,"@azeem luckily my intended audiences consists entirely of humans, such as yourself :)"
6772,@GaryMarcus,2021-01-08 22:39:02+00:00,https://twitter.com/GaryMarcus/status/1347674200123691008,"this lanyard-wearing doofus already got fired and our government can‚Äôt manage to 25th the guy who incited the riot? 

maybe VP Pence should take some management lessons from Navistar. https://t.co/lDzv36VyPH"
6773,@GaryMarcus,2021-01-08 18:59:16+00:00,https://twitter.com/GaryMarcus/status/1347618895536943105,this is so important. giuliani knew something was coming and said so and the game was delay.
6774,@GaryMarcus,2021-01-08 18:47:01+00:00,https://twitter.com/GaryMarcus/status/1347615812799012867,". @SpeakerPelosi don‚Äôt wait. Your question has been answered. Call the vote, today."
6775,@GaryMarcus,2021-01-08 16:55:04+00:00,https://twitter.com/GaryMarcus/status/1347587636488097799,@ChrisGPotts @jwangARK @NewYorker @alex_carstensen @atticus_geiger @mcxfrank for my latest thinking around this you might read https://t.co/rbeWGMvqMO
6776,@GaryMarcus,2021-01-08 16:54:10+00:00,https://twitter.com/GaryMarcus/status/1347587410536714242,"@ChrisGPotts @jwangARK @NewYorker @alex_carstensen @atticus_geiger @mcxfrank yes, as necessary but not sufficient condition. will add your interesting looking paper to my queue..."
6777,@GaryMarcus,2021-01-08 16:50:10+00:00,https://twitter.com/GaryMarcus/status/1347586405061459969,2014 New Yorker essay: https://t.co/1N4qeEE9wH
6778,@GaryMarcus,2021-01-08 16:42:45+00:00,https://twitter.com/GaryMarcus/status/1347584536851279874,"‚ÄúWhat will it take to impress Gary Marcus?‚Äù, asks @jwangARK  

Answer: machines that could reliably comprehend the world, as I wrote in @NewYorker in 2014. My goalposts haven‚Äôt changed. 

Has there been progress towards what I called for then? 

Not so much."
6779,@GaryMarcus,2021-01-08 01:21:42+00:00,https://twitter.com/GaryMarcus/status/1347352746521858049,this specific psychopathology reminds me of someone else
6780,@GaryMarcus,2021-01-07 23:18:43+00:00,https://twitter.com/GaryMarcus/status/1347321799466315776,"@arcathorn 4 people lost their lives yesterday in the Capitol, all ardent Trump supporters. One was shot to death, another trampled to death."
6781,@GaryMarcus,2021-01-07 23:15:49+00:00,https://twitter.com/GaryMarcus/status/1347321070781493248,"403,000 likes. he made it happen."
6782,@GaryMarcus,2021-01-07 22:25:30+00:00,https://twitter.com/GaryMarcus/status/1347308406932086787,@yrfgs3461 @Plinz hard to believe that as a scientist I should want an understanding of the relation between inputs and the output before drawing conclusions.
6783,@GaryMarcus,2021-01-07 21:49:19+00:00,https://twitter.com/GaryMarcus/status/1347299300489875457,depraved video.
6784,@GaryMarcus,2021-01-07 21:45:19+00:00,https://twitter.com/GaryMarcus/status/1347298291763933185,"@Plinz it‚Äôs a little less good at guitar standing by the bed, physics wise. i still really would like to see the training set. https://t.co/PePInEr0P4"
6785,@GaryMarcus,2021-01-07 21:38:07+00:00,https://twitter.com/GaryMarcus/status/1347296483804995584,@Plinz yes i am also amazed but also again curious about the training set and how general that phenomenon might be
6786,@GaryMarcus,2021-01-07 21:37:27+00:00,https://twitter.com/GaryMarcus/status/1347296315797950464,"@Plinz but eg you get the same style of cartoonish solid block color drawings if you try ‚Äúan illustration of a baby chipmunk wearing a helmet walking a dog‚Äù. if it we‚Äôre a random image search you would see much more diversity.  no line drawings, no stippling, no charcoal, etc. https://t.co/pKdBYOzkhi"
6787,@GaryMarcus,2021-01-07 20:49:04+00:00,https://twitter.com/GaryMarcus/status/1347284138345185280,"@Plinz touch√©. do you know what the training set is, and why (unlike in Google) essentially all the outputs for this query type share a common style?"
6788,@GaryMarcus,2021-01-07 20:17:15+00:00,https://twitter.com/GaryMarcus/status/1347276129422331904,"these are the people that @IvankaTrump, converted Jew, called ‚Äúpatriots‚Äù yesterday. her father cheered them on."
6789,@GaryMarcus,2021-01-07 18:32:21+00:00,https://twitter.com/GaryMarcus/status/1347249733815791616,this shocking-not shocking news might actually lead to the 25th.
6790,@GaryMarcus,2021-01-07 18:09:30+00:00,https://twitter.com/GaryMarcus/status/1347243982389088257,"@phineasgreg @Plinz the blog says almost nothing about what the training set is. we don‚Äôt know how much is a sort of extended version of lookup. and there is a long literature on the complex relation between memorization and deep learning. and, there is no paper available nor access to training set"
6791,@GaryMarcus,2021-01-07 15:51:44+00:00,https://twitter.com/GaryMarcus/status/1347209313245306881,"‚ÄúBaseless‚Äù was the word of November and December, and, look, now it‚Äôs on track to chart again in January:"
6792,@GaryMarcus,2021-01-07 15:24:31+00:00,https://twitter.com/GaryMarcus/status/1347202462843764736,@Plinz i forgot the headphones but you get the idea.
6793,@GaryMarcus,2021-01-07 15:23:01+00:00,https://twitter.com/GaryMarcus/status/1347202084253310976,@Plinz changed panda to elephant and fed into the great intelligence that is Google and got this as hit #2. https://t.co/sWPyqXOTDi
6794,@GaryMarcus,2021-01-07 04:07:45+00:00,https://twitter.com/GaryMarcus/status/1347032148126023683,"@nickwalton00 @NeuroMyths @OpenAI - note that they presented no metrics
- assuming my speculation is correct-that they cherry picked which items to report on-we really have no idea how robust the system is"
6795,@GaryMarcus,2021-01-07 03:58:56+00:00,https://twitter.com/GaryMarcus/status/1347029930450710537,"@nickwalton00 @NeuroMyths @OpenAI right, but did they do that with every input they tried? or pick some interesting set of inputs and report results for those? if the latter, why on earth did they promote the paper after looking at &lt; 100 items? i would like to see full log of items tried and results for each."
6796,@GaryMarcus,2021-01-07 01:19:34+00:00,https://twitter.com/GaryMarcus/status/1346989823920197635,good for @jack and @twitter and thanks to people like @karaswisher and @EricTopol for speaking up: trump‚Äôs account has been temporarily locked.
6797,@GaryMarcus,2021-01-06 23:56:46+00:00,https://twitter.com/GaryMarcus/status/1346968987687473152,completely agree with @karaswisher.
6798,@GaryMarcus,2021-01-06 23:27:33+00:00,https://twitter.com/GaryMarcus/status/1346961635068452864,https://t.co/85ksnDd3ET
6799,@GaryMarcus,2021-01-06 21:46:02+00:00,https://twitter.com/GaryMarcus/status/1346936085788512257,"What four years of Trump have wrought. Photo by Andrew Harnik @APNews.

Destroyer of worlds. This is how I will remember Donald Trump, always. https://t.co/yI3fFYhx8S"
6800,@GaryMarcus,2021-01-06 21:34:28+00:00,https://twitter.com/GaryMarcus/status/1346933176023789570,. @jack @Twitter stand up and be counted.
6801,@GaryMarcus,2021-01-06 21:32:17+00:00,https://twitter.com/GaryMarcus/status/1346932624258949120,@donwinslow @jack stand up and be counted
6802,@GaryMarcus,2021-01-06 21:19:09+00:00,https://twitter.com/GaryMarcus/status/1346929320720154624,"Biden: ""Our democracy is under unprecedented assault""

‚ÄúWhite House adviser: Trump doesn't want to do more to calm riots‚Äù

https://t.co/v9r9QgsPrn"
6803,@GaryMarcus,2021-01-06 20:45:30+00:00,https://twitter.com/GaryMarcus/status/1346920853724745728,"@XGlorot @OpenAI there are no reported metrics, just full logs for some subset of tested cases."
6804,@GaryMarcus,2021-01-06 20:45:02+00:00,https://twitter.com/GaryMarcus/status/1346920733864198144,@XGlorot @OpenAI i said the preview was dynamite. but i really would like to see the full log and results for everything that was tested.
6805,@GaryMarcus,2021-01-06 17:20:57+00:00,https://twitter.com/GaryMarcus/status/1346869374943076354,@ML_EHSAN @OpenAI in the sense of massive d aa but no subtlety about linguistics
6806,@GaryMarcus,2021-01-06 17:16:41+00:00,https://twitter.com/GaryMarcus/status/1346868301675184129,@IntuitMachine @OpenAI Sutton was quite clear in his answer to me at #aidebate that he saw RL as a necessary prior but not a sufficient one.
6807,@GaryMarcus,2021-01-06 17:09:59+00:00,https://twitter.com/GaryMarcus/status/1346866616965816323,@NeuroMyths @OpenAI the drop downs menus are what made it feel so cherry picked to me. did they really report every variation they tried? why did they post if they only tried a few hundred variations? i‚Äôd love to see the full log of queries and responses
6808,@GaryMarcus,2021-01-06 17:07:37+00:00,https://twitter.com/GaryMarcus/status/1346866018430271488,"@IntuitMachine @OpenAI finding a good prior and building the right structure. 

AlphaFold is mix of those two, plus brute force."
6809,@GaryMarcus,2021-01-06 16:56:16+00:00,https://twitter.com/GaryMarcus/status/1346863165888348161,"DALL-E encapsulates everything that @OpenAI has become

Dynamite preview but ... 
- it's not ""open""
- there isn't even a paper (yet)
- just a demo of presumably cherry-picked examples 
- it's all brute force
- it's not reliable

Reminds me lot of #Cyberpunk2077, tbh 

ü§¶‚Äç‚ôÇÔ∏è"
6810,@GaryMarcus,2021-01-06 16:44:17+00:00,https://twitter.com/GaryMarcus/status/1346860147201593345,@titudeadjust @IntuitMachine nobody would ever use a compiler that is 90% correct.
6811,@GaryMarcus,2021-01-06 16:36:25+00:00,https://twitter.com/GaryMarcus/status/1346858167334965248,"strong and possibly true claim. 

anyone want to disagree with @luislamb that ‚Äúthe interpretability of AI systems demands a formal semantics‚Äù? 

@openAI‚Äôs DALL-E doesn‚Äôt have one, and it shows."
6812,@GaryMarcus,2021-01-06 15:44:28+00:00,https://twitter.com/GaryMarcus/status/1346845093903233024,@loretoparisi @OpenAI it doesn‚Äôt understand *anything*. it draws statistical associations that are sometimes correct and sometimes not.
6813,@GaryMarcus,2021-01-06 15:34:37+00:00,https://twitter.com/GaryMarcus/status/1346842615786835969,@LittleBimble but see also https://t.co/UbSDhZHHTc
6814,@GaryMarcus,2021-01-06 15:05:40+00:00,https://twitter.com/GaryMarcus/status/1346835331627196422,"The hidden but clear lesson from DALL-E (&amp; see also https://t.co/qSbhx6Nj3R which foreshadowed this, one year ago):"
6815,@GaryMarcus,2021-01-05 16:35:36+00:00,https://twitter.com/GaryMarcus/status/1346495574401454081,"‚ÄúApril 2019 Elon Musk promised...by the end of 2020 there would be a million Tesla robotaxis on the road (via a magical software update ....) And here we are, 2020 is over and there are zero Tesla robotaxis on the road‚Äù &amp; more tales of AI hype and reality, by @filippie509"
6816,@GaryMarcus,2021-01-04 20:33:00+00:00,https://twitter.com/GaryMarcus/status/1346192931477024768,‚Äúrecording of President Trump pressuring...Georgia secretary of state to overturn the results of the election is a harrowing moment in the history of our democracy...Though the number of his days in office is dwindling...only appropriate response is to impeach Mr. Trump. Again.‚Äù
6817,@GaryMarcus,2021-01-02 17:23:13+00:00,https://twitter.com/GaryMarcus/status/1345420396082860034,wonderful that #AIDebate2 is inspiring people to read more cognitive science!
6818,@GaryMarcus,2021-01-01 00:40:32+00:00,https://twitter.com/GaryMarcus/status/1344805673251471360,@MahsooSalimi and see also https://t.co/iFJ1q4pTKI
