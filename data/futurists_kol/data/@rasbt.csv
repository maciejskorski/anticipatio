,0,1,2,3
0,@rasbt,2023-02-16 18:17:39+00:00,https://twitter.com/rasbt/status/1626284690658263042,"@LightningAI Phew, after flipping a coin to decide between scikit-learn and PyTorch, PyTorch it is! üòÖ"
1,@rasbt,2023-02-16 18:13:57+00:00,https://twitter.com/rasbt/status/1626283758331502593,"@westurner @dask_dev @mrocklin @CoiledHQ @GaelVaroquaux @TomAugspurger @NumFOCUS @aterrel @PyData I am not saying that Dask is not super useful and powerful, I was just curious how you would implement the weight and optimizer param sharding in the multi-GPU training context when you also have things like data parallelism etc. Or in other words, why reinventing the wheel?"
2,@rasbt,2023-02-16 18:12:41+00:00,https://twitter.com/rasbt/status/1626283439551807489,"@westurner @dask_dev @mrocklin @CoiledHQ @GaelVaroquaux @TomAugspurger @NumFOCUS @aterrel @PyData These optimizations are pretty framework specific. In this case, the weights &amp; optimizer params in PyTorch. It's complicated when you add all the JIT graph compilation. Not sure how you would use that within the Dask context which is why I was curious about your recommendation."
3,@rasbt,2023-02-16 16:56:43+00:00,https://twitter.com/rasbt/status/1626264320815386628,"@westurner @dask_dev @mrocklin @CoiledHQ @GaelVaroquaux @TomAugspurger @westurner 
""What additional information is needed?"" --&gt; Here's a good summary: https://t.co/GiyU6XnK6z"
4,@rasbt,2023-02-16 16:51:49+00:00,https://twitter.com/rasbt/status/1626263090168725508,"@danofer Not that familiar with spacy, but one trick that comes to mind is sequence parallelism: https://t.co/NIJFjsvgHz"
5,@rasbt,2023-02-16 16:44:55+00:00,https://twitter.com/rasbt/status/1626261352355340297,"@sarojbono @LightningAI Good question, it's a bit easy to overlook, but one is train_loader/val_loader/test_loader

trainer.test(..., dataloaders=train_loader/val_loader/test_loader,...)"
6,@rasbt,2023-02-16 16:37:58+00:00,https://twitter.com/rasbt/status/1626259601711587329,@westurner @dask_dev @mrocklin @CoiledHQ I think it's awesome. I just wonder if it's the right job for the task -- training large language models in PyTorch. Have you tried that or are there any real-world examples?
7,@rasbt,2023-02-16 16:22:18+00:00,https://twitter.com/rasbt/status/1626255661599232000,"@westurner @dask_dev @mrocklin @CoiledHQ Thanks for sharing! Would there be any advantage compared to using methods that already implement tensor parallism, like sharded DDP or DeepSpeed?"
8,@rasbt,2023-02-16 15:40:20+00:00,https://twitter.com/rasbt/status/1626245097380622336,"The above example uses the @LightningAI Trainer for PyTorch where model checkpointing comes basically for free. 
I have a full notebook example fine-tuning an LLM (BERT) here: https://t.co/ruijZ04wwD"
9,@rasbt,2023-02-16 15:35:40+00:00,https://twitter.com/rasbt/status/1626243925714280448,"And I'd argue it's always a good idea to consider adopting early stopping by default.
If you are using @PyTorch, that's super easy to implement, so no excuses üòä https://t.co/BQx5TiwRGc"
10,@rasbt,2023-02-16 14:43:35+00:00,https://twitter.com/rasbt/status/1626230817407266817,"@philbinj Actually, they reference that paper: 
""However, we observe that stochastically removing Transformer layers destabilizes the performance and easily results in severe consequences such as model divergence or convergence to bad/suspicious local optima."""
11,@rasbt,2023-02-16 14:33:27+00:00,https://twitter.com/rasbt/status/1626228267203309572,"@ducnh279 @LightningAI Hah, thanks for sharing. Unit 7 is actually an introduction to computer vision, from the basics to pretraining with self-supervised learning. But yeah, a full-blown CV course will be nice one day :)"
12,@rasbt,2023-02-16 14:32:02+00:00,https://twitter.com/rasbt/status/1626227912230969346,"@BhowalDebjit Yes, but it's usually better to fine-tune all layers. I found this to be true even if the transformer was pretrained in English and adopted for another English task."
13,@rasbt,2023-02-16 14:26:28+00:00,https://twitter.com/rasbt/status/1626226509756391424,"Incremental learning can be used both ways. Instead of the traditional approach of progressively stacking layers and initializing a larger model from a smaller one, the reverse direction (layer dropping) seems to be very promising for transformers: https://t.co/w5YQDeOmud

6/6"
14,@rasbt,2023-02-16 14:26:27+00:00,https://twitter.com/rasbt/status/1626226507340455938,"Large batch training (which I recently discussed in another Twitter thread, https://t.co/WrKctPboMm) is one of the prevailing ways to accelerate training.

5/6"
15,@rasbt,2023-02-16 14:26:27+00:00,https://twitter.com/rasbt/status/1626226505163603971,"Increasing the number of parameters and overparameterizing transformers improves both generalization and convergence. Inspired by the lottery ticket hypothesis, an efficient training strategy is to train a large model via early stopping and then prune it.

4/6"
16,@rasbt,2023-02-16 14:26:26+00:00,https://twitter.com/rasbt/status/1626226502508634118,"Weight initialization and rescaling schemes like Fixup (https://t.co/X9cXw28txq) for residual blocks stabilize training an enable higher learning rates, removing the need for BatchNorm and LayerNorm.

3/6"
17,@rasbt,2023-02-16 14:26:26+00:00,https://twitter.com/rasbt/status/1626226500461793282,"Sharpness-aware minimization (SAM) nearly doubles the training time (since it needs to solve a bi-level min-max optimization problem). Stochastic weight perturbation (https://t.co/F3icIMt9NC), is a more efficient alternative.

2/6"
18,@rasbt,2023-02-16 14:26:25+00:00,https://twitter.com/rasbt/status/1626226498180120579,"""A Survey on Efficient Training of Transformers"" 2023 (https://t.co/ahfiyqRB58)
 
Summarized some of the interesting takeaways below. 
(Note that alternatives to scaled-dot product self-attention are notably absent -- no one uses these, still?)

1/6 https://t.co/rfMZvVCVg7"
19,@rasbt,2023-02-16 12:54:21+00:00,https://twitter.com/rasbt/status/1626203326327947264,"@predict_addict @ChristophMolnar Yea, it is very frustrating sometimes. Actually, this year, I decided not to participate anymore as a reviewer (and author) until there is an effort towards changing and hopefully improving the current peer review system."
20,@rasbt,2023-02-16 12:51:07+00:00,https://twitter.com/rasbt/status/1626202515711598592,"@sarojbono Ah sry, a heads up: there‚Äôs been a little change of plans. We will be finishing up editing units 9 &amp; 10, and then release all units in March/April instead of the current 2-4 weeks gap between Units. So it might be a few weeks until Unit 5. But everything else will be faster then"
21,@rasbt,2023-02-16 12:48:24+00:00,https://twitter.com/rasbt/status/1626201829989122052,"@ChristophMolnar @predict_addict And especially if the peers had a bad day, make no effort to understand your paler, and write a somewhat passive aggressive review."
22,@rasbt,2023-02-16 12:46:29+00:00,https://twitter.com/rasbt/status/1626201348759777281,"@cesifoti @penguinrandom @penguinlibroscl @LearningCCL Congrats, that‚Äôs exciting! 

PS: 2 years is certainly not much in author years, but as a reader looking forward to it, it will be tough waiting üòÖ"
23,@rasbt,2023-02-16 12:41:51+00:00,https://twitter.com/rasbt/status/1626200180922937344,"@yas1nth Yes, exactly."
24,@rasbt,2023-02-16 12:41:16+00:00,https://twitter.com/rasbt/status/1626200034931875840,"@ChristophMolnar I don‚Äôt think anyone really needs AGI. It‚Äôs totally fine to solve problems with special purpose applications. 
E.g., AlphaFold for protein structure prediction works just fine w/o AGI. 

That being said, AGI has maybe value in terms of motivating people to come up with new ideas."
25,@rasbt,2023-02-16 04:01:23+00:00,https://twitter.com/rasbt/status/1626069203965845507,@mkayanda @shoumikhin @machsci Thanks for the kind words!
26,@rasbt,2023-02-15 19:08:33+00:00,https://twitter.com/rasbt/status/1625935111517573127,@MuhammadAnas707 @luis_likes_math Which is generally a very positive trait :)
27,@rasbt,2023-02-15 18:37:22+00:00,https://twitter.com/rasbt/status/1625927264377491456,"@MuhammadAnas707 @luis_likes_math Nice! And don't worry too much about recursion. It's something that is typically covered in CS classes and textbooks, but not all that relevant (and not at all recommended) for Python"
28,@rasbt,2023-02-15 17:34:58+00:00,https://twitter.com/rasbt/status/1625911558701297671,"@MorafahMahdi It's a highly customized version of ResNet with lots of bells and whistles. Lots of it is general and could be applied to other networks as well. (The custom conv groups, temperature scaling, and batchnorm for example)"
29,@rasbt,2023-02-15 17:33:24+00:00,https://twitter.com/rasbt/status/1625911165942476825,"@ShivamKPy I will cover that in Unit 9 of my DL-Fundamentals course, https://t.co/B0rVXxbjgX @LightningAI. It should go live early April. (Sorry that I don't have anything earlier)"
30,@rasbt,2023-02-15 15:50:18+00:00,https://twitter.com/rasbt/status/1625885220623745024,"@levy_vix Glad to hear, thanks for the kind words!"
31,@rasbt,2023-02-15 15:27:08+00:00,https://twitter.com/rasbt/status/1625879390750900224,"@BeEngelhardt @roydanroy Maybe distribute the funding fairly across colleges, and the colleges distribute it fairly among their students so that PI's don't have to constantly apply for grants to hire research students."
32,@rasbt,2023-02-15 15:25:25+00:00,https://twitter.com/rasbt/status/1625878959320604672,"@jessenleon It was probably coined by the same mathematician who first wrote that ""it is trivial to show that ..."""
33,@rasbt,2023-02-15 15:14:34+00:00,https://twitter.com/rasbt/status/1625876226828017665,"@mandystadt @chaton_thomas @LightningAI @otter_ai Nice, I hope you are getting something useful out of the course. Just let me know if you have any questions or feedback! üòä"
34,@rasbt,2023-02-15 15:12:18+00:00,https://twitter.com/rasbt/status/1625875657833033728,@thallukrish You mean using a reduce operation as opposed to concatenation? How would that work in the context of matrix multiplication?
35,@rasbt,2023-02-15 14:55:01+00:00,https://twitter.com/rasbt/status/1625871308906020867,"Theoretically, we could also use block multiplication, but I don't think this is commonly implemented or used for tensor parallelism (yet) https://t.co/6ejr6cEnTg"
36,@rasbt,2023-02-15 14:53:37+00:00,https://twitter.com/rasbt/status/1625870953497432065,"Regarding Tensor Parallelism: how does that work, how can we just split a matrix or tensor across GPUs?

Like always, it goes back to the fundamental concepts of linear algebra üòä https://t.co/RoHTouYvO5"
37,@rasbt,2023-02-15 14:43:13+00:00,https://twitter.com/rasbt/status/1625868337975635969,"@srvmshr Haha, thanks! Maybe one day! (It's actually a section in my Machine Learning and Q and AI book already :P) https://t.co/IvqeMeIBtu"
38,@rasbt,2023-02-15 03:54:18+00:00,https://twitter.com/rasbt/status/1625705031490994178,"@colleagula Henceforth, people using ‚Äúwe‚Äù on single author papers are acknowledging that they consider ChatGPT as a coauthor."
39,@rasbt,2023-02-15 03:53:28+00:00,https://twitter.com/rasbt/status/1625704823055065088,"@colleagula Agreed, why not using first person (singular) when you are the only author. It‚Äôs already on in other types of non-fiction writing. Imagine autobiographies used ‚Äúwe‚Äù."
40,@rasbt,2023-02-15 03:49:50+00:00,https://twitter.com/rasbt/status/1625703910064197633,@KyleCranmer My intuition tells me solutions for 11 and 17 look like something an AI would come up with.
41,@rasbt,2023-02-15 02:22:36+00:00,https://twitter.com/rasbt/status/1625681954954792961,"@itsanderz As a single person probably not, unless you have a lot of time and resources. It's a major undertaking. A good reference would be the BLOOM paper: https://t.co/W0fyOnZgvm"
42,@rasbt,2023-02-14 22:41:56+00:00,https://twitter.com/rasbt/status/1625626423871303680,@alfcnz @GaugeRedundant @Sony Beats Fit Pro! Same convenience as AirPods (same chip) but more comfy and secure fit -- and cheaper (but still expensive).
43,@rasbt,2023-02-14 22:35:49+00:00,https://twitter.com/rasbt/status/1625624884435996675,@vikaswakdeOS @shoumikhin @machsci I think Python programming should be sufficient. The courses start very gentle :)
44,@rasbt,2023-02-14 22:28:12+00:00,https://twitter.com/rasbt/status/1625622967093800962,@sarojbono @MuhammadAnas707 @luis_likes_math @AndrewYNg See it as keeping rested for Unit 5 :)
45,@rasbt,2023-02-14 22:28:00+00:00,https://twitter.com/rasbt/status/1625622916493635585,@shoumikhin @machsci And a traditional machine learning (not deep learning) course: https://t.co/tJU9cJp9ek
46,@rasbt,2023-02-14 22:27:09+00:00,https://twitter.com/rasbt/status/1625622700839391237,"@shoumikhin @machsci Sure! Since you asked üòÖ: 

Book: ""Machine Learning with PyTorch and Scikit-Learn: Develop machine learning and deep learning models with Python"" (https://t.co/vQv1P30OFR)

Deep learning course: (free) Deep Learning Fundamental course: https://t.co/B0rVXxbjgX"
47,@rasbt,2023-02-14 20:44:01+00:00,https://twitter.com/rasbt/status/1625596747232714754,@CanumaGdt @machsci @jeremyphoward @huggingface @AndrewYNg @PyTorch Glad to hear you like the redesigned @LightningAI docs as well! We put a lot of work into these :). Very motivating to hear that it's well received!
48,@rasbt,2023-02-14 20:32:19+00:00,https://twitter.com/rasbt/status/1625593803842150414,"@CanumaGdt @machsci @jeremyphoward @huggingface @AndrewYNg Thanks for the shoutout! Re ""PTL"" You can think of my course (https://t.co/B0rVXxbjgX) as a @PyTorch course really üòä. 

But yeah, there are some aspects of Lightning where it makes sense (e.g., multi-GPU training, code organization, coming in Unit 5)"
49,@rasbt,2023-02-14 19:22:50+00:00,https://twitter.com/rasbt/status/1625576315645485058,"@machsci There are a lot of concepts out there. Start with an introductory book or course and don‚Äôt worry about all the tangents (which can be overwhelming) before completing it. It‚Äôs a marathon, not a sprint."
50,@rasbt,2023-02-14 18:01:55+00:00,https://twitter.com/rasbt/status/1625555952333164565,"@MuhammadAnas707 @luis_likes_math @AndrewYNg A very interesting combo üëç! Specifically because decision trees don't consider any dependency of features (compared to generalized linear models and most neural network architectures)

Fun fact, you can implement decision trees as matrix multiplication: https://t.co/cmDYE1pbER"
51,@rasbt,2023-02-14 17:57:03+00:00,https://twitter.com/rasbt/status/1625554727759974410,"Here are some additional resources (and I will also have a Lightning Trainer intro in Unit 5 of my DL Fundamentals course, dropping next week hopefully):

Multi-GPU training intro: https://t.co/ys0OFcW4wK

More advanced discussion: https://t.co/TGEWCONx29

[5/5]"
52,@rasbt,2023-02-14 17:55:59+00:00,https://twitter.com/rasbt/status/1625554460855439361,"or, for fine-tuning if 5) is not enough, consider DeepSpeed again:
Trainer(‚Ä¶, strategy=‚Äúdeepspeed_stage_3"") 
Trainer(‚Ä¶, strategy=""deepspeed_stage_3_offload"")

[4/5]"
53,@rasbt,2023-02-14 17:55:14+00:00,https://twitter.com/rasbt/status/1625554270765424642,"4) If 3) is not enough, also shard the optimizer and gradients via DeepSpeed:
Trainer(‚Ä¶, strategy=""deepspeed_stage_2"") or
Trainer(‚Ä¶, strategy=""deepspeed_stage_2_offload"")

5) Fine-tune a large model:
Trainer(‚Ä¶, strategy=""fdsp_native"", precision=16

[3/n]"
54,@rasbt,2023-02-14 17:54:58+00:00,https://twitter.com/rasbt/status/1625554203824295942,"2) Same as above but in a Jupyter notebook: Trainer(‚Ä¶, strategy='ddp_notebook')
[data parallel]

3) Pretrain a large model: Trainer(‚Ä¶, strategy=""ddp_sharded"") 
[this uses data parallel + tensor parallel]

2/n"
55,@rasbt,2023-02-14 17:54:21+00:00,https://twitter.com/rasbt/status/1625554049884979202,"If you are training your models using PyTorch, you can use the @LightningAI Trainer to experiment with these various techniques.

My recommendation: 

1) Speed up regular model training where things fit on a single GPU: Trainer(‚Ä¶, strategy='ddp')
 
1/n"
56,@rasbt,2023-02-14 17:32:54+00:00,https://twitter.com/rasbt/status/1625548651677335557,"@vnyz_ Regarding parallelizing the layers on different hardware: it's not possible to completely parallelize this since it's sequential (which is why I recommend using data and tensor parallelism instead) eg
 via Trainer(startegy=""ddp_sharded"") or Trainer(startegy=""deepspeed_stage_2"")"
57,@rasbt,2023-02-14 17:31:16+00:00,https://twitter.com/rasbt/status/1625548239217868829,"@vnyz_ Yes, I adopted the figure from my Machine Learning Q and AI book for Unit 9 of my Deep Learning Fundamentals course (Unit 9 will be released March/April): https://t.co/B0rVXxbjgX"
58,@rasbt,2023-02-14 16:12:51+00:00,https://twitter.com/rasbt/status/1625528505009053696,"@cwizprod1 @DigThatData @OpenAI @StabilityAI @DataChaz @brockwebb @bl_artcult @svpino Yes, traditional systems are simpler rule-based (not necessarily AI-based) systems."
59,@rasbt,2023-02-14 14:17:44+00:00,https://twitter.com/rasbt/status/1625499535094210562,@rezafuru I think that's a good idea. Instead of spending hours debating the contents of MacBeth it would make more sense to spend that time critically analyzing LLM outputs in literature class these days üòÖ
60,@rasbt,2023-02-14 14:16:19+00:00,https://twitter.com/rasbt/status/1625499180130246660,"@vlordier Yes! Actually, AI in aggriculture is now a big thing! I think it even has a specific name ..."
61,@rasbt,2023-02-14 14:14:41+00:00,https://twitter.com/rasbt/status/1625498770900406273,"@juanpablomanson Don't know. The focus was more on training. If I would use this for inference, I would do some additional modifications besides mixed precision as we recently discussed in our webinar, e.g., using CUDA graphs."
62,@rasbt,2023-02-14 14:12:15+00:00,https://twitter.com/rasbt/status/1625498157529579521,"@vnyz_ You mean tensor parallelism? Yes and no. There may be a short delay but if you split into equal sizes, there shouldn't be a big delay.
How it works? That's where linear algebra comes in handy again üòä https://t.co/yPQsbDPRP7"
63,@rasbt,2023-02-14 14:11:07+00:00,https://twitter.com/rasbt/status/1625497871369015300,"@KleppeThorsten Yes, I tried it multiple times. It's usually 93%-94%. ~93.5%ish on average actually"
64,@rasbt,2023-02-14 14:10:28+00:00,https://twitter.com/rasbt/status/1625497706901942272,"@arna_ghosh No, I haven't"
65,@rasbt,2023-02-14 14:08:32+00:00,https://twitter.com/rasbt/status/1625497221306388480,"@JordiClive It's actually really simple: Combine them! üòä

a) Pretrain a large model: 
Trainer(‚Ä¶, strategy=""deepspeed_stage_2"") 

b) Finetune a large model:
Trainer(‚Ä¶, strategy=""deepspeed_stage_3"")"
66,@rasbt,2023-02-14 14:05:58+00:00,https://twitter.com/rasbt/status/1625496577422036992,"@asadaftabiqbal Which approach are you referring to? Usually, most people use a mix of data parallel (more data throughput) &amp; tensor parallel (split large models to fit into RAM) these days.  
E.g., if you are training PyTorch models, Trainer(‚Ä¶, strategy=‚Äúdeepspeed_stage_3"")  using Lightning"
67,@rasbt,2023-02-14 14:03:36+00:00,https://twitter.com/rasbt/status/1625495981856030720,"@kaleom410 Averaging the gradients, yes, that's one of the simpler parallelism techniques via DataParallel or DistributedDataParallel. You give each GPU a different microbatch and then average the gradients to update the model weights."
68,@rasbt,2023-02-14 13:59:15+00:00,https://twitter.com/rasbt/status/1625494884357644289,@DigThatData @cwizprod1 @OpenAI @StabilityAI @DataChaz @brockwebb @bl_artcult @svpino Yes. A good friend of mine from highschool who is a pilot has been complaining about that for 10 years or so now: autopilots make flying increasingly boring (he actually prefers flying Boing over Airbus as they tend to be less automated)
69,@rasbt,2023-02-14 13:57:19+00:00,https://twitter.com/rasbt/status/1625494398778892292,"Training deep neural nets on multiple GPUs has become increasingly common in recent years.
Dividing the workload allows for larger and more complex models to be trained more quickly.

I made a little cheatsheet summarizing the different approaches: https://t.co/GQ6FRw2aBA"
70,@rasbt,2023-02-14 02:16:41+00:00,https://twitter.com/rasbt/status/1625318076425142272,"@MuhammadAnas707 @luis_likes_math Whoa, it's been 30 consistent days! Big congrats! Don't forget to plan in some rewards :)"
71,@rasbt,2023-02-14 01:56:10+00:00,https://twitter.com/rasbt/status/1625312915552182272,"@paul_rietschka A relatively small, heavily customized ResNet"
72,@rasbt,2023-02-14 01:30:07+00:00,https://twitter.com/rasbt/status/1625306360224133122,"@itsanderz @modal_labs In this case, maybe fine-tuning a DistilGPT would make most sense and be least frustrating. The Distil-* models usually work pretty well on a single GPU."
73,@rasbt,2023-02-14 01:27:50+00:00,https://twitter.com/rasbt/status/1625305785759571968,"@itsanderz Other than that, maybe the OPT model. I think they are basically easy to get your hands on pretrained. PaLM probably not."
74,@rasbt,2023-02-14 01:26:55+00:00,https://twitter.com/rasbt/status/1625305554011693056,"@itsanderz Hah, thanks!

If you have the resources, you could try this: https://t.co/4vQ83pcX2H ^^"
75,@rasbt,2023-02-14 01:20:46+00:00,https://twitter.com/rasbt/status/1625304006665928705,"I should mention this is on a single A100, same hardware as suggested in the repo."
76,@rasbt,2023-02-14 01:19:49+00:00,https://twitter.com/rasbt/status/1625303767129239555,@AbhiRaama22 A100 (as suggested in the repo)
77,@rasbt,2023-02-14 01:19:28+00:00,https://twitter.com/rasbt/status/1625303679682195456,"@AISupremacyNews Regarding ChatGPT specifically, the additional data used for finetuning was all proprietary I think. 
Regarding the concern when it comes to the data for pretraining, yes, that's maybe a valid point, but that would concern all neural network lang models (even pre-transformer)"
78,@rasbt,2023-02-14 01:18:03+00:00,https://twitter.com/rasbt/status/1625303324932145155,"@itsanderz BLOOM is actually worse than GPT-3. I think PaLM would be a good one. 
Or, for open source, OPT by Meta (available upon request)"
79,@rasbt,2023-02-14 01:17:02+00:00,https://twitter.com/rasbt/status/1625303066923728898,"Training a convolutional neural network to 94% accuracy on CIFAR-10 in 8 seconds? 
Yes, I can confirm, it works!

Source code: https://t.co/gnsCGAC1Ug https://t.co/HFcWOXEI0W"
80,@rasbt,2023-02-13 20:37:32+00:00,https://twitter.com/rasbt/status/1625232726746963968,"@JanSlabbaert Yeah. LLMs can certainly create misinformation, but that doesn't mean everyone will just start putting misinformation on their websites."
81,@rasbt,2023-02-13 20:15:34+00:00,https://twitter.com/rasbt/status/1625227199639855113,"Not everyone likes using LLMs as writing aids. That's okay. 
But a ban on LLMs as writing aids would be similar to banning calculators as calculation aids -- because calculators can be misused by individuals engaging in financial crimes."
82,@rasbt,2023-02-13 18:54:55+00:00,https://twitter.com/rasbt/status/1625206903482552321,@zacharylipton @AbridgeHQ Awesome news! Congrats on this new role! üéâ
83,@rasbt,2023-02-13 16:59:19+00:00,https://twitter.com/rasbt/status/1625177814122086400,"@TheSequenceAI @fchollet @Grammarly As one can hopefully see in my ""Machine Learning Q and AI"" book (where I compare human and AI responses side by side), the need for technical writers won't go away in the foreseeable future üòâ"
84,@rasbt,2023-02-13 15:03:32+00:00,https://twitter.com/rasbt/status/1625148674186653696,"@ylecun Re LLMs: they make writing easier. And if we use them as a writing aid, that's totally fine. 
Does it make it easier for malicious actors to create misinformation? Sure, maybe. But it doesn't mean we all will carelessly start trusting random websites on the internet."
85,@rasbt,2023-02-13 15:02:13+00:00,https://twitter.com/rasbt/status/1625148342618423296,"@ylecun This makes me think back to my days in high school when Wikipedia just came out. Back then, teachers advised and warned us against using it since it allowed humans to create and spread misinformation. We all know how that turned out."
86,@rasbt,2023-02-13 14:03:18+00:00,https://twitter.com/rasbt/status/1625133515950940164,"@DerekNonGeneric Right, so it's ready for when self-driving cars will finally arrive."
87,@rasbt,2023-02-13 13:43:52+00:00,https://twitter.com/rasbt/status/1625128627732897795,"The significance of deep learning in the natural and physical sciences is often underappreciated.
Despite the media buzz surrounding conversational chatbots &amp; consumer-facing AI apps, the real impact of AI may lie in its applications in the natural and physical sciences."
88,@rasbt,2023-02-13 04:36:34+00:00,https://twitter.com/rasbt/status/1624990893005496320,"@izzyz Nice work! I think it‚Äôs a different team at Google, but I also remember reading their previous deep learning approach for predicting rain on a short time scale:

https://t.co/ak26QkhbD0

https://t.co/uleSAjHoF9"
89,@rasbt,2023-02-13 01:16:23+00:00,https://twitter.com/rasbt/status/1624940514691760128,"@drenerbas @DynamicWebPaige Yes, which makes it even worse. Was just saying that internet plans and smartphone plans are ~$100 each -- never had a TV so I am not sure what the costs are, but I think that's also in that ballpark, so they are maybe thinking that people would be willing to spend ~100ish"
90,@rasbt,2023-02-13 00:10:56+00:00,https://twitter.com/rasbt/status/1624924046096842753,"@cleavey1985 @karpathy Thanks, glad that this was helpful. 

Haha, I often went overboard with my articles in the past . I am now trying hard to keep them more focused, talking about one topic at a time. But just in case someone is interested in the embedding stuff as well, here‚Äôs a compact tweet üòÖ"
91,@rasbt,2023-02-13 00:06:18+00:00,https://twitter.com/rasbt/status/1624922876594774022,@DynamicWebPaige Agreed. But then that‚Äôs also what most internet and smartphone plans currently cost üòî
92,@rasbt,2023-02-12 23:51:09+00:00,https://twitter.com/rasbt/status/1624919067902484482,"@ylecun Yup, it‚Äôs a great sentence-level thesaurus."
93,@rasbt,2023-02-12 23:50:08+00:00,https://twitter.com/rasbt/status/1624918811739672583,"@CSProfKGD Yeah it feels quite wasteful. But then, their products usually have a long lifetime and resale value, so I usually keep the packaging for when I sell it or pass it on."
94,@rasbt,2023-02-12 17:20:46+00:00,https://twitter.com/rasbt/status/1624820822769631232,"Somewhat inspired by the recent paper recommendation by @Machine01776819 üòä, ""When Deep Learners Change Their Mind: Learning Dynamics for Active Learning"" https://t.co/UsShiDoS1H"
95,@rasbt,2023-02-12 17:08:44+00:00,https://twitter.com/rasbt/status/1624817794800840704,"@fchollet @CSProfKGD It will get better with time :P. 

I remember taking an official TensorFlow class in 2015 (I think it was via Udacity) where they used 2-space indentation which was super annoying since it didn‚Äôt only look weird but completely threw of the Jupyter Notebook syntax highlighting."
96,@rasbt,2023-02-12 16:57:55+00:00,https://twitter.com/rasbt/status/1624815073397993474,"This week, I have been working on including reader quizzes for the remaining Q &amp; A's -- adding two new questions for each.

I tried to make them challenging, and I may probably end up using some of them as #machinelearning interview questions :P

https://t.co/2hcrhceVTz https://t.co/JQPAaXZFTW"
97,@rasbt,2023-02-12 15:19:02+00:00,https://twitter.com/rasbt/status/1624790189439610881,"@Etylio Good catch, I fixed that in the meantime since I posted this picture :)"
98,@rasbt,2023-02-12 15:02:33+00:00,https://twitter.com/rasbt/status/1624786041402957827,"@thallukrish I didn't mention fake news. It's a different issue. But yeah, the fact that it makes it easier to auto-generate news could potentially make it easier to spawn off fake news. What will happen is that we will trust random websites on the internet even less."
99,@rasbt,2023-02-12 14:49:50+00:00,https://twitter.com/rasbt/status/1624782840960352258,"@jules_lewis @emollick I haven't seen this yet, thanks for sharing. And yes, this is definitely coming ..."
100,@rasbt,2023-02-12 14:43:27+00:00,https://twitter.com/rasbt/status/1624781231312318464,"@jules_lewis Exactly. It will become harder to impress educators with a paper/essay. You'll have to work extra hard to make sure it doesn't come across as something ""boring"" or ""standard"" that an AI could create."
101,@rasbt,2023-02-12 14:38:11+00:00,https://twitter.com/rasbt/status/1624779906893639687,@ashvanth_s1 Considering most Hollywood movies and TV shows in recent years strongly support your point :P
102,@rasbt,2023-02-12 14:36:53+00:00,https://twitter.com/rasbt/status/1624779578542628865,"@jules_lewis Moving forward, educators will likely expect more from an essay. The essays shouldn't sound too similar to other essays. And to demonstrate understanding, educators will ask students to include elements that an AI can't solve yet, e.g., adding drawings (causal path diagrams?)"
103,@rasbt,2023-02-12 14:31:47+00:00,https://twitter.com/rasbt/status/1624778297790853121,"@hedgetherumor Yeah, that's a fair point. But I think that's just shifting the goalpost even further. If you increase the variety of the essays about topic X that an AI can produce, the next step for a good essay would then be changing the format to stay original. It's an arms race."
104,@rasbt,2023-02-12 14:21:54+00:00,https://twitter.com/rasbt/status/1624775807913664515,"Are LLMs making it easier to write good essays? I‚Äôd say NO, they are just shifting the goalpost.

LLMs will help us to write ""correctly"". But crafting an original and engaging essay that someone wants to read will become more challenging in the future.

https://t.co/V8LWhQeXdk https://t.co/i4RzrFkesX"
105,@rasbt,2023-02-12 14:21:02+00:00,https://twitter.com/rasbt/status/1624775592548700164,"@melkebir1 @akhileshutup Wow, thanks for this really nice complicated on this Sunday morning üòä"
106,@rasbt,2023-02-12 14:18:28+00:00,https://twitter.com/rasbt/status/1624774944436387840,"@akhileshutup @melkebir1 My book, Machine Learning with PyTorch and Scikit-Learn: https://t.co/vQv1P30OFR"
107,@rasbt,2023-02-12 13:55:53+00:00,https://twitter.com/rasbt/status/1624769261917900802,"@pythiccoder @ID_AA_Carmack Sure, haven't trademarked it yet, so please feel free to borrow"
108,@rasbt,2023-02-12 04:16:27+00:00,https://twitter.com/rasbt/status/1624623442338144257,@ID_AA_Carmack could have termed it ‚Äútypewriter‚Äù and ‚Äústock market‚Äù format to make it more clear
109,@rasbt,2023-02-12 03:51:36+00:00,https://twitter.com/rasbt/status/1624617190077919232,"@deliprao @francoisfleuret @NeurIPSConf @icmlconf @iclr_conf I don't think that additional figures make it more work for the reviewers. Rather the contrary, if you add more figures to the existing text, it may actually become more accessible. Given that lots of reviewers misunderstand papers, maybe that's what we need."
110,@rasbt,2023-02-11 22:33:34+00:00,https://twitter.com/rasbt/status/1624537153588920324,"@GiorgioMantova @barlowjon Sounds plausible, but the answer is that the original sentence was ""Can you help me to translate this sentence"" :P"
111,@rasbt,2023-02-11 21:04:43+00:00,https://twitter.com/rasbt/status/1624514794576396295,"@francoisfleuret @NeurIPSConf @icmlconf @iclr_conf Yup. Given that no one distributes the conference proceedings as a hardcopy anymore (or is this still a thing?) I don't know why we haven't switched to word counts instead of page limits yet. 
This way, authors wouldn't have to shrink figures to microscopic sizes anymore"
112,@rasbt,2023-02-11 21:02:32+00:00,https://twitter.com/rasbt/status/1624514242404548609,"@rafael73267301 Backprop. You can think about them as fully connected layers. In PyTorch, you'd implement them as  torch.nn.Linear(..., bias=False)"
113,@rasbt,2023-02-11 20:52:38+00:00,https://twitter.com/rasbt/status/1624511754343485443,"@francoisfleuret @NeurIPSConf @icmlconf @iclr_conf Haha, as a twitter user, I can see that scenario where you work around the character limit via screenshots of text üòÜ.
But what else?"
114,@rasbt,2023-02-11 20:38:10+00:00,https://twitter.com/rasbt/status/1624508112420982786,"@francoisfleuret @NeurIPSConf @icmlconf @iclr_conf I believe that more figures of any kind would improve scientific communication. A lot of times authors are forced to omit figures due to the 8-page limit.

How about a revision of the submission guidelines where figures don't count against the page limit, similar to references?"
115,@rasbt,2023-02-11 20:18:33+00:00,https://twitter.com/rasbt/status/1624503175544819713,"@thekillernote @tunguz You could. But then think about a scenario where you started typing a response on your phone, and you want to finish it on your computer. Just copy &amp; paste the draft.

Or you took a screenshot of your phone you want to then include. Copy &amp; paste that screenshot to yoru computer"
116,@rasbt,2023-02-11 18:44:03+00:00,https://twitter.com/rasbt/status/1624479394105372672,"@firoozye @kchonyc I don't really have any experience with these, but wouldn't these have the limitation that they squash everything into some intermediate representation, so there is a lot of information loss like in RNNs?"
117,@rasbt,2023-02-11 18:35:15+00:00,https://twitter.com/rasbt/status/1624477178703319040,"@firoozye @kchonyc The attention matrix elements are essentially adaptive weights. Or, what would be an other way to implement adaptive weights based on the input sequence that is different from attention?"
118,@rasbt,2023-02-11 18:26:47+00:00,https://twitter.com/rasbt/status/1624475049875935232,"@firoozye @kchonyc Feature selection is usually static, and it's a hard selection whereas in most modern attention mechanism, you have a form of ""soft"" (vs ""hard"") selection, computing a weighted version of *all* the tokens."
119,@rasbt,2023-02-11 18:23:34+00:00,https://twitter.com/rasbt/status/1624474239905538048,"@TaliaRinger Maybe that's a sign to take a leap of faith and follow your dreams, you never know... üòÖüòä"
120,@rasbt,2023-02-11 16:39:19+00:00,https://twitter.com/rasbt/status/1624448002218762240,"@RobertWKemp Thanks! I made it with plain Keynote, and I must say it was a bit finicky ... so I am glad to hear!"
121,@rasbt,2023-02-11 16:18:01+00:00,https://twitter.com/rasbt/status/1624442642367934466,And now back to writing Machine Learning Q and AI üòÖüòä
122,@rasbt,2023-02-11 16:17:04+00:00,https://twitter.com/rasbt/status/1624442405301760002,@MadeUpMasters Cross attention added!
123,@rasbt,2023-02-11 16:16:29+00:00,https://twitter.com/rasbt/status/1624442258358521858,@sarojbono glad you liked it üòä
124,@rasbt,2023-02-11 16:13:03+00:00,https://twitter.com/rasbt/status/1624441393182539777,"Ty for the all the positive feedback on the ""coding self-attention from scratch"" article!

Lots of questions about cross-attention. The beautiful thing about blogs is that it is easy to update and extend!

I hope you like the new sections and figures.
https://t.co/zFsWH4orpa https://t.co/TlZ2PL7bfJ"
125,@rasbt,2023-02-11 15:33:58+00:00,https://twitter.com/rasbt/status/1624431558810648579,"@hamilton_mcmc Lots of *queries* (no pun intended) about cross-attention. Hold on a few minutes, I am just about to update the article with a new section ^^"
126,@rasbt,2023-02-11 13:26:50+00:00,https://twitter.com/rasbt/status/1624399563292393479,"@tunguz Copying &amp; pasting images and text across devices. 

I could just copy the URL of your tweet on my phone and then press CMD+V on my MacBook to respond to it more conveniently from my computer‚Äôs web browser."
127,@rasbt,2023-02-11 13:20:37+00:00,https://twitter.com/rasbt/status/1624398000561717251,"@cwizprod1 @DigThatData It depends a bit on the task. I would say the hallucination of current-gen generative AI is by design. For diffusion models, it‚Äôs basically essential for creating new outputs. Or for LLMs, without hallucination, the models would just memorize and copy."
128,@rasbt,2023-02-11 13:17:27+00:00,https://twitter.com/rasbt/status/1624397203803369473,@itsanderz PyTorch by a long shot. I haven‚Äôt touched TensorFlow since 2019ish
129,@rasbt,2023-02-11 13:16:37+00:00,https://twitter.com/rasbt/status/1624396994302160898,@iPrabhavKaula @kritipraks @_akhaliq @aladdinpersson @3blue1brown Thanks for the shoutout!
130,@rasbt,2023-02-11 13:16:06+00:00,https://twitter.com/rasbt/status/1624396862206668807,"@xiaoyao65391263 I actually don‚Äôt use rocker, sry! But if you use conda, you can use the makefile oneliner described in the readme here: https://t.co/J1A2couq01

Pls let me know if you have any questions or feedback about it."
131,@rasbt,2023-02-10 18:28:56+00:00,https://twitter.com/rasbt/status/1624113203587256321,"@GaelBreton @roydanroy In other words, it's a writing and template machine, not a knowledgebase"
132,@rasbt,2023-02-10 16:48:23+00:00,https://twitter.com/rasbt/status/1624087899246366724,"@efujikei They are a bit diferent.

https://t.co/CxUuuFhagQ_transform(X_training)

is essentially a short cut for

https://t.co/CxUuuFhagQ(X_training)
std.transform(X_training)"
133,@rasbt,2023-02-10 16:46:32+00:00,https://twitter.com/rasbt/status/1624087430268682241,"@gerardsans Totally agree! I was trying to be too time-efficient maybe, haha. I added the respective visualization from the original paper now."
134,@rasbt,2023-02-10 16:23:26+00:00,https://twitter.com/rasbt/status/1624081618980810752,"@dynamics The 16 is arbitrary to keep it relatively small for visualization purposes. I would have to look it up again, but the original transformer uses 512-dimensional embeddings I think. Regarding the embeddings in general, you might find this tweet helpful: https://t.co/OuTQilfmW0"
135,@rasbt,2023-02-10 16:19:50+00:00,https://twitter.com/rasbt/status/1624080713677959168,"@barlowjon Oh, I originally had slighly longer, different input sentence and must have forgotten to adjust that. Just updated that. Thanks!"
136,@rasbt,2023-02-10 16:13:12+00:00,https://twitter.com/rasbt/status/1624079042247856130,@gerardsans Oh my example above is not depicting (self-)attention but the problem with translating a sentence word by word. What I mean is the example you generated above with attention would be nice for a sentence-translated sentence pair
137,@rasbt,2023-02-10 14:50:49+00:00,https://twitter.com/rasbt/status/1624058311111766018,"With the original attention mechanism, I mean the RNN attention mechanism developed by @kchonyc et al. 2014 in https://t.co/WZVNxMIN5Z"
138,@rasbt,2023-02-10 14:45:48+00:00,https://twitter.com/rasbt/status/1624057046919262208,"As a follow-up to my post yesterday, some were wondering why it's called *self*-attention.

That's because it's an attention mechanism for all the elements of the same set.

In contrast, the original attention for RNNs is applied between the encoder and the decoder embeddings. https://t.co/ewV54jDzaR"
139,@rasbt,2023-02-10 14:30:58+00:00,https://twitter.com/rasbt/status/1624053314626232324,"@gerardsans That's a good one. I think a language-translation example would be even nicer because it highlights the motivation for why we need to pay attention to different contexts for each word, i.e., because we can't just translate word by word https://t.co/erJanV5ufG"
140,@rasbt,2023-02-10 14:29:23+00:00,https://twitter.com/rasbt/status/1624052915278123010,"@GodwinHoudji @MadeUpMasters Thanks for the feedback @MadeUpMasters &amp; @GodwinHoudji! 
I changed the matrices to be non-square now to make it more clear!"
141,@rasbt,2023-02-10 13:30:17+00:00,https://twitter.com/rasbt/status/1624038043509264384,"@penguinvondoom Hah, part of writing it down like this is also that my future-self can go back to it in case I forget :P"
142,@rasbt,2023-02-10 13:29:18+00:00,https://twitter.com/rasbt/status/1624037795261022209,@examachine Thanks for the kind compliment!
143,@rasbt,2023-02-10 13:28:49+00:00,https://twitter.com/rasbt/status/1624037676700540928,"@cs_mshah Thanks, and I am glad to hear! The CV reading list sounds like a good idea btw. Maybe something to get back to after finishing my ML Q and AI book!"
144,@rasbt,2023-02-10 03:38:12+00:00,https://twitter.com/rasbt/status/1623889042403123204,"@MadeUpMasters Actually, thanks a lot for the feedback and bringing up cross attention. That‚Äôd be a good section to include or write about next!"
145,@rasbt,2023-02-10 03:06:54+00:00,https://twitter.com/rasbt/status/1623881164799807489,"@fabmilo Thanks, that's actually good to hear -- so no need to change anything about the looks üòÖ. I am using Jekyll with a custom HTML template that I set up about 10 years ago. I've been updating little things here and there but it's mainly still the same core."
146,@rasbt,2023-02-10 02:07:26+00:00,https://twitter.com/rasbt/status/1623866199204298754,"@_y1450 Hah, nothing fancy, just plain old macOS Keynote"
147,@rasbt,2023-02-10 02:06:14+00:00,https://twitter.com/rasbt/status/1623865895771570177,"@hackotorch Yeah, I think that coding and visuals are sometimes really helpful for understanding (and hopefully explaining) these concepts :)"
148,@rasbt,2023-02-09 20:49:54+00:00,https://twitter.com/rasbt/status/1623786291090391040,"@lauradietz99 @chris_j_beckham @percyliang But even if s.o. doesn't explicitly train a model on the test set, there are still reasons why new test data is good. A fixed test set is fine for model selection but it doesn't give you a good estimate of the generalization perfm. Eg see @beenwrekt's 
https://t.co/joAN2ASftJ"
149,@rasbt,2023-02-09 20:30:45+00:00,https://twitter.com/rasbt/status/1623781469465325568,"@lauradietz99 @chris_j_beckham @percyliang If nothing else, it also adds your results a lot of extra credibility -- e.g., I think there would have been a lot more skepticism around AlphaFold 2 if they had used their own test data"
150,@rasbt,2023-02-09 20:29:42+00:00,https://twitter.com/rasbt/status/1623781205593280519,@lauradietz99 @chris_j_beckham @percyliang I think something like Kaggle but for empirical results in research papers would not be a bad idea. It's also not unprecedented. In computational bio research it's quite common (https://t.co/yC3ZEIRS2R)
151,@rasbt,2023-02-09 19:59:43+00:00,https://twitter.com/rasbt/status/1623773659763466242,@FVanGess Should be updated for consistency now!
152,@rasbt,2023-02-09 19:59:19+00:00,https://twitter.com/rasbt/status/1623773557653118979,"@cwizprod1 Haha, how can we draw sth then doesn't exist?"
153,@rasbt,2023-02-09 19:58:52+00:00,https://twitter.com/rasbt/status/1623773447829573635,"@ai4_all Haha, glad I got your attention"
154,@rasbt,2023-02-09 19:56:02+00:00,https://twitter.com/rasbt/status/1623772731316600832,"@FVanGess Thanks! I must warn you that it may be some time until then. But yeah, eventually I want to follow up with a from-scratch transformer post."
155,@rasbt,2023-02-09 19:00:23+00:00,https://twitter.com/rasbt/status/1623758728208998401,"@FVanGess Thanks &amp; Good catch. The figure got a bit too crowded with 8 heads so I reduced that to three! But then I forgot to update the text. Will update it in a bit, thanks!"
156,@rasbt,2023-02-09 18:53:09+00:00,https://twitter.com/rasbt/status/1623756908652896262,@raketstar2 @gerardsans Oh you mean going from the words to the embedding vectors? Maybe this tweet helps :) https://t.co/hquH7TLi9D
157,@rasbt,2023-02-09 17:50:44+00:00,https://twitter.com/rasbt/status/1623741199054938112,"@raketstar2 @gerardsans Good point. But for that, we may have train the weight matrices using backpropagation -- optimizing the prediction for a particular class label. We can then see the attention scores change over the course of training. But that's quite a lot. Good idea for a follow-up though!"
158,@rasbt,2023-02-09 17:25:43+00:00,https://twitter.com/rasbt/status/1623734905396944896,"@gerardsans Yeah so in transformers you need positional encodings because self-attention is permutation-invariant. But in RNN, you don't need positional encodings for the attention weights since it's processing the inputs sequentially"
159,@rasbt,2023-02-09 17:16:10+00:00,https://twitter.com/rasbt/status/1623732501259644929,"@gerardsans Oh I see. I have a book chapter on this in my book, but yeah, it's not freely available https://t.co/vQv1P30OFR"
160,@rasbt,2023-02-09 17:15:21+00:00,https://twitter.com/rasbt/status/1623732296879677440,"@MadeUpMasters Hm, maybe I am misreading your tweet but afaik the attention weights are T x T, that's because it's connecting each token to each other token. (T is the sequence length, i.e., number of tokens)"
161,@rasbt,2023-02-09 17:11:41+00:00,https://twitter.com/rasbt/status/1623731372199116804,"@gerardsans And why do we need these contexts, that's mainly because we can't e.g., translate a sentence 1-by-1, word by word: https://t.co/uGyQHDiNVZ"
162,@rasbt,2023-02-09 17:07:57+00:00,https://twitter.com/rasbt/status/1623730433732014081,"@gerardsans So in other words, people already somewhat now what attention is, what transformers are etc. It was an article that is more focused on the self-attention details."
163,@rasbt,2023-02-09 17:06:54+00:00,https://twitter.com/rasbt/status/1623730170719834112,"@gerardsans Ah yes, this is a longer context. I was cutting it short here to avoid making this a gigantic article. But yeah, it would require going back to the problem: processing longer sequences in RNNs in language translation (the 2014 paper) etc. https://t.co/2gwBjoKlcx"
164,@rasbt,2023-02-09 16:58:14+00:00,https://twitter.com/rasbt/status/1623727987098099712,@gerardsans You are asking about an article that covers training a transformer from scratch essentially?
165,@rasbt,2023-02-09 16:51:34+00:00,https://twitter.com/rasbt/status/1623726310949265408,"@gerardsans Yes, but this would be a very long article then. It's a good topic for a follow-up though, I agree"
166,@rasbt,2023-02-09 16:50:40+00:00,https://twitter.com/rasbt/status/1623726084951875595,"@LeoVasanko Haha, yeah, I am bit oldschool :P"
167,@rasbt,2023-02-09 16:34:23+00:00,https://twitter.com/rasbt/status/1623721987607601152,"@TalhaIrf Since this is a personal website, there is currently no submission for guest articles. Thanks for asking though."
168,@rasbt,2023-02-09 16:23:41+00:00,https://twitter.com/rasbt/status/1623719292653953029,"@MadeUpMasters As far as I know, query and key have the same dimension because you use them (via dot product) to compute the unnormalized attention scores."
169,@rasbt,2023-02-09 15:28:21+00:00,https://twitter.com/rasbt/status/1623705367333986305,"Since self-attention is now everywhere, it's important to understand how it works.
And there is no better and more fun way than coding it from scratch!
My new article on ""Understanding the Self-Attention Mechanism of Large Language Models From Scratch""
üëâ https://t.co/zFsWH4orpa"
170,@rasbt,2023-02-09 00:45:11+00:00,https://twitter.com/rasbt/status/1623483112930803712,"@dbngsh_mkhrj @soumithchintala Yes that‚Äôs often true. One of the reasons why I do think industry is a better fit for me. I think as faculty you ultimately have to fully focus on the planning and grant writing parts, and there is less and less time for actual work and helping students in a more-hands on manner."
171,@rasbt,2023-02-09 00:42:49+00:00,https://twitter.com/rasbt/status/1623482518660956161,"@karpathy Wow, big congrats!! Can‚Äôt wait to see what you build next! üéâ"
172,@rasbt,2023-02-08 23:51:03+00:00,https://twitter.com/rasbt/status/1623469489760116736,"@soumithchintala Agreed. Learned it the hard way when working on LLMs for protein synthesis. 
Ideas are cheap, execution is really what matters. 
Also beyond coding and engineering efforts, here it‚Äôs also cross-functional team effort with collaborators who actually synthesize the proteins"
173,@rasbt,2023-02-08 20:45:05+00:00,https://twitter.com/rasbt/status/1623422689619705857,"@StenRuediger @cwolferesearch @peterjliu Hm, I think you could still use the same reward model for supervised learning. It would then basically just be a form of weakly supervised learning where it's not a human label but a label by another model or method."
174,@rasbt,2023-02-08 20:07:22+00:00,https://twitter.com/rasbt/status/1623413196697530370,"@omarsar0 Yeah, my typical prompts are usually things like ""what are the different ways of doing x"" to get ideas. Out of 10 things it lists, 5 are what I thought about as well, 2 are something I forgot or didn't think about, and 3 are just wrong. For those 2 things, it's actually very cool"
175,@rasbt,2023-02-08 19:56:35+00:00,https://twitter.com/rasbt/status/1623410485780680704,@amaldorai @omarsar0 That's a good way to put it actually.
176,@rasbt,2023-02-08 19:55:14+00:00,https://twitter.com/rasbt/status/1623410144225665036,"@debreuil @omarsar0 It makes too many mistakes though (see some examples I posted below my response). I use it to list things, but then I have to filter out the correct and incorrect responses. It's good for that kind of brainstorming but I need to have domain expertise to interpret the responses"
177,@rasbt,2023-02-08 19:53:08+00:00,https://twitter.com/rasbt/status/1623409614279647235,"@omarsar0 Or consider this explanation of data-centric AI. It's basically a generic statement that also describes supervised learning in general. 

Tbh all these are plausible explanations, but it's not that useful for learning. https://t.co/g7UPbXX9wT"
178,@rasbt,2023-02-08 19:51:52+00:00,https://twitter.com/rasbt/status/1623409297341181958,@omarsar0 It also things that ordinal regression is a GLM https://t.co/x9mWDkubou
179,@rasbt,2023-02-08 19:50:34+00:00,https://twitter.com/rasbt/status/1623408969694990336,"@omarsar0 E.g., check this out, I asked ChatGPT to ""List the three properties of a metric space. Then discuss whether commonly used loss functions such as mean squared error and the cross-entropy loss are proper metrics."" https://t.co/zdP2CL90Ho"
180,@rasbt,2023-02-08 19:42:27+00:00,https://twitter.com/rasbt/status/1623406926598897665,@omarsar0 I use ChatGPT for rewording but based on my experiments it makes way too many mistakes on technical questions so I am hesitant about adopting it for learning. Good tool for brainstorming though.
181,@rasbt,2023-02-08 19:37:28+00:00,https://twitter.com/rasbt/status/1623405673944952835,@Felix72784942 @sir_deenicus @yar_vol The code is open source
182,@rasbt,2023-02-08 19:37:09+00:00,https://twitter.com/rasbt/status/1623405593888280578,"@Felix72784942 @sir_deenicus @yar_vol We have a stable diffusion deployment here if useful: https://t.co/OySIXw8nDA

There is an write up about that linked at the top"
183,@rasbt,2023-02-08 19:33:29+00:00,https://twitter.com/rasbt/status/1623404671116222465,"@sir_deenicus @yar_vol Btw are you able to run ONNX with GPU support in this case, or is this for the CPU-only mode"
184,@rasbt,2023-02-08 19:21:16+00:00,https://twitter.com/rasbt/status/1623401594573230082,"@cwolferesearch @peterjliu What I mean is that from a technical perspective either supervised or RL would work, but it happens that, empirically, RL works better for this type of problem where we want to optimize based on the whole sentence /response-level rather than on a token-basis."
185,@rasbt,2023-02-08 19:18:39+00:00,https://twitter.com/rasbt/status/1623400937229369344,"@cwolferesearch @peterjliu Preference is just a class label for training the reward model though; I think the differentiability is not the prob here. Ie you could use supervised learning for fine tuning the model on the reward labels, but then the token-based loss doesn‚Äôt work so well compared to RL"
186,@rasbt,2023-02-08 18:42:26+00:00,https://twitter.com/rasbt/status/1623391823975616514,"@MuhammadAnas707 Nice, I hope you will like the part on gradient boosting! That was one of the most fun ones to write for the new editions :)"
187,@rasbt,2023-02-08 16:55:13+00:00,https://twitter.com/rasbt/status/1623364842064121861,@jmschreiber91 @chaton_thomas @_neilbhatt upgrade your hardware üòÖ
188,@rasbt,2023-02-08 15:49:17+00:00,https://twitter.com/rasbt/status/1623348248340492290,"@paul_rietschka @BlackHC No, pandas is great. But similar to matplotlib, you need a gallery of old projects/examples to get the most out of it."
189,@rasbt,2023-02-08 14:11:07+00:00,https://twitter.com/rasbt/status/1623323545810993153,"@yar_vol haha, depending on the application, that's probably right.
But what would be your current go-to alternative framework for stable diffusion or large language models?"
190,@rasbt,2023-02-08 14:09:26+00:00,https://twitter.com/rasbt/status/1623323122630795264,"@chaton_thomas, @_neilbhatt, and I will of course also be happy to answer any questions you may have!"
191,@rasbt,2023-02-08 14:03:00+00:00,https://twitter.com/rasbt/status/1623321503688429570,"Want to improve the inferencing speed of your PyTorch models? Join us at our webinar in 2 hours (10 am CT).

We'll give a broad overview of techniques, and I'll be doing a code demo &amp; load testing example on stable diffusion https://t.co/w6hvkOVAQ6"
192,@rasbt,2023-02-08 13:13:28+00:00,https://twitter.com/rasbt/status/1623309037105213440,"@capetorch @BlackHC I haven‚Äôt had a need to use it yet, but I‚Äôve recently got to appreciate all the new Rust libraries with Python APIs as they feel super snappy. Does polars‚Äôs Python API follow the pandas syntax or is it its own thing?"
193,@rasbt,2023-02-08 13:10:57+00:00,https://twitter.com/rasbt/status/1623308402632937474,"@BlackHC My step 1 is usually searching through my gallery of past projects to see if I can copy and paste sth from there. If the answer is no, I‚Äôd proceed with the steps in the exact order you described üòÜ"
194,@rasbt,2023-02-08 03:03:50+00:00,https://twitter.com/rasbt/status/1623155615706087425,"@harrypotter0820 Oh I am just using custom HTML and Jekyll. Nothing fancy.
I haven't had any big issues with it so I will probably keep that setup for another decade, but if I were to start over today, I would maybe go with Hugo. Heard good things about it."
195,@rasbt,2023-02-07 20:29:50+00:00,https://twitter.com/rasbt/status/1623056462980194305,@sarahookr @oh_that_hat 1 column to avoid formatting hassles for writers. And it‚Äôs also nice for readers who read on a 10 inch e-reader.
196,@rasbt,2023-02-07 17:35:57+00:00,https://twitter.com/rasbt/status/1623012703823441923,"@m_usmanrafique Haha, no, my improv skills stop at live coding üòÖ"
197,@rasbt,2023-02-07 16:57:03+00:00,https://twitter.com/rasbt/status/1623002913156001792,"@tunguz whoa, I am flattered. I am curious, what were the loose criteria üòÖ"
198,@rasbt,2023-02-07 16:41:34+00:00,https://twitter.com/rasbt/status/1622999019361300480,"Whoa, my coworkers are having too much fun! üòÜ

Haha, I presume this is the first comedy series centered around machine learning &amp; AI (if we don't count the last season of Silicon Valley)"
199,@rasbt,2023-02-07 16:06:12+00:00,https://twitter.com/rasbt/status/1622990118771429383,"@AssemblyAI @bentossell @BigBrainDaily @Saboo_Shubham_ Thanks for recommending my newsletter, glad you like it!! üòä"
200,@rasbt,2023-02-07 15:40:55+00:00,https://twitter.com/rasbt/status/1622983755429294081,"@8ctopuso Ah, that was for ""attention"" and ""FlashAttention"" üòÖ"
201,@rasbt,2023-02-07 14:59:01+00:00,https://twitter.com/rasbt/status/1622973212547231749,"@robertnridley1 good call! Wanted to keep it focused to 10, but yeah, that's challenging. Another post with papers like LaMDA, PaLM, Gopher etc. would be a good follow-up"
202,@rasbt,2023-02-07 14:50:03+00:00,https://twitter.com/rasbt/status/1622970953620951047,@ashvanth_s1 Of course!
203,@rasbt,2023-02-07 14:45:44+00:00,https://twitter.com/rasbt/status/1622969866897723395,"@ashvanth_s1 Thanks, glad to hear it's useful! I tried very hard to keep it to 10 only :P"
204,@rasbt,2023-02-07 14:35:59+00:00,https://twitter.com/rasbt/status/1622967413498327040,"Since transformers have such a big impact on everyone's research agenda, I wanted to flesh out a short reading list for machine learning researchers and practitioners getting started with large language models:
https://t.co/xSSAdoHsFi"
205,@rasbt,2023-02-07 02:37:56+00:00,https://twitter.com/rasbt/status/1622786712685408258,"@lauradietz99 @chris_j_beckham @percyliang But as soon as you post the test labels online, you have leakage. Better to only share the test data without labels. 
One could use a Kaggle-style platform where researchers send in the predictions to see the performance, but they don't get direct access to the test labels."
206,@rasbt,2023-02-07 00:18:41+00:00,https://twitter.com/rasbt/status/1622751666171772928,@deliprao CC @alfcnz ‚Äî Alfredo has a trademark pending on softargmax‚Ñ¢
207,@rasbt,2023-02-06 21:33:02+00:00,https://twitter.com/rasbt/status/1622709981941309442,"@chris_j_beckham @lauradietz99 @percyliang Yeah, it's misaligned with the target objective (paper acceptance). 
If you are developing a hobby model to predict stock prices or so, it's maybe ok because you would shoot yourself in the foot if you exploit the test data. But yeah, that's not the case with papers."
208,@rasbt,2023-02-06 21:21:54+00:00,https://twitter.com/rasbt/status/1622707179491917829,"@chris_j_beckham @lauradietz99 @percyliang It should be similar to CASP (the way structure prediction models such as AlphaFold) are evaluated: You use new data each year. I get the appeal behind benchmark datasets, but if you have access to the labels during dev, it's not true test data."
209,@rasbt,2023-02-06 20:56:36+00:00,https://twitter.com/rasbt/status/1622700810345025536,"@GomezpoloDiego @AndrewYNg Interesting, haven't read it yet. Looks like a modified RLHF system that includes a fixed set of rules/principles. Need to read it some time! 
If others are interested: https://t.co/3Dq7YAjiMR https://t.co/lCe3CIR1fw"
210,@rasbt,2023-02-06 20:16:35+00:00,https://twitter.com/rasbt/status/1622690740299042849,"@AndrewYNg 4/4

And a few more/most recent ones

BLOOM, a distributed open-source effort, https://t.co/W0fyOnZgvm

Sparrow, DeepMind's ChatGPT offering (since there is no ChatGPT paper), https://t.co/BuYPXp6rnq

Meta's ChatGPT alternative that can search the internet https://t.co/3lmHtBc9Ly"
211,@rasbt,2023-02-06 20:09:18+00:00,https://twitter.com/rasbt/status/1622688907883122703,"@AndrewYNg 3/3

6) Cramming to train on a single GPU (https://t.co/sv3VMPE5KF)

7) InstructGPT to align LLMs (https://t.co/cHpi3Wrbwb)"
212,@rasbt,2023-02-06 20:08:53+00:00,https://twitter.com/rasbt/status/1622688804082487313,"@AndrewYNg 2/3

3) GPT for a decoder-style LLM for generative modeling (https://t.co/jG19dPH5oO)

4) BART to combine both encoder &amp; decoder parts again (https://t.co/sU7b6jUSdA)

5) FlashAttention to boost efficiency (https://t.co/LZkECZEHka)"
213,@rasbt,2023-02-06 20:08:38+00:00,https://twitter.com/rasbt/status/1622688741335699457,"@AndrewYNg I can't help but recommend a whole selection üòÖ

in chron. order

1) The original transformer for the intro to scaled dot product attention (https://t.co/biCse5KhzW)

2) BERT for an encoder-style LLM and masked-language modeling for prediction tasks (https://t.co/aDqI0QSiL6)

1/3"
214,@rasbt,2023-02-06 17:00:56+00:00,https://twitter.com/rasbt/status/1622641503930548226,"@SVenkatachalam Whoa, thanks for the compliment üòä"
215,@rasbt,2023-02-06 16:42:22+00:00,https://twitter.com/rasbt/status/1622636832377667585,"@svpino Haha, oops, free points for a few more minutes until I get it fixed üòÖ! Thanks!"
216,@rasbt,2023-02-06 16:36:38+00:00,https://twitter.com/rasbt/status/1622635388236857346,"@svpino Thanks for the recommendation! üòä

PS: You mean this one? (Didn't want to make the initial quizzes too hard ...) https://t.co/03Ak51yXAp"
217,@rasbt,2023-02-06 15:07:58+00:00,https://twitter.com/rasbt/status/1622613073746862081,@alexxubyte @FaisalAlsrheed Congrats! Ordered and looking forward to it! I love reading Q&amp;A resources since that's such an effective way to learn!
218,@rasbt,2023-02-06 14:14:57+00:00,https://twitter.com/rasbt/status/1622599731540107275,"@AllenDowney @marktenenholtz üíØHaha, this is hard to beat!"
219,@rasbt,2023-02-06 13:38:44+00:00,https://twitter.com/rasbt/status/1622590618030706689,"Ahead of AI #5: RevAIval of Ideas is out!

A particularly exciting one since a lot has happened this month!

This issue covers
‚Ä¢ Self-supervised learning for CNNs
‚Ä¢ Benefits of pretraining LLMs from scratch
‚Ä¢ Open source highlights

üëâ https://t.co/ZfVkFn6YYB

Happy Monday!"
220,@rasbt,2023-02-06 12:46:35+00:00,https://twitter.com/rasbt/status/1622577493621321730,@cwizprod1 That makes me really happy to hear. I put a lot of thought into the sequencing and structure of this course!
221,@rasbt,2023-02-06 12:45:42+00:00,https://twitter.com/rasbt/status/1622577274359889920,"@AlbertoAndreott Protein engineering in pharma and food industries. Or think of new, more efficient variants of the enzymes in your laundry detergent."
222,@rasbt,2023-02-06 03:00:01+00:00,https://twitter.com/rasbt/status/1622429882016727041,"@cwizprod1 Thanks for the kind words, glad to hear you got something useful out of it!"
223,@rasbt,2023-02-05 23:08:11+00:00,https://twitter.com/rasbt/status/1622371537964654593,"@paddy_the_faddy @ylecun When I remember correctly, the YouTube video cat-detector was one of the first big things Google Brain did after it was founded a few months earlier. 
@AndrewYNg may know more of the details."
224,@rasbt,2023-02-05 23:04:27+00:00,https://twitter.com/rasbt/status/1622370600000884737,"@paddy_the_faddy @ylecun It's been more than a decade and not sure if people remember, but cats were pretty big back then: https://t.co/4wrQyL3Eo1"
225,@rasbt,2023-02-05 23:02:26+00:00,https://twitter.com/rasbt/status/1622370091907129344,@ylecun Cat-level AI would be very useful for creating compelling public demos to secure future rounds of funding. The internet loves cats
226,@rasbt,2023-02-05 23:00:59+00:00,https://twitter.com/rasbt/status/1622369726511947777,@ylecun Hot take: Cat videos did more for AI than any LLM so far.
227,@rasbt,2023-02-05 22:22:30+00:00,https://twitter.com/rasbt/status/1622360043269005312,"@GiorgioMantova @KingSoon4774 Thanks for the feedback, that‚Äôs good to know!"
228,@rasbt,2023-02-05 15:14:23+00:00,https://twitter.com/rasbt/status/1622252303569887232,"@cwolferesearch Oh yes, I remember this one, I think this was by the teams at Meta / FAIR"
229,@rasbt,2023-02-05 14:49:01+00:00,https://twitter.com/rasbt/status/1622245917565898753,"@harichandra01 We just need a large enough training dataset for these 3D printer code examples. If you want to get good results, 500 million to 2 billion code examples would be a reasonable number here."
230,@rasbt,2023-02-05 14:21:41+00:00,https://twitter.com/rasbt/status/1622239037829308416,"@Yoozer00 Ok, even if it is possible to somehow get your data conveniently in there, hook  it up to GitHub, install Visual Studio Code, and manage multiple virtual Python environments with conda, there is still the question of ""why"" (compared to doing it on a laptop) :P"
231,@rasbt,2023-02-05 14:16:03+00:00,https://twitter.com/rasbt/status/1622237621475835905,"The impressive thing here is that the researchers didn't just train an LLM on amino acid strings. They went ahead, synthesized full-length genes, and expressed these proteins for real. The artificial proteins exhibited the same level of functionality as natural proteins."
232,@rasbt,2023-02-05 14:06:46+00:00,https://twitter.com/rasbt/status/1622235284610899968,"Tired: train a large language model (LLM) to generate text in human languages

Wired: train an LLM to generate proteins sequences, the language of life

In this recent paper, researchers trained a decoder-style LLM to generate functional proteins:
https://t.co/bZFBoULnN0 https://t.co/FQvb3rKnw3"
233,@rasbt,2023-02-05 13:48:26+00:00,https://twitter.com/rasbt/status/1622230670645858304,"@Yoozer00 Say I want to write a quick Python script to change all the ""¬© 2013-2022"" to ""¬© 2013-2023"" on my website. Can I do that with any of these programs? How would I rsync / upload my website HTMLs into these programs?"
234,@rasbt,2023-02-05 13:41:38+00:00,https://twitter.com/rasbt/status/1622228958992375808,@Yoozer00 Which is only useful for like 20% of the real-world use cases.
235,@rasbt,2023-02-05 13:39:36+00:00,https://twitter.com/rasbt/status/1622228449229160448,@fazlulkarim97 that model doesn't have ports on the other side
236,@rasbt,2023-02-05 13:38:03+00:00,https://twitter.com/rasbt/status/1622228057426743297,@Yoozer00 It can't even run Python
237,@rasbt,2023-02-05 13:37:33+00:00,https://twitter.com/rasbt/status/1622227934990798848,"@zaialamm Then there's also the big advantage that macOS is Unix-based, so the terminal supports the same bash/zsh that I use on external linux servers -- so, I'd say familiarity is also a big one.
This extends also to how the file system works."
238,@rasbt,2023-02-05 13:35:57+00:00,https://twitter.com/rasbt/status/1622227531733540866,"@zaialamm I had a windows laptop until ~2011; back then it was due to the better Python support. I think Python's multiprocessing on Windows is still buggy for example 
(when I am teaching and students come to me with problems, most of them are Windows-related)"
239,@rasbt,2023-02-05 04:22:33+00:00,https://twitter.com/rasbt/status/1622088262297714688,@lgvelazco Not specifically about production‚Äîi think there are not many papers on production use cases because most papers tend to be academic‚Äî but I‚Äôd say anything related to overfitting and/or robustness would probably qualify
240,@rasbt,2023-02-05 04:17:48+00:00,https://twitter.com/rasbt/status/1622087066002522113,"@MichaelKevinSp2 @LexSokolin You are welcome! Substack is a fun place, and thanks for the kind words! (Speaking of which, Ahead of AI #5 is ready to go life on Monday :))"
241,@rasbt,2023-02-05 04:14:49+00:00,https://twitter.com/rasbt/status/1622086317700939777,@JirkaBorovec Haha yeah that‚Äôs fair. It more of that satisfaction that it feels more snappy when you use it locally.
242,@rasbt,2023-02-05 00:16:17+00:00,https://twitter.com/rasbt/status/1622026288717258754,"@nikhil_ai @NatureBiotech Oh never mind, I got my hands on the recent paper in Nature now -- I guess it took 2 1/2 to publish? Anyways, happy to read it now and reference it in Ahead of AI newsletter on Monday!"
243,@rasbt,2023-02-04 23:53:36+00:00,https://twitter.com/rasbt/status/1622020580206592000,"@nikhil_ai @NatureBiotech Just reading the blog post, and big congrats on this work! Sorry, maybe silly question, but since you tweeted this in Jan 2023, I wonder if the 2021 time stamp is a typo? https://t.co/Vrt4Jhtamx"
244,@rasbt,2023-02-04 22:54:05+00:00,https://twitter.com/rasbt/status/1622005603072622593,@chrisalbon Can it do my German accent üòÖ
245,@rasbt,2023-02-04 22:53:39+00:00,https://twitter.com/rasbt/status/1622005492959567873,"@chrisalbon Whoa, that‚Äôs in iBooks?"
246,@rasbt,2023-02-04 20:17:28+00:00,https://twitter.com/rasbt/status/1621966186429677578,"@MaziyarPanahi Yeah, it's crazy expensive (1,599) and you could buy a second laptop for that. But yeah, I am hoping it will last me a long time, maybe 5-10 years."
247,@rasbt,2023-02-04 19:11:56+00:00,https://twitter.com/rasbt/status/1621949695005163520,@Tom14985282 @wongmjane Yeah I know what you mean. But with newer higher res monitors you can now have everything side by side which is even more convenient
248,@rasbt,2023-02-04 17:38:32+00:00,https://twitter.com/rasbt/status/1621926189815275520,"@egrefen Same for me, I've always been using the laptop in clamshell mode in recent years when at home. Also, via two-finger swipe, it's easy enough to switch to a separate virtual screen in macOS, no need for a second physical screen I'd say."
249,@rasbt,2023-02-04 17:28:57+00:00,https://twitter.com/rasbt/status/1621923778228883461,"@egrefen That's a too expensive Apple Monitor. I told myself that it's essential for me because due to the high resolution
a) I am still putting it off to get reading/computer glasses
b) I am doing lot of high-resolution screen capturing. üòÖ"
250,@rasbt,2023-02-04 17:22:32+00:00,https://twitter.com/rasbt/status/1621922163484663810,"@nixcad @wongmjane I was using the university cluster. I was also fortunate that we had some GPUs in our lab as well.
Nowadays, I mostly use cloud services."
251,@rasbt,2023-02-04 17:13:15+00:00,https://twitter.com/rasbt/status/1621919826691198977,"@harshit1verma Hah, don't want to take a side, I am just here for the ride üòÖ"
252,@rasbt,2023-02-04 16:53:50+00:00,https://twitter.com/rasbt/status/1621914942495510528,@roydanroy Metaphor for the S&amp;P 500 this month? üòÖ
253,@rasbt,2023-02-04 16:34:53+00:00,https://twitter.com/rasbt/status/1621910173613789184,"@shravankumar147 @pytorchlightnin No worries, you don't have to use it yourself. It's just used by the Trainer to keep track of certain things (e.g., when you do distributed training etc.). You just have it there as a parameter but you don't have to explicitly do anything with it."
254,@rasbt,2023-02-04 16:13:48+00:00,https://twitter.com/rasbt/status/1621904868934909953,"@elyktrix 27"" is a good size. I once tried a larger 32"" one but it's too much where you have to turn your head left and right all the time."
255,@rasbt,2023-02-04 15:51:19+00:00,https://twitter.com/rasbt/status/1621899210730643456,"All you need is a 13"" inch MacBook Air. 

When I was a student, I wrote
- MLxtend
- My first two books
- My blog
- PhD Thesis
- ...

all on that little laptop.
And guess what I am using right now ... 

(ok ok, connected to a external monitor for posture reasons) https://t.co/qO5MyTXjM2"
256,@rasbt,2023-02-04 15:39:37+00:00,https://twitter.com/rasbt/status/1621896265771384833,"@wongmjane I think I was most productive when I was a student and just had a 13"" MacBook Air. 
Both my PhD thesis and my first 2 books were written on that thing."
257,@rasbt,2023-02-04 15:37:34+00:00,https://twitter.com/rasbt/status/1621895747355418624,"@ykilcher Hah, just saw the logo and for a sec I thought you joined Baidu"
258,@rasbt,2023-02-04 15:35:22+00:00,https://twitter.com/rasbt/status/1621895196182036481,@KingSoon4774 Thanks! I always tell my students: making the exam is probably harder than taking the exam. But I hope it's worth it!
259,@rasbt,2023-02-04 14:45:01+00:00,https://twitter.com/rasbt/status/1621882523801325570,"If you are working on some hobby projects this weekend and find that submitting PRs has become a slog due to the slow CI pipelines, it's maybe worth giving Ruff a try. Ruff is an extremely fast Python linter written in Rust and can be installed via pip: 

https://t.co/bvwo7fImQu https://t.co/Fh7hmXVK0J"
260,@rasbt,2023-02-04 13:46:16+00:00,https://twitter.com/rasbt/status/1621867738971996160,"@CodyWatsonAI @deliprao @srchvrs @johnjnay @TheEconomist @stateofaireport @ZetaVector @jakubzavrel Yeah, exactly. Honestly, I don't mind answering questions and explaining. However, most reviewers don't ask like normal people but, most of the time, seem really hostile, which is what I find so frustrating about this."
261,@rasbt,2023-02-04 13:43:22+00:00,https://twitter.com/rasbt/status/1621867011360833536,"@ylecun I was thinking of the distraction they create, but agreed regarding usefulness."
262,@rasbt,2023-02-04 13:42:08+00:00,https://twitter.com/rasbt/status/1621866697589153796,"@brodreger of course, haha. I don't know why I said otherwise."
263,@rasbt,2023-02-04 13:41:35+00:00,https://twitter.com/rasbt/status/1621866558539681794,"@shikhar1verma Created those ... Context: Ahead of AI #5 coming next week :)

https://t.co/W5kmcV5puC"
264,@rasbt,2023-02-04 13:39:56+00:00,https://twitter.com/rasbt/status/1621866146210238464,@ylecun or a car accident üòÜ
265,@rasbt,2023-02-04 13:38:53+00:00,https://twitter.com/rasbt/status/1621865880836620288,"I realized that the textbooks &amp; courses that were most impactful for me all incorporated varying levels of challenging exercises &amp; quizzes to check my understanding. 

So, I've begun adding reader quizzes ...
Have fun &amp; thanks for supporting this work!

https://t.co/2hcrhceVTz"
266,@rasbt,2023-02-04 03:41:35+00:00,https://twitter.com/rasbt/status/1621715564967108608,@roydanroy I agree. This should be an opt-in option; maybe make that a default for people who already put their paper on arxiv. Otherwise it‚Äôs kind of irresponsible.
267,@rasbt,2023-02-03 20:45:54+00:00,https://twitter.com/rasbt/status/1621610956273979393,@0empathy0 @AlphaSignalAI How would using an LLM impact their add business though? They can still keep the ads if they upgrade their LLM?
268,@rasbt,2023-02-03 20:11:15+00:00,https://twitter.com/rasbt/status/1621602235632259073,@dvassallo It would cover all my monthly online subscription costs and still leave me enough to buy myself a fun book each month. I‚Äôd take it.
269,@rasbt,2023-02-03 20:00:57+00:00,https://twitter.com/rasbt/status/1621599642373787648,@shwin_m @CSProfKGD *Only if it‚Äôs sunny and not super windy
270,@rasbt,2023-02-03 19:57:07+00:00,https://twitter.com/rasbt/status/1621598678946353154,@shwin_m @CSProfKGD Yeah but -20 C vs -30 C is quite a lot for me. Going for a walk vs staying entirely at home.
271,@rasbt,2023-02-03 18:41:43+00:00,https://twitter.com/rasbt/status/1621579705294921728,"@karpathy I wonder what boost you would get from decreasing it to 2^15 = 32,768, (like they did in the cramming paper) and how that would impact the quality of the outputs."
272,@rasbt,2023-02-03 18:34:51+00:00,https://twitter.com/rasbt/status/1621577977128443904,"@Machine01776819 @ylecun @ykilcher @DamiBenveniste Not sure, even if it turns out that works well for larger, higher res datasets and larger models, I think convolutional layers are the least of our concern when it comes to computational requirements.
I remember the results were impressive on the simple benchmarks though."
273,@rasbt,2023-02-03 15:58:46+00:00,https://twitter.com/rasbt/status/1621538697282818049,@deliprao @srchvrs @johnjnay @TheEconomist @stateofaireport @ZetaVector @jakubzavrel Thanks! We have a fun seminar coming up next week üòä https://t.co/ZZj7PXbHkN
274,@rasbt,2023-02-03 15:54:29+00:00,https://twitter.com/rasbt/status/1621537617882873856,@deliprao @srchvrs @johnjnay @TheEconomist @stateofaireport @ZetaVector @jakubzavrel There were always at least 1-2 of those unreasonably negative reviewers that misunderstood something in your paper but wouldn't move an inch from their pre-conceived opinions. It made me angry every time I had to deal with that. Life is too short for that imho.
275,@rasbt,2023-02-03 15:52:24+00:00,https://twitter.com/rasbt/status/1621537092252622849,"@deliprao @srchvrs @johnjnay @TheEconomist @stateofaireport @ZetaVector @jakubzavrel Actually I recently resigned from UW last month and am fully focused on Lighting AI now. I loved research, teaching, and my colleagues, but the academic politics were not for me. Reviewers, on both grants and papers, were too frustrating for me tbh."
276,@rasbt,2023-02-03 15:41:42+00:00,https://twitter.com/rasbt/status/1621534402416185345,"@deliprao @srchvrs @johnjnay @TheEconomist @stateofaireport @ZetaVector @jakubzavrel What did it for me was 2 agencies asking me repeatedly to help reviewing grant apps again (which I did plenty in the past, of course for free) while not even bothering to give me a response to my own submitted applications. 
I don't think I will review grants again either."
277,@rasbt,2023-02-03 15:39:05+00:00,https://twitter.com/rasbt/status/1621533741775478785,"@deliprao @srchvrs @johnjnay @TheEconomist @stateofaireport @ZetaVector @jakubzavrel Haha thanks, but I decided for myself recently that life is too short to waste it on writing grants / funding requests üòÖ"
278,@rasbt,2023-02-03 15:24:21+00:00,https://twitter.com/rasbt/status/1621530033385836545,"@boydgraber @CSProfKGD Personally, -20C is the sweet spot where I'd still go for a 45 min morning walk if it's sunny out. -30C? Nah."
279,@rasbt,2023-02-03 15:19:18+00:00,https://twitter.com/rasbt/status/1621528762457231360,"@deliprao @srchvrs @johnjnay @TheEconomist @stateofaireport @ZetaVector @jakubzavrel I only wish that my passion for research could withstand the cutthroat funding politics in academia, it's basically akin to Game of Thrones ..."
280,@rasbt,2023-02-03 14:55:54+00:00,https://twitter.com/rasbt/status/1621522876305399809,"Finally, you may wonder why do we need to pretrain LLMs yourself anyway given that pretrained models are available off-the-shelf? Research/study purposes, or you may want to adapt them to new language or domains (think protein or DNA sequences).
8/8"
281,@rasbt,2023-02-03 14:55:53+00:00,https://twitter.com/rasbt/status/1621522872060764163,"Btw. a triangular one-cycle learning rate schedules work best.

And dropout was not needed during pretraining due to the large training dataset and 1 epoch training schedule.
7/8 https://t.co/K1kz6Ppf59"
282,@rasbt,2023-02-03 14:55:51+00:00,https://twitter.com/rasbt/status/1621522863206592518,"- there were no benefits of replacing the original multi-head self-attention mechanism with FLASH attention or Fourier attention
- No advantage from changing GELU activations to sth else
- Keeping the original 12 attention heads is important to maintain finetuning performance
6/8"
283,@rasbt,2023-02-03 14:55:51+00:00,https://twitter.com/rasbt/status/1621522860425777162,"What were some of the performance squeezing tricks?

- they used automated operator fusion &amp; 32/16 bit mixed precision training
- they disabled biases in QKV attention matrices and fully-connected layers
- the decreased the input length from 512 -&gt; 128 tokens

5/8"
284,@rasbt,2023-02-03 14:55:50+00:00,https://twitter.com/rasbt/status/1621522856529252352,"Using a few tricks &amp; improvements here and there, they were able to train BERT with 78.6 average performance one a single GPU in 24h
(compared to 80.9 for the original BERT model -- the larger the better)
4/8 https://t.co/QLTLY4n1Us"
285,@rasbt,2023-02-03 14:55:47+00:00,https://twitter.com/rasbt/status/1621522847461163009,"Taking a step back: What did they do? The researchers trained a masked language model / decoder-style LLM (here: BERT) for 24h on 1 GPU ‚Äî for comparison, the original 2018 BERT paper trained it on 16 TPUs for 4 days.
3/8"
286,@rasbt,2023-02-03 14:55:47+00:00,https://twitter.com/rasbt/status/1621522844458049536,"Let‚Äôs start with maybe the most interesting take-way: Sure, smaller models have higher throughput, but smaller models learn less efficiently.
Consequently, larger models don‚Äôt take longer to train!
2/8"
287,@rasbt,2023-02-03 14:55:46+00:00,https://twitter.com/rasbt/status/1621522841417170946,"After putting together a lecture on multi-GPU training paradigms, I thought it might be a good idea to catch up with the recent ‚ÄúCramming: Training a Language Model on a Single GPU in One Day‚Äù paper (https://t.co/sv3VMPEDAd).

An interesting read with lots of insights!
1/8"
288,@rasbt,2023-02-03 14:38:15+00:00,https://twitter.com/rasbt/status/1621518434122235904,"@0empathy0 @AlphaSignalAI Take the CI-MARS requirements:
1. Cost
3. Interpretability
4. Maintainability
5. Adaptability
6. Reliability
7. Scalability

My guess is Google was mainly concerned with 1, 3, 6, 7 regarding releasing ChatGPT-like models. They do already use LLMs for search since 2019ish though"
289,@rasbt,2023-02-03 13:53:20+00:00,https://twitter.com/rasbt/status/1621507128526606342,"*Forgot one:

According to report by Semafor, OpenAI is training a ChatGPT model to execute mundane coding tasks -- the headline reads ""to replace software engineers"".

https://t.co/8zffCfClir"
290,@rasbt,2023-02-03 13:50:57+00:00,https://twitter.com/rasbt/status/1621506531366764544,"LLMs definitely win the headlines this month, again. https://t.co/k3dRJUhW6I"
291,@rasbt,2023-02-03 13:38:39+00:00,https://twitter.com/rasbt/status/1621503432841388033,@deliprao @srchvrs @johnjnay @TheEconomist @stateofaireport @ZetaVector @jakubzavrel Stanford NLP Group specifically. I guess they love the ‚Äúattention‚Äù ‚Äî no pun intended üòÜ
292,@rasbt,2023-02-03 13:24:37+00:00,https://twitter.com/rasbt/status/1621499902768414721,"@harvey_peng123 @CSProfKGD Not ‚Äúextreme‚Äù cold then, just winter :P https://t.co/72vbKMWpry"
293,@rasbt,2023-02-03 13:19:33+00:00,https://twitter.com/rasbt/status/1621498628513714176,@CSProfKGD Fahrenheit or Celsius?
294,@rasbt,2023-02-03 13:17:03+00:00,https://twitter.com/rasbt/status/1621497999481348100,@AlphaSignalAI This could have all been avoided if they had offered a public access version of LaMDA in summer instead of the ‚Äúour AI is conscious‚Äù marketing stunt they did. Show don‚Äôt tell.
295,@rasbt,2023-02-03 12:40:56+00:00,https://twitter.com/rasbt/status/1621488910315528195,"@marketingeyeaus @JagersbergKnut @Google The non-deterministic, unreliable behavior of large language models ‚Ä¶"
296,@rasbt,2023-02-03 12:38:43+00:00,https://twitter.com/rasbt/status/1621488351290265600,@akshay_pachaar I was just about to say ‚Äúhow does it compare to CleanLab?‚Äù before scrolling down ‚Ä¶ never thought of CleanLab as a MIT product lol
297,@rasbt,2023-02-03 12:35:53+00:00,https://twitter.com/rasbt/status/1621487640104116229,"@AiSimonThompson @erich_elsen Yeah, if you are using PyTorch DataLoaders or DataPipes, it‚Äôs actually hard to sample with replacement even if you want to. AFAIK it doesn‚Äôt sample with replacement even if you have a multinode distributed setup where each gpu in each node has a copy of the loader."
298,@rasbt,2023-02-03 03:25:12+00:00,https://twitter.com/rasbt/status/1621349052783681537,"@austinvhuang @BlackHC @randal_olson I think GPTZero is essentially approximating the perplexity scores with a linear model (originally linear regression). DetectGPT ‚Äî haven‚Äôt tried ‚Äî might be a bit more robust 

https://t.co/J0aoXKbDrM"
299,@rasbt,2023-02-03 03:21:26+00:00,https://twitter.com/rasbt/status/1621348105080684546,"@jefrankle @NaveenGRao @MosaicML As a side note, I must say it‚Äôs refreshing to hear that someone is still working on encoder-style LLMs. I think that most real-world problems for AI are probably prediction tasks."
300,@rasbt,2023-02-03 03:18:37+00:00,https://twitter.com/rasbt/status/1621347396016869376,"@marktenenholtz @austinvhuang @BlackHC @randal_olson Yup, that‚Äôs a good idea. Btw I have an overview of the other detection methods here if useful: https://t.co/J0aoXKbDrM"
301,@rasbt,2023-02-03 03:16:57+00:00,https://twitter.com/rasbt/status/1621346978088062976,"@boustta_mo for all the units that follow unit 5, I am hoping to release them all a bit faster in a 1-2 week cadence.l ‚Äî currently working on streamlining the process"
302,@rasbt,2023-02-03 03:15:47+00:00,https://twitter.com/rasbt/status/1621346683790450688,@boustta_mo Thanks for asking! It‚Äôs nice to hear that people are looking forward to it! Still some video editing work to wrap up but hopefully either next week or the following week!
303,@rasbt,2023-02-03 02:12:16+00:00,https://twitter.com/rasbt/status/1621330698995994625,@jrhwood Must have been an early-gen character-level RNN. I always knew the writing was a bit off üòÜ
304,@rasbt,2023-02-03 00:19:48+00:00,https://twitter.com/rasbt/status/1621302399196356610,@austinvhuang @BlackHC @randal_olson I think many educators might include even (possibly) both labels ‚Äúpossibly AI‚Äù and ‚Äúlikely AI‚Äù
305,@rasbt,2023-02-02 20:56:44+00:00,https://twitter.com/rasbt/status/1621251292541640708,"Adding CSI:
- Cost
- Scalability
- Interpretability"
306,@rasbt,2023-02-02 20:48:22+00:00,https://twitter.com/rasbt/status/1621249188791992320,"@LightningAI Cost, speed, interpretability are good ones to add.
CSI MARS?"
307,@rasbt,2023-02-02 20:42:55+00:00,https://twitter.com/rasbt/status/1621247815014912003,@LightningAI I created the MARS mnemonic so I don't forget üòÖ https://t.co/pVg8DBtZIt
308,@rasbt,2023-02-02 20:01:18+00:00,https://twitter.com/rasbt/status/1621237345193271297,@LorenzoBrigato Thanks! I will take a look!
309,@rasbt,2023-02-02 19:31:49+00:00,https://twitter.com/rasbt/status/1621229923242221569,@sama Unless it stands for ‚Äúgenerative Art Investments‚Äù
310,@rasbt,2023-02-02 19:27:56+00:00,https://twitter.com/rasbt/status/1621228946032414722,@erich_elsen You train for a given number of steps. Do people stop the training when they sampled N training points where N is the size of the dataset?
311,@rasbt,2023-02-02 19:25:12+00:00,https://twitter.com/rasbt/status/1621228259185762305,"@Yonatan80710683 The short summaries were not informative enough? üò¢

I have a short (but somewhat longer) write-up here as well: https://t.co/J0aoXKbDrM"
312,@rasbt,2023-02-02 19:23:54+00:00,https://twitter.com/rasbt/status/1621227932432666624,"@__dipam__ @johnjnay @TheEconomist @stateofaireport Yes of course. It depends on what you want to show. If you want to measure the throughput or productivity of the labs there, sure then you would normalize. If you just want to measure the total number of papers, the absolute count makes more sense."
313,@rasbt,2023-02-02 19:21:59+00:00,https://twitter.com/rasbt/status/1621227449408176131,@erich_elsen But that‚Äôs only if you fix N and set N to the number of training examples. Do people still do that?
314,@rasbt,2023-02-02 19:19:20+00:00,https://twitter.com/rasbt/status/1621226783977738244,"@zanospi @ylecun Oops, missed that. It‚Äôs weird though; the OpenAI plot suggests it‚Äôs more than 5 though. The scaling seems off."
315,@rasbt,2023-02-02 19:17:59+00:00,https://twitter.com/rasbt/status/1621226440841740289,"@TheSeaMouse @ylecun Hah, that was what I was originally thinking actually. But given that OpenAI only had 5 papers in 2022 (via their website https://t.co/m9vFyKShXo) I thought the scale wouldn‚Äôt make sense then."
316,@rasbt,2023-02-02 19:15:38+00:00,https://twitter.com/rasbt/status/1621225851340595201,@tunguz Guessing it‚Äôs Probably True
317,@rasbt,2023-02-02 19:14:10+00:00,https://twitter.com/rasbt/status/1621225480329240588,"@ylecun The y-axis is papers per person, or papers in hundreds?"
318,@rasbt,2023-02-02 19:10:55+00:00,https://twitter.com/rasbt/status/1621224662779691010,@CSProfKGD Nice! That‚Äôs a good opportunity to start tracking the espressos/paper metric (or should it be papers/espresso üòÜ)
319,@rasbt,2023-02-02 18:59:02+00:00,https://twitter.com/rasbt/status/1621221671624478720,@__dipam__ @johnjnay @TheEconomist @stateofaireport I assumed the y axis is showing papers in hundreds or in thousands. Not sure what it actually shows
320,@rasbt,2023-02-02 18:49:19+00:00,https://twitter.com/rasbt/status/1621219227720994828,"@tunguz Requirements to add 2 numbers‚Ä¶ 

‚Ä¶ somewhat accurately in 2022: 175 billion parameters and 350 Gb GPU RAM via 5x A100s

‚Ä¶ absolutely accurately in 1980: Texas Instruments pocket calculator with 4kb memory"
321,@rasbt,2023-02-02 18:38:29+00:00,https://twitter.com/rasbt/status/1621216502425784320,@johnjnay @TheEconomist @stateofaireport Otherwise I would have expected to see at least Berkeley or NYU among these ü§î
322,@rasbt,2023-02-02 18:36:17+00:00,https://twitter.com/rasbt/status/1621215950094606336,"@johnjnay @TheEconomist @stateofaireport Is this ranked by total number of papers per institution? Or are some omitted for clarity? 

So yeah, if this is the top 7, it‚Äôs as most people suspected, research may be dominated by companies now (there‚Äôs only one traditional academic institution there if I see it correctly)"
323,@rasbt,2023-02-02 17:48:49+00:00,https://twitter.com/rasbt/status/1621204002321960962,"@EthFr34k Instead of training PaLM, I think we could already use a pre-trained model like BLOOM or OPT for this. The real challenge is to get the supervised data from users. It's not easy to collected hundreds of thousands hand-written answers to certain prompts."
324,@rasbt,2023-02-02 17:17:26+00:00,https://twitter.com/rasbt/status/1621196103654711300,"@KouraAbdelrahim @MuhammadAnas707 Good question! There are two parts to this answer: 1st, it's an extension of my original Machine Learning Book from 2015. (It grew to half ML, half DL). The 2nd part is that I do think that regular ML is still relevant and a good intro before diving into deep neural networks"
325,@rasbt,2023-02-02 15:59:18+00:00,https://twitter.com/rasbt/status/1621176441357336576,"@MuhammadAnas707 Thanks for asking / checking in! I am okay, no worries, just a very busy week at work!"
326,@rasbt,2023-02-02 15:13:25+00:00,https://twitter.com/rasbt/status/1621164894736506880,"Sources 3/3 

Science Magazine's policies state that ""text generated by ChatGPT (or any other AI tools) cannot be used in the work, nor can figures, images, or graphics be the products of such tools""
https://t.co/8nXQQBvFGq"
327,@rasbt,2023-02-02 15:13:24+00:00,https://twitter.com/rasbt/status/1621164892647731205,"Sources 2/3:

Springer Nature ""says it has no problem with AI being used to help write research ‚Äî as long as its use is properly disclosed.""
https://t.co/Htl7O9bcjK"
328,@rasbt,2023-02-02 15:13:24+00:00,https://twitter.com/rasbt/status/1621164890839982080,"Sources 1/3: 
Getty Images bans AI-generated content: https://t.co/rKklzMwrBt

Getty Images sues Stability AI https://t.co/ItunQBiRIC

Shutterstock adds text-to-image AI: https://t.co/hI7k7VJDFE 

Shutterstock compensation plan for data used for training: https://t.co/2KDQsc7egO"
329,@rasbt,2023-02-02 15:09:41+00:00,https://twitter.com/rasbt/status/1621163956210487297,"It will be interesting to see how things play out for competing companies who are pro/con AI-generated content.

(1) 
- Getty Images bans AI and sues
- Shutterstock adds AI and compensates

(2) 
- Science Magazine bans AI content 
- Springer Nature permits authors to use AI"
330,@rasbt,2023-02-02 13:55:16+00:00,https://twitter.com/rasbt/status/1621145228957868034,"@CristiVlad25 @aureliengeron Thanks for the recommendation, glad you liked our books! :)"
331,@rasbt,2023-02-02 13:34:08+00:00,https://twitter.com/rasbt/status/1621139908504199169,"@BlackHC @OpenAI Isn't the false positive rate they reported 30%?
21% + 9%? https://t.co/fm4gEbsRer"
332,@rasbt,2023-02-02 01:19:24+00:00,https://twitter.com/rasbt/status/1620955007951720449,@srchvrs @chriswolfvision Exactly. That‚Äôs a GAN setup right there.
333,@rasbt,2023-02-02 00:47:27+00:00,https://twitter.com/rasbt/status/1620946966007128066,"@chriswolfvision Yeah, to some extent it kind of feels like a bandaid ü©π"
334,@rasbt,2023-02-02 00:46:02+00:00,https://twitter.com/rasbt/status/1620946612691374081,@k_saifullaah Thanks! I agree with the advantages of watermarking. The problem would be to get people/companies to adopt watermarked LLMs.
335,@rasbt,2023-02-02 00:44:16+00:00,https://twitter.com/rasbt/status/1620946164789936129,@JoseLuisMarrugo I agree. But it would be some form of average ‚Äî humans also have vastly different writing styles.
336,@rasbt,2023-02-01 19:02:47+00:00,https://twitter.com/rasbt/status/1620860229658488833,@EmilWallner Whoa congrats! Sounds like some exciting times ahead! üòä
337,@rasbt,2023-02-01 17:58:17+00:00,https://twitter.com/rasbt/status/1620843999501377537,@akshay_pachaar Thanks for the recommendation @akshay_pachaar ! I am glad you like the course!
338,@rasbt,2023-02-01 16:44:12+00:00,https://twitter.com/rasbt/status/1620825352204591106,"@thomasahle @randal_olson Hard to say something about ""better written"" üòÖ. Depending on how this particular detection  method works, all we can say is that the Preface looks more similar to something other humans would write -- but it's not necessarily related to ""better"" or ""worse"""
339,@rasbt,2023-02-01 16:02:56+00:00,https://twitter.com/rasbt/status/1620814969901318146,"@flybird110013 I have a slightly extended version here, I hope it helps: https://t.co/J0aoXKcbhk"
340,@rasbt,2023-02-01 15:32:26+00:00,https://twitter.com/rasbt/status/1620807293700038656,"@AISupremacyNews @GaryMarcus @bentossell @nonmayorpete @AiBreakfast @AnthonyCastrio Wow, flattered that Ahead of AI made the list!! 

(PS: New issue dropping next week üòä)"
341,@rasbt,2023-02-01 15:31:21+00:00,https://twitter.com/rasbt/status/1620807019300265984,"@joramar_ Yeah, it's an arms race"
342,@rasbt,2023-02-01 15:21:43+00:00,https://twitter.com/rasbt/status/1620804595885944833,Here is a slightly longer version I typed up before truncating it for the Twitter thread: https://t.co/J0aoXKcbhk
343,@rasbt,2023-02-01 14:22:15+00:00,https://twitter.com/rasbt/status/1620789630487482371,"[5/5] Sources:

(1) OpenAI AI classifier: https://t.co/ibTQboJuc5

(2) Detect GPT: https://t.co/3Rlxuvw1mx

(3) GPTZero: https://t.co/K4SsVPeuTo

(4) Watermarking: https://t.co/eWlQKSS0Z1"
344,@rasbt,2023-02-01 14:22:14+00:00,https://twitter.com/rasbt/status/1620789627429732361,"(4) Watermarking. The idea is to lower the probas of certain words so that they are less likely being used by the LLMs using an ""avoid list"".

Limitations: Requires an LLM that has been modified with this avoid list. If the avoid list is known, one can modify AI-generated text."
345,@rasbt,2023-02-01 14:22:13+00:00,https://twitter.com/rasbt/status/1620789624317644803,"(3) GPTZero computes perplexity values (related to log-probas of the texts). GPTZero assumes the lower perplexity are more likely generated by an AI.

Limitations: see DetectGPT above. Furthermore, GPTZero only approximates the perplexity values by using a linear model."
346,@rasbt,2023-02-01 14:22:13+00:00,https://twitter.com/rasbt/status/1620789620777574401,"(2) DetectGPT perturbs the text: if the probability of the new text is noticeably lower than the original one it is AI-generated. Otherwise, if it's approx the same, it's human-generated.

Limitation: Access to probas via a specific LLM model that may not be representative"
347,@rasbt,2023-02-01 14:22:12+00:00,https://twitter.com/rasbt/status/1620789617585692674,"(1) AI Classifier: a GPT model fine-tuned via supervised learning to perform binary classification -- the training dataset consisted of human- &amp; AI-written text passages. The probas [0, 1] are thresholded to obtain the four categories.

Limitation: Representative training data"
348,@rasbt,2023-02-01 14:22:11+00:00,https://twitter.com/rasbt/status/1620789614490357760,"What are the different approaches for detecting content generated by LLMs such as ChatGPT? And how do they work and differ?

Let's discuss
(1) The AI Classifier by OpenAI
(2) DetectGPT
(3) GPTZero
(4) Watermarking

1/5"
349,@rasbt,2023-02-01 03:27:41+00:00,https://twitter.com/rasbt/status/1620624905464336385,"@AliAbdaal @AISupremacyNews For all the hard times I am giving it, I do find ChatGPT useful. Especially when my brain is tired and I need to rewrite a sentence because I am reusing the same word or structure too often. It‚Äôs basically a thesaurus on steroids for me."
350,@rasbt,2023-02-01 00:58:59+00:00,https://twitter.com/rasbt/status/1620587483611422720,@BlackHC @randal_olson Yes that‚Äôs fair
351,@rasbt,2023-01-31 20:45:15+00:00,https://twitter.com/rasbt/status/1620523629825126400,"@omarsar0 Agreed, e.g., let it rewrite your thoughts not create your thoughts"
352,@rasbt,2023-01-31 19:46:40+00:00,https://twitter.com/rasbt/status/1620508884619378688,"Plot twist: after ChatGPT making your homework easier, it's now harder than ever before. 

You now have to rephrase your own words several times until they don't look AI-generated anymore before you can submit."
353,@rasbt,2023-01-31 19:36:13+00:00,https://twitter.com/rasbt/status/1620506255239544834,"@ludwig_stumpp Ahh thanks, I just saw it's under the ""Where can I find a Model Card for the classifier?"" menu. 
Maybe it would make sense to create a more obvious ""Limitations"" section for that."
354,@rasbt,2023-01-31 19:34:11+00:00,https://twitter.com/rasbt/status/1620505745262510080,"@chrisalbon Given my writing style, I will never be allowed to submit a school or college essay again üò¢.

Already looking forward to the day when all my emails get rerouted to SPAM folders because ChatGPT is apparently mimicking my style thanks to all the free training data from my website."
355,@rasbt,2023-01-31 19:23:31+00:00,https://twitter.com/rasbt/status/1620503057695141888,"If you deploy a model like this, pls share a confusioon matrix.
Models like this can cause real-world harm due to educators adopting this for grading. So let's add some transparency about False Positives and False Negatives."
356,@rasbt,2023-01-31 19:20:35+00:00,https://twitter.com/rasbt/status/1620502321590579200,"Hypothesis: can't feed anything created before 2022, because it was all training data."
357,@rasbt,2023-01-31 19:17:21+00:00,https://twitter.com/rasbt/status/1620501507924975618,"@jmschreiber91 @randal_olson I'll admit, I just imitated Shakespeare
https://t.co/KxmEuJcZWN"
358,@rasbt,2023-01-31 19:16:32+00:00,https://twitter.com/rasbt/status/1620501301527453702,First page from Shakespeare's Macbeth. What!? https://t.co/hnNcBcM9Wk
359,@rasbt,2023-01-31 19:11:22+00:00,https://twitter.com/rasbt/status/1620500000278192129,"@fisadev @randal_olson Maybe I should feel flattered, the AI read so many of my text that it learned to imitate me, haha"
360,@rasbt,2023-01-31 19:10:30+00:00,https://twitter.com/rasbt/status/1620499783956987904,"I mean, this is a funny example, but I already feel bad for students who might get penalized for their essays in the future because of this."
361,@rasbt,2023-01-31 19:08:18+00:00,https://twitter.com/rasbt/status/1620499228983463936,"@RespectToX @randal_olson Haha, yeah, my private AI toolchain was way ahead of its time"
362,@rasbt,2023-01-31 19:01:30+00:00,https://twitter.com/rasbt/status/1620497520479830016,"OpenAI just launched the ""AI Text Classifier"" to identify texts generated by AI. 
Tried it, and IT DOES NOT WORK.
https://t.co/ibTQboK21D

Using my Python ML book published in 2015:

1) @randal_olson's foreword: unclear
2) my preface: possibly AI
3) paragraph from Ch1: likely AI https://t.co/lm1D1lYohb"
363,@rasbt,2023-01-31 15:02:44+00:00,https://twitter.com/rasbt/status/1620437432692019201,"@bozavlado @david_picard @PyTorch Yeah, there's such a rich interaction between methods that it's impossible to make statements that generalize. It's always more useful to say ""in this specific context, on this model and dataset, with these other hyperparameters, this thing may be better"""
364,@rasbt,2023-01-31 14:38:50+00:00,https://twitter.com/rasbt/status/1620431418278178818,"@bozavlado @david_picard @PyTorch Yeah, I am adding/experimenting with all techniques in isolation before combining them.

https://t.co/KL4AtbKzah"
365,@rasbt,2023-01-31 14:25:20+00:00,https://twitter.com/rasbt/status/1620428019503620107,"Had a fun chat with @prateekvjoshi on the Infinite Machine Learning podcast üöÄ

We chatted about frameworks for writing books, the current state of AI, trends, and our favorite AI use-cases üéß

Apple Podcasts: https://t.co/h1lUDJ2M1m

Spotify: https://t.co/Aw7tAFkPqn"
366,@rasbt,2023-01-31 14:16:48+00:00,https://twitter.com/rasbt/status/1620425873517334530,"@david_picard @PyTorch This was originally part of an experiment where I wanted to study how much each of the ~16 techniques to reduce overfitting helps, starting with each method individually before trying different combinations."
367,@rasbt,2023-01-31 14:13:26+00:00,https://twitter.com/rasbt/status/1620425024841846784,@bozavlado @david_picard @PyTorch It's on purpose
368,@rasbt,2023-01-31 14:13:03+00:00,https://twitter.com/rasbt/status/1620424926753853449,@david_picard @PyTorch This was on purpose. To measure the effect of only data augmentation without any interference from other techniques.
369,@rasbt,2023-01-31 14:11:53+00:00,https://twitter.com/rasbt/status/1620424633219698695,@JayDeep_1729 Neural nets (trained via backpropagation and fine-tuning via proximal policy optimization) are not rule-based but learn to approximate functions by learning from labeled examples. That's not really a good approach for solving math problems that are rule-based.
370,@rasbt,2023-01-31 14:09:34+00:00,https://twitter.com/rasbt/status/1620424053222961155,"@vattybear @PacktPub Thanks for the note @vattybear!

Could you please look into this @PacktPublishing  ?"
371,@rasbt,2023-01-31 03:25:32+00:00,https://twitter.com/rasbt/status/1620261976286064646,"@robertnridley1 Yeah. The right thing to do here would be to recognize math requests, then reroute these to Copilot to write the Python or SymPy code, run code in the backend, and then return the results."
372,@rasbt,2023-01-31 03:22:07+00:00,https://twitter.com/rasbt/status/1620261113391882249,"@labeeb_Ibrahim It does have 42 in it, doesn't it? üòÜ"
373,@rasbt,2023-01-31 03:21:25+00:00,https://twitter.com/rasbt/status/1620260940930482177,"By all means, use chatGPT to improve your writing. It's great for that. But math is not its strength. That's not how neural networks work."
374,@rasbt,2023-01-31 03:10:00+00:00,https://twitter.com/rasbt/status/1620258064690724864,"""We‚Äôve upgraded the ChatGPT model with improved factuality and mathematical capabilities."" (https://t.co/EafWZGKBuj)

Close! https://t.co/QioInP19Cn"
375,@rasbt,2023-01-30 23:49:27+00:00,https://twitter.com/rasbt/status/1620207596149047298,"@gowthami_s @PyTorch Need to read this, this was sth I was looking for! Thanks for sharing!"
376,@rasbt,2023-01-30 23:48:28+00:00,https://twitter.com/rasbt/status/1620207349351981056,"@mr_anton_r @fisadev Cleaned it up based on your suggestion, and will add it to the next book update next weekend, along with a kind acknowledgement üòä https://t.co/zFC9HIeJzm"
377,@rasbt,2023-01-30 23:40:10+00:00,https://twitter.com/rasbt/status/1620205261066743809,@fhuszar I believe it. No one can be that productive and dedicated towards answering questions as @ptrblck_de! üòä
378,@rasbt,2023-01-30 22:18:14+00:00,https://twitter.com/rasbt/status/1620184640727433229,"@jsotterbach Yeah, I can see how larger batch sizes are useful for having a larger pool to select samples from in contrastive learning regimes. 
As a side note, autoregressive methods have recently become the more successful self-supervised learning paradigm ... maybe because of that :P"
379,@rasbt,2023-01-30 20:53:58+00:00,https://twitter.com/rasbt/status/1620163432602546176,"@yaroslavvb @deliprao @ylecun Nice! Just sent to my e-reader, and I am looking forward to reading it!"
380,@rasbt,2023-01-30 20:41:08+00:00,https://twitter.com/rasbt/status/1620160203353362435,"@anuragcomm @svpino Not sure how you do it, but I am constantly above 10Gb in my RAM usage."
381,@rasbt,2023-01-30 20:35:54+00:00,https://twitter.com/rasbt/status/1620158888099340288,"Excited to be giving a live webinar next week where we talk more about how we 3x-ed the inference speed of Stable Diffusion in PyTorch.

Do you have any questions you‚Äôd like us to answer &amp; chat about? Happy to include those!!

https://t.co/w6hvkOVAQ6"
382,@rasbt,2023-01-30 20:27:24+00:00,https://twitter.com/rasbt/status/1620156748618436609,"@wenmingye @svpino If I buy a machine that ends up in a server-rack, I maybe don't care. But if it's a laptop that I plan on using 3-5 years, and that I carry around on at least 100 trips, I have different priorities :P"
383,@rasbt,2023-01-30 20:25:10+00:00,https://twitter.com/rasbt/status/1620156186267103232,"@wenmingye @svpino For better or worse, when you buy a MacBook, you largely pay for the design (both the OS and the hardware). 
Sure, other laptops are cheaper, but they are not as quiet and durable. My partner has a Thinkpad which is basically all plastic, huge, and sounds like hairdryer."
384,@rasbt,2023-01-30 19:44:28+00:00,https://twitter.com/rasbt/status/1620145942459736066,"@thegautamkamath Fun fact: I only recently learned that the endorsement was not mandatory if you use an .edu address. I signed up for arxiv via my private email vs using my university work email address, which caused a lot of extra hassle.
Tip: use an edu address if you have one."
385,@rasbt,2023-01-30 18:36:43+00:00,https://twitter.com/rasbt/status/1620128892718837760,@wightmanr @PyTorch Thanks for sharing! Curious to try that on ViTs!
386,@rasbt,2023-01-30 18:27:12+00:00,https://twitter.com/rasbt/status/1620126499335708673,"@wightmanr @PyTorch That's true. The RandAugment paper discusses this; however the PyTorch version, as far as I can tell, does not implement the magnitude schedule."
387,@rasbt,2023-01-30 18:21:39+00:00,https://twitter.com/rasbt/status/1620125103966257152,"@wightmanr @PyTorch But of course, that is true for any type of methods, ye goode olde no free lunch theorem"
388,@rasbt,2023-01-30 18:21:06+00:00,https://twitter.com/rasbt/status/1620124965424226304,"@wightmanr @PyTorch That's fair. As I mentioned in the limitation section, this is only based on a single architectures and YMMV depending on your dataset and model. That's why I specifically mentioned CIFAR-10 in the OP."
389,@rasbt,2023-01-30 18:18:28+00:00,https://twitter.com/rasbt/status/1620124301310722048,"@wightmanr @PyTorch Hah, ok, I see what you mean. Then let's me rephrase it. TrivialAugment/Timm's RandAugment performs better than vanilla RandAugment on CIFAR-10/ImageNet"
390,@rasbt,2023-01-30 18:16:54+00:00,https://twitter.com/rasbt/status/1620123907943714816,"@wightmanr @PyTorch The other aspect: my findings are consistent with the ones in the TrivialAug paper where they reported that TrivialAug performed better on ImageNet as well. I am curious, do you have different experiences?"
391,@rasbt,2023-01-30 18:13:40+00:00,https://twitter.com/rasbt/status/1620123095158890497,"@wightmanr @PyTorch In the paper, the authors specifically said that it's not just a special case of RandAug. In RandAug, you choose a hyperparameter for the whole dataset. In TrivialAug, you sample randomly for each individual image in each minibatch."
392,@rasbt,2023-01-30 18:00:44+00:00,https://twitter.com/rasbt/status/1620119836734128128,"Went down the rabbit hole of comparing *automatic* image augmentation methods in @pytorch.
TrivialAugment -- the simplest solution -- seems to be the clear winner, boosting the test set accuracy on CIFAR-10 by 15%!

A more detailed write-up in my blog: https://t.co/dcayy2lkrT"
393,@rasbt,2023-01-30 15:43:44+00:00,https://twitter.com/rasbt/status/1620085361400778752,"@MuhammadAnas707 Haha, it's been some time and I don't remember. I hope I didn't forget to carve it that year üòÖ"
394,@rasbt,2023-01-30 14:43:28+00:00,https://twitter.com/rasbt/status/1620070195242086400,"@LChoshen @icmlconf Agreed, the social media ban does not sound very practical."
395,@rasbt,2023-01-30 14:21:53+00:00,https://twitter.com/rasbt/status/1620064763098300416,"@AISupremacyNews There are even much bigger models by now (see https://t.co/sIHyFGvEVR and https://t.co/4SDSEpfCkH).
I still believe that the RLHF is the bottleneck -- the pre-trained models already exists and can be readily adopted."
396,@rasbt,2023-01-30 14:18:09+00:00,https://twitter.com/rasbt/status/1620063822064275458,@ADutchEngineer @rossbach_io @svpino Yes üíØ
397,@rasbt,2023-01-30 14:14:26+00:00,https://twitter.com/rasbt/status/1620062889599184897,@ADutchEngineer @rossbach_io @svpino *but it may have changed in recent years. It's a good platform for exchanging ideas though due to the comment feature. It's just not very efficient for real work.
398,@rasbt,2023-01-30 14:13:30+00:00,https://twitter.com/rasbt/status/1620062653531164675,"@ADutchEngineer @rossbach_io @svpino I am not a big fan of Google Colab. It's limited to one single GPU, and there is no easy way to request more (I would be willing to pay hourly if I need to get important work done). And I also found there are data loading bottlenecks due to RAM limitations and slow hard drives.*"
399,@rasbt,2023-01-30 13:43:01+00:00,https://twitter.com/rasbt/status/1620054981415170048,@LeoVasanko @AISupremacyNews I think the pre-training is not the issue. You can use an existing model for that. (That's what they did with ChatGPT as well via GPT-3). The bottleneck is the RLHF part
400,@rasbt,2023-01-30 13:28:29+00:00,https://twitter.com/rasbt/status/1620051324548288513,"@LeoVasanko @AISupremacyNews I think Whisper has been explicitely trained for that. I don't doubt that ChatGPT does ok on other languages (ChatGPT is down for me; gonna have to stress-test it in German later haha). But for a big search company, it probably makes sense to develop a model in their main lang."
401,@rasbt,2023-01-30 13:22:39+00:00,https://twitter.com/rasbt/status/1620049855812108288,"@CicmilJovan I usually 'print' my newsletters as PDF and then send them to my e-reader. So, Option 1 is way more convenient, otherwise, I have to make a note to export the other article later as well."
402,@rasbt,2023-01-30 13:20:23+00:00,https://twitter.com/rasbt/status/1620049286020104193,"@AISupremacyNews In addition, ChatGPT was also primarily trained &amp; finetuned on English texts afaik"
403,@rasbt,2023-01-30 13:12:23+00:00,https://twitter.com/rasbt/status/1620047272481550337,"@mr_anton_r @fisadev Thanks, I will bookmark it!"
404,@rasbt,2023-01-30 13:05:00+00:00,https://twitter.com/rasbt/status/1620045416099368960,@mr_anton_r @fisadev This DOES look really nice. Thanks!
405,@rasbt,2023-01-30 13:04:08+00:00,https://twitter.com/rasbt/status/1620045194510086146,"@rossbach_io @ADutchEngineer @svpino Yeah, the M1 GPU. I don't train models on my laptop though unless it's for simple examples &amp; teaching. For everything else I use a separate server."
406,@rasbt,2023-01-30 13:02:34+00:00,https://twitter.com/rasbt/status/1620044802548191232,"@windy_dean1219 @svpino No it's not. Right now I basically only have a browser, email, calendar, and text editor open right now and am already at 60% of the 16 Gb RAM in my machine. https://t.co/eJnwTaRjaG"
407,@rasbt,2023-01-30 01:52:26+00:00,https://twitter.com/rasbt/status/1619876157033435136,@shwin_m @_rlys I‚Äôd say it depends. Can be more like a brisk walk I‚Äôd say. But ok that‚Äôs fair. Let‚Äôs add video games to the list then instead.
408,@rasbt,2023-01-30 01:48:46+00:00,https://twitter.com/rasbt/status/1619875235737788416,@_rlys More time for skiing ‚õ∑Ô∏è if weather permits. Learning guitar!
409,@rasbt,2023-01-30 01:05:35+00:00,https://twitter.com/rasbt/status/1619864368132558849,@roydanroy üíØ
410,@rasbt,2023-01-30 00:02:05+00:00,https://twitter.com/rasbt/status/1619848387893018624,"@svpino *buy/use/borrow/recommend, fill in the blank üòÖ"
411,@rasbt,2023-01-30 00:00:28+00:00,https://twitter.com/rasbt/status/1619847980978421760,@percyliang @chris_j_beckham new user-provided data is the actual test data
412,@rasbt,2023-01-29 23:58:17+00:00,https://twitter.com/rasbt/status/1619847429997867009,@roydanroy Yup! One quick (yet not perfect) indicator: do they have a lab/group website or just a personal faculty website?
413,@rasbt,2023-01-29 22:48:21+00:00,https://twitter.com/rasbt/status/1619829830983483393,@AluruRatnakar There is no new edition or update planned for now
414,@rasbt,2023-01-29 22:47:43+00:00,https://twitter.com/rasbt/status/1619829671499292674,"@sarojbono Oh, happy to add more clarification! Did the figure help by the way? Otherwise, I will think about clarifying this better!"
415,@rasbt,2023-01-29 22:46:24+00:00,https://twitter.com/rasbt/status/1619829340484829185,"@IMScalable @bentossell @svpino @browsercompany I haven't tried on this one, but I ran stable diffusion on my work laptop (32 Gb), no problem. 

We (@LightningAI) also have stable diffusion code optimized for inference now  if that helps: https://t.co/rOpOrmAYIH
Code is on GitHub here: https://t.co/XVvmkKsFoE"
416,@rasbt,2023-01-29 18:12:28+00:00,https://twitter.com/rasbt/status/1619760404435185666,@jdegourville @svpino plus it's 100% quiet
417,@rasbt,2023-01-29 18:12:00+00:00,https://twitter.com/rasbt/status/1619760286134865922,"@jdegourville @svpino I prefer the fact that it's Unix-based under the hood since all my servers run Linux, and I feel more at home on it. Mac is basically Linux with a polished UI. Plus, the Apple laptop hardware is rock solid, lasts forever, has great battery life, and is super fast"
418,@rasbt,2023-01-29 18:02:27+00:00,https://twitter.com/rasbt/status/1619757883234856962,"@rohepe @svpino I am lucky that my work laptop has 32 Gb. I have the RAM stats in my menu bar as shown in the screenshot above, and from using that computer for more than a year: 16 Gb is ok for basic things; for a work computer with coding, Slack, and occasional video editing: 32 Gb"
419,@rasbt,2023-01-29 17:58:51+00:00,https://twitter.com/rasbt/status/1619756974555660290,@LeoVasanko @LightningAI Thanks for the note. It's currently in maintenance and should be back up next week.
420,@rasbt,2023-01-29 17:57:46+00:00,https://twitter.com/rasbt/status/1619756705801449474,"@ADutchEngineer @svpino I am lucky to have a work computer with 32 Gb. My private one has 16 Gb; I love this computer, but I am already constantly maxing out the RAM. 16 Gb is really the minimum, and I agree, 32 Gb is probably the current recommendation if you want to get a few years out of it."
421,@rasbt,2023-01-29 17:56:11+00:00,https://twitter.com/rasbt/status/1619756305690030080,"@svpino It's a great machine, but I feel like it's already quite at the limit with its 16 Gb, and I really don't do that much stuff on it. I wonder why they sell 8 Gb computers in 2023 still."
422,@rasbt,2023-01-29 17:54:12+00:00,https://twitter.com/rasbt/status/1619755805053685760,"@svpino My private M1 Mb Air has 16 Gb. It's okay but it's always almost maxed out  -- and I just have Safari with open with like 5 tabs. 
8 Gb would probably work but probably kill the SSD in like a year due to swapping. https://t.co/qjTZuiutL9"
423,@rasbt,2023-01-29 17:49:45+00:00,https://twitter.com/rasbt/status/1619754686088908800,"@svpino The 256 Gb SSD is also 50% slower than the 512 Gb one, or the old 256 Gb one in the M1. So, if you can, try to get at least the 512 Gb version.
https://t.co/c6fcCKSFKU"
424,@rasbt,2023-01-29 17:48:16+00:00,https://twitter.com/rasbt/status/1619754313575976963,@svpino Friends don't let friends a computer with 8 Gb RAM
425,@rasbt,2023-01-29 17:43:00+00:00,https://twitter.com/rasbt/status/1619752987194429442,@ADutchEngineer have fun üòä
426,@rasbt,2023-01-29 16:03:33+00:00,https://twitter.com/rasbt/status/1619727960898174976,@bentossell My favorite recent DIY AI use case:
427,@rasbt,2023-01-29 15:54:54+00:00,https://twitter.com/rasbt/status/1619725785539170304,@DSaience Yes! No. 1 lesson was: need more and better data üòÖ
428,@rasbt,2023-01-29 15:51:30+00:00,https://twitter.com/rasbt/status/1619724926323417089,"@LeoVasanko @SnehilRC Yes, thanks! I wanted it to be 2 separate books: one machine learning (w/o neural nets) and one on deep learning ‚Äî but the publisher insisted having everything in one book."
429,@rasbt,2023-01-29 15:23:20+00:00,https://twitter.com/rasbt/status/1619717838377484288,"@SnehilRC Sure! Machine Learning with PyTorch and Scikit  is the newer one (added two new chapters: Transformers &amp; Graph Neural Nets, and changed everything from TensorFlow to PyTorch). Some more details here: https://t.co/WsT2MvUWbC"
430,@rasbt,2023-01-29 15:21:02+00:00,https://twitter.com/rasbt/status/1619717262608596992,"@LeoVasanko @PyTorch Yes and no, or: it depends. It's essentially a method that learns the best augmentation policy based on optimizing the validation accuracy. It may include rotation and scaling."
431,@rasbt,2023-01-29 15:19:17+00:00,https://twitter.com/rasbt/status/1619716820679921666,"@LWThompson5 Thanks, I am glad you like it!"
432,@rasbt,2023-01-29 15:01:22+00:00,https://twitter.com/rasbt/status/1619712309701799943,@jameshuang1981 Thanks!
433,@rasbt,2023-01-29 14:57:44+00:00,https://twitter.com/rasbt/status/1619711397910425602,"Quite the productive weekend! Lots of new content added to Machine Learning Q and AI:  https://t.co/2hcrhcftJ7

Q21. Stateless vs Stateful Training
Q27. Proper Metrics
Q30. Limited Labeled Data https://t.co/kvMcou3oyd"
434,@rasbt,2023-01-29 03:47:03+00:00,https://twitter.com/rasbt/status/1619542612314329088,@MrColeslaw972 @PyTorch Thanks for sharing!!
435,@rasbt,2023-01-29 03:46:54+00:00,https://twitter.com/rasbt/status/1619542576482385920,@deliprao @SamuelMullr I was wrong: there is an NLP version of AutoAugment already: https://t.co/3mrOeLHT1i
436,@rasbt,2023-01-29 03:45:33+00:00,https://twitter.com/rasbt/status/1619542235007315969,"@jerome_massot Thanks, I hope you'll like it and get something useful out of it!!"
437,@rasbt,2023-01-29 03:44:48+00:00,https://twitter.com/rasbt/status/1619542049602273280,"@MuhammadAnas707 I shipped 3 copies internationally from a Xmas give-away, and yeah, international shipping is super expensive :(. 
I think the publisher sells it cheaper in certain regions, maybe worth checking: https://t.co/BCLrRolam1"
438,@rasbt,2023-01-29 03:43:36+00:00,https://twitter.com/rasbt/status/1619541746895167488,@iamvijaymaurya @PyTorch Maybe try this one: https://t.co/hZjdd2Laac
439,@rasbt,2023-01-29 01:06:09+00:00,https://twitter.com/rasbt/status/1619502123703750656,"@deliprao @SamuelMullr Based on reading the AutoAugment paper, it‚Äôs very specific for computer vision. But you could potentially come up with something similar for back translation and synonym replacement for NLP. I just don‚Äôt think torchtext implements that."
440,@rasbt,2023-01-29 00:58:35+00:00,https://twitter.com/rasbt/status/1619500219133222913,"@deliprao @SamuelMullr It's from torchvision, so I don't think they have anything NLP-compatible."
441,@rasbt,2023-01-29 00:49:58+00:00,https://twitter.com/rasbt/status/1619498049243578369,"@saiprakash_c Thanks for the compliment, makes me really happy to hear! I modeled it after the lecture I gave at UW-Madison, and there was a lot of thought that went into structuring it :)"
442,@rasbt,2023-01-28 21:00:44+00:00,https://twitter.com/rasbt/status/1619440363076460544,"@MuhammadAnas707 No, no worries. I meant: no pressure, you can focus on one thing at a time and don't need to do everything all at once :)"
443,@rasbt,2023-01-28 21:00:01+00:00,https://twitter.com/rasbt/status/1619440181408567298,"@CarolineJeanFr1 Thanks! And likewise, I am a big fan of printed books as well. There is something about reading a printed book that really helps me to stay more focused."
444,@rasbt,2023-01-28 19:18:15+00:00,https://twitter.com/rasbt/status/1619414570921259008,"@marsstache Thanks for sharing, it's always motivating to hear these positive words, and I am glad you like it!"
445,@rasbt,2023-01-28 19:17:20+00:00,https://twitter.com/rasbt/status/1619414339903193088,@MuhammadAnas707 One thing at a time :)
446,@rasbt,2023-01-28 19:14:58+00:00,https://twitter.com/rasbt/status/1619413743779352576,"Or even better: TrivialAugment! 

(Notebook here if you want to give it a try: https://t.co/yo3LUeFbf1)

Thanks for the suggestion @SamuelMullr! https://t.co/Ljcr3AOUCq"
447,@rasbt,2023-01-28 18:23:22+00:00,https://twitter.com/rasbt/status/1619400758579073024,"@gfotedar @akshay_pachaar @PyTorch yes, that's one technique. Usually, you need to apply more than one type of technique to reduce overfitting.

From my ML Q and AI book:
- more data, pretraining, feature engineering, regularization, dropout, early-stopping, inductive biases, ensembles, ..."
448,@rasbt,2023-01-28 18:17:53+00:00,https://twitter.com/rasbt/status/1619399376782372864,"@MuhammadAnas707 Nice! Another productive week! üöÄ
Make sure to get some rest on the weekend, you earned it!"
449,@rasbt,2023-01-28 17:22:29+00:00,https://twitter.com/rasbt/status/1619385436631334913,"@MoeinShariatnia @PyTorch Have to give that a try sometime, too!"
450,@rasbt,2023-01-28 16:57:06+00:00,https://twitter.com/rasbt/status/1619379048458911744,"@SamuelMullr @PyTorch Even better. After 500 epochs: 

(actually, there was quite the slope, so let me train for 500 more) https://t.co/bmMiImycyp"
451,@rasbt,2023-01-28 16:04:47+00:00,https://twitter.com/rasbt/status/1619365881234214918,@SamuelMullr @PyTorch On it! https://t.co/bHGByFPWWc
452,@rasbt,2023-01-28 15:58:23+00:00,https://twitter.com/rasbt/status/1619364273364545536,@CompellingN thanks!! hope you'll like it!
453,@rasbt,2023-01-28 15:42:22+00:00,https://twitter.com/rasbt/status/1619360240289583106,"Whoa, just looking up my book on Amazon and saw it's now #1 in Natural language processing. (https://t.co/1puBDrUjpi)

Yeah, it's not an NLP book, but there is an extensive transformer chapter that was a lot of work. Glad it's so well received! https://t.co/leSGmnIwrf"
454,@rasbt,2023-01-28 15:33:57+00:00,https://twitter.com/rasbt/status/1619358124342931457,"@akshay_pachaar @PyTorch Yeah, I omitted it for simplicity, but it also wouldn't have done anything because the validation accuracy doesn't go down at any point here."
455,@rasbt,2023-01-28 15:30:42+00:00,https://twitter.com/rasbt/status/1619357304029351936,"@akshay_pachaar @PyTorch I would say it's overfitting a lot to begin with. But yeah, training longer doesn't make it worse. 

(Btw. I didn't address the original overfitting gap because I wanted to keep the comparison as simple as possible, so it's a vanilla ResNet-18)"
456,@rasbt,2023-01-28 15:21:30+00:00,https://twitter.com/rasbt/status/1619354988660285440,"AutoAugment paper:
https://t.co/gZXxKyFyuc

transforms.AutoAugment docs:
https://t.co/xaoBhVK6eX"
457,@rasbt,2023-01-28 15:19:04+00:00,https://twitter.com/rasbt/status/1619354379295010816,"Once in a while, I stumble upon some nice little feature in the @PyTorch  library that I haven't seen before. 

Have you tried AutoAugment, yet?

Just gave it a try: takes a few epochs, but that's a 10% accuracy improvement in this simple example case
https://t.co/yo3LUeFbf1 https://t.co/MxPSyxSBHM"
458,@rasbt,2023-01-28 14:59:01+00:00,https://twitter.com/rasbt/status/1619349331949289473,"@francoisfleuret Yes but it doesn‚Äôt roll as nicely of the tongue.
I also just call it a weighted sum, people usually know what is meant :P"
459,@rasbt,2023-01-28 14:38:48+00:00,https://twitter.com/rasbt/status/1619344244002680832,"@FaisalAlsrheed Wow thanks! üòä
Making steady progress, and a little update coming sometime this weekend."
460,@rasbt,2023-01-28 14:25:18+00:00,https://twitter.com/rasbt/status/1619340847950237698,The whimsical elements on GitHub always bring a sense of delight. https://t.co/Z5nqIhKzgM
461,@rasbt,2023-01-28 01:31:17+00:00,https://twitter.com/rasbt/status/1619146061280612353,"@ylecun In contrast to Science, ‚ÄúSpringer Nature, which publishes thousands of scientific journals, says it has no problem with AI being used to help write research ‚Äî¬†as long as its use is properly disclosed.‚Äù (https://t.co/Htl7O9bcjK)

Looks like Nature made the smarter choice here."
462,@rasbt,2023-01-28 00:44:44+00:00,https://twitter.com/rasbt/status/1619134346681786369,"@swooooooosh_ml @ylecun Work in progress üòÖ

https://t.co/2hcrhcftJ7"
463,@rasbt,2023-01-28 00:15:53+00:00,https://twitter.com/rasbt/status/1619127085855014912,@svpino @ylecun üôÑ
464,@rasbt,2023-01-27 21:24:08+00:00,https://twitter.com/rasbt/status/1619083864126660613,"@daniela_witten Played it in my childhood and it was actually quite fun. Totally forgot about it until I recently had a student in class who was a professional player and traveling to Pok√©mon card tournaments. 
It‚Äôs fun to see that it‚Äôs still a thing."
465,@rasbt,2023-01-27 21:14:35+00:00,https://twitter.com/rasbt/status/1619081459796701184,@ds_ldn Thanks! I‚Äôd say contrastive learning would be a subcategory for self-supervised learning so I wouldn‚Äôt add an extra node; the thing is that it‚Äôs also been largely replaced in favor of autoregressive methods for both CNNs and ViTs
466,@rasbt,2023-01-27 20:53:26+00:00,https://twitter.com/rasbt/status/1619076136113242113,"@giffmana @chargeshivers @neu_rips Haha, no worries. My research is on deep neural nets for ordinal or interval data, and for some reason I was still in this mode where I didn't think of it as arbitrary nominal categories A, B, C"
467,@rasbt,2023-01-27 20:48:07+00:00,https://twitter.com/rasbt/status/1619074799556345856,"@Intrinsic29 @ylecun Yeah, it seems like a weird mix of gatekeeping and trying to hold on to the past."
468,@rasbt,2023-01-27 20:37:13+00:00,https://twitter.com/rasbt/status/1619072056372662274,"@giffmana @chargeshivers @neu_rips It's probably class labels, so not even ordinal but nominal. Yeah, I see now ... I thought of it as numbers 1, 2, 3, but since you showed Entropy I should have thought about these representing class labels or sth, haha"
469,@rasbt,2023-01-27 20:35:18+00:00,https://twitter.com/rasbt/status/1619071572790362112,"@giffmana @chargeshivers @neu_rips Ahh, so your 1, 2, 3 in the plot are just names / placeholders. It's ordinal data; i.e. discrete but not in a metric space? Got it."
470,@rasbt,2023-01-27 20:22:06+00:00,https://twitter.com/rasbt/status/1619068252944207873,@chargeshivers @giffmana @neu_rips Or Wikipedia: https://t.co/qKeIUDcT7l https://t.co/NcDQU6D3OD
471,@rasbt,2023-01-27 20:20:19+00:00,https://twitter.com/rasbt/status/1619067800785686531,@chargeshivers @giffmana @neu_rips via https://t.co/xD9TfrbhCL https://t.co/UjHA0nLnTF
472,@rasbt,2023-01-27 19:27:36+00:00,https://twitter.com/rasbt/status/1619054537234616320,@fisadev CC @vigu
473,@rasbt,2023-01-27 19:27:14+00:00,https://twitter.com/rasbt/status/1619054444603392001,"@fisadev Oh ""no""!!! Thanks! Cleaned that up a bit! https://t.co/2yQkEl9Dzd"
474,@rasbt,2023-01-27 18:39:05+00:00,https://twitter.com/rasbt/status/1619042326885838848,"@ylecun Totally agree. I use ChatGPT in my latest book because why not. 

Full disclosure: I also use a calculator /computer for most applied math. 
And I also use a grammar checker for important emails and papers."
475,@rasbt,2023-01-27 16:01:38+00:00,https://twitter.com/rasbt/status/1619002703853805568,@m_elantkowski Learning about it in a Data Mining class in grad school. Have to check later if the textbook had a chapter on that. Btw there is a sklearn submodule for this: https://t.co/iyMDgIecNA
476,@rasbt,2023-01-27 15:43:29+00:00,https://twitter.com/rasbt/status/1618998135052988421,"@lecturer34 Good catch! And sorry about that, I cleaned that up a bit below https://t.co/Q2YCEA8AhM"
477,@rasbt,2023-01-27 15:30:09+00:00,https://twitter.com/rasbt/status/1618994778380832768,Totally missed that one node had 3 arrows above. Just cleaned that up: https://t.co/gL3rN65emT
478,@rasbt,2023-01-27 14:52:51+00:00,https://twitter.com/rasbt/status/1618985391213928449,@tunguz a yearly checkup at the dentist is usually not a bad idea
479,@rasbt,2023-01-27 14:44:38+00:00,https://twitter.com/rasbt/status/1618983323778576386,@joshuastarmer ReQuest would be a cool name for StatQuest office hours üòÖ
480,@rasbt,2023-01-27 14:29:17+00:00,https://twitter.com/rasbt/status/1618979461910925314,"@F_Vaggi @giffmana @neu_rips Afaik you can use Wasserstein distance for discrete distributions as well. E.g., people use it to compare color histograms in computer vision, for example."
481,@rasbt,2023-01-27 14:25:02+00:00,https://twitter.com/rasbt/status/1618978394062082048,@3scorciav @giffmana @F_Vaggi @neu_rips @gabrielpeyre Earth mover distance is a synonym for Wasserstein distance afaik
482,@rasbt,2023-01-27 14:09:55+00:00,https://twitter.com/rasbt/status/1618974589295661058,"@TheRandomMtrix Thanks for the feedback. I most techniques could be used with non-DNNs. Except transfer learning or self-supervised learning wouldn't work with tree-based models, but others should be compatible."
483,@rasbt,2023-01-27 14:05:23+00:00,https://twitter.com/rasbt/status/1618973448956686341,"*  The black boxes are not terminal nodes but arch back to ""Evaluate model performance"" (arrows omitted to reduce clutter)

** Techniques such as data augmentation, multi-task, and multi-modal learning could be combined with all these strategies"
484,@rasbt,2023-01-27 14:05:23+00:00,https://twitter.com/rasbt/status/1618973446066827264,"I outlined 9 different machine learning strategies, but which one to use? 
An attempt to bring a bit of structure into this: https://t.co/TI8h2jwtqm"
485,@rasbt,2023-01-26 22:57:43+00:00,https://twitter.com/rasbt/status/1618745026330361857,"@giffmana @neu_rips You could do distance to uniform and bimodal. But if you just want to check for bimodality, there are also specific indices which I can't remember top off my head"
486,@rasbt,2023-01-26 22:50:57+00:00,https://twitter.com/rasbt/status/1618743321249329152,@giffmana @neu_rips Wasserstein distance
487,@rasbt,2023-01-26 22:06:06+00:00,https://twitter.com/rasbt/status/1618732034788306946,"@DSaience Yeah, and thinking about the questions is a good learning process in itself :)"
488,@rasbt,2023-01-26 21:48:53+00:00,https://twitter.com/rasbt/status/1618727702655279107,"@thegautamkamath What I always found weird is that faculty has to apply for most of these awards themselves (the only exception I know of are paper awards). 
Consequently, so much more work could get done without the awards."
489,@rasbt,2023-01-26 21:29:18+00:00,https://twitter.com/rasbt/status/1618722772364173314,"@cwizprod1 @svpino Yes, that's actually a great exercise! And then you can feed in the corrected info back a training data :P"
490,@rasbt,2023-01-26 21:28:27+00:00,https://twitter.com/rasbt/status/1618722560446971904,"@sarojbono @svpino @LightningAI Thanks, that's nice to hear and means a lot üòä"
491,@rasbt,2023-01-26 21:08:21+00:00,https://twitter.com/rasbt/status/1618717501126496256,@rewtoetzi @svpino *good article recommendations for articles published before 2021.
492,@rasbt,2023-01-26 20:59:24+00:00,https://twitter.com/rasbt/status/1618715249309528065,"@svpino Absolutely! It‚Äôs a great companion that can help you with some chores around writing. It‚Äôs great for that.
But when it comes to teaching &amp; learning, take it with a grain of salt üßÇ"
493,@rasbt,2023-01-26 20:56:20+00:00,https://twitter.com/rasbt/status/1618714480120307712,@svpino Or Lightning AI. Not unlimited free but you get $30 cloud credits for free. For example: https://t.co/gHZ8sixw9N
494,@rasbt,2023-01-26 20:41:48+00:00,https://twitter.com/rasbt/status/1618710822754340866,"@tunguz Basically a subscription service that always runs on/updates itself to the newest tech? 
That might be $1000-10,000/yr thing then if it can do a decent portion of my chores well."
495,@rasbt,2023-01-26 20:34:46+00:00,https://twitter.com/rasbt/status/1618709052707733504,"@tunguz Sure but it's the same as next-gen gaming consoles: You know it's is always only good for a couple of years. 
A car is good for 10-20 years, and it's okay to spend more on that. 
Smart phones, computers, AI, gaming consoles have a much shorter half-life."
496,@rasbt,2023-01-26 20:31:49+00:00,https://twitter.com/rasbt/status/1618708308218769408,"@AndrewYNg Text. There are more use cases from note-taking, to email, to online articles. 
Image-gen is useful for generating images for said articles, but an image is still a non-essential component of an article.
But it will be interesting to come back to this once AI can create videos."
497,@rasbt,2023-01-26 20:26:20+00:00,https://twitter.com/rasbt/status/1618706927365787648,"@tunguz Definitely not more than $1000. That's because I would know its quite limited if it would be trained with current technology. 
And I would know the model is probably outdated by next year already."
498,@rasbt,2023-01-26 18:54:12+00:00,https://twitter.com/rasbt/status/1618683740305379328,@LouisLebbos @LightningAI Whisper is so far the only tool that can handle my accent and technical terms well!
499,@rasbt,2023-01-26 18:25:52+00:00,https://twitter.com/rasbt/status/1618676612488372224,"@yaroslavvb Yeah, I can see how that could work in certain scenarios where there are convergence problems. But it's probably not a generally useful thing. On the other hand, if it doesn't actively hurt the final convergence, it might not be bad to just always use it."
500,@rasbt,2023-01-26 18:22:45+00:00,https://twitter.com/rasbt/status/1618675829466337281,"@LightningAI Oh oh, 28.2%! üòÖ
Spoiler alert: 

- 2* log(0.33) / 2 = 1.1"
501,@rasbt,2023-01-26 18:13:08+00:00,https://twitter.com/rasbt/status/1618673406442110985,"Here's a link to the code if you want to give it a try: https://t.co/qXMBwn1AQB

And if you prefer a nice and polished UI, we recently launched the Echo App @LightningAI on top of Whisper earlier this year: https://t.co/ob5yaaIEj2"
502,@rasbt,2023-01-26 18:13:07+00:00,https://twitter.com/rasbt/status/1618673402272972800,"Had a fun podcast recording &amp; chat with
@prateekvjoshi yesterday!

Realized on my morning walk that I totally forgot my currently fav AI use case:
Transcribing my voice recordings!

Earlier this year, I got a simple voice recorder that I use to take notes when driving/walking. https://t.co/YzhCOzF6xU"
503,@rasbt,2023-01-26 18:08:35+00:00,https://twitter.com/rasbt/status/1618672260843442176,"@Amir_Hajiabadi_ @John4man @marktenenholtz Glad to hear you like it!! (Hah, may I ask which one üòÖ)"
504,@rasbt,2023-01-26 16:22:13+00:00,https://twitter.com/rasbt/status/1618645495383232514,"@DSaience Oh, a mix between fun facts and some theoretical stuff :). Usually not recipes. 

Stuff like ""When is the least-squares regression hypothesis the maximum likelihood estimate?""

""What's the difference between MSAs and Convs in terms of being high- and low-pass filters"""
505,@rasbt,2023-01-26 14:34:34+00:00,https://twitter.com/rasbt/status/1618618401500585987,@patloeber @AssemblyAI Congrats on the anniversary!
506,@rasbt,2023-01-26 14:29:38+00:00,https://twitter.com/rasbt/status/1618617162180227076,"@akshay_pachaar Nice, I read the R version many years ago, and it was a really nice read. I am glad to hear that they fixed the one flaw this book had &amp; added Python examples :)"
507,@rasbt,2023-01-26 14:27:56+00:00,https://twitter.com/rasbt/status/1618616735695003651,"@MuhammadAnas707 @joshuastarmer @aniketmaurya @LightningAI Haha yes, small world! I am really lucky to have @joshuastarmer as a friend &amp; colleague!

Double BAM! üòä"
508,@rasbt,2023-01-26 14:26:35+00:00,https://twitter.com/rasbt/status/1618616394375135233,"@divya_raichura Hi there! There are lot of courses out there, and yeah, it can be hard to navigate this vast field! 
Personally, I would recommend my own course, which I am currently creating here (it's 100% free, no catch, so you can give it a try): https://t.co/B0rVXxbR6v"
509,@rasbt,2023-01-26 01:08:03+00:00,https://twitter.com/rasbt/status/1618415438605742080,@ncooper57 This looks pretty good! Thanks!
510,@rasbt,2023-01-25 23:56:47+00:00,https://twitter.com/rasbt/status/1618397502985895937,"@cwizprod1 Haven't seen it -- but on the other hand, ChatGPT itself is already a pretty good summarizer. 
I would say though it requires more than summarization since the summary is usually not the most interesting question/answer candidate for an Anki deck."
511,@rasbt,2023-01-25 23:43:31+00:00,https://twitter.com/rasbt/status/1618394164936454144,"üíØ! I spend a good chunk of time each week reading books and articles to extend my Machine Learning flashcard decks in Anki.

On the one hand, it's quite rewarding, on the other hand, that's where I wouldn't mind some AI assistance."
512,@rasbt,2023-01-25 23:01:47+00:00,https://twitter.com/rasbt/status/1618383662856437760,"@cwolferesearch Just saw your second part at the bottom 
""Just my opinion though! I'd be interested to see where this idea came from.""

=&gt; that was due to the success of pretraining in general (transfer learning, self-supervised learning). I.e., ""warmstarting"" the network before training"
513,@rasbt,2023-01-25 22:52:22+00:00,https://twitter.com/rasbt/status/1618381290222538752,@themintsv @cwolferesearch That's a good counter-argument actually
514,@rasbt,2023-01-25 22:51:34+00:00,https://twitter.com/rasbt/status/1618381088371638272,"@cwolferesearch Yeah, that sounds intuitive. I think there is a risk that you converge to bad local minima."
515,@rasbt,2023-01-25 18:41:47+00:00,https://twitter.com/rasbt/status/1618318229356810242,@ThadOfSphere Haha exactly. There are always too many interesting things to try :P
516,@rasbt,2023-01-25 18:37:49+00:00,https://twitter.com/rasbt/status/1618317230693027840,"@cwizprod1 No, first I am going to wrap up the DL Fundamentals class. 6 more units to release in the next few months :)
https://t.co/B0rVXxbR6v"
517,@rasbt,2023-01-25 18:36:00+00:00,https://twitter.com/rasbt/status/1618316772469534720,@kevinschawinski It might maybe help with larger networks where the initial random weights are too random and there are convergence issues.
518,@rasbt,2023-01-25 17:56:53+00:00,https://twitter.com/rasbt/status/1618306931571200003,"One weird trick .
Someone suggested on can decrease time to convergence by ""warmstarting"" / overfitting to a small number of batches first (like during debugging).

Wanted to debunk that, and yeah, it doesn't work . 

Hm, crowdsourcing this suggestion: Anyone done that before? https://t.co/BAfkyv1gD5"
519,@rasbt,2023-01-25 17:44:44+00:00,https://twitter.com/rasbt/status/1618303872459739137,"It's the beginning of the semester, so some of you might be looking for interesting machine learning datasets for teaching or class projects.

Put together some resources here:
https://t.co/tiwSj76Su7

(Haven't updated it in a few months -- is there's anything worthwhile to add?)"
520,@rasbt,2023-01-25 17:41:54+00:00,https://twitter.com/rasbt/status/1618303158266261504,"@guysnovelutumba Wow thanks. It's a bit different from my other books, but I thought it might be fun to try something different once :)"
521,@rasbt,2023-01-25 17:30:10+00:00,https://twitter.com/rasbt/status/1618300206629679106,"@dvgodoy Thanks, Daniel!"
522,@rasbt,2023-01-25 15:51:42+00:00,https://twitter.com/rasbt/status/1618275425549160448,"@MuhammadAnas707 @luis_likes_math @DeepLearningAI_ @AndrewYNg @akshay_pachaar Right now, due to ChatGPT, I am focusing on finishing the Machine Learning Q and AI book, because it's currently so much fun to write :).

After that, I will pick up the Math for ML drafts again. Have some early PDFs here: https://t.co/R3B1AH6DdE"
523,@rasbt,2023-01-25 15:47:57+00:00,https://twitter.com/rasbt/status/1618274483374297088,"@MuhammadAnas707 @luis_likes_math @DeepLearningAI_ @AndrewYNg @akshay_pachaar Wow nice! Congrats on launching this! @luis_likes_math &amp; @DeepLearningAI_ . It looks like a nice, comprehensive course 
(... and useful companion for my Mathematics for Deep Learning Book I haven't finished yet üòÖ)"
524,@rasbt,2023-01-25 15:44:07+00:00,https://twitter.com/rasbt/status/1618273519531622405,Whoa üòä https://t.co/SrjLVmGiYN
525,@rasbt,2023-01-25 15:27:21+00:00,https://twitter.com/rasbt/status/1618269300485394432,"@MuhammadAnas707 @akshay_pachaar Love the description. One computes it, the other calculates it. Lol"
526,@rasbt,2023-01-25 14:52:21+00:00,https://twitter.com/rasbt/status/1618260490542800896,"@John4man @marktenenholtz Well said!
Priority in research: State-of-the-art accuracy.
Priority for production/business: It depends."
527,@rasbt,2023-01-25 14:32:44+00:00,https://twitter.com/rasbt/status/1618255552605478914,"@marktenenholtz 1) Improving data quality to improve model performance.
 
2) Dealing with/updating a model -- the stuff that happens after evaluating it on the test set; also the  stuff they don't teach you in college."
528,@rasbt,2023-01-25 03:38:10+00:00,https://twitter.com/rasbt/status/1618090827473092610,@zerdeve Loved it. It was actually my favorite book I read last year!
529,@rasbt,2023-01-25 03:35:22+00:00,https://twitter.com/rasbt/status/1618090122351902724,"@MuhammadAnas707 @akshay_pachaar Sounds like a productive day, and glad you found the NumPy tutorial useful üöÄ"
530,@rasbt,2023-01-25 03:29:31+00:00,https://twitter.com/rasbt/status/1618088651849879552,"@NathanLands @leanpub @burkov Hah thanks! It‚Äôs designed to be bite-sized, and hopefully educational ü§û"
531,@rasbt,2023-01-25 00:35:42+00:00,https://twitter.com/rasbt/status/1618044909776404482,@LeonDerczynski Arxiv of course :)
532,@rasbt,2023-01-24 22:39:29+00:00,https://twitter.com/rasbt/status/1618015662424850433,"@sarojbono Happy learning, and please feel free to post any questions you might have in the discussion forum!"
533,@rasbt,2023-01-24 21:17:45+00:00,https://twitter.com/rasbt/status/1617995090991124480,"@ducha_aiki This can be fixed now!
ChatGPT, rewrite: my awesome review."
534,@rasbt,2023-01-24 21:14:36+00:00,https://twitter.com/rasbt/status/1617994298997473282,@RichmanRonald Not a small model though üòÖ: https://t.co/4vQ83pduSf
535,@rasbt,2023-01-24 19:53:36+00:00,https://twitter.com/rasbt/status/1617973916324204544,@ph_singer Besides the latex aspect everything seems to work nicely &amp; fine. I like that you can hook your profile up to GitHub to push new versions.
536,@rasbt,2023-01-24 19:52:49+00:00,https://twitter.com/rasbt/status/1617973718432747520,"@ph_singer They allow you to upload your own files, but I was using their custom markdown syntax. Its ok but not great for latex math since you have to use backticks instead of $ signs, so you can‚Äôt easily preview the math locally anymore. Ok if your texts incl. math but are not math-heavy"
537,@rasbt,2023-01-24 19:29:30+00:00,https://twitter.com/rasbt/status/1617967851679416320,"@sarojbono Nice to hear! And the good thing is you can take it as many times as you like, no penalty for trying &amp; learning :)"
538,@rasbt,2023-01-24 19:20:25+00:00,https://twitter.com/rasbt/status/1617965562071777281,"@xanturo_com Nice, looking forward to feedback if you have any! :)"
539,@rasbt,2023-01-24 19:13:37+00:00,https://twitter.com/rasbt/status/1617963852335046658,"Btw if you are taking my Deep Learning Fundamentals course (https://t.co/B0rVXxbR6v), how do you feel about the difficulty of the quizzes so far?

Happy to adjust!"
540,@rasbt,2023-01-24 18:05:36+00:00,https://twitter.com/rasbt/status/1617946734675787781,"@HexenkingTV Thanks! I find it very difficult to watch longer videos as I easily get distracted on my computer. I can read textbooks in 1-2 h chunks, but with videos, my max capacity is 10 min.
So, it's nice to hear others appreciate the bite-sized video style as well üòä"
541,@rasbt,2023-01-24 17:26:32+00:00,https://twitter.com/rasbt/status/1617936905550852097,@sarojbono Nice timing! Have fun!!
542,@rasbt,2023-01-24 17:07:05+00:00,https://twitter.com/rasbt/status/1617932008751239168,"Happy to share that Unit 4 of my free Deep Learning Fundamentals class is now live!

It covers multilayer neural nets and important design considerations (using nonlinear activation functions, and small random weight initialization).

üëâ https://t.co/Bu0L8sJ3YP

Happy Learning! https://t.co/xRhQbwfIeg"
543,@rasbt,2023-01-24 16:27:16+00:00,https://twitter.com/rasbt/status/1617921991012646912,"@omarsar0 @leanpub @burkov Thanks, @omarsar0, and let me return the compliment! Likewise, keep up the good work! üòä"
544,@rasbt,2023-01-24 16:15:28+00:00,https://twitter.com/rasbt/status/1617919019113385984,"Wow, I just saw that ""Machine Learning Q and AI"" (https://t.co/87ijAKwVM7) jumped to #2 in the ""machine learning"" and ""AI"" Bestseller lists on @leanpub  
(just behind @burkov's excellent 100 pg ML book)

Thx for all the support &amp; early feedback, everyone. Really appreciate it! üòä https://t.co/1l3V5Fs2N4"
545,@rasbt,2023-01-24 14:12:52+00:00,https://twitter.com/rasbt/status/1617888168656928775,"I am particularly looking forward to read Chapter 18 on Diffusion Models!

https://t.co/f4rONpLXkS

Great work @SimonPrinceAI!"
546,@rasbt,2023-01-24 13:22:17+00:00,https://twitter.com/rasbt/status/1617875438461911043,"@allenscope @ylecun @GaryMarcus I don't want to speak of behalf of someone else, but to me, if there is mockery, it comes more across as mocking the hype, not mocking the system(s)."
547,@rasbt,2023-01-24 13:03:56+00:00,https://twitter.com/rasbt/status/1617870820252221443,"@allenscope @ylecun Or in other words, I don't intend to mock everything. It's more about acknowledging that LLMs work ok -- pretty well actually. But let's not get carried away, they don't solve everything (anything?) yet"
548,@rasbt,2023-01-24 13:00:40+00:00,https://twitter.com/rasbt/status/1617869995740123137,"@allenscope @ylecun I am impressed by the capabilities of the latest LLMs. Systems like ChatGPT are pretty capable given how they were trained. At the same time, there is this big hype, and some people think that it's ready to take over everything because it's that good. It's not THAT good."
549,@rasbt,2023-01-24 12:23:05+00:00,https://twitter.com/rasbt/status/1617860540558356482,"@davidbau CC @irinarish, I think you recently mentioned a compute grant you got for LLMs and might have tips &amp; ideas"
550,@rasbt,2023-01-24 12:20:30+00:00,https://twitter.com/rasbt/status/1617859890365759488,"@allenscope @MuhammadAnas707 Ha no, I am a responsible human. ChatGPT‚Äôs machine learning knowledge is pretty spotty compared to resources written by a human as of now.

(was doing a comparison in my recent book: https://t.co/2hcrhcftJ7)"
551,@rasbt,2023-01-24 12:12:56+00:00,https://twitter.com/rasbt/status/1617857984528539649,"@MuhammadAnas707 Keep up the good work! By the way, you might find this companion guide for NumPy helpful :) https://t.co/SkStNbG5Z2"
552,@rasbt,2023-01-24 03:18:41+00:00,https://twitter.com/rasbt/status/1617723537430827012,@code_star @emilymbender Been there üòÖ
553,@rasbt,2023-01-24 03:16:15+00:00,https://twitter.com/rasbt/status/1617722925561569281,When ChatGPT got your attention ‚Äî no pun intended
554,@rasbt,2023-01-24 03:14:33+00:00,https://twitter.com/rasbt/status/1617722495754440705,@osoleve @fchollet Yeah what I like about miniconda is that I can just delete it from my home directly and it‚Äôs gone
555,@rasbt,2023-01-24 03:13:39+00:00,https://twitter.com/rasbt/status/1617722271292076032,@emilymbender And ‚Äúexperiments‚Äù ‚Äúconfirm‚Äù ‚Äúefficacy‚Äù
556,@rasbt,2023-01-24 03:06:50+00:00,https://twitter.com/rasbt/status/1617720554123059201,@KenJee_DS I like OpenML. Collected a few more here but I don‚Äôt use them all. I curated it mainly for students in my class who were looking for project ideas: https://t.co/tiwSj76Su7
557,@rasbt,2023-01-24 02:51:19+00:00,https://twitter.com/rasbt/status/1617716649804845057,@fchollet *i am actually not using windows but that was how it was when I was into PC video gaming 15 years ago
558,@rasbt,2023-01-24 02:49:46+00:00,https://twitter.com/rasbt/status/1617716257612234752,"@fchollet The Windows of programming languages. Everyone uses it, it kind of supports everything, but it‚Äôs also very borkable and needs a reinstall like once a year"
559,@rasbt,2023-01-24 02:26:09+00:00,https://twitter.com/rasbt/status/1617710316246433793,@10x_er I wonder if they used VSCode üòÜ
560,@rasbt,2023-01-23 23:56:55+00:00,https://twitter.com/rasbt/status/1617672760368717824,@deliprao @Diemooder1 Essentially what they used to further train GPT-3 after self-supervised pretraining and finetuning it on a small supervised dataset when they created ChatGPT. The InstructGPT paper is a good reference: https://t.co/cHpi3WrJlJ
561,@rasbt,2023-01-23 23:34:04+00:00,https://twitter.com/rasbt/status/1617667010946797568,"@srchvrs @code_star @francoisfleuret @ameyaajoshi Nice! Pretrained &amp; finetuned, or pure supervised training on Cifar?"
562,@rasbt,2023-01-23 23:32:46+00:00,https://twitter.com/rasbt/status/1617666684181155840,@CSProfKGD Awesome stuff and thanks for sharing üëè
563,@rasbt,2023-01-23 22:16:25+00:00,https://twitter.com/rasbt/status/1617647466631008257,Loved the first episode! Nice way to keep up with DL via a fun conversational interview.
564,@rasbt,2023-01-23 22:15:00+00:00,https://twitter.com/rasbt/status/1617647110601707525,"@yaroslavvb @deliprao @ylecun Thanks for the detailed, informative comment!"
565,@rasbt,2023-01-23 22:02:13+00:00,https://twitter.com/rasbt/status/1617643894262599681,Here are some fun student project examples: https://t.co/xEetakYL33
566,@rasbt,2023-01-23 22:00:59+00:00,https://twitter.com/rasbt/status/1617643583405985792,"Totally agree! Big fan of project-based learning. 
And my students always had a lot of fun with their class projects (+ it gives them something for their resume!)
https://t.co/Q1LJvDXNUx"
567,@rasbt,2023-01-23 21:54:06+00:00,https://twitter.com/rasbt/status/1617641853012279296,@DrEliDavid @ylecun I do think that the batch size has an influence on predictive performance for sure. It‚Äôs complicated. E.g. with older architectures and batchnorm too small and too large is bad. But I think it‚Äôs reasonable to fix the batch size and focus on other hparams / knobs instead
568,@rasbt,2023-01-23 21:47:28+00:00,https://twitter.com/rasbt/status/1617640183826120705,@DrEliDavid @ylecun 2003 was probably before people started using learning rate schedulers :P
569,@rasbt,2023-01-23 21:07:19+00:00,https://twitter.com/rasbt/status/1617630078812442624,@Frank37004246 @TheoPoinsot @ylecun @collectivei Yes
570,@rasbt,2023-01-23 20:00:25+00:00,https://twitter.com/rasbt/status/1617613242431582208,"@TheoPoinsot @ylecun @collectivei As far as everyone knows, it‚Äôs a scaled up version of the 1-year old InstructGPT model &amp; method. So I have to agree with @ylecun here. Until or unless there is a paper coming out revealing some interesting new details that we don‚Äôt know about yet."
571,@rasbt,2023-01-23 19:56:21+00:00,https://twitter.com/rasbt/status/1617612219528712201,"@deliprao @ylecun That would be an interesting experiment, but I am not sure if that would help. Because you are not adding useful information, and the information still gets averaged out. If you want to escape minima you are probably better off with changing your learning rate schedule."
572,@rasbt,2023-01-23 19:48:48+00:00,https://twitter.com/rasbt/status/1617610318628233216,@deliprao @ylecun I would say it approaches gradient descent and information gets averaged out
573,@rasbt,2023-01-23 19:45:32+00:00,https://twitter.com/rasbt/status/1617609497459163138,@ETorlig @francoisfleuret Oh yeah 8-bit of course ;)
574,@rasbt,2023-01-23 19:44:54+00:00,https://twitter.com/rasbt/status/1617609337282891776,@deliprao @ylecun The ‚Äúup to a point‚Äù part refers to the upper right subfigure. I.e. bigger batch sizes don‚Äôt perform worse if you stay within reasons (below 8k)
575,@rasbt,2023-01-23 19:29:34+00:00,https://twitter.com/rasbt/status/1617605479076888577,"@ruchowdh @BKCHarvard Wow, awesome news!! Congrats!!üëè üéâ"
576,@rasbt,2023-01-23 19:26:53+00:00,https://twitter.com/rasbt/status/1617604801864556544,@MuhammadAnas707 Or streamlit to get started https://t.co/Qbh5Qd0Isx
577,@rasbt,2023-01-23 19:24:37+00:00,https://twitter.com/rasbt/status/1617604231992856577,"@MuhammadAnas707 I may be a bit biased, but in this day and age I would maybe consider React (depending on the target audience). Eg https://t.co/l8yOiN4vKv"
578,@rasbt,2023-01-23 19:19:39+00:00,https://twitter.com/rasbt/status/1617602981339500545,@francoisfleuret Were 8-but video gaming systems a mistake? üôÉ
579,@rasbt,2023-01-23 19:14:01+00:00,https://twitter.com/rasbt/status/1617601564268724224,@jhasanofficial Glad to hear!! Thanks!! More questions will be added next weekend!
580,@rasbt,2023-01-23 18:25:32+00:00,https://twitter.com/rasbt/status/1617589365441691648,"@OmnesResNetwork @11Gunz leave-one-out doesn't work great for classification. Also, the folds will be too similar due to the overlap, so it's not super interesting for studying the variance of the training pipeline."
581,@rasbt,2023-01-23 16:34:29+00:00,https://twitter.com/rasbt/status/1617561416122220547,@ChrisBridges95 @ylecun Devil's advocate: use gradient accumulation then to increase the effective batch size :P
582,@rasbt,2023-01-23 16:18:59+00:00,https://twitter.com/rasbt/status/1617557515528699904,Was doing some more search and found a relevant post from @ylecun that argues for a smaller batch size. The discussion remains interesting :P https://t.co/EUzqTOjIZR
583,@rasbt,2023-01-23 16:13:59+00:00,https://twitter.com/rasbt/status/1617556258495627267,"@DataScienceHarp I haven't seen this paper before. Thanks for sharing. When I see it correctly, they also find that larger batch sizes work better: https://t.co/tFgBpprplA"
584,@rasbt,2023-01-23 15:26:03+00:00,https://twitter.com/rasbt/status/1617544195220312066,"Regarding choosing a good batch size:
Choosing a batch size to be as large as your hardware permits (up to a point) seems to be a good recommendation.
Compiled some resources via the figure below. https://t.co/P8VWTDfliZ"
585,@rasbt,2023-01-23 14:59:54+00:00,https://twitter.com/rasbt/status/1617537615976169478,"@_OliverStanley @ylecun Yup, that's what I think as well. When ChatGPT gave a wrong explanation of weight decay, I checked Perxplexity AI, and its references indicated that it was  due to incorrect training data: https://t.co/C5pVCHlO3O"
586,@rasbt,2023-01-23 14:35:08+00:00,https://twitter.com/rasbt/status/1617531381541916674,"@_dylancastillo Ah, I see what you mean ... without ChatGPT context  that looks indeed weird haha"
587,@rasbt,2023-01-23 14:29:28+00:00,https://twitter.com/rasbt/status/1617529954501263361,@_dylancastillo Exactly! ChatGPT got that wrong and said exactly the opposite.
588,@rasbt,2023-01-23 14:22:54+00:00,https://twitter.com/rasbt/status/1617528305862995981,"@BenTuringT @ylecun Yeah, it's mainly because ViTs have fewer spatial and locality inductive biases (and more parameters). Recent ViT architectures are also taking inspiration (and layers :P) from CNNs to get the best of both worlds."
589,@rasbt,2023-01-23 14:16:02+00:00,https://twitter.com/rasbt/status/1617526574001328128,@11Gunz Depends on the data and goals. It's always a trade-off. 5 and 10 are often solid choices though.
590,@rasbt,2023-01-23 14:14:56+00:00,https://twitter.com/rasbt/status/1617526297726701570,"@doorisajar In it's current form, I would stay away from using it for anything where I am trying to learn something about a new topic. I would be way too worried that I'd be soaking in all kinds of misinformation."
591,@rasbt,2023-01-23 14:14:00+00:00,https://twitter.com/rasbt/status/1617526065420980224,"@doorisajar Yeah, I think in its current form it's only useful for a domain expert who feels a bit lazy and wants it to automate some mundane writing parts. But you still need to be a domain expert to be able to tell which parts are correct."
592,@rasbt,2023-01-23 14:02:44+00:00,https://twitter.com/rasbt/status/1617523226875252736,"Another one regarding disadvantages of a large k in k-fold CV: 

&gt; Reduced data for training: As k increases, the size of each fold decreases, which means that less data is available for training the model, which can lead to poor performance when the model is applied to new data."
593,@rasbt,2023-01-23 13:48:45+00:00,https://twitter.com/rasbt/status/1617519710630989825,"When I asked ChatGPT the ""Why do ViTs need more data than ConvNets"" question this morning, I saw the biggest blunder yet

&gt; ""Fewer parameters: Vision transformers have fewer parameters than CNNs, this means that they require more data [...].""

(via https://t.co/2hcrhcftJ7)"
594,@rasbt,2023-01-23 13:43:17+00:00,https://twitter.com/rasbt/status/1617518335260004358,"@simocolo75 Thanks, and I am glad to hear you like it!"
595,@rasbt,2023-01-23 13:41:23+00:00,https://twitter.com/rasbt/status/1617517854278176768,"@ylecun I am exploring this currently in Machine Learning Q and AI (https://t.co/2hcrhcftJ7) -- after writing the initial draft, I was worried that ChatGPT makes it (and me) obsolete. ChatGPT seems good at first glance but it's not replacing domain experts anytime soon."
596,@rasbt,2023-01-23 13:38:35+00:00,https://twitter.com/rasbt/status/1617517151983898625,"@ylecun Yes! Current LLMs like ChatGPT can write eerily good responses. But then there are occasional big bloopers, for example, ChatGPT thinks 
""Vision transformers have fewer parameters than CNNs, this means that they require more data to learn the same amount of information."""
597,@rasbt,2023-01-23 12:42:38+00:00,https://twitter.com/rasbt/status/1617503069776019456,"@He50005621Hazem @HrijulChauhan The book is covering both machine learning fundamentals and deep learning fundamentals, so I think it might be a good start"
598,@rasbt,2023-01-23 12:23:45+00:00,https://twitter.com/rasbt/status/1617498319714144259,"@HrijulChauhan If you have a beginner background in Python I‚Äôd say it‚Äôs a good fit. There are mathematical formulas l in there of course, but you can think of them as a bonus, not a requirement."
599,@rasbt,2023-01-23 12:22:20+00:00,https://twitter.com/rasbt/status/1617497960471826434,"@wulti_ Designing ML Systems, The Kaggle Book, Machine Learning with PyTorch and Scimitar-learn came out 2022. Given that there are no newer books on the topic, I would say they are still very much relevant today. (And I‚Äôd say the other 3 books are pretty timeless)"
600,@rasbt,2023-01-23 03:27:30+00:00,https://twitter.com/rasbt/status/1617363365122428928,@el_keogh Haha thanks!
601,@rasbt,2023-01-23 03:21:18+00:00,https://twitter.com/rasbt/status/1617361804778262528,"@akshay_pachaar I should warn you, it's R code though -- I got it mainly as a refresher for some relevant R code back then. But I have positive memories. A very quick &amp; easy read."
602,@rasbt,2023-01-23 02:10:48+00:00,https://twitter.com/rasbt/status/1617344062872223745,@MuhammadAnas707 It's been a long time but I like it. It's basically for a more advanced Python understanding.
603,@rasbt,2023-01-23 01:39:23+00:00,https://twitter.com/rasbt/status/1617336157200867328,@NathanLands Mean question ... I heard the one at the bottom-center is pretty good üòá
604,@rasbt,2023-01-23 01:24:08+00:00,https://twitter.com/rasbt/status/1617332320880435201,"@phinance99 batch size can have an effect on predictive performance, but given all the other knobs to tune, I guess that keeping the batch size fixed to maximize the number of epochs is just making thing a bit more convenient and affordable."
605,@rasbt,2023-01-23 01:22:52+00:00,https://twitter.com/rasbt/status/1617332000549109760,"@phinance99 I think nowadays there are more effective ways to improve generalization. And regarding keeping out of sharp minima, varying the learning rate (via schedulers) and SGD helps I guess."
606,@rasbt,2023-01-22 23:55:54+00:00,https://twitter.com/rasbt/status/1617310116956495873,"PS: I remember reading and liking @jakevdp's book, but I  must have donated that some time back in 2018 when I moved to Madison.
And a little disclaimer, I never finished the Math for ML one."
607,@rasbt,2023-01-22 23:55:54+00:00,https://twitter.com/rasbt/status/1617310114922336258,"Just saw this post, and what a fun coincidence. Read all of these, and I can definitely recommend them all as well! https://t.co/8ex2R7BzYA"
608,@rasbt,2023-01-22 23:05:19+00:00,https://twitter.com/rasbt/status/1617297387411894272,"@PersianWanderer @YassineAlouini Here is a good paper on this: https://t.co/oahwQQA4OE

tl;dr is that the biggest batch size that works usually makes sense. If the model is properly tuned, you wouldn't have to worry that it makes performance worse"
609,@rasbt,2023-01-22 17:27:28+00:00,https://twitter.com/rasbt/status/1617212361819193346,@siddddhesh @AI_Kho_ @arya_akhare @DataScienceHarp @rowancheung @Gautam_Ak_ @BowTied_Raptor @estebanairaldo @levikul09 @freest_man @SanthoshKumarS_ @akshay_pachaar @DanKornas @Sentdex @paulabartabajo_ @marktenenholtz @omarsar0 @svpino Thanks for the mention! It's always flattering and motivating to hear that my little creations and outputs help others learn!! üòä
610,@rasbt,2023-01-22 17:19:15+00:00,https://twitter.com/rasbt/status/1617210297403555841,"@nutzer_inaktiv @j_foerst I do occasionally, but only for journals because I find the review load for conferences too intimidating if you have a regular day job. I simply don't have the necessary free time to review 5 papers within a few weeks."
611,@rasbt,2023-01-22 16:39:49+00:00,https://twitter.com/rasbt/status/1617200371172274176,"@ylecun And vice versa, interesting empirical results help to identify interesting avenues to focus on for theoretical work/explanations"
612,@rasbt,2023-01-22 16:03:33+00:00,https://twitter.com/rasbt/status/1617191246342103042,@BenTuringT As per recommendation in that article (and my experience) you can just go with the largest one that works with your hardware.
613,@rasbt,2023-01-22 16:02:27+00:00,https://twitter.com/rasbt/status/1617190966992977924,"@TheZachMueller That being said, I should  probably upgrade some time soon too. I have the cheap ATR 2100 I got in 2012 (originally used it via USB, now I am using it via XLR) and then I tried a Blue Yeti upon recommendation (but that's really terrible in my room)."
614,@rasbt,2023-01-22 15:26:41+00:00,https://twitter.com/rasbt/status/1617181966050238466,"@TheZachMueller I should also add: it's worth investing in an XLR-USB interface vs restricting yourself to USB microphones. They are like $100-200 extra, but it broadens the range of options significantly.
An XLR interface is really just a little box between mic a computer and no hassle at all."
615,@rasbt,2023-01-22 15:11:22+00:00,https://twitter.com/rasbt/status/1617178113217101825,"@THowitis @moyix I am not developing any app for OpenAI's playground if that's what you mean; but if you are curious, the token limit (usually 512, 2048 or 4096 for most LLMs) is due to memory limitations due to the quadratic complexity if scaled dot product attention"
616,@rasbt,2023-01-22 15:01:45+00:00,https://twitter.com/rasbt/status/1617175691639885826,@THowitis @moyix which API?
617,@rasbt,2023-01-22 14:55:52+00:00,https://twitter.com/rasbt/status/1617174210224193543,"@ojtakbyczku We have an automatic batch size finder in the Lightning Trainer for PyTorch that might be useful:

# Autoscale batch size
trainer = Trainer(auto_scale_batch_size=None | ""power"" | ""binsearch"")

# Find the batch size
trainer.tune(model)"
618,@rasbt,2023-01-22 14:29:10+00:00,https://twitter.com/rasbt/status/1617167493725921284,"In other words, choose it as large as your hardware allows, but don't treat it as a tunable hyperparameter. But there is also no point in using larger batch sizes if it increased the training time."
619,@rasbt,2023-01-22 14:28:14+00:00,https://twitter.com/rasbt/status/1617167257121193985,"Just reading the Deep Learning Tuning Playbook (https://t.co/tX9t9twDcb).

""The batch size governs the training speed and shouldn't be used to directly tune the validation set performance. Often, the ideal batch size will be the largest batch size supported [...]""

Good advice üëå"
620,@rasbt,2023-01-22 13:03:38+00:00,https://twitter.com/rasbt/status/1617145969597992962,@j_foerst Maybe starting by including and acknowledging the reviewers and editors (maybe at least in smaller font below the author names)
621,@rasbt,2023-01-22 12:56:22+00:00,https://twitter.com/rasbt/status/1617144139883368448,"@MuhammadAnas707 @Twitter @arya_akhare @salman_codes @akshay_pachaar @eddiejaoude @FrancescoCiull4 @xsgames_ @GrahamTheDev @krshkun @chai_really Nice achievement, congrats!"
622,@rasbt,2023-01-22 12:24:02+00:00,https://twitter.com/rasbt/status/1617136001125842955,"@HLSCodes @CicmilJovan @Ghost @ConvertKit The omission of substack is probably intentional, but I am curious to hear what the main differentiating points are. Substack is too social-media-like compared the other options compared to these other ones who are more conventional newsletters?"
623,@rasbt,2023-01-22 12:09:09+00:00,https://twitter.com/rasbt/status/1617132257625382912,@j_foerst That‚Äôs a really good point. Reviewers in science are also part editors since authors usually (have to) address their points and suggestions.
624,@rasbt,2023-01-22 12:02:54+00:00,https://twitter.com/rasbt/status/1617130682823888901,"@dvassallo Yup, and like with other types of investments, there is compounding interest (eg thinking of learning math or coding when you are young). Its important to pick your battles and think long term"
625,@rasbt,2023-01-22 11:57:43+00:00,https://twitter.com/rasbt/status/1617129377656979456,"@TaliaRinger Wow great initiative, thanks for doing this! 
Btw probably not only helpful for ex Google people (thinking Ali l of ex Microsoft, Meta, etc)"
626,@rasbt,2023-01-22 11:49:48+00:00,https://twitter.com/rasbt/status/1617127387052867586,"@thiojoe @sama Google Translate is based on LLMs since 2017ish. They also use LLMs (eg BERT) for G Search, among others"
627,@rasbt,2023-01-22 04:04:45+00:00,https://twitter.com/rasbt/status/1617010353317228544,"@willdye @docmilanfar Talking about jargon, I was teaching in a statistics department: the term inference was a particularly fun one."
628,@rasbt,2023-01-22 04:02:47+00:00,https://twitter.com/rasbt/status/1617009857164627968,@MichaelKevinSp2 Like this book above üòä ‚Äî it‚Äôs mainly technical-conceptual (but for those who already read an intro ML book. Lots of people asked me for follow-up material; I wrote it with that thought in mind).
629,@rasbt,2023-01-22 04:00:45+00:00,https://twitter.com/rasbt/status/1617009348299083777,@MichaelKevinSp2 I can go through my digital and physical book shelves tomorrow and contribute some ideas/candidates üòÖ
630,@rasbt,2023-01-22 03:59:36+00:00,https://twitter.com/rasbt/status/1617009056958533635,@deliprao (Thank god the person who came up with the price is not one of those using 99 or 123 as a default random seed)
631,@rasbt,2023-01-22 03:58:11+00:00,https://twitter.com/rasbt/status/1617008699951968257,@deliprao It‚Äôs probably also the positive psychology for people my age and older who find 42 particularly because of that insider joke / book reference.
632,@rasbt,2023-01-22 03:56:02+00:00,https://twitter.com/rasbt/status/1617008158987386882,"@moyix It depends a bit on the task. If you are after classification, I‚Äôd probably go with embeddings from an encoder-style LLM"
633,@rasbt,2023-01-22 03:49:45+00:00,https://twitter.com/rasbt/status/1617006579965956096,@raedjinn @moyix @teoliphant might know more üòä
634,@rasbt,2023-01-22 03:47:20+00:00,https://twitter.com/rasbt/status/1617005971934674944,"@MichaelKevinSp2 Either way it would be a huge list for each, but maybe I would use at least those 3 subcategories to start curating recommendations"
635,@rasbt,2023-01-22 03:45:57+00:00,https://twitter.com/rasbt/status/1617005621114556418,@docmilanfar Like transpose convolutions are not literally transposed convolutions üòÖ
636,@rasbt,2023-01-22 03:44:00+00:00,https://twitter.com/rasbt/status/1617005130531983361,"@MichaelKevinSp2 Which type of books are you looking for? Primarily textbooks, coding books, or conceptual books?"
637,@rasbt,2023-01-22 03:33:18+00:00,https://twitter.com/rasbt/status/1617002437427986434,"@TheZachMueller Like others said, the mic is probably most important. And different mics work better for different types of rooms &amp; environments. Here's a pretty good guide that might help: https://t.co/y5qHrfrsbL"
638,@rasbt,2023-01-22 00:45:43+00:00,https://twitter.com/rasbt/status/1616960264989020160,@WoWGradStudent @luctielen Scala was all the rage in data science when I was a fresh grad student. I haven't heard that much about it recently. Is it just too boring to talk about or did people move on / back to Python. (CC @chrisalbon @vboykis may also have opinions about this üòÜ)
639,@rasbt,2023-01-22 00:16:32+00:00,https://twitter.com/rasbt/status/1616952922213941250,@drscotthawley @DSaience Your book is a textbook btw? Any spoilers regarding the topic yet? üòä
640,@rasbt,2023-01-22 00:15:14+00:00,https://twitter.com/rasbt/status/1616952591619092481,"@drscotthawley @DSaience Then, there are cases though where it includes points I haven't considered. E.g., on the lottery hypothesis and smaller models, it mentioned interpretability (my explanation and answer was purely from an efficiency standpoint).
So, GPT might a good companion for brainstorming. https://t.co/mALcHc1T6S"
641,@rasbt,2023-01-22 00:12:40+00:00,https://twitter.com/rasbt/status/1616951947747266561,"@drscotthawley @DSaience Yeah, it's hit or miss. 

E.g., this one on few-shot learning is super generic and basically sounds like supervised learning on a small dataset.

And then sometimes it's very detailed, where 80% of the details are correct, but some weird unrelated things are peppered in there. https://t.co/FfF8Tcb7AS"
642,@rasbt,2023-01-22 00:09:37+00:00,https://twitter.com/rasbt/status/1616951178365136896,"@DSaience Hah, making these figures was certainly a lot of effort! We will see how long it takes until there's an AI that can catch up with me üòÖ 
(PS: You are right, it's probably only a matter of time until someone trains a model that can produce rough block diagrams) https://t.co/Q9JlLJ10mh"
643,@rasbt,2023-01-21 23:44:26+00:00,https://twitter.com/rasbt/status/1616944842386575360,"@curiousspaceman @edertec @leanpub There's an epub version you can load onto a Kindle. I haven't 100% decided, but there may be a Kindle version once the book is completed. Right now, I am planning to extend it with 1-3 Q's each weekend. Most of it is written, but I want to do some careful editing &amp; formatting"
644,@rasbt,2023-01-21 22:41:55+00:00,https://twitter.com/rasbt/status/1616929110348922883,"@edertec @leanpub Thanks, hope you'll like it! üòä"
645,@rasbt,2023-01-21 22:32:36+00:00,https://twitter.com/rasbt/status/1616926765980520448,"@DSaience One thing for sure, ChatGPT has a lot of false positives (includes unrelated or misleading info in the answers). And its achilles heel is that it can't generate figures/illustrations -- a picture is worth a million words.

I do think ChatGPT could be good for inspiration though."
646,@rasbt,2023-01-21 22:16:41+00:00,https://twitter.com/rasbt/status/1616922761573588994,"@sarojbono Hah, nice! Lectures on that coming up in Unit 4 next week :) https://t.co/0yDG4AgCHk"
647,@rasbt,2023-01-21 22:05:49+00:00,https://twitter.com/rasbt/status/1616920023406084096,"@CSProfKGD @jmtomczak @SimonPrinceAI Nice, really looking forward to it! Thanks for the pointer!"
648,@rasbt,2023-01-21 22:05:17+00:00,https://twitter.com/rasbt/status/1616919888731283460,"@DSaience Yeah, I put a lot of hours into writing this book. Many weekends I could have done sth else instead ... 
So when ChatGPT came out in December, I was like: does that make me obsolete? 
I couldn't help but make the best out of it and compare my answers to the AI-generated ones üòä"
649,@rasbt,2023-01-21 22:02:36+00:00,https://twitter.com/rasbt/status/1616919214509400065,"@CSProfKGD @jmtomczak @SimonPrinceAI Thanks! I think the chapter is not included in the PDF preview/draft, but I bookmarked for when the book comes out!"
650,@rasbt,2023-01-21 21:45:39+00:00,https://twitter.com/rasbt/status/1616914949888180225,@xinformatics @CSProfKGD @jmtomczak Ahh yes meant the ToC of course üòÖ
651,@rasbt,2023-01-21 21:44:31+00:00,https://twitter.com/rasbt/status/1616914665199570944,@luctielen I think it‚Äôs nice for math stuff and smaller conceptual stuff. But it becomes too unwieldy pretty quick. There‚Äôs a reason why all neural network APIs for JAX are object-oriented.
652,@rasbt,2023-01-21 21:40:41+00:00,https://twitter.com/rasbt/status/1616913699188477956,@moyix üíØ! And a tensor/array library like NumPy would also be nice.
653,@rasbt,2023-01-21 21:30:33+00:00,https://twitter.com/rasbt/status/1616911147852247041,"@Pimp_Fada @CSProfKGD Did some benchmarks here: https://t.co/6f0HX8zwlX

(Should rerun that maybe on the latest PyTorch versions some time to see if it changed)"
654,@rasbt,2023-01-21 21:28:15+00:00,https://twitter.com/rasbt/status/1616910569004761089,"@MuhammadAnas707 Nice! Glad to hear you are alternating reading/studying and project work. That‚Äôs also what I do and recommend to students! 
(PS: the video game topic is a fun pick)"
655,@rasbt,2023-01-21 21:26:49+00:00,https://twitter.com/rasbt/status/1616910208936345600,"@efujikei Makes total sense. That‚Äôs because the feature space is much smaller ‚Äî someone extracted feature ‚Äúmanually‚Äù.

If someone‚Äôs curious, it‚Äôs the exercise here: https://t.co/HFC6FjcZAA"
656,@rasbt,2023-01-21 21:24:18+00:00,https://twitter.com/rasbt/status/1616909578423132160,@EhsanHaghighat @CSProfKGD I think PyTorch only supports the CPU and GPU cores based on the latest seminar by one of the PyTorch devs. But that‚Äôs been a couple of months back and maybe that changed recently
657,@rasbt,2023-01-21 21:22:48+00:00,https://twitter.com/rasbt/status/1616909199903956995,"@sarojbono Cool! Let me know what you think! (I hope the topics are not too intimidating, it‚Äôs basically a book discussing topics as a follow-up to my or other intro books and courses)"
658,@rasbt,2023-01-21 21:20:09+00:00,https://twitter.com/rasbt/status/1616908534049869831,@CSProfKGD @jmtomczak Would you mind photographing the appendix üòÖ! Mainly curious how comprehensive the diffusion sections are (looking for good treatments that are going beyond the standard blog posts on that topic)
659,@rasbt,2023-01-21 21:17:54+00:00,https://twitter.com/rasbt/status/1616907968242499586,@CSProfKGD Wohoo nice!!! Would love to see the PyTorch GPU benchmarks of that one (happy to compare to the M1 Max for the same code)
660,@rasbt,2023-01-21 21:15:23+00:00,https://twitter.com/rasbt/status/1616907331068989445,@GiorgioMantova Yes this one is without code. It‚Äôs more conceptual. I may think about adding optional code for some Q‚Äòs if there‚Äòs demand for that üòä
661,@rasbt,2023-01-21 21:13:55+00:00,https://twitter.com/rasbt/status/1616906965250367488,@sarojbono Looks super cool! Thanks üòä
662,@rasbt,2023-01-21 19:24:28+00:00,https://twitter.com/rasbt/status/1616879421008367617,@_sidmohan Thanks for your support! More Q‚Äòs will go live next weekend! Working on polishing the figures!
663,@rasbt,2023-01-21 17:18:31+00:00,https://twitter.com/rasbt/status/1616847723105341442,"@DSaience Thanks! It was tons of work, and I was hoping the ChatGPT aspect is an interesting little twist! üòä"
664,@rasbt,2023-01-21 17:10:13+00:00,https://twitter.com/rasbt/status/1616845634610565120,"If I am not too optimistic, the ETA for the complete version is Q1/Q2 2023 üöÄ
I have most questions already written last year. 
The plan is to be editing + formatting 2-3 q's per weekend. 
(Some of you may recognize snippets from all my social media posts over the years üòä)"
665,@rasbt,2023-01-21 16:53:24+00:00,https://twitter.com/rasbt/status/1616841404470157313,"@learningritik The 100 page machine learning book by @burkov perhaps: https://t.co/43zSbuRS1s? It's not a code book. However, as I recall, it's about ML in general (not DL specifically).

Otherwise, my ML with PyTorch &amp; Sklearn book (if you skip the code parts) üòÖ"
666,@rasbt,2023-01-21 15:39:03+00:00,https://twitter.com/rasbt/status/1616822692384223239,"Machine Learning Q and AI -- Expand your machine learning &amp; AI knowledge with 30 questions and answers.

An early-access of my new book, my first in the era of ChatGPT, is now on Leanpub: https://t.co/87ijAKwVM7

Would love to hear what you think!

Happy weekend &amp; happy learning!"
667,@rasbt,2023-01-21 13:19:28+00:00,https://twitter.com/rasbt/status/1616787562554658817,"@Sergei_Imaging Yes, and because of that, I think human expertise will be more important than ever ‚Äî since it will be easy to create deceptively well-written texts with lower effort:
https://t.co/C5pVCHlO3O

(Stay tuned for my new book which involves ChatGPT with an interesting twist.)"
668,@rasbt,2023-01-21 01:27:37+00:00,https://twitter.com/rasbt/status/1616608422153146369,"@keyutian Wow, big congrats!!! üéâ"
669,@rasbt,2023-01-20 22:56:46+00:00,https://twitter.com/rasbt/status/1616570460384157696,@engineerabdulll @MuhammadAnas707 will DM you :)
670,@rasbt,2023-01-20 20:42:00+00:00,https://twitter.com/rasbt/status/1616536543392399379,@McDonald_Ibekwe I will discuss these in some more detail in an upcoming book ...
671,@rasbt,2023-01-20 17:36:20+00:00,https://twitter.com/rasbt/status/1616489819156119569,"@MuhammadAnas707 Wohoo! And don't forget to take a break (e.g., on the weekend) if you need it!"
672,@rasbt,2023-01-20 16:55:37+00:00,https://twitter.com/rasbt/status/1616479574191112194,@MuhammadAnas707 @MeetWadekar04 @100DaysOfML does it help with motivation or accountability if I ask about day 6? üòÜüòá
673,@rasbt,2023-01-20 16:54:01+00:00,https://twitter.com/rasbt/status/1616479169822752770,@anonymousobe There are different ways to approach this. I would probably start with a course or book. Shameless plug: I have a free course here: https://t.co/B0rVXxbR6v
674,@rasbt,2023-01-20 15:17:36+00:00,https://twitter.com/rasbt/status/1616454905992028160,"@fon_tran CC @Apple  -- if could my hands on a M2 machine for a few days, I'd be delighted to update the benchmarks üòä"
675,@rasbt,2023-01-20 15:16:02+00:00,https://twitter.com/rasbt/status/1616454512645898240,"@chaturv3di I would rather use data augmentation than synthetic data generation. Regarding SMOTE, there are also deep learning methods for synthetic data now
E.g., ""Language Models are Realistic Tabular Data Generators""  https://t.co/SQq1G24KDg

(discussed it here: https://t.co/9sgOVRJSkz)"
676,@rasbt,2023-01-20 15:08:46+00:00,https://twitter.com/rasbt/status/1616452682935410688,"@sharma_P19 Interesting blend, it's kind of active learning (but not in the original sense)"
677,@rasbt,2023-01-20 14:55:08+00:00,https://twitter.com/rasbt/status/1616449252707762178,"@JagersbergKnut yeah, good one, I would say that it sits somewhere between semi-supervised learning and weakly supervised learning."
678,@rasbt,2023-01-20 14:53:56+00:00,https://twitter.com/rasbt/status/1616448948302155780,"@yousafokhan Fine-tuning is part of transfer learning. Using a pretraining model as is ... I would just call that ""inference"" üòÖ"
679,@rasbt,2023-01-20 14:49:59+00:00,https://twitter.com/rasbt/status/1616447957691424770,@fon_tran If only someone would donate me a M2 machine ... haha üòÖ
680,@rasbt,2023-01-20 14:22:24+00:00,https://twitter.com/rasbt/status/1616441013765128193,"@NoureddinSadawi Good question, as someone who likes to categorize and structure things, I was thinking about this really hard but it's hard and I don't think so."
681,@rasbt,2023-01-20 14:20:59+00:00,https://twitter.com/rasbt/status/1616440657580797952,"@Invasive_Bias Although I see your point. We can think of meta-learning as one of the 3 techniques for approaching FSL. But in a sense, we can also think of meta-learning as a less technical but more conceptual approach, and then FSL would be a subcategory of meta-learning."
682,@rasbt,2023-01-20 14:19:25+00:00,https://twitter.com/rasbt/status/1616440263651598338,"@Invasive_Bias It's the opposite I'd say: Meta-learning is a subcategory of  few-shot learning. But there are also different types of meta-learning. One definition of meta-learning is unrelated to few-shot learning. E.g., take the definition of meta-learning in AutoML contexts."
683,@rasbt,2023-01-20 14:09:47+00:00,https://twitter.com/rasbt/status/1616437839356657665,"6.  Active learning: actively select the most informative examples to be labeled by a human

7.  Weakly supervised learning: create noisy, limited, or imprecise labels for a supervised learner

8.  Multi-task learning: train with multiple losses to perform well on multiple tasks"
684,@rasbt,2023-01-20 14:09:46+00:00,https://twitter.com/rasbt/status/1616437836651302913,"4.  Few-shot learning: learn from a very small number of examples/class (e.g., 1 or 5) using meta-learning, transfer learning, or metric-based methods.

5.  Meta-learning: two definitions, a) either learn from meta-features, b) train a meta-learner in few-shot contexts"
685,@rasbt,2023-01-20 14:09:46+00:00,https://twitter.com/rasbt/status/1616437833979555848,"1.  Transfer learning: pretrain on general, labeled dataset. Then fine-tune on target dataset.

2.  Self-supervised learning: pretrain on unlabeled data, then fine-tune on target dataset.

3.  Semi-supervised: train on a dataset that is partially labeled and partially unlabeled."
686,@rasbt,2023-01-20 14:09:45+00:00,https://twitter.com/rasbt/status/1616437831085494273,"Derivatives of regular supervised learning when you don't have enough labeled data:

1.  Transfer learning
2.  Self-supervised learning
3.  Semi-supervised learning
4.  Few-shot learning
5.  Meta-learning
6.  Active learning
7.  Weakly supervised learning
8.  Multi-task learning"
687,@rasbt,2023-01-20 13:59:29+00:00,https://twitter.com/rasbt/status/1616435247423553538,@TaliaRinger I know what you mean in the context of live coding üòÖ
688,@rasbt,2023-01-20 12:50:25+00:00,https://twitter.com/rasbt/status/1616417864734359553,"@AllenDowney When I review articles in computational bio, the authors usually have the figures appended to the end of the text, which I always find super annoying. As a reviewer you have to create 2 PDFs and view them side by side, and switching is still painful if you use an e-reader."
689,@rasbt,2023-01-20 03:40:20+00:00,https://twitter.com/rasbt/status/1616279434712989696,@MuhammadAnas707 @MeetWadekar04 @100DaysOfML Spaced repetition / Anki :)
690,@rasbt,2023-01-20 02:48:15+00:00,https://twitter.com/rasbt/status/1616266326703480832,@MuhammadAnas707 @MeetWadekar04 @100DaysOfML Btw I find it helpful to build an Anki (flash card) deck when I am learning sth new. Thinking about interesting questions helps me to recall things better. Described it in brief here at the bottom: https://t.co/SylIoQJ4Pu
691,@rasbt,2023-01-20 02:43:40+00:00,https://twitter.com/rasbt/status/1616265173332811777,"@MuhammadAnas707 @MeetWadekar04 @100DaysOfML No worries, you are just taking time to let it sink in üòä."
692,@rasbt,2023-01-19 21:04:09+00:00,https://twitter.com/rasbt/status/1616179728448110593,"@CristiVlad25 Whoa thanks for the long-time support!!! 

And sorry about the slow roll out. Video is quite a lot of work compared to writing. 

But in the mean time, my recent book has a transformer/LLM chapter (chapter 16) üòä"
693,@rasbt,2023-01-19 20:44:11+00:00,https://twitter.com/rasbt/status/1616174706142363666,"@CristiVlad25 Yes, in unit 8 üòä"
694,@rasbt,2023-01-19 20:43:20+00:00,https://twitter.com/rasbt/status/1616174491163312128,@vboykis *we could host the Distil version of a pretrained model on a handful of GPUs. Getting a properly finetuned one (on human feedback) will be the bigger challenge.
695,@rasbt,2023-01-19 20:41:26+00:00,https://twitter.com/rasbt/status/1616174014614933505,"@vboykis Agreed. And my hot take: the biggest bottleneck will be us humans in RLHF (reinforcement learning with human feedback), not the compute infrastructure."
696,@rasbt,2023-01-19 19:35:38+00:00,https://twitter.com/rasbt/status/1616157454324187136,"@tunguz @ArtificalNate @SmokeAwayyy @sujalyadav22007 @goth600 @xlr8harder @MichaelTrazzi @anammostarac @mezaoptimizer @Lan_Dao_ @jenny____r @juliewdesign_ @karpathy @tszzl @_akhaliq @Liff_82 @mrjonfinger @smylkshmn @archillect @EMostaque @TheMoonMidas @zaesarius @Scobleizer @fchollet @ylecun @marktenenholtz @svpino @growing_daniel @joelgrus @NathanLands @LinusEkenstam @DrJimFan @sama Let me add @omarsar0, @DynamicWebPaige and @_akhaliq to the list!"
697,@rasbt,2023-01-19 18:23:14+00:00,https://twitter.com/rasbt/status/1616139234351673346,"@lvwerra Probably Rust, because I already know Python ;)"
698,@rasbt,2023-01-19 18:19:28+00:00,https://twitter.com/rasbt/status/1616138284664487950,"@xinformatics Haha sorry can‚Äôt help with that, but Unit 5 will be about PyTorch Lightning if that helps üôÉ."
699,@rasbt,2023-01-19 17:25:03+00:00,https://twitter.com/rasbt/status/1616124592732647429,"Big shoutout for @xamat's LLM family tree blog post! It comes with nice &amp; concise summaries of each model (63 pages, if you export it as a PDF!)

https://t.co/3he7VI1Vzy https://t.co/HcHNnHF28V"
700,@rasbt,2023-01-19 17:16:09+00:00,https://twitter.com/rasbt/status/1616122350726172675,"@Kaszanas Haha, I wish this existed years ago. @randal_olson always beat me at Rocket League"
701,@rasbt,2023-01-19 17:08:53+00:00,https://twitter.com/rasbt/status/1616120522059960320,@wolfcry3_0 @MuhammadAnas707 This one :) https://t.co/tJU9cJpH3S
702,@rasbt,2023-01-19 17:04:25+00:00,https://twitter.com/rasbt/status/1616119398317555715,"@MuhammadAnas707 Yes, for sure! You will also have an easier time adopting models from recent research projects. I.e., most deep learning papers use PyTorch these days according to this analysis: https://t.co/DcWadBnqE3 https://t.co/LVExbf5TBL"
703,@rasbt,2023-01-19 16:58:09+00:00,https://twitter.com/rasbt/status/1616117823750766592,"@fk_boat @LightningAI Good question! Was a busy couple of weeks, but it should be up by next week!"
704,@rasbt,2023-01-19 16:53:40+00:00,https://twitter.com/rasbt/status/1616116694967267328,"@Kaszanas No, that's super out of scope for this course, which is already waaaaay longer than I wanted to be. But interesting topics for standalone courses for sure!"
705,@rasbt,2023-01-19 16:50:18+00:00,https://twitter.com/rasbt/status/1616115847810154497,@MuhammadAnas707 A short summary here: https://t.co/EfH4g1oqRe
706,@rasbt,2023-01-19 16:46:38+00:00,https://twitter.com/rasbt/status/1616114923225989140,"@MuhammadAnas707 PyTorch :). I used TensorFlow 2015-2018, but I made the switch to PyTorch in 2018 and never looked back"
707,@rasbt,2023-01-19 16:44:42+00:00,https://twitter.com/rasbt/status/1616114436246323201,"@MuhammadAnas707 I think you'll like it! But the ML class you are currently taking is super relevant too, though, and it's probably a good idea to take that first. It has much bigger focus on model evaluation, which is super important."
708,@rasbt,2023-01-19 16:31:24+00:00,https://twitter.com/rasbt/status/1616111091423281153,"The DL Fundamentals lectures will incl additional fun stuff &amp; goodies that are usually not included in most other DL resources (like my book)

- learning rate schedulers
- automating hparam tuning
- logging &amp; checkpointing
- mixed precision &amp; quantization &amp; multi-GPU training
..."
709,@rasbt,2023-01-19 15:57:11+00:00,https://twitter.com/rasbt/status/1616102480160657408,Better idea: let's make each of the 250 operators in PyTorch 2.0's PrimTorch a trading card.
710,@rasbt,2023-01-19 15:53:01+00:00,https://twitter.com/rasbt/status/1616101431622397953,"@ai_files @GaryMarcus @tdietterich @billyperrigo We are going back to the old, overused metaphor that data is the new oil. 
&gt; Data, like oil, is hard to extract and valuable only after it is refined."
711,@rasbt,2023-01-19 15:25:05+00:00,https://twitter.com/rasbt/status/1616094403155599361,@ai_files @GaryMarcus @tdietterich @billyperrigo That's a great analogy! (PS: My answer above was sarcastic if that wasn't clear)
712,@rasbt,2023-01-19 14:50:17+00:00,https://twitter.com/rasbt/status/1616085645512015875,@pythonprimes For modern neural networks? Not that I am aware of.
713,@rasbt,2023-01-19 14:47:42+00:00,https://twitter.com/rasbt/status/1616084993566019585,"@roald @sarojbono Haha, this was in 2015, two years before Transformers (""Attention is All You Need"") where invented -- but yeah, I wish I anticipated it earlier üòÜ.

Glad you liked the book though!"
714,@rasbt,2023-01-19 14:44:27+00:00,https://twitter.com/rasbt/status/1616084175588847616,"@danofer Yes, that's my original intuition as well. But how would it explain effects like double decent and grokking?"
715,@rasbt,2023-01-19 14:42:50+00:00,https://twitter.com/rasbt/status/1616083769617793038,"@TornbergLars @lorenzofamigli1 It's an improvement, but the issue is that it's still the same fixed training dataset."
716,@rasbt,2023-01-19 03:49:13+00:00,https://twitter.com/rasbt/status/1615919278754041856,"@GaryMarcus @tdietterich @billyperrigo Yeah, totally. I wanted to get at the fact we currently don't know how to really fix the issue (not just patch it with data). And deleting the ""bad"" internet data would of course not be feasible and your point 2 would even then still apply."
717,@rasbt,2023-01-19 03:21:34+00:00,https://twitter.com/rasbt/status/1615912320592498689,@roydanroy @_davemacdonald I wish they offered more than a 28-day view so I could compare Nov-Dec to Dec-Jan
718,@rasbt,2023-01-19 02:57:20+00:00,https://twitter.com/rasbt/status/1615906223542489090,"@GaryMarcus @tdietterich @billyperrigo With current technology, the most feasible approach would be to delete all toxic data from the internet so that we starve the AI systems of that training data."
719,@rasbt,2023-01-19 02:54:40+00:00,https://twitter.com/rasbt/status/1615905552965722112,"@beenwrekt Nothing beyond things like when I remove nonlinear activation functions from the hidden layers, I get a linear decision boundary, because a combination of linear functions is still a linear function."
720,@rasbt,2023-01-19 02:52:27+00:00,https://twitter.com/rasbt/status/1615904996914040832,"@renegadesilicon Good point. It's a hyperparameter itself, but we should be multiplying the k-fold performance with a decay rate to adjust for that."
721,@rasbt,2023-01-19 02:47:43+00:00,https://twitter.com/rasbt/status/1615903805106786308,"I mean it üòä! 
I wrote an article on model evaluation a few years back, and it's literally like an ad for cross-validation. And I didn't change my mind since then üòä! 
https://t.co/aYvW168wLF"
722,@rasbt,2023-01-19 02:40:49+00:00,https://twitter.com/rasbt/status/1615902066341449728,"@srchvrs @marktenenholtz 2/2 but I would say, with nested CV, it's still probably the best approach. Everything short of tapping into a pool of infinite test data has its shortcomings. I think k-fold is ok if we use it with a bit of care."
723,@rasbt,2023-01-19 02:39:21+00:00,https://twitter.com/rasbt/status/1615901699696218112,"@srchvrs @marktenenholtz Yeah, the problem is that you are still selecting based on validation folds which are part of the training dataset -- no free lunch: you are not fitting to it explicitly, but if you have a very large number of hparam, you are kind of fitting to it implicitely. 1/2"
724,@rasbt,2023-01-19 02:37:36+00:00,https://twitter.com/rasbt/status/1615901256106610689,"@marktenenholtz Totally. It's a bit of extra work but worth it. It's of course not fixing the issue, but it should help a bit for sure."
725,@rasbt,2023-01-19 02:30:12+00:00,https://twitter.com/rasbt/status/1615899395517730816,"Btw I am a big fan of k-fold cross validation. Don‚Äôt want to imply that cross-validation (k-fold or nested) is bad.
Just wanted to make a point that it doesn‚Äôt completely save you from overfitting if you run crazy extensive hyperparameter tuning sessions."
726,@rasbt,2023-01-18 23:56:28+00:00,https://twitter.com/rasbt/status/1615860708884840448,@sarojbono Haven‚Äôt read it but it definitely looks useful for learning. Is it using the latest cutting edge LLM? No. Is it helpful? Yes! Looks like it :). They cover how to implement a chat bot in general + you‚Äôll learn how LLMs work.
727,@rasbt,2023-01-18 23:47:55+00:00,https://twitter.com/rasbt/status/1615858553553825792,"@cybertiger16 @sarojbono I think it depends on the exact position and experience required, but I can proudly say that people shared with me that they did get a job thanks to my book :)"
728,@rasbt,2023-01-18 21:36:24+00:00,https://twitter.com/rasbt/status/1615825459937173504,@JustinRGoheen @LightningAI noted!
729,@rasbt,2023-01-18 20:49:27+00:00,https://twitter.com/rasbt/status/1615813643915956256,@conormacd Thanks! I actually have notebook of 100+ things to add one day üòä
730,@rasbt,2023-01-18 20:03:50+00:00,https://twitter.com/rasbt/status/1615802161941843968,@joftius @F_Vaggi totally agree. the thing is only that a lot of people tend to tune GB more than other methods (like random forests)
731,@rasbt,2023-01-18 20:00:26+00:00,https://twitter.com/rasbt/status/1615801307142721536,"@benitocm1 @lilianweng I have a series of videos here (Lecture 19): https://t.co/JhY0KBGZRb

and a more polished chapter in my book (Chapter 16): https://t.co/y5OOHFDAm5"
732,@rasbt,2023-01-18 19:25:48+00:00,https://twitter.com/rasbt/status/1615792593203515393,"@RDub2 Yeah, but would that explain why it occurs on small, fixed-size training sets?"
733,@rasbt,2023-01-18 18:43:22+00:00,https://twitter.com/rasbt/status/1615781911187836929,@RDub2 Yup. And I didn‚Äôt believe it until I experienced it.
734,@rasbt,2023-01-18 18:36:13+00:00,https://twitter.com/rasbt/status/1615780113513070624,"@RespectToX I think it's an insider joke/reference (similar to using 42 as a random seed, but different book), and I agree :P"
735,@rasbt,2023-01-18 18:24:57+00:00,https://twitter.com/rasbt/status/1615777279497613312,"@lorenzofamigli1 üíØ! Although, I think even nested cross-validation has a similar issue if you crank up the number of hyperparameter configurations to a crazy large value."
736,@rasbt,2023-01-18 17:27:19+00:00,https://twitter.com/rasbt/status/1615762775199842305,"@MuhammadAnas707 @Techtrocity_ Likewise, it's very motivating to see people getting something useful out of the materials I am sharing ^^. Definitely keeps me motivated to create more!"
737,@rasbt,2023-01-18 17:11:17+00:00,https://twitter.com/rasbt/status/1615758739738619904,@alfer_jan @MuhammadAnas707 Eigentlich alles ausser diffusion models üôÉ
738,@rasbt,2023-01-18 16:59:43+00:00,https://twitter.com/rasbt/status/1615755827272351746,"@8ctopuso Haha, giving out too many practice tests maybe :P"
739,@rasbt,2023-01-18 16:45:24+00:00,https://twitter.com/rasbt/status/1615752226009382920,"@HamedBH better, I have the whole code here in a jupyter notebook if you want to reproduce it ^^ https://t.co/zqEeCLznQx"
740,@rasbt,2023-01-18 16:43:17+00:00,https://twitter.com/rasbt/status/1615751691911188483,"@MuhammadAnas707 @Techtrocity_ Usually, you split the dataset into a training and a test dataset. If you use cross-validation for model selection, you only apply it to the training set (which you split into training and validation folds)"
741,@rasbt,2023-01-18 16:29:23+00:00,https://twitter.com/rasbt/status/1615748195145117699,"@Techtrocity_ @MuhammadAnas707 The test validation is on an independent test set.
But yes, cross validation is an evaluation technique, and it is also often used for model selection (like above)"
742,@rasbt,2023-01-18 16:19:06+00:00,https://twitter.com/rasbt/status/1615745608672845824,"@F_Vaggi An interesting point someone brought up: maybe instead of using the average over the k validation folds for model selection, what happens if we use the worst fold?"
743,@rasbt,2023-01-18 16:18:24+00:00,https://twitter.com/rasbt/status/1615745431136309250,@omar_javd @daniela_witten Very nice thread indeed!
744,@rasbt,2023-01-18 16:07:07+00:00,https://twitter.com/rasbt/status/1615742591735054336,"@F_Vaggi Yeah, so the method above is also what 95% (if not more) of papers do in practice"
745,@rasbt,2023-01-18 16:06:03+00:00,https://twitter.com/rasbt/status/1615742322595233793,"@F_Vaggi Sure, that would be ideal, but getting fresh held-out data is often not practical"
746,@rasbt,2023-01-18 16:05:05+00:00,https://twitter.com/rasbt/status/1615742081380790272,"@F_Vaggi Hm, so what would be a better way to do model selection if not using k-fold cross validation. Nested CV?"
747,@rasbt,2023-01-18 16:00:21+00:00,https://twitter.com/rasbt/status/1615740890076561409,"@F_Vaggi To your point of unbiasedness: that's only true if you do exactly 1 round of k-fold cross validation for model evaluation. If you use it for model selection, it's no longer unbiased since you use the data multiple times."
748,@rasbt,2023-01-18 15:58:01+00:00,https://twitter.com/rasbt/status/1615740302924419074,"@F_Vaggi Because you re-use the training dataset during k-fold cross-validation. At some point, you will find hyperparameters that work super well on the validation folds in that training dataset. The problem is that you don't really have held-out data since you don't change the dataset."
749,@rasbt,2023-01-18 15:52:35+00:00,https://twitter.com/rasbt/status/1615738934327222272,"@timothyvh Choosing a smaller, reasonable number of hyperparameter configurations."
750,@rasbt,2023-01-18 15:46:51+00:00,https://twitter.com/rasbt/status/1615737492476395522,"From a recent collaboration: Gradient boosting is usually great, but beware of overtuning. And no, k-fold cross-validation does not prevent overfitting. 

Tune a large number of hyperparameters, and you will overfit to your k-fold partitions: https://t.co/qQmLNhZM8c"
751,@rasbt,2023-01-18 15:13:55+00:00,https://twitter.com/rasbt/status/1615729203240136705,@mohsinmahmood00 @MuhammadAnas707 It's maybe easiest to navigate the course via this table: https://t.co/tJU9cJpH3S
752,@rasbt,2023-01-18 15:08:24+00:00,https://twitter.com/rasbt/status/1615727813218140162,"@sarojbono No worries :). Btw if you are curious, there is a transformer chapter in my Machine Learning with Python book  you are reading (Ch 16), but no need to rush to it yet :)"
753,@rasbt,2023-01-18 15:06:18+00:00,https://twitter.com/rasbt/status/1615727286690500608,"@sandyasm Yeah, sure, see the paper referenced below: https://t.co/E6hWOA6YTk"
754,@rasbt,2023-01-18 15:03:46+00:00,https://twitter.com/rasbt/status/1615726650552975361,"@sandyasm According to the most recent insights, the pruned models may have better generalization performance due to the more intense training, not because they are smaller"
755,@rasbt,2023-01-18 14:50:10+00:00,https://twitter.com/rasbt/status/1615723224389533700,"@code_star If you train the original model using the same procedures, you get the same (or better loss though). We can still use this analogy though: longer training yields more tickets"
756,@rasbt,2023-01-18 14:48:20+00:00,https://twitter.com/rasbt/status/1615722762953281537,"@code_star Hm yeah, but the recent plot twist in the observed improvements in generalization performance in LTH are not due to the smaller model size but due to the more intense training."
757,@rasbt,2023-01-18 14:43:22+00:00,https://twitter.com/rasbt/status/1615721514539839490,"@code_star Eg in the beginning, the features &amp; interactions are rough &amp; specific so that they overfit to noise, but they evolve to be more general over time? Do you think it might be due to chance from training so long, because there is no added incentive from a training loss perspective?"
758,@rasbt,2023-01-18 14:34:50+00:00,https://twitter.com/rasbt/status/1615719367831863297,"Recent research showed that the reduction of overfitting in smaller models (e.g. via pruning) can be partly explained by the improved training processes (https://t.co/mvf2nE7agl).

I wonder if there are any alternative theories or pointers to explain this?
4/4"
759,@rasbt,2023-01-18 14:34:50+00:00,https://twitter.com/rasbt/status/1615719366019932161,"How can we reconcile the observation that smaller (e.g., pruned) models can exhibit better generalization performance with contradictory observations from studies of double-decent and grokking? 
3/4"
760,@rasbt,2023-01-18 14:34:49+00:00,https://twitter.com/rasbt/status/1615719364560388096,"However, counterintuitively, recent research studying phenomenas like ""double decent"" and ""grokking"" also showed that larger, overparameterized models show improved generalization performance if they are trained beyond the point of overfitting.
2/4"
761,@rasbt,2023-01-18 14:34:49+00:00,https://twitter.com/rasbt/status/1615719362668761090,"Classic bias-variance theory suggests that reducing model size can reduce overfitting. Why? As a rule of thumb, the smaller the number of model parameters the smaller its capacity -- a smaller capacity reduces the model's capacity to memorize or overfit to noise in the data. 1/4"
762,@rasbt,2023-01-18 13:31:21+00:00,https://twitter.com/rasbt/status/1615703392222863361,"Large Transformer Model Inference Optimization (https://t.co/vMFkSsCk5S)-- a really nice &amp; thorough article by @lilianweng.

Interesting tidbit: low-bit quantization can cause severe qualitative drops due to outliers; fixes are mixed-precision techniques and outlier smoothing https://t.co/IO3XxAlVmL"
763,@rasbt,2023-01-18 13:08:29+00:00,https://twitter.com/rasbt/status/1615697638338297859,@svpino üíØ! And don‚Äôt forget to supercharge your ResNet with masked autoencoding!
764,@rasbt,2023-01-18 12:44:25+00:00,https://twitter.com/rasbt/status/1615691578802114563,@radekosmulski @fastdotai @bhutanisanyam1 @kaggle Wohoo congrats üéâüçæ!
765,@rasbt,2023-01-18 12:43:12+00:00,https://twitter.com/rasbt/status/1615691274304032768,"@hankgreen Wow congrats!! 

PS: wouldn‚Äôt mind a golden üê¶ @elonmusk"
766,@rasbt,2023-01-18 12:35:26+00:00,https://twitter.com/rasbt/status/1615689318244421632,"@prdeepakbabu @benhamner RLHF is *trying* to solve that, but it is not quite there yet. https://t.co/C5pVCHmlTm"
767,@rasbt,2023-01-18 12:33:05+00:00,https://twitter.com/rasbt/status/1615688726243409920,"@calumbirdo @huggingface Awesome stuff, thanks for creating and sharing! Little side question: how specific is that to decoder-style LLMs, and is the formula different for encoder-style LLMs for predictive (vs generative) modeling tasks (like BERT and successors)"
768,@rasbt,2023-01-18 12:27:25+00:00,https://twitter.com/rasbt/status/1615687300305899521,"@foozlefoo @kushirosea Good summary. To elaborate a bit: if masked autoencoding is adapted without the proposed sparse convolution part, there are several issues:"
769,@rasbt,2023-01-18 12:24:26+00:00,https://twitter.com/rasbt/status/1615686551597375488,"@MuhammadAnas707 @Saboo_Shubham_ Whoa, that‚Äôs really nice to see üòä! And big congrats @Saboo_Shubham_, you book looks super exciting! Will add it to my wish &amp; reading list for this year!!"
770,@rasbt,2023-01-17 22:33:48+00:00,https://twitter.com/rasbt/status/1615477515639820288,@alkalait This tweet has been agreed with üëç
771,@rasbt,2023-01-17 22:25:45+00:00,https://twitter.com/rasbt/status/1615475489329618956,"@pythiccoder @LightningAI All the features in DeepSpeed should already be automatically available in Lightning Trainer for both training and inference ... so we just have to DeepSpeed releases new features, haha üòÜ. 
(And in the meantime, there is also ColossalAI support in the Lightning Trainer.)"
772,@rasbt,2023-01-17 22:21:15+00:00,https://twitter.com/rasbt/status/1615474357370855441,"@omarsar0 Looks awesome! But 2 hours ... wow ... will have to try hard to muster my attention span for this (no pun intended), and it probably has to wait for the weekend, but I am looking forward to this!"
773,@rasbt,2023-01-17 21:41:45+00:00,https://twitter.com/rasbt/status/1615464418069848065,@NoureddinSadawi This would actually be most feasible/best for image data :)
774,@rasbt,2023-01-17 20:42:15+00:00,https://twitter.com/rasbt/status/1615449443637297152,"@vitavonni @tdietterich @paul_rietschka @MuhammadAnas707 But you are right. RandomForest works better out of the box. You can get good baseline performance without tuning. With gradient boosting (XGBoost, LightGBM), you need more tuning, and it can be easier to overfit."
775,@rasbt,2023-01-17 20:40:00+00:00,https://twitter.com/rasbt/status/1615448877015916577,@vitavonni @tdietterich @paul_rietschka @MuhammadAnas707 Gradient boosting (via HistGradientBoostingClassifier) in scikit-learn is LightGBM. I have very good experiences with it.
776,@rasbt,2023-01-17 20:37:01+00:00,https://twitter.com/rasbt/status/1615448127799975946,"@vitavonni @tdietterich @MuhammadAnas707 Interestingly, looking at recent papers on tabular datasets (https://t.co/VAXJRBMyzj) SVMs are not even used for the baseline or comparison anymore. It's all tree-based models (or neural networks of course)."
777,@rasbt,2023-01-17 19:33:15+00:00,https://twitter.com/rasbt/status/1615432076760854528,"@sarojbono @LightningAI Hah, thanks! There will definitely be more videos coming out this year!"
778,@rasbt,2023-01-17 18:56:00+00:00,https://twitter.com/rasbt/status/1615422702667370520,"Yes, sitting down and spending a few hours on fixing labeling issues can sometimes save you days fiddling with hyperparameters!

(Days in terms of both human days and GPU days!) 

As an added bonus: you get to keep &amp; reuse the improved dataset for any future model."
779,@rasbt,2023-01-17 18:52:57+00:00,https://twitter.com/rasbt/status/1615421937060089886,"@svpino Nicely done! üôå

(Btw how many label errors did you find in MNIST? And do you have a cleaned version on GitHub? Last time I used cleanlab, I think it was 24ish or so but I don't recall, and I am not sure if I caught all of them.)"
780,@rasbt,2023-01-17 16:00:41+00:00,https://twitter.com/rasbt/status/1615378585887416321,"@ai_files No, it's the same thing. You are right you can generate the same results if you seed the model, but that doesn't work across different hardware."
781,@rasbt,2023-01-17 15:54:38+00:00,https://twitter.com/rasbt/status/1615377062155653122,"@ai_files The results can be different each time, so in that sense it's neither repeatable nor accurate. https://t.co/Lf96zUipFJ"
782,@rasbt,2023-01-17 15:42:56+00:00,https://twitter.com/rasbt/status/1615374116374315009,"@keyutian Thanks for adding these! Point 1 is a big one. I think contrastive learning was a great idea initially, but it seems like generative pretraining is more worthwhile.
Re ""2. CNNs gain more from pretraining than Transformers."", only for Detection &amp; Segmentation, right?"
783,@rasbt,2023-01-17 15:27:37+00:00,https://twitter.com/rasbt/status/1615370262341361664,"In contrast, to me, a calculator is something that's precise &amp; deterministic, the opposite of current-gen AI."
784,@rasbt,2023-01-17 15:26:57+00:00,https://twitter.com/rasbt/status/1615370093504106496,"@dl_insider To me, a calculator is something that's precise &amp; deterministic, the opposite of current-gen AI."
785,@rasbt,2023-01-17 15:20:16+00:00,https://twitter.com/rasbt/status/1615368413085409280,"@reidatcheson Interesting to hear from your experiences. In practice, does it work as well as advertised?"
786,@rasbt,2023-01-17 15:16:51+00:00,https://twitter.com/rasbt/status/1615367552334528512,"Large language models are more like a thesaurus, but for complete sentences and paragraphs."
787,@rasbt,2023-01-17 14:32:46+00:00,https://twitter.com/rasbt/status/1615356460439048196,"Anyways, here are some more resources and links if you want to check it out:

openpeview: https://t.co/0OqhaJ167j
arxiv: https://t.co/bljoFCRuNj
github: https://t.co/LVmPsZ5ID2

7/7"
788,@rasbt,2023-01-17 14:32:46+00:00,https://twitter.com/rasbt/status/1615356457700196353,"Speaking of ConvNeXt, remember the ConvNeXt paper I shared a few days ago? Yes, this follows a similar idea. This paper here appears to have been published around the same time (perhaps even earlier if we consider the OpenReview version)

6/7"
789,@rasbt,2023-01-17 14:32:45+00:00,https://twitter.com/rasbt/status/1615356453854023681,"SparK can be used with any convolutional network.

For example, here are some results on ResNet and ConvNeXt.

Pretraining those purely convolutional networks with 1.28 million unlabeled images can improve the predictive performance by up to 1.7% on ImageNet.

5/7 https://t.co/3Q8ZwkiVRb"
790,@rasbt,2023-01-17 14:32:43+00:00,https://twitter.com/rasbt/status/1615356445905809409,"In the ""Designing BERT for convolutional networks"" paper, the researchers propose the use of sparse convolutions to address this -- they propose SparK (Sparse masKed modeling with hierarchy)
4/7"
791,@rasbt,2023-01-17 14:32:42+00:00,https://twitter.com/rasbt/status/1615356441698922498,"What is the issue with regular convolutions on masked pixels?

1.  Computations on masked pixels are redundant (inefficient)

2.  They disturb the data distribution of pixel values (figure above)

3.  Patterns on masked maps will vanish (figure below)

3/7 https://t.co/pWF98DScS8"
792,@rasbt,2023-01-17 14:32:39+00:00,https://twitter.com/rasbt/status/1615356431267688448,"In recent years, we largely moved to generative (versus contrastive learning) for self-supervised pretraining. I.e., in vision transformers masked autoencoding has seen a lot of success!

However, convolutions cannot handle such irregular, randomly masked input images.

2/7 https://t.co/0DFMTjzERu"
793,@rasbt,2023-01-17 14:32:37+00:00,https://twitter.com/rasbt/status/1615356420823863298,"How can we leverage successful pretraining techniques from transformers to improve purely convolutional networks? The answer is *Sparse Convolutions*!

Let's see what happens when purely convolutional networks are pretrained with 1.28 million unlabeled images ...

1/7 https://t.co/rr9qd7TWWo"
794,@rasbt,2023-01-17 12:28:46+00:00,https://twitter.com/rasbt/status/1615325252275548160,"@EMostaque That will be a attractive to a decent chunk of companies. 

But at the same time, there will always be demand for customized, fine-tuned LLMs. 

Also, there will also always demand for running things on premise; not only related to costs but due to data policies."
795,@rasbt,2023-01-16 22:40:37+00:00,https://twitter.com/rasbt/status/1615116843131314182,@ANyulund @MuhammadAnas707 Lots of students were super excited about the coding parts. It was challenging for them but they seemed to truly love it at the same time üòä
796,@rasbt,2023-01-16 22:35:27+00:00,https://twitter.com/rasbt/status/1615115541479587840,"@ANyulund @MuhammadAnas707 Same, I usually prefer code &amp; examples to illustrate concepts. Most students in this class had little coding experience but a strong math background (senior undergrads and MSc students in the stats department) so I maybe used more math jargon than necessary in the slides"
797,@rasbt,2023-01-16 19:48:41+00:00,https://twitter.com/rasbt/status/1615073573277958145,@martinvars Yeah that‚Äôs certainly the lower end. I do prefer being a tad too cold over too hot though :P
798,@rasbt,2023-01-16 18:53:41+00:00,https://twitter.com/rasbt/status/1615059735610331186,@martinvars 62 F
799,@rasbt,2023-01-16 18:48:24+00:00,https://twitter.com/rasbt/status/1615058404371795995,"@KountayDwivedi Big congrats on the manuscript!! Very exciting! (And I am flattered that my resources were helpful, this is very motivating to hear!)"
800,@rasbt,2023-01-16 18:46:43+00:00,https://twitter.com/rasbt/status/1615057981078646785,"@cwolferesearch Speaking of expert knowledge, I recently stumbled upon you substack at https://t.co/8OLnAqbzXH which looks like a treasure trove üëå"
801,@rasbt,2023-01-16 18:30:15+00:00,https://twitter.com/rasbt/status/1615053835571171328,@JordiClive Weight decay also doesn‚Äôt touch the loss function in general.
802,@rasbt,2023-01-16 18:15:52+00:00,https://twitter.com/rasbt/status/1615050216478019594,"@andrewgwils @chris_j_beckham Yes, please!"
803,@rasbt,2023-01-16 18:14:51+00:00,https://twitter.com/rasbt/status/1615049961237843990,"@__mbel__ You were right, I was able to find a 1991 NeurIPS paper where L2 == weight decay: https://t.co/ErpHFjNSqG

But yeah, it is certainly not the same thing anymore today :P"
804,@rasbt,2023-01-16 17:59:04+00:00,https://twitter.com/rasbt/status/1615045987499757570,"@TheSeaMouse Sure, but then I have to read the original resources anyway to double check of the answer is *actually* correct :P"
805,@rasbt,2023-01-16 17:57:48+00:00,https://twitter.com/rasbt/status/1615045670938857473,"@__mbel__ Hm, what's the cut-off for ""old""? I think PyTorch implemented weight decay as a modification of the weight update from the very beginning.
I think also AlexNet defined weight decay as a modification of the weight update back in 2012."
806,@rasbt,2023-01-16 17:55:09+00:00,https://twitter.com/rasbt/status/1615045001624358913,"@TheSeaMouse Yes, exactly, and my point was, what's the point of using an LLM then versus just using these resources directly?"
807,@rasbt,2023-01-16 17:54:36+00:00,https://twitter.com/rasbt/status/1615044863380099094,@srchvrs The tricky part is: how do we know that it dreams up data (versus regurgitating what it has seen in flawed training data like with the *weight decay* query). Maybe those with missing references are more likely dreamed up?
808,@rasbt,2023-01-16 17:50:43+00:00,https://twitter.com/rasbt/status/1615043886132432915,"@TheSeaMouse Yeah, but the problem might be that we end up with too few sources then to train the models well."
809,@rasbt,2023-01-16 17:49:34+00:00,https://twitter.com/rasbt/status/1615043597350408222,"@bjh_ip They use a reward model for ranking the answers. I assume the highest reward label is only given for factual correctness. The problem is training this reward model well. As we can see on the internet, many people give wrong explanations of weight decay. It's challenging. https://t.co/dNnIjrfTsN"
810,@rasbt,2023-01-16 17:40:04+00:00,https://twitter.com/rasbt/status/1615041208551604232,"Training factually correct LLMs requires vast amounts of factually correct training data.

Curating &amp; creating factually correct training data for LLMs is very inefficient (vs using this data directly in the first place).

Wrote a shot post about it here:
https://t.co/C5pVCHlO3O"
811,@rasbt,2023-01-16 17:27:55+00:00,https://twitter.com/rasbt/status/1615038149427712000,"@MuhammadAnas707 Haha, wow, that's one messy slide I created there üòÖ"
812,@rasbt,2023-01-16 15:32:48+00:00,https://twitter.com/rasbt/status/1615009178933760000,"@john_lam @blueitserver Thanks! The only thing I should be to filling in is the ChatGPT-3 answer placeholder, correct? https://t.co/2PY9MCy4ij"
813,@rasbt,2023-01-16 15:04:45+00:00,https://twitter.com/rasbt/status/1615002118779191298,@jackclarkSF Wow congrats! This is well-deserved. Have been enjoying your weekly newsletter for years and can‚Äôt imagine my Monday mornings without them :)
814,@rasbt,2023-01-16 14:51:57+00:00,https://twitter.com/rasbt/status/1614998897637613571,@BerbaFan Haven‚Äôt read any book yet that specializes in/focuses on categorical data. But besides tackling it with encoding (like embeddings for text) RL is maybe what you are looking for
815,@rasbt,2023-01-16 14:38:31+00:00,https://twitter.com/rasbt/status/1614995517464870915,@john_lam @blueitserver This sounds super cool! Do you have a demo hosted somewhere?
816,@rasbt,2023-01-16 14:37:28+00:00,https://twitter.com/rasbt/status/1614995256285560832,@rezar It‚Äôs the other way around I‚Äôd say: RL is DeepMind‚Äôs specialty. They also just released/published DreamerV3 which is the best RL method to date according to a wide plethora of benchmarks.
817,@rasbt,2023-01-16 14:00:37+00:00,https://twitter.com/rasbt/status/1614985981056397312,"@marktenenholtz yup, your observation falls into my 95% confidence interval"
818,@rasbt,2023-01-16 13:49:17+00:00,https://twitter.com/rasbt/status/1614983129495703553,"@ntkris Depends on the perspective. Given that we have trustworthy information sources out there, it can also be seen as a step backward. E.g., I could find the correct answer by doing a web search, followed by clicking on a resource that I trust https://t.co/l0706R6vOG"
819,@rasbt,2023-01-16 13:39:58+00:00,https://twitter.com/rasbt/status/1614980785995481088,@pandaym It can probably answer those. The challenge is more about giving correct answers. https://t.co/UvkQjmuKhO
820,@rasbt,2023-01-16 13:37:40+00:00,https://twitter.com/rasbt/status/1614980206518992896,@ai_files Maybe we will see a revAIval of good-quality blogs üòä
821,@rasbt,2023-01-16 13:36:45+00:00,https://twitter.com/rasbt/status/1614979975043780608,"@blueitserver Yeah, I don't think it's meant to be a search engine. Search engines, as the name implies, are more meant for information look-up (look-up here as opposed to generative tasks)."
822,@rasbt,2023-01-16 13:28:14+00:00,https://twitter.com/rasbt/status/1614977833343897602,@blueitserver Sounds like you are getting lots of good use out of it. Fascinating that it seems like it has some memory even if you are resetting the session (when I understand correctly)
823,@rasbt,2023-01-16 13:26:50+00:00,https://twitter.com/rasbt/status/1614977480271761409,"Adding references DOES NOT automatically solve all the issues with misinformation. 
Eg consider the following sentence from Perplexity AI, which is obviously wrong. 

But it helps us understand why it's wrong (the model didn't dream it up, the training source contains the error.) https://t.co/ccQkGJCKM2"
824,@rasbt,2023-01-16 13:22:53+00:00,https://twitter.com/rasbt/status/1614976485986639874,"@blueitserver That being said, it's not impossible to develop systems that can do that. For example, consider https://t.co/apwqjhLuB7"
825,@rasbt,2023-01-16 13:22:00+00:00,https://twitter.com/rasbt/status/1614976261918543872,"@blueitserver Right, in its current implementation, it cannot do that because it doesn't store or process these explicitely. It's basically generating statistically likely sentences but can't pinpoint to single training instances because that's not how it works"
826,@rasbt,2023-01-16 13:14:57+00:00,https://twitter.com/rasbt/status/1614974490483515393,"@blueitserver nah, we already have lots of search engines"
827,@rasbt,2023-01-16 13:13:52+00:00,https://twitter.com/rasbt/status/1614974217258422272,"@sarojbono @ADutchEngineer @DataScienceHarp Ahh, sorry, I am not intentionally ignoring you. Social media can be a very busy place, and I sometimes miss things. I am also trying to limit my online time each day since I often get easily distracted, and there is so many things I want to work on üòÖ"
828,@rasbt,2023-01-16 13:08:01+00:00,https://twitter.com/rasbt/status/1614972742167662592,"@Morteza_AI14 I have no plans, yet. I am sure it will definitely not be this year. (But stay tuned for something else üôÑ)"
829,@rasbt,2023-01-16 13:06:16+00:00,https://twitter.com/rasbt/status/1614972303250538497,"""DeepMind is also considering releasing its own chatbot, called Sparrow, for a ‚Äúprivate beta‚Äù some time in 2023. (The delay is in order for DeepMind to work on reinforcement learning-based features that ChatGPT lacks, **like citing its sources** üëè ...)""

https://t.co/R0VZQNcVkk"
830,@rasbt,2023-01-15 20:05:35+00:00,https://twitter.com/rasbt/status/1614715440462450689,"@joshuastarmer @7NDAlvarez @guysnovelutumba @__mharrison__ @StefanieMolin @BecomingDataSci @GaborBekes @GutmanDataHead @fchollet @aureliengeron @billfranksga I can only speak for those I read &amp; it depends on what you need ^^. 
If you work with SQL, I recommend @BecomingDataSci's book! Then, to get started with ML, @joshuastarmer book. My book if you want to learn how to implement ML &amp; DL models. And @__mharrison__ 's book for Pandas!"
831,@rasbt,2023-01-15 19:03:56+00:00,https://twitter.com/rasbt/status/1614699926419636225,@david_perell Including lunch or coffee with the author üòÜ
832,@rasbt,2023-01-15 19:01:13+00:00,https://twitter.com/rasbt/status/1614699240747319299,@MuhammadAnas707 Whoa you are moving fast! I should hurry to get my new book out in the next 2 months so you are not running out of material by day 60 üòÖ
833,@rasbt,2023-01-15 18:38:50+00:00,https://twitter.com/rasbt/status/1614693609688944640,"@KyleCranmer The current opt-out option they added is kind of like ‚Äúhey, someone forgot to lock their house when they went on vacation. I will just make myself comfortable there until they are back. It‚Äôs fine, they could just let me know if they don‚Äôt like it &amp; I‚Äôll leave.‚Äù"
834,@rasbt,2023-01-15 18:29:32+00:00,https://twitter.com/rasbt/status/1614691267769950209,"@KyleCranmer Whether it‚Äôs legal to scrape artwork for training, at this point it‚Äôs pretty clear that a lot of artists don‚Äôt want their work to be included in training AI models.
We should acknowledge &amp; respect that, and moving to an opt-in model would just be the decent thing to do here."
835,@rasbt,2023-01-15 17:10:34+00:00,https://twitter.com/rasbt/status/1614671397606854656,"@airwoz @tdietterich @MuhammadAnas707 Thanks!! I've seen that the other day when I was trying to respond to @tdietterich  -- I only skimmed it, but I don't think they show/find that XGBoost/LightGBM results in a max-margin classifier?"
836,@rasbt,2023-01-15 17:07:30+00:00,https://twitter.com/rasbt/status/1614670624080760835,"@alvinhxy You mean between the original XGBoost implementation and RAPIDS' implementation? Haven't benchmarked, but you can swap the code with the RAPIDS' code, no problem. https://t.co/2Vfu6djqA0"
837,@rasbt,2023-01-15 16:36:51+00:00,https://twitter.com/rasbt/status/1614662910617464838,"Woke up and felt like writing a blog post on how to train an XGBoost Classifier with cloud GPUs, avoiding infrastructure headaches.
Happy Sunday! üòä

üëâ https://t.co/gHZ8sixw9N"
838,@rasbt,2023-01-15 16:26:28+00:00,https://twitter.com/rasbt/status/1614660297821941762,"@sarojbono Not intentional: sometimes too busy, sometimes I am missing things (I get a lot of questions each day üòÖ). I think the ML modeling workflow explanations and broader concepts of the sklearn sections are useful, but no you don't miss anything if you skim over the math imho"
839,@rasbt,2023-01-15 14:40:10+00:00,https://twitter.com/rasbt/status/1614633544428437506,"@rationalcypher @Altimor I am not sure if they are legally entitled, but asking for permission would just be the nice thing to do here."
840,@rasbt,2023-01-15 14:31:08+00:00,https://twitter.com/rasbt/status/1614631272206467072,@Altimor But many artists don‚Äôt want their work to be used to train AI. Why can‚Äôt we respect that?
841,@rasbt,2023-01-15 14:18:33+00:00,https://twitter.com/rasbt/status/1614628107646033920,"@cwizprod1 @EMostaque @StabilityAI I work in AI &amp; find the tech fascinating. I also love contributing to open source &amp; share many things freely. 
At the same time, I think that artists have a right to complain &amp; be concerned, and @Kelly_McKernan might be doing the right thing here. It should be opt-in not opt-out."
842,@rasbt,2023-01-15 14:14:31+00:00,https://twitter.com/rasbt/status/1614627089990164480,"@guysnovelutumba @__mharrison__ @StefanieMolin @BecomingDataSci @GaborBekes @GutmanDataHead @fchollet @aureliengeron @joshuastarmer @billfranksga Nice selection üëå. Haha, my book looks pretty used, which looks like a good thing ‚Äî glad it was (hopefully) worthwhile reading!"
843,@rasbt,2023-01-15 14:12:30+00:00,https://twitter.com/rasbt/status/1614626584987828225,"@kidwhocodes @MuhammadAnas707 Yeah, the predictive performance measure would be the percentage of correctly classified digits, for example"
844,@rasbt,2023-01-14 20:15:39+00:00,https://twitter.com/rasbt/status/1614355586233008128,"@tdietterich @ljbuturovic @MuhammadAnas707 I think that only applies for hard-margin case though? It's nice for theoretical studies, but for real-world problems, where people use a soft-margin version for practical reasons, the robustness argument would not really hold empirically?"
845,@rasbt,2023-01-14 19:05:09+00:00,https://twitter.com/rasbt/status/1614337843253637121,"@MuhammadAnas707 When you get to the deep learning part of my book, I also recommend my DL fundamentals course as a companion :) https://t.co/B0rVXxbR6v"
846,@rasbt,2023-01-14 18:49:53+00:00,https://twitter.com/rasbt/status/1614334000063037447,"@ljbuturovic @MuhammadAnas707 @tdietterich Yeah. But if the answer to 2) is yes, wouldn't you say it's ""outdated""? :)"
847,@rasbt,2023-01-14 18:24:17+00:00,https://twitter.com/rasbt/status/1614327557939400705,"4) ""Big Transfer (BiT): General Visual Representation Learning""
https://t.co/lR8Cd8WXWX"
848,@rasbt,2023-01-14 18:24:16+00:00,https://twitter.com/rasbt/status/1614327555267653632,"References:
1) ""Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets""
https://t.co/WT4mhyk3ww

2) ""Well-tuned Simple Nets Excel on Tabular Datasets""
https://t.co/Nvzm8RkhRk

3) ""S4L: Self-Supervised Semi-Supervised Learning""
https://t.co/HoM3DFhJ0D"
849,@rasbt,2023-01-14 18:24:15+00:00,https://twitter.com/rasbt/status/1614327550058328064,"The story of weight decay in pictures:

weight decay ...
1)  improves data efficiency by &gt; 50%
2) is frequently found in the best hyperparam configs
3) is among the most important hparams to tune
4) is also tricky to tune https://t.co/PjWpk3pJxz"
850,@rasbt,2023-01-14 17:22:34+00:00,https://twitter.com/rasbt/status/1614312028385968130,@ljbuturovic @MuhammadAnas707 @tdietterich Thanks for sharing; devil's advocate here: did they compare it to other methods or just pick that arbitrarily because it just happens that's the only technique they knew?
851,@rasbt,2023-01-14 17:08:31+00:00,https://twitter.com/rasbt/status/1614308491702804482,"@SalamElBsat @TwitterSupport Ah yes, must have dropped some time this morning!"
852,@rasbt,2023-01-14 13:51:39+00:00,https://twitter.com/rasbt/status/1614258946713489414,"@rtombs @ylecun My thought as well, but PyTorch seems like a way bigger contributor to this. Just checking, JAX adoption seems tiny via https://t.co/DcWadBnYtB https://t.co/8TyM2bZuzH"
853,@rasbt,2023-01-14 13:48:28+00:00,https://twitter.com/rasbt/status/1614258146255446018,"@MortimerWerther Not sure if that was just for the sake of this ablation study and whether they combined it for other experiments. Re combining different techniques, ""Well-tuned Simple Nets Excel on Tabular Datasets"", https://t.co/Nvzm8RjK1M did that, finding that there is benefit in using both"
854,@rasbt,2023-01-14 13:44:34+00:00,https://twitter.com/rasbt/status/1614257165568548866,"**13 regularization techniques compared on tabular datasets in https://t.co/Nvzm8RjK1M

WD is a strong contributor

https://t.co/vZo1wsFyhd https://t.co/UzfGS9Xq37"
855,@rasbt,2023-01-14 13:42:45+00:00,https://twitter.com/rasbt/status/1614256707609464835,"@muhaksim Hah, you called it üòä! A little follow-up here: https://t.co/zIzqvDVlEq"
856,@rasbt,2023-01-14 13:41:23+00:00,https://twitter.com/rasbt/status/1614256363319791618,"@Mlbot4 ""on par with the performance of InstructGPT_001"" --&gt; Nice, but a long way from ChatGPT"
857,@rasbt,2023-01-14 13:39:07+00:00,https://twitter.com/rasbt/status/1614255796627603459,@DHolzmueller Even wrote a summary back then üòÖ. Looks like WD is one of the big contributors to the best hparam cocktail https://t.co/OEDTYukHy7
858,@rasbt,2023-01-14 13:34:16+00:00,https://twitter.com/rasbt/status/1614254574033838080,"@DHolzmueller Thanks! No that you mention it, I actually read that one 1-2 years ago, haha"
859,@rasbt,2023-01-14 13:28:10+00:00,https://twitter.com/rasbt/status/1614253039321235457,"* This is for a specific, synthetic dataset they investigated. I wonder if there are any recent, larger benchmarks for various overfitting remedies."
860,@rasbt,2023-01-14 13:28:10+00:00,https://twitter.com/rasbt/status/1614253036905594881,"Weight decay (with AdamW) can yield a significant improvement in data efficiency compared to other methods (like Dropout), reducing the required amount of samples by over 50%
(via ""Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets, https://t.co/WT4mhyk3ww) https://t.co/8iDwHSSoIf"
861,@rasbt,2023-01-14 12:25:36+00:00,https://twitter.com/rasbt/status/1614237292427726848,@tdietterich @MuhammadAnas707 Both are essentially voting classifiers so I would expect both of them to be somewhat robust to small changes. I haven‚Äôt done a literature search on the margin aspect though. My claims are based on empirical observation that gradient boosting results in better generalization perf
862,@rasbt,2023-01-14 12:12:46+00:00,https://twitter.com/rasbt/status/1614234063597977601,"@AlexisBRENON @PyTorch For sure! I will have a dedicated lecture about that in Unit 9, but a brief mention here could be good as well!"
863,@rasbt,2023-01-14 03:51:42+00:00,https://twitter.com/rasbt/status/1614107966994628609,@Saroj50552416 @MuhammadAnas707 A little explanation here:
864,@rasbt,2023-01-14 03:50:18+00:00,https://twitter.com/rasbt/status/1614107612039061504,"@tdietterich @MuhammadAnas707 When you look at the recent deep learning for tabular data literature, the baseline is typically a gradient boosting model because SVMs usually can‚Äôt compete. 

And for linear SVMs and quick baselines, I don‚Äôt think there is a meaningful advantage over logistic regression."
865,@rasbt,2023-01-14 03:48:34+00:00,https://twitter.com/rasbt/status/1614107176242479104,"@tdietterich @MuhammadAnas707 That was a bit tongue in cheek, but kernel SVMs don‚Äôt scale as well to larger datasets, and most people prefer gradient boosting for tabular data these days. If Kaggle competitions are any indicator, they are also better in terms of predictive performance."
866,@rasbt,2023-01-14 03:40:41+00:00,https://twitter.com/rasbt/status/1614105193683030017,"@burkov Ok swap PaLM with something pretrained like OPT. Given that pretrained LLMs exist, I don‚Äôt think the compute is necessarily the issue here. You still need to spend &gt;$100k to hire the contractors for writing the prompts and providing feedback."
867,@rasbt,2023-01-14 03:36:28+00:00,https://twitter.com/rasbt/status/1614104131882426371,@burkov Ok here you go then: https://t.co/4vQ83pcX2H
868,@rasbt,2023-01-14 03:29:46+00:00,https://twitter.com/rasbt/status/1614102447701610497,@enteatenea @joes_jarvis @PyTorch PyTorch Lightning adds a fit method (and lots of extra conveniences üòä). Will be talking about in Unit 5 of my Deep Learning Fundamentals course!
869,@rasbt,2023-01-13 22:47:05+00:00,https://twitter.com/rasbt/status/1614031306328883204,"@MathiasFuchs10 @MuhammadAnas707 ok ok this was a bit tongue in cheek üòÖ. But regarding scaling, gradient boosting scales linearly with the number of examples vs quadratically"
870,@rasbt,2023-01-13 22:31:42+00:00,https://twitter.com/rasbt/status/1614027434688487426,@MathiasFuchs10 @MuhammadAnas707 Kernel SVMs also don't scale really well to larger datasets. (We didn't talk about clustering etc. above.)
871,@rasbt,2023-01-13 21:49:52+00:00,https://twitter.com/rasbt/status/1614016909326053377,"@MathiasFuchs10 @MuhammadAnas707 The rationale behind this: many people prefer using gradient boosting (XGBoost, LightGBM, etc.) for their tabular datasets. And for linearly separable datasets or a quick baseline, logistic regression usually suffices."
872,@rasbt,2023-01-13 21:01:51+00:00,https://twitter.com/rasbt/status/1614004825527664642,"@joes_jarvis @PyTorch 2/2
Consider the custom CoralLayer I wrote for a research paper here: https://t.co/mlAlllzDrS

Now compare that to the Keras port: https://t.co/y2Q0tPyXji"
873,@rasbt,2023-01-13 21:00:46+00:00,https://twitter.com/rasbt/status/1614004552855965698,"@joes_jarvis @PyTorch I think PyTorch is the best of both worlds: Pythonic &amp; intuitive, and flexible enough to be easily customizable. So, it doesn't get in the way when I do research and want to try new things.
1/2"
874,@rasbt,2023-01-13 20:41:45+00:00,https://twitter.com/rasbt/status/1613999767654223903,"@themintsv Well they used unsupervised pretraining (GPT-3) as a base model. But yeah, the novelty is the human-in-the-loop approach for which they hired contractors."
875,@rasbt,2023-01-13 20:25:55+00:00,https://twitter.com/rasbt/status/1613995779496235009,"@TwitterSupport Nice, when is it coming to the web client? üòä"
876,@rasbt,2023-01-13 20:20:17+00:00,https://twitter.com/rasbt/status/1613994365025935361,"@Saroj50552416 That's pretty good! Personally, I stopped at 98.5% üòÖ"
877,@rasbt,2023-01-13 20:02:13+00:00,https://twitter.com/rasbt/status/1613989815187537920,"@muhaksim Yeah, maybe, but we got a chicken-egg problem here üòä"
878,@rasbt,2023-01-13 19:46:13+00:00,https://twitter.com/rasbt/status/1613985789527953409,"@asadaftabiqbal I don't know &amp; we will see. 

If you want to publish a paper but your model suffers from poor performance and massive overfitting, people are usually not that excited about labeling https://t.co/Y2gi19s9Hd"
879,@rasbt,2023-01-13 19:35:10+00:00,https://twitter.com/rasbt/status/1613983011325755392,@MultimodalAI @3scorciav Like I mentioned in the quote tweet üòä: https://t.co/s5WoxuKeLk
880,@rasbt,2023-01-13 19:25:29+00:00,https://twitter.com/rasbt/status/1613980573285900288,@muhaksim I don‚Äôt think so because the goal here is to mimic humans. It‚Äôs not just labeling but writing correct and human-like responses.
881,@rasbt,2023-01-13 19:22:30+00:00,https://twitter.com/rasbt/status/1613979821436178432,@dtweiseth @3scorciav Methods if it helped coming up with some interesting insights or analyses. If it just helped with some mundane writing then the Acknowledgement section (at most).
882,@rasbt,2023-01-13 19:20:42+00:00,https://twitter.com/rasbt/status/1613979366932811799,"@chriswolfvision If you consider all the whitepaper-like  publications and non-open source LLM models, that‚Äôs unfortunately not unrealistic :("
883,@rasbt,2023-01-13 19:17:40+00:00,https://twitter.com/rasbt/status/1613978605356257287,"@themintsv InstructGPT used 40 contractors to write the desired answers to the various prompts. We don‚Äôt know how many contractors they used for ChatGPT, but  InstructGPT pales against ChatGPT."
884,@rasbt,2023-01-13 19:14:36+00:00,https://twitter.com/rasbt/status/1613977835546316800,@chrisalbon Which perceptron? Perceptron is a broad term üòÜ
885,@rasbt,2023-01-13 19:13:09+00:00,https://twitter.com/rasbt/status/1613977469777809435,@thegautamkamath Wow that‚Äôs awesome! Quite healthy numbers there! Really glad to see this!
886,@rasbt,2023-01-13 19:02:35+00:00,https://twitter.com/rasbt/status/1613974811172012049,@chrisalbon Neural nets is a broad term üôÉ
887,@rasbt,2023-01-13 18:59:15+00:00,https://twitter.com/rasbt/status/1613973971304579092,"@dctanner Yeah, I am happy to be wrong here üòä"
888,@rasbt,2023-01-13 18:58:15+00:00,https://twitter.com/rasbt/status/1613973718862004228,"@engineerabdulll @MuhammadAnas707 Good q! In my experience it makes no difference (sometimes one results in slightly different trees, but there is no better or worse imho). Gini impurity has the same concave shape as information entropy, both are better than classification error: https://t.co/4NV1eDJIR8"
889,@rasbt,2023-01-13 18:55:29+00:00,https://twitter.com/rasbt/status/1613973023207600128,"@themintsv But most of it is really poor quality, and you still need to filter for prompts. If you want to just train on the web data in general, that's already GPT-3, and you can see how that compares to the curated ChatGPT."
890,@rasbt,2023-01-13 17:51:13+00:00,https://twitter.com/rasbt/status/1613956850302742529,"@MuhammadAnas707 No worries, SVMs are quite outdated anyways. Tree-based models are way more relevant if you use non-neural network models üòä"
891,@rasbt,2023-01-13 17:25:32+00:00,https://twitter.com/rasbt/status/1613950387089805330,@Oladip_Olawoye @Saroj50552416 Logistic regression using PyTorch
892,@rasbt,2023-01-13 17:22:27+00:00,https://twitter.com/rasbt/status/1613949610677997577,"@dl_insider We will see. I don't think many people are excited about labeling data, even if it's an open source project :P"
893,@rasbt,2023-01-13 16:36:25+00:00,https://twitter.com/rasbt/status/1613938026899546112,@daryl_imagineai @TheSeaMouse @3scorciav is that the official coca cola recipe? üôÉ
894,@rasbt,2023-01-13 16:30:48+00:00,https://twitter.com/rasbt/status/1613936610504069121,"@Sim_Startup_ LLM agents are already scoring, but who trains the scoring LLM agents üòÖ"
895,@rasbt,2023-01-13 16:21:17+00:00,https://twitter.com/rasbt/status/1613934217326465024,@Saroj50552416 The exercise can be found here if others want to give it a try üòä: https://t.co/zdjQCe2uYJ
896,@rasbt,2023-01-13 16:19:22+00:00,https://twitter.com/rasbt/status/1613933736810221571,"@Saroj50552416 Nice, have fun! PS: I love the bird!!"
897,@rasbt,2023-01-13 16:09:56+00:00,https://twitter.com/rasbt/status/1613931360216817668,"@XRMultiverse @julien_c @huggingface You can say the same thing about GPT-3, which doesn't even require labeling. GPT-3 was released 2 1/2 years ago and made a big splash. Yet, there are only 2? open source versions of it, yet. BLOOM and OPT. (And, besides, they don't even match GPT-3's performance yet)"
898,@rasbt,2023-01-13 15:37:22+00:00,https://twitter.com/rasbt/status/1613923166740533251,"In an academic collaboration, it was hard to convince my collaborators to even label 50 additional short texts for training a classifier. 
They preferred spending days (if not weeks) fine-tuning hyperparameters."
899,@rasbt,2023-01-13 15:29:12+00:00,https://twitter.com/rasbt/status/1613921108553601031,"Agreed, there will be many open source implementations of ChatGPT. But there won't be many high-quality models.
I think we underestimate how much people hate labeling (or worse: writing) training data by hand. https://t.co/A4wftoVWOe"
900,@rasbt,2023-01-13 14:41:36+00:00,https://twitter.com/rasbt/status/1613909131290906624,"@hadiazouni @julien_c @huggingface Yes, totally agree. I think OPT is a bit more up to par (but it's only available upon request, and I don't know how freely these requests are granted)"
901,@rasbt,2023-01-13 14:00:34+00:00,https://twitter.com/rasbt/status/1613898804511801346,@enteatenea @3scorciav It definitely looks like a marketing stunt
902,@rasbt,2023-01-13 13:59:37+00:00,https://twitter.com/rasbt/status/1613898563733397505,"@naughtynates @julien_c @huggingface One thing I wonder about is whether it's possible to easily update the models. I.e., once they are finetuned on the human prompts &amp; after the RL part, can you proceed with updating it on unsupervised data from the web or do you have to follow-up with another finetuning round"
903,@rasbt,2023-01-13 13:47:29+00:00,https://twitter.com/rasbt/status/1613895511932542977,"@julien_c @huggingface In the InstructGPT paper, they mentioned 40 contractors. 
So, I assume it's been a much larger number for a much longer time for ChatGPT. 
So that estimate doesn't sound too bad."
904,@rasbt,2023-01-13 13:35:14+00:00,https://twitter.com/rasbt/status/1613892427470741505,"@julien_c @huggingface Yeah, you could adopt open-source variants of GPT-3 like BLOOM or OPT for that.

But the fact that you have to spend a lot of time / hire contractors to generate the data for supervised finetuning ,and the human-in-the-loop reward/ranking RL part, might be prohibitive."
905,@rasbt,2023-01-13 12:55:19+00:00,https://twitter.com/rasbt/status/1613882385271238657,"Interested in learning or transitioning to @PyTorch over the weekend?

The core API can be explained in two steps:
(1) defining the model, and
(2) setting up the training loop.

I have a concise 3-minute video explaining the PyTorch API here: https://t.co/8fCGenhvAF https://t.co/lbRHknl2qI"
906,@rasbt,2023-01-13 12:52:51+00:00,https://twitter.com/rasbt/status/1613881763679424513,"@miiipus @PyTorch Yes, we collaborate with a lot of companies that use PyTorch."
907,@rasbt,2023-01-13 12:36:32+00:00,https://twitter.com/rasbt/status/1613877657384673284,"@TheSeaMouse @3scorciav Haha, ok that's fair!"
908,@rasbt,2023-01-13 12:34:17+00:00,https://twitter.com/rasbt/status/1613877089022922753,"@nirsd @3scorciav Hah, yes, that's an unintended side-effect"
909,@rasbt,2023-01-12 22:50:23+00:00,https://twitter.com/rasbt/status/1613669750634336257,"@Muhtasham9 @3scorciav Wow, I am surprised this is allowed by NIH"
910,@rasbt,2023-01-12 21:59:25+00:00,https://twitter.com/rasbt/status/1613656923777400832,@tadeodonegana *p*AIgiarism when OpenAI adds the paid pro tier üôÉ
911,@rasbt,2023-01-12 21:41:19+00:00,https://twitter.com/rasbt/status/1613652370113855488,"Here we go. I guess that ship has sailed. Researchers started adding ChatGPT as co-author on their papers ü´£

PS: Dear researchers, you forgot the version number!

https://t.co/OpA2HQ4CtU

(thx @3scorciav for sharing this!) https://t.co/8xyKwuuraW"
912,@rasbt,2023-01-12 21:01:53+00:00,https://twitter.com/rasbt/status/1613642446411268101,@anothercohen git checkout -b exciting-feature
913,@rasbt,2023-01-12 19:36:40+00:00,https://twitter.com/rasbt/status/1613621000163233798,@anothercohen 9:00 pm for me
914,@rasbt,2023-01-12 18:59:02+00:00,https://twitter.com/rasbt/status/1613611527512129544,"Whoa, maybe it's worthwhile investing more time in learning how to use visual debuggers.
https://t.co/Mvnj7p9QLx"
915,@rasbt,2023-01-12 17:53:05+00:00,https://twitter.com/rasbt/status/1613594932828311552,@LearnOpenCV Is there a paper for this?
916,@rasbt,2023-01-12 16:30:55+00:00,https://twitter.com/rasbt/status/1613574252816470020,"@roydanroy @jefrankle @gkdziugaite @mcarbin Found the paper here https://t.co/UgwTTjoozq and wrote this more as a response acknowledging the pointer, but definitely should have tagged the main authors of the paper as well üòÖ! (But be assured, I will be incl the full citation/reference in a longer write-up I am preparing!)"
917,@rasbt,2023-01-12 14:09:08+00:00,https://twitter.com/rasbt/status/1613538574737244168,"For datasets with noisy labels the training loss of a pruned model worsens on noisy examples. This suggests that the pruned model does not fit the noisy examples (similar to models with smaller widths). This, I think, is consistent with the original intuition.
4/4 https://t.co/iDpWLPRePS"
918,@rasbt,2023-01-12 14:09:06+00:00,https://twitter.com/rasbt/status/1613538564159180807,"For standard datasets, the authors found that it's due to the improved training regimes when models are pruned. For instance, the replaying of the learning rate schedule in modern pruning techniques is ~ like increasing the number of epochs and using a cyclical schedule.
3/4 https://t.co/SnlfNZsdYI"
919,@rasbt,2023-01-12 14:09:04+00:00,https://twitter.com/rasbt/status/1613538555699265537,"Theory suggests that pruning could improve generalization due to smaller model sizes (contradicting other observations where larger model sizes can also improve generalization -- i.e. see double decent). So, how can the improvements in generalization performance be explained?
2/4"
920,@rasbt,2023-01-12 14:09:03+00:00,https://twitter.com/rasbt/status/1613538551488217091,"Yesterday, I shared a list of approaches that improve generalization.

Thx to @jefrankle, I discovered his work (https://t.co/mvf2nE7I5T) studying the observation that pruning improves model generalization, decomposing this phenomenon into 2 factors.
The magic of Twitter!

1/4 https://t.co/0RnsDzF4Jx"
921,@rasbt,2023-01-12 13:22:08+00:00,https://twitter.com/rasbt/status/1613526745050660864,"@LakhanP32 For me, it was/is super useful to build things from scratch sometime. It‚Äôs useful as an exercise and as a test to see whether you understood a concept well. But the emphasis is on ‚Äúsometimes‚Äù. If you need to get things done, then use TF/PyTorch :)"
922,@rasbt,2023-01-12 13:16:02+00:00,https://twitter.com/rasbt/status/1613525210069614592,"@nbashaw TextEdit (set to plaintext mode) on macOS. Best no-frills distraction-free writing tool. 

You can have it as a small window in the corner or as large window in the center depending on the task. Easy to zoom in and out via cmd +/-"
923,@rasbt,2023-01-12 13:11:22+00:00,https://twitter.com/rasbt/status/1613524035517972480,@bernhardsson I was reading this with self-driving cars in mind üòÖ
924,@rasbt,2023-01-12 13:01:36+00:00,https://twitter.com/rasbt/status/1613521576019873792,"@HoachuckJulien Depends. Using duplicate training examples is equivalent to a weighted loss function. So if these duplicates correspond to hard-to-classify instances, it could potentially help."
925,@rasbt,2023-01-12 12:59:45+00:00,https://twitter.com/rasbt/status/1613521110129152002,"@3scorciav Hah, haven‚Äôt seen this yet. Nice PR stunt üòÖ"
926,@rasbt,2023-01-11 21:40:03+00:00,https://twitter.com/rasbt/status/1613289662826663944,@karpathy neural engine architecture search
927,@rasbt,2023-01-11 20:10:05+00:00,https://twitter.com/rasbt/status/1613267019985477632,"@xinformatics I think most people use weight decay instead of L2 regularization (similar but different), and yeah I‚Äôve seen it in architectures together with Dropout. It does require lots of fiddling/tuning to find a good compromise in my experience. But lots of fiddling is important nowadays"
928,@rasbt,2023-01-11 19:07:56+00:00,https://twitter.com/rasbt/status/1613251379799396354,"@jefrankle Whoa, fresh from the press! Thanks for sharing this paper"
929,@rasbt,2023-01-11 19:04:36+00:00,https://twitter.com/rasbt/status/1613250542729306135,"@jefrankle Yeah and l, it‚Äôs certainly not an ‚Äúeffective‚Äù way for overfitting reduction"
930,@rasbt,2023-01-11 19:01:13+00:00,https://twitter.com/rasbt/status/1613249689427791873,"@jefrankle Maybe I am misremembering and you certainly would know this better, but didn‚Äôt the original lottery hypothesis paper have something about the smaller networks showing (sometimes) a better generalization performance?"
931,@rasbt,2023-01-11 18:05:24+00:00,https://twitter.com/rasbt/status/1613235642770812929,"@kzmolikova Nice find, have to check this out!!"
932,@rasbt,2023-01-11 17:30:05+00:00,https://twitter.com/rasbt/status/1613226755208187924,@aniketmaurya @pythiccoder I don't think that's supported on Remarkable and the Sony e-reader. I think there could be other e-ink readers that support it though.
933,@rasbt,2023-01-11 17:28:41+00:00,https://twitter.com/rasbt/status/1613226404711174172,@aniketmaurya @pythiccoder On a different e-ink device?
934,@rasbt,2023-01-11 17:16:44+00:00,https://twitter.com/rasbt/status/1613223395453198336,"An additional method might be using label smoothing, or focal losses. But I never had good experiences with that."
935,@rasbt,2023-01-11 16:43:34+00:00,https://twitter.com/rasbt/status/1613215051258933248,"@mkamp True, but you can easily modify that by adding auxiliary training objectives. (We have done some work on that  here: https://t.co/UfrpGciWL7) https://t.co/43PZvhGQUo"
936,@rasbt,2023-01-11 16:20:40+00:00,https://twitter.com/rasbt/status/1613209287630721026,"@mkamp Yeah, autoencoders are interestingly closely related to SVD, PCA. If you remove the nonlinear activation functions, an Autoencoder is essentially the same thing (except you don't have the hard constrained on orthogonality)"
937,@rasbt,2023-01-11 16:18:39+00:00,https://twitter.com/rasbt/status/1613208778169614336,"@allenscope Both grid search and Bayesian optimization are just hyperparameter tuning strategies in this context though. Themselves, they can be used to evaluate different configurations -- they help you compare models (that you change) but they don't necessarily change the model itself."
938,@rasbt,2023-01-11 16:05:11+00:00,https://twitter.com/rasbt/status/1613205388580511748,"@pythiccoder @aniketmaurya Agree on e-ink. I use a Remarkable for ~12 months (previously Sony e-reader); Kindles are great for fiction books from Amazon, but other e-readers are more flexible when it comes to textbooks, PDFs, etc."
939,@rasbt,2023-01-11 15:56:27+00:00,https://twitter.com/rasbt/status/1613203191750971393,"@allenscope I was thinking specifically of neural networks, where the hyperparameter-related reduction of overfitting would mostly fall under the two first categories above.

But yeah, say we are talking about the depth of the tree as a hparam ... but then, isn't that ~ ""smaller models""?"
940,@rasbt,2023-01-11 15:53:44+00:00,https://twitter.com/rasbt/status/1613202509488701450,"@jeanlapintade Wow, super cool. These are pretty fancy actually!"
941,@rasbt,2023-01-11 15:53:17+00:00,https://twitter.com/rasbt/status/1613202396871593987,"@CD_loverz TabDDPM is a method for generating synthetic tabular data using a diffusion model. Kotelnikov, Baranchuk, Rubachev, Babenko (2022). TabDDPM: Modelling Tabular Data with Diffusion Models. https://t.co/ghg553JgN0
3/3"
942,@rasbt,2023-01-11 15:52:40+00:00,https://twitter.com/rasbt/status/1613202238545035266,"@CD_loverz The GReaT method is a way to generate synthetic tabular data using an auto-regressive generative large language model. Reference: Borisov, Se√üler, Leemann, Pawelczyk, Kasneci, (2022). Language Models Are Realistic Tabular Data Generators. https://t.co/SQq1G24KDg
2/3"
943,@rasbt,2023-01-11 15:52:16+00:00,https://twitter.com/rasbt/status/1613202138401853440,"@CD_loverz Sure. When working with image data, think of GANs or diffusion models. And there are several techniques for tabular data as well, e.g., the most classic one might be SMOTE. Or let me share 2 more modern ones for tabular data below:
1/3"
944,@rasbt,2023-01-11 15:50:10+00:00,https://twitter.com/rasbt/status/1613201609353216000,"@paniterka_ch @JPerezAlcantara Thanks for sharing, would love to check that out. It's on my playlist!"
945,@rasbt,2023-01-11 15:49:02+00:00,https://twitter.com/rasbt/status/1613201327076831232,"@Saroj50552416 Happy to discuss! Btw you mean that the ""New discussion"" button on GitHub does not work for you? https://t.co/CrdBybGTNL

Maybe you are accidentally logged out of GitHub? https://t.co/tZc4V4U74w"
946,@rasbt,2023-01-11 13:56:21+00:00,https://twitter.com/rasbt/status/1613172968015941638,"@IntuitMachine Yes, but I would say it's more of an analysis or phenomenon. Not necessarily a technique to mitigate overfitting in general"
947,@rasbt,2023-01-11 13:55:22+00:00,https://twitter.com/rasbt/status/1613172720774127616,@PrasoonPratham It's more of an evaluation to *detect* overfitting imho
948,@rasbt,2023-01-11 13:51:54+00:00,https://twitter.com/rasbt/status/1613171846958182400,"And as a companion: Effective ways to reduce overfitting *via model changes*:

1. Regularization: L2 penalty, weight decay, dropout, early stopping
2. Smaller models: lottery ticket hypothesis, knowledge distillation
3. Ensemble models

https://t.co/1he8u8b0Nj"
949,@rasbt,2023-01-11 13:45:38+00:00,https://twitter.com/rasbt/status/1613170269186854913,"Effective ways to reduce overfitting through additional &amp; altered data:

1.  Get more labeled data
2.  Data augmentation &amp; synthetic data
3. Labeled data from related domain for pretraining (via transfer learning)
4.  Unlabeled data for pretraining (via self-supervised learning)"
950,@rasbt,2023-01-11 12:42:00+00:00,https://twitter.com/rasbt/status/1613154255296397313,"@capetorch Haha, I see. Yeah there is a link in the tweet above. Not one but multiple notebooks üôÉ"
951,@rasbt,2023-01-11 12:40:57+00:00,https://twitter.com/rasbt/status/1613153994758569985,"@mkamp Useful to understand for classical ML (e.g., SVD, PCA, optimization); less so for deep learning unless you want to study training dynamics, which is more of an advanced or research topic"
952,@rasbt,2023-01-11 12:25:52+00:00,https://twitter.com/rasbt/status/1613150198494101505,"@rzeta0 @AlphaSignalAI If you have more data, yes. The chinchilla paper analyzed the scaling laws that if you increase the model size you need to offset that with more data by equal amounts"
953,@rasbt,2023-01-11 12:23:32+00:00,https://twitter.com/rasbt/status/1613149609580167171,@shravankumar147 @svpino @DeepLearningAI_ @TeachTheMachine @PyImageSearch I actually never really have more than 5 tabs open üòÖ
954,@rasbt,2023-01-11 12:21:49+00:00,https://twitter.com/rasbt/status/1613149178602954753,"@capetorch As opposed to scripts? Actually, plots are actually one place where notebooks really shine."
955,@rasbt,2023-01-11 12:20:07+00:00,https://twitter.com/rasbt/status/1613148750675070981,"@JPerezAlcantara Yeah, I think there are also too many API ways to use matplotlib, which makes it look really complicated sometimes"
956,@rasbt,2023-01-11 12:18:39+00:00,https://twitter.com/rasbt/status/1613148379122438144,"@AI_Sensei_ Totally agree. A lot of concepts make a lot more sense if they are accompanied by a fully working, self-contained code example. Eg this may look daunting without the text description in the book, but showing backprop in code for an MLP is very useful https://t.co/4r1K5Vsxyh"
957,@rasbt,2023-01-11 01:13:50+00:00,https://twitter.com/rasbt/status/1612981074887319552,@bilayerguy Nice! It‚Äôs a fun exercise for conceptualizing ML models. I wish humans could visualize higher dimensional spaces üòÖ
958,@rasbt,2023-01-10 23:15:10+00:00,https://twitter.com/rasbt/status/1612951212491522049,@FeedCompu That's a good question and would probably be enough material for a new book üòÖ
959,@rasbt,2023-01-10 23:11:57+00:00,https://twitter.com/rasbt/status/1612950399786553346,@Saroj50552416 The PyTorch codes are all on GitHub. There should be links to it on each page.
960,@rasbt,2023-01-10 22:49:02+00:00,https://twitter.com/rasbt/status/1612944632580657154,"The secret to using matplotlib is building a personal gallery of your most frequently used plots üòÜ

https://t.co/FjtEcsIDRy"
961,@rasbt,2023-01-10 22:45:17+00:00,https://twitter.com/rasbt/status/1612943692276310016,"@marktenenholtz @chris_j_beckham Haha, yes, for sure! The matplotlib gallery is probably among the top 5 websites I visit üòÖ"
962,@rasbt,2023-01-10 21:34:40+00:00,https://twitter.com/rasbt/status/1612925920691585025,"@jmschreiber91 @AlphaSignalAI Oh, so it‚Äôs a hyphen, not a minus sign. That clarifies things. Thanks!"
963,@rasbt,2023-01-10 21:33:28+00:00,https://twitter.com/rasbt/status/1612925616944459777,"@AlphaSignalAI Yeah ChatGPT has two components to it using GPT-3 as the base-model: finetuning in a supervised fashion and RL with humans in the loop. 

I am curious whether GPT-4 being 10x bigger is just a rumor, or whether the innovation was scaling the RL part in ChatGPT (from InstructGPT)"
964,@rasbt,2023-01-10 21:16:13+00:00,https://twitter.com/rasbt/status/1612921273998364692,"@AlphaSignalAI At this point, I would be interested to know whether ChatGPT = GPT-4, and if not, what GPT-4 brings to the table"
965,@rasbt,2023-01-10 21:14:24+00:00,https://twitter.com/rasbt/status/1612920818492919808,@Saroj50552416 Thanks! The next one is hopefully ready by next week! (Maybe we can even squeeze in Unit 5 before Feb.)
966,@rasbt,2023-01-10 20:45:48+00:00,https://twitter.com/rasbt/status/1612913620102578176,"On that note, I remember a good (although a bit harsh üòÖ) discussion of the design of the triplet loss by @alfcnz here: https://t.co/2QsOOJR2ep"
967,@rasbt,2023-01-10 20:45:47+00:00,https://twitter.com/rasbt/status/1612913617447550976,"Sure, we may mostly rely on automatic differentiation/autograd in practice. But understanding the chain rule lets us understand backprop, which helps us understand

1.  The need for residual connections
2.  Feature normalization
3.  The design of certain loss functions
etc."
968,@rasbt,2023-01-10 20:45:46+00:00,https://twitter.com/rasbt/status/1612913612603150336,"One Q during today's discussion was how much math we actually need in order to use deep learning.

I am a big fan of covering the basics: e.g., applying the chain rule (with computation graphs ‚ù§Ô∏è) &amp; always try to reserve some time for it in my lectures.

https://t.co/bd9o1wHGpd https://t.co/45WC7loBAR"
969,@rasbt,2023-01-10 18:18:46+00:00,https://twitter.com/rasbt/status/1612876617705193473,@paddy_the_faddy @LakhanP32 @abacusai @bindureddy I think there was a recording and they will upload it to YT some time in the future
970,@rasbt,2023-01-10 18:09:26+00:00,https://twitter.com/rasbt/status/1612874269079240704,@LakhanP32 @abacusai @bindureddy Thanks for the kind words &amp; glad to hear it was informative :)
971,@rasbt,2023-01-10 15:27:24+00:00,https://twitter.com/rasbt/status/1612833494534885377,"@cwolferesearch @srchvrs @MetaAI I think if you would just do the SFT part, it would be too strict in terms of mimicking authors contents. If you just do the RL part without fine-tuning, you may end up with ""all bad"" answers."
972,@rasbt,2023-01-10 15:25:24+00:00,https://twitter.com/rasbt/status/1612832990547136514,"@cwolferesearch @srchvrs @MetaAI I think they are quite different. SFT forces the model to mimick answers that the labelers provided. I think this is an important baseline. Then, once the model can do that somewhat well, you let the model generate answers (some good, some bad), and you let humans rank them."
973,@rasbt,2023-01-10 14:42:39+00:00,https://twitter.com/rasbt/status/1612822232950083584,"@sharongoldman @AlphaSignalAI Oops, you are right!"
974,@rasbt,2023-01-10 14:38:35+00:00,https://twitter.com/rasbt/status/1612821208331964416,"@AlphaSignalAI Just curious, is it known what their current stake is given that they had that ~10 billion investment in 2019 (and maybe others before and/or after)?"
975,@rasbt,2023-01-10 14:23:43+00:00,https://twitter.com/rasbt/status/1612817465058156544,"My rubric may still stand the test of time re ChatGPT-generated content:
It's important to compare your work to related work, give proper attributions, describe contributions, and give original thoughts. If LLMs help automate the tedious parts, that's ok!

https://t.co/MjmvONYVv0"
976,@rasbt,2023-01-10 14:23:42+00:00,https://twitter.com/rasbt/status/1612817463061667840,"Sure, there are valid concerns about ChatGPT and cheating. 
Personally, I prefer project-oriented assignments (https://t.co/HLJzYQNS7b), and if students want to use ChatGPT to improve their writing, that's ok!

The more readable the text, the better for me."
977,@rasbt,2023-01-10 12:29:13+00:00,https://twitter.com/rasbt/status/1612788650789445635,@cwolferesearch @srchvrs @MetaAI What I am thinking is that the supervised finetuning approach may already get you most of the way there
978,@rasbt,2023-01-10 12:28:24+00:00,https://twitter.com/rasbt/status/1612788447038828544,"@cwolferesearch @srchvrs @MetaAI Yes. Am on mobile and don‚Äôt have the InstructGPT paper at hand, but when I recall correctly there weren‚Äôt ablation studies on how the ‚Äúsupervised fine-tuning only‚Äù compared to the vanilla GPT-3 model and to the full InstructGPT model (which has both supervised finetuning and RL)."
979,@rasbt,2023-01-10 03:11:34+00:00,https://twitter.com/rasbt/status/1612648313072848896,"@shawntsullivan @TivadarDanka Yup, and small molecules and protein structures :) https://t.co/ddZuqSpg0b"
980,@rasbt,2023-01-10 02:45:35+00:00,https://twitter.com/rasbt/status/1612641775952199681,"@wpenman @CalcCon @beenwrekt For example, modeling protein structures like @CalcCon mentioned above.

(Also language translation; only few can do that for multiple languages)"
981,@rasbt,2023-01-09 22:33:52+00:00,https://twitter.com/rasbt/status/1612578430964342784,"@CalcCon @beenwrekt This is probably the right answer. The other examples are about automating things that we can already do well, which is itself impressive on the surface, but not as fascinating maybe."
982,@rasbt,2023-01-09 17:42:00+00:00,https://twitter.com/rasbt/status/1612504976835907585,@ChristophMolnar This probably results in Very Interesting Manuscripts
983,@rasbt,2023-01-09 15:39:21+00:00,https://twitter.com/rasbt/status/1612474111627763719,"@akshay_pachaar @bindureddy Nice, looking forward!"
984,@rasbt,2023-01-09 15:21:11+00:00,https://twitter.com/rasbt/status/1612469541996531714,"@beenwrekt Everyone can use them, and they don't endanger our lives ... yet"
985,@rasbt,2023-01-09 15:14:09+00:00,https://twitter.com/rasbt/status/1612467772197376000,"Edward Tian @edward_the6 developed GPTZero (https://t.co/cos2sugNmw) to help detect AI-generated content.

Was just giving it a try, and it seems to work on the example I tried. 

PS: Kudos for providing perplexity scores, which a human has to interpret, rather than binary labels https://t.co/KU3l1UQcCd"
986,@rasbt,2023-01-09 15:06:22+00:00,https://twitter.com/rasbt/status/1612465813847707652,"@cwolferesearch @MetaAI Super interesting! Thanks for sharing! 
""Fine-tuned on ~2000 instruction-based tasks"" would refer to the step before training the reward model in InstructGPT? Did they follow-up with RL or focused on studying a model purely based on supervised fine-tuning?"
987,@rasbt,2023-01-09 14:36:58+00:00,https://twitter.com/rasbt/status/1612458413568524288,"@AISupremacyNews @edward_the6 Awesome, thanks for sharing. I just wanted to give it a try, but the app at https://t.co/cos2sugNmw seems to be either overwhelmed or down. I will revisit this in the next couple of days and share what I find."
988,@rasbt,2023-01-09 14:25:09+00:00,https://twitter.com/rasbt/status/1612455439119093764,"The virtual StateOfTheArt() 2023 conference will take place tomorrow. 
To kick it off, @bindureddy &amp; I will be chatting about generative &amp; large language models at 9:00 am PST. If you are interested there is a free registration form for the Zoom link here: https://t.co/PFkJN46bSS"
989,@rasbt,2023-01-09 13:21:02+00:00,https://twitter.com/rasbt/status/1612439303984148480,"@nathanbenaich Google bought Deepmind in 2014, Microsoft invested in OpenAI in 2019. 

So, the answer is Google. Google has 5 years more foresight."
990,@rasbt,2023-01-08 17:33:27+00:00,https://twitter.com/rasbt/status/1612140440081551362,"@_chasmcgill Good question, I meant vs using traditional supervised transfer learning"
991,@rasbt,2023-01-08 17:32:10+00:00,https://twitter.com/rasbt/status/1612140114972483586,@drexalt Oh no :(. I guess that's kind of in inline with my open-source vs open-access 2023 prediction but for different reasons üò∞ https://t.co/njz5RnTW7B
992,@rasbt,2023-01-08 17:25:00+00:00,https://twitter.com/rasbt/status/1612138313116258307,"@profdave @beenwrekt A bit of both. I think Parti used VitGAN, but given how unwieldy and annoying GANs are to train, the world will eventually converge (no pun intended) to diffusion models near-future"
993,@rasbt,2023-01-08 17:23:24+00:00,https://twitter.com/rasbt/status/1612137909427048448,"@drexalt Interesting, I didn't see that at first ü§î"
994,@rasbt,2023-01-08 16:17:37+00:00,https://twitter.com/rasbt/status/1612121354958155776,"@MuhammadAnas707 It's a good intro to machine learning, with a special emphasis on tree-based methods (the most relevant non-neural network methods) and model evaluation :)"
995,@rasbt,2023-01-08 15:50:05+00:00,https://twitter.com/rasbt/status/1612114425955196930,@profdave @beenwrekt I honestly wouldn't spend time on that. GANs are dead.
996,@rasbt,2023-01-08 15:47:42+00:00,https://twitter.com/rasbt/status/1612113828413833217,"For more details, see ""ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders"" (https://t.co/SMZT81BiNE) or shoot me questions. (PS: I covered ConvNeXt v1 in Ahead of AI #4: https://t.co/4E1pUhSIob)
5/5"
997,@rasbt,2023-01-08 15:47:42+00:00,https://twitter.com/rasbt/status/1612113825754677248,"The use of sparse convolutions is mainly to use high-mask ratios and to boost efficiency during training.
The global response normalization part is a new type of normalization layer that replaces e.g., batch or layer normalization.
4/5"
998,@rasbt,2023-01-08 15:47:41+00:00,https://twitter.com/rasbt/status/1612113823078699015,"ConvNeXt V2 co-designs a pure convolutional network for self-supervised via 2 mechanisms (illustrated in the figure above):

1.  using sparse convolutions for sparse patches with a high-mask ratio;
2.  adding a new global response normalization layer.
3/5"
999,@rasbt,2023-01-08 15:47:41+00:00,https://twitter.com/rasbt/status/1612113820406943744,"Self-supervised learning, which lets us leverage large unlabeled datasets for supervised pretraining, is one of the keys of success behind language and vision transformers. But using self-supervised learning like masked auto-encoding can harm the performance of CNNs.
2/5"
1000,@rasbt,2023-01-08 15:47:40+00:00,https://twitter.com/rasbt/status/1612113816363610112,"Convolutional networks strike back, again. The fully convolutional ConvNeXt v2 extends the successful ConvNeXt architecture by adding self-supervised learning capabilities.

What's new?
1/5 https://t.co/sHpXH9uipe"
1001,@rasbt,2023-01-08 14:52:12+00:00,https://twitter.com/rasbt/status/1612099857887510529,"@3scorciav @aniketvartak @Michael_J_Black And sure, here's the secret ingredient since you asked: https://t.co/BxpfzQ5eKd"
1002,@rasbt,2023-01-08 14:51:34+00:00,https://twitter.com/rasbt/status/1612099698143158274,"@3scorciav @aniketvartak @Michael_J_Black We should be transparent when it comes to the core results of the paper, but I don't think you need to explain the writing process &amp; routines. 
Sure, I like to share that too (see my Study Tips &amp; Productivity sections in my newsletter) but that doesn't have to be part of a paper."
1003,@rasbt,2023-01-08 14:46:56+00:00,https://twitter.com/rasbt/status/1612098533435539456,"@profdave @beenwrekt Yes yes, but didn't it motivate the original authors to work on GANs? But could have also been the other way around, the authors worked on GANs and tried to retrofit GT later on."
1004,@rasbt,2023-01-08 13:14:09+00:00,https://twitter.com/rasbt/status/1612075185292591107,"@PipiPopiLopi @AbhiRaama22 @svpino Yes and no. They are zero/one-shot learners but that doesn‚Äôt mean they are good zero/one-shot learners. Currently, the zero/one-shot performance still lags behind finetuned LLMs by a lot"
1005,@rasbt,2023-01-08 13:11:59+00:00,https://twitter.com/rasbt/status/1612074638078533633,@paddy_the_faddy @ntkris I agree
1006,@rasbt,2023-01-07 21:44:10+00:00,https://twitter.com/rasbt/status/1611841146828750850,"@sarahookr If they are thoughtful comments then I would respond in the rebuttal of course. If someone raises a concern due to a misunderstanding, I am also happy to clarify in the rebuttal. If someone is rude, writing a rebuttal would just make me angry, and I find it better to not engage."
1007,@rasbt,2023-01-07 21:41:04+00:00,https://twitter.com/rasbt/status/1611840365488750593,"@sarahookr It goes both ways: happened to me quite often that reviewers didn‚Äôt really carefully read the paper and wrote lazy or rude criticisms. It took a lot of time to write the paper, and it is similarly selfish to write some quick comments to fulfill your review quota"
1008,@rasbt,2023-01-07 20:50:10+00:00,https://twitter.com/rasbt/status/1611827557631918090,@wjarek Nice! And those skis looks familiar üòÖ https://t.co/7l1m5b9qTI
1009,@rasbt,2023-01-07 20:45:59+00:00,https://twitter.com/rasbt/status/1611826503200784386,"@aniketvartak @Michael_J_Black Yeah, I think we should include all necessary details to reproduce the experiments that are the core of the paper. But we don‚Äôt need to explain how we wrote the paper. If we used ChatGPT to come up with some conclusions or insights, you can mention it in the method section though"
1010,@rasbt,2023-01-07 20:00:01+00:00,https://twitter.com/rasbt/status/1611814937579372548,"@aniketvartak @Michael_J_Black Hm, I don't know. What's next then? ""I wrote the Results section first, then I made the figures, based on which I wrote the Discussion section. I took the day off before I wrote the Abstract, and I used Grammarly to help me reduce the use of passive voice."""
1011,@rasbt,2023-01-07 19:41:15+00:00,https://twitter.com/rasbt/status/1611810213497303041,"@bigblueboo Interesting! I only heard about ChatGPT for Bing so far. 

Haha, ChatGPT is going to be the new Clippy."
1012,@rasbt,2023-01-07 19:06:11+00:00,https://twitter.com/rasbt/status/1611801387364454401,"@fisadev @elonmusk @paulg I would like this tweet ... but yes, exactly!"
1013,@rasbt,2023-01-07 18:37:21+00:00,https://twitter.com/rasbt/status/1611794132317659137,"@bernhardsson Packages are usually tested more thoroughly for compat. Everyone can upload a package to PyPI. But for conda-forge it has to pass a whole lot of tests before it‚Äôs available. Of course, for well-maintained packages there is no difference but YMMV"
1014,@rasbt,2023-01-07 18:34:40+00:00,https://twitter.com/rasbt/status/1611793456275275776,"@BlackHC @zacharynado @dustinvtran @balajiln I think it falls out naturally. And on that note, Dropout implicitly approximates geometric model averaging. 
(I am on mobile so pls don‚Äôt ask me to dig out references right away üòÖ)"
1015,@rasbt,2023-01-07 18:02:32+00:00,https://twitter.com/rasbt/status/1611785370080788482,"@beenwrekt Game theory led to GANs, and GANs led to the adoption of diffusion models, which ‚Ä¶ either destroy the internet or make us all more productive, TBD"
1016,@rasbt,2023-01-07 17:58:11+00:00,https://twitter.com/rasbt/status/1611784277464678400,"@elonmusk @paulg I would like tweets way more often if they weren‚Äôt always shoved in my followers‚Äô timelines. 
Maybe only put retweets in the timeline like in the old days?"
1017,@rasbt,2023-01-07 17:38:15+00:00,https://twitter.com/rasbt/status/1611779260775014400,"@johnmyleswhite Speaking from experience, the grass is also always greener on the other side."
1018,@rasbt,2023-01-07 17:27:19+00:00,https://twitter.com/rasbt/status/1611776505905807362,"@Michael_J_Black Hm, that‚Äôs like asking authors what they had for breakfast when they wrote the Discussion section."
1019,@rasbt,2023-01-07 16:49:18+00:00,https://twitter.com/rasbt/status/1611766940384591872,"@mohammad2012191 @tennis_dr So if you have 512-dimensional word embeddings your input matrix would be that times the size of the context (number of words) it can handle. Top off the top of my head, I think BERT can handle 512 tokens with a 768-dim embedding size each"
1020,@rasbt,2023-01-07 13:41:12+00:00,https://twitter.com/rasbt/status/1611719601854742528,"@WickedViper23 Human authorship info is useful for correspondence &amp; job satisfaction. And, whether we like it or not, given the current system, it‚Äôs important for credit assignment &amp; required for promotion, funding, etc"
1021,@rasbt,2023-01-07 13:36:36+00:00,https://twitter.com/rasbt/status/1611718446198456320,"@sarahookr I would just let it go, withdraw my submission, and submit elsewhere."
1022,@rasbt,2023-01-07 13:32:19+00:00,https://twitter.com/rasbt/status/1611717370107543554,@ChrisBridges95 üíØ
1023,@rasbt,2023-01-07 13:18:05+00:00,https://twitter.com/rasbt/status/1611713784262844425,"Or in other words, if you use ChatGPT as a tool to interpret &amp; write about some of the results, just reference it in the Methods section where it belongs."
1024,@rasbt,2023-01-07 13:03:04+00:00,https://twitter.com/rasbt/status/1611710006931652608,@corrptedharmony @b4bodkhe @ylecun and back to the point above: I do think that we can define beauty with language. Some can do it better than others.
1025,@rasbt,2023-01-07 13:01:02+00:00,https://twitter.com/rasbt/status/1611709495377563651,"@IamManuell Ok fair. So, let‚Äôs consider an applied paper like ‚ÄúSARS-CoV-2 Omicron-B.1.1.529 leads to widespread escape from neutralizing antibody responses‚Äù https://t.co/BPUDMJ0wR1

Here, models of Omicron RBD and NTD were created by AlphaFold 2. Yet AlphaFold is not a coauthor."
1026,@rasbt,2023-01-07 12:54:22+00:00,https://twitter.com/rasbt/status/1611707819367010304,"@bytetweets Exactly. It is possible for algorithms to be used to create a patentable invention, but under current law and practice, algorithms cannot be recognized as inventors (vs the person behind using the algorithm). And so forth ‚Ä¶"
1027,@rasbt,2023-01-07 12:16:03+00:00,https://twitter.com/rasbt/status/1611698175345057792,@MattBlandCambs I don‚Äôt know but I saw multiple people seriously discussing ChatGPT as paper co-author last week.
1028,@rasbt,2023-01-07 12:01:08+00:00,https://twitter.com/rasbt/status/1611694419589185536,"Re: ChatGPT and authorship.

If a person creates or contributes results for a paper, this person is a coauthor. But this naturally doesn‚Äôt extend to models or algorithms.

Imagine AlphaFold were an author on the AlphaFold paper.

So, why would/should it be different for ChatGPT?!"
1029,@rasbt,2023-01-07 11:46:59+00:00,https://twitter.com/rasbt/status/1611690862290903041,"@RRejeleene Basically if we are hiring? üòÖ
We do have a Careers page on our we site you could check out if you are interested."
1030,@rasbt,2023-01-07 11:45:53+00:00,https://twitter.com/rasbt/status/1611690583524868096,"@brihatsquirrel Yeah, when you learn the embedding matrix in a masked or next-word pretext task, add a larger weight to the cross entropy loss for the words you care about more."
1031,@rasbt,2023-01-07 11:42:14+00:00,https://twitter.com/rasbt/status/1611689665895202821,"@corrptedharmony @b4bodkhe @ylecun That‚Äôs totally true. But on the other hand, you can also have poem that someone finds beautiful.  But yes.
Also the sunset case would be an example of ‚Äúshow, don‚Äôt tell‚Äù ‚Äî of course the real thing is different than a description of the real thing."
1032,@rasbt,2023-01-07 11:38:24+00:00,https://twitter.com/rasbt/status/1611688699732918273,"@3scorciav @ylecun @AllenHW0 @Michael_J_Black @CSProfKGD I see ChatGPT as an algorithm &amp; I don‚Äôt think we need to add algorithms as co-authors. Similarly, if you train a neural network to make predictions, it contributes results but you wouldn‚Äôt consider it an author. 

Can you clarify what you mean regarding not caring about students?"
1033,@rasbt,2023-01-07 03:35:15+00:00,https://twitter.com/rasbt/status/1611567111813447680,@cwizprod1 Yea there is! (There are also further references in that paper).
1034,@rasbt,2023-01-06 20:31:08+00:00,https://twitter.com/rasbt/status/1611460379841908739,"@svpino No, we need to keep it around to provide training data üòâ"
1035,@rasbt,2023-01-06 20:18:04+00:00,https://twitter.com/rasbt/status/1611457089435475979,"@ylecun @AllenHW0 @Michael_J_Black @CSProfKGD Oh, and while it is possible for algorithms to be used to create a patentable invention, but under current law and practice, algorithms cannot be recognized as inventors and cannot get inventorship status. So, why should LLMs (algorithms) be listed as authors on a paper?"
1036,@rasbt,2023-01-06 20:07:14+00:00,https://twitter.com/rasbt/status/1611454365755211776,"@ylecun @AllenHW0 @Michael_J_Black @CSProfKGD 2/2 Human authorship info is useful for correspondence, job satisfaction, and credit assignment (promotion, funding). Something that LLMs don't require. Nonetheless, it's may be useful to somehow acknowledge LLMs if they were useful, to justify funding for further improvements."
1037,@rasbt,2023-01-06 20:05:10+00:00,https://twitter.com/rasbt/status/1611453844394840066,"@ylecun @AllenHW0 @Michael_J_Black @CSProfKGD I don't think LLMs that helped generating portions of the text should be listed as co-authors. (Optionally, one may list it as a tool for preparing the paper in the acknowledgement section.)
1/2"
1038,@rasbt,2023-01-06 17:51:32+00:00,https://twitter.com/rasbt/status/1611420213135740929,"@mohammad2012191 @tennis_dr For one-hot encoding, the dimensionality is equal to the vocabulary size."
1039,@rasbt,2023-01-06 17:44:11+00:00,https://twitter.com/rasbt/status/1611418362902364189,"@mohammad2012191 @tennis_dr And the one-hot encoding is much higher-dimensional than the embedding. If your vocabulary is 50,000 words, you cannot approximate that 50,000-dimensional one-hot representation with a 512-dimensional embeddings, for example."
1040,@rasbt,2023-01-06 17:42:04+00:00,https://twitter.com/rasbt/status/1611417833035939862,@mohammad2012191 @tennis_dr In word2vec you minimize the distance between words used in similar contexts though
1041,@rasbt,2023-01-06 17:27:08+00:00,https://twitter.com/rasbt/status/1611414073219891242,*The green box should be down by 1 position of course. Didn't mean to use 1-based indexing üòÖ https://t.co/rgNM7fpPpE
1042,@rasbt,2023-01-06 17:12:31+00:00,https://twitter.com/rasbt/status/1611410393733152771,"@tennis_dr To illustrate the 3 points above further. The embedding layer is just the weight matrix of the first hidden layer. E.g., the network below has a hidden layer and an output layer. The hidden layer is the embedding. https://t.co/VG8m7gybZO"
1043,@rasbt,2023-01-06 17:09:38+00:00,https://twitter.com/rasbt/status/1611409668378607626,"@tennis_dr &gt; 3. How is embedding different from feature preprocessing?
It's implicit, not manual."
1044,@rasbt,2023-01-06 17:09:13+00:00,https://twitter.com/rasbt/status/1611409565177757702,"@tennis_dr &gt; 2. Are embedding layers trained jointly or separately from main task n/w?
Either or. WordVec is seperate of course, but modern methods train them jointly. It's just the first layer of your network."
1045,@rasbt,2023-01-06 17:08:56+00:00,https://twitter.com/rasbt/status/1611409495414149122,"@tennis_dr &gt; 1. What makes a ‚Äúoptimum‚Äù embedding? 
Weights that minimize the loss, e.g., cross-entropy loss in classification contexts."
1046,@rasbt,2023-01-06 16:56:26+00:00,https://twitter.com/rasbt/status/1611406347093917697,"@MuhammadAnas707 Ah yes, so test_idx would refer to the indices of the test examples.

Suppose you have a dataset with 5 examples, let's assign indices 0, 1, 2, 3, 4 to them. Data points 0, 1, 3 are used for the training set, 2 &amp; 4 are used for the test set. In this case test_idx = [2, 4]"
1047,@rasbt,2023-01-06 16:54:37+00:00,https://twitter.com/rasbt/status/1611405888748945410,"@tulkenss Yeah, right, if you don't use/add a positional encoding, it doesn't matter."
1048,@rasbt,2023-01-06 16:49:34+00:00,https://twitter.com/rasbt/status/1611404621662093312,"@tulkenss Hm yeah, if you consider a generalized linear model. The big caveat of BoW is that the words (embeddings) are out of (sentence) order."
1049,@rasbt,2023-01-06 16:47:45+00:00,https://twitter.com/rasbt/status/1611404164386676736,Videos on that to be released in Unit 8 of my deep learning fundamentals course üòä https://t.co/B0rVXxbR6v
1050,@rasbt,2023-01-06 16:38:26+00:00,https://twitter.com/rasbt/status/1611401818021703680,"@Nicole_Janeway Glad you like it, and thanks for sharing üòä"
1051,@rasbt,2023-01-06 16:37:26+00:00,https://twitter.com/rasbt/status/1611401567030083587,"Embedding layers are often perceived as a fancy operation that we apply to encode the inputs (each word tokens) for large language models.
But embedding layers = fully-connected layers on one-hot encoded inputs. They just replace expensive matrix multiplications w index look-ups. https://t.co/0I3AFk4por"
1052,@rasbt,2023-01-06 16:21:08+00:00,https://twitter.com/rasbt/status/1611397462924705792,@MuhammadAnas707 Probably: the indices of the data points in the test set. Could you provide some context?
1053,@rasbt,2023-01-06 14:21:41+00:00,https://twitter.com/rasbt/status/1611367404814143489,"@giffmana Yes, this! And there is a reason things like the Advent of Code and hackathons are so popular üòä"
1054,@rasbt,2023-01-06 13:09:01+00:00,https://twitter.com/rasbt/status/1611349118336507904,@rishdotuk I expanded on these a bit in the thread. I will also discuss that more in Unit 8 of my new deep learning course ^^
1055,@rasbt,2023-01-06 12:42:53+00:00,https://twitter.com/rasbt/status/1611342538438320128,"@KLdivergence Wow nice, congrats on this great new position!!"
1056,@rasbt,2023-01-05 19:54:22+00:00,https://twitter.com/rasbt/status/1611088737982636055,"@GaryMarcus @pgolding Thanks! All bookmarked, and I hope to be able to check it out on the wknd!"
1057,@rasbt,2023-01-05 18:59:15+00:00,https://twitter.com/rasbt/status/1611074866056204292,"@pgolding 2/2 what we can potentially learn is given that LLMs are not biological and that LLMs can parse and write language, biology may not be a requirement for language?"
1058,@rasbt,2023-01-05 18:57:29+00:00,https://twitter.com/rasbt/status/1611074421380243462,"@pgolding Thanks, bookmarked this and will try to read it some time! In the meantime, regarding the biology of language, yeah, I am not sure it‚Äôs a legit point of enquiry. What we can potentially learn 1/2"
1059,@rasbt,2023-01-05 18:42:40+00:00,https://twitter.com/rasbt/status/1611070695009558528,@pgolding I wonder what there is to know or decipher about language that we don‚Äôt already know. Not being sarcastic but a genuine question.
1060,@rasbt,2023-01-05 18:37:54+00:00,https://twitter.com/rasbt/status/1611069492989423619,"@GaryMarcus @pgolding I see. Yeah what I said above was more about confirming what we know, not what LLMs contributed. Wasn‚Äôt familiar with Chomsky‚Äôs point the original question was referring to."
1061,@rasbt,2023-01-05 17:43:31+00:00,https://twitter.com/rasbt/status/1611055808233541646,"@b4bodkhe @ylecun I do think we can define beauty with language, i.e., something along the lines of ""a subjective perceptual experience of pleasure"". 
If you show someone a particular piece of music or painting that you find beautiful, that would be an example but not definition of beauty."
1062,@rasbt,2023-01-05 16:13:42+00:00,https://twitter.com/rasbt/status/1611033204198088706,@muktabh @ylecun I think there is no one-size-fits-all. It really depends so much on the context. Ikea assembly instructions? Way more efficient via video or pictures.  API documentation? Way more efficient as text.
1063,@rasbt,2023-01-05 15:33:40+00:00,https://twitter.com/rasbt/status/1611023131296120832,"@ylecun Love this example.
But is it because language-only is insufficient or because it's boring?

If steak and potatoes are all that you need to survive, why are there (still) so many different types of foods, preferences, cuisines, and recipes? Because life would be bland otherwise."
1064,@rasbt,2023-01-05 15:20:09+00:00,https://twitter.com/rasbt/status/1611019730391031809,"Open source had a good year!
I compiled a list of my favorite machine learning- and AI-related open-source libraries &amp; releases that I discovered, used, or contributed to in 2022:
https://t.co/W1KSkAp1PG"
1065,@rasbt,2023-01-05 14:15:38+00:00,https://twitter.com/rasbt/status/1611003492499615746,"@frochet @jackclarkSF Dang, I shouldn't have advertised this paper üòÖ"
1066,@rasbt,2023-01-05 14:01:28+00:00,https://twitter.com/rasbt/status/1610999927164866561,"@alfarabyab hah, yeah, maybe just calling it ""active reinforcement learning"""
1067,@rasbt,2023-01-05 13:54:16+00:00,https://twitter.com/rasbt/status/1610998117649858560,@osoleve Haven't heard of this one yet! Very intriguing!
1068,@rasbt,2023-01-05 13:45:26+00:00,https://twitter.com/rasbt/status/1610995895004463104,"I forgot 
7) Reinforcement Learning with Human Feedback"
1069,@rasbt,2023-01-05 01:54:59+00:00,https://twitter.com/rasbt/status/1610817104336371712,"@Ronak75yg @michael_nielsen Machine learning is a broad field. Sorry that I can‚Äôt be more specific, but it really depends what / how you want to use ML. Generally, statistics is important and useful for ML. Even if you don‚Äôt use statistics-based models (eg a simple perceptron) it‚Äôs useful for eg model eval"
1070,@rasbt,2023-01-04 23:56:16+00:00,https://twitter.com/rasbt/status/1610787226140524545,@aniketvartak @soumithchintala @icmlconf Same if you use a tax preparation tool: it‚Äôs still your fault if your tax return contained errors
1071,@rasbt,2023-01-04 23:55:20+00:00,https://twitter.com/rasbt/status/1610786992350191616,"@aniketvartak @soumithchintala @icmlconf But at the same time, if authors generate nonsense or flawed articles (using LLMs) and submit them, the authors should of course also be reprimanded. It all comes down to responsible use."
1072,@rasbt,2023-01-04 23:52:51+00:00,https://twitter.com/rasbt/status/1610786368422035459,@aniketvartak @soumithchintala @icmlconf Haha yeah so to clarify: unless we treat it as a competition or exercise (think sports events or exams) there shouldn‚Äôt be a restriction when it comes to a tool that makes you more productive.
1073,@rasbt,2023-01-04 23:34:00+00:00,https://twitter.com/rasbt/status/1610781622042869761,"@aniketvartak @soumithchintala @icmlconf Yup, that's my point. There shouldn't be an artificial restriction -- use whatever helps you to produce better science progress."
1074,@rasbt,2023-01-04 23:31:27+00:00,https://twitter.com/rasbt/status/1610780979848683521,@jpirruccello @soumithchintala @icmlconf Fair. Or consider only being allowed to use a pocket calculator for exams in college.
1075,@rasbt,2023-01-04 23:26:23+00:00,https://twitter.com/rasbt/status/1610779706617364484,@soumithchintala @icmlconf imagine you were organizing a marathon and some of the attendees brought a bicycle üòÜ
1076,@rasbt,2023-01-04 21:41:55+00:00,https://twitter.com/rasbt/status/1610753415591739392,@JonErlichman Love this cover. Nostalgia.
1077,@rasbt,2023-01-04 21:27:40+00:00,https://twitter.com/rasbt/status/1610749828425781261,"@wingedRuslan Oh yeah, I removed those because the courses were more meant for beginners ‚Äî people who would like to learn about the more current methods. Topics like SVMs etc are of course an interesting topic to study, there was just no time/space for it"
1078,@rasbt,2023-01-04 21:21:46+00:00,https://twitter.com/rasbt/status/1610748344971759619,"@karlrohe Depends üòÖ. 
More ""natural"" peanut butter, yes. The ""regular"" ones? No."
1079,@rasbt,2023-01-04 20:56:29+00:00,https://twitter.com/rasbt/status/1610741982753705984,"@wingedRuslan Shameless plug: If you are interested, my courses are somewhat related to the topics on the book. In some areas, they go into to more depth: https://t.co/OcL9XWoNIV"
1080,@rasbt,2023-01-04 17:33:05+00:00,https://twitter.com/rasbt/status/1610690796910514176,"Are you interested in learning how to use PyTorch's autograd module to compute gradients?
I've created a short, 5-minute video to get you started:
https://t.co/K4JOuQzPKA https://t.co/NnX1vii0t5"
1081,@rasbt,2023-01-04 16:43:19+00:00,https://twitter.com/rasbt/status/1610678271116546064,"@unsorsodicorda @jackclarkSF You mean assigning/predicting conference review scores? No, it's a generative model that outputs text, it doesn't rank papers. The classification part in the figure above is for identifying different sections in the papers. (Results, Conclusion, etc.)"
1082,@rasbt,2023-01-04 15:46:35+00:00,https://twitter.com/rasbt/status/1610663992183193600,"@FlorianGallwitz @jackclarkSF Yes. And maybe they'll reactivate Galactica, so we can automate the whole research pipeline."
1083,@rasbt,2023-01-04 15:39:06+00:00,https://twitter.com/rasbt/status/1610662110496784387,"And so it begins ...
Researchers created a peer-review dataset &amp; review comment generation model: https://t.co/QgvWf7PQAv

""[...] if you thought Human Reviewer 2 was hard to reason with, just wait until reviewer 2 is a language model!"" -- via @jackclarkSF https://t.co/v8BgCTi6ka"
1084,@rasbt,2023-01-04 15:01:27+00:00,https://twitter.com/rasbt/status/1610652635496910849,"@mmitchell_ai @yoavgo @icmlconf Whether using LLMs should be allowed aside, I don‚Äôt think LLMs should be considered as authors. They are non-conscious, non-human algorithms.

I see it related to laws around patents &amp; copyrights that an LLM ‚Äúlacks the human authorship required to substantiate a copyright claim‚Äù"
1085,@rasbt,2023-01-04 11:48:34+00:00,https://twitter.com/rasbt/status/1610604093961113604,"@mhajabri It‚Äôs more of a beginner book so it would be great if you are new to ML. If you are familiar with ML, it‚Äôs still a useful survey in terms of conventions or things to consider on kaggle (but you may want to skip over the general machine learning explanations)"
1086,@rasbt,2023-01-04 11:37:13+00:00,https://twitter.com/rasbt/status/1610601237619113987,"@michael_nielsen Yup, the ‚Äúunreasonable effectiveness of next word/token prediction‚Äù"
1087,@rasbt,2023-01-04 11:34:53+00:00,https://twitter.com/rasbt/status/1610600650664022022,"@omarsar0 Agree with you on that. To take it  step further, I predict that these efficiency changes are going to be mostly focused on inference mode. There will be more differences between training and inference mode  model architectures."
1088,@rasbt,2023-01-04 11:28:19+00:00,https://twitter.com/rasbt/status/1610598997856501760,"@luyben @ylecun Haha yeah, that was just a fun side note / joke  (and a complaint that it is frustrating &amp; failed above). At the same time there is a kernel of truth there: it doesn‚Äôt seem to consider broader sentence contexts (when changing its-&gt; it‚Äôs for example)"
1089,@rasbt,2023-01-04 11:25:27+00:00,https://twitter.com/rasbt/status/1610598275928801286,"@Insidedctm @jxmnop @SimonPrinceAI That makes sense. The orig attention mechanism was developed for RNNs, so it‚Äôs worth mentioning them to understand the motivation behind transformers. But other than for time series modeling, it does really make sense to talk about RNN instead of transformers for lang modeling"
1090,@rasbt,2023-01-04 11:22:58+00:00,https://twitter.com/rasbt/status/1610597653540208640,"@AiSimonThompson Yes, üíØ agree with you in that"
1091,@rasbt,2023-01-03 23:40:15+00:00,https://twitter.com/rasbt/status/1610420809574539266,"@pgolding The more books I read the bigger my vocabulary and understanding becomes. Also, the more i read the better I become at writing. Recent years showed that this is also true for LLMs. So, exposure to and consumption of language helps with understanding language?"
1092,@rasbt,2023-01-03 22:45:54+00:00,https://twitter.com/rasbt/status/1610407129361387526,@Ankit85076055 @ylecun Regarding design. A neural network (RFDiffusion) seems to be great at designing proteins (https://t.co/bArzrVXD4A) -- or at least it's seems better than any alternative approach to date.
1093,@rasbt,2023-01-03 22:41:55+00:00,https://twitter.com/rasbt/status/1610406129619853319,@AiSimonThompson It involves a language model trained on a string representation (1D sequence) of proteins
1094,@rasbt,2023-01-03 22:40:31+00:00,https://twitter.com/rasbt/status/1610405777260281856,"@miriam_bukin @DSaience Unfortunately no. If you come across something, please share!"
1095,@rasbt,2023-01-03 22:39:33+00:00,https://twitter.com/rasbt/status/1610405531188862977,"@brendan_evers @jxmnop Sure, and there was actually the Muse paper by Google where they used GANs. Still, if you have to make a choice and either have a lecture on GANs or Diffusion Models (because you can‚Äôt add extra weeks in the semester), it should be diffusion models imho"
1096,@rasbt,2023-01-03 18:53:24+00:00,https://twitter.com/rasbt/status/1610348618828943360,"@ylecun *the best example is the autocorrect AI on iOS. I am üíØ confident that I typed ‚Äúits‚Äù, and it automatically changed it to ‚Äúit‚Äôs‚Äù üò©"
1097,@rasbt,2023-01-03 18:49:41+00:00,https://twitter.com/rasbt/status/1610347683192995841,@jxmnop It‚Äôs still a nice syllabus! If I had to replace some things: Recurrent neural networks for text. GANs.
1098,@rasbt,2023-01-03 18:44:14+00:00,https://twitter.com/rasbt/status/1610346313169649672,"@ylecun I agree. But I also wouldn‚Äôt say that it‚Äôs surprising that it‚Äôs structure can be well captured by artificial neural nets. 
The challenge is more in parsing and resolving ambiguities that require experience and contexts. And current gen networks still have limited context windows."
1099,@rasbt,2023-01-03 17:58:00+00:00,https://twitter.com/rasbt/status/1610334676589346817,"@LightningAI Yeah, let‚Äôs try Julia again üòÖ https://t.co/HEFUVJgcJU"
1100,@rasbt,2023-01-03 17:40:46+00:00,https://twitter.com/rasbt/status/1610330342233182208,"@StatMixedML @RichmanRonald Yup, check this out for example: https://t.co/1K8UWWaUnR"
1101,@rasbt,2023-01-03 17:24:58+00:00,https://twitter.com/rasbt/status/1610326363046825984,"@LongFormMath Yes! Coding books are typically written like this. Starting with the broad goal, and then describing how to solve that goal before showing the actual code."
1102,@rasbt,2023-01-03 17:22:00+00:00,https://twitter.com/rasbt/status/1610325620042375171,@SnehilRC The ‚ÄúModern Time Series Forecasting with Python‚Äù one by @manujosephv above might be good. But yeah it‚Äôs on the reading list
1103,@rasbt,2023-01-03 15:21:31+00:00,https://twitter.com/rasbt/status/1610295299343253509,"@nsomazr Haha, funny, I just tried. It seems like LLMs are in denial and/or don't like it :P https://t.co/axWLUa4Xtt"
1104,@rasbt,2023-01-03 14:57:03+00:00,https://twitter.com/rasbt/status/1610289140834107394,"@jwbrassell @ArnaudovKrum Nice. I never read ""Learn Python the Hard Way"" (because I already knew Python when the book came out) but I heard good things about it. This more advanced book might be useful, thanks for sharing!"
1105,@rasbt,2023-01-03 14:55:48+00:00,https://twitter.com/rasbt/status/1610288824046989312,"Researchers want LLMs (large language models) to mimic humans.
But let's also keep in mind that LLMs are highly effective at modeling proteins (as demonstrated by AlphaFold 2 and the ESM metagenomic Atlas) not in spite of but rather *because* they work differently than humans."
1106,@rasbt,2023-01-03 14:36:41+00:00,https://twitter.com/rasbt/status/1610284013792419840,"@ArnaudovKrum Unfortunately none comes to mind, but I'd be interested, too, in case you come across a good one that fits this description"
1107,@rasbt,2023-01-03 13:05:15+00:00,https://twitter.com/rasbt/status/1610261004222595075,"- Fluent Python (2nd, Ramalho)
- Creating a Wordle Game in React and TypeScript (Gold)

And some fun ones I got for Xmas:
- Fairy Tale (King)
- The last 2 Witcher books
- The Nineties (Klosterman)

2/2"
1108,@rasbt,2023-01-03 13:05:14+00:00,https://twitter.com/rasbt/status/1610261002389528580,"Saw lots of people sharing their reading list for 2023! Let me join! üòä

- A pile of paper first
- Modern Time Series Forecasting with Python (Joseph)
- Modern Deep Learning for Tabular Data (Ye &amp; Wang)
- the new Probabilistic Machine Learning (Murphy), comes out in summer

1/2"
1109,@rasbt,2023-01-03 12:06:07+00:00,https://twitter.com/rasbt/status/1610246123825799169,@RichmanRonald Nice find! Will be adding it to my reading list for 2023!
1110,@rasbt,2023-01-02 23:30:02+00:00,https://twitter.com/rasbt/status/1610055849971523584,"@wingedRuslan Nice! Yeah, I think it certainly doesn't affect all models. Whisper is another nice example. You can download it and run it on your laptop."
1111,@rasbt,2023-01-02 21:59:58+00:00,https://twitter.com/rasbt/status/1610033181419347968,"@OmnesResNetwork Interesting! Haven't heard of that one, yet. Tbh that's sounds very reasonable to facilitate peer-review but I also share your concerns regarding the compute costs"
1112,@rasbt,2023-01-02 17:55:03+00:00,https://twitter.com/rasbt/status/1609971546147418113,"@beenwrekt It‚Äôs been many years, but as I recall it started out as my favorite fiction series. Don‚Äôt want to spoil too much, but I remember the last books were definitely a bit over the top and super meta. But yeah, until then, enjoy!"
1113,@rasbt,2023-01-02 17:51:38+00:00,https://twitter.com/rasbt/status/1609970689217380354,@julien_c @BMJHayward @streamlit Nice! Things are accelerating (no pun intended) indeed!
1114,@rasbt,2023-01-02 17:30:10+00:00,https://twitter.com/rasbt/status/1609965283829252096,@cwizprod1 @EMostaque Really? I thought Google had their own voice assistant
1115,@rasbt,2023-01-02 17:13:02+00:00,https://twitter.com/rasbt/status/1609960975712616452,@ArtificialAva Glad to hear these write-ups we‚Äôre worthwhile to you. Happy New Year ü•Ç
1116,@rasbt,2023-01-02 15:43:26+00:00,https://twitter.com/rasbt/status/1609938425318367233,"@RichmanRonald There will be an increased focused on boosting deep tabular performance with diffusion-based synthetic data augmentation, and people will come up with more interesting pretraining objectives to pretrain deep tabular methods -- one big advantage they have over tree-based methods!"
1117,@rasbt,2023-01-02 15:37:07+00:00,https://twitter.com/rasbt/status/1609936836587126786,"@akshay_pachaar Yup. And yes, a top-3 or top-5 papers list turned out to be way too challenging ... so I went with a top-10 after all üòÖ"
1118,@rasbt,2023-01-02 15:14:34+00:00,https://twitter.com/rasbt/status/1609931159013822465,"""Ahead of AI #4: A Big Year For AI"" is out!

In this issue I'm discussing:
- My top 10 papers I read this year
- AI industry trends
- Open source highlights
- My yearly review routine

üëâ https://t.co/4E1pUhSIob

Happy New Year!"
1119,@rasbt,2023-01-02 13:50:34+00:00,https://twitter.com/rasbt/status/1609910020442841088,"@MuhammadAnas707 You only get 8 cores for Google Colab which are often even slower than the single GPU. It‚Äôs fine for learning and teaching and tinkering, but for serious research projects it‚Äôs really not enough"
1120,@rasbt,2023-01-02 13:48:24+00:00,https://twitter.com/rasbt/status/1609909476202536960,@cwizprod1 @EMostaque Basically like Siri and/or whatever the Android equivalent is
1121,@rasbt,2023-01-02 13:47:10+00:00,https://twitter.com/rasbt/status/1609909166612647937,"@nirsd That‚Äôd basically be Kaggle then, which is nice, but I think you still need someone reviewing whether someone‚Äôs cheating, plagiarizing etc"
1122,@rasbt,2023-01-02 13:45:33+00:00,https://twitter.com/rasbt/status/1609908757894516738,@bitdribble Wow that‚Äôs a pretty comprehensive and fun curriculum! üëç
1123,@rasbt,2023-01-02 13:44:11+00:00,https://twitter.com/rasbt/status/1609908413248507904,"@MuhammadAnas707 I don‚Äôt think they have solved the issue. Google Colab gives you exactly 1 GPU, which is not enough to train any modern computer vision or language model."
1124,@rasbt,2023-01-02 13:43:04+00:00,https://twitter.com/rasbt/status/1609908134084050944,"@mandubian @suzatweet Yes, and this also has big implications for research. Most researchers will have to pivot to different topics or purely theoretical work to make meaningful contributions if this trend continues."
1125,@rasbt,2023-01-02 13:41:46+00:00,https://twitter.com/rasbt/status/1609907808094363652,"@BMJHayward Yeah, based on what I can tell it looks like it. Although I think (and I haven‚Äôt use their service extensively) you are restricted to Gradio UIs. Can‚Äôt have a custom UI or API endpoint, but I may be wrong."
1126,@rasbt,2023-01-02 13:37:25+00:00,https://twitter.com/rasbt/status/1609906711128674304,@kashifmanzoor @suzatweet Expensive and often complicated since we cannot run things one a single machine anymore but have to consider &amp; connect multi-node setups
1127,@rasbt,2023-01-02 13:35:28+00:00,https://twitter.com/rasbt/status/1609906223238840320,@MuhammadAnas707 @jsulopzs @arya_akhare @akshay_pachaar Classes perhaps ‚ò∫Ô∏è
1128,@rasbt,2023-01-01 19:30:38+00:00,https://twitter.com/rasbt/status/1609633213650968585,"@pastaraspberry Agreed. It‚Äôs going to be more of a ‚Äúshow, don‚Äôt tell‚Äú"
1129,@rasbt,2023-01-01 19:23:51+00:00,https://twitter.com/rasbt/status/1609631506678382593,@NeuroTaha RLHF ‚Äî Reinforcement Learning with Human Feedback ‚Äî will become more important and widespread at companies to finetune models
1130,@rasbt,2023-01-01 19:22:14+00:00,https://twitter.com/rasbt/status/1609631101693181954,@pastaraspberry @RobertWKemp The thing is that AI models become outdated way more quickly than highways need to be repaired maybe
1131,@rasbt,2023-01-01 19:20:58+00:00,https://twitter.com/rasbt/status/1609630780270968832,"@pastaraspberry @RobertWKemp Hm maybe. We will see. So far, we have seen more like the opposite where lots of stuff happens server-side. Eg even take Siri on the iPhone which has become completely useless without and internet connection."
1132,@rasbt,2023-01-01 18:33:44+00:00,https://twitter.com/rasbt/status/1609618893047468032,"@perrabyte We are saying this every year. Sure, compute will become faster, storage will become more abundant. Yet, it requires more resources than ever to train and host ML models."
1133,@rasbt,2023-01-01 18:28:05+00:00,https://twitter.com/rasbt/status/1609617471929032705,"@MamadyNabeke Oh that's weird. The new link is https://t.co/zymCvWoQhv (changed it when I switched from Revue to Substack). And I had a auto-forwarding set up for that one. Btw where did you find the link, will make change it there now."
1134,@rasbt,2023-01-01 17:22:17+00:00,https://twitter.com/rasbt/status/1609600914737831937,"@tripp_jaden42 Only the absolute minimum tier seems to be free, which is not enough for most models."
1135,@rasbt,2023-01-01 17:20:51+00:00,https://twitter.com/rasbt/status/1609600552790523906,@Sidmoh1 We have been saying that for years though. An 4xA100 costs you at least $5/h. That's ~$1000/week.
1136,@rasbt,2023-01-01 17:17:32+00:00,https://twitter.com/rasbt/status/1609599717310140417,"@cwizprod1 @EMostaque So, what I am getting from it is that each individual should have their own AI model. I think that's a reasonable thing to say. Now, devil's advocate: most people don't even bother having an own App or even personal website. How would you get people to having their own AI model?"
1137,@rasbt,2023-01-01 17:14:08+00:00,https://twitter.com/rasbt/status/1609598864163590145,"@RobertWKemp I think cloudflare is mostly perfecting caching, right? So yeah, I can see that for common models that lots of people use, where you have lots of duplicate queries. For niche models it's maybe less useful."
1138,@rasbt,2023-01-01 17:11:32+00:00,https://twitter.com/rasbt/status/1609598206635122689,"@RobertWKemp Also, there is a reason why Google doesn't use a ChatGPT-type model for search yet"
1139,@rasbt,2023-01-01 17:10:30+00:00,https://twitter.com/rasbt/status/1609597948903686144,@RobertWKemp Both are kind of expensive. Try to run the large Whisper model on your laptop.
1140,@rasbt,2023-01-01 17:09:59+00:00,https://twitter.com/rasbt/status/1609597817751846914,"@realohtweets In the short term, yes. As the Chinchilla paper showed, most models are still severely undertrained. In the long-run, I think we may need different ideas."
1141,@rasbt,2023-01-01 16:59:03+00:00,https://twitter.com/rasbt/status/1609595066099634177,@cwizprod1 @EMostaque That's interesting &amp; promising! I will stay tuned for that.
1142,@rasbt,2023-01-01 16:57:17+00:00,https://twitter.com/rasbt/status/1609594621817937925,"@cwizprod1 @EMostaque And this is just 1 model. There are lots of cool models out there. Take PaLM + RLHF (https://t.co/4vQ83pcX2H), an open-source equivalent of ChatGPT. 

Stability AI is doing cool stuff. My original trend prediction above is that it's getting harder and more expensive to do that."
1143,@rasbt,2023-01-01 16:54:19+00:00,https://twitter.com/rasbt/status/1609593877534490625,"@cwizprod1 @EMostaque Yeah, my original point was that open sourcing won't be as useful as it once was. Eg the Stable Diffusion code may be open source, but it's not trivial to train the model. I.e, the paper (Latent Diffusion Model) came out in 2021. And it took Stability AI 8 months and lots of $$$"
1144,@rasbt,2023-01-01 16:49:24+00:00,https://twitter.com/rasbt/status/1609592637773717505,"@cwizprod1 Yeah, running final diffusion model on your laptop is now pretty straightforward (you can use the code below without the --cloud flag to do just that) https://t.co/gNontBFoqL

Still, it tooks lots of effort to develop SD and make that happen. And it's a model from yesteryear"
1145,@rasbt,2023-01-01 16:48:07+00:00,https://twitter.com/rasbt/status/1609592317463109634,"@cwizprod1 @EMostaque It's a 43 min interview, do you have a tl;dr by chance? üòÖ"
1146,@rasbt,2023-01-01 16:44:51+00:00,https://twitter.com/rasbt/status/1609591492300906496,"@arian_ghashghai Yes, like it or not, we have been spoiled in recent years.

ML models are getting more and more complex. This in terms of compute resources required, but also in terms of tips &amp; tricks (like pretraining objectives) that are required to make it all work (well)."
1147,@rasbt,2023-01-01 16:42:46+00:00,https://twitter.com/rasbt/status/1609590970479448065,"@realohtweets True, most models already come with ""Pro"" modes. E.g., think of Whisper, which lets you choose ""small"", ""medium"", and ""large"" models, for example.

Regarding performance, data, and compute: it will keep increasing. As Chinchilla showed, most models are still super undertrained!"
1148,@rasbt,2023-01-01 16:36:29+00:00,https://twitter.com/rasbt/status/1609589387146280960,"My ML &amp; AI prediction for 2023: 

""open access"" becomes the new ""open source"". Code will remain open source but be less useful due to data requirements &amp; compute costs.

For demos or peer-reviews, devs will have to host models. Easy &amp; cheap hosting will likely be a focus in 2023."
1149,@rasbt,2023-01-01 16:16:24+00:00,https://twitter.com/rasbt/status/1609584334008107009,"@AndrewYNg I enjoy tinkering and learning. So, from a personal perspective, I hope that models stay transparent and continue to be released into the open source world!"
1150,@rasbt,2023-01-01 15:36:00+00:00,https://twitter.com/rasbt/status/1609574166113538048,"@naivebayesian Hah, nice. I thought there was an issue with using the ""YYYY - present"" phrase, but I recall what it was. Or maybe there is no issue with it like that article hints at, and I am just a creature of habit üòÖ"
1151,@rasbt,2023-01-01 14:53:50+00:00,https://twitter.com/rasbt/status/1609563554901905416,"3 papers from my personal top-10 2022.*

8. A Generalist Agent
9. Robust Speech Recognition via Large-Scale Weak Supervision
10. Revisiting Pretraining Objectives for Tabular Deep Learning

*The top 7, incl write-ups, in tomorrow's Ahead of AI üöÄ"
1152,@rasbt,2023-01-01 14:18:50+00:00,https://twitter.com/rasbt/status/1609554745886220288,"@Nux1971 Yes, nested cross-validation is definitely a good approach. Especially if you have small datasets. I would say the difference is mostly that CI's are typically for a model, whereas nested CV evaluates algorithms."
1153,@rasbt,2023-01-01 14:15:52+00:00,https://twitter.com/rasbt/status/1609554002378915840,"Happy New Year! üéä

What‚Äôs your theme for the year?
Personally, I am aiming to automate more mundane tasks again

My first project is automating the 2022 -&gt; 2023 bumps on various websites (using my old, trusty py-args utils https://t.co/7wJADPhNCB)"
1154,@rasbt,2022-12-31 23:54:50+00:00,https://twitter.com/rasbt/status/1609337316014686210,"@cypher_text @CSProfKGD And if you only consider 2022, it's 5k: https://t.co/chGJeCDm1d"
1155,@rasbt,2022-12-31 22:06:24+00:00,https://twitter.com/rasbt/status/1609310027428384770,"@AbhiRaama22 @ylecun Absolutely. It doesn't have to be pretty or follow whatever the best software-engineering standards are at the time of submission, but it should be *clear* (or at least *clearly described*)."
1156,@rasbt,2022-12-31 21:36:22+00:00,https://twitter.com/rasbt/status/1609302469372174338,"@AbhiRaama22 @ylecun They should of course read the paper, but they don't have to write a detailed review of the paper and theory.
The Journal of Open Source Software has good practices for reviewing repos even if they don't come with a research paper."
1157,@rasbt,2022-12-31 21:28:37+00:00,https://twitter.com/rasbt/status/1609300518580494337,"@TaiNguyen34 @ylecun Exactly. The editors should be finding 
a) 2 reviewers who check the paper, related work, and theory if applicable
b) 2 reviewers who check the code repo

a) and b) should not be the same reviewers because that would be way too much work for a reviewer to do both."
1158,@rasbt,2022-12-31 19:13:04+00:00,https://twitter.com/rasbt/status/1609266406901649408,"@ylecun I know it's all based on good faith that results in plots are correct. Still, sth I find baffling in 2022 is that no one is reviewing benchmark code.
There needs to be a better delagation of tasks among reviewers.
E.g., 
&gt;= 2 reviewers review text, 
&gt;= 2 reviewers check the repo"
1159,@rasbt,2022-12-31 17:36:19+00:00,https://twitter.com/rasbt/status/1609242059680153603,"@svpino It's definitely crazy how many computer vision papers are coming out each day! When I served as a machine learning moderator on arXiv from 2018 to 2020, we received a staggering 100 to 200 new machine learning papers EVERY SINGLE DAY. 
(But yeah, paper doesn't imply advancement.)"
1160,@rasbt,2022-12-31 16:10:36+00:00,https://twitter.com/rasbt/status/1609220485685907456,"@berman66 By offering a subscription for labeled, high-resolution training data I suppose üò£"
1161,@rasbt,2022-12-31 16:08:58+00:00,https://twitter.com/rasbt/status/1609220077458714624,@DrEliDavid üíØ
1162,@rasbt,2022-12-31 15:49:40+00:00,https://twitter.com/rasbt/status/1609215219137679360,"@bentossell Successful sequels: GPT-4, DALLE-3, AlphaFold 3, PyTorch 2"
1163,@rasbt,2022-12-31 15:43:25+00:00,https://twitter.com/rasbt/status/1609213646395305986,@akshay_pachaar Thanks for the compliments about the concise writing style &amp; good selection of topics! Glad to hear you liked my book!
1164,@rasbt,2022-12-31 15:02:56+00:00,https://twitter.com/rasbt/status/1609203456375406594,"@learn_byexample @bascodes The most fun one was ""Tomorrow, and Tomorrow, and Tomorrow"" by Gabrielle Zevin"
1165,@rasbt,2022-12-31 14:58:45+00:00,https://twitter.com/rasbt/status/1609202406616715266,Not even a deep learning model can keep up with it all üòÜ https://t.co/VNP3icFOsk
1166,@rasbt,2022-12-31 14:36:08+00:00,https://twitter.com/rasbt/status/1609196711922077698,"@thegautamkamath Totally agree. There must be lots of false positives. I can't see / don't want to believe it's been 22,000"
1167,@rasbt,2022-12-31 14:31:33+00:00,https://twitter.com/rasbt/status/1609195558052192258,"Sorry, I got too excited there. I didn't mean twenty-two-thousand-""factorial"" of course :P"
1168,@rasbt,2022-12-31 14:25:28+00:00,https://twitter.com/rasbt/status/1609194030385987590,@giffmana @XiaohuaZhai @__kolesnikov__ @_arohan_ @royaleerieme The best ever ResNet50? Better than ConvNeXt? You got my attention (no pun intended)
1169,@rasbt,2022-12-31 14:24:08+00:00,https://twitter.com/rasbt/status/1609193691607973890,@hardmaru Currently picking my top-3 for my end of the year review. It's never been harder to narrow it down to 3.
1170,@rasbt,2022-12-31 14:16:16+00:00,https://twitter.com/rasbt/status/1609191713515663360,"Fun fact: According to Google Scholar, researchers published about 22,000! vision transformer papers this year! https://t.co/aN8f40Dl0x"
1171,@rasbt,2022-12-30 18:51:02+00:00,https://twitter.com/rasbt/status/1608898473667227649,"@ItakGol Yes, but ViTs are relatively new, and I have more experience with CNNs :)."
1172,@rasbt,2022-12-30 18:47:44+00:00,https://twitter.com/rasbt/status/1608897641009778694,"@ItakGol If the ImageNet benchmarks in the MaxViT paper are to be believed, then yes. (Here, ConvNeXt is a fully-convolutional network) https://t.co/kutKlMMzQA"
1173,@rasbt,2022-12-30 18:45:03+00:00,https://twitter.com/rasbt/status/1608896966288904192,"@mohammad2012191 The best convolutional network I know of is ConvNeXt. But according to the MaxViT paper, vision transformers are now better on benchmark datasets like ImageNet (this includes classification, object detection, and instance segmentation)"
1174,@rasbt,2022-12-30 17:41:07+00:00,https://twitter.com/rasbt/status/1608880879899901954,"@LoriWitDaModelo Transformers (or attention layers in particular) offers a dynamic, data-specific pooling whereas MLP mixer is static."
1175,@rasbt,2022-12-30 17:30:43+00:00,https://twitter.com/rasbt/status/1608878260888424450,"@leonpalafox Which topic, vision transformers or visualizing neural network layers?"
1176,@rasbt,2022-12-30 17:23:37+00:00,https://twitter.com/rasbt/status/1608876473057959936,"That is, early layers capture edges and textures, and later layers learn more complex representations to capture broader concepts.

More analysis and insights in the paper: ""What do vision transformers learn? A visual exploration"" https://t.co/oa4hyZNbUr

2/2"
1177,@rasbt,2022-12-30 17:23:36+00:00,https://twitter.com/rasbt/status/1608876470524612609,"Vision transformers have taken the field of computer vision by storm, but what do vision transformers learn?

ViTs have fewer inductive biases than CNNs. However, it turns out that they learn inductive biases (or features) similar to CNNs!

1/2 https://t.co/CjUYgcPGbw"
1178,@rasbt,2022-12-30 16:19:24+00:00,https://twitter.com/rasbt/status/1608860314589884416,@HolgerFoysi Thanks for the support!
1179,@rasbt,2022-12-30 14:20:06+00:00,https://twitter.com/rasbt/status/1608830292130959360,"@soumithchintala Yup. My favorite peer review I received once started with the sentence ""This method looks too simple, almost like a trick."" 
(Duh, that's why it's so useful and why we wrote a paper about it. It outperformed more complicated methods, and I think that's worth knowing about.)"
1180,@rasbt,2022-12-30 13:06:10+00:00,https://twitter.com/rasbt/status/1608811684000595969,"@wonjun_y Thanks for sharing, it feels good to hear that these are useful! Happy New Year!"
1181,@rasbt,2022-12-30 13:05:46+00:00,https://twitter.com/rasbt/status/1608811582196420610,"@arielbosano Wow, reading my book more than once is one of the greatest compliments! Cheers!"
1182,@rasbt,2022-12-30 13:04:29+00:00,https://twitter.com/rasbt/status/1608811259784499201,"@perrabyte the book is available as a paperback, too, if that helps"
1183,@rasbt,2022-12-30 13:03:31+00:00,https://twitter.com/rasbt/status/1608811018662318082,"@RealColaBear Glad you liked the previous one! This is essentially the PyTorch edition of it. It also includes other bonus chapters, like the ones on graph neural networks and large language transformers"
1184,@rasbt,2022-12-30 03:32:14+00:00,https://twitter.com/rasbt/status/1608667249178734593,"@wightmanr @iamtrask @seb_ruder Thanks, super useful practical insights üëç
(PS: you mean that AdamW implementation in PyTorch doesn‚Äôt strictly follow the AdamW paper? I vaguely remember sth about that but it‚Äôs been way too long ago since I looked at the AdamW paper)"
1185,@rasbt,2022-12-30 01:40:19+00:00,https://twitter.com/rasbt/status/1608639084016308224,"@wightmanr @iamtrask @seb_ruder Nice! As a ballpark estimate, how often/much do you use weight decay (given that it's just one out of many weight regularization techniques). Is it something you find helpful for the majority of architectures?"
1186,@rasbt,2022-12-30 00:50:19+00:00,https://twitter.com/rasbt/status/1608626500684894208,"@nrln_phd @RylanSchaeffer @_arohan_ Also books!
https://t.co/gM6Nk7oF8F"
1187,@rasbt,2022-12-29 20:59:14+00:00,https://twitter.com/rasbt/status/1608568348920647683,"@tangming2005 Wow, thanks for the support! Hope you &amp; your colleagues will like it!"
1188,@rasbt,2022-12-29 20:35:22+00:00,https://twitter.com/rasbt/status/1608562340580175873,@hashiranhar I would say it‚Äôs a bit of both
1189,@rasbt,2022-12-29 17:38:02+00:00,https://twitter.com/rasbt/status/1608517712992411652,@chrisalbon Algorithms
1190,@rasbt,2022-12-29 16:32:18+00:00,https://twitter.com/rasbt/status/1608501171076874243,"@omarsar0 @dair_ai Wow congrats, that's a very exciting move and start into the new year!! ü•≥"
1191,@rasbt,2022-12-29 16:28:49+00:00,https://twitter.com/rasbt/status/1608500293632663552,"@allakky Honestly, it's all about practice. I.e., getting the fundamentals and then applying them. You don't have to  implement all the fundamentals from scratch, it's usually more about combining them. E.g. if you want to go from ResNet -&gt; DenseNet, no need to implement Adam from scratch"
1192,@rasbt,2022-12-29 16:27:44+00:00,https://twitter.com/rasbt/status/1608500023331016706,"@Frank37004246 @iamtrask @seb_ruder Nice, thanks for sharing. At first glance it looked like a type. Haven't heard of that one yet!"
1193,@rasbt,2022-12-29 15:07:52+00:00,https://twitter.com/rasbt/status/1608479925123555329,"To celebrate the new year, there's a temporary discount on my book ""Machine Learning with PyTorch and Scikit-Learn."" 

For a limited time, you can purchase the ebook for just $5, which is a 90% discount.

https://t.co/Pa2EgQPVEX"
1194,@rasbt,2022-12-29 14:53:07+00:00,https://twitter.com/rasbt/status/1608476213143654405,"Wow, between Substack and LinkedIn, Ahead of AI reached 20k subscribers!

20k!! This is both very motivating and flattering!

PS: issue #4 is just around the corner, with my top-5 papers in 2022 and some other fun stuff."
1195,@rasbt,2022-12-29 14:35:56+00:00,https://twitter.com/rasbt/status/1608471887096455168,@_krr12 @iamtrask @seb_ruder https://t.co/lWTCK3sBps
1196,@rasbt,2022-12-29 14:13:20+00:00,https://twitter.com/rasbt/status/1608466199872180226,"@RajmundnM @iamtrask @seb_ruder E.g., state-of-the-art computer vision models:
- ConvNeXt: https://t.co/4ZBTcMu6MB
- MaxViT: https://t.co/7B3BZiN3Uk"
1197,@rasbt,2022-12-29 14:09:55+00:00,https://twitter.com/rasbt/status/1608465341377552386,@roydanroy @kchonyc *and this was before everything was based on Electron
1198,@rasbt,2022-12-29 14:05:59+00:00,https://twitter.com/rasbt/status/1608464349949042690,"@iamtrask @seb_ruder Based on recent papers, AdamW seems to be all the rage now."
1199,@rasbt,2022-12-29 14:04:54+00:00,https://twitter.com/rasbt/status/1608464076283252736,@roydanroy @kchonyc Tbh 8 Gb was already too small back when I had a MacBook Air as a grad student ~2014
1200,@rasbt,2022-12-29 12:45:57+00:00,https://twitter.com/rasbt/status/1608444207445979136,@Joseph_Aribido Wow very impressive project! And thanks for the discussion &amp; sharing!
1201,@rasbt,2022-12-29 12:44:45+00:00,https://twitter.com/rasbt/status/1608443904914767873,@Joseph_Aribido Oh yeah totally agree. I was purely referring to inference; no training at all
1202,@rasbt,2022-12-29 12:43:15+00:00,https://twitter.com/rasbt/status/1608443530011082753,@aparimeya AFAIK yes. I think it would probably be more feasible to use BLOOM instead of PaLM for that. Or maybe the BLOOM researchers know more than we know üòÜ
1203,@rasbt,2022-12-29 12:41:09+00:00,https://twitter.com/rasbt/status/1608443001218498560,@SaleemUsama @PTrubey @NeuroTaha I think BLOOM was trained using sth like that
1204,@rasbt,2022-12-29 12:40:15+00:00,https://twitter.com/rasbt/status/1608442775909052416,@zaqlinguini It‚Äôs based on PaLM
1205,@rasbt,2022-12-29 12:39:09+00:00,https://twitter.com/rasbt/status/1608442498233384960,"@FractalFlows @ChristophMolnar Sounds like that person joined the dark side üò©.
But hey fwiw books can be cited too! ‚ò∫Ô∏è https://t.co/U9JmX1P2lN"
1206,@rasbt,2022-12-29 03:39:58+00:00,https://twitter.com/rasbt/status/1608306806773760000,@_lewtun Face PaLM ü§¶‚Äç‚ôÇÔ∏è
1207,@rasbt,2022-12-28 19:23:01+00:00,https://twitter.com/rasbt/status/1608181745815531520,@Joseph_Aribido There are diff. forms of quantization. I think casting to integers is most typical for increasing inference speeds. In my experience casting down to lower precision floats is of course common for mixed-precision training but I haven‚Äôt seen it commonly used for inference (vs ints)
1208,@rasbt,2022-12-28 19:17:53+00:00,https://twitter.com/rasbt/status/1608180455291097089,@mdredze @kchonyc Yeah. I feel like 16 GB is already almost too small these days.
1209,@rasbt,2022-12-28 18:55:35+00:00,https://twitter.com/rasbt/status/1608174843760984067,"@Nick_Davidov Yes, it‚Äôs mostly about balancing modeling performance and cost+latency at this point."
1210,@rasbt,2022-12-28 18:53:26+00:00,https://twitter.com/rasbt/status/1608174300711817220,"@nevmed I actually mostly read blog posts, papers, and books. Has higher information content and lets me focus better. Occasionally I watch talks, lecture videos, and movies but no other forms of short videos."
1211,@rasbt,2022-12-28 18:50:46+00:00,https://twitter.com/rasbt/status/1608173629925113857,@RylanSchaeffer @_arohan_ It‚Äôs the architecture and code for training it. It doesn‚Äôt come with pretrained weights.
1212,@rasbt,2022-12-28 16:11:57+00:00,https://twitter.com/rasbt/status/1608133663937495041,"Looks like the first open source equivalent of ChatGPT has arrived: https://t.co/4vQ83pcX2H

I.e., an implementation of RLHF (Reinforcement Learning with Human Feedback) on top of Google‚Äôs 540 billion parameter PaLM architecture"
1213,@rasbt,2022-12-28 15:59:02+00:00,https://twitter.com/rasbt/status/1608130412949262338,"@madmaxbr5 @vboykis Yes! I do think that learning the fundamentals is harder and more valuable long term. Was trying to say that if you know the fundamentals and one/some tool, it‚Äôs easy to pick up another tool. If you only know certain tools but not the fundamentals, it‚Äôs harder"
1214,@rasbt,2022-12-28 15:19:04+00:00,https://twitter.com/rasbt/status/1608120353632436230,@romcabrera That‚Äôs a very similar prompt. Lucky random seed I guess üòä. Btw the disclaimer doesn‚Äôt seem to do much besides this awkward last sentence at the bottom.
1215,@rasbt,2022-12-28 15:15:01+00:00,https://twitter.com/rasbt/status/1608119336601886723,"@romcabrera Yes, this looks a bit better. What was the prompt you used?"
1216,@rasbt,2022-12-28 14:55:14+00:00,https://twitter.com/rasbt/status/1608114356062912513,"@vboykis üíØ good statistics and engineering fundamentals first. If push comes to shove, you can always learn about the latest tool over the weekend"
1217,@rasbt,2022-12-28 14:50:55+00:00,https://twitter.com/rasbt/status/1608113268987420673,"@Abe_404 Thanks! Yes, related to your point: batching &amp; autoscaling are good additions. 
And caching like you mentioned below!"
1218,@rasbt,2022-12-28 14:28:54+00:00,https://twitter.com/rasbt/status/1608107727158484992,"@LukaszBorchmann yeah, maybe. At first glance, it just memorizes various approaches related to optimizing inference speeds. It 
a) either doesn't ""think"" about the constraints too hard
b) like you suggest, I need to phrase it/include the constraints differently."
1219,@rasbt,2022-12-28 13:45:20+00:00,https://twitter.com/rasbt/status/1608096767010131968,"Nope, ChatGPT is not ready to replace me yet üòÆ‚Äçüí® https://t.co/nDgQZFC8tQ"
1220,@rasbt,2022-12-27 20:25:46+00:00,https://twitter.com/rasbt/status/1607835148292132866,"@ahatamiz1 @themintsv For sure, it's impossible to read it all (and even just to bookmark &amp; track it all). The ""yearly top-papers list"" is just a small glimpse of my personal favorites -- a subset of papers I read this year, which is a tiny fraction of papers that came out this year."
1221,@rasbt,2022-12-27 20:21:18+00:00,https://twitter.com/rasbt/status/1607834026953564160,@ahatamiz1 @themintsv Totally missed that one. Looks like great work!
1222,@rasbt,2022-12-27 20:15:24+00:00,https://twitter.com/rasbt/status/1607832541146370052,"@ChristophR1996 @wightmanr That's a very nice, clean, and readable implementation. Thanks a lot for sharing!"
1223,@rasbt,2022-12-27 19:51:25+00:00,https://twitter.com/rasbt/status/1607826507233099777,"@ch4nd4n I think the newer versions provide SRT files directly now. Otherwise, there are lots of free online services that convert the .vtt files (that also have time stamps) into .srt.

Regarding multiple people speaking: haven't tried that one yet, but it probably works as well."
1224,@rasbt,2022-12-27 19:19:19+00:00,https://twitter.com/rasbt/status/1607818427691065344,@themintsv Purely convolutional nets ftw!
1225,@rasbt,2022-12-27 19:18:36+00:00,https://twitter.com/rasbt/status/1607818248304590849,"@karpathy Yup, 
- implement 1) 
- then add good unit tests &amp; compute benchmarks
- and then proceed to 2)"
1226,@rasbt,2022-12-27 19:17:26+00:00,https://twitter.com/rasbt/status/1607817951696269312,"@themintsv Out of curiosity, did you fine-tune or train from scratch?"
1227,@rasbt,2022-12-27 19:16:35+00:00,https://twitter.com/rasbt/status/1607817737501544450,"@themintsv Thanks for sharing! What would be your currently preferred go-to if there is one? CoAtNet, Swin, ConvNeXt, or something else?"
1228,@rasbt,2022-12-27 18:51:26+00:00,https://twitter.com/rasbt/status/1607811408334557184,"The local-global interaction between visual tokens is achieved via multi-axis attention, which can be decomposed into
1.  local attention (""block attention"")
2.  global attention (""grid attention"")
It scales linearly, not quadratically :)

Paper: https://t.co/7B3BZiN3Uk

2/2"
1229,@rasbt,2022-12-27 18:51:25+00:00,https://twitter.com/rasbt/status/1607811404333219840,"Compiling my yearly top-papers list, and
""MaxViT: Multi-axis Vision Transformer""
should probably make the cut.

It's vision transformer with local-global interaction between visual tokens within a single block that didn't get the proper attention it deserved (no pun intended)
1/2 https://t.co/toIk3Ym8V1"
1230,@rasbt,2022-12-27 18:47:24+00:00,https://twitter.com/rasbt/status/1607810395711979522,"@karpathy Super cool, and super important to distinguish between the  1) educational and 2) efficiency contexts. For teaching, I often try to find a balance/trade-off between the two, but I think it's better to focus on one or the other as you are trying to do."
1231,@rasbt,2022-12-27 17:13:13+00:00,https://twitter.com/rasbt/status/1607786693255434240,"@NormaPadron__ @KaelinHooper @OpenAI Yup, can confirm. Even when I mentioned that it could write their Highschool homework essays &amp; college application essays they were totally unimpressed"
1232,@rasbt,2022-12-27 14:57:07+00:00,https://twitter.com/rasbt/status/1607752444007809026,"@chrisalbon they ""code things"""
1233,@rasbt,2022-12-27 14:35:20+00:00,https://twitter.com/rasbt/status/1607746959057752066,If you are looking for a fun event after holidAIs üëá
1234,@rasbt,2022-12-27 12:18:07+00:00,https://twitter.com/rasbt/status/1607712429752082432,"@TheFucking22 It‚Äôs a way for including domain knowledge, and I suppose it can thus help reduce overfitting"
1235,@rasbt,2022-12-27 03:05:37+00:00,https://twitter.com/rasbt/status/1607573385990520832,@Falkris_ @sh_reya I think that‚Äôs about right
1236,@rasbt,2022-12-27 03:04:41+00:00,https://twitter.com/rasbt/status/1607573150623047682,"@az_mtl @svpino Actually, I think the Hello World of GNNs is the GCN on a/the molecular toxicity dataset üòÖ"
1237,@rasbt,2022-12-27 03:03:10+00:00,https://twitter.com/rasbt/status/1607572770463879168,@madhavjha I haven‚Äôt curated a reading list on transformers. I have been reading most papers in chronological order as they were published which wasn‚Äôt too bad. Btw I have a chapter on the key architecture concepts in my ML with PyTorch and Scikit-Learn book which might be helpful.
1238,@rasbt,2022-12-26 19:58:05+00:00,https://twitter.com/rasbt/status/1607465797240201223,"@svpino The ""Hello World""s of machine learning:

2015: RandomForestClassifier on Iris
2017: MLP on MNIST
2019: AlexNet on Cifar-10
2022: DistilBERT on IMDb movie reviews"
1239,@rasbt,2022-12-26 18:51:25+00:00,https://twitter.com/rasbt/status/1607449016232542208,"@madhavjha Check out the thread below for the key default difference.
Regarding which one to use in practice. Your mileage will vary depending on the project. HistGradientBoostingClassifier is a great, easy to use implementation that I recommend.

https://t.co/S0AaZVES32"
1240,@rasbt,2022-12-26 18:23:13+00:00,https://twitter.com/rasbt/status/1607441919382278145,"I.e., HistGradientBoostingClassifier now supports

1.  interaction constraints (in trees, features that appear along a particular path are considered as ""interacting"")
2.  class weights
3.  feature names for categorical features

2/2"
1241,@rasbt,2022-12-26 18:23:12+00:00,https://twitter.com/rasbt/status/1607441916534329344,"Scikit-learn 1.2 is out: https://t.co/w9Zw0096a8

Was an eventful December &amp; I totally missed the new release of my favorite ML lib

My personal highlights are around the HistGradientBoostingClassifier (if you haven't used it yet, it's a LightGBM impl that works really well)

1/2"
1242,@rasbt,2022-12-26 17:12:39+00:00,https://twitter.com/rasbt/status/1607424160753504256,@zacharylipton To maintain the 32.5 hour work week plus commuting
1243,@rasbt,2022-12-25 22:13:44+00:00,https://twitter.com/rasbt/status/1607137546588532737,"@moyix Nice!! Merry Christmas!

PS: My all time favorite one was: ‚Äúsigned up for a 3 credit point class that taught me knowledge worth of 10‚Äù ‚ò∫Ô∏è"
1244,@rasbt,2022-12-25 22:05:39+00:00,https://twitter.com/rasbt/status/1607135508844478465,"@heikkiarponen @somehowicode Hah, yeah, which is in turn why BatchNorm helps (due to centering the net inputs)"
1245,@rasbt,2022-12-25 21:59:49+00:00,https://twitter.com/rasbt/status/1607134042159288320,"@heikkiarponen @somehowicode You have a good point. To add to the scaling argument: the tanH activation function is preferred over the logistic sigmoid, because it is a rescaled version with larger gradients https://t.co/t5sZgZyIv7"
1246,@rasbt,2022-12-25 19:59:00+00:00,https://twitter.com/rasbt/status/1607103638878535680,@iamtrask I can‚Äôt believe it slipped through my reading pile cracks so far! Looks awesome!
1247,@rasbt,2022-12-25 19:55:00+00:00,https://twitter.com/rasbt/status/1607102629431377920,"@burkov I just think it‚Äôs easier to add a ChatGPT-style LLM to Google Search than building a search engine-grade infrastructure around ChatGPT, but we will see :)"
1248,@rasbt,2022-12-25 19:14:47+00:00,https://twitter.com/rasbt/status/1607092509540323328,@burkov I would say that it definitely lacks the infrastructure to serve customers with low latency at scale. I see it more like ‚ÄúDecoder-style LLMs pose a threat to traditional search‚Äù  (whereas traditional search also already employs encoder-style LLMs)
1249,@rasbt,2022-12-25 19:02:15+00:00,https://twitter.com/rasbt/status/1607089355872428034,"@somehowicode Yup. And since the derivative is ‚Äúsigmoid(x) * (1-sigmoid(x))‚Äù the derivative is maximally 0.25, which will eventually cause weak signals in backprop (and vanishing gradient problems) and slow learning"
1250,@rasbt,2022-12-25 15:27:18+00:00,https://twitter.com/rasbt/status/1607035261720088576,"@MatejKorvin @arnabbiswas1 And I totally agree that the chapters on (or last 100 years) were totally meh. I didn‚Äôt care for those, and the AI chapter was really bad as far as I recall. But that‚Äôs what I almost always feel when reading AI-related things by a person who doesn‚Äôt work in the field."
1251,@rasbt,2022-12-25 15:24:49+00:00,https://twitter.com/rasbt/status/1607034637037236224,"@MatejKorvin @arnabbiswas1 I found that it described the origin story of humans, from the Stone Age to ancient Egypt, in a very interesting  way. Maybe it was how it cherry picked highlights and illustrations, but somehow it was more interesting than the history books I had to read in school."
1252,@rasbt,2022-12-24 18:17:32+00:00,https://twitter.com/rasbt/status/1606715714521407489,@WalterReade @arnabbiswas1 @hemanath1712 I honestly don‚Äôt recall that part of the book at all
1253,@rasbt,2022-12-24 18:08:59+00:00,https://twitter.com/rasbt/status/1606713563329994757,@roydanroy Was in Milan earlier this year and it was probably the best food I ever had
1254,@rasbt,2022-12-24 18:04:31+00:00,https://twitter.com/rasbt/status/1606712437851541504,"@11Gunz Depends a bit how/what you pickle. If you used gs=GridSearchCV(‚Ä¶), used it to find the best hyperparameters etc, the you can access the best pipeline via gs. best_estimator_ for pickling"
1255,@rasbt,2022-12-24 17:22:50+00:00,https://twitter.com/rasbt/status/1606701951030370306,"@11Gunz GridSearchCV, RandomizedSearcCV etc refit on the whole training dataset &amp; retain the best model"
1256,@rasbt,2022-12-24 17:21:16+00:00,https://twitter.com/rasbt/status/1606701556249788417,"@ericwastl Exactly. I initially thought there would be reminder emails for those people how signed up, haha. Totally forgot to check back the website."
1257,@rasbt,2022-12-24 16:46:35+00:00,https://twitter.com/rasbt/status/1606692827840532486,PPS: some ‚ÄúL04: Linear algebra and calculus for deep learning‚Äù videos I recorded: https://t.co/Z6b05HeOfh
1258,@rasbt,2022-12-24 16:45:12+00:00,https://twitter.com/rasbt/status/1606692476999192576,"PS: as little bonus, 4 short videos on linear algebra basics in a PyTorch context: https://t.co/UkNdATV2Sn"
1259,@rasbt,2022-12-24 15:32:35+00:00,https://twitter.com/rasbt/status/1606674205256335361,@zr_zona @arnabbiswas1 Here are some I read this year
1260,@rasbt,2022-12-24 15:09:06+00:00,https://twitter.com/rasbt/status/1606668292818489344,@guysnovelutumba Not yet not yet. The notes were a bit rough(er) and I need to flesh them out a bit more
1261,@rasbt,2022-12-24 15:07:33+00:00,https://twitter.com/rasbt/status/1606667905860571138,"@Adan265 Yeah, the drafts were a bit less fleshed out and they need some more polishing."
1262,@rasbt,2022-12-24 15:06:51+00:00,https://twitter.com/rasbt/status/1606667729498509317,@guysnovelutumba Always working on sth üôÑ. Can‚Äôt say the year though ‚Äî going with a ‚Äúwhen it‚Äôs done‚Äù philosophy instead of deadlines this time :)
1263,@rasbt,2022-12-24 15:00:07+00:00,https://twitter.com/rasbt/status/1606666033296998400,"Started a Mathematics for Machine Learning book many years ago that evolved into an appendix for another book I was working on at the time (around 2018).

I just rediscovered my notes &amp; it might be a fun thing to o pick up over the break.

https://t.co/R3B1AH6DdE

Happy Holidays!"
1264,@rasbt,2022-12-24 14:53:49+00:00,https://twitter.com/rasbt/status/1606664450022440969,@elonmusk @tobi But you can‚Äôt bring a Tesla on an airplane since it exceeds the allowed 100-watt-hour limit
1265,@rasbt,2022-12-24 14:48:41+00:00,https://twitter.com/rasbt/status/1606663157879013376,@rogue_hci Exactly. I think this is the implementation that makes most sense (and is probably also the quickest one to implement)
1266,@rasbt,2022-12-24 14:42:23+00:00,https://twitter.com/rasbt/status/1606661571459137539,"If you can‚Äôt decide whether ChatGPT should replace traditional web search, just have them side by side."
1267,@rasbt,2022-12-24 14:17:19+00:00,https://twitter.com/rasbt/status/1606655260902178817,"@arnabbiswas1 No machine-learning related books? ü•≤

Btw I also read Sapiens (this year) and really liked it."
1268,@rasbt,2022-12-24 14:12:50+00:00,https://twitter.com/rasbt/status/1606654134345687043,@GiorgioMantova @sh_reya Yup. And the same goes for college application essays
1269,@rasbt,2022-12-24 12:26:45+00:00,https://twitter.com/rasbt/status/1606627437189730305,"@csaba_kissi Writing, including writing about coding"
1270,@rasbt,2022-12-24 12:23:04+00:00,https://twitter.com/rasbt/status/1606626508776148992,@ericwastl I signed up some time in November but never got the reminder email on the first of December and then totally missed it üò¢
1271,@rasbt,2022-12-24 12:17:15+00:00,https://twitter.com/rasbt/status/1606625044863619073,@thatroblennon ‚ÄúDepends on your audience‚Äù
1272,@rasbt,2022-12-24 11:44:44+00:00,https://twitter.com/rasbt/status/1606616862783000576,@TheJackForge Wouldn‚Äôt have happened if you used @1Password instead of Password1
1273,@rasbt,2022-12-24 03:01:39+00:00,https://twitter.com/rasbt/status/1606485226624106498,"@pafmer1 Yeah, things are hit &amp; miss. Take Android and Stadia. But speaking as an academic &amp; researcher, lots of hypotheses don't amount to anything useful before you find that one thing that works really well üòÜ"
1274,@rasbt,2022-12-24 02:59:30+00:00,https://twitter.com/rasbt/status/1606484684560629760,"@osoleve @sh_reya Yes, I think it is analogous to search engines. In the early days, you had to be really careful about the input formatting (we even had cheatsheets). Now, you can even have 30% typos and it doesn't matter."
1275,@rasbt,2022-12-23 22:24:55+00:00,https://twitter.com/rasbt/status/1606415582462623748,"@rogue_hci @tobias_rees Yeah, there are certainly some ‚Äúif all you have is a hammer, everything looks like a nail‚Äù-type applications"
1276,@rasbt,2022-12-23 19:40:30+00:00,https://twitter.com/rasbt/status/1606374206479994893,"@KyleCranmer Hah, would have liked to see it at -22F this morning :P"
1277,@rasbt,2022-12-23 18:08:18+00:00,https://twitter.com/rasbt/status/1606351002507935744,@NormaPadron__ @Yale @DukeEcon Happy birthday I guess ?! üéâ üòä
1278,@rasbt,2022-12-23 17:48:53+00:00,https://twitter.com/rasbt/status/1606346115384836096,@osoleve @sh_reya Might be a short term thing. I don‚Äôt think it‚Äôs going to be that relevant in the upcoming years as prompt parsing and encoding improves
1279,@rasbt,2022-12-23 17:33:00+00:00,https://twitter.com/rasbt/status/1606342118267654149,@mrtj120 definitely missed this one. thanks!
1280,@rasbt,2022-12-23 17:30:50+00:00,https://twitter.com/rasbt/status/1606341573624492032,"@Nofollo84908800 either ""something"" or ""south"" depending on the context"
1281,@rasbt,2022-12-23 17:27:35+00:00,https://twitter.com/rasbt/status/1606340758721761286,@sh_reya High school students are going to be the most experienced prompt engineers; they will be in high demand for employment at tech companies.
1282,@rasbt,2022-12-23 17:18:17+00:00,https://twitter.com/rasbt/status/1606338417398353933,"@ylecun @tobias_rees I think the problem is the communication of these objectively beneficial technologies. It's typically always about ""beating"" &amp; ""replacing"" previous efforts instead of ""helping with"""
1283,@rasbt,2022-12-23 17:16:35+00:00,https://twitter.com/rasbt/status/1606337988102950933,"@tobias_rees I think this is mostly owed to a particular type of arrogance when it comes to ""marketing"" said AI advances. 
And also the ""Hey, we never worked in field X, but we just developed this AI that is 10x better than you domain experts who devoted your life to working on X. See ya."""
1284,@rasbt,2022-12-23 16:57:06+00:00,https://twitter.com/rasbt/status/1606333086211493889,@guysnovelutumba Glad to hear you liked it :)!
1285,@rasbt,2022-12-23 16:54:40+00:00,https://twitter.com/rasbt/status/1606332472978915328,"@shawntsullivan Yes! I have a daily habit list, and 30 min of study is usually my daily minimum :)"
1286,@rasbt,2022-12-23 16:53:41+00:00,https://twitter.com/rasbt/status/1606332225061916676,"@gisblog yes, intent &amp; motivation are very important :)"
1287,@rasbt,2022-12-23 16:36:15+00:00,https://twitter.com/rasbt/status/1606327836637216768,@siggibecker Twentysomethings ‚Äî I wish üòÖ
1288,@rasbt,2022-12-23 16:35:00+00:00,https://twitter.com/rasbt/status/1606327525675864066,"@silent_soul_1 Yup, and there‚Äôs no turning back"
1289,@rasbt,2022-12-23 16:34:34+00:00,https://twitter.com/rasbt/status/1606327413348175874,@guysnovelutumba Yeah. I actually enjoy learning (a bit) everyday as my daily habit/ritual :)
1290,@rasbt,2022-12-23 16:29:47+00:00,https://twitter.com/rasbt/status/1606326211478593538,"@DataScienceHarp @naval @joerogan Personally, I studied biology as an undergrad before I got into stats and then machine learning. It‚Äôs been a fun ride so far :)"
1291,@rasbt,2022-12-23 16:25:09+00:00,https://twitter.com/rasbt/status/1606325043495149568,"@guysnovelutumba Deleted it coz I found it in my personal notebook and am not sure anymore if that was my one quote or someone else‚Äôs that I read somewhere. 

Googled it and didn‚Äôt find any matches but I am not üíØ sure. Don‚Äôt want to accidentally take credit for someone else‚Äôs quote."
1292,@rasbt,2022-12-23 16:16:02+00:00,https://twitter.com/rasbt/status/1606322749995106304,"In 10 years, the world will be very different from today.

Once upon a time, it was okay to learn sth in school &amp; then apply it for the rest of your life. 

Today, to keep up and thrive with the rapid pace of change, it's pivotal to keep reinventing yourself and to keep learning."
1293,@rasbt,2022-12-23 15:39:41+00:00,https://twitter.com/rasbt/status/1606313604155850752,"@pafmer1 ‚ÄúThe core product has remained unchanged for 15 years!!!‚Äù -&gt; Or take airlines, the core product hasn‚Äôt changed in like 50 years."
1294,@rasbt,2022-12-23 14:58:38+00:00,https://twitter.com/rasbt/status/1606303272066768897,@TaliaRinger Streisand effect and self-fulfilling prophecy I guess?! üòÜ
1295,@rasbt,2022-12-23 14:57:16+00:00,https://twitter.com/rasbt/status/1606302927890526210,"@TaliaRinger Plot twist, it‚Äôs not everyone but Google themselves who think ChatGPT is a thread to Search"
1296,@rasbt,2022-12-23 02:43:55+00:00,https://twitter.com/rasbt/status/1606118375859568640,@VitruviusSuper @TheSeaMouse Yup. Or even the beginning of the internet when we had to use search engines like this (random find in my parents basement last summer) https://t.co/jKaGwXPOca
1297,@rasbt,2022-12-23 02:40:37+00:00,https://twitter.com/rasbt/status/1606117543013339137,@natfriedman Yup. Lots of low-hanging fruit &amp; compute
1298,@rasbt,2022-12-23 02:37:29+00:00,https://twitter.com/rasbt/status/1606116754165338113,"@VitruviusSuper @TheSeaMouse Totally agree. They were using LLMs (ie BERT) for encoding queries a while back to try to improve that ‚Äî maybe they still do. But yeah, I know what you mean, it‚Äôs not perfect"
1299,@rasbt,2022-12-23 02:11:19+00:00,https://twitter.com/rasbt/status/1606110172245639168,"I wasn‚Äôt suggesting the ChatGPT *should* replace Google Search. 

But some people were saying that ChatGPT wasn‚Äôt even a discussion topic for Search.

Well here you have it now üôÉ 

https://t.co/u9Lnf1kIEd https://t.co/ygiFUz4PPr"
1300,@rasbt,2022-12-22 22:29:53+00:00,https://twitter.com/rasbt/status/1606054444214255617,"@AI_Sensei_ Yap, it‚Äôs all open source. In fact you can run it all locally if you skip the ‚Äú‚Äîcloud‚Äù flag"
1301,@rasbt,2022-12-22 22:05:21+00:00,https://twitter.com/rasbt/status/1606048273004761090,"@AI_Sensei_ Based on the paper, I recall it's slightly worse than GPT-3. It's definitely not on the level of Chinchilla. 
But yeah, the goal here was to show how to fine-tune a model on the cloud on a multi-GPU cluster in just ~90 lines of code üòä https://t.co/R4mlabulIr"
1302,@rasbt,2022-12-22 22:00:39+00:00,https://twitter.com/rasbt/status/1606047089875570689,"I know you all can't wait to fine-tune your LLMs over the holiday break! We just added a template that gets you started. 
E.g., copy and paste the code from the website here to fine-tune a 3-billion param BLOOM model on a multi-node GPU cluster: https://t.co/U1SRtfrs8h https://t.co/ktYFDBH9AP"
1303,@rasbt,2022-12-22 21:51:39+00:00,https://twitter.com/rasbt/status/1606044824573861888,@sGx_tweets @aniketmaurya whoa üòä
1304,@rasbt,2022-12-22 19:40:09+00:00,https://twitter.com/rasbt/status/1606011731674701824,"@technotweet @MehradAnsari @JOSS_TheOJ Not a rigorous code review or replication of results. More like checking that the material is clear enough, in terms of instructions and organization, that someone can reproduce the results (if desired)."
1305,@rasbt,2022-12-22 19:38:42+00:00,https://twitter.com/rasbt/status/1606011367516880896,"@DSaience @MehradAnsari Oh yes, you are totally right. I didn't mean fully replicating the results but more like checking that someone could use the code. E.g., making sure everything is there, well-documented, and can be run (if hardware is available)"
1306,@rasbt,2022-12-22 19:17:20+00:00,https://twitter.com/rasbt/status/1606005987105570816,"@technotweet @MehradAnsari @JOSS_TheOJ It doesn't necessarily mean an extra burden for the reviewers. Just have separate paper content reviewers and code-health reviewers. This way, an individual reviewer doesn't have to do extra work."
1307,@rasbt,2022-12-22 19:16:01+00:00,https://twitter.com/rasbt/status/1606005657940869120,"@technotweet @MehradAnsari Hm, maybe, but then you will end up with rigorous, and not so rigorous journals. I think the code test/review part should be done by any journal if the paper comes with code. For example @JOSS_TheOJ also does that and it doesn't charge any fees."
1308,@rasbt,2022-12-22 18:31:34+00:00,https://twitter.com/rasbt/status/1605994469525962752,"@peter_richtarik @MehradAnsari Yes, and I feel like it gets worse by the year"
1309,@rasbt,2022-12-22 18:20:09+00:00,https://twitter.com/rasbt/status/1605991598109495297,@MehradAnsari I would go a step further and say that it‚Äôs 2022 &amp; journals should review/test the open source code that comes with a paper.
1310,@rasbt,2022-12-22 17:01:27+00:00,https://twitter.com/rasbt/status/1605971793235378176,@TheZachMueller of course üòä
1311,@rasbt,2022-12-22 16:36:03+00:00,https://twitter.com/rasbt/status/1605965401375920132,"@fedezanetti @yu_angela I think I read that like 2 years ago.  It's a good one. 
What I got out from it was that it
a) confirmed that time-boxing is a good approach
b) that I should pick a ""focus"" for the day"
1312,@rasbt,2022-12-22 16:35:18+00:00,https://twitter.com/rasbt/status/1605965210853855246,@deepakns @yu_angela That's the $1M dollar question ...
1313,@rasbt,2022-12-22 14:13:59+00:00,https://twitter.com/rasbt/status/1605929648411533312,"@ntkris I use @LightningAI for deployment. I have a bottom-up tutorial here if you are interested: https://t.co/LKeu5ELrVW

And here are blog posts on deploying things like 

- Stable Diffusion: https://t.co/Mulqo308Th

- OpenAI‚Äôs Whisper: https://t.co/Ft6LvNK2AA"
1314,@rasbt,2022-12-22 13:28:47+00:00,https://twitter.com/rasbt/status/1605918271911387137,"@ntkris For my deep learning projects I use both 
- notebooks (for analysis) and 
- .py scripts (for submitting/running code)

I have a template for my typical deep learning workflow in the README here: https://t.co/11IzzyfsCz"
1315,@rasbt,2022-12-22 12:41:03+00:00,https://twitter.com/rasbt/status/1605906258946555905,@asywahd @yu_angela This helps but is far from perfect: https://t.co/KLKfnEXyKj
1316,@rasbt,2022-12-22 12:35:27+00:00,https://twitter.com/rasbt/status/1605904852894130176,"Same, having too many browser tabs open makes me anxious. 
That‚Äôs why I am using JupyterLab over Jupyter Notebook üôÉ"
1317,@rasbt,2022-12-22 12:33:36+00:00,https://twitter.com/rasbt/status/1605904386000969729,@yu_angela I want to learn to become better at saying No and stay more focused so that I can learn more things more efficiently üòä
1318,@rasbt,2022-12-22 12:32:15+00:00,https://twitter.com/rasbt/status/1605904047873167360,@moyix It‚Äôs actually quite nice. Started using it 1 or 2 years ago as a Doodle &amp; WhenIsGood replacement for 1-on-1 meetings.
1319,@rasbt,2022-12-22 11:31:09+00:00,https://twitter.com/rasbt/status/1605888669084180482,@mrtj120 I have such a big pile of papers I bookmarked ‚Ä¶ I maybe missed it. Would appreciate a link ‚ò∫Ô∏è
1320,@rasbt,2022-12-22 11:29:47+00:00,https://twitter.com/rasbt/status/1605888325981798400,"@CSatisficer @chrisalbon Yup, pre-trained with self-supervised learning, followed by human-in-the-loop reinforcement learning. Also requires lots of prompt engineering."
1321,@rasbt,2022-12-22 11:20:23+00:00,https://twitter.com/rasbt/status/1605885958259412996,"@Kaszanas I tried to keep everything nice &amp; concise, so in the worst case it shouldn‚Äôt take you too much time to find out :P"
1322,@rasbt,2022-12-22 03:25:11+00:00,https://twitter.com/rasbt/status/1605766372696301568,@chrisalbon Basically like getting a puppy
1323,@rasbt,2022-12-22 02:55:17+00:00,https://twitter.com/rasbt/status/1605758846550646784,"@JJitsev @irinarish Sure, Chinchilla is another level, but there is BLOOM for example, which has GPT-3-type quality."
1324,@rasbt,2022-12-22 02:32:48+00:00,https://twitter.com/rasbt/status/1605753190783369222,"@JJitsev @irinarish True, but on the other hand, given carbon footprints of those models, is it really worth it to waste those resources on just rerunning/training an existing LLM again? But then again, it does make sense as part of establishing a baseline / testing your compute framework"
1325,@rasbt,2022-12-22 02:29:37+00:00,https://twitter.com/rasbt/status/1605752387129544706,"@cwizprod1 No worries, please feel free to ask away!"
1326,@rasbt,2022-12-22 01:27:14+00:00,https://twitter.com/rasbt/status/1605736688256311296,"@cwizprod1 Yes! Not many questions so far yet, but I think that's because the first units are still more of an intro. It will get more interesting as we are advancing to the later units :)"
1327,@rasbt,2022-12-22 01:19:22+00:00,https://twitter.com/rasbt/status/1605734707475488769,"@cwizprod1 wohoo, thanks! Also, we have the discussion board on GitHub (https://t.co/FdLUDTrNFs) if anyone has any questions about the contents. More than happy to clarify things!"
1328,@rasbt,2022-12-22 01:15:59+00:00,https://twitter.com/rasbt/status/1605733858971828224,"@cwizprod1 Thanks so much, it feels really good to hear this üòä"
1329,@rasbt,2022-12-21 19:13:36+00:00,https://twitter.com/rasbt/status/1605642662727614465,"@jmschreiber91 As a kid, I built my own bow and it was 10x worse than the composite bows they sell in the store. Maybe you were holding it wrong."
1330,@rasbt,2022-12-21 18:26:30+00:00,https://twitter.com/rasbt/status/1605630809871773696,"@PABLO_LEWIN @LordGiustiniani No, I haven't heard anything (or maybe missed it)"
1331,@rasbt,2022-12-21 18:02:09+00:00,https://twitter.com/rasbt/status/1605624681947664385,"The focus of this one is on

- computation graphs
- full-batch vs stochastic gradient descent
- automatic differentiation
- the PyTorch API

Covering all the foundations before we'll dive deeper into multilayer neural networks in Unit 4! https://t.co/yhVW4qPTdB"
1332,@rasbt,2022-12-21 18:00:29+00:00,https://twitter.com/rasbt/status/1605624262273880065,"Btw. if you have any questions as you are taking the course don't hesitate to reach out, I am always excited to chat more about deep learning üòä"
1333,@rasbt,2022-12-21 17:48:26+00:00,https://twitter.com/rasbt/status/1605621226910519296,"Thanks for all the positive feedback on my new, free deep learning course!

Happy to share that Unit 3 is now live!

Math can be fun. But let's be honest, who doesn't like the convenience of automatic differentiation üòä

üëâ Unit 3: https://t.co/baqlnx1caq

Enjoy the holidays! https://t.co/jWYQqAxCS5"
1334,@rasbt,2022-12-21 17:44:28+00:00,https://twitter.com/rasbt/status/1605620231665176576,"@DataScienceHarp It's tough, but sometimes you need to let the old things die to make room for new things"
1335,@rasbt,2022-12-21 17:38:49+00:00,https://twitter.com/rasbt/status/1605618807577378820,"@DataScienceHarp Tricky question! I would say that it's a bit about following what you are passionate about, and that you can learn almost anything if you are passionate about it."
1336,@rasbt,2022-12-21 16:01:25+00:00,https://twitter.com/rasbt/status/1605594296312176642,"@varshneygk @suprabhasupi Oh I see. Sounds like a lot of hassle. Personally, I used (and still use) conda-forge for many years because the packages are usually more up to date then the anaconda ones. Plus, I find that they sometimes handle complex dependencies and requirements better than pip."
1337,@rasbt,2022-12-21 15:49:00+00:00,https://twitter.com/rasbt/status/1605591171111129089,"@varshneygk @suprabhasupi As far as I remember, this was/is only for packages in the Anaconda repo but not conda itself. If you use conda with the conda-forge channel or miniforge this wouldn't apply afaik."
1338,@rasbt,2022-12-21 15:43:12+00:00,https://twitter.com/rasbt/status/1605589711094849536,"@varshneygk @suprabhasupi Conda has a BSD3 license, which permits commercial use afaik. You can check it here: https://t.co/BUETtzRWEJ https://t.co/1qe8njCDDE"
1339,@rasbt,2022-12-21 15:37:41+00:00,https://twitter.com/rasbt/status/1605588325661917184,"@varshneygk @suprabhasupi I think Apache 2.0 is fine (other popular projects like TensorFlow use it as well). 
Conda is licensed under BSD3 which is also fine (that's what I personally use, and what other popular libraries like scikit-learn use)"
1340,@rasbt,2022-12-21 15:07:54+00:00,https://twitter.com/rasbt/status/1605580828565680128,"@irinarish Training an open source model would be a nice reproducibility study, but it would be more interesting to try sth new. Ie developing a new model or applying an existing model to a new domain. Like applying a recent open source LLM to protein sequence data (like ProtBERT)"
1341,@rasbt,2022-12-21 14:31:57+00:00,https://twitter.com/rasbt/status/1605571780067749888,"A reinventing specialist ^^. That is, focusing on something intensely, and then moving to the next thing when it gets too boring."
1342,@rasbt,2022-12-21 13:20:43+00:00,https://twitter.com/rasbt/status/1605553856103845888,@suprabhasupi PyScript :)
1343,@rasbt,2022-12-21 13:10:02+00:00,https://twitter.com/rasbt/status/1605551168419160072,@douglaskarr Oh I agree with you. I think people would pay for it. I meant more that I don‚Äôt think Google will introduce a basic vs premium search. It would rather find a solution that somewhat works well for everyone (with ads).
1344,@rasbt,2022-12-21 13:04:28+00:00,https://twitter.com/rasbt/status/1605549765399175168,@wwwojtekk @roydanroy Burgers
1345,@rasbt,2022-12-21 13:03:13+00:00,https://twitter.com/rasbt/status/1605549449337376769,@andruyeung @roydanroy One of the most beautiful places I visited https://t.co/46zFaMaWPI
1346,@rasbt,2022-12-21 13:01:46+00:00,https://twitter.com/rasbt/status/1605549087356600320,@andruyeung @roydanroy Have been visiting twice when I was a student and liked it! One of the perks was that it was only 1 1/2 drive to the Niagara Falls :)
1347,@rasbt,2022-12-21 03:51:46+00:00,https://twitter.com/rasbt/status/1605410672518615041,@_nateraw And latex math please!
1348,@rasbt,2022-12-21 03:14:55+00:00,https://twitter.com/rasbt/status/1605401400627892225,"@jukebapes I agree with you. There seem to be a lot of people talking about ChatGPT as the next-gen search engine. I think it originated as a fun, hyperbolic comparison. But then it somehow started to become a serious conversation."
1349,@rasbt,2022-12-21 00:53:34+00:00,https://twitter.com/rasbt/status/1605365830040309760,@Bsunter @arpagon Thanks for the recommendation @arpagon &amp; I am curious to hear what you think @Bsunter once you got a chance to check it out
1350,@rasbt,2022-12-20 22:25:23+00:00,https://twitter.com/rasbt/status/1605328535211888640,"While there‚Äôs nothing wrong with it, I can‚Äôt see Google working on a premium/paid tier for advanced search via a ChatGPT-like model. 

Just doesn‚Äôt fit their history and brand. 

They are more likely working on a DistilChatGPT/DistilLambda version for the current free tier."
1351,@rasbt,2022-12-20 20:18:40+00:00,https://twitter.com/rasbt/status/1605296646170071062,@jeremyphoward Sure sure. Just curious if it will be more like &lt;90% acc or whether they are above the 90% threshold
1352,@rasbt,2022-12-20 19:22:53+00:00,https://twitter.com/rasbt/status/1605282607658373120,"@jeremyphoward YMMV of course, but here are a few numbers from ""Fine-Tuning DARTS for Image Classification"" https://t.co/qfTZXxMINJ. Not 20 epochs of course, but might be interesting to try out these methods and see what happens when trained for 20 epochs. https://t.co/cTVHugUfm1"
1353,@rasbt,2022-12-20 17:49:01+00:00,https://twitter.com/rasbt/status/1605258987666288640,"@z3nmaster9 Yup! That's exactly what I meant with ""They already started doing that years ago."" :). I think it's for encoding the queries though. Not sure what they use for generating the Q&amp;A responses that are sometimes features at the top of the search results."
1354,@rasbt,2022-12-20 17:47:18+00:00,https://twitter.com/rasbt/status/1605258557074571265,"@justinjoboyle @ntkris @Neeva That's a nice write-up! And yes, @justinjoboyle, I meant even  if Google hosted ChatGPT (or an equivalent) themselves, it would be prohibitively expensive to use that on all their search queries (esp if you want to minimize the delay &amp; processing time)."
1355,@rasbt,2022-12-20 17:45:41+00:00,https://twitter.com/rasbt/status/1605258150441287681,"@BodzionyRafal Hah, pls, no! But it's either that or a premium-tier subscription model. The latter gives me a choice at least :P"
1356,@rasbt,2022-12-20 15:00:29+00:00,https://twitter.com/rasbt/status/1605216576365551618,@unsorsodicorda Interesting use case! Haven‚Äôt tried it yet. ü§î
1357,@rasbt,2022-12-20 14:52:32+00:00,https://twitter.com/rasbt/status/1605214573753237508,"@IntuitMachine @aidan_mclau Agreed. I know for a fact that Google already uses transformers for their search. And yes, you also get that selective behavior depending on the query"
1358,@rasbt,2022-12-20 14:32:50+00:00,https://twitter.com/rasbt/status/1605209614081224705,@aidan_mclau @IntuitMachine And way fewer queries
1359,@rasbt,2022-12-20 14:21:16+00:00,https://twitter.com/rasbt/status/1605206706249662464,"@TheSeaMouse I think that‚Äôs smart to point to the website directly in this case, because you probably need to be signed in and/or policies and UIs change (and it would be infeasible to update the LLM continuously on all website changes)"
1360,@rasbt,2022-12-20 14:13:53+00:00,https://twitter.com/rasbt/status/1605204845664911360,@TheSeaMouse Hm but didn‚Äôt they already have that on the top of the search results for years? No digging through links and ads here: https://t.co/UAFIPORZJO
1361,@rasbt,2022-12-20 14:09:18+00:00,https://twitter.com/rasbt/status/1605203694869532673,"@Sergei_Imaging Yes, I can see them adding a premium tier"
1362,@rasbt,2022-12-20 14:08:33+00:00,https://twitter.com/rasbt/status/1605203506742571009,"@bentossell It‚Äôs a smart system that can perform accurate computations instantly far beyond human capabilities. E.g., early examples include pocket calculators."
1363,@rasbt,2022-12-20 14:03:07+00:00,https://twitter.com/rasbt/status/1605202138870812675,@newplatonism I wouldn‚Äôt entirely replace search because you still want to find websites. But LLMs are useful for creating tl;dr‚Äôs for certain queries
1364,@rasbt,2022-12-20 13:58:51+00:00,https://twitter.com/rasbt/status/1605201065674252288,"Re: Replacing Google Search with ChatGPT

If Google Search used Chat-GPT, Google would probably be bankrupt in a month or so given that there are 8.5 billion search queries a day.

Using LLMs in/for Google Search makes sense though. They already started doing that years ago."
1365,@rasbt,2022-12-20 12:59:54+00:00,https://twitter.com/rasbt/status/1605186229011619840,"@mmitchell_ai @tdietterich I remember that Google was using encoder-style LLMs/transformers like BERT for Google Search, but I think that was just for encoding the query. I am not sure if they already use any kind of decoder-style LLM for their current summary texts."
1366,@rasbt,2022-12-20 12:53:48+00:00,https://twitter.com/rasbt/status/1605184695343255552,"@mmitchell_ai @tdietterich Yeah, even if ChatGPT were perfect at summarizing/rewording content from websites, there are always scenarios where you just want to find the/access an original website.
I think search-engine hybrids would make sense; e.g. augment the search results with tl:dr‚Äôs via ChatGPT or so"
1367,@rasbt,2022-12-20 02:27:22+00:00,https://twitter.com/rasbt/status/1605027046908129280,"@SaschaGriffiths @dimleve Afaik it's still that according to the distributional hypothesis, words occurring in the same contexts tend to have similar meanings"
1368,@rasbt,2022-12-19 19:12:46+00:00,https://twitter.com/rasbt/status/1604917673934168064,@sir_deenicus Lots of parameters maybe üòÖ https://t.co/DzarRFiNEg
1369,@rasbt,2022-12-19 19:11:05+00:00,https://twitter.com/rasbt/status/1604917250833743890,"@pgolding Hm, maybe not. Bag-of-words isn't that great :P"
1370,@rasbt,2022-12-19 19:08:39+00:00,https://twitter.com/rasbt/status/1604916640382128128,"@sudonymously See GPT-3, ChatGPT, etc ^^"
1371,@rasbt,2022-12-19 15:56:28+00:00,https://twitter.com/rasbt/status/1604868277385461760,"@GiorgioMantova @DataScienceHarp That's a good question @DataScienceHarp, and you make a good point @GiorgioMantova. I start with RNNs in my book, because the orig attention mechanism for developed for RNNs (before the first transformer paper came out). It's a good motivation for attention but maybe not crucial."
1372,@rasbt,2022-12-19 15:52:41+00:00,https://twitter.com/rasbt/status/1604867324439404547,"@GiorgioMantova Haha, oops, I thought ""act"" was referring to something like ""acl"" (Association for Computational Linguistics)"
1373,@rasbt,2022-12-19 15:04:07+00:00,https://twitter.com/rasbt/status/1604855098932596736,"@GiorgioMantova Which of the many things the ACT refers to üòÖ? 
Tbh it doesn‚Äôt make sense to use RNNs for any language tasks at this points. Completely superseded. It‚Äôs useful for other problems though, ligh time series data, videos, etc"
1374,@rasbt,2022-12-19 14:50:44+00:00,https://twitter.com/rasbt/status/1604851735003992064,"@dimleve Yeah, the ‚Äúdistributional hypothesis‚Äù in NLP"
1375,@rasbt,2022-12-19 14:38:07+00:00,https://twitter.com/rasbt/status/1604848555985862659,The ‚Äúunreasonable effectiveness of recurrent neural networks‚Äù should have been called ‚Äúthe unreasonable effectiveness of next-word prediction‚Äù
1376,@rasbt,2022-12-19 13:46:06+00:00,https://twitter.com/rasbt/status/1604835465751846912,@Sergei_Imaging To be continued ‚Ä¶
1377,@rasbt,2022-12-19 02:53:56+00:00,https://twitter.com/rasbt/status/1604671345492639744,"@phily8020 @langfab yeah, the name suggests that it is a conversational chat ""bot"", not a search engine, knowledge base, or paper writing service -- even though the common usage may suggest otherwise ^^"
1378,@rasbt,2022-12-18 18:37:18+00:00,https://twitter.com/rasbt/status/1604546361470459912,@plantifull @AlgosRhythm I would say that scikit-learn is actually a great library to contribute to. That's how I started. It has a very sophisticated yet clean codebase.
1379,@rasbt,2022-12-18 18:36:34+00:00,https://twitter.com/rasbt/status/1604546177956995072,"@v3n0m92 It's a good survey/overview book. It's not hands-on and only outlining the challenges and topics, but I really liked it overall.

https://t.co/8JWjljGPfF"
1380,@rasbt,2022-12-18 18:33:40+00:00,https://twitter.com/rasbt/status/1604545448642871297,"@PhilippRisius Three are 3 books from that list that might somewhat fall into the ""non-technical / social science"" category: 
- Sapiens (about humans)
- Zero to One (about start ups), 
- Deep Thinking (about chess and humans vs AI)"
1381,@rasbt,2022-12-18 16:08:19+00:00,https://twitter.com/rasbt/status/1604508868981161988,"@robma1982 With some weird habits :P. I usually get up at 5 am and have a morning (nonfiction) reading ritual (minimum of 30 min, often 60 min) with my morning coffee. I also read (fiction) 30-60 min before going to bed."
1382,@rasbt,2022-12-18 16:05:35+00:00,https://twitter.com/rasbt/status/1604508182096875525,@paulditterline Not explicitly. But it‚Äôs kind of a good implicit mindset when thinking and reasoning about experimental designs in applied projects
1383,@rasbt,2022-12-18 14:22:43+00:00,https://twitter.com/rasbt/status/1604482293384548353,"@ahwz84 @Abdelakreemkobo Hah, yes, the reason is that I only have 1 e-reader/tablet. 

(I prefer note-taking on my Remarkable but when I use it for reading, I don't have enough screen space for taking notes.)"
1384,@rasbt,2022-12-18 14:17:08+00:00,https://twitter.com/rasbt/status/1604480888154492928,*with most weight on the Experiments &amp; Results since ChatGPT is probably not super useful here (yet) üôÑ
1385,@rasbt,2022-12-18 14:15:02+00:00,https://twitter.com/rasbt/status/1604480362629005313,"Splitting a paper into 4 assignments is a great idea &amp; could also work for machine learning projects:

1) Intro
2) Proposed Method/Experiments + Related Work
3) Results
4) Discussion + Conclusion

(Previously split it into a midterm proposal &amp; final paper https://t.co/HSNiPN57zn) https://t.co/vI1D91Z0oP"
1386,@rasbt,2022-12-18 13:51:05+00:00,https://twitter.com/rasbt/status/1604474333224632327,@itsanderz @Codecademy *I took the Python 2.7 version back then but am recommending their Python 3 course of course. I am assuming it‚Äôs the same code but with slightly adjusted syntax.
1387,@rasbt,2022-12-18 13:50:03+00:00,https://twitter.com/rasbt/status/1604474072871899136,"@itsanderz @Codecademy Yes, I did take the course about 11 years ago. I remember that I really liked it, and I am still recommending it as my favorite beginner resources to people who are interested in getting started with programming and Python."
1388,@rasbt,2022-12-18 13:46:42+00:00,https://twitter.com/rasbt/status/1604473231351521280,"@isamelb It‚Äôs essentially a very short overview of the different ways to approach a problem (in broad strokes, statistics vs ML thinking)"
1389,@rasbt,2022-12-18 13:45:20+00:00,https://twitter.com/rasbt/status/1604472888307892224,"@iam_subhasmita *I mean, it does explain the idea behind transformers on broad strokes but skips the mathematical aspects. The code examples are great though. It‚Äôs a good companion for my transformer book chapter in ‚ÄòMachine Learning with PyTorch and Scikit-Learn‚Äô"
1390,@rasbt,2022-12-18 13:43:08+00:00,https://twitter.com/rasbt/status/1604472331220533250,@iam_subhasmita It was a good read overall. It doesn‚Äôt really go into detail in terms of how transformers work but give a high-level conceptual overview. The focus/strength of the book is the variety of code examples. Basically a curated documentation of the Hugging Face transformers library.
1391,@rasbt,2022-12-17 20:23:46+00:00,https://twitter.com/rasbt/status/1604210768475471876,"@iamknighton @MosaicML Very nice, thanks a lot for sharing this!"
1392,@rasbt,2022-12-17 20:22:11+00:00,https://twitter.com/rasbt/status/1604210371300048901,@hiydavid @DSaience Glad to hear. I have quite the pile (at least 5 more papers) to add some time :)
1393,@rasbt,2022-12-17 19:24:07+00:00,https://twitter.com/rasbt/status/1604195755530391552,"@hiydavid It certainly had its highs and lows but I liked it overall. Haha, but I guess it helped that it was the only book in my backpack on those airplane trips üôÑ"
1394,@rasbt,2022-12-17 18:37:24+00:00,https://twitter.com/rasbt/status/1604184000632946689,"@sebastian_rtj Coincidentally someone else just asked ^^. 

Might be a good topic to cover in the Productivity &amp; Study Tips section of my Ahead of AI newsletter."
1395,@rasbt,2022-12-17 18:14:26+00:00,https://twitter.com/rasbt/status/1604178219653107713,@Machine01776819 Heard a lot about it but actually never read it. I think I tried it once before a few years but somehow I could bring myself to finish it. Can‚Äôt remember why
1396,@rasbt,2022-12-17 18:01:16+00:00,https://twitter.com/rasbt/status/1604174905867919360,"@christophepere_ Sure! I would say it's a good book, but expectation-wise be aware that it's a survey book not a hands-on book. It's outlining challenges and general approaches, but you would have to consult follow-up resources to learn about certain things in more detail."
1397,@rasbt,2022-12-17 17:57:37+00:00,https://twitter.com/rasbt/status/1604173989446049794,"@christophepere_ I liked it. It was a good survey book.
https://t.co/fzXEesErWP"
1398,@rasbt,2022-12-17 17:33:15+00:00,https://twitter.com/rasbt/status/1604167853854183425,@ahsan_chaudhry It's a bit hard to rank: https://t.co/tAcLy5IoRR
1399,@rasbt,2022-12-17 16:40:59+00:00,https://twitter.com/rasbt/status/1604154702173597696,"@DSaience Oh yes! There were so many ... And I didn't really track my paper reading :P. Haha, my favorites are probably buried in this list: https://t.co/VAXJRC49qR"
1400,@rasbt,2022-12-17 16:39:30+00:00,https://twitter.com/rasbt/status/1604154331279683586,"@manuel__carro There are no mathematical formulas in this book, and there are lots of good, hands-on examples to illustrate the main points. I actually enjoyed it a lot. Btw the book would probably be 70% smaller if it didn't contain all the historical notes. It's partly also a history book"
1401,@rasbt,2022-12-17 16:37:27+00:00,https://twitter.com/rasbt/status/1604153813815943169,"@manuel__carro I found it pretty complicated at times. Actually, I made the mistake and got the audiobook version in 2018. This book does not work as audiobook because of the many diagrams, and because it requires lots of pausing &amp; thinking"
1402,@rasbt,2022-12-17 16:36:16+00:00,https://twitter.com/rasbt/status/1604153516431400961,@Olearningcurve They are sooo different from each other that they are really hard to compare. I would probably start with Modeling Mindsets before reading the Book of Why &amp; the Kaggle Book since it's a good framework for organizing concepts &amp; approaches.
1403,@rasbt,2022-12-17 16:34:43+00:00,https://twitter.com/rasbt/status/1604153123895148544,"@DSaience Modeling Mindsets
üëâ  Nice, short 100-page book that I enjoyed. ML practitioners usually come from diff educational backgrounds. It's an excellent survey of the different mindsets for approaching data problems: Frequentism, Bayesiansism, Likelihoodism, Causal Inference &amp; ML"
1404,@rasbt,2022-12-17 16:33:37+00:00,https://twitter.com/rasbt/status/1604152848207454208,"@DSaience The Book of Why
üëâ  If you are interested in causality and causal inference, this is THE book. Initially, I got the audiobook version when this book was first published about four years ago. A mistake coz it requires a lot of pausing &amp; thinking &amp; it contains a lot of diagrams."
1405,@rasbt,2022-12-17 16:32:46+00:00,https://twitter.com/rasbt/status/1604152635799789571,"@DSaience Natural Language Processing with Transformers
üëâ  A good summary of the Hugging Face transformers library. It's a very hands-on book without theory but with lots of examples."
1406,@rasbt,2022-12-17 16:32:24+00:00,https://twitter.com/rasbt/status/1604152541251518472,"@DSaience The Kaggle Book
üëâ It's partly an introductory ML book, but it has some good insights into how Kaggle works and summarizes things to look out for."
1407,@rasbt,2022-12-17 16:32:00+00:00,https://twitter.com/rasbt/status/1604152440403681287,"@DSaience Designing Machine Learning Systems
üëâ This is a good introductory book outlining the different aspects and challenges to consider when putting machine learning systems in production. Note that this book is more of a survey than a hands-on book."
1408,@rasbt,2022-12-17 16:24:38+00:00,https://twitter.com/rasbt/status/1604150588173869057,"@Abdelakreemkobo Yeah, I think there is a lot of value in writing down notes and reprocessing/organizing them. In the end, I find the process (which makes you think about the material) is more valuable than the notes themselves."
1409,@rasbt,2022-12-17 16:23:26+00:00,https://twitter.com/rasbt/status/1604150287412994055,@davidwkastner Not yet! It's really hard to pick favorites :P
1410,@rasbt,2022-12-17 16:22:32+00:00,https://twitter.com/rasbt/status/1604150058701754369,"@Abdelakreemkobo Depends as well. When I read a physical book, I use a Remarkable e-ink tablet for notetaking. If I read an e-book on the Remarkable, I use pen &amp; paper. I process these notes afterwards (e.g., refining them and putting them into Anki, mindmaps, or markdown files)"
1411,@rasbt,2022-12-17 16:20:42+00:00,https://twitter.com/rasbt/status/1604149598699880450,"@Abdelakreemkobo 2/2

1) There are notes that I take for my Anki collection: more about that in the Study Tips section here (https://t.co/SylIoQJ4Pu)

2) There are notes to look things up. I would search online then.

3) If I have summary notes, I organize them neatly on my computer."
1412,@rasbt,2022-12-17 16:18:57+00:00,https://twitter.com/rasbt/status/1604149156527968257,"@Abdelakreemkobo It depends. If it's complicated, I read it 2 times: 1st time just reading, 2nd reading with outlining/summarizing in my own words. Otherwise, I take notes while reading. I usually process these notes afterwards 1/2"
1413,@rasbt,2022-12-17 16:17:04+00:00,https://twitter.com/rasbt/status/1604148683875966977,"@panda1ai Modeling Mindsets is actually a cool, little book. It's actually really small and just 100 pages. However, it's well written and really nice if you are a stickler for jargon/approaches and like to organize &amp; categorize things. I actually liked it a lot."
1414,@rasbt,2022-12-17 16:15:48+00:00,https://twitter.com/rasbt/status/1604148363678560257,"@panda1ai The Kaggle Book is partly an intro to ML; but it did include some nuggets of wisdom for Kaggle beginners. Don't get me wrong it's a solid book, although maybe a bit unfocused (or, the target audience is more people who want to learn both ML and Kaggle at the same time)"
1415,@rasbt,2022-12-17 16:14:08+00:00,https://twitter.com/rasbt/status/1604147944327880706,@Aditya_OoO_ Re hard work: I must admit that a good chunk of these 29 books are fiction book I read for entertainment ^^
1416,@rasbt,2022-12-17 16:12:42+00:00,https://twitter.com/rasbt/status/1604147586402865153,*At least 10 of these 29 books are the silver lining of all those delayed &amp; canceled flights this year.
1417,@rasbt,2022-12-17 16:11:30+00:00,https://twitter.com/rasbt/status/1604147282827517952,"@JacobRishworth Depends, haha. To communicate more effectively with collaborators, Modeling Mindsets. If you are interested in causality &amp; causal inference: The Book of Why. If you are coming from academia and are interested in developing &amp; deploying ML products: Designing ML Systems"
1418,@rasbt,2022-12-17 16:09:33+00:00,https://twitter.com/rasbt/status/1604146793461202944,@Peter23239124 I am waiting for the Notes feature that Twitter is planning to add :P
1419,@rasbt,2022-12-17 16:08:32+00:00,https://twitter.com/rasbt/status/1604146537885569025,"@karpathy Fun fact: compressing prompts that retain the abstract information in a prompt can reduce toxicity in the generated text. 

via ""Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models"" (https://t.co/WkvkvNe895)"
1420,@rasbt,2022-12-17 16:05:03+00:00,https://twitter.com/rasbt/status/1604145659959037953,"Started my yearly review üòä. Wow, apparently, I read 29 books in 2022 ...
Some of the more technical ones üòÖ:

- Designing ML Systems
- The Kaggle Book
- NLP w Transformers
- The Book of Why
- Modeling Mindsets
Let me know if you would like to hear more about them, happy to chat!"
1421,@rasbt,2022-12-17 16:00:50+00:00,https://twitter.com/rasbt/status/1604144600263827464,"@bascodes I just created my Revue newsletter in October üò¢. 

Just moved it to Substack last month and like it (the editing/layouting interface feels much smoother). 

Also, the newsletter has also grown to 4300 subscribers since then ‚ò∫Ô∏è

https://t.co/W5kmcV5puC"
1422,@rasbt,2022-12-17 13:41:18+00:00,https://twitter.com/rasbt/status/1604109482036199424,@AlgosRhythm Yea totally agree. I think the best way to learn best-practices is to participate in well-maintained open source projects. You learn by co tributing. win-win.
1423,@rasbt,2022-12-17 13:39:09+00:00,https://twitter.com/rasbt/status/1604108941331423233,@Jimmy14624495 @CanumaGdt I think so. Perplexity AI seems to be able to do it.
1424,@rasbt,2022-12-16 20:45:53+00:00,https://twitter.com/rasbt/status/1603853943708258308,@DrAlibrahim_H That‚Äôs a lot of if‚Äôs though for what I think should be the default behavior
1425,@rasbt,2022-12-16 18:31:59+00:00,https://twitter.com/rasbt/status/1603820247596793857,@WalterReade Nice! Let me know what you find!
1426,@rasbt,2022-12-16 12:43:25+00:00,https://twitter.com/rasbt/status/1603732529667870721,"@LordGiustiniani Actually, I originally tried that to see whether it copies/uses information verbatim. On a positive note, it seems it does not simply copy. However, that also makes it hard for these tools to trace/identify the references."
1427,@rasbt,2022-12-16 12:41:35+00:00,https://twitter.com/rasbt/status/1603732068575461381,"Thanks for all the comments and lively discussion! If you think it's impossible to have an LLM like ChatGPT learn to provide references for the factual information it creates ...
... I learned that Perplexity AI (https://t.co/IOezEK4xwF) seems to be doing a good job here: https://t.co/GU4wIjwKmN"
1428,@rasbt,2022-12-15 18:26:55+00:00,https://twitter.com/rasbt/status/1603456583949815812,@KyriacosXanthos It‚Äôs maybe inconvenient but certainly not impossible
1429,@rasbt,2022-12-15 18:25:20+00:00,https://twitter.com/rasbt/status/1603456185641930762,@camstreet1 You can ask for references but it doesn‚Äôt do anything about it even if you ask.
1430,@rasbt,2022-12-15 18:23:54+00:00,https://twitter.com/rasbt/status/1603455827213692929,"@bwinterrose @sama Yes, doesn‚Äôt work. https://t.co/kTru0DCTPZ"
1431,@rasbt,2022-12-15 18:06:51+00:00,https://twitter.com/rasbt/status/1603451533856849931,"@CanumaGdt @sir_deenicus Was thinking Galactica as well, but I think it was only creating specific references when it was explicitly told. But yeah I was traveling when it came out and had no good chance to play around with it before it was taken down"
1432,@rasbt,2022-12-15 13:53:03+00:00,https://twitter.com/rasbt/status/1603387666875170817,@sama Citations / sources
1433,@rasbt,2022-12-15 13:32:18+00:00,https://twitter.com/rasbt/status/1603382443968339968,@phily8020 @langfab You can consider it as a subset of interpretable machine learning ;)
1434,@rasbt,2022-12-15 13:31:17+00:00,https://twitter.com/rasbt/status/1603382186127794176,"@CanumaGdt Have to check that out, thanks for the reference :P"
1435,@rasbt,2022-12-15 13:21:58+00:00,https://twitter.com/rasbt/status/1603379840551469056,@CanumaGdt Search engines can index and match content for much larger datasets.
1436,@rasbt,2022-12-15 13:11:58+00:00,https://twitter.com/rasbt/status/1603377327139872772,"@CanumaGdt He, it‚Äôs maybe not trivial, but I also think it‚Äôs possible. If you use an index-based approach you don‚Äôt need to index everything. And even if you do, I think the training datasets are still a small subset of data that internet search engines index and query."
1437,@rasbt,2022-12-15 12:59:44+00:00,https://twitter.com/rasbt/status/1603374248478748672,"@tony_copr Obviously that doesn‚Äôt need a reference. I am not suggesting brute-force adding a reference to everything.
Wikipedia articles or research papers are how it‚Äôs done."
1438,@rasbt,2022-12-15 12:52:00+00:00,https://twitter.com/rasbt/status/1603372301948522497,"@jrhwood Yes, sth like that :)"
1439,@rasbt,2022-12-15 12:49:43+00:00,https://twitter.com/rasbt/status/1603371726448066562,"@dwhdai Yeah, totally. Eg like in my first tweet above. This one here was just a quick tweet where is used screenshots from two different coding notebooks and didn‚Äôt want to rerun things. But yeah if this was the actual lecture slide I would of course adjust this."
1440,@rasbt,2022-12-15 12:47:27+00:00,https://twitter.com/rasbt/status/1603371156127588353,"I think systems like ChatGPT would be a lot less controversial if they cited references.

Eg when querying ‚ÄúWhat are the origins of AI‚Äù, sure have it provide a summary. But also append the sources where it learned this info from. To a) give credit &amp; b) so we can validate the info"
1441,@rasbt,2022-12-15 00:17:54+00:00,https://twitter.com/rasbt/status/1603182524418691078,@miquelmr92 A little bit
1442,@rasbt,2022-12-15 00:04:34+00:00,https://twitter.com/rasbt/status/1603179171878174720,"And here are some more extreme results from Unit 6 of my new Deep Learning Fundamentals Course (https://t.co/B0rVXxbR6v) 

(Unit 6 will be released next spring) https://t.co/jOkwP3BQwE"
1443,@rasbt,2022-12-14 23:57:30+00:00,https://twitter.com/rasbt/status/1603177393300115459,"Learning rate schedulers ftw ‚Üù

(https://t.co/YYZInNDeaq) https://t.co/OUqMk2XNuM"
1444,@rasbt,2022-12-14 21:42:04+00:00,https://twitter.com/rasbt/status/1603143308481634306,"@dobersch @Velofisch @FlorianGallwitz Yeah, nah, that‚Äôs not going to work. It would probably take a week until someone posts a watermark-remover on GitHub. The only viable solution to this problem is to design better/different types of homeworks or rethink the concept of homework assignments."
1445,@rasbt,2022-12-14 14:04:17+00:00,https://twitter.com/rasbt/status/1603028102355066881,"@jrhwood Hah, absolutely. And I would certainly not mind more capable grammar checker. When it comes to the writing process itself (haha, I mean books, not emails) and you enjoy that process, having the AI do that for you is like having an AI playing video games/watching movies for you :P"
1446,@rasbt,2022-12-14 12:34:54+00:00,https://twitter.com/rasbt/status/1603005608835284992,@handler_nft Happy learning!!
1447,@rasbt,2022-12-14 12:33:56+00:00,https://twitter.com/rasbt/status/1603005365876133982,"@GiorgioMantova @hsuyab @atomicflndr @PatrickKidger @fchollet I have several ‚Äúfrom scratch‚Äù implementations in my book: Perceptrons, ensemble classifiers, multilayer neural networks, and some bits and pieces of transformers‚Ä¶ üòä"
1448,@rasbt,2022-12-14 12:31:10+00:00,https://twitter.com/rasbt/status/1603004670435381249,@ChristophMolnar Haha good point. You just have to make write/type the suggestions manually üòá
1449,@rasbt,2022-12-14 12:29:25+00:00,https://twitter.com/rasbt/status/1603004231052566528,"@irari_bom Right, for example, if you used a grammar checker, you‚Äôd probably already violate the ‚Äú100% written by a human‚Äù rule üôÉ"
1450,@rasbt,2022-12-14 02:22:15+00:00,https://twitter.com/rasbt/status/1602851430787911683,@J_M_Brehm @SimonBurns_ ‚Äúcomputational structure-based drug design and development engine‚Äù ‚Äî the same description you‚Äôd use for any traditional molecular docking software or molecular dynamics-based approach
1451,@rasbt,2022-12-14 00:40:47+00:00,https://twitter.com/rasbt/status/1602825896372703240,"@mdarshad1000 unfortunately no, sry!"
1452,@rasbt,2022-12-14 00:07:26+00:00,https://twitter.com/rasbt/status/1602817505055088641,@mdarshad1000 sometimes
1453,@rasbt,2022-12-14 00:07:08+00:00,https://twitter.com/rasbt/status/1602817427036950528,"Working title: ""So Good They Can't Ignore You: Why Passion Trumps Algorithms"""
1454,@rasbt,2022-12-14 00:05:49+00:00,https://twitter.com/rasbt/status/1602817095053484032,It's fun working on AI. It's not fun working with an AI. And I am bad at delegating anyways.
1455,@rasbt,2022-12-14 00:03:25+00:00,https://twitter.com/rasbt/status/1602816494311612417,"It's going to be an interesting time for writing and publishing.

I guess my next book will proudly declare, ""100% written by human"" on the cover‚Äîa reminder to readers of our commitment to quality and authenticity in a world where AI is making its mark."
1456,@rasbt,2022-12-13 21:28:36+00:00,https://twitter.com/rasbt/status/1602777534088630273,@CSProfKGD @YorkUniversity @LassondeSchool An Xmas tree made of gifts. Love it!
1457,@rasbt,2022-12-13 21:25:35+00:00,https://twitter.com/rasbt/status/1602776774051512325,"@handler_nft Sry, unfortunately I am not doing mentoring since I currently lack the time and am way too overcommitted already."
1458,@rasbt,2022-12-13 21:23:54+00:00,https://twitter.com/rasbt/status/1602776348493332481,"@handler_nft Good question. I would definitely start with cloud resources since it‚Äôs easier to get going, and you can scale it more easily. There is a point where buying your own GPU server is more cost effective, but it‚Äôs expensive, loud, and requires space, etc. I would start with the cloud"
1459,@rasbt,2022-12-13 13:30:39+00:00,https://twitter.com/rasbt/status/1602657252015570945,@handler_nft I have a chapter on fine-tuning an LLM in my book. You probably don't need to read all the theory and get started on the coding part. You can always go back and learn more theory later :)
1460,@rasbt,2022-12-13 13:29:24+00:00,https://twitter.com/rasbt/status/1602656936008318976,"@handler_nft I'd say it's feasible. It will be quite some effort though. I would plan in a few months for that. 
1) You can adopt another pretrained LLM (ChatGPT is not available yet)
2) You'd need a labeled dataset for fine-tuning
3) You'll need a couple of GPUs"
1461,@rasbt,2022-12-13 13:12:51+00:00,https://twitter.com/rasbt/status/1602652771798249472,"@handler_nft I hope my recent 

üìñ book (https://t.co/dZzvgQSkjM) and 
üì∫ course (https://t.co/OcL9XWGoAt) are good start! 

But I would recommend spending a few weeks on learning Python before diving in, though. 

Some pointer for learning Python here: https://t.co/89D9r4JK8N"
1462,@rasbt,2022-12-13 12:56:48+00:00,https://twitter.com/rasbt/status/1602648732612186112,"@VeredShwartz Yes, afaik it‚Äôs a common practice. Almost like us researchers probing different hypotheses but only writing about the ‚Äúmost interesting‚Äù (with the most convincing results)"
1463,@rasbt,2022-12-13 12:21:21+00:00,https://twitter.com/rasbt/status/1602639811776598017,@yoavgo @ylecun To me SSL remains essential unless you show me a real-world counter example üôÉ
1464,@rasbt,2022-12-13 12:20:11+00:00,https://twitter.com/rasbt/status/1602639516665229313,"@yoavgo @ylecun What I remember from eg the SimCLR paper is that supervised learning remains better of course. But I don‚Äôt think even OpenAI has that much labeled data compared to the vast amounts of unlabeled data on the internet. But sure, there might be a point where it‚Äôs enough one day"
1465,@rasbt,2022-12-13 01:39:58+00:00,https://twitter.com/rasbt/status/1602478404015722497,"@alfcnz @sirbayes Wait what, does that mean we may get the 1st print version of volume 1 pretty soon? You know, Xmas is coming up, and I can't think of anything better than ..."
1466,@rasbt,2022-12-13 00:51:32+00:00,https://twitter.com/rasbt/status/1602466215234048000,@yoavgo @ylecun instruct-tuning follows SSL.  No way you can get a LLM working well without SSL.
1467,@rasbt,2022-12-13 00:48:51+00:00,https://twitter.com/rasbt/status/1602465537392611330,@wongmjane The M1 Max is a poor space heater. I recommend the Intel MacBooks for that üôÉ
1468,@rasbt,2022-12-13 00:36:22+00:00,https://twitter.com/rasbt/status/1602462398392082434,"10 months in ...
Can't wait for Twitter to increase the char limit so that I can add ChatGPT to that list!"
1469,@rasbt,2022-12-13 00:31:22+00:00,https://twitter.com/rasbt/status/1602461141166428161,"@taraqur Hah, yes, along with the short-lived Galactica"
1470,@rasbt,2022-12-12 19:16:43+00:00,https://twitter.com/rasbt/status/1602381953600192536,@yoavgo @ylecun Yes of course. Every single one of the LLMs we are so impressed about was (pre)trained using SSL afaik.
1471,@rasbt,2022-12-12 18:27:57+00:00,https://twitter.com/rasbt/status/1602369683205885977,"@MereSophistry Cutting corners to get more articles out. 
By cutting corners, I mean cherry picking results and skipping analyses where your newly proposed method performs worse."
1472,@rasbt,2022-12-12 18:19:32+00:00,https://twitter.com/rasbt/status/1602367564574855217,"@HamelHusain It‚Äôs the process (here: capturing notes) that matters, not the tool. 

You can interpret that both ways: the tool doesn‚Äôt matter that much, so
a) feel free to switch 
b) don‚Äôt bother about switching

Personally, I know how time consuming migrating is, so I‚Äôd avoid that."
1473,@rasbt,2022-12-12 17:30:09+00:00,https://twitter.com/rasbt/status/1602355137707937792,"@simocristea Nice! I am glad to hear! I always have this tendency to go overboard when writing, and cutting back content is hard. So that‚Äôs nice!"
1474,@rasbt,2022-12-12 17:11:32+00:00,https://twitter.com/rasbt/status/1602350453383385089,"Whoa, just saw that the Ahead of AI newsletter magazine (https://t.co/hPKFGmwAWm) has almost 4k regular readers now!

Glad to see that it‚Äôs something you like &amp; find useful!! https://t.co/4auDPAB02x"
1475,@rasbt,2022-12-12 16:27:57+00:00,https://twitter.com/rasbt/status/1602339481268490240,@MuzafferKal_ @mayhewsw Wow first thought you were kidding but just looked it up. Learned sth new today!
1476,@rasbt,2022-12-12 16:18:43+00:00,https://twitter.com/rasbt/status/1602337159343734784,"@mayhewsw Hah, wait, what does calculus mean to a dentist? Sth involving root canals? üòÖ"
1477,@rasbt,2022-12-12 12:57:49+00:00,https://twitter.com/rasbt/status/1602286601903783942,"@ylecun Spot on. I wonder, in your initial predictions back then, if you were thinking of LLMs or if that came as a surprise. Just curious. 
I.e., SSL works great for computer vision ‚Äî but you can still can get good results without it. For LLMs, on the other hand, SSL is a must."
1478,@rasbt,2022-12-12 12:53:24+00:00,https://twitter.com/rasbt/status/1602285491889786880,@FilipNoworolnik @giffmana That‚Äôs sounds nice! Thats‚Äôs probably probably as close to the ideal PhD program as it can get!
1479,@rasbt,2022-12-11 20:52:48+00:00,https://twitter.com/rasbt/status/1602043747373666305,"@madsjw not a ""grade"" experience"
1480,@rasbt,2022-12-11 20:45:32+00:00,https://twitter.com/rasbt/status/1602041917365260289,"@DaveJuergens @ChrSzegedy Now, that's an application of diffusion models that gets me excited! 

Looking forward to reading!!"
1481,@rasbt,2022-12-11 16:30:02+00:00,https://twitter.com/rasbt/status/1601977617640558594,"@AI_Sensei_ Glad you like it! Btw we have a blog article about the deployment process here: https://t.co/Ft6LvNK2AA

If you prefer a bottom-up explanation of the open source Lightning framework, I've written about it here: https://t.co/LKeu5ELrVW"
1482,@rasbt,2022-12-11 15:35:54+00:00,https://twitter.com/rasbt/status/1601963996973740034,Big credit to @alecmerdler for developing this user-friendly app &amp; UI!
1483,@rasbt,2022-12-11 15:35:53+00:00,https://twitter.com/rasbt/status/1601963993639243776,"PS: We launched the Echo App this week, deploying OpenAI Whisper with a nice UI: https://t.co/5tJTlF9721

Fun fact: Whisper works great! Had used it to generate subtitles for all my course vids!
(Tried many subtitle/closed-captioning services but none could deal with tech jargon) https://t.co/bSdIHs2sOg"
1484,@rasbt,2022-12-11 14:47:05+00:00,https://twitter.com/rasbt/status/1601951711488344067,@MaartenvSmeden @LiadhT TIL that AUC stands for AccUraCy
1485,@rasbt,2022-12-11 14:40:21+00:00,https://twitter.com/rasbt/status/1601950016058413056,@roydanroy This paper has a good take on evaluating capabilities of LLMs:
1486,@rasbt,2022-12-11 13:35:15+00:00,https://twitter.com/rasbt/status/1601933634969210880,"@giffmana Not sure if that‚Äôs still true, but I heard there is also less ‚Äúpublish or perish‚Äù pressure. I.e., it‚Äôs ok to have 1 or 2 good papers, and the focus is more on the PhD thesis vs papers."
1487,@rasbt,2022-12-11 13:23:26+00:00,https://twitter.com/rasbt/status/1601930661333434371,"@AllesistKode For reference, if someone wants to check it out, here is a link to the book: https://t.co/vQv1P30OFR"
1488,@rasbt,2022-12-11 13:21:13+00:00,https://twitter.com/rasbt/status/1601930102945759234,"@AllesistKode Wow! Thanks for recommending my book, and I am glad to hear it‚Äôs been that useful!!"
1489,@rasbt,2022-12-11 13:19:55+00:00,https://twitter.com/rasbt/status/1601929773571313664,"@AlexSS_022 @blackw1ng You are right, it‚Äôs not unique. But a) regular transfer learning or b) self-supervised learning + fine tuning on non-transformer architectures don‚Äôt give you the same great results."
1490,@rasbt,2022-12-11 13:17:34+00:00,https://twitter.com/rasbt/status/1601929183546032130,"@manaskar Regarding RPA and AI: isn‚Äôt RPA considered as a subcategory of expert systems? If yes, then it‚Äôs considered GOFAI (good old fashioned AI) and thus AI ü§î"
1491,@rasbt,2022-12-11 13:15:18+00:00,https://twitter.com/rasbt/status/1601928614790025216,"@AlexSS_022 @ashvanth_s1 But the nice thing about transformers is that we don‚Äôt have to train them from scratch. If you work with image or text, it‚Äôs never been easier to get good results with small datasets."
1492,@rasbt,2022-12-11 13:13:46+00:00,https://twitter.com/rasbt/status/1601928226774945793,"@__nnet__ Yes, that‚Äôs an edge case that maybe doesn‚Äôt fit into one of the categories above  ü§î"
1493,@rasbt,2022-12-11 00:37:48+00:00,https://twitter.com/rasbt/status/1601737980959653888,@iScienceLuvr @francoisfleuret @OpenAI Ah nice! thanks!
1494,@rasbt,2022-12-11 00:08:22+00:00,https://twitter.com/rasbt/status/1601730576285077504,"@francoisfleuret @OpenAI I heard it‚Äôs a fine-tuned version of InstructGPT, i.e. a flavor of GPT3 that has 100x fewer parameters"
1495,@rasbt,2022-12-10 23:32:30+00:00,https://twitter.com/rasbt/status/1601721548510855168,"@ManuelHrokr Yup, would be interesting to know whether there was even a category for that in the survey"
1496,@rasbt,2022-12-10 23:31:36+00:00,https://twitter.com/rasbt/status/1601721321523941376,"@blackw1ng Agreed. The interesting twist is that you don‚Äôt need as much data though when working with transformers ‚Ä¶ if transformers have been pretrained in text or vision, and that is close to what you want to do, you need less data to get good results compared to traditional ML and DL"
1497,@rasbt,2022-12-10 23:27:59+00:00,https://twitter.com/rasbt/status/1601720412731510785,"@technotweet On mobile and don‚Äôt have the link at hand, but yeah, eg natural language processing was more in the middle, now it‚Äôs tied with CV"
1498,@rasbt,2022-12-10 15:10:45+00:00,https://twitter.com/rasbt/status/1601595280260239361,"@datenzauberai Yup, lots of questions ...
As always, we have to take these surveys with a big grain of salt."
1499,@rasbt,2022-12-10 15:09:58+00:00,https://twitter.com/rasbt/status/1601595082888851458,@paul_rietschka I do think it may be largely thanks to the medical-imaging companies
1500,@rasbt,2022-12-10 15:08:12+00:00,https://twitter.com/rasbt/status/1601594638158422016,"@paul_rietschka Haha, exactly. 

Btw. I was super surprised to see GANs in that survey btw"
1501,@rasbt,2022-12-10 14:59:20+00:00,https://twitter.com/rasbt/status/1601592405941067776,@cohenrap You *could* use transformers for classification or dialogue or vision or search
1502,@rasbt,2022-12-10 14:54:00+00:00,https://twitter.com/rasbt/status/1601591062568792065,"@cohenrap Or, how ""recent"" this survey is. Results came out this week, but when did they actually survey those companies. Last year, last month?"
1503,@rasbt,2022-12-10 14:50:50+00:00,https://twitter.com/rasbt/status/1601590265609080832,"@overlordayn @ph_singer Hah, yes. Also for safety reasons I guess üòÜ"
1504,@rasbt,2022-12-10 14:48:50+00:00,https://twitter.com/rasbt/status/1601589764141944832,"@ph_singer Hm, I don't find it that weird. RL has been around for decades. Also, some people use it for multi-arm bandits."
1505,@rasbt,2022-12-10 14:40:16+00:00,https://twitter.com/rasbt/status/1601587609763217410,"@dimleve Interesting, this would be ""generation"" though. Although, they don't say that categories cannot overlap, so you are probably right."
1506,@rasbt,2022-12-10 14:38:54+00:00,https://twitter.com/rasbt/status/1601587264739762176,"@ph_singer Fair. Regarding the 20% reinforcement learning (RL): You mean the discrepancy between ""robotic process automation"" (which ranks high and is probably RL based) and RL (which ranks low)?"
1507,@rasbt,2022-12-10 14:24:11+00:00,https://twitter.com/rasbt/status/1601583561651277824,"So, taking point 2 and 3 above, this implies most natural-language generation in industry

a) uses BoW, RNNs, etc. instead of BERT-like transformers
b) uses RNNs (and sth else) for text generation instead of GPT-like transformers

4 of 4"
1508,@rasbt,2022-12-10 14:24:11+00:00,https://twitter.com/rasbt/status/1601583559155732481,"3.  At the same time transformers (bottom of the chart above) do not seem to be common for NLP yet.

3 of 4"
1509,@rasbt,2022-12-10 14:24:10+00:00,https://twitter.com/rasbt/status/1601583556488093697,"2.  Natural-language text understanding (probably mostly NLP for *classification*?) is almost twice as popular as natural-language *generation* (i.e., generative NLP like GPT)

2 of 4"
1510,@rasbt,2022-12-10 14:24:09+00:00,https://twitter.com/rasbt/status/1601583553459863553,"Just read through state of AI report by McKinsey: https://t.co/fYhnZ2JGvX
(As a researcher, it seems to be useful summary of how AI is *actually* used in industry.)

Interesting insights

1.  Computer vision now ties with NLP for classification/understanding

1 of 4 https://t.co/8FBhjjRJau"
1511,@rasbt,2022-12-10 13:04:02+00:00,https://twitter.com/rasbt/status/1601563388491927553,@j_foerst @Thom_Wolf Maybe too close to GOFAI (good old fashioned AI) and too prone to confusion :P
1512,@rasbt,2022-12-10 13:00:55+00:00,https://twitter.com/rasbt/status/1601562607810666498,"@egrefen @akbirkhan @LauraRuis what I meant was that metrics used in LLM papers are not capturing ‚Äúhuman understanding‚Äù which is what a lot of people care about. Hence your paper is very relevant. 

(Commonly used metrics are also useful in the sense that they broad us to where we are, but it‚Äôs time to update)"
1513,@rasbt,2022-12-10 12:55:12+00:00,https://twitter.com/rasbt/status/1601561167595720705,"@AxeShikhar Sry to hear. Also, this could be me üòá."
1514,@rasbt,2022-12-10 12:54:19+00:00,https://twitter.com/rasbt/status/1601560943883788288,@shubham12et1062 @mt0rm0 @fchollet I think that‚Äôs a very nice analogy üëç
1515,@rasbt,2022-12-10 01:14:43+00:00,https://twitter.com/rasbt/status/1601384883565170688,@egrefen @akbirkhan @LauraRuis It‚Äôs a nice paper and the point it makes is more relevant than ever. Will be curious to see how the creators will choose to evaluate ChatGPT in their paper as a response
1516,@rasbt,2022-12-10 01:12:12+00:00,https://twitter.com/rasbt/status/1601384249676140544,@egrefen @akbirkhan @LauraRuis The other aspect is the way we evaluate LLMs in papers is flawed. The general insights and methodology are still super relevant. Not doubting that.
1517,@rasbt,2022-12-10 01:09:32+00:00,https://twitter.com/rasbt/status/1601383581791965184,@egrefen @akbirkhan @LauraRuis Exactly! What I was getting at was in a half-joking way that it is evaluating ‚Äúlegacy‚Äù conversational LLMs. But they are now uninteresting as of last week.
1518,@rasbt,2022-12-10 00:25:09+00:00,https://twitter.com/rasbt/status/1601372409222746112,"@HaffendenHector Yeah, maybe too broad of an umbrella term"
1519,@rasbt,2022-12-10 00:24:39+00:00,https://twitter.com/rasbt/status/1601372285742370816,"@egrefen @akbirkhan Mainly because it discussed the flaws/limitations of InstructGPT, and ChatGPT is all the rage now. Based on what I heard they share the same model architecture but different training data, so it‚Äôs still relevant."
1520,@rasbt,2022-12-10 00:22:54+00:00,https://twitter.com/rasbt/status/1601371845462458370,"@GaelVaroquaux Ah yes, thanks, I remember this!"
1521,@rasbt,2022-12-09 20:24:10+00:00,https://twitter.com/rasbt/status/1601311764078960640,@drenerbas @jmourabarbosa Yeah. And I am pretty sure if you use a random seed you would get the same results with a generative model.
1522,@rasbt,2022-12-09 20:23:10+00:00,https://twitter.com/rasbt/status/1601311514681815041,"@themintsv Good point. Maybe, with a stretch, a special case of data augmentation ... Hmmm"
1523,@rasbt,2022-12-09 20:15:01+00:00,https://twitter.com/rasbt/status/1601309462815334400,"@IsackOdero yup, this happened to me before"
1524,@rasbt,2022-12-09 20:10:42+00:00,https://twitter.com/rasbt/status/1601308376528740352,"@IsackOdero Yes, this will probably slightly affect the model training."
1525,@rasbt,2022-12-09 20:09:39+00:00,https://twitter.com/rasbt/status/1601308113952722944,@RobFlynnHere Good one! I read this amazing 50-page articles a few months back ... wish I could find it now
1526,@rasbt,2022-12-09 20:07:14+00:00,https://twitter.com/rasbt/status/1601307505174278144,"@Raza_Habib496 Thanks! Hmm, could that fall under data sampling? (Renaming point 2?)"
1527,@rasbt,2022-12-09 20:05:47+00:00,https://twitter.com/rasbt/status/1601307138831577088,"In this day end age, most people probably don't want to rerun model training due to financial reasons. 
Fortunately, trained models themselves (usually) behave deterministically, which is probably all that matters."
1528,@rasbt,2022-12-09 20:03:47+00:00,https://twitter.com/rasbt/status/1601306636722704386,@josueortc Good point. This doesn't quite fit into Nondeterministic algos. Probably a modification of point 2: Data shuffling *and augmentation*. Thanks!!
1529,@rasbt,2022-12-09 19:59:49+00:00,https://twitter.com/rasbt/status/1601305635664334849,"Collecting thoughts on the common sources of randomness when training deep neural nets:

1. Model weight initialization
2. Dataset shuffling
3. Nondeterministic algorithms
4. Different runtime algos (e.g., diff CUDA convolutions)
5. (GPU) Hardware and drivers

Anything missing?"
1530,@rasbt,2022-12-09 19:32:37+00:00,https://twitter.com/rasbt/status/1601298794519228416,@mt0rm0 @fchollet Try changing the random seed üôÉ
1531,@rasbt,2022-12-09 18:50:19+00:00,https://twitter.com/rasbt/status/1601288147257937925,@fchollet Luck favors the one who tries.
1532,@rasbt,2022-12-09 17:51:38+00:00,https://twitter.com/rasbt/status/1601273380346679297,"@tdietterich @pfau Protein structures are not static, but yes the/a rigid crystal pose is probably most useful for most application. But the point is that it hasn‚Äôt solved protein folding but protein structure prediction."
1533,@rasbt,2022-12-09 17:07:58+00:00,https://twitter.com/rasbt/status/1601262391106207744,"@DSaience Hah ok, in that context ... honestly, if you have a similarly big pile as I do, then maybe don't ... unless you are trying to evaluate LLMs."
1534,@rasbt,2022-12-09 16:54:52+00:00,https://twitter.com/rasbt/status/1601259094392074241,@alfcnz PS: Looks like a solid monitor stand :P
1535,@rasbt,2022-12-09 16:50:50+00:00,https://twitter.com/rasbt/status/1601258078565175296,@DSaience Yes I think so. Once we can get our hands on the ChatGPT model (in a Python/PyTorch session) we/one can use it as a blueprint to evaluate it
1536,@rasbt,2022-12-09 16:39:27+00:00,https://twitter.com/rasbt/status/1601255213494829056,"@alfcnz An Xmas break is coming up, right!? üòÜ"
1537,@rasbt,2022-12-09 16:00:08+00:00,https://twitter.com/rasbt/status/1601245318665773056,"Just read the excellent ""Large language models are not zero-shot communicators"" (https://t.co/Etc1dpElYk) paper on InstructGPT LLM a few weeks ago. 

Great paper but (probably) already out of date. 

That's the current pace of AI research for you. https://t.co/tBxQRr7r7i"
1538,@rasbt,2022-12-09 15:35:18+00:00,https://twitter.com/rasbt/status/1601239071166459909,"@MausJens Wow that was quick! Glad you liked it! Depending on how the editing goes, there will be a new unit every 1-3 weeks (10 units in total)"
1539,@rasbt,2022-12-09 15:34:19+00:00,https://twitter.com/rasbt/status/1601238822863241217,@ChristophMolnar And a ‚Äúliterature review‚Äù or ‚Äúreview paper‚Äù is basically a survey of research directions &amp; results. Not analogous to movie or book reviews. And not to be confused with a ‚Äúcommentary‚Äù or ‚Äúletter‚Äù
1540,@rasbt,2022-12-09 15:24:34+00:00,https://twitter.com/rasbt/status/1601236369745272835,@ykilcher It was weird to see such a polarized discussion on both ‚Äúsides‚Äù though. It seems that many people are not willing to understand other persons‚Äô viewpoints anymore and are unwilling to change their mind.
1541,@rasbt,2022-12-09 14:49:11+00:00,https://twitter.com/rasbt/status/1601227463140741121,"@ykilcher Since it may not be clear from my responses, let me add that I am not against developing LLMs, Galactica etc. just noting that the marketing needs some finetuning. I have some more thoughts here (first section) https://t.co/ZxEQsHIiL8"
1542,@rasbt,2022-12-09 14:45:48+00:00,https://twitter.com/rasbt/status/1601226613936467969,"@ykilcher The Galactica website said ‚ÄúGenerate a Literature Review‚Äù (/Wikipedia Article) for you. Imho if they wrote ‚Äúarticle template‚Äù it probably would have been way less controversial. Ie instead of implying it writes the article for you, implying that it provides the article structure."
1543,@rasbt,2022-12-09 13:54:26+00:00,https://twitter.com/rasbt/status/1601213684784975872,"@Thom_Wolf Maybe a bitter lesson, but still a lesson learned. It‚Äôs important to btw check and try different paths. Not all paths work out but there‚Äôs something to learn from it, which is what matters most."
1544,@rasbt,2022-12-09 13:48:07+00:00,https://twitter.com/rasbt/status/1601212098406555648,@ykilcher The marketing of ChatGPT is way more sensible.
1545,@rasbt,2022-12-09 13:45:40+00:00,https://twitter.com/rasbt/status/1601211480564981761,@bookauthority Thanks! But it shows the wrong cover  üòÖ
1546,@rasbt,2022-12-09 13:43:49+00:00,https://twitter.com/rasbt/status/1601211012228653056,"@tdietterich @pfau Yes! Was trying to make the point that the methods are impressive but they skip the actual ‚Äúfolding‚Äù part that traditional molecular-mechanics methods aim to simulate. I.e., AlphaFold gives you the final structure but doesn‚Äôt give any insights how."
1547,@rasbt,2022-12-09 13:40:41+00:00,https://twitter.com/rasbt/status/1601210226405158912,@bitdribble Good to know! I will be explaining DataLoaders in Unit 4 :). Will also be covering data modules in later sections ‚Äî not all are from-scratch loaders though to keep the code more focused.
1548,@rasbt,2022-12-08 17:38:01+00:00,https://twitter.com/rasbt/status/1600907564790620161,"As an academic and researcher, I had to get used to non-deterministic behavior at first.
I'm becoming ok with it &amp; it may be fine.

The world is moving towards saving &amp; reusing weights. It will always be important to validate models. But there's maybe less need to rerun things."
1549,@rasbt,2022-12-08 17:26:57+00:00,https://twitter.com/rasbt/status/1600904781081366528,"@capetorch @Birchlabs Yeah, I wish there was more of a (academic) side-by-side comparison with related works :)"
1550,@rasbt,2022-12-08 17:25:23+00:00,https://twitter.com/rasbt/status/1600904386137710592,"@DoktorSly Thanks, Sylvain!!"
1551,@rasbt,2022-12-08 17:25:07+00:00,https://twitter.com/rasbt/status/1600904319926034434,@shravankumar147 I am using PyTorch utilities (and LightningDataModule for certain codes)
1552,@rasbt,2022-12-08 16:43:19+00:00,https://twitter.com/rasbt/status/1600893800809140224,"@putmoremaths Glad to hear! Structuring a class, since all ML topics are so interrelated, is something I try to put a lot of thought into. Feels really nice to hear!"
1553,@rasbt,2022-12-08 16:40:10+00:00,https://twitter.com/rasbt/status/1600893008098250760,"@vjay_deshpande Yup, will have something in Unit 10.3 :)"
1554,@rasbt,2022-12-08 16:03:01+00:00,https://twitter.com/rasbt/status/1600883658247663617,"I am positively overwhelmed by all the positive feedback so far! Thanks everyone for the support and kind words!

Now, if I were to record a little ""ask-me-anything"" next week (about the course, but open to anything, haha) ...

Anything you are curious to hear about?"
1555,@rasbt,2022-12-08 14:44:23+00:00,https://twitter.com/rasbt/status/1600863868095455232,"@marekkraft Planning to release a new units every 1-2 weeks, until unit 10. Lots of work to be done on the editing front, but that's at least the plan :)"
1556,@rasbt,2022-12-08 13:50:02+00:00,https://twitter.com/rasbt/status/1600850189920575488,@Machine01776819 I'd say it's a pragmatic course that teaches deep learning. It will teach you how backpropagation works from the ground up but it also teaches you how to run neural networks on multi-GPU nodes.
1557,@rasbt,2022-12-08 13:43:43+00:00,https://twitter.com/rasbt/status/1600848600736858114,"@PABLO_LEWIN @ChristophMolnar ChatGPT can't play video games, so it must be narrow artificial intelligence, not AGI üòÜ"
1558,@rasbt,2022-12-08 13:42:43+00:00,https://twitter.com/rasbt/status/1600848349166718976,"@Pascallisch Haha, yup. Plus Text-Davinci-003. Just wrote about it here the other day https://t.co/ZxEQsHIiL8 https://t.co/TS1vg1H5aw"
1559,@rasbt,2022-12-08 13:41:40+00:00,https://twitter.com/rasbt/status/1600848085139456000,"@NikzadMurtaza Sorry, there were a few server hiccups. Is it working for you now?"
1560,@rasbt,2022-12-08 13:38:42+00:00,https://twitter.com/rasbt/status/1600847338313900032,"True. Little fun fact though: Apple just released a Python package for converting Stable Diffusion models from PyTorch to Core ML, to run Stable Diffusion faster on hardware with M1/M2 chips: https://t.co/fEWyygZ0D1

(So, maybe there's more to come ...?) https://t.co/ZG3WnBpN0A"
1561,@rasbt,2022-12-08 03:38:08+00:00,https://twitter.com/rasbt/status/1600696200600375297,"@deliprao Until there‚Äôs reliable continual training without catastrophic forgetting, I am not worried about LLMs taking over ‚Ä¶ at least when it comes to newsletter writing üòÖ"
1562,@rasbt,2022-12-08 02:17:57+00:00,https://twitter.com/rasbt/status/1600676022906548224,"@DataKimist @chrisalbon Fair point, but that‚Äôs also a bit changing in both CV and NLP where you can get great results by taking pretrained models and fine tune them on your smaller target task."
1563,@rasbt,2022-12-08 02:15:40+00:00,https://twitter.com/rasbt/status/1600675448161439744,"@CMastication In fact, probably the best burrito I ever had!"
1564,@rasbt,2022-12-08 02:10:01+00:00,https://twitter.com/rasbt/status/1600674025889730560,@GaryMarcus @Grady_Booch Whoa. And welcome to the club!
1565,@rasbt,2022-12-08 00:27:47+00:00,https://twitter.com/rasbt/status/1600648298980724736,@merl_syrex @AndrewYNg Good question. They are still being processed and it may be 1-2 weeks. There will be 10 units in total actually :)
1566,@rasbt,2022-12-08 00:26:13+00:00,https://twitter.com/rasbt/status/1600647905265582080,"@denzil_correa Ah no, sry, they didn‚Äôt make the cut üòÖ. I do have a chapter on graph neural nets in my book though https://t.co/gfgF8T7Jsz"
1567,@rasbt,2022-12-07 21:53:04+00:00,https://twitter.com/rasbt/status/1600609362359230473,"@aureliengeron Thanks, Aur√©lien! Coming from you this means a lot!"
1568,@rasbt,2022-12-07 21:51:52+00:00,https://twitter.com/rasbt/status/1600609062164504595,@prashanthsriram Wow thanks ü´∂
1569,@rasbt,2022-12-07 21:05:22+00:00,https://twitter.com/rasbt/status/1600597358982696960,"@andrea21385914 There was a temporary server issue, I think it's fixed now. Sorry about that!"
1570,@rasbt,2022-12-07 21:04:47+00:00,https://twitter.com/rasbt/status/1600597211569655826,@GiorgioMantova @taocds I think it was a server issue for some people. Should be fixed now!
1571,@rasbt,2022-12-07 21:04:21+00:00,https://twitter.com/rasbt/status/1600597101330812928,"@JulienMouchnino Should be fixed now, let me know if the issue still persists!"
1572,@rasbt,2022-12-07 21:03:30+00:00,https://twitter.com/rasbt/status/1600596888012603392,"@DLbot96 Good question. Not in this course since the 10 units are already waaaay too long :). Will be covering other topics like self-supervised learning though. 
Segmentation is a great topic for a standalone computer vision course!"
1573,@rasbt,2022-12-07 21:01:29+00:00,https://twitter.com/rasbt/status/1600596381194137600,@1258632 Thanks for letting me know!
1574,@rasbt,2022-12-07 20:45:08+00:00,https://twitter.com/rasbt/status/1600592266388717573,@Vinee_ethN *Not a requirement for this course though. Just a little goodie that comes with a free account :P
1575,@rasbt,2022-12-07 20:44:47+00:00,https://twitter.com/rasbt/status/1600592176286781440,@Vinee_ethN 2/2 So you can create a free account on the https://t.co/yQF6ZKDEnU website. It just so happens that a free account comes with free computing credits. Currently I think it's $30 worth of credits (it's essentially like AWS credits) you can spend on GPU computing if you like.
1576,@rasbt,2022-12-07 20:43:37+00:00,https://twitter.com/rasbt/status/1600591885029998595,"@Vinee_ethN For sure! Planning to write a blog article later this week or next week! 
Btw do you mean the cloud computing credits? This is kind of unrelated ^^. If you want to track your progress on the course, you naturally need to be logged in to the website. So you can create a free...1/2"
1577,@rasbt,2022-12-07 19:56:16+00:00,https://twitter.com/rasbt/status/1600579969297809409,"@moro065 Yes, that's the plan! We are working on it! üòä"
1578,@rasbt,2022-12-07 19:55:47+00:00,https://twitter.com/rasbt/status/1600579846723223578,"@V_J_S_1 @AndrewYNg wow thanks, glad to hear this had such a positive influence ü´∂"
1579,@rasbt,2022-12-07 19:00:06+00:00,https://twitter.com/rasbt/status/1600565834367254533,"@LightningAI Predictive modeling all the way 

‚Ä¶ unless creating some AI art for my tweets and newsletters counts as work üòÜ"
1580,@rasbt,2022-12-07 18:49:01+00:00,https://twitter.com/rasbt/status/1600563044270018561,"I ""grew up"" with @AndrewYNg's machine learning course in 2013, and he has been a big inspiration for me ever since!

I am not only really flattered to hear this, but this is very touching on a personal level :)."
1581,@rasbt,2022-12-07 18:47:16+00:00,https://twitter.com/rasbt/status/1600562604727885825,"@olgias It's a bottom-up explanation. It's the same concept behind deploying stable diffusion, for example. e.g.,
- https://t.co/p63IOj2F8x
https://t.co/NgTb4sBxTB"
1582,@rasbt,2022-12-07 18:45:23+00:00,https://twitter.com/rasbt/status/1600562129307770880,"@olgias The focus of this course is to teach the latest knowledge / tools behind deep learning itself. Planning to have a different course in future that will focus on the deployment side. Not a super impressive app, but I do have a very simple overview here: https://t.co/LKeu5EtQxm"
1583,@rasbt,2022-12-07 18:43:27+00:00,https://twitter.com/rasbt/status/1600561643725131776,"@olgias Unit 10 will include some short info about app building. But luckily it doesn't require docker, haha"
1584,@rasbt,2022-12-07 17:51:42+00:00,https://twitter.com/rasbt/status/1600548620998410241,"Since it was a tad too long for a tweet-thread, I just shared an expanded write-up of the ""Revisiting Pretraining Objectives"" paper here: 
https://t.co/ZxEQsHIiL8 https://t.co/731yNL5rs7"
1585,@rasbt,2022-12-07 17:23:38+00:00,https://twitter.com/rasbt/status/1600541555252600832,"@kchonyc I hate these forms. My students are all automatically a 5/5 on these because why would I be writing a ""recommendation"" letter otherwise."
1586,@rasbt,2022-12-07 17:10:55+00:00,https://twitter.com/rasbt/status/1600538357880131584,"To those who got the 500 error yesterday:
 Sry, that was a server misconfiguration issue. It should be fixed now!"
1587,@rasbt,2022-12-07 17:07:49+00:00,https://twitter.com/rasbt/status/1600537578603675650,"@rasmus1610 Thanks, and good call, I will get that fixed!"
1588,@rasbt,2022-12-07 16:40:04+00:00,https://twitter.com/rasbt/status/1600530594416541697,"@yoavgo @ChristophMolnar And for those who say that the fact that you have to verify is an issue or tedious: remember, the same thing (still) applies to Wikipedia. Don't take facts at face value."
1589,@rasbt,2022-12-07 16:39:01+00:00,https://twitter.com/rasbt/status/1600530328040267776,"""Ahead of AI"" No. 3 is out!

This month, I'm covering:
- the release of various large language models
- major open source highlights (PyTorch 2.0!)
- pretraining objectives for tabular deep learning (research paper deep dive)
- and ""note-to-self"" tips

https://t.co/ZxEQsHZlN8"
1590,@rasbt,2022-12-07 16:09:44+00:00,https://twitter.com/rasbt/status/1600522957507420160,"@JulienMouchnino Arg, sry! You are not the first one! Luckily it's a rare issue, but it's so weird. We are looking into this rn!"
1591,@rasbt,2022-12-07 16:07:21+00:00,https://twitter.com/rasbt/status/1600522358976036864,"@ChristophMolnar Totally agree. A search engine and a conversational chatbot are different things. Both are useful, and they (should) have different use cases."
1592,@rasbt,2022-12-07 16:04:56+00:00,https://twitter.com/rasbt/status/1600521753146671104,"@RobertERitz Agreed. Both a traditional search engine and ChatGPT are useful in a way, but in different ways, as they are different things."
1593,@rasbt,2022-12-07 16:03:37+00:00,https://twitter.com/rasbt/status/1600521421234610176,@ducnh279 Glad to hear you liked the YT course! This course will be in a way more concise but also more expanded in certain aspects :)
1594,@rasbt,2022-12-07 13:52:24+00:00,https://twitter.com/rasbt/status/1600488397008691200,‚ÄúYou are holding it wrong‚Äù üôÉ
1595,@rasbt,2022-12-07 13:23:57+00:00,https://twitter.com/rasbt/status/1600481240322383872,"@shortstein @tdietterich Hah true, except for the 1 year time period some conference proceedings take to upload PDFs to their own website."
1596,@rasbt,2022-12-07 13:22:22+00:00,https://twitter.com/rasbt/status/1600480842274557953,"@wightmanr @LambdaAPI Whoa nice, that‚Äôs almost 2x the throughput. Sry, research-part-of-my-brain is asking what the speed up of the 3090 is when you use torch.compile on the model. From what I gathered, the speed-up is somewhat proportional to the memory bandwidth, so probably small(er), but curious"
1597,@rasbt,2022-12-07 13:17:44+00:00,https://twitter.com/rasbt/status/1600479674248835072,@svpino @elonmusk I was just counting ‚Ä¶ unfortunately that‚Äôs right
1598,@rasbt,2022-12-07 01:49:47+00:00,https://twitter.com/rasbt/status/1600306545383702528,"@tidyeval Glad you liked those! I can only answer from the PyTorch Lightning perspective. What I like about it is that you can use your existing PyTorch models and just wrap it in a LightningModule to make lots of things more convenient, like logging, mixed-precision training, multi-GPU..."
1599,@rasbt,2022-12-06 23:42:22+00:00,https://twitter.com/rasbt/status/1600274482123325440,"@soumithchintala Thanks, Soumith! üòä"
1600,@rasbt,2022-12-06 23:11:16+00:00,https://twitter.com/rasbt/status/1600266652725043201,@svpino Thanks for the kind words! üôå
1601,@rasbt,2022-12-06 21:01:00+00:00,https://twitter.com/rasbt/status/1600233871177834496,@TheFucking22 @AI_Sensei_ Attention &amp; LLms are are coming up in Unit 8
1602,@rasbt,2022-12-06 21:00:45+00:00,https://twitter.com/rasbt/status/1600233807080132608,"@olgias Python for everything, PyTorch for deep learning, Lightning Trainer for scaling to multiple GPUs and capturing logs, transformers for LLMs, ...üòä"
1603,@rasbt,2022-12-06 20:06:25+00:00,https://twitter.com/rasbt/status/1600220134915776512,@HemanthSai3187 Thanks @HemanthSai3187! Will be looking forward to hearing your thoughts!
1604,@rasbt,2022-12-06 19:55:54+00:00,https://twitter.com/rasbt/status/1600217489144545281,"@drexalt In the meantime, a few points on batching and efficiency in our blog post on stable diffusion here: https://t.co/Mulqo2IxuH"
1605,@rasbt,2022-12-06 19:54:37+00:00,https://twitter.com/rasbt/status/1600217166350934016,"@drexalt Thanks! There will be some basics in Unit 10.3!
(Great topic for a future, standalone course btw! üòá)"
1606,@rasbt,2022-12-06 19:40:54+00:00,https://twitter.com/rasbt/status/1600213711637327872,@megthescientist Awesome! Curious to hear what you think ^^
1607,@rasbt,2022-12-06 19:35:44+00:00,https://twitter.com/rasbt/status/1600212414074540032,"It will also go beyond my university class, covering multi-GPU training, self-supervised learning, setting up effective hyperparameter sweeps, learning rate scheduling ..."
1608,@rasbt,2022-12-06 19:29:20+00:00,https://twitter.com/rasbt/status/1600210800961933312,"@GiorgioMantova @taocds huh weird, just asked someone with Android and it doesn't seem to work. Strange"
1609,@rasbt,2022-12-06 19:22:32+00:00,https://twitter.com/rasbt/status/1600209092940730368,"@GiorgioMantova Of course not! In fact, Units 1-5 are all based on just PyTorch. I am using Lightning for a few things later, to get extra featurs and make things more convenient. But the core models are all pure PyTorch!"
1610,@rasbt,2022-12-06 19:20:35+00:00,https://twitter.com/rasbt/status/1600208600747503617,"@cwizprod1 Arg! But now worries, the (same) video here has subtitles / closed captions: https://t.co/rTuuDyp2lJ"
1611,@rasbt,2022-12-06 19:05:07+00:00,https://twitter.com/rasbt/status/1600204709008052225,@taocds Glad to hear! You made me a bit nervous tbh üòÑ
1612,@rasbt,2022-12-06 19:01:28+00:00,https://twitter.com/rasbt/status/1600203787960193025,@skeletonfire9 Somewhat periodically üòÜ . Will be rolling out one by one over the couple of weeks. There will be 10 units in total.
1613,@rasbt,2022-12-06 18:57:54+00:00,https://twitter.com/rasbt/status/1600202890282295296,"@JonathanSumDL Fair point. However, I will be covering more advanced stuff like setting efficient hyperparameter sweeps, multi-GPU training, self-supervised learning and so forth. Stuff that is typically missing from other courses and books"
1614,@rasbt,2022-12-06 18:33:51+00:00,https://twitter.com/rasbt/status/1600196839520673792,"With this one, I was trying to rethink and modernize my university class I have on YouTube. The main feedback was that it was nice, but way too long. 
So, I am curious to hear what you think about this one! üòä"
1615,@rasbt,2022-12-06 17:59:08+00:00,https://twitter.com/rasbt/status/1600188101107720192,"@DSaience Thanks! It's been super fun working on it. Was reviewing and refining all the materials I taught over the years, plus adding new things! Hope you'll like it!"
1616,@rasbt,2022-12-06 17:46:44+00:00,https://twitter.com/rasbt/status/1600184982382616578,@taocds Maybe a little server hiccup due to the traffic. should work now üòÖ
1617,@rasbt,2022-12-06 17:38:22+00:00,https://twitter.com/rasbt/status/1600182877664120833,@mj_bilodeau @cobra_winfrey @NikitaBurdein @aylohalo It took a great team to make it happen! Thanks for all your hard work!!
1618,@rasbt,2022-12-06 17:37:21+00:00,https://twitter.com/rasbt/status/1600182622235156485,@AI_Sensei_ Thanks! More of that to come ^^
1619,@rasbt,2022-12-06 17:33:24+00:00,https://twitter.com/rasbt/status/1600181629145665537,"Wondering what I've been up to lately?
I'm excited to share my new free course:

Deep Learning Fundamentals
-- Learning Deep Learning Using a Modern Open Source Stack!

I hope you‚Äôll find it useful! Check it out here:
üëâ https://t.co/B0rVXwTHSn

Let me know what you think! https://t.co/EyCewrHBrO"
1620,@rasbt,2022-12-06 14:40:49+00:00,https://twitter.com/rasbt/status/1600138195902951428,"@jeremyphoward Wow, that was quick üòÑ. I suppose both Google &amp; ChatGPT have their use cases. You probably need Google Search to crawl and find the latest relevant training data to update ChatGPT. At the same time ChatGPT would be an excellent tool inside Google Search to answer certain queries."
1621,@rasbt,2022-12-06 12:30:01+00:00,https://twitter.com/rasbt/status/1600105277411336192,@UlisesMoya12 Active learning can be considered as a subcategory.
1622,@rasbt,2022-12-06 01:53:12+00:00,https://twitter.com/rasbt/status/1599945019598974977,"@thomascygn @RespectToX yup, active learning is one of the many subcatgories of data-centric AI"
1623,@rasbt,2022-12-05 21:26:33+00:00,https://twitter.com/rasbt/status/1599877912189992961,@RespectToX Data-centric AI impliclitely includes everything from labeling &amp; cleaning to outlier removal. The key idea is that you keep the model training procedure fixed and iterate over the data. It's usually contrary to the academic method development approach where the data is fixed
1624,@rasbt,2022-12-05 21:24:57+00:00,https://twitter.com/rasbt/status/1599877510585409537,"@RespectToX So far, I think there are only seminars about it. But tbh it's not a topic that warrants a whole book. Unless, it's a project-based book that showcases examples."
1625,@rasbt,2022-12-05 21:23:58+00:00,https://twitter.com/rasbt/status/1599877262362705920,@RespectToX I wrote about it and will share at some point. Probably next year. In a nutshell: Data-centric AI is a paradigm or workflow where we keep the model training procedure fixed and iterate over the dataset to improve the predictive performance of a model.
1626,@rasbt,2022-12-05 21:20:38+00:00,https://twitter.com/rasbt/status/1599876425976541184,"Looks like data-centric AI, a workflow largely focused on iterating and improving the data.

(Yeah, data-centric AI is not new, but it's a nice term that captures *data work* and makes it attractive. 
Like *deep learning* made machine learning with neural networks attractive.)"
1627,@rasbt,2022-12-05 19:51:35+00:00,https://twitter.com/rasbt/status/1599854013721169920,"@alfcnz @ChristophMolnar Yeah, but only on Wednesday. I later saw from your tweets that you were there too and was thinking too bad that we missed each other!"
1628,@rasbt,2022-12-05 19:13:01+00:00,https://twitter.com/rasbt/status/1599844308328189958,"""In machine learning, there are not as many constraints on the model as in statistical modeling. Models are algorithms, not statistical models.""
Lots of good, quotable tidbits in that one!"
1629,@rasbt,2022-12-05 18:36:07+00:00,https://twitter.com/rasbt/status/1599835021229010944,"@rctatman No paper, same with StableDiffusion 2.0. I think people started giving up on papers and go for demos now. 

https://t.co/KcYakHEgxz"
1630,@rasbt,2022-12-05 14:32:32+00:00,https://twitter.com/rasbt/status/1599773722835320832,"@HarveenChadha @1littlecoder @tunguz @abhi1thakur Whoa, this is good! Haha, the last paragraph is 100% sth I'd say."
1631,@rasbt,2022-12-05 14:13:56+00:00,https://twitter.com/rasbt/status/1599769043153539072,"@1littlecoder @tunguz @abhi1thakur well, I am glad that it can't do [insert @tunguz favorite meme here] just yet üòÜ"
1632,@rasbt,2022-12-05 13:40:56+00:00,https://twitter.com/rasbt/status/1599760737278169088,@paul_rietschka need a regularized french press for regular people like me üòÖ
1633,@rasbt,2022-12-05 13:39:56+00:00,https://twitter.com/rasbt/status/1599760487163363330,"@paul_rietschka I have a love-hate relationship with it since there are too many variables: type of beans, grind setting, coffee amount, water temperature, water amount, percolation time, steeping time, stir/not stir, ..."
1634,@rasbt,2022-12-05 13:23:54+00:00,https://twitter.com/rasbt/status/1599756452453060610,@marksaroufim @ylecun Bookmarked &amp; now hoping someone sends me a A10G/A100 for Xmas üòÜ
1635,@rasbt,2022-12-05 13:19:01+00:00,https://twitter.com/rasbt/status/1599755221000851457,"What has changed in Stable Diffusion 2.0 to explain the diff in results? OpenCLIP? The data? The transformer architecture? The training procedure?
As much as we complain about the state of scientific publishing and call for demos, there's a lot of value in doing ablation studies."
1636,@rasbt,2022-12-05 13:18:59+00:00,https://twitter.com/rasbt/status/1599755215116193792,@marktenenholtz tell me you are living in the Bay Area without telling me you are living in the Bay Area üòÜ
1637,@rasbt,2022-12-05 13:03:15+00:00,https://twitter.com/rasbt/status/1599751253843533825,@ChristophMolnar And the (in)famous aeropress of course ;)
1638,@rasbt,2022-12-05 12:56:03+00:00,https://twitter.com/rasbt/status/1599749442172727296,ChatGPT does not seem very opinionated ... playing it safe üôÉ https://t.co/sH5Y7EPu5t
1639,@rasbt,2022-12-05 02:43:14+00:00,https://twitter.com/rasbt/status/1599595220785856513,"@SamuelMullr Whoa big congrats!! 

PS: If someone is looking for a tl;dr of TabPFN https://t.co/ftUnPLnKHU"
1640,@rasbt,2022-12-05 02:36:39+00:00,https://twitter.com/rasbt/status/1599593566334251008,@pwang We ‚Äújust‚Äù need to learn the right questions
1641,@rasbt,2022-12-05 02:34:30+00:00,https://twitter.com/rasbt/status/1599593024660463616,"@randall_balestr @ylecun @kohjingyu Thx for sharing. Personally I used ‚Äúcontrastive‚Äù as an umbrella term to capture all the pairwise relation learning methods. Non-contrastive would then be self-prediction (like next-word prediction, inpainting etc). Hence the confusion. Your non-contrastive in context makes sense."
1642,@rasbt,2022-12-04 21:56:23+00:00,https://twitter.com/rasbt/status/1599523033311776768,@pfau *protein structure refinement and prediction.
1643,@rasbt,2022-12-04 21:43:04+00:00,https://twitter.com/rasbt/status/1599519680707760128,"@paul_rietschka @MIT_CSAIL According to the internet, the final cut is the true director's cut. I think we mean the same thing then"
1644,@rasbt,2022-12-04 21:40:44+00:00,https://twitter.com/rasbt/status/1599519094860296192,@paul_rietschka @MIT_CSAIL No I haven‚Äôt! Thanks a lot for the recommendation. I usually don‚Äôt watch much anymore because I watched all the good stuff already and recent stuff is just meh
1645,@rasbt,2022-12-04 21:24:52+00:00,https://twitter.com/rasbt/status/1599515099940605952,@chrisalbon @fchollet Ok boomer
1646,@rasbt,2022-12-04 21:24:24+00:00,https://twitter.com/rasbt/status/1599514984102629377,"@paul_rietschka @MIT_CSAIL Sry, i have to go with the Final Cut https://t.co/KCUujLxj6f"
1647,@rasbt,2022-12-04 21:19:43+00:00,https://twitter.com/rasbt/status/1599513804488192000,@fchollet There was also a time when people said that perceptron algorithms were based on the principles of how biological neural networks such as the human brain work.
1648,@rasbt,2022-12-04 20:12:35+00:00,https://twitter.com/rasbt/status/1599496912230821888,"@ylecun @kohjingyu Or in other words, the ‚Äúabandon‚Äù on the slide only refers to *sample* contrastive methods, not contrastive methods at large? Making the point because if you just say ‚Äúabandon contrastive methods‚Äù it could imply you are favoring self-prediction methods"
1649,@rasbt,2022-12-04 20:07:50+00:00,https://twitter.com/rasbt/status/1599495716069515264,@ylecun @kohjingyu Thanks but I am still confused: So you don‚Äôt consider *dimension contrastive* methods as contrastive methods?
1650,@rasbt,2022-12-04 19:43:10+00:00,https://twitter.com/rasbt/status/1599489508642201600,@Merzmensch @TobiasWustefeld OpenCLIP?
1651,@rasbt,2022-12-04 19:33:05+00:00,https://twitter.com/rasbt/status/1599486971860029441,"@ylecun @kohjingyu Isn‚Äôt Barlow Twins a flavor of contrastive learning? If you consider the broad categories of SSL, self-prediction and contrastive learning, Barlow Twins looks like a flavor of a contrastive method where you minimize similarity betw. two embeddings (plus the redundancy condition)"
1652,@rasbt,2022-12-04 19:20:09+00:00,https://twitter.com/rasbt/status/1599483717713424384,"@Heptoop @MIT_CSAIL Tough one, and maybe a tad boring since three of those spots would probably be occupied by LOTR üòÜ"
1653,@rasbt,2022-12-04 19:19:19+00:00,https://twitter.com/rasbt/status/1599483507859824641,"@HexenkingTV @MIT_CSAIL The original one, although 2049 is pretty good too"
1654,@rasbt,2022-12-04 19:18:48+00:00,https://twitter.com/rasbt/status/1599483374556524544,@tianbao_li @MIT_CSAIL I like it a lot too. Much better than expected!
1655,@rasbt,2022-12-04 18:10:49+00:00,https://twitter.com/rasbt/status/1599466269018771457,@deliprao @apaszke @soumithchintala Maybe a philosophical question: can we call it declarative even though we ‚Äòdeclare‚Äô the model imperatively in Python? üòÜ
1656,@rasbt,2022-12-04 17:04:24+00:00,https://twitter.com/rasbt/status/1599449554385924097,@Plinz Which one? The Alexa internet analytics team or the voice assistant team?
1657,@rasbt,2022-12-04 17:01:57+00:00,https://twitter.com/rasbt/status/1599448935742914561,@MIT_CSAIL Blade Runner. The number of times I watched it ‚Ä¶ could have written a new book! üôÉ
1658,@rasbt,2022-12-04 16:41:37+00:00,https://twitter.com/rasbt/status/1599443817811234816,"@randal_olson Yeah, interesting, hashtags are not really a thing anymore ü§î. 
I also feel the same thing is happening to regular (non-quote) retweets"
1659,@rasbt,2022-12-04 15:33:00+00:00,https://twitter.com/rasbt/status/1599426551711350784,@TobiasWustefeld @Merzmensch Afaik you are üíØ right. All they did is applying an NSFW filter to the dataset.
1660,@rasbt,2022-12-04 14:58:16+00:00,https://twitter.com/rasbt/status/1599417809917730817,"@903124S Exactly! I‚Äôd say it uses its different strengths of being a symbolic, declarative framework for a different niche &amp; application area"
1661,@rasbt,2022-12-04 14:44:02+00:00,https://twitter.com/rasbt/status/1599414230209335297,"TIL that (part of) Theano is still alive and under active development ...

... as a library that allows one to define, optimize, and efficiently evaluate mathematical expressions involving multi-dimensional arrays.

It's now called Aesara: https://t.co/1GPMaF3LRq https://t.co/kjcwL3r5eG"
1662,@rasbt,2022-12-04 14:28:11+00:00,https://twitter.com/rasbt/status/1599410238750593024,@oleg008 Open to criticism
1663,@rasbt,2022-12-04 14:08:18+00:00,https://twitter.com/rasbt/status/1599405237382524928,@deliprao @apaszke @soumithchintala Really? I thought that was what people ultimately didn‚Äôt like about Theano and TensorFlow v1
1664,@rasbt,2022-12-03 19:40:42+00:00,https://twitter.com/rasbt/status/1599126501437231106,"@kohjingyu @ylecun Maybe self-prediction with constraints (e.g., geometric constraints)"
1665,@rasbt,2022-12-03 18:46:10+00:00,https://twitter.com/rasbt/status/1599112774579126272,"@Krzych337 if that's a concern you could just add type hints
https://t.co/eQWX8REvky"
1666,@rasbt,2022-12-03 15:22:41+00:00,https://twitter.com/rasbt/status/1599061568482054144,"@DSaience Simplicity? Yes. But in a good way. 
After watching the @PyTorch keynote yesterday, I am more convinced than ever that you can do some pretty complicated stuff in Python üòâ (think of TorchDynamo, AOTAutograd, PrimTorch, and TorchInductor)"
1667,@rasbt,2022-12-03 14:31:48+00:00,https://twitter.com/rasbt/status/1599048760835059712,Or they are #Python coders https://t.co/kx8K4pFRCi
1668,@rasbt,2022-12-03 13:45:50+00:00,https://twitter.com/rasbt/status/1599037195951607808,"@soumithchintala @giffmana Yes, people hated the compile time. It was really bad for debugging. On the flip side people still loved Theano coz it was still Python (vs the Lua-aspect of Torch 7).
The symbolic a differentiation engine in Theano is still cool. I think PyMC switched back to Theano as a backend"
1669,@rasbt,2022-12-03 04:09:41+00:00,https://twitter.com/rasbt/status/1598892200833662976,"@cHHillee You write-ups are always super technical ‚Ä¶ in a good, insightful way! Always lots to learn. Looking forward to it."
1670,@rasbt,2022-12-02 22:09:46+00:00,https://twitter.com/rasbt/status/1598801625820413954,"1. Backwards-compatibility is a relief üòÆ‚Äçüí®
2. Speed-up is a delight ‚ò∫Ô∏è
3. Debugging help is the cherry on top! üç∞

(4. Can I say that the work &amp; interplay of TorchDynamo, AOTAutograd, PrimTorch, and TorchInductor is super impressive!? üëè)"
1671,@rasbt,2022-12-02 21:52:33+00:00,https://twitter.com/rasbt/status/1598797293007753217,"@mpaepper @PyTorch It has better (99%) graph-capture due to TorchDynamo, has a relatively simple IR implemented in Python to generate Triton code, and has better backward support."
1672,@rasbt,2022-12-02 21:51:18+00:00,https://twitter.com/rasbt/status/1598796978992709633,@joe_deasy @emilymbender Shouldn't make a difference. The paper is still published/accepted at NeurIPS. It is just uploaded to arxiv.
1673,@rasbt,2022-12-02 18:52:19+00:00,https://twitter.com/rasbt/status/1598751936517672961,@drexalt @PyTorch Yes! As far as I understand the .optimize call will be changed to .compile
1674,@rasbt,2022-12-02 18:33:33+00:00,https://twitter.com/rasbt/status/1598747214561435648,"@cdixon On that note, I wonder what the query costs are for both Google search and ChatGPT (ie how much money does the company lose due to server runtime costs if a user submits a query)"
1675,@rasbt,2022-12-02 17:41:35+00:00,https://twitter.com/rasbt/status/1598734133311803399,"@drexalt @PyTorch No need, as the existing API will stay 100% the same :). Lots of under the hood changes but it won‚Äôt affect the way you write PyTorch code."
1676,@rasbt,2022-12-02 17:30:39+00:00,https://twitter.com/rasbt/status/1598731384251506689,"@MuhammadAnas707 The ""return self"" returns the object itself. As a user, you can ignore it. It's useful for building scikit-learn pipelines."
1677,@rasbt,2022-12-02 17:29:36+00:00,https://twitter.com/rasbt/status/1598731117649170450,"@MuhammadAnas707 w_ &amp; b_ store the model parameters: w_ the weights, b_ the bias unit. 
Why the trailing underscore? A scikit-learn convention to indicate that these are not tuning parameters set by the user but model  parameters modified during training."
1678,@rasbt,2022-12-02 16:37:39+00:00,https://twitter.com/rasbt/status/1598718045987295232,"@ammaryh92 @svpino Scientific computing related? I mean there's a lot. At the core, you have NumPy, SciPy for many scientific works, from astrophysics to computational bio. And pandas of course, which is somewhere at the intersection of scientific computing and data science."
1679,@rasbt,2022-12-02 16:35:11+00:00,https://twitter.com/rasbt/status/1598717423036862464,"7/6
Here's a good at-a-glance summary of the TorchInductor compiler stack: https://t.co/6oW0VujkcJ"
1680,@rasbt,2022-12-02 16:22:54+00:00,https://twitter.com/rasbt/status/1598714335760482318,There is now a full write-up here: https://t.co/yAMJ7IcFO0
1681,@rasbt,2022-12-02 16:19:11+00:00,https://twitter.com/rasbt/status/1598713398912507904,"@drufball I think the acquisition happened in Dec 2019, but I can't see anything fishy about the trend line. 
I am not sure if they have open-sourced their paper-scraping code, but I cannot imagine they would skew the numbers."
1682,@rasbt,2022-12-02 16:07:22+00:00,https://twitter.com/rasbt/status/1598710425406914563,"@drufball Totally agree. According to Papers with Code, that's already a lot of steam (https://t.co/DcWadBnqE3) https://t.co/QoCXTYMnIz"
1683,@rasbt,2022-12-02 15:57:13+00:00,https://twitter.com/rasbt/status/1598707869443948544,"Tested across 7k projects on GitHub, it works 93% out of the box right now, and there is an 43% (average) speed-up on an A100. Note that the faster the GPU the more gains you will see. Why? Because the faster the GPU, the more eager mode struggles to keep up.
6/6 https://t.co/eSCOyS74vF"
1684,@rasbt,2022-12-02 15:57:10+00:00,https://twitter.com/rasbt/status/1598707856567463936,"At first, torch.compile will only support the model, later on it will also support the whole training loop.
5/6 https://t.co/ttQU1QLx1b"
1685,@rasbt,2022-12-02 15:57:07+00:00,https://twitter.com/rasbt/status/1598707845377105921,"It's because it will meaningfully change the user experience. We will still be able to run our models in eager mode. However, as we try to squeeze performance for bigger models, we want to wrap our code in torch.compile.
4/6"
1686,@rasbt,2022-12-02 15:57:06+00:00,https://twitter.com/rasbt/status/1598707842717925376,"How? There is now a new feature, torch.compile, available in the nightly release. It will be part of the upcoming 1.14 release.
A stable PyTorch 2.0 release will then follow in March 2023.
Why 2.0 if there are no code rewrites, just an optional feature, torch.compile?
3/6"
1687,@rasbt,2022-12-02 15:57:06+00:00,https://twitter.com/rasbt/status/1598707838947192832,"The challenge w. the current version of PyTorch is that the eager mode struggles to keep up with increasing GPU bandwidths and crazier model architectures.
On the other hand, how do you keep PyTorch easy to use and debug?
The tricky balance between code accessibility &amp; speed.
2/6 https://t.co/8oIAeakSHh"
1688,@rasbt,2022-12-02 15:57:03+00:00,https://twitter.com/rasbt/status/1598707827886804992,"PyTorch 2.0 was just announced at the @PyTorch Conference!

The focus is speed and accessibility, and the great news is that
there are no breaking changes. PyTorch 2.0 will be fully backward compatible.

Here's my tl;dw

1/6 https://t.co/1ZmqW2wGiS"
1689,@rasbt,2022-12-02 13:33:37+00:00,https://twitter.com/rasbt/status/1598671732713443330,"@emilymbender Tweeting about a NeurIPS paper on arxiv is just a UI preference. Nothing wrong with that. 

But now that you mention it, it‚Äôs worth thinking about whether it still makes sense for non-profits to roll their own archival system vs just referencing/using arxiv in the first place."
1690,@rasbt,2022-12-02 13:27:29+00:00,https://twitter.com/rasbt/status/1598670186885824512,"@giffmana And on top of that there are also two flavors of meta-learning for tabular data: 
(1) learning from past experiments &amp; Bayesian opt (like AutoML)
(2) learning from meta-features"
1691,@rasbt,2022-12-02 13:21:23+00:00,https://twitter.com/rasbt/status/1598668652286451713,"@giffmana Since it‚Äôs a broad term for different things, is this in the context of few-shot learning here? In that case I think you are definitely spot on for domains like image and text"
1692,@rasbt,2022-12-02 13:03:44+00:00,https://twitter.com/rasbt/status/1598664213395906563,"@svpino Let me add a big one to this list:
Scientific computing!"
1693,@rasbt,2022-12-02 12:53:22+00:00,https://twitter.com/rasbt/status/1598661603825696769,"@wightmanr Can‚Äôt bring myself to like Mastodon for some reason. Feels a bit like the same old but not in a good way. There needs to be a fresh take on social media. 
Until then, LinkedIn doesn‚Äôt seem too bad but a bit noisy (no concept of lists yet). Maybe we should start an ML group there?"
1694,@rasbt,2022-12-02 12:41:06+00:00,https://twitter.com/rasbt/status/1598658514829955072,"@Tom14985282 @mashrur_morshed I had no idea! Interesting tidbit, thanks for sharing!"
1695,@rasbt,2022-12-01 17:30:26+00:00,https://twitter.com/rasbt/status/1598368939821748224,"@MuhammadAnas707 Hope that was fun! Haha, wait until you are in chapter 10 and code a multilayer perceptron from scratch üòÖ"
1696,@rasbt,2022-12-01 17:29:06+00:00,https://twitter.com/rasbt/status/1598368603715342351,"@capetorch Yup, exactly! That‚Äôs why I probably just noticed it today for the first time when working with a very small dataset"
1697,@rasbt,2022-12-01 16:01:41+00:00,https://twitter.com/rasbt/status/1598346604532097025,@KyleCranmer Nice! So the tl;dr is that the unbiased version (ddof=1) is biased but less biased!? https://t.co/rzTSIAl9gY
1698,@rasbt,2022-12-01 15:20:03+00:00,https://twitter.com/rasbt/status/1598336128737738752,"@KyleCranmer Hah, touche. You are right, it doesn't factor in the-square root transform.
Maybe the sample standard deviation is empirically *less* biased estimate of the population standard deviation :P. Dunno to be honest."
1699,@rasbt,2022-12-01 15:07:07+00:00,https://twitter.com/rasbt/status/1598332875627184129,@SnehilRC Probably :). The thing is also that it doesn't really matter with the typical dataset sizes we use in ML. But it once again somewhat matters in very small batch size regimes.
1700,@rasbt,2022-12-01 15:06:15+00:00,https://twitter.com/rasbt/status/1598332658001580032,"@marktenenholtz same thing, happened to me early on in my PhD work, lol"
1701,@rasbt,2022-12-01 15:05:27+00:00,https://twitter.com/rasbt/status/1598332454032576516,"You can change it of course. Above, I only showed the default settings. To compute the population or biased sample variance (/ standard deviation) in PyTorch, you can set unbiased=False: https://t.co/Hxj75ukHQo"
1702,@rasbt,2022-12-01 15:01:53+00:00,https://twitter.com/rasbt/status/1598331559190433792,"Since there've been a couple of questions, a short clarification. The reason why the results are different is that one implementation (sample statistic) uses ""Bessel's correction"". E.g., the ""-1"" term in the denominator shown for the variance below https://t.co/FDct3H8Xlp"
1703,@rasbt,2022-12-01 14:33:02+00:00,https://twitter.com/rasbt/status/1598324299034554368,"Was just standardizing a small dataset in PyTorch ...

After all these years, I just now noticed that it defaults to *sample statistics*!! https://t.co/7odSyPafJh"
1704,@rasbt,2022-12-01 12:49:50+00:00,https://twitter.com/rasbt/status/1598298324511395840,"* Oops, I just realize the ""typo"", I originally meant to write

""... similar to how the term *deep learning* made neural networks attractive again.""

But you were all thinking that of course given that no one said anything :)"
1705,@rasbt,2022-12-01 12:47:36+00:00,https://twitter.com/rasbt/status/1598297762222772224,"@SunnySanyal9 @RobertLaurella @broadercollabs Interesting topic (and thinking of models like BLOOM, also a very timely one!). Thanks for the invite, it sounds super interesting, but unfortunately, I will already be out of town."
1706,@rasbt,2022-12-01 03:01:38+00:00,https://twitter.com/rasbt/status/1598150302557143040,@SunnySanyal9 @RobertLaurella Thanks for joining!!
1707,@rasbt,2022-11-30 20:01:04+00:00,https://twitter.com/rasbt/status/1598044460625326080,"@datenzauberai Or computational statistics and data science, the list goes on an on :)"
1708,@rasbt,2022-11-30 20:00:10+00:00,https://twitter.com/rasbt/status/1598044235131146241,@datenzauberai Agreed. But then again so many people probably said they always worked with neural networks before deep learning was coined üòâ
1709,@rasbt,2022-11-30 18:20:02+00:00,https://twitter.com/rasbt/status/1598019033919795202,"@EigenGender All HWs will be live-coding/writing whiteboard sessions from now on.

(Silver lining: Maybe not a bad way to prepare for the world of tech interviews.)"
1710,@rasbt,2022-11-30 16:59:10+00:00,https://twitter.com/rasbt/status/1597998685253963777,"@CalcCon Yap, not sure why, but ordinal methods are totally under-appreciated for some reason!"
1711,@rasbt,2022-11-30 16:59:01+00:00,https://twitter.com/rasbt/status/1597998645630025728,"Are you at #NeurIPS2022 and have no plans from 6-8 pm tonight, yet?

@RobertLaurella &amp; I will be organizing a social in Room 388:
""Industry, Academia, and the In-Betweens""

Stop by and say hello! Lots of stuff to talk about!

(Details here: https://t.co/NFjn55D3B3)"
1712,@rasbt,2022-11-30 16:34:58+00:00,https://twitter.com/rasbt/status/1597992593068957698,"@dericdesta It should be possible to use the CORN loss for gradient boosting / XGBoost. It's a drop-in replacement for the cross-entropy.
(How to actually swap/define custom losses in XGBoost is another story, never tried that.)"
1713,@rasbt,2022-11-30 15:40:41+00:00,https://twitter.com/rasbt/status/1597978934976843778,"@kevinschawinski Yes, there have been lots of interesting developments in this space. (Based on some of the recent data centric AI seminars I attended)"
1714,@rasbt,2022-11-30 15:39:53+00:00,https://twitter.com/rasbt/status/1597978730843975680,"@GermanicusCM Yes, I think it will also help teams to be more aligned with the overall goal, not just the tinkering :)"
1715,@rasbt,2022-11-30 15:11:49+00:00,https://twitter.com/rasbt/status/1597971668940775427,"@RyYesterday Yeah, as a video game player, I can already see the confusion with AI in gaming ...
Btw. I'd say that data-centric AI is more about the workflow than the model, so you can make anything data-centric. It's a bit more natural for ML than other paradigms, because ML learns from data"
1716,@rasbt,2022-11-30 15:00:29+00:00,https://twitter.com/rasbt/status/1597968819267731457,"@RyYesterday I see. Yeah, it's the classic debate üòÜ. The concentric circles where ML is (one of) the learning algorithms(s) for AI"
1717,@rasbt,2022-11-30 14:59:19+00:00,https://twitter.com/rasbt/status/1597968522319376385,"@jmschreiber91 @PyTorch See, that's why, for the sake of scientific discussion &amp; dissemination, the top-priority feature should be sarcasm font, @elonmusk!"
1718,@rasbt,2022-11-30 14:52:04+00:00,https://twitter.com/rasbt/status/1597966700577980418,"@RyYesterday To me it's a bit different. Is it related to machine learning? Sure. The same way hyperparameter optimization is related to machine learning.

https://t.co/QjURCm0tqf"
1719,@rasbt,2022-11-30 14:46:01+00:00,https://twitter.com/rasbt/status/1597965175763611648,"Many people think ""Data-centric AI"" is nothing new. They're missing the point.

The point of ""Data-centric AI"" is to make ""caring about data quality"" attractive again ...

... similar to how the term ""deep neural networks"" made neural networks attractive again."
1720,@rasbt,2022-11-30 14:00:07+00:00,https://twitter.com/rasbt/status/1597953624596172801,"@_ScottCondron Totally agree with you, and ""experiments ‚â† better ML"" is also spot on. 
That being said, the number of hyperparameters keeps increasing, and you do need to run a lot of experiments to even get a competitive baseline these days."
1721,@rasbt,2022-11-30 03:32:34+00:00,https://twitter.com/rasbt/status/1597795696413114369,"@jmschreiber91 I guess it‚Äôs probably already fast enough as is for the common use cases. 
But yes, many people use GPUs, and since it‚Äôs already implemented in PyTorch ‚Ä¶"
1722,@rasbt,2022-11-30 02:42:53+00:00,https://twitter.com/rasbt/status/1597783192794468358,"@jmschreiber91 And that‚Äôs just on CPU? üò≤

How is the GPU support btw?"
1723,@rasbt,2022-11-30 02:41:14+00:00,https://twitter.com/rasbt/status/1597782779999432704,"@jmschreiber91 @PyTorch Wow! Knowing you, I went back and forth between thinking you were kidding or not in our previous convos. I settled on ‚Äúyou were kidding‚Äù. What a nice surprise!"
1724,@rasbt,2022-11-30 02:36:04+00:00,https://twitter.com/rasbt/status/1597781476556558336,"@F_Vaggi @3scorciav @soumithchintala @OriolVinyalsML @teoliphant @ogrisel Yeah, I remember Perl for bioinfo. I didn‚Äôt mind it actually. But Python just feels smoother for my mental programming model somehow. Maybe the OOP aspects."
1725,@rasbt,2022-11-30 02:30:52+00:00,https://twitter.com/rasbt/status/1597780171050057729,"@F_Vaggi @3scorciav @soumithchintala @OriolVinyalsML @teoliphant @ogrisel Yeah, that‚Äôs a very interesting alternative universe to ruminate about!"
1726,@rasbt,2022-11-30 01:09:49+00:00,https://twitter.com/rasbt/status/1597759773944188928,@pwang @3scorciav @soumithchintala @OriolVinyalsML @teoliphant @ogrisel I heard from others that he tends to block deep learning researchers and engineers for some unkown reason
1727,@rasbt,2022-11-30 00:53:13+00:00,https://twitter.com/rasbt/status/1597755596496773121,"@xLaszlo @3scorciav @soumithchintala @OriolVinyalsML @teoliphant @ogrisel @3scorciav haha there is probably only one right answer! Btw regarding the free version of MATLAB, you mean Octave? I think it was never super popular actually. I could tell because I had to use it for HW assignments and constantly had code issues üòÜ"
1728,@rasbt,2022-11-29 20:32:57+00:00,https://twitter.com/rasbt/status/1597690098178719745,"@TheRandomMtrix Nah, just ping one of the 500 co-authors for the code"
1729,@rasbt,2022-11-29 16:53:05+00:00,https://twitter.com/rasbt/status/1597634765124796417,@shockrobortyy We need to up our prompt engineering game i guess üòÜ
1730,@rasbt,2022-11-29 16:48:30+00:00,https://twitter.com/rasbt/status/1597633610575933441,@Thom_Wolf For example https://t.co/nAIx8hcvcq and the resources it links :)
1731,@rasbt,2022-11-29 16:46:41+00:00,https://twitter.com/rasbt/status/1597633157385551874,@Machine01776819 Agreed. It‚Äôs more AI as a product/service now
1732,@rasbt,2022-11-29 15:21:03+00:00,https://twitter.com/rasbt/status/1597611606317289473,"The new slogan of AI might as well be ""show, don't tell""!

Finding the BLOOM paper was really hard. Searching Google &amp; multiple blogs, all I found were demos.

If someone's still interested in papers: ""BLOOM: A 176B-Parameter...Language Model"" https://t.co/W0fyOnHF6M https://t.co/5hcHOLUlp4"
1733,@rasbt,2022-11-29 12:37:21+00:00,https://twitter.com/rasbt/status/1597570407728836610,"Most ML practitioners think they lack compute but it‚Äôs actually programming and setup.

If you have a good setup you can do both 
1) flexibly run your experiments on a single machine and 
2) *simply* scale to multi-node cloud machines when needed."
1734,@rasbt,2022-11-29 12:30:10+00:00,https://twitter.com/rasbt/status/1597568599790870529,@zacharylipton Google Groups
1735,@rasbt,2022-11-29 12:28:01+00:00,https://twitter.com/rasbt/status/1597568058293620736,"@tianbao_li @3scorciav @soumithchintala @OriolVinyalsML @teoliphant @ogrisel It‚Äôs a neat, minimalist framework indeed! Used it in my book to build a simple web app for a movie review classifier"
1736,@rasbt,2022-11-29 12:09:15+00:00,https://twitter.com/rasbt/status/1597563337172475904,@tianbao_li @3scorciav @soumithchintala @OriolVinyalsML @teoliphant @ogrisel I have some thoughts based on hearsay but I am not a web developer. Don‚Äôt want to give misleading info üòÖ
1737,@rasbt,2022-11-29 12:03:56+00:00,https://twitter.com/rasbt/status/1597561997985746953,@Academ_pandem @AndrewYNg @OpenAI Interesting. Maybe. For me personally the problem was that it was advertised as an AI service that writes complete research articles for you (as opposed to an AI service that generates article templates or improves your writing)
1738,@rasbt,2022-11-29 12:00:17+00:00,https://twitter.com/rasbt/status/1597561081106681857,"@3scorciav @soumithchintala @OriolVinyalsML @teoliphant @ogrisel 2/2 
3) a wide variety of useful libraries and big ecosystem (like NumPy + SciPy for scientific computing, or Django &amp; Flask a popular web frameworks back then). 
4) the ease of use, the vast amount of libraries, and the big community lead to a positive momentum to keep growing"
1739,@rasbt,2022-11-29 11:57:25+00:00,https://twitter.com/rasbt/status/1597560358209978368,"@3scorciav @soumithchintala @OriolVinyalsML @teoliphant @ogrisel Sry as a matter of principle I am not listening to that podcast :). As to why I think Python became so popular: 1) style &amp; syntax makes it very beginner-friendly. 2) Then being very-general purpose, it was adopted across many big fields (web and science). This then lead to ‚Ä¶ 1/2"
1740,@rasbt,2022-11-29 01:01:59+00:00,https://twitter.com/rasbt/status/1597395412779864065,"@nicolasvelezb @AndrewYNg Reproducible is nice, but it does not universally apply. Eg it wouldn‚Äôt work for review papers. (One of the examples Galactica had on their website was generating a review paper)"
1741,@rasbt,2022-11-28 23:53:32+00:00,https://twitter.com/rasbt/status/1597378186077425664,"@Ryan_Lanham @AndrewYNg Yes, I am in favor of progress. The marketing on that one was just off."
1742,@rasbt,2022-11-28 22:36:07+00:00,https://twitter.com/rasbt/status/1597358706408460289,@ChurchillMic Thanks for sharing! I suppose that Stable Diffusion 3.0 will add an input parser module that will automatically take care of the negative prompting then to improve the UI üòÜ
1743,@rasbt,2022-11-28 22:14:12+00:00,https://twitter.com/rasbt/status/1597353190110171136,"@Ryan_Lanham @AndrewYNg To make it harder to automatically generate and submit fake research articles based on misinformation. E.g., there was this example where someone had Galactica generate a research article on the benefits of eating crushed glass"
1744,@rasbt,2022-11-28 21:57:28+00:00,https://twitter.com/rasbt/status/1597348979444174848,"@karpathy Nice! Really interested in checking that out. 
Is it basically like Masterclass in longer form and more physics &amp; computer-sciency? Can you consume it as audio-only or are the videos materials crucial (or does it depend on the class)? Sry so many questions! üòÖ"
1745,@rasbt,2022-11-28 21:54:12+00:00,https://twitter.com/rasbt/status/1597348156630761473,"@AndrewYNg 2/2
I am not against progress, and I think there is room for compromise. 
For example, why not changing the marking: instead of promising a system that generates entire articles and fasts, create an ""article template generator"" where researchers have to fill in the facts."
1746,@rasbt,2022-11-28 21:51:17+00:00,https://twitter.com/rasbt/status/1597347421293776896,"@AndrewYNg Well said!
On one hand, I am in favor or sharing large language models in the interest of science (both figuratively and literally). However, as a former moderator of the Arxiv machine learning category, I do share some of the concerns.
1/2"
1747,@rasbt,2022-11-28 20:52:14+00:00,https://twitter.com/rasbt/status/1597332560882737152,"@dataBiryani Hah, that's prompt tuning 2.0 right there."
1748,@rasbt,2022-11-28 18:45:12+00:00,https://twitter.com/rasbt/status/1597300595236274176,"@actualGeorg @LightningAI So, this was a serving example using diffusion. This works with any type of ML model.

To finetune it, you would need to train it. Here's an example for PyTorch + Lightning, but also that one works with any model, and not just PyTorch (eg it could be sklearn or XGBoost) https://t.co/c7cqNWlnzB"
1749,@rasbt,2022-11-28 18:29:37+00:00,https://twitter.com/rasbt/status/1597296672182525952,"@iamgrigorev @LightningAI Can it be simpler if you just want to run locally? Sure. But with this code, you can do both, run it locally or have it run as a production system in the cloud. I don't think there is any other platform that makes a cloud deployment that simple :)"
1750,@rasbt,2022-11-28 18:21:57+00:00,https://twitter.com/rasbt/status/1597294741309206528,"@marktenenholtz Hah, should be pretty fast with that one! Give it a try &amp; let us know!

To run locally, 
1) copy the code from https://t.co/U1SRtfrs8h into a file diffusion. py
2) run `pip install lightning`
3) run `lightning run app https://t.co/KnyPfIyToF --setup` https://t.co/VnxRDy9NX9"
1751,@rasbt,2022-11-28 16:37:41+00:00,https://twitter.com/rasbt/status/1597268502196682752,@RuthgerRighart @aaron_wtr What‚Äôs the rebuttal deadline üòÖ
1752,@rasbt,2022-11-28 16:29:27+00:00,https://twitter.com/rasbt/status/1597266431951134721,@shwayguy Interesting! Btw image quality is certainly better but content quality is what I find is lacking. But yeah maybe it‚Äôs a good (better) base that just requires more finetuning.
1753,@rasbt,2022-11-28 16:27:54+00:00,https://twitter.com/rasbt/status/1597266039255203840,"@aaron_wtr @RuthgerRighart Yeah, I think there is no real good metric for that (yet). It‚Äôs a tricky problem that existed since the good old GAN days. FID is pretty rough."
1754,@rasbt,2022-11-28 15:27:27+00:00,https://twitter.com/rasbt/status/1597250829765181440,@RuthgerRighart @aaron_wtr I didn‚Äôt do any prompt engineering but just put in the first fun phrase that came to mind. This is not a peer-reviewed research tweet lol. üòÜ
1755,@rasbt,2022-11-28 15:09:12+00:00,https://twitter.com/rasbt/status/1597246235437506560,Step 4: Try your own prompts! https://t.co/YiLfSot2Nw
1756,@rasbt,2022-11-28 15:09:08+00:00,https://twitter.com/rasbt/status/1597246219125825537,Step 3: Copy the example code and prompt and run it in your Python session https://t.co/aJbW0kK3aJ
1757,@rasbt,2022-11-28 15:09:06+00:00,https://twitter.com/rasbt/status/1597246209130827776,"Step 2: Wait 2-3 min for the app to launch, then click on ""Open App"" https://t.co/EEvhEPWMzq"
1758,@rasbt,2022-11-28 15:09:03+00:00,https://twitter.com/rasbt/status/1597246198326341634,"Btw we just released a @LightningAI component that lets you run your own Stable Diffusion 2.0 server in ~5 min (in just 4 simple steps).

Step 1: Click on the ""Serve Stable Diffusion 2.0"" button.
(right from https://t.co/VbQC5o9FIq)! https://t.co/PCI4cKG7t5"
1759,@rasbt,2022-11-28 15:05:57+00:00,https://twitter.com/rasbt/status/1597245418815229958,@gusthema I am using a cloud machine and it takes about 5 seconds per image. Sampling from diffusion models is naturally slower than GANs
1760,@rasbt,2022-11-28 14:56:14+00:00,https://twitter.com/rasbt/status/1597242971707297794,@aaron_wtr I just picked the first 4 images from each
1761,@rasbt,2022-11-28 14:38:03+00:00,https://twitter.com/rasbt/status/1597238396820213760,"That was a nice, long Thanksgiving weekend!

And yes, I also think that Stable Diffusion 1.5 is actually better than Stable Diffusion 2.0 https://t.co/LldadPPWCW"
1762,@rasbt,2022-11-28 14:23:48+00:00,https://twitter.com/rasbt/status/1597234808614420480,"@kchonyc 2:2, what a comeback! üî•"
1763,@rasbt,2022-11-28 11:51:51+00:00,https://twitter.com/rasbt/status/1597196568251318272,@elonvestor @Ukerzel Haha surprised to see that the ‚Äúdata are‚Äù vs ‚Äúdata is‚Äù debate is still such as sensitive topic in 2022 üôÉ
1764,@rasbt,2022-11-28 11:35:15+00:00,https://twitter.com/rasbt/status/1597192394579259392,Great content thus far but I spotted a major flaw: ‚Äúdata are‚Äù (as opposed to ‚Äúdata is‚Äù üòÜ)
1765,@rasbt,2022-11-27 18:11:30+00:00,https://twitter.com/rasbt/status/1596929724311535616,@ChristophMolnar @guysnovelutumba Cutting content is the hardest part about writing
1766,@rasbt,2022-11-27 18:03:09+00:00,https://twitter.com/rasbt/status/1596927625217593345,@guysnovelutumba @ChristophMolnar It‚Äôs surprisingly small and compact (which is a positive thing)!
1767,@rasbt,2022-11-27 16:57:16+00:00,https://twitter.com/rasbt/status/1596911042533068800,"Looks like I got myself an early Xmas present @ChristophMolnar! 
Gonna be a nice, pocketable airplane companion for the trip to #NeurIPS2022 next week!

(I‚Äôll let you all know what I think! üòä) https://t.co/SQBrbgDzvb"
1768,@rasbt,2022-11-27 16:28:17+00:00,https://twitter.com/rasbt/status/1596903749523365888,@chrisalbon *People you‚Äôve never met asking for free consulting.
1769,@rasbt,2022-11-27 16:21:00+00:00,https://twitter.com/rasbt/status/1596901915094302720,"@chrisalbon Or the latest email trend: ‚ÄúHey, I just stumbled upon your website. I think you can help with ABC / you are interested in XYZ. Let me know a good time to chat next week.‚Äù"
1770,@rasbt,2022-11-27 16:16:32+00:00,https://twitter.com/rasbt/status/1596900791721558016,"@MuhammadAnas707 I did a few months ago, but I don‚Äôt have any copies left üòÖ"
1771,@rasbt,2022-11-27 15:35:42+00:00,https://twitter.com/rasbt/status/1596890514477182976,"@MuhammadAnas707 Yup! I cover them in Chapter 3, and I revisit them in the ensemble methods chapter when talking about AdaBoost and Gradient Boosting."
1772,@rasbt,2022-11-26 23:58:36+00:00,https://twitter.com/rasbt/status/1596654688857980928,"@CSProfKGD Yes, that‚Äôs the best feeling! Only rivaled by the joy when a former student thanks you for how useful your book &amp; classes were for finding a job / solving a real-world problem!"
1773,@rasbt,2022-11-26 23:51:54+00:00,https://twitter.com/rasbt/status/1596653003158818818,@hardmaru @LambdaAPI Nice! That looks like one productive Xmas break right there! Wow!
1774,@rasbt,2022-11-26 23:44:05+00:00,https://twitter.com/rasbt/status/1596651033786306560,@DSaience @marktenenholtz It‚Äôs a long thanksgiving weekend ;)
1775,@rasbt,2022-11-26 23:43:18+00:00,https://twitter.com/rasbt/status/1596650836536754177,@GiorgioMantova @anilkeshwani I‚Äôd say it‚Äôs also a bit of a personal preference or pattern I like using. Usually the code I share is also how I would code it for myself :)
1776,@rasbt,2022-11-26 22:51:29+00:00,https://twitter.com/rasbt/status/1596637798001676289,@anilkeshwani Glad to hear this was useful!!
1777,@rasbt,2022-11-24 16:37:45+00:00,https://twitter.com/rasbt/status/1595818966886547456,@CicmilJovan Not all good things come in threes
1778,@rasbt,2022-11-24 16:19:01+00:00,https://twitter.com/rasbt/status/1595814252702404608,"The double-edged sword of AI: a smart inbox that prioritizes content will make us more productive, but we'll spend more time filtering out fake content."
1779,@rasbt,2022-11-24 16:16:11+00:00,https://twitter.com/rasbt/status/1595813538672611333,@MuhammadAnas707 @jsulopzs Tbh I would recommend it in chronological order
1780,@rasbt,2022-11-24 16:03:51+00:00,https://twitter.com/rasbt/status/1595810437483970560,@patloeber @AssemblyAI Whoa! Happy creating!
1781,@rasbt,2022-11-24 15:57:06+00:00,https://twitter.com/rasbt/status/1595808737977040897,"@MuhammadAnas707 @jsulopzs That‚Äôs a productive Thanksgiving! I hope you are liking the book so far! Chapter 3 is a broad survey, a top down view on the different algos before the next chapters dive into workflow concepts."
1782,@rasbt,2022-11-23 21:01:13+00:00,https://twitter.com/rasbt/status/1595522881861083151,"@pandaym @tunguz We will have free lunch at the Tabular Data workshop at #NeurIPS2022 next week! Come and join us!
https://t.co/OY35qVyZSI"
1783,@rasbt,2022-11-23 17:32:00+00:00,https://twitter.com/rasbt/status/1595470231685808135,@monsieurwagner @annargrs @Sergei_Imaging @ylecun Yeah you are right. If you don‚Äôt make it part of the model (training) you would need a second model parsing and modifying the outputs for entity matching &amp; masking
1784,@rasbt,2022-11-23 17:29:47+00:00,https://twitter.com/rasbt/status/1595469673868541964,"@tunguz Agreed, XGBoost is a good baseline üî•"
1785,@rasbt,2022-11-23 17:28:15+00:00,https://twitter.com/rasbt/status/1595469289011789830,@leonpalafox @FoldMani @julien_c *you are too modest! you were literally running the Google+ ML group if I am remembering correctly.
1786,@rasbt,2022-11-23 16:39:56+00:00,https://twitter.com/rasbt/status/1595457129246511108,@monsieurwagner @annargrs @Sergei_Imaging @ylecun You can leave pretraining as is and just enable that fact-masking in inference mode
1787,@rasbt,2022-11-23 14:27:06+00:00,https://twitter.com/rasbt/status/1595423699531927552,"@ylecun Agreed. One exception is ‚Äúacted negativism‚Äù though (aka ‚Äúplaying devil‚Äôs advocate‚Äù). Particularly in academic settings (seminars, reviews) it can sometimes help with improving one‚Äôs work."
1788,@rasbt,2022-11-23 14:18:24+00:00,https://twitter.com/rasbt/status/1595421511149670400,"@annargrs @Sergei_Imaging @ylecun I think so. You could at least mask out key words and generated facts, letting authors fill in the blanks to prevent lazy copy &amp; pasting"
1789,@rasbt,2022-11-23 14:00:54+00:00,https://twitter.com/rasbt/status/1595417106883153920,"@EMostaque @ylecun @tdietterich @leonpalafox @wightmanr @paperswithcode @MetaAI @Michael_J_Black I don't totally disagree with you here. I just think the truth lies somewhere in between. Is there fear mongering? Yes. Are there some valid concerns? Also, yes."
1790,@rasbt,2022-11-23 12:53:41+00:00,https://twitter.com/rasbt/status/1595400192391618561,"@EMostaque @ylecun @tdietterich @leonpalafox @wightmanr @paperswithcode @MetaAI @Michael_J_Black I am not against LLMs, but I don‚Äôt like  the marketing. 

It‚Äôs also weird that there seems to be no nuance in these discussions here. It‚Äôs a very heated ‚Äúit‚Äôs harmful, take it down‚Äù vs ‚Äúall fears are unwarranted‚Äù."
1791,@rasbt,2022-11-23 12:49:04+00:00,https://twitter.com/rasbt/status/1595399029722353664,@EMostaque @ylecun @tdietterich @leonpalafox @wightmanr @paperswithcode @MetaAI @Michael_J_Black Arxiv does not peer review articles
1792,@rasbt,2022-11-23 11:53:35+00:00,https://twitter.com/rasbt/status/1595385065940439043,@ylecun @tdietterich @leonpalafox @wightmanr @EMostaque @paperswithcode @MetaAI @Michael_J_Black I agree with you that reputable researchers would not submit generated fake science. But I can see people making new accounts (maybe using their undergrad EDU address) and shamelessly submit. This already happened with COVID-related fake science 2 yrs ago https://t.co/VFVZhya06x
1793,@rasbt,2022-11-23 02:25:53+00:00,https://twitter.com/rasbt/status/1595242199687512065,"@jon_e_barker For my projects, I usually experiments with things like new loss functions. Once I have one that is promising, I would run it with larger networks for example. Or analogously, finetuning BERT instead of DistilBert etc"
1794,@rasbt,2022-11-23 02:24:10+00:00,https://twitter.com/rasbt/status/1595241768936787974,"@jon_e_barker Usually epoch numbers (and model size). Imagine you have a fixed GPU budget. In the beginning, you can use that to see what generally works. And then once you have a subset of things that work, you can run the fewer, promising ones longer, or just finetune them."
1795,@rasbt,2022-11-23 00:24:47+00:00,https://twitter.com/rasbt/status/1595211724386361345,"@ylecun @tdietterich @leonpalafox @wightmanr @EMostaque @paperswithcode @MetaAI Yes, at least most of its input data was peer reviewed, or at least written in good faith according to scientific standards."
1796,@rasbt,2022-11-23 00:07:51+00:00,https://twitter.com/rasbt/status/1595207461841293312,"@svpino Whoa, congrats üôå"
1797,@rasbt,2022-11-22 23:28:07+00:00,https://twitter.com/rasbt/status/1595197466265149440,"@leonpalafox @julien_c hah, haven't even checked"
1798,@rasbt,2022-11-22 23:27:59+00:00,https://twitter.com/rasbt/status/1595197432547229696,"Q: ""How can I improve my machine learning knowledge after completing your book and course?""

A: ""Twitter!"""
1799,@rasbt,2022-11-22 23:20:47+00:00,https://twitter.com/rasbt/status/1595195620050046977,"@realGeorgeHotz The advanced search is great. I wish they supported that on mobile (or maybe they do and I am just bad at using a phone, lol)"
1800,@rasbt,2022-11-22 23:19:21+00:00,https://twitter.com/rasbt/status/1595195259977404419,@alfcnz @realGeorgeHotz Useful skill! (I remember when you got mad when I deleted my old twitter posts once üòÖ)
1801,@rasbt,2022-11-22 23:07:39+00:00,https://twitter.com/rasbt/status/1595192311855587328,"@julien_c A little bit. Lots of people are still here, and I feel like there is more engagement among those who stayed.

(But yeah, a decent portion of people are now scattered across discord, slack, various mastodon instances, reddit, LinkedIn, and more)"
1802,@rasbt,2022-11-22 21:28:57+00:00,https://twitter.com/rasbt/status/1595167475460673546,@janseben Separately. Basically just submitting multiple single-GPU scripts.
1803,@rasbt,2022-11-22 21:26:14+00:00,https://twitter.com/rasbt/status/1595166791785144320,"@janseben The lambda machine does get pretty hot, so I had to move it from my office into a server room (otherwise the room gets way to warm). The server is in a cooled server room, too."
1804,@rasbt,2022-11-22 20:57:55+00:00,https://twitter.com/rasbt/status/1595159666363101184,"@tunguz yes, maybe! eagerly waiting for a standardized benchmark set (aka https://t.co/FHB92hcNTk) üòÅ"
1805,@rasbt,2022-11-22 20:50:39+00:00,https://twitter.com/rasbt/status/1595157837415518208,"@paniterka_ch @Michael_J_Black @OpenAlex_org Valid concern. It could be a chance for publishers to prove that they can provide value (e.g., by stringent reviews and strict curation)"
1806,@rasbt,2022-11-22 20:48:53+00:00,https://twitter.com/rasbt/status/1595157393750773760,"@DSaience Thanks, that's basically what I had in mind with 3) üòÖ (experiment is essentially a hyperparameter config)"
1807,@rasbt,2022-11-22 20:47:17+00:00,https://twitter.com/rasbt/status/1595156991017902080,"@ovsienkobohdan If you are interested in simple notebooks with multi-GPU support, you could also try this app: https://t.co/vkh5rhaf6M"
1808,@rasbt,2022-11-22 20:39:54+00:00,https://twitter.com/rasbt/status/1595155130290442240,"@ggdupont @Michael_J_Black Agreed, that's worth thinking about."
1809,@rasbt,2022-11-22 20:38:59+00:00,https://twitter.com/rasbt/status/1595154899943428096,"@ovsienkobohdan There are several paid services, don't want to single one out over the other üòÖ. If you are into hyperparameter tuning, you may find our Training Studio App useful https://t.co/wm9uO4oRf4"
1810,@rasbt,2022-11-22 20:32:49+00:00,https://twitter.com/rasbt/status/1595153348520718337,"@Michael_J_Black We should be thinking about how we can assign fewer papers to each peer reviewer, having more peer reviewers per paper, and having each peer reviewer spend more time on checking the validity of a paper. This includese checking for plagiarism, reproducing results, checking proofs."
1811,@rasbt,2022-11-22 20:30:22+00:00,https://twitter.com/rasbt/status/1595152730301280257,"@Michael_J_Black You can't control whether someone uses a writing tool or not (let it be Galactica or just a Grammar checker). 
Imho, the only viable way to address potential issues is for peer review to make a paradigm shift from quantity to quality."
1812,@rasbt,2022-11-22 20:24:09+00:00,https://twitter.com/rasbt/status/1595151166442131456,@Michael_J_Black Sounds like this is a call to finally fix/replace peer-review.
1813,@rasbt,2022-11-22 20:17:15+00:00,https://twitter.com/rasbt/status/1595149431682531328,"@ovsienkobohdan Depending on your strategy, using 4 GPUs vs 1 GPU can give you up to a 3.5x speed-up."
1814,@rasbt,2022-11-22 20:14:52+00:00,https://twitter.com/rasbt/status/1595148829397225473,"@ducha_aiki And ""I don't have time for this"" haha"
1815,@rasbt,2022-11-22 20:10:20+00:00,https://twitter.com/rasbt/status/1595147691214147585,"@ovsienkobohdan Hm, I thought Colab only supports single GPU?"
1816,@rasbt,2022-11-22 20:07:54+00:00,https://twitter.com/rasbt/status/1595147078535376896,"@janseben Both. I have Lambda workstation from 2018 (4 GPUs), and a custom 2019 Nortech server with 8 GPUs that I still use in addition to a corporate grid."
1817,@rasbt,2022-11-22 20:05:50+00:00,https://twitter.com/rasbt/status/1595146559813218305,"@DeepSchneider @LightningAI Depends on the strategy -- for simple strategies like DististributedDataParallel, that's right. 
But you could use a strategy that supports pipeline parallelism or tensor parallelism, or both (e.g., colossolai). Today, it's really easy with 1 line of code."
1818,@rasbt,2022-11-22 19:54:04+00:00,https://twitter.com/rasbt/status/1595143595186860035,"If you have access to a multi-GPU machine, enabling multi-GPU training is literally just 1 line of code. 

If you are using @LightningAI, there are lots of different strategies available (https://t.co/CIVtkfoob6): bagua, collaborative, colossalai, ddp, ddp_sharded, ..., tpu_spawn"
1819,@rasbt,2022-11-22 19:49:01+00:00,https://twitter.com/rasbt/status/1595142325331587072,"Utilizing multiple GPUs for deep learning?

My workflow is usually as follows:

1.  Implement: Tinker and debug on the CPU

2.  Test: Try the first run on a single GPU

3.  Run wide: many experiments on many GPUs

4.  Hone in: run a few bigger, promising experiments via multi-GPU"
1820,@rasbt,2022-11-22 19:46:55+00:00,https://twitter.com/rasbt/status/1595141799102017536,"@jrosell @tunguz @muslimquant @SMKainkaryam I also don't understand why we are comparing it to target-encoding. In target encoding, you encode a feature to predict a label. Here, we are talking about conditioning on the target label to predict the features. Kind of the opposite."
1821,@rasbt,2022-11-22 19:45:15+00:00,https://twitter.com/rasbt/status/1595141376496521216,"@jrosell @tunguz @muslimquant @SMKainkaryam I honestly don't understand why/how this is cheating. Conditioning on the label is pretty common in conditional Autoencoders or conditional GANs, for example.

Btw. I want to emphasize that I am not affiliated with the paper and don't know the authors."
1822,@rasbt,2022-11-22 14:34:33+00:00,https://twitter.com/rasbt/status/1595063185974956033,@seandmacrae Spoiler: self-prediction works even better than contrastive learning (similar to computer vision)
1823,@rasbt,2022-11-22 14:14:25+00:00,https://twitter.com/rasbt/status/1595058122246492160,"@giffmana @hardmaru ""2) skip connections existed long before, and *not* by Schmidthuber's lab.""  
--&gt; In a way, LSTMs can be considered as skip connections / highways. Hah, but they also come from @SchmidhuberAI's lab"
1824,@rasbt,2022-11-22 14:06:56+00:00,https://twitter.com/rasbt/status/1595056237041037312,"@SeguraAndres7 @patloeber @python_engineer @github Thanks! I am curious what happens to ""Most
references to your repositories under the old username automatically change to the new username."" when the old username is eventually claimed (by you or by someone else) üòÖ"
1825,@rasbt,2022-11-22 13:46:02+00:00,https://twitter.com/rasbt/status/1595050979191578631,"@josueortc I think it worked until pretty recently, like 2 years ago. Similarly, I knew someone who was (or still is?) renting DVDs on Netflix lol"
1826,@rasbt,2022-11-22 13:43:53+00:00,https://twitter.com/rasbt/status/1595050438369619968,"@patloeber @python_engineer Interesting, thanks for sharing. So what you did is sth like the following?

1) rename orig handle A (python_engineer) to new B (patloeber)

2) Create a new account with orig handle, python_engineer (since it's now free)?"
1827,@rasbt,2022-11-22 12:56:50+00:00,https://twitter.com/rasbt/status/1595038596741955585,@tunguz @muslimquant @SMKainkaryam Btw I will include a more detailed discussion plus figure in the next Ahead of AI issue at https://t.co/W5kmcV5puC. Lots of text (already written) that is too long for Twitter threads
1828,@rasbt,2022-11-22 12:53:13+00:00,https://twitter.com/rasbt/status/1595037684996919296,"@tunguz @muslimquant @SMKainkaryam 2) The target-aware pretraining is optional. The non-target-aware pretraining outperforms GBDTs as well.
I am honestly not concerned about that part."
1829,@rasbt,2022-11-22 12:51:12+00:00,https://twitter.com/rasbt/status/1595037180539375619,"@tunguz @muslimquant @SMKainkaryam I don‚Äôt understand that criticism tbh. 

1) target encoding applies to the feature at large. You target-encode features in the validation and test set as well. 
This is not the case here. It‚Äôs only done during the pretraining phase and doesn‚Äôt involve any test or validation data."
1830,@rasbt,2022-11-22 12:48:59+00:00,https://twitter.com/rasbt/status/1595036621585649666,"@elonmusk Depends on your role, and that‚Äôs a good question to ask your boss"
1831,@rasbt,2022-11-22 12:46:01+00:00,https://twitter.com/rasbt/status/1595035873308905473,"Twitter has changed a lot in 10 years.

I remember when:
- We didn't have threads, we had to @ each other
- To quote tweet, we had to copy &amp; paste characters
- Twitter handles counted against the char count (hence rasbt = RAschka SeBasTian)
- ...

And yet it still feels the same."
1832,@rasbt,2022-11-22 12:42:24+00:00,https://twitter.com/rasbt/status/1595034963686182916,@muslimquant @SMKainkaryam @tunguz it was so peaceful ...
1833,@rasbt,2022-11-22 12:32:04+00:00,https://twitter.com/rasbt/status/1595032363750330370,"@patloeber Nice! Since twitter handles don‚Äôt cut into the max character count anymore, I was also thinking about changing it. But the problem is that I have linked threads with my old one in too many places across the internet. Is there a way to auto forward things to the new one?"
1834,@rasbt,2022-11-22 12:15:01+00:00,https://twitter.com/rasbt/status/1595028074885971972,@OneandonlyBaraa Probably YMMV :)
1835,@rasbt,2022-11-22 12:14:33+00:00,https://twitter.com/rasbt/status/1595027956207915013,@JayDeep_1729 In a self-supervised fashion: contrastive learning or self-prediction
1836,@rasbt,2022-11-22 02:27:31+00:00,https://twitter.com/rasbt/status/1594880223501238272,@Read_The_Dung I think the same pretraining objectives they used here could also be applied to time series data. There is no independence assumption for these
1837,@rasbt,2022-11-22 02:11:01+00:00,https://twitter.com/rasbt/status/1594876070460694528,"""Overall, our experiments demonstrate that properly performed pretraining significantly increases the performance of tabular DL models, which often leads to their superiority over GBDTs."""
1838,@rasbt,2022-11-21 22:34:49+00:00,https://twitter.com/rasbt/status/1594821663056699395,"How can you improve your coding skills after an intro course/book?

Contribute to an open-source project! You can learn a lot from interacting with well-maintained code.

I started with scikit-learn ~10 years ago. 
Today, if you are into deep learning, Lightning‚ö°Ô∏è is a good pick!"
1839,@rasbt,2022-11-21 19:59:20+00:00,https://twitter.com/rasbt/status/1594782534054907916,"@chrisalbon @feedbin Whoa came her to check out your feed and feel super flattered! 

For those who are interested, the RSS feed is in the upper right corner üòä

https://t.co/oFLrItjqAV"
1840,@rasbt,2022-11-21 19:54:25+00:00,https://twitter.com/rasbt/status/1594781298375200769,"@ylecun Good decision. If people ask you to spend time answering, you can also expect that they spent time going through your previous answers.

Also, no need to justify not answering. Social media is not the same as office hours üòÖ"
1841,@rasbt,2022-11-21 19:16:10+00:00,https://twitter.com/rasbt/status/1594771669985464339,@TMrtSmith *Basically all those scenarios where people use semi-supervised or weakly supervised learning.
1842,@rasbt,2022-11-21 19:14:44+00:00,https://twitter.com/rasbt/status/1594771311418822656,@TMrtSmith Yup. The challenge is that you can‚Äôt just scrape unlabeled data from the internet (like with text and images). Still there are real-world scenarios where you do have lots of unlabeled tabular data from the same domain.
1843,@rasbt,2022-11-21 18:51:07+00:00,https://twitter.com/rasbt/status/1594765366344851456,"[6/6]

Link to the paper: https://t.co/tUBYxbiou2

Link to the code repo: https://t.co/NjaaspavXq"
1844,@rasbt,2022-11-21 18:51:06+00:00,https://twitter.com/rasbt/status/1594765363312328704,"[5/6]
3) Gradient boosting (XGBoost and CatBoost) outperform the pretrained deep neural networks in only 2 out of the 11 datasets! https://t.co/uNGFUeNltR"
1845,@rasbt,2022-11-21 18:51:04+00:00,https://twitter.com/rasbt/status/1594765356219785217,"[4/6] To keep this thread short and concise, the 3 main take-aways are:

1) Adding target information to the pretraining objective further improves the benefits of pretraining.

2) Out of all the combinations, target-aware mask-based pretraining works best."
1846,@rasbt,2022-11-21 18:51:04+00:00,https://twitter.com/rasbt/status/1594765353669709829,"[3/6] Consistent with what we know from computer vision, self-prediction (which is also what we use for pretraining LLMs) performs slightly better than contrastive learning as a pretraining objective."
1847,@rasbt,2022-11-21 18:51:03+00:00,https://twitter.com/rasbt/status/1594765350167465984,"[2/6] In this paper, the authors study self-supervised pretraining.

Self-supervised learning can be grouped into 2 broad categories:
1) contrastive learning
2) self-prediction.

I've drawn the figure below to illustrate how they work in this tabular context: https://t.co/kVsDXCEW7D"
1848,@rasbt,2022-11-21 18:51:01+00:00,https://twitter.com/rasbt/status/1594765341048987648,"""Revisiting Pretraining Objectives for Tabular Deep Learning""

What advantages do deep neural networks have over gradient boosting? That's right, we can pretrain deep neural nets!

New week ... bring it on!
üßµ[1/6]"
1849,@rasbt,2022-11-21 17:23:30+00:00,https://twitter.com/rasbt/status/1594743317669056516,@roydanroy @ylecun https://t.co/oeG3CUwwXR
1850,@rasbt,2022-11-21 16:33:57+00:00,https://twitter.com/rasbt/status/1594730846983946243,"@ylecun Yes, but change the marketing.
Clarify that this is a demo for creating paper templates, not a service for writing entire research papers for you.

Ideally, also don't let it guess facts. Leave blanks for the author to fill in."
1851,@rasbt,2022-11-21 16:28:15+00:00,https://twitter.com/rasbt/status/1594729413979029509,@MuhammadAnas707 Glad you like it üôå
1852,@rasbt,2022-11-21 13:13:41+00:00,https://twitter.com/rasbt/status/1594680449170870280,@aallpp83 Thanks so much for the compliment. Feedback like this will definitely keep me motivated to write more :)
1853,@rasbt,2022-11-21 13:12:41+00:00,https://twitter.com/rasbt/status/1594680196493447178,"@sugatoray Thanks! As a big conda-forge user, having it on there would be nice"
1854,@rasbt,2022-11-21 13:11:39+00:00,https://twitter.com/rasbt/status/1594679938656911362,"@ch3njus @PyTorch Yes, that would be a nice addition, indeed!"
1855,@rasbt,2022-11-20 21:32:49+00:00,https://twitter.com/rasbt/status/1594443671642210304,"@aallpp83 @Singularitarian @chriswolfvision Thanks for sharing! It's very motivating to hear that my book has been useful to you, and I am glad you are enjoying scientific computing in Python as much as I do :)"
1856,@rasbt,2022-11-20 19:11:34+00:00,https://twitter.com/rasbt/status/1594408125087780864,@FeakAustin @kevin_jordan__ Glad to hear!
1857,@rasbt,2022-11-20 17:59:36+00:00,https://twitter.com/rasbt/status/1594390016595214336,@TrlWorkshop @hhsun1 @eisenjulian @FrankRHutter @elgreco_winter @gneubig Looking forward to it!!
1858,@rasbt,2022-11-20 17:57:35+00:00,https://twitter.com/rasbt/status/1594389505875886081,"@FeakAustin @kevin_jordan__ I guess it only works in web browsers that support javascript, which is used for displaying the submission form https://t.co/8WLkijzX6G"
1859,@rasbt,2022-11-20 16:01:32+00:00,https://twitter.com/rasbt/status/1594360300232400898,"@ybgoi Yup, it‚Äôs 2022, let‚Äôs embrace Unicode! (Cc @alfcnz üòÜ)"
1860,@rasbt,2022-11-20 16:00:15+00:00,https://twitter.com/rasbt/status/1594359981188464642,@chriswolfvision MATLAB -&gt; Python &amp; NumPy
1861,@rasbt,2022-11-20 15:26:48+00:00,https://twitter.com/rasbt/status/1594351559822950401,@tunguz TV as in Tabular Videoconference?
1862,@rasbt,2022-11-20 15:05:44+00:00,https://twitter.com/rasbt/status/1594346260340801538,@kevin_jordan__ Thanks for the support üôè https://t.co/g83JoU8t5k
1863,@rasbt,2022-11-20 15:05:02+00:00,https://twitter.com/rasbt/status/1594346083974402048,"Debugging your PyTorch code today?

Here's a lovely, little open-source project for a lovely Sunday!

Lovely tensors -- tensors, ready for human consumption:
https://t.co/e4IfEoRf0y https://t.co/9xa4K87MWG"
1864,@rasbt,2022-11-20 15:03:24+00:00,https://twitter.com/rasbt/status/1594345671900921856,"@Sergei_Imaging @ylecun Right!m, it would be great to have the model take care of the prose (but not the information and facts)"
1865,@rasbt,2022-11-20 14:50:40+00:00,https://twitter.com/rasbt/status/1594342467998199808,@dimleve Finetuning II. It‚Äôs significantly slower but also substantially better.
1866,@rasbt,2022-11-20 14:28:11+00:00,https://twitter.com/rasbt/status/1594336809453965312,@tunguz Maybe I should buy the $8 ticket to enjoy the view from a front row seat? ü§î
1867,@rasbt,2022-11-20 14:25:38+00:00,https://twitter.com/rasbt/status/1594336170271350786,@wichmaennchen @JFPuget Yeah ü§î! I still don‚Äôt get the joke though üòÖ. Does it mean they don‚Äôt edit/moderate on there?
1868,@rasbt,2022-11-20 14:23:54+00:00,https://twitter.com/rasbt/status/1594335732881129472,"@vboykis Yeah, and the alternatives (Instagram, TikTok?) make me feel really old üòÖ."
1869,@rasbt,2022-11-20 14:19:38+00:00,https://twitter.com/rasbt/status/1594334659634425856,"@Sergei_Imaging @ylecun Yeah, there are so many ways this could be improved. My initial thought was essentially a masked output. 

Eg ‚ÄúLorem ipsum [human author pls insert number] ‚Ä¶‚Äú"
1870,@rasbt,2022-11-20 14:16:35+00:00,https://twitter.com/rasbt/status/1594333889388060675,@JFPuget The spelling error ‚Äúsigmioid‚Äù is on purpose? A kind of captcha to weed out bots?
1871,@rasbt,2022-11-20 13:57:10+00:00,https://twitter.com/rasbt/status/1594329005498441728,2023 will be a(i) hot mess
1872,@rasbt,2022-11-20 13:00:09+00:00,https://twitter.com/rasbt/status/1594314656612499457,@GiorgioMantova Haha two things are pretty close ‚Ä¶
1873,@rasbt,2022-11-20 12:52:28+00:00,https://twitter.com/rasbt/status/1594312723172507650,@tunguz You basically described TensorFlow on Windows
1874,@rasbt,2022-11-20 11:44:06+00:00,https://twitter.com/rasbt/status/1594295516627697664,@ludwig_stumpp Thanks for the warm words and adding my book to the list of recommended resources!!
1875,@rasbt,2022-11-20 03:32:00+00:00,https://twitter.com/rasbt/status/1594171675977068544,"@ylecun FWIW I didn‚Äôt like the Galactica page but was also not in favor of taking it down. 

To me, the marketing was problematic: why not saying that it‚Äôs a demo for creating article templates.

Suggestion: don‚Äôt let it create output for low certainty. Don‚Äôt let it fill in everything."
1876,@rasbt,2022-11-19 19:32:58+00:00,https://twitter.com/rasbt/status/1594051121777356800,@QoyilbekV Thanks so much for your interest in my book and being interested in translating it. @PacktPublishing should be able to help!
1877,@rasbt,2022-11-19 19:26:54+00:00,https://twitter.com/rasbt/status/1594049594744180736,"@parth007_96 @fhuszar Yes that‚Äôs what I meant. The inputs are the same, but the resulting vectors are different because the weigh matrices are different for the query and key tokens"
1878,@rasbt,2022-11-18 21:59:42+00:00,https://twitter.com/rasbt/status/1593725660320731138,"@fhuszar *if you think of the attention score matrix, the diagonal corresponds to the cases where query and key are the same. Am on mobile otherwise I would insert a pretty picture here :P"
1879,@rasbt,2022-11-18 21:55:47+00:00,https://twitter.com/rasbt/status/1593724677989564417,"@fhuszar In self-attention you don‚Äôt have to parse the sequence twice like in the original attention (the paper that introduced attention for RNNs before transformers). 
The query and key are NOT the same except for one token."
1880,@rasbt,2022-11-18 21:46:21+00:00,https://twitter.com/rasbt/status/1593722303493423104,@jmes_harrison @Luke_Metz @bucketofkets @poolio @jaschasd @ada_rob @IMordatch @amilmerchant @jekbradbury @naman33k Whoa! I like that premise. Excited about reading and taking this for a spin!
1881,@rasbt,2022-11-18 20:16:57+00:00,https://twitter.com/rasbt/status/1593699805037039616,"@yoavgo @manes @GaryMarcus @ylecun @Abebab Like I said earlier, you wouldn't believe what some people submit ...
 
Anyways, here's a related meta post on this: https://t.co/VFVZhya06x"
1882,@rasbt,2022-11-18 20:03:21+00:00,https://twitter.com/rasbt/status/1593696382388502529,"@yoavgo @manes @GaryMarcus @ylecun @Abebab Arxiv is not peer reviewing content. But I don‚Äôt think anyone wants to have harmful content on there. 
(eg you probably question a lot of the COVID-19 preprints on arxiv; well, you haven‚Äôt seen the thousands of articles that didn‚Äôt make it onto arxiv)"
1883,@rasbt,2022-11-18 19:58:15+00:00,https://twitter.com/rasbt/status/1593695097287168000,@yoavgo @manes @GaryMarcus @ylecun @Abebab These guidelines exist already üòÆ‚Äçüí®
1884,@rasbt,2022-11-18 19:55:22+00:00,https://twitter.com/rasbt/status/1593694372826062849,"@yoavgo @manes @GaryMarcus @ylecun @Abebab Of course. But I worry about the increased frequency. Like I said, a moderator already spends and hour of their free a day."
1885,@rasbt,2022-11-18 19:52:18+00:00,https://twitter.com/rasbt/status/1593693599153152005,"@yoavgo @manes @GaryMarcus @ylecun @Abebab *removal should only happen in rare cases where things slipped through, but it shouldn‚Äôt be a default thing in my opinion"
1886,@rasbt,2022-11-18 19:51:31+00:00,https://twitter.com/rasbt/status/1593693405330264075,"@yoavgo @manes @GaryMarcus @ylecun @Abebab In a sense that‚Äôs a good idea but I can just imagine it backfiring when people start emailing moderators and ask for removals of articles. Also I think for an archive, it‚Äôs bad to remove articles once published"
1887,@rasbt,2022-11-18 19:49:31+00:00,https://twitter.com/rasbt/status/1593692901959155713,"@yoavgo @manes @GaryMarcus @ylecun @Abebab Hah, and we already have tons of people fighting over preprints. 

Then imagine people emailing moderators to remove preprints because they can‚Äôt believe the numbers and suspect the content was LLM-generated."
1888,@rasbt,2022-11-18 19:46:34+00:00,https://twitter.com/rasbt/status/1593692159684870144,"@yoavgo @manes @GaryMarcus @ylecun @Abebab Btw, sry if it was unclear. I wasn‚Äôt asking in a snarky way. Was just curious because a lot of questionable material is already submitted today. Was asking because it‚Äôs probably hard to believe if you haven‚Äôt seen it."
1889,@rasbt,2022-11-18 19:38:09+00:00,https://twitter.com/rasbt/status/1593690039778672640,"@hssn_20 @ylecun @manes @GaryMarcus @Abebab * and that doesn‚Äôt include the compute and time budget for training and evaluating these models. It‚Äôs all possible, sure, but it puts lots of extra burden on the volunteers. The current submission numbers are already crazy enough."
1890,@rasbt,2022-11-18 19:35:45+00:00,https://twitter.com/rasbt/status/1593689437359194112,"@hssn_20 @ylecun @manes @GaryMarcus @Abebab 2/2 but you still have to check if the model is correct. If there are 200 extra articles a day flagged for possibly generated and fictitious content (which is also a hard problem itself), it‚Äôs another hour or so volunteers have to put in every day ‚Ä¶"
1891,@rasbt,2022-11-18 19:33:18+00:00,https://twitter.com/rasbt/status/1593688817432657927,"@hssn_20 @ylecun @manes @GaryMarcus @Abebab That‚Äôs the good point, and yes, we could. There are already models in place for suggesting and flagging wrong categories etc. There are also plagiarism and other quality checks in place. It‚Äôs faster to check automatically flagged articles than flagging articles manually 1/2"
1892,@rasbt,2022-11-18 17:22:27+00:00,https://twitter.com/rasbt/status/1593655891739418624,@yoavgo @manes @GaryMarcus @ylecun @Abebab Are you currently moderating for arxiv?
1893,@rasbt,2022-11-18 16:04:00+00:00,https://twitter.com/rasbt/status/1593636148114608128,"@ylecun @manes @GaryMarcus @Abebab Moderation is a volunteer effort. If you make it easier to spam it, it will first cut even more into the moderators‚Äô free time and then slowly burn them out."
1894,@rasbt,2022-11-18 16:01:08+00:00,https://twitter.com/rasbt/status/1593635423884017665,"@yoavgo @manes @GaryMarcus @ylecun @Abebab Not sure if this is sarcasm. 

If you let everything in, you will get plagiarism, all kinds of blog posts, etc. It would cease to become a preprint server."
1895,@rasbt,2022-11-18 15:19:29+00:00,https://twitter.com/rasbt/status/1593624942960152578,"@manes @GaryMarcus @ylecun @Abebab I‚Äôve been a moderator for cs.LG on arxiv.

Detecting and removing problematic submissions is already tons of work given the current rate of submissions. 

While I think that a service like this is a nice demo, it literally has the potential to ruin arxiv."
1896,@rasbt,2022-11-18 14:47:01+00:00,https://twitter.com/rasbt/status/1593616775899336704,"I'm thrilled about the ~3k subscribers so far! Thank you, everyone! The next newsletter will feature a BIG announcement - stay tuned!"
1897,@rasbt,2022-11-18 14:47:01+00:00,https://twitter.com/rasbt/status/1593616773198200840,"Useful machine learning &amp; AI content will keep flowing - I can't help myself!

But if push comes to shove ...

I'll keep on keeping on
- sharing insights,
- discussing papers, and
- posting ML tidbits
on Substack

(https://t.co/W5kmcVn0ma)"
1898,@rasbt,2022-11-18 14:06:52+00:00,https://twitter.com/rasbt/status/1593606670747312129,"@MosquitoCapital Good thread. I wish they are working on an ‚Äúexport long thread to blog‚Äù feature 

‚Ä¶ so that I can export that to PDF and read it on my e-reader."
1899,@rasbt,2022-11-18 13:56:22+00:00,https://twitter.com/rasbt/status/1593604028545597441,@corentinm_py I think it would work out of the box since it‚Äôs treating such cases as a noun is my guess.
1900,@rasbt,2022-11-18 13:54:41+00:00,https://twitter.com/rasbt/status/1593603601812832256,@tunguz A better question is probably how many people are developing and running mastodon instances. The base developers + the number of people maintaining &amp; moderating instances so that it equals 100-400 million-ish users.
1901,@rasbt,2022-11-18 13:30:43+00:00,https://twitter.com/rasbt/status/1593597572752490502,"@gupta_anik I appreciate the warm words! I tried Discord in the past, but it‚Äôs a bit too hectic for me üòÖ. It‚Äôs great for live discussions accompanying events, though. And I may occasionally use it for that purpose. But it‚Äôs not an everyday thing, otherwise I wouldn‚Äôt get anything done haha"
1902,@rasbt,2022-11-18 08:45:29+00:00,https://twitter.com/rasbt/status/1593525791438131200,@IsackOdero Thanks so much for the kind words!
1903,@rasbt,2022-11-18 08:17:39+00:00,https://twitter.com/rasbt/status/1593518785679527936,"@jrosell @topepos @juliasilge Std err from CV is a good algo stability measure, but yeah i think there is a risk that people misinterpret so using just the std dev is maybe better ü§î"
1904,@rasbt,2022-11-18 08:15:42+00:00,https://twitter.com/rasbt/status/1593518294060892163,"@rahuldave @SIGMOID Thx for the invite, but I think if this place goes away, I will do a Donald Knuth: ‚ÄúI'd used social media since about 1975, and it seems to me that 47 years of social media is plenty for one lifetime.‚Äù üòÖ"
1905,@rasbt,2022-11-18 08:13:11+00:00,https://twitter.com/rasbt/status/1593517662268694528,"@JonathanSumDL Aww thanks ‚ò∫Ô∏è. Yes I‚Äôll stay here until the end, no worries!"
1906,@rasbt,2022-11-18 07:43:23+00:00,https://twitter.com/rasbt/status/1593510162085593091,@ChristophMolnar Thanks for asking! That‚Äôd be LinkedIn: https://t.co/BDqLu5R3iK
1907,@rasbt,2022-11-18 07:27:07+00:00,https://twitter.com/rasbt/status/1593506071187963906,"@timdsci Thanks @timdsci! There will be a big announcement in a few weeks (*no spoilers*), you won't regret it ^^"
1908,@rasbt,2022-11-18 07:22:28+00:00,https://twitter.com/rasbt/status/1593504897726648322,"Hi üëã if you are STILL interested in:

‚öôÔ∏è Machine Learning
üî¨ Artificial Intelligence Research
üêç Python &amp; Open Source

Follow me* ‚úî

*While supplies last

#RIPTwitter https://t.co/kNDOa5VWii"
1909,@rasbt,2022-11-18 07:10:27+00:00,https://twitter.com/rasbt/status/1593501877072715780,@ChrisWolf1987 Data mining &amp; Pattern recognition!
1910,@rasbt,2022-11-18 06:44:43+00:00,https://twitter.com/rasbt/status/1593495399498645509,"One day, I will be able to tell my children that I am both 

- old enough to remember that AI was also known as Machine Learning

- young enough to remember that Machine Learning was commonly referred to as AI"
1911,@rasbt,2022-11-17 22:29:25+00:00,https://twitter.com/rasbt/status/1593370754535522310,"@ylecun I guess it was a ‚ÄúReject with option to resubmit‚Äù from the community. 

(Tbh I think it could easily be fixed by changing the marketing and language around it)"
1912,@rasbt,2022-11-17 20:56:49+00:00,https://twitter.com/rasbt/status/1593347447648129027,"@CalcCon Oh yeah, recently rebranded as data-centric AI :)"
1913,@rasbt,2022-11-17 16:52:14+00:00,https://twitter.com/rasbt/status/1593285897688055809,"@DSaience Yes, exposures to different fields can be very productive for getting inspiration and learning about things that can be applied to your problem as well."
1914,@rasbt,2022-11-17 14:23:26+00:00,https://twitter.com/rasbt/status/1593248449084129282,"@ammaryh92 Yes, that's what I had in mind. (Not a strict requirement)"
1915,@rasbt,2022-11-17 13:27:15+00:00,https://twitter.com/rasbt/status/1593234313234903045,"@saikatkrd Yes, sth exactly like that!"
1916,@rasbt,2022-11-17 12:39:37+00:00,https://twitter.com/rasbt/status/1593222325880512512,"Anyways, I wouldn‚Äôt mind sth like that for generating exam questions from my lecture notes üòÖ. I would pay for that"
1917,@rasbt,2022-11-17 12:17:53+00:00,https://twitter.com/rasbt/status/1593216853253697536,"It's cool stuff, but Galactica would be a lot more clear and a lot less controversial if ""Generate Wiki Article"" was called ""Generate Wiki Article Template"" etc."
1918,@rasbt,2022-11-17 12:07:55+00:00,https://twitter.com/rasbt/status/1593214347631022081,@elonmusk *legacy media
1919,@rasbt,2022-11-17 10:12:44+00:00,https://twitter.com/rasbt/status/1593185359625871360,"@DrGroftehauge @radekosmulski Yup, I typically use them as part of the tokenizer (Sec 2 and 3: https://t.co/ruijZ054mb)"
1920,@rasbt,2022-11-17 09:46:37+00:00,https://twitter.com/rasbt/status/1593178786702712832,"@BendikAF @karpathy Yeah, hone your skills and specialize. Always learn sth new but don‚Äôt try to chase things."
1921,@rasbt,2022-11-17 09:44:09+00:00,https://twitter.com/rasbt/status/1593178168860766209,"@karpathy Slack is bad for the Attention span of high Performers.

No puns intended."
1922,@rasbt,2022-11-17 09:37:00+00:00,https://twitter.com/rasbt/status/1593176366924472321,"@radekosmulski Sounds super cool! How did you implement the PyTorch DataSet/Dataloader as a baseline? Does it get each row by index from a DataFrame/no array / PyTorch tensor that is kept in memory, or do you fetch each record from disk?"
1923,@rasbt,2022-11-17 09:29:04+00:00,https://twitter.com/rasbt/status/1593174371623145472,life is barely long enough to be good at one thing so choose wisely
1924,@rasbt,2022-11-17 08:11:14+00:00,https://twitter.com/rasbt/status/1593154783552057344,@alexandrudinu_ This is absolutely the right way to look at it!
1925,@rasbt,2022-11-16 22:26:48+00:00,https://twitter.com/rasbt/status/1593007707631812608,"@Guilherme1946_ whoa, thanks for the compliment!? üòä"
1926,@rasbt,2022-11-16 22:20:34+00:00,https://twitter.com/rasbt/status/1593006138710462467,"@predict_addict @GaelVaroquaux I mean, it depends on what you want to get out of your baseline. For me, I use logistic regression coz it's not only easy to implement but is also a (code) subset of more complicated models I am usually using. Good for getting a perf baseline &amp; debugging the computation pipeline. https://t.co/khnWvXTprs"
1927,@rasbt,2022-11-16 22:14:33+00:00,https://twitter.com/rasbt/status/1593004623320993792,"@predict_addict @GaelVaroquaux @tunguz Theoretically, it's not required. Practically, it can make a difference due to the heuristics of binning the features for finding good splitting thresholds."
1928,@rasbt,2022-11-16 22:13:34+00:00,https://twitter.com/rasbt/status/1593004377748357120,"@predict_addict @GaelVaroquaux if you choose XGBoost as your baseline you won't need it. Personally, I'd choose the simplest model as the (first) baseline; preferably a model that is easy to implement, requires little tuning, and easy to understand/analyze."
1929,@rasbt,2022-11-16 22:06:19+00:00,https://twitter.com/rasbt/status/1593002550248497153,"@predict_addict Right. So to answer the ""Why would one normalise numerical features"" question, you may want to normalize it for that baseline"
1930,@rasbt,2022-11-16 22:05:17+00:00,https://twitter.com/rasbt/status/1593002289723510786,"@nixcad oh yes (sorry, I wasn't implying to do these as steps or in order)

https://t.co/RpyfiOlHDv"
1931,@rasbt,2022-11-16 22:04:05+00:00,https://twitter.com/rasbt/status/1593001988002033665,@_NicT_ @predict_addict I think it is related to the binning algorithm
1932,@rasbt,2022-11-16 22:03:16+00:00,https://twitter.com/rasbt/status/1593001783101919232,"@predict_addict These are options, not requirements :). Also, you probably still want to compare your model to baselines and other algos (to make sure it's well tuned at the very least)"
1933,@rasbt,2022-11-16 21:31:18+00:00,https://twitter.com/rasbt/status/1592993737571201024,"@adbreind yes yes yes!
https://t.co/sdpDwkzIlB"
1934,@rasbt,2022-11-16 21:17:31+00:00,https://twitter.com/rasbt/status/1592990272086237184,"@GaryMarcus @MetaAI Agreed. This is a bad look. If you don‚Äôt want to implement a lookup feature, it should at least not generate output for certain queries (eg based on low certainty scores) instead of just guessing."
1935,@rasbt,2022-11-16 21:04:12+00:00,https://twitter.com/rasbt/status/1592986918559838208,"@ID_AA_Carmack But without enough training data, the AI is DOOMed"
1936,@rasbt,2022-11-16 20:56:45+00:00,https://twitter.com/rasbt/status/1592985043978563585,@GaelVaroquaux But what if you want to implement a simple logistic regression baseline first? üòÜ
1937,@rasbt,2022-11-16 20:41:35+00:00,https://twitter.com/rasbt/status/1592981229007441920,@TheRandomMtrix üëç. But could be grouped under ‚Äúreplace‚Äù
1938,@rasbt,2022-11-16 20:35:32+00:00,https://twitter.com/rasbt/status/1592979703303806976,@michabdelmalek I‚Äôd put it under normalization :)
1939,@rasbt,2022-11-16 20:34:58+00:00,https://twitter.com/rasbt/status/1592979560882372608,"@michabdelmalek @GaelVaroquaux Ok fair, these are options that exist, not guidelines ^^"
1940,@rasbt,2022-11-16 20:19:44+00:00,https://twitter.com/rasbt/status/1592975729842847744,@LeopolisDream good one. I would group it under normalization
1941,@rasbt,2022-11-16 20:06:57+00:00,https://twitter.com/rasbt/status/1592972511184293889,"@KMarwatov haha, yes!"
1942,@rasbt,2022-11-16 20:06:04+00:00,https://twitter.com/rasbt/status/1592972291444727808,"@KMarwatov that's a good one, but maybe more of an EDA than a preprocessing step"
1943,@rasbt,2022-11-16 19:58:49+00:00,https://twitter.com/rasbt/status/1592970465886470144,"@putkapu arg, definitely the most painful one on that list so far"
1944,@rasbt,2022-11-16 19:53:56+00:00,https://twitter.com/rasbt/status/1592969235617447936,"Maybe two more obvious one (assuming we want to train a classification or regression model):

5. Stratify partitions based on target variable
6. Resample/rebalance partitions"
1945,@rasbt,2022-11-16 19:53:55+00:00,https://twitter.com/rasbt/status/1592969233713201152,"Here are some common preprocessing steps prior to feeding the data to a machine learning algo:

1. Replace/remove missing data
2. Remove/rescale outliers
3. Encode categorical features
4. Normalize numeric feats

Any not-so-obvious ones you encountered in your career so far? üòä"
1946,@rasbt,2022-11-16 19:23:16+00:00,https://twitter.com/rasbt/status/1592961518483648515,"@tunguz @SharplyUnclear @Shishira_N @mariofilhoml Thanks for the insightful thread below üôè! Btw I didn't mean to be a deep tabular vs gradient boosting kind of person, haha. I would always recommend gradient boosting as a baseline. Then use deep tabular learning (only) if you are feeling bored &amp; experimental :)"
1947,@rasbt,2022-11-16 18:24:05+00:00,https://twitter.com/rasbt/status/1592946624451706880,"@Ihor_Bobak Yup, I run nbs in batch mode to build documentation pages. E.g. for mlxtend: https://t.co/aI3i8GRTvA

At the same time, I would not consider using or recommending notebooks for production -- e.g., deploying deep neural networks. It's just extra hassle and asking for trouble."
1948,@rasbt,2022-11-16 16:04:19+00:00,https://twitter.com/rasbt/status/1592911449302925312,"@svpino If you have an unbiased coin that turns up heads, heads, heads, heads, the chance that the next coin flip ‚Ä¶"
1949,@rasbt,2022-11-16 09:23:28+00:00,https://twitter.com/rasbt/status/1592810572110008324,"@VickersBiostats @marktenenholtz Agreed, I feel like there is not much talk about calibration in core ML/AI papers. I am not following the ML biostats literature that well, but I suppose it‚Äôs also an issue there (hence the article you shared in the thread above)?"
1950,@rasbt,2022-11-16 06:37:57+00:00,https://twitter.com/rasbt/status/1592768922448990208,@alfcnz @cHHillee In a nutshell it's a way and API for computing gradients using a Jax-like functional approach: https://t.co/KJVpV9dYx2
1951,@rasbt,2022-11-15 21:59:33+00:00,https://twitter.com/rasbt/status/1592638462599245824,"@F_Vaggi @cHHillee @alfcnz Hah, in a way this would be both weird but also very direct &amp; on point"
1952,@rasbt,2022-11-15 21:49:43+00:00,https://twitter.com/rasbt/status/1592635985182892032,"@rdshapiro I agree. But it‚Äôs also like writing a book, paper, or thesis; you would never submit your first draft :P"
1953,@rasbt,2022-11-15 21:48:21+00:00,https://twitter.com/rasbt/status/1592635643892740096,@chrisoffner3d Tbh it would be super cool if the next gen Jupyter notebook app had this reactive behavior as a default. You can still choose to do analyses verbosely by appending cells. At the same time fewer people would should themselves in the foot
1954,@rasbt,2022-11-15 21:46:58+00:00,https://twitter.com/rasbt/status/1592635294582738945,"@chrisoffner3d This is cool. I feel like the reactive component is useful, but there is also something useful about a workflow where you just append cells to have a full trace of all your steps and exploration (at least in the initial version)."
1955,@rasbt,2022-11-15 21:42:04+00:00,https://twitter.com/rasbt/status/1592634062778544128,"@rdshapiro Totally! Have a similar workflow where I may draft something in a notebook but if it‚Äôs something that is important and/or used only once, don‚Äôt define it in the notebook."
1956,@rasbt,2022-11-15 21:36:31+00:00,https://twitter.com/rasbt/status/1592632663617462272,"@O_igggy A good analogy is maybe writing a book in PowerPoint. You can use PowerPoint to draft ideas etc, outline things and move things around. But you probably don‚Äôt want to write the whole book in PowerPoint itself."
1957,@rasbt,2022-11-15 21:35:00+00:00,https://twitter.com/rasbt/status/1592632283059875840,@O_igggy 2/ I love notebooks. My favorite tool for exploration and teaching (for things that involve code). But I would not go so far and recommend them for production. Even if it‚Äôs your favorite tool it doesn‚Äôt mean you have to use it for everything.
1958,@rasbt,2022-11-15 21:33:00+00:00,https://twitter.com/rasbt/status/1592631780850683905,"@O_igggy Yes, mostly the same. I use it for exploratory work and keep it as sth to reference later. 

Regarding the package &amp; production question. I meant a manual process where you take ideas from the notebook and implement it as a Python package, for example. 1/2"
1959,@rasbt,2022-11-15 21:27:11+00:00,https://twitter.com/rasbt/status/1592630316669501441,"@O_igggy I mean you can certainly iterate on it to make it less messy, and depending into he context, you can convert it into code files or even package for production. It‚Äôs certainly a good learning experiences"
1960,@rasbt,2022-11-15 21:23:34+00:00,https://twitter.com/rasbt/status/1592629406459392002,"Re: Jupyter notebooks. 

There's a reason why they are called ""note""books. Notes are supposed to be messy.

And note""book"" implies that it's meant to be read sequentially (like the majority of books)."
1961,@rasbt,2022-11-15 15:34:07+00:00,https://twitter.com/rasbt/status/1592541463707111426,"@dryeeseeks I remember Ovomaltine from my childhood; i recall it as a super sweet sugar-cocoa powder that you mix into milk. 

Loved it as a kid but would probably be way to sugary for me these days. 

Didn‚Äôt know they made a chocolate bar üç´. Tbh I expect it to taste sth like Hershey‚Äôs üò£"
1962,@rasbt,2022-11-15 14:58:22+00:00,https://twitter.com/rasbt/status/1592532467046830081,"@VickersBiostats @marktenenholtz 2/2 Would I include it directly in the article if I had infinite time? Absolutely! But what about interpretability etc then? If you broaden the scope, it would soon be more of a book than an article."
1963,@rasbt,2022-11-15 14:57:13+00:00,https://twitter.com/rasbt/status/1592532177602097152,"@VickersBiostats @marktenenholtz In this article, I covered the essentials; I think this is what you should minimally consider for all applications. Calibration is important for a whole bunch of applications, and you could add it as a follow-up. 1/2"
1964,@rasbt,2022-11-15 14:51:17+00:00,https://twitter.com/rasbt/status/1592530685239214082,"@VickersBiostats @marktenenholtz E.g., if you select models via classification accuracy or ROC AUC, it doesn't make a difference whether the model was calibrated or not. The predictive performance doesn't change for these metrics. So, in algorithm &amp; model selection, and evaluation, you would end up w. the same"
1965,@rasbt,2022-11-15 09:04:18+00:00,https://twitter.com/rasbt/status/1592443363558817793,"@cHHillee or maybe torch.fnx / torch.fnc for ""function composition"" 
(to differentiate it more from torch.nn.functional)"
1966,@rasbt,2022-11-15 09:02:42+00:00,https://twitter.com/rasbt/status/1592442961081425920,"@macacq @cHHillee yeah, but I would worry that it causes confusion with the common
import torch.nn.functional as F"
1967,@rasbt,2022-11-15 07:34:02+00:00,https://twitter.com/rasbt/status/1592420648252747776,"@dvassallo You are not wrong, but on the flip side you might miss out on working with &amp; learning from amazing colleagues."
1968,@rasbt,2022-11-15 06:55:00+00:00,https://twitter.com/rasbt/status/1592410821430165506,@cHHillee torch.fn
1969,@rasbt,2022-11-15 06:50:44+00:00,https://twitter.com/rasbt/status/1592409747885821952,"@VickersBiostats @marktenenholtz The article was more focused on evaluating the predictive performance of the model. So, yes, model calibration was out of scope. But yeah, for some application areas, it's an important topic. Since it is often done post-hoc, it could be a good add-on."
1970,@rasbt,2022-11-14 22:53:14+00:00,https://twitter.com/rasbt/status/1592289583026573312,"@tunguz @SharplyUnclear @Shishira_N Alternatively, how about this one then as an example of a deep neural net winning a Kaggle competition on a real-world tabular dataset: Porto Seguro‚Äôs Safe Driver Prediction (https://t.co/J4ihKr4EmV)

(Thanks for sharing @mariofilhoml)"
1971,@rasbt,2022-11-14 22:44:41+00:00,https://twitter.com/rasbt/status/1592287430786404354,@mblondel_ml @glouppe Another rare one is that people joined a lab after the initial submission and helped with additional experiments that were done to address reviewer concerns.
1972,@rasbt,2022-11-14 22:21:31+00:00,https://twitter.com/rasbt/status/1592281601177976832,"@DynamicWebPaige (7) a fun one: how many conference talks are about (or heavily use) your library. Ok can also be gamed, but still a good one to not only capture usage but also has a pulse on community enthusiasm"
1973,@rasbt,2022-11-14 22:18:57+00:00,https://twitter.com/rasbt/status/1592280955385188352,"@DynamicWebPaige Very good point! Always thought it was weird to count installs and stars, because it‚Äôs very platform specific. Like is it fair to compare pip installs to CRAN downloads, and what about GitHub vs GitLab stars. Metrics should be more universal."
1974,@rasbt,2022-11-14 16:46:18+00:00,https://twitter.com/rasbt/status/1592197241410031616,@MuhammadAnas707 Wohoo! Hope you‚Äôll like it!!
1975,@rasbt,2022-11-14 15:08:21+00:00,https://twitter.com/rasbt/status/1592172591414140928,@_a_Seeker_ And every ML person should know at least a bit dev :)
1976,@rasbt,2022-11-14 13:14:20+00:00,https://twitter.com/rasbt/status/1592143896926359552,"@michabdelmalek @marktenenholtz I think it's more complex because you usually operate in a classification setting where you, depending on the model, look at binary results. Also, it's tricky because you have nonparametetric models like nearest neighbors &amp; decision trees etc"
1977,@rasbt,2022-11-14 13:08:26+00:00,https://twitter.com/rasbt/status/1592142411588943877,"@marktenenholtz Thanks, glad you got something useful out of it! For those who are interested, I also have video lectures for some portions of this!

Check out Part 4 here: https://t.co/bb0yjRpX7V"
1978,@rasbt,2022-11-14 13:00:32+00:00,https://twitter.com/rasbt/status/1592140426836074496,@pksivasubraman1 @Shishira_N @tunguz Bad marketing decision. No one show up. The name branding is so 2016
1979,@rasbt,2022-11-14 12:56:30+00:00,https://twitter.com/rasbt/status/1592139408819752961,"@LucileSaulnier @NeurIPSConf Exciting! 

Tip 1: Come to hour social ^^ https://t.co/NFjn55VcPb

Tip 2: And the tabular data workshop! https://t.co/OY35qVzxIg

üòäüòä"
1980,@rasbt,2022-11-14 12:54:38+00:00,https://twitter.com/rasbt/status/1592138940932591616,"@cHHillee On that note, I am curious how much Netflix will make from their new model compared to the ad-free subscription. It‚Äôs probably going to be way more than the pricing difference suggests."
1981,@rasbt,2022-11-14 12:08:17+00:00,https://twitter.com/rasbt/status/1592127277084643329,"@tunguz @SharplyUnclear @Shishira_N *For those who read this without the context above: I do think deep learning can be useful for tabular data. The emphasis is on non-DL based neural networks not being that useful. (E.g., plain old MLPs)"
1982,@rasbt,2022-11-14 12:06:38+00:00,https://twitter.com/rasbt/status/1592126859449352195,"@tunguz @SharplyUnclear @Shishira_N Denoising autoencoder architectures won kaggle competitions as well. E.g., this one won the Tabular Playground Series - Feb 2021: https://t.co/ecJ08Xm4bB"
1983,@rasbt,2022-11-14 12:00:50+00:00,https://twitter.com/rasbt/status/1592125401291460609,"@tunguz @SharplyUnclear @Shishira_N For me it's the opposite actually, I don't think non-DL NN's are that useful to tabular data."
1984,@rasbt,2022-11-14 07:08:02+00:00,https://twitter.com/rasbt/status/1592051714227867648,@paul_rietschka A Normconf shower curtain? I did not! Thx for the FOMO!
1985,@rasbt,2022-11-14 07:07:01+00:00,https://twitter.com/rasbt/status/1592051458609905664,@Shishira_N @tunguz @tunguz joining would be üî•
1986,@rasbt,2022-11-13 20:00:57+00:00,https://twitter.com/rasbt/status/1591883837604507649,"You can also follow @TrlWorkshop for updates! 
And here's the list of accepted papers and posters: https://t.co/eoYqISzshJ"
1987,@rasbt,2022-11-13 19:49:01+00:00,https://twitter.com/rasbt/status/1591880835325517824,"There will be a full-day workshop on deep learning for tabular data at #NeurIPS2022 this year! üôå

To prepare for the panel, I also just found 4 new papers to review; will add to the list below üìö!
It'll be fun!

(the event is on Dec 2, 2022; more info: https://t.co/OY35qVQAKg)"
1988,@rasbt,2022-11-13 19:24:16+00:00,https://twitter.com/rasbt/status/1591874607128399872,"@GiorgioMantova Oh for sure, that's actually a great idea. I suggested something like this to the publisher back then but we never found the time to set it up. Definitely a cool idea though!"
1989,@rasbt,2022-11-13 16:34:49+00:00,https://twitter.com/rasbt/status/1591831964629274631,@yeahtwoERs Same! And most textbooks are also quick reads. Kind of enjoy the process of sitting down with a book each morning
1990,@rasbt,2022-11-13 16:26:18+00:00,https://twitter.com/rasbt/status/1591829818500579328,"Nice blog post on tackling the ML tech stack. 

Actually, keeping up via books is also the more calm &amp; structured way to learn (compared to sifting through preprints &amp; GitHub repos üòÖ )"
1991,@rasbt,2022-11-13 13:36:18+00:00,https://twitter.com/rasbt/status/1591787037966876672,@drChromiak I hear you ;)
1992,@rasbt,2022-11-12 21:02:51+00:00,https://twitter.com/rasbt/status/1591537028272996355,"@CalcCon For imagenet classification performance, i think the hottest example of a ViT is CoCa https://t.co/S8elGxzr7Z (best classification accuracy; mildly better than efficientnet though so YMMV in practice. Not sure if it‚Äôs in HF yet)"
1993,@rasbt,2022-11-12 19:52:35+00:00,https://twitter.com/rasbt/status/1591519344873426946,"Yup! An example of this is a fully convolutional network vs a vision transformer (ViT) without convolutional layers (CNN).

The ViT requires much more data (and pre-training) to perform well. But yeah, when it performs it performs üöÄ

A on large datasets the ViT will beat the CNN"
1994,@rasbt,2022-11-12 19:10:01+00:00,https://twitter.com/rasbt/status/1591508633954971648,"@lmoroney @hellenkeniford @yoavgo @CSProfKGD @ylecun haha yeah, fair enough. being stubborn is one of my biggest weaknesses haha üòÖ"
1995,@rasbt,2022-11-12 18:33:05+00:00,https://twitter.com/rasbt/status/1591499336122253313,"@lmoroney @hellenkeniford @yoavgo @CSProfKGD @ylecun Also an original blue subscriber (for about a year) since I genuinely love the platform and community here and wanted to support twitter back then. However, I couldn't quite pull the trigger on the pay-to-verify upgrade. (No worries, not judging though) https://t.co/OJls0yrMgs"
1996,@rasbt,2022-11-12 16:40:01+00:00,https://twitter.com/rasbt/status/1591470884732403713,"Great thread on steps towards inheriting a complex deep learning pipeline or building a neural network from scratch.

To add my very first steps: 

1) get the data loader working
2) examine summary stats (data normalized ok?)
3) look at label distributions (is it shuffled ok?)"
1997,@rasbt,2022-11-12 16:11:16+00:00,https://twitter.com/rasbt/status/1591463648274546689,"@lmoroney Hmm, maybe the latter, going off of one data point here. haven‚Äôt seen any change tbh."
1998,@rasbt,2022-11-12 16:09:44+00:00,https://twitter.com/rasbt/status/1591463263300354049,"@CSProfKGD Oops, was on mobile and just saw the screenshot ‚Ä¶ totally missed the link to the paper"
1999,@rasbt,2022-11-12 16:08:08+00:00,https://twitter.com/rasbt/status/1591462858533244929,"@hellenkeniford @yoavgo No worries @CSProfKGD, @ylecun, and I are still here, and all ‚Äúunverifiable‚Äù so"
2000,@rasbt,2022-11-12 16:03:57+00:00,https://twitter.com/rasbt/status/1591461808275070976,@zippeurfou @tunguz Haha yeah of course. It‚Äôs just unclear whether real Elon even said that or whether just someone said it
2001,@rasbt,2022-11-12 11:29:31+00:00,https://twitter.com/rasbt/status/1591392742760153090,"@mpaepper Actually no, because it doesn‚Äôt support GPUs yet üò¨"
2002,@rasbt,2022-11-12 00:28:01+00:00,https://twitter.com/rasbt/status/1591226271333486593,@jorgex135 Thanks for the warm words and support!
2003,@rasbt,2022-11-11 22:30:27+00:00,https://twitter.com/rasbt/status/1591196685161869312,"‚è±Ô∏è 6 hours until the #CVPR2023 paper submission deadline. 

I thought you might appreciate this as a quick baseline üôÉ"
2004,@rasbt,2022-11-11 22:20:30+00:00,https://twitter.com/rasbt/status/1591194182890434560,"@chrisalbon This is fine üî•üî•

https://t.co/ZF4kSAKwSm"
2005,@rasbt,2022-11-11 22:19:29+00:00,https://twitter.com/rasbt/status/1591193926178045953,"You can also use embetter with computer vision models. 
Here's an example training a scikit-learn logistic regression model on MobileNet embeddings: https://t.co/TWXt86Fctn https://t.co/JE7C8li7vn"
2006,@rasbt,2022-11-11 19:23:48+00:00,https://twitter.com/rasbt/status/1591149714376101888,@tunguz GANs having real FOMO now
2007,@rasbt,2022-11-11 19:03:59+00:00,https://twitter.com/rasbt/status/1591144727277146119,"@tunguz of course, but doing your own research (on twitter) takes like $8times as long now

(now people have to 1) navigate to the profile and 2) manually click the checkmarks to see who paid and who is legit)"
2008,@rasbt,2022-11-11 16:55:21+00:00,https://twitter.com/rasbt/status/1591112353244143618,"@dtsci_rj @tunguz haha yes! bottom line: the current interface is ""probably"" confusing"
2009,@rasbt,2022-11-11 16:18:04+00:00,https://twitter.com/rasbt/status/1591102971076657154,@elonmusk https://t.co/lMw7u7TgkF
2010,@rasbt,2022-11-11 16:09:11+00:00,https://twitter.com/rasbt/status/1591100737890967553,"@tunguz ü§Ø
https://t.co/JDt3lznqek"
2011,@rasbt,2022-11-11 16:08:44+00:00,https://twitter.com/rasbt/status/1591100625496023040,"@tunguz Great, and how do I know it's real? 4 possibilities here:

1. real reuters post, fake musk response
2. fake reuters post, real musk response
3. fake reuters post, fake musk response
4. real reuters post, real musk response"
2012,@rasbt,2022-11-11 15:33:47+00:00,https://twitter.com/rasbt/status/1591091827553497090,@iWaltzAround @TheZachMueller Nice! That might actually fix twitter (for a while...)
2013,@rasbt,2022-11-11 15:27:43+00:00,https://twitter.com/rasbt/status/1591090303242764291,"@TwitterSupport And how do I know it's real? You don't seem to be ""official"""
2014,@rasbt,2022-11-11 13:57:01+00:00,https://twitter.com/rasbt/status/1591067476015517698,"Upon popular request, the monthly Ahead Of AI magazine is now also available on Substack: https://t.co/W5kmcVn0ma

Enjoy the cleaner layout and higher resolution figures!"
2015,@rasbt,2022-11-11 13:41:07+00:00,https://twitter.com/rasbt/status/1591063473806794752,@eduardoczini I was thinking about writing about this because it's a popular request actually. But it's a very tricky topic because it's super super project-dependent. I guess a case-study book would make most sense.
2016,@rasbt,2022-11-11 13:34:01+00:00,https://twitter.com/rasbt/status/1591061685917212672,"@ChristophMolnar Thanks for offering! We should definitely connect, and I'd love to chat with you some time!!"
2017,@rasbt,2022-11-11 13:15:42+00:00,https://twitter.com/rasbt/status/1591057078290092032,"Fun fact: Did you know that you can get verified on GitHub for free?

Here's how: https://t.co/Yiv1zGJOAs

Kidding not kidding. https://t.co/10ZG6YUVnP"
2018,@rasbt,2022-11-11 13:01:00+00:00,https://twitter.com/rasbt/status/1591053378355957760,@TwitterSupport How much?
2019,@rasbt,2022-11-11 12:55:06+00:00,https://twitter.com/rasbt/status/1591051893173731329,@ZoeSchiffer Are those sources *verified*?
2020,@rasbt,2022-11-11 12:50:53+00:00,https://twitter.com/rasbt/status/1591050831947767809,@sitzikbs Offsite backups on arxiv work too ;)
2021,@rasbt,2022-11-11 12:47:12+00:00,https://twitter.com/rasbt/status/1591049904205406208,"@RobertERitz @python_engineer I gave up video gaming a few years ago when video games started to feel like work. 
I only play Zelda and Metroid games now on a modded GBA and Switch."
2022,@rasbt,2022-11-11 12:45:10+00:00,https://twitter.com/rasbt/status/1591049394677518341,"@ChristophMolnar Yes exactly, their error handling is a disaster. With all the time I spent going back and forth I could have easily finished writing my book already üòÜ

PS: thanks that‚Äôs good to know. I thought it was just me. Will maybe give this a try some time."
2023,@rasbt,2022-11-11 12:41:33+00:00,https://twitter.com/rasbt/status/1591048485377572866,@wongmjane It‚Äôll probably back on Black Friday
2024,@rasbt,2022-11-11 12:37:14+00:00,https://twitter.com/rasbt/status/1591047398037803008,"@ChristophMolnar Btw for the leanpub version, are you formatting it locally with bookdown/quarto and then upload it, or do you use the leanpub built-in tools? 

(Started writing a book on leanpub a few years back and found the leanpub formatting workflow very clunky)"
2025,@rasbt,2022-11-11 12:32:27+00:00,https://twitter.com/rasbt/status/1591046192036974594,Native Jupyter notebook diffs on GitHub. Yes yes yes! üëè
2026,@rasbt,2022-11-11 12:29:15+00:00,https://twitter.com/rasbt/status/1591045387057434624,"@baykenney @napoperez1998 Yup, machine learning is a modeling and design contest"
2027,@rasbt,2022-11-11 11:56:10+00:00,https://twitter.com/rasbt/status/1591037061288497152,@akshay_pachaar @python_engineer üíØ  same workflow
2028,@rasbt,2022-11-11 11:55:13+00:00,https://twitter.com/rasbt/status/1591036823845097472,@python_engineer PS: haven‚Äôt touched windows since 2012 so that would be my ranking as well üòÖ
2029,@rasbt,2022-11-11 11:55:04+00:00,https://twitter.com/rasbt/status/1591036786800984064,@python_engineer Tell me your are not into video gaming w/o telling me you are not into video gaming.
2030,@rasbt,2022-11-11 11:53:25+00:00,https://twitter.com/rasbt/status/1591036372303118338,@akshay_pachaar Thanks üôè
2031,@rasbt,2022-11-11 02:51:14+00:00,https://twitter.com/rasbt/status/1590899926015545345,"@DSaience @deliprao This! And fast, frictionless input. Otherwise you will sometimes miss capturing important stuff (and you'll regret later). Here, most apps are great for text but struggle with screenshots."
2032,@rasbt,2022-11-11 01:04:05+00:00,https://twitter.com/rasbt/status/1590872959740411904,"@leonpalafox @vamchale @elonmusk Yeah, and if I could version-control my tweets via git, that'd be great too!"
2033,@rasbt,2022-11-11 00:57:51+00:00,https://twitter.com/rasbt/status/1590871393163685888,"@knitesh Nah, just my gut-feeling that prevented me from getting into crypto last year"
2034,@rasbt,2022-11-11 00:56:57+00:00,https://twitter.com/rasbt/status/1590871164179468288,"@deliprao The key with notetaking apps is that you have to trust that they stay around for years if not decades. At least if you put somewhat useful stuff in there. The long you use it, the more painful it is to transition. 
So far, OneNote seems to be the one with the best track record"
2035,@rasbt,2022-11-11 00:53:31+00:00,https://twitter.com/rasbt/status/1590870303273783296,@soumithchintala I wish ...
2036,@rasbt,2022-11-10 22:46:07+00:00,https://twitter.com/rasbt/status/1590838241770758144,"@jechacas Servers burning down / being shut down is totally exaggerated, but"
2037,@rasbt,2022-11-10 22:44:15+00:00,https://twitter.com/rasbt/status/1590837772050472970,"@FaisalAlsrheed @BlindAnonymous1 There are tools like Freedom for this purpose, but I heard all your info and traffic would go through them, and them, and I am not sure if I would place that level of trust in an App."
2038,@rasbt,2022-11-10 22:43:14+00:00,https://twitter.com/rasbt/status/1590837512947531777,"@FaisalAlsrheed @BlindAnonymous1 Nice one! Haha but I am using Safari most of the time, and since I have multiple browsers installed, I would need the plug in for each individual one üòÖ"
2039,@rasbt,2022-11-10 22:42:22+00:00,https://twitter.com/rasbt/status/1590837296777265152,"@ReneKriest Yeah that‚Äôs a good idea (especially for apps on mobile). On macOS, the problem is that I would essentially blocks everything (including Jupyter) when you block the browser. Or can you now also set limits for individual websites?"
2040,@rasbt,2022-11-10 22:35:01+00:00,https://twitter.com/rasbt/status/1590835448015773696,"I love this community &amp; I am going to share useful stuff about machine learning &amp; AI until the bitter end! üôå

But in case the servers burn down tonight, you can find me on LinkedIn: https://t.co/AJAxKWCKKY"
2041,@rasbt,2022-11-10 22:20:16+00:00,https://twitter.com/rasbt/status/1590831735369273345,"@vamchale @elonmusk Yes, LaTeX support, and syntax color for code blocks pls!"
2042,@rasbt,2022-11-10 21:42:11+00:00,https://twitter.com/rasbt/status/1590822152919404544,"@implisci If you use books more as a quick reference, digital is probably better due to digital search capabilities"
2043,@rasbt,2022-11-10 21:41:23+00:00,https://twitter.com/rasbt/status/1590821948476776448,"@implisci For books I prefer paper most of the time. That‚Äôs because I use a Remarkable for note taking. If I had 2 remarkable tablets, i would probably read books in digital format more often. Although, given that I spend lot of time with books, I do get a lot out of the physical format"
2044,@rasbt,2022-11-10 21:20:18+00:00,https://twitter.com/rasbt/status/1590816643554353159,@DSaience Oh yeah I used both back in the day in college when I was using an iPad.
2045,@rasbt,2022-11-10 20:47:01+00:00,https://twitter.com/rasbt/status/1590808267667677197,"@BlindAnonymous1 @FaisalAlsrheed That‚Äôs a tough one. No perfect solution yet, but the following helps me a little bit at least:"
2046,@rasbt,2022-11-10 20:45:29+00:00,https://twitter.com/rasbt/status/1590807882282708992,"Staying focused when coding is a bit trickier ‚Äî you cannot just turn off Wifi (you typically need it).

My current workarounds:

1) I block news websites (nytimes etc) in the /etc/hosts file

2) I try to log out of social media; having 2-factor auth to make logging back tedious"
2047,@rasbt,2022-11-10 14:36:16+00:00,https://twitter.com/rasbt/status/1590714964876357632,"@paul_rietschka I did something similar before where I had a Google Drive folder with my exported article PDFs, it's basically the same thing?"
2048,@rasbt,2022-11-10 14:34:25+00:00,https://twitter.com/rasbt/status/1590714499723538432,"@HarriVayrynen Regarding transfer, that's e-reader specific. In my case, since I use a Remarkable, I just Drag &amp; Drop the PDF from my Desktop into their app, and it syncs automatically. https://t.co/53YJvzNI6w"
2049,@rasbt,2022-11-10 14:32:30+00:00,https://twitter.com/rasbt/status/1590714015776661504,"@HarriVayrynen I just use ""Print -&gt; Export PDF"" from the browser (Safari). 
If it looks ""ugly"" in the preview view, I enable ""Reader View"" to see if that looks better. If not, I export it as PDF from Chrome.

(In case it still looks ugly, which happens rarely, I don't read the article) https://t.co/AxwE1GuuSS"
2050,@rasbt,2022-11-10 14:27:06+00:00,https://twitter.com/rasbt/status/1590712658654699520,"@FaisalAlsrheed I used a Sony Digital Paper tablet until ~1 year ago. Switched to a smaller form-factor Remarkable -- I like the UI and notetaking feel better.

I'd say the tool doesn't matter as much as the workflow &amp; habit though :)"
2051,@rasbt,2022-11-10 14:25:27+00:00,https://twitter.com/rasbt/status/1590712245142843392,@paul_rietschka My problem is that I'm not that disciplined. Give me the internet and I guarantee you that I get distracted.
2052,@rasbt,2022-11-10 13:54:06+00:00,https://twitter.com/rasbt/status/1590704352813264898,"Pro tip: I export newsletters and blog posts as PDFs so I can read them offline on my e-reader. 

Have been doing that for about a year now and found that it really helps me focus better."
2053,@rasbt,2022-11-10 13:52:32+00:00,https://twitter.com/rasbt/status/1590703957806321664,"@DrGroftehauge @marktenenholtz Yes and no. They are specific forms of data augmentation. Eg an adversarial attack is usually involving augmenting data, but a data augmentation is not necessarily an adversarial attack.
Eg in vision, most people don‚Äôt train with adversarial attacks and weight perturbation either"
2054,@rasbt,2022-11-10 13:49:21+00:00,https://twitter.com/rasbt/status/1590703160364273666,"@bot_fra You could be right. I force myself to read through the chapter it and take notes. I would then follow up with supplementary material afterwards if needed, but I am not always that disciplined"
2055,@rasbt,2022-11-10 13:48:05+00:00,https://twitter.com/rasbt/status/1590702839453843458,"@NormaPadron__ Good point. Audiobooks, for me, only for as entertainment medium. I once made the mistake and got The Book of Why as audiobook version ‚Ä¶"
2056,@rasbt,2022-11-10 13:45:19+00:00,https://twitter.com/rasbt/status/1590702144923242496,"@mikiobraun @paul_rietschka moderation makes and breaks a platform, and I don‚Äôt see how mastodon solves it differently/better. For machine learning, I am almost thinking what people do on mastodon could also be done on Slack or Discourse. I guess critical mass is the issue."
2057,@rasbt,2022-11-10 13:24:29+00:00,https://twitter.com/rasbt/status/1590696898671030274,"I really love the linear structure of books. Sitting down in the morning and reading a textbook brings me a certain level of peace. I can go through it linearly w/o distraction. 

Give me an article &amp; the internet, and I will go onto 1 million tangents before I finish reading it."
2058,@rasbt,2022-11-10 13:15:05+00:00,https://twitter.com/rasbt/status/1590694534727757827,"@marktenenholtz Whoa thanks for sharing! Btw since we just had this debate about data augmentation yesterday, any experiences or thoughts on this? (Let‚Äôs say versus regular MLM, dropout etc)"
2059,@rasbt,2022-11-10 13:12:26+00:00,https://twitter.com/rasbt/status/1590693869389516800,"@tunguz I heard it can be pretty complicated so it requires lots of tweets to explain the why, where, and how üòÖ"
2060,@rasbt,2022-11-10 13:02:36+00:00,https://twitter.com/rasbt/status/1590691392904663042,@gintriag @simonholdorf I think so. There will be less ‚Äúout of curiosity‚Äù research and more ‚Äúlet‚Äôs solve this important problem‚Äù research
2061,@rasbt,2022-11-10 13:00:53+00:00,https://twitter.com/rasbt/status/1590690962984284167,@Tinker_1081 It does not buy itself but it helps you make sure everything works smoothly on multi node setups
2062,@rasbt,2022-11-10 12:59:25+00:00,https://twitter.com/rasbt/status/1590690592589115392,@_Kcnarf @amitness Thanks for sharing! The visual survey is awesome! Very useful resource!
2063,@rasbt,2022-11-10 12:56:34+00:00,https://twitter.com/rasbt/status/1590689875250278401,"@aniketmaurya @FaisalAlsrheed Thanks! So people like us who have been programming for a few years can maybe skip that, but it would be a good one to recommend to students who have taken a Python course and would like to eg contribute to machine learning and deep learning and libraries I assume"
2064,@rasbt,2022-11-09 22:54:17+00:00,https://twitter.com/rasbt/status/1590477909537730560,@FaisalAlsrheed Looks interesting! Is it a book for someone learning Python or would this be aimed at intermediate/advanced Python users? Asking for a friend!
2065,@rasbt,2022-11-09 21:33:55+00:00,https://twitter.com/rasbt/status/1590457680795439106,"@dillonniederhut Thanks! Have to check that out! 
Btw ""I think my favorite is still the one for appending 'love' to random sentences"" would be a nice one for the new Twitter, haha"
2066,@rasbt,2022-11-09 21:31:48+00:00,https://twitter.com/rasbt/status/1590457149775568901,"@ph_singer Totally agree! Coming from largely doing computer vision, I had the same thoughts (and complaints), and I am just exploring the space of possibilities here"
2067,@rasbt,2022-11-09 21:27:29+00:00,https://twitter.com/rasbt/status/1590456063165599745,"@ph_singer But yeah, the proof is in the pudding, and YMMV. I was just looking for common things one can try during fine-tuning tbh, coz I am not going to train transformers from scratch myself yet. Not sure how systematic I will be, but I hope to share my own experiments in a few months"
2068,@rasbt,2022-11-09 21:25:50+00:00,https://twitter.com/rasbt/status/1590455649581731840,@ph_singer For 2) you can also use it for fine-tuning; here would be one ablation study on Roberta: https://t.co/twmvShPADD
2069,@rasbt,2022-11-09 21:22:04+00:00,https://twitter.com/rasbt/status/1590454702348861442,"@ph_singer I may be wrong, but I assumed that they only used backtranslation for training on the WMT2014 English-German dataset and not for the pretraining"
2070,@rasbt,2022-11-09 21:11:14+00:00,https://twitter.com/rasbt/status/1590451975229169665,"@ph_singer Ok fair, but it literally has the best BLEU score on e.g., WMT2014 English-German afaik https://t.co/MduoNVpsNH"
2071,@rasbt,2022-11-09 21:04:41+00:00,https://twitter.com/rasbt/status/1590450326536015875,"@ph_singer * for 2), not every masked language model does all the listed things though, e.g. BERT is not using synonyms but random words"
2072,@rasbt,2022-11-09 21:02:51+00:00,https://twitter.com/rasbt/status/1590449863116075009,"@ph_singer For example, for 1) https://t.co/BGwY3Av18p
and for 
2) basically all masked language models, like the original BERT paper among others"
2073,@rasbt,2022-11-09 20:50:31+00:00,https://twitter.com/rasbt/status/1590446762208423936,@PredaGabi @elonmusk you don't like getting holiday gifts?
2074,@rasbt,2022-11-09 20:49:32+00:00,https://twitter.com/rasbt/status/1590446511934300161,"@v3n0m92 sry, nothing ready that I can share yet. Aiming more for Q1 2023"
2075,@rasbt,2022-11-09 20:41:53+00:00,https://twitter.com/rasbt/status/1590444586706817024,"Text data augmentation techniques that are commonly used for large language models:

1) back translation: translate text to another language &amp; back

2) token perturbations: replace words with synonyms; swap, delete or insert words

3) intentionally left blank"
2076,@rasbt,2022-11-09 19:59:39+00:00,https://twitter.com/rasbt/status/1590433960244355073,"@CurtTigges @hardmaru Sry I didn't want to imply universities have mandates. I meant that to keep doing AI alignment &amp; Ethics research, they can't rely on company money, so more will need to come out from tuition and grants"
2077,@rasbt,2022-11-09 19:29:42+00:00,https://twitter.com/rasbt/status/1590426422992343040,@brianalast and true friends don‚Äôt ask you to reconsider the order of authorship
2078,@rasbt,2022-11-09 19:21:54+00:00,https://twitter.com/rasbt/status/1590424459688955904,"@WholeMarsBlog Yeah, it kind of hurts my eyes. If you expect most people to get this, it might make more sense to have an unverified badge instead, or sth like that."
2079,@rasbt,2022-11-09 19:18:13+00:00,https://twitter.com/rasbt/status/1590423534316453889,"@elonmusk Move fast and ‚Ä¶ ship things! 
The holidays are just around the corner."
2080,@rasbt,2022-11-09 17:34:00+00:00,https://twitter.com/rasbt/status/1590397306834399232,@TaliaRinger Ah thx didn‚Äôt realize it was a thread üôè
2081,@rasbt,2022-11-09 14:58:38+00:00,https://twitter.com/rasbt/status/1590358207708348416,"If someone has some unallocated free time, it would be interesting to see forward/backward times for individual layers (fully-connected, conv) side by side for Nvidia GPUs vs ARM chips üòä
https://t.co/6f0HX8QznX"
2082,@rasbt,2022-11-09 14:56:03+00:00,https://twitter.com/rasbt/status/1590357554940764162,*you may have to install the nightly version of PyTorch for now to make it work. But I guess it will work out of the box after the next PyTorch release ^^
2083,@rasbt,2022-11-09 14:55:05+00:00,https://twitter.com/rasbt/status/1590357314619310080,@jbohnslav Only caveat is that it currently only seems to work with the nightly version. But super cool stuff!!
2084,@rasbt,2022-11-09 14:45:03+00:00,https://twitter.com/rasbt/status/1590354787047903233,"Are you profiling your deep learning code to find performance bottlenecks? If yes, what are your go-to tools?

1) official PyTorch Profile, operator-call level: https://t.co/J7DjfMJwzf

2) a new, helpful community project for profiling at the layer level: https://t.co/JDNy7M4hKj https://t.co/Uf49GcMvvO"
2085,@rasbt,2022-11-09 14:19:11+00:00,https://twitter.com/rasbt/status/1590348277916270593,"@LynAldenContact Not far off. When I was in school, the Big Mac Index was a big thing (https://t.co/2hnvYHgkLf). 

Only thing that was holding it back was its expiration date."
2086,@rasbt,2022-11-09 14:08:09+00:00,https://twitter.com/rasbt/status/1590345500674297856,@HugoYeche Ah this is bad. Contact AC I‚Äôd say. I think that‚Äôs a failure in the OpenReview system. Editors/ACs should check reviews before they get posted.
2087,@rasbt,2022-11-09 13:55:24+00:00,https://twitter.com/rasbt/status/1590342292287520768,"@CurtTigges @hardmaru two ways: the (more) unbiased AI alignment research is academic for obvious reasons; with fewer companies supporting research, academic departments and researchers will have to support programs, hiring, and computational budgets via tuition $$$"
2088,@rasbt,2022-11-09 13:01:56+00:00,https://twitter.com/rasbt/status/1590328836025380865,@GaryMarcus tl;dr üòâ
2089,@rasbt,2022-11-09 12:58:29+00:00,https://twitter.com/rasbt/status/1590327967627898880,@dylanmatt Is there a https://t.co/G76tEZrI38 for Mastodon servers yet?
2090,@rasbt,2022-11-09 12:57:25+00:00,https://twitter.com/rasbt/status/1590327701080244225,@philipvollet @fintechfrank üî•
2091,@rasbt,2022-11-09 12:55:51+00:00,https://twitter.com/rasbt/status/1590327306513698816,@tunguz Heart beat after morning meditation?
2092,@rasbt,2022-11-09 12:54:08+00:00,https://twitter.com/rasbt/status/1590326874928209920,"@hardmaru The answer is, I guess, yet another increase in college tuitions :("
2093,@rasbt,2022-11-09 12:49:37+00:00,https://twitter.com/rasbt/status/1590325738086932481,@simonholdorf Machine Learning is CONTINUING to be one of the hottest disciplines in 2023 üòâ
2094,@rasbt,2022-11-09 12:45:33+00:00,https://twitter.com/rasbt/status/1590324715482415107,"@drChromiak I think you can add the newsletter to your RSS reader: https://t.co/SczSPkmnjw

If that doesn‚Äôt work, you can try the substack RSS: https://t.co/aUwFil4uPS

Let me know if there are issues!"
2095,@rasbt,2022-11-09 12:39:23+00:00,https://twitter.com/rasbt/status/1590323163401179136,"@Tinker_1081 1: Because this was a simple project I omitted the DataModule because the code in the notebook was already too long. If you run simple experiments on a single machine PyTorch dataloaders already suffice
2: batch size, learning rate, number of output layers"
2096,@rasbt,2022-11-08 23:48:41+00:00,https://twitter.com/rasbt/status/1590129210408177665,"@ferpicado1 Wohoo, thanks for the support, and I hope you'll like it!!"
2097,@rasbt,2022-11-08 19:55:14+00:00,https://twitter.com/rasbt/status/1590070461312167936,"@CSProfKGD @chriswolfvision oops, I see now"
2098,@rasbt,2022-11-08 19:50:48+00:00,https://twitter.com/rasbt/status/1590069346533281793,"@chriswolfvision @CSProfKGD Hah, I can see both sides here. The author's response was maybe a bit too strong, haha. 
How about 
""Thanks for offering to review our paper. Unfortunately, it seems like your review text is missing. Please amend so that we can address potential issues (if any) in the rebuttal"""
2099,@rasbt,2022-11-08 19:18:00+00:00,https://twitter.com/rasbt/status/1590061090796638208,"@bndgyawali sry, and thanks for the note. Just fixed it. Should have been https://t.co/iK41TzC7AH"
2100,@rasbt,2022-11-08 18:18:09+00:00,https://twitter.com/rasbt/status/1590046026857349121,"@arjunnnio @MiguelCRomao The molecules don't look like realistic molecules. They may look fine locally, but I think it's maybe missing the proper modeling of larger-scale physical constraints and interactions."
2101,@rasbt,2022-11-08 17:59:09+00:00,https://twitter.com/rasbt/status/1590041248639094784,"@arjunnnio @MiguelCRomao Or in other words, with a GNN it‚Äôs already hard to model a single amino acid. And a protein consists of 375 amino acids on average"
2102,@rasbt,2022-11-08 17:58:08+00:00,https://twitter.com/rasbt/status/1590040992169988097,"@arjunnnio @MiguelCRomao That‚Äôs for predictive modeling. For generative modeling, with GNNs it also doesn‚Äôt scale qualitatively; beyond like 20-50 atoms the results get ugly. Now a protein consists of 375 amino acids each with like 20 atoms on average each"
2103,@rasbt,2022-11-08 17:55:00+00:00,https://twitter.com/rasbt/status/1590040200704839680,@arjunnnio @MiguelCRomao What I meant was that conventional GNNs work more on the atom level and that doesn‚Äôt scale very well (computationally) to larger structures.
2104,@rasbt,2022-11-08 17:46:16+00:00,https://twitter.com/rasbt/status/1590038005930024960,"[2/2] Predictive performance is worse than the fine-tuning examples I shared last week, but hey, it's a lean &amp; simple baseline.

My full code example here: https://t.co/gj6dkSkJYj"
2105,@rasbt,2022-11-08 17:46:15+00:00,https://twitter.com/rasbt/status/1590038002771709952,"Recently stumbled upon embetter, a little scikit-learn compatible library centered around embeddings for computer vision and text: https://t.co/fOePIfP4DQ.

Build an LLM feature extractor-based classifier pipeline in 4 lines of code.

[1/2] https://t.co/Nhr9qbvTO9"
2106,@rasbt,2022-11-08 14:02:15+00:00,https://twitter.com/rasbt/status/1589981629355024384,"@cbrnr_ Agreed. I was of course exaggerating üòâ. But yeah as soon as you try to use it as a programming language rather than a toolbox, it feels very clunky"
2107,@rasbt,2022-11-08 13:45:24+00:00,https://twitter.com/rasbt/status/1589977390092288000,"@ItaDude Generally, you are right. But I don‚Äôt want to be just posting and not responding to responses. So I would basically have to split myself between two platforms now to interact with people. Because I think posting without the interaction is not that useful."
2108,@rasbt,2022-11-08 13:28:53+00:00,https://twitter.com/rasbt/status/1589973234212274183,"@rezar It‚Äôs essentially message passing; not sure about the linked list; kind of, yes, but with multiple nodes and pooling."
2109,@rasbt,2022-11-08 13:26:49+00:00,https://twitter.com/rasbt/status/1589972711064817664,"@Kaustubh_D_09 Personally I never had to use HBASE (Java may be useful for getting I to Scala, but that‚Äôs another one I dodged so far; I think it‚Äôs popularity also severely declined in recent years)"
2110,@rasbt,2022-11-08 12:48:04+00:00,https://twitter.com/rasbt/status/1589962958372601856,"@Kaustubh_D_09 Machine learning &amp; deep learning, data munging, data exploration and statistical analyses, and automating various mundane things"
2111,@rasbt,2022-11-08 12:45:22+00:00,https://twitter.com/rasbt/status/1589962281345241088,"@giffmana @Michael_J_Black If you ever consider to modify it or build your own, consider putting it up here: https://t.co/G76tEZJRhg"
2112,@rasbt,2022-11-08 12:42:51+00:00,https://twitter.com/rasbt/status/1589961647602692096,@ID_AA_Carmack ‚Äúdominated by confident predictions of catastrophe‚Äù ‚Äî a healthy sign that twitter still works as usual üòÜ
2113,@rasbt,2022-11-08 12:33:59+00:00,https://twitter.com/rasbt/status/1589959415188271104,"Next: Javascript because that sounded pretty cool back then.

But yeah, eventually all roads lead to Python (even though I also learned C, C++, and Java). Today, I am just using Python, and I could have certainly skipped the rest without missing out and having a fulfilled life üòÖ"
2114,@rasbt,2022-11-08 12:33:58+00:00,https://twitter.com/rasbt/status/1589959412843585536,"Pascal, but I am not sure if that really counts because I didn‚Äôt really pay attention in high school. 

Learned R next (thx, statistics classes) but I am also not sure if that counts as programming ‚Ä¶ coz R.

Then Perl in bioinformatics, but I was just hacking together scripts"
2115,@rasbt,2022-11-08 12:22:16+00:00,https://twitter.com/rasbt/status/1589956469528854528,"@GergelyOrosz Never heard of it, could you give us a eli5 version of the test procedure and rationale?"
2116,@rasbt,2022-11-08 12:20:32+00:00,https://twitter.com/rasbt/status/1589956030875983873,Christoph has a unique ability to break down statistical jargon into accessible bits. Looking forward to reading!
2117,@rasbt,2022-11-08 12:17:50+00:00,https://twitter.com/rasbt/status/1589955349930725376,@ChristophMolnar Big congrats üéâ !! Really looking forward to reading it!!
2118,@rasbt,2022-11-08 12:16:40+00:00,https://twitter.com/rasbt/status/1589955056350416896,"@ItaDude I am currently not planning on using mastodon, I am already spending too much time on social media haha. So if there is someone with my name on mastodon then yeah that‚Äôs probably an impersonator"
2119,@rasbt,2022-11-08 01:58:25+00:00,https://twitter.com/rasbt/status/1589799472632299521,"@cwizprod1 Good question, and I would say yes. Except Google Translate already switched to transformers a few years ago üòä https://t.co/pYk0DClhES"
2120,@rasbt,2022-11-08 01:56:22+00:00,https://twitter.com/rasbt/status/1589798953864032257,"@CalcCon Yeah, esp for molecular dynamics. But that makes it even more impressive that AlphaFold2, a completely new approach, outperformed them at CASP"
2121,@rasbt,2022-11-08 01:52:41+00:00,https://twitter.com/rasbt/status/1589798027187085312,"@DerkKooi Yes you are right, GNNs can shine when applied to small molecules when you are interested in the more local properties. Especially when modeling eg 3D conformers, and when estimating quantum mechanical properties"
2122,@rasbt,2022-11-07 22:14:19+00:00,https://twitter.com/rasbt/status/1589743072715632640,"@beenwrekt Well, in classification you can have an arbitrary black box just give an answer ‚Äî it‚Äôs either correct or incorrect, and no one cares about the gray zone in-between. Regression models can fail more epically because you are not matching answers &amp; it‚Äôs all about that zone in between"
2123,@rasbt,2022-11-07 21:07:03+00:00,https://twitter.com/rasbt/status/1589726146018828289,"@AllesistKode @technotweet As a subscriber you don‚Äôt have to worry about the backend though, you will get the next issue either way ;)"
2124,@rasbt,2022-11-07 21:05:13+00:00,https://twitter.com/rasbt/status/1589725684951584768,@AllesistKode @technotweet heard some rumor about that but we will see. I set up a substack account for the just in case scenario. It‚Äôs currently lagging 1 week because I just set it up on Fri and didn‚Äôt want to overwhelm the new subscribers with 2 articles in a row üòÜ https://t.co/W5kmcV5Xka
2125,@rasbt,2022-11-07 20:36:23+00:00,https://twitter.com/rasbt/status/1589718428276826112,"@_chasmcgill We have an unfinished paper on that (the PhD student I was co-advising recently moved to a startup so I am not sure if we will ever finish it). Anyways, I probably shouldn‚Äôt post the details on social media (just yet) üòÜ"
2126,@rasbt,2022-11-07 20:27:00+00:00,https://twitter.com/rasbt/status/1589716067727077376,@technotweet Thanks for the support and the kind words! Glad to hear you are liking it!
2127,@rasbt,2022-11-07 20:26:11+00:00,https://twitter.com/rasbt/status/1589715861543452672,@alexanderrofail Totally. Their strengths are tasks like predicting bioactivity in ligand &amp; drug screening projects where you have millions of small molecules. But tbh you can also get similarly good results with fingerprint or ProtBERT embeddings based on my practical experience
2128,@rasbt,2022-11-07 20:20:35+00:00,https://twitter.com/rasbt/status/1589714451678101505,"In other words, I totally would have bet on graph neural nets 5-10 years ago. Actually, I did start two major projects based on graph neural nets for generative modeling. The results have been underwhelming and we canceled the projects after 3 years of wasted efforts."
2129,@rasbt,2022-11-07 20:15:27+00:00,https://twitter.com/rasbt/status/1589713158742364164,"Graph neural networks. They scale relatively well to datasets with large numbers of molecules; they don‚Äôt scale well to datasets consisting of large molecules. 

(Take AlphaFold2 and ESMFold. 5 years ago, who would have thunk protein folding would be tackled by language models)"
2130,@rasbt,2022-11-07 19:07:56+00:00,https://twitter.com/rasbt/status/1589696168539607040,"@FaisalAlsrheed Thanks üôå, and that sounds like a plan! üëç"
2131,@rasbt,2022-11-07 18:32:05+00:00,https://twitter.com/rasbt/status/1589687145895440385,"@chrisalbon Arg, what a ride! (no pun intended)"
2132,@rasbt,2022-11-07 18:28:59+00:00,https://twitter.com/rasbt/status/1589686365398405120,"And the longer version of how I ""harvest"" info from these resources here: https://t.co/oJmspacuJx

(scroll down to Productivity Tips; unfortunately, I can't link the section directly, arg)"
2133,@rasbt,2022-11-07 17:44:13+00:00,https://twitter.com/rasbt/status/1589675103092346881,"@LandupDavid @jackclarkSF @DeepLearningAI_ @AndrewYNg @dataelixir @seb_ruder üî•
Thanks!"
2134,@rasbt,2022-11-07 17:31:45+00:00,https://twitter.com/rasbt/status/1589671963810668544,"Big thanks to the 2k subscribers that joined since the first issue was released last month! Very motivating! 
W/o you, I wouldn't have nearly put as much effort into it this weekend üòä"
2135,@rasbt,2022-11-07 17:29:28+00:00,https://twitter.com/rasbt/status/1589671389384282113,"@permutans @srchvrs @ph_singer ""Not everything has to be for everything"" --&gt; Right, that's why I use Linux only for my server üòÖ"
2136,@rasbt,2022-11-07 17:27:30+00:00,https://twitter.com/rasbt/status/1589670895651409920,"Hot off the press: 
üí® Ahead of AI #2: Transformers, Fast and Slow!

This time, we cover
- Language transformers, and what they are good for
- Exciting open source releases
- And how to keep up with ML!

https://t.co/oJmsp9Ulvp"
2137,@rasbt,2022-11-07 17:14:02+00:00,https://twitter.com/rasbt/status/1589667504435376129,@permutans @srchvrs @ph_singer I have a friend who still has to dial in into zoom meetings both with computer + phone because of bluetooth drivers
2138,@rasbt,2022-11-07 16:47:16+00:00,https://twitter.com/rasbt/status/1589660769817616385,@Mohanty15Roy @rediffmail The newsletter? The address is https://t.co/TmndH1bJVN
2139,@rasbt,2022-11-07 16:43:26+00:00,https://twitter.com/rasbt/status/1589659803059904512,"@OkbaLeftHanded Oh I only do keyword alerts, not author alerts ^^"
2140,@rasbt,2022-11-07 15:28:24+00:00,https://twitter.com/rasbt/status/1589640922337513472,"@OkbaLeftHanded Yeah, I check reddit like once per month or so üòÖ. the ML subreddit is not what it once was üò¢"
2141,@rasbt,2022-11-07 14:20:10+00:00,https://twitter.com/rasbt/status/1589623748461666305,@anirudhacharya1 sure! https://t.co/ekLuz6dE5e
2142,@rasbt,2022-11-07 14:20:06+00:00,https://twitter.com/rasbt/status/1589623731474743296,"@ai_sparkle99 Good idea, should do that some time!!"
2143,@rasbt,2022-11-07 14:19:27+00:00,https://twitter.com/rasbt/status/1589623570577358848,"@LandupDavid To name a few: 
- @jackclarkSF's Import AI. 
- @DeepLearningAI_ &amp; @AndrewYNg 's The Batch.
- @dataelixir 
- @seb_ruder's NLP news

(And then there is Ahead of AI of course https://t.co/TmndH1bJVN, new issue dropping today)"
2144,@rasbt,2022-11-07 14:07:35+00:00,https://twitter.com/rasbt/status/1589620581812404224,@srchvrs @ph_singer or even worse: laptop
2145,@rasbt,2022-11-07 13:57:36+00:00,https://twitter.com/rasbt/status/1589618069483458560,"@ph_singer It's basically the Linux of social media. Nothing wrong with Linux (I run it on my server), but yeah, it's still Linux üòÖ"
2146,@rasbt,2022-11-07 13:47:19+00:00,https://twitter.com/rasbt/status/1589615482541207553,"What are some resources that I use to stay up to date with ML?

‚Ä¢ Google Scholar keyword alerts
‚Ä¢ https://t.co/G75gvSTgXw
‚Ä¢ following machine learning folks on Twitter
‚Ä¢ newsletters
‚Ä¢ sometimes (/rarely) checking the ML subreddit

Will share details in today's newsletter üòä"
2147,@rasbt,2022-11-06 20:09:35+00:00,https://twitter.com/rasbt/status/1589349297589407745,"@LandupDavid Hah, remember 

from pylab import * ? üòÜ"
2148,@rasbt,2022-11-06 20:04:32+00:00,https://twitter.com/rasbt/status/1589348025369243648,"@TaliaRinger Yeah, same! Met so many smart people here and learned so many new things over there years. Also, it‚Äôs pretty cool to just casually start a conversation with a Nobel prize laureate or Turing award winner. No other platform comes close to this."
2149,@rasbt,2022-11-06 19:58:02+00:00,https://twitter.com/rasbt/status/1589346390693793793,@chrisalbon You work at wikipedia; probably easier to change the spelling of the word on Wiktionary instead üòÜ
2150,@rasbt,2022-11-06 19:52:07+00:00,https://twitter.com/rasbt/status/1589344899274805249,"@chrisalbon I like it a lot! Has the same charm but looks cleaner. Btw, if you are like me, I guess it‚Äôs also way less frustrating to make these thx to the digital eraser tool."
2151,@rasbt,2022-11-06 16:12:34+00:00,https://twitter.com/rasbt/status/1589289649369133056,@LandupDavid My eyes hurt
2152,@rasbt,2022-11-06 16:10:28+00:00,https://twitter.com/rasbt/status/1589289119053930498,@between_2_pines @moyix But it is actually ‚Äútweeted‚Äù (or ‚Äútwittered‚Äù if you are gen x)
2153,@rasbt,2022-11-06 16:03:02+00:00,https://twitter.com/rasbt/status/1589287251233583105,"@seanparadiso I don't think pymc is feasible ... the data-generating processes of real-world datasets are usually black-boxes; otherwise you wouldn't be using machine learning.

With better I meant better than the other commonly used methods like SMOTE, CTGAN/CTABGAN+, and TVAE"
2154,@rasbt,2022-11-06 15:51:12+00:00,https://twitter.com/rasbt/status/1589284273512919040,"@seanparadiso A bit of both, haha. The numbers look quite good tbh. Better than the other synthetic tabular data methods for sure. But yeah, like with all papers, YMMV, and you have to try it on your own datasets to draw any real-world conclusions."
2155,@rasbt,2022-11-06 15:34:34+00:00,https://twitter.com/rasbt/status/1589280086565744640,@akshay_pachaar attention is all you need!
2156,@rasbt,2022-11-06 15:23:03+00:00,https://twitter.com/rasbt/status/1589277185507938305,"""Language Models Are Realistic Tabular Data Generators"" (https://t.co/SQq1G1N9eG).

A new method for generating synthetic data via large-language models (ie pre-trained transformers / GPT-2).

Pls welcome our newest member to the Chronology of Deep Learning for Tabular Data list! https://t.co/UUNMIQiNS8"
2157,@rasbt,2022-11-06 14:46:45+00:00,https://twitter.com/rasbt/status/1589268052482281472,@kchonyc it's probably by design. instagram is an advertisement channel that sometimes also shows you pictures of your friends
2158,@rasbt,2022-11-06 14:42:22+00:00,https://twitter.com/rasbt/status/1589266950756401152,"@CSProfKGD @soumithchintala @fchollet @tunguz @lmoroney Oh yes, looking at particular failure cases (misclassified examples) is a particularly useful exercises in CV!"
2159,@rasbt,2022-11-06 14:40:23+00:00,https://twitter.com/rasbt/status/1589266449671262209,@ylecun touch√© üòÖ
2160,@rasbt,2022-11-06 13:20:45+00:00,https://twitter.com/rasbt/status/1589246409332600832,"Flattered to be part of it!
- @soumithchintala about learning from books
- @fchollet on limitations of ML
- @tunguz on sequencing your learning journey
- @lmoroney on imposter syndrome and academic credentials
- and yours truly on evaluating models and metrics without context üòä"
2161,@rasbt,2022-11-06 13:11:05+00:00,https://twitter.com/rasbt/status/1589243977655459842,"@R_Bodaban Personally, I learned a lot from scikit-learn"
2162,@rasbt,2022-11-06 13:10:32+00:00,https://twitter.com/rasbt/status/1589243840640450562,"@R_Bodaban Don‚Äôt be too hard on yourself. In takes time and there‚Äôs is no rush.That being said, I think a great way to advance your skills is by participating in open source projects. There are lots of projects with pretty elegant and advanced code to learn from."
2163,@rasbt,2022-11-06 13:06:48+00:00,https://twitter.com/rasbt/status/1589242897022750725,@_vonarchimboldi @DebarpanBhatta8 I really like the premise of this. Haha maybe I‚Äôll will add it to my Xmas wishlist
2164,@rasbt,2022-11-06 13:05:10+00:00,https://twitter.com/rasbt/status/1589242485989330944,@eduardoczini @dabeaz Thanks for the recommendation! Should definitely check it out and add it to the list! I really like @dabeaz‚Äôs content!
2165,@rasbt,2022-11-06 13:03:06+00:00,https://twitter.com/rasbt/status/1589241967166488576,"@GiorgioMantova @Codecademy Absolutely! Applying learned concepts to a passion project is a great motivator to learn. Personally, I learned pandas (and ML concepts) by automating a daily fantasy soccer betting pipeline ‚Äî I was really into soccer and it was just a fun way to tinker with messy data"
2166,@rasbt,2022-11-06 13:00:55+00:00,https://twitter.com/rasbt/status/1589241419109380098,"@GiorgioMantova Hah yeah fair, I will maybe update this more often :)"
2167,@rasbt,2022-11-05 17:31:13+00:00,https://twitter.com/rasbt/status/1588947053232951297,"My colleague @DaniDapena made a really awesome video tutorial on Stable Diffusion! 

üìΩÔ∏è https://t.co/7dMaOC5EOC
(Comprehensive yet very accessible!!)

Highly recommend it in case you don't have any plans for this weekend, yet, and can spare 30 min to learn something new!"
2168,@rasbt,2022-11-05 16:36:09+00:00,https://twitter.com/rasbt/status/1588933194241298439,"@permutans @Codecademy Yeah, of course free would be nicer -- I think it was free when I took it back then. Anyways, I also posted lots of free alternatives below. 
(But imho, sometimes the best resource are not free. I am not affiliated or so, I just think their interactive course is really effective)"
2169,@rasbt,2022-11-05 16:10:49+00:00,https://twitter.com/rasbt/status/1588926819352588288,@ylecun you are not wrong ... it was actually quite cool until my parents joined
2170,@rasbt,2022-11-05 16:02:17+00:00,https://twitter.com/rasbt/status/1588924672368087040,"@permutans @Codecademy Yeah, I would recommend the Python 3 course if you can afford it. It's not cheap at $~18 but yeah, it will be a good investment."
2171,@rasbt,2022-11-05 14:49:52+00:00,https://twitter.com/rasbt/status/1588906447894872066,"@rascazzione Thanks for link! Which particular Python course from this huge collection would you recommend? ""Python for Everyone -- Interactive""?"
2172,@rasbt,2022-11-05 14:16:10+00:00,https://twitter.com/rasbt/status/1588897965808136192,@Z54010612 Fluent Python by Luciano Ramalho is a good one. For really advanced stuff there is no way around working on &amp; contributing to open source projects. One of the best ways to learn new skills and getting exposed to advanced code bases (YMMV depending on the project of course)
2173,@rasbt,2022-11-05 14:12:32+00:00,https://twitter.com/rasbt/status/1588897053111111680,@XiongChenyan Just wow. Tbh I think editors should do a better job filtering out bad reviewers
2174,@rasbt,2022-11-05 14:05:30+00:00,https://twitter.com/rasbt/status/1588895282619568128,@Twitch ‚ÄúPizza Time‚Äù ‚Äî TMNT 2 on the original Gameboy https://t.co/cJqTLzWpYR
2175,@rasbt,2022-11-05 14:02:34+00:00,https://twitter.com/rasbt/status/1588894545067970561,"@ola_oi_friends Haha fair! I don‚Äôt know how it came to this but I came to associate blog posts with longer writing projects ‚Ä¶ but right, it doesn‚Äôt have to be this way üòÖ"
2176,@rasbt,2022-11-05 13:12:05+00:00,https://twitter.com/rasbt/status/1588881839103479808,"Ok, originally, I wanted to share resources for all 10 topics in the original tweet, but this ü™°  is already getting out of hand üòÖ. Since learning 1 thing will already keep you pretty busy, I guess there is no rush and I can share additional resources on a monthly basis or so üòä"
2177,@rasbt,2022-11-05 13:12:04+00:00,https://twitter.com/rasbt/status/1588881836364603392,"Then, as a follow-up to learning Python, I recommend getting into NumPy (it will be super relevant for machine learning!): https://t.co/HDUrwkmNvC

Alternative, a shorter tutorial by yours truly: https://t.co/SkStNbnWKU"
2178,@rasbt,2022-11-05 13:12:03+00:00,https://twitter.com/rasbt/status/1588881833730535425,"In addition there's a great video series by educators at Microsoft, which was recently made available for free on YouTube: https://t.co/PzVqFMOEjA."
2179,@rasbt,2022-11-05 13:12:03+00:00,https://twitter.com/rasbt/status/1588881831062958080,A free alternative (that is also interactive) is https://t.co/jtbXtHjarB. A former student who took my machine learning class highly recommended it and found it super helpful but I haven't tried it myself.
2180,@rasbt,2022-11-05 13:12:02+00:00,https://twitter.com/rasbt/status/1588881828395462656,"Anyways, they have a Python 2 version that is free (https://t.co/6uWMPIyOmK), and you could follow up with my 2-to-3 guide: https://t.co/Qg0NcegJfY

(Btw I am absolutely not affiliated with @Codecademy; is just one of the resources I used when I started, and I really liked it)"
2181,@rasbt,2022-11-05 13:12:01+00:00,https://twitter.com/rasbt/status/1588881825765597184,"I recommend the @Codecademy Python 3 course (not free anymore): https://t.co/msclcr41qO
Ok, there's lots of free material on the the internet &amp; you wonder why paying for this? Absolutely check out free material, but certain material is sometimes a tad better &amp; helps you faster"
2182,@rasbt,2022-11-05 13:12:01+00:00,https://twitter.com/rasbt/status/1588881823098056704,"You asked me for resources for each of these subjects? Ok, so let's go!

1. Python: In the beginning, I think this is best learned interactively. I.e., learning by doing. If you read a Python book, you might lose motivation quickly. ü™°"
2183,@rasbt,2022-11-05 02:59:57+00:00,https://twitter.com/rasbt/status/1588727793118220290,"@AmandaAskell Oh yes! Blogs! They were my favorite things about the internet. I am not kidding, I miss those üò¢"
2184,@rasbt,2022-11-05 02:56:42+00:00,https://twitter.com/rasbt/status/1588726972464914432,@ruchowdh sending virtual support. it so sad to see it all go down like this üò¢
2185,@rasbt,2022-11-05 02:54:42+00:00,https://twitter.com/rasbt/status/1588726469232300034,"@KLdivergence Arg sorry to hear üò£.
Tbh, I can't imagine someone not hiring someone with your experience! Please be gentle with yourself, you got this!"
2186,@rasbt,2022-11-05 02:47:12+00:00,https://twitter.com/rasbt/status/1588724584463077376,"@maosbot yeah, I am a completionist as well https://t.co/RCYb8I9MbK"
2187,@rasbt,2022-11-05 02:40:36+00:00,https://twitter.com/rasbt/status/1588722924013654017,"@tunguz Right, it never got a PyTorch backend üòÜ"
2188,@rasbt,2022-11-05 02:38:45+00:00,https://twitter.com/rasbt/status/1588722455857991680,@deliprao I am old enough to remember Google+ ... It actually had a pretty nice ML community over there.
2189,@rasbt,2022-11-04 20:12:43+00:00,https://twitter.com/rasbt/status/1588625310328958976,"@vladiliescu @HamelHusain ""I‚Äôm trying to join a new platform and first thing they ask is to pick a *server* to use for my account?"" --&gt; sounds like World of Warcraft, lol. 
(PS: never played because it was released during my final years of high school, and I wanted to graduate)"
2190,@rasbt,2022-11-04 20:10:20+00:00,https://twitter.com/rasbt/status/1588624708425375745,"@TheZachMueller @bndgyawali @HamelHusain And for the social aspect and the ML community feel, I could/should probably be more active on the PyTorch forum üòÖ"
2191,@rasbt,2022-11-04 20:08:59+00:00,https://twitter.com/rasbt/status/1588624370158948353,"@TheZachMueller @bndgyawali @HamelHusain Haha, I share your sentiment. Not planning to move. In case this ship sinks, I'll probably go back to no social media (remember those times where we got so much before social media when we got so much more done? üòÜ)"
2192,@rasbt,2022-11-04 19:58:25+00:00,https://twitter.com/rasbt/status/1588621711485898752,"@monsieurwagner Actually, not too far off. I think @ykilcher's company (DeepJudge) is centered around/working on it üòÜ"
2193,@rasbt,2022-11-04 19:49:36+00:00,https://twitter.com/rasbt/status/1588619492510224384,"@monsieurwagner It depends on the application. For language translation it probably doesn't make sense (just run multiple queries with a few sentences each). However, I think this could be super useful for text summarization and classification, for example, where the whole context matters."
2194,@rasbt,2022-11-04 19:15:04+00:00,https://twitter.com/rasbt/status/1588610798829510656,"[3/3] Sounds depressing? Here are some good news: actually, you can combine sequence parallelism with sparse attention mechanisms to train transformers with 27x longer input sequences. The researchers report token lengths up to 114k!"
2195,@rasbt,2022-11-04 19:15:03+00:00,https://twitter.com/rasbt/status/1588610795604045824,"[2/3] Sequence parallelism is an distributed comp alternative to using sparse attention mechanisms --for some reason, no one seems to be using efficient scaled-dot product versions! https://t.co/SCbeCBp7F1
(This observation was later also picked up by the State of AI 2022 report)"
2196,@rasbt,2022-11-04 19:15:02+00:00,https://twitter.com/rasbt/status/1588610792311529472,"Looks like I have to amend my list and add number 5: Sequence parallelism as a new multi-GPU paradigm.
Sequence parallelism seems very useful for large-scale transformer training as it can take transformer inputs to new lengths (no pun intended).
https://t.co/NIJFjsdFiZ
[1/3] https://t.co/sp4G0vShpb"
2197,@rasbt,2022-11-04 16:39:45+00:00,https://twitter.com/rasbt/status/1588571715843805184,"@SashaMTL @huggingface @BigscienceW Awesome work!! üôå

(Hah, and great timing! The upcoming Ahead of AI issue will be transformer-themed, and I am looking forward to reading &amp; including it this weekend!)"
2198,@rasbt,2022-11-04 15:20:52+00:00,https://twitter.com/rasbt/status/1588551861673820161,@RabirajBandyop1 thanks @RabirajBandyop1! üôå
2199,@rasbt,2022-11-04 15:18:31+00:00,https://twitter.com/rasbt/status/1588551269836550144,"@IsaacAfedzi3 @atheeralattar To me, PyTorch has a good balance between flexibility while feeling like Python &amp; being user friendly. Tf is good for standard networks, but as soon as you want to customize things (e.g., develop your own layers) it becomes very clunky."
2200,@rasbt,2022-11-04 15:12:56+00:00,https://twitter.com/rasbt/status/1588549865147052032,@svpino @LandupDavid solution: treat it as a hyperparameter üòÜ
2201,@rasbt,2022-11-04 15:12:05+00:00,https://twitter.com/rasbt/status/1588549653368565763,"@svpino Yup, there has been quite some back and forth. I think the survey is only a bit tilted towards the first option because of the original paper and code re-use.
 https://t.co/o2iK0y5ng3"
2202,@rasbt,2022-11-04 15:04:11+00:00,https://twitter.com/rasbt/status/1588547665683677184,"@atheeralattar @IsaacAfedzi3 Personally, I started with TF in 2015 (I also used it in previous editions of my book). 
After adopting PyTorch in ~2018 I use it exclusively now. 
Hard to say if I would recommend TF these days. I think I would probably skip it. Most moved on to PyTorch: https://t.co/DcWadBnYtB https://t.co/iSg751OQbX"
2203,@rasbt,2022-11-04 14:51:37+00:00,https://twitter.com/rasbt/status/1588544501106155521,"@LandupDavid @svpino Thanks for sharing! Actually, I used that exact one as an example in my deep learning class at UW-Madison when discussing this topic ^^. 
Tbh there are arguments on both sides, pro and con. Based on my experiments, sometimes one is better than the other. It's inconclusive imho"
2204,@rasbt,2022-11-04 13:56:50+00:00,https://twitter.com/rasbt/status/1588530713829478403,@ChristophMolnar Maybe turn it into a symbiotic relationship by writing about big language models üòÜ
2205,@rasbt,2022-11-04 13:51:53+00:00,https://twitter.com/rasbt/status/1588529467257163778,"@PLMarquet If I had infinite time, sure I'd learn Julia. It's just not high on my priority list because Python is currently not a limitation (quite the opposite) for me."
2206,@rasbt,2022-11-04 13:50:31+00:00,https://twitter.com/rasbt/status/1588529124188225541,"@PLMarquet From a personal perspective, I do think that Julia as a language is appealing. However, there is currently no downside using Python for my deep learning research projects. The Python compute overhead is just 10%, but you gain lots of flexibility and convenience."
2207,@rasbt,2022-11-04 13:49:25+00:00,https://twitter.com/rasbt/status/1588528848919941122,"@PLMarquet 2/2 Hey @paperswithcode, if you ever have the time &amp; capacity, it would be interesting to see how much of the ""Other languages and libraries"" portion comes from Julia (Flux?). Genuinely curious üòä"
2208,@rasbt,2022-11-04 13:47:14+00:00,https://twitter.com/rasbt/status/1588528297805479937,"@PLMarquet Fair! It looks like a lot of pharma companies picked it up, which is nice. I would say they are upgrading their statistical computing &amp; ML from R to Julia. For deep learning, that's a different story: https://t.co/DcWadBnYtB 1/2"
2209,@rasbt,2022-11-04 12:57:15+00:00,https://twitter.com/rasbt/status/1588515721558265856,"@michaelaye @PLMarquet 2/2 I was on a committee of a PhD student who used Julia for a DL research project. It was very painful, and the student really regretted it. Julia as a language is fine, nice even. But yeah, don't use it for your deep learning research üòÖ"
2210,@rasbt,2022-11-04 12:55:29+00:00,https://twitter.com/rasbt/status/1588515273426206721,"@michaelaye @PLMarquet I haven't checked the general user growth, but I said that from a personal perspective because I am more into machine learning deep learning than statistical simulations these days. 1/2"
2211,@rasbt,2022-11-04 12:53:40+00:00,https://twitter.com/rasbt/status/1588514817324724225,"@Tdy1817 For now (until I have more exciting stuff coming later this year) I have 

- a general book on deep learning  (https://t.co/oFLrItB1st)
- and a course on deep learning (https://t.co/8FhMfLo5Vl)

 in case that's useful! üòä"
2212,@rasbt,2022-11-04 12:17:14+00:00,https://twitter.com/rasbt/status/1588505650354872322,"@PLMarquet In other words, I don't think Julia can (or should) replace Python. I think its target audience, at this point, are R users who want more performance in statistical simulations"
2213,@rasbt,2022-11-04 12:15:47+00:00,https://twitter.com/rasbt/status/1588505283365830657,"@PLMarquet Julia is cool, but I don't think it's going anywhere. I think this ship has sailed. Also, I am too deeply into deep learning and Julia is really lacking in that regard. It's a great language for statistics though. Lots of people in my department love it!

https://t.co/tqbXcGPM2l"
2214,@rasbt,2022-11-04 11:39:50+00:00,https://twitter.com/rasbt/status/1588496238965821442,"@Parisa__Rashidi Yes, agreed! In addition, it's also a good idea to annotate your data wrt to when it was collected. It will be useful for experiments to analyze (and detect) concept drift later on"
2215,@rasbt,2022-11-04 11:34:04+00:00,https://twitter.com/rasbt/status/1588494786163376128,"[4/4] On the other hand, storing data, if possible, is still a good idea because the model might suffer from ""bad"" updates in stateful training, and (temporarily) switching to stateless retraining might make sense then."
2216,@rasbt,2022-11-04 11:34:03+00:00,https://twitter.com/rasbt/status/1588494783655268352,"[3/4] One paradigm is not universally better than the other. However, an advantage of stateful training is that it doesn't require permanent data storage."
2217,@rasbt,2022-11-04 11:34:03+00:00,https://twitter.com/rasbt/status/1588494781017034752,"[2/4] In stateful training, we train the model on an initial batch of data and then update it periodically (as opposed to retraining it) when new data arrives."
2218,@rasbt,2022-11-04 11:34:02+00:00,https://twitter.com/rasbt/status/1588494777829294080,"What is the difference between stateless and stateful training? And when to use which?
[1/4] üß∂

PS: Will be working on the Ahead of AI Issue #2 (https://t.co/TmndH1sMXN) this weekend with more educational nuggets! Stay tuned for the release on Monday! https://t.co/O1AweP6ZVx"
2219,@rasbt,2022-11-04 02:19:12+00:00,https://twitter.com/rasbt/status/1588355149348888578,"@benny856694 If I had to pick between one concept to bring on a lonely island, I would definitely pick programming over math myself üòÜ. 
However, math concepts are also quite important for advancing in machine learning. Anyways, don't worry, I'll share sth for everyone."
2220,@rasbt,2022-11-03 23:44:31+00:00,https://twitter.com/rasbt/status/1588316221631782914,"@iamtrask @BelmontUniv Haha, well it was less romantic than it may sound like. We had to implement them with pen &amp; paper in the final exam üò£"
2221,@rasbt,2022-11-03 23:42:12+00:00,https://twitter.com/rasbt/status/1588315639881420800,"@UttamTarasariya hah, that's a high bar, but the challenge is on! üôå"
2222,@rasbt,2022-11-03 20:06:07+00:00,https://twitter.com/rasbt/status/1588261259912581120,"@madzadev hah, that's a trick question because one was used to implement the other üòÜ"
2223,@rasbt,2022-11-03 18:42:08+00:00,https://twitter.com/rasbt/status/1588240126706343936,"@SubhamEng I am flattered that you asked, but at the moment, I am not accepting new research students. Thanks for offering though, I appreciate it!"
2224,@rasbt,2022-11-03 18:41:01+00:00,https://twitter.com/rasbt/status/1588239844462977029,@_jonathan_codes Thanks! You won't be disappointed :)
2225,@rasbt,2022-11-03 18:27:03+00:00,https://twitter.com/rasbt/status/1588236328554188800,@iamtrask @BelmontUniv Happy anniversary!! Btw what was your first architecture? My machine learning journey started with Bayesian Nets (took a Statistical Pattern Rec class back then) before I went neural!
2226,@rasbt,2022-11-03 18:05:52+00:00,https://twitter.com/rasbt/status/1588230999510392834,@akshay_pachaar Thanks for the support @akshay_pachaar ü´∂
2227,@rasbt,2022-11-03 16:37:15+00:00,https://twitter.com/rasbt/status/1588208696374476800,@nevrekaraishwa2 Hi there! üôå
2228,@rasbt,2022-11-03 16:08:30+00:00,https://twitter.com/rasbt/status/1588201461653114880,"@rychinex hah, no worries, I have no intention to use it. Checked it out last year and it was not for me; I am more comfortable in PyTorch and it does everything I need"
2229,@rasbt,2022-11-03 15:11:58+00:00,https://twitter.com/rasbt/status/1588187235413037056,"@OceanYumnam @stat110 Sure! And keep machine learning while you are learning -- that's how you stay motivated. Really, get started with machine learning and if certain things don't make sense, yet, be patient ... via the foundational studies, you will fill in those blanks over time."
2230,@rasbt,2022-11-03 15:00:14+00:00,https://twitter.com/rasbt/status/1588184281289195521,"@naivebayesian No, I meant to imply that it's a balance stick, balancing statistics, computer science, and domain expertise üòù"
2231,@rasbt,2022-11-03 14:56:03+00:00,https://twitter.com/rasbt/status/1588183228917370880,"@OceanYumnam For calculus, check out Robert Ghrist's courses on Coursera: https://t.co/ANe7P5ApYj

For probability, check out @stat110's class: https://t.co/CnehK2uiXv

Most importantly: be patient. It'll take time (maybe years) to build a solid foundation. There's no shortcut"
2232,@rasbt,2022-11-03 14:49:06+00:00,https://twitter.com/rasbt/status/1588181479229571072,"@OceanYumnam Personally, I recommend with introductory data science and machine learning courses &amp; learn the math later (and alongside). Tbh the best way to learn math is to take dedicated courses (like Gilbert Strang's intro to Linear Algebra) vs reading ""math for machine learning"" shortcuts"
2233,@rasbt,2022-11-03 14:41:12+00:00,https://twitter.com/rasbt/status/1588179493637672962,"Hi üëã if you are STILL interested in:

‚öôÔ∏è Machine Learning
üî¨ Artificial Intelligence Research
üêç Python &amp; Open Source
ü™Ñ Data Science

Follow me. ‚úî

I'm STILL planning on using Twitter to share a lot of content that you won't want to miss. üéâ"
2234,@rasbt,2022-11-03 14:40:48+00:00,https://twitter.com/rasbt/status/1588179390206468096,"@ItaDude No, I don't have any plans to move to mastodon atm. 
Should twitter go away (which it probably won't), I'll use my newly earned focus time to write more books üòÜ"
2235,@rasbt,2022-11-03 14:22:39+00:00,https://twitter.com/rasbt/status/1588174821657026562,"@ZarTaCH_0x @elonmusk Ah yes, good catch! 
0, z &lt; theta  and
1,  z &gt;= theta 
would have been the version to match the figure. 

(Haha, machine learning people probably won't notice because z == theta is unlikely in practice due to floating point calc)"
2236,@rasbt,2022-11-03 13:39:25+00:00,https://twitter.com/rasbt/status/1588163943645708291,"@tunguz haha, basically the grown-up version of ""Parents Aren't Home"""
2237,@rasbt,2022-11-03 13:36:56+00:00,https://twitter.com/rasbt/status/1588163318593847297,"@elonmusk If you hear it echoing 
""Stay focused! Stay Focused!""
then you know it has become (self-)conscious!"
2238,@rasbt,2022-11-03 13:35:32+00:00,https://twitter.com/rasbt/status/1588162964892393480,"@sarah_edo @pythiccoder @SheCodeAfrica Looks awesome, congrats!! Will be getting a copy! Btw the cover is just üòç!"
2239,@rasbt,2022-11-03 13:06:10+00:00,https://twitter.com/rasbt/status/1588155576084750336,"@fchollet Same. No intends to leave ... but if it leaves us, where does it leave us? If push comes to shove, the silver lining  is that if Twitter won't be as active as it once was, I'll have two new books published by 2024 üòÜ"
2240,@rasbt,2022-11-03 13:00:51+00:00,https://twitter.com/rasbt/status/1588154236277227526,@elonmusk What do neurons and some people have in common? They either fire (someone) or not! https://t.co/sa5mM0JFyy
2241,@rasbt,2022-11-03 12:55:13+00:00,https://twitter.com/rasbt/status/1588152819609206786,Best intro to JAX so far!
2242,@rasbt,2022-11-03 12:52:54+00:00,https://twitter.com/rasbt/status/1588152236127002630,"@merseykilling @tunguz @PCacioppi Yeah, the terminology can be super weird until you've built that muscle memory. 
Take ""git checkout"" for example. Git even introduced ""git switch"" to make that sound a bit more intuitive &amp; natural. 
(But thx to the aforementioned muscle memory, I'm still a ""checkout"" kind of guy)"
2243,@rasbt,2022-11-03 01:23:55+00:00,https://twitter.com/rasbt/status/1587978849765265410,@karpathy @matttalbert @lexfridman @Tesla @elonmusk adding one more labeled training example to the set ... üòÜ
2244,@rasbt,2022-11-03 01:20:40+00:00,https://twitter.com/rasbt/status/1587978030508539905,"@bernhardsson {==, ===, eql?, equal?} in Ruby. Choose your own adventure!"
2245,@rasbt,2022-11-03 01:17:06+00:00,https://twitter.com/rasbt/status/1587977133279903744,@jmschreiber91 also applies to supermarkets
2246,@rasbt,2022-11-03 01:15:13+00:00,https://twitter.com/rasbt/status/1587976658744664064,@tunguz @kaggle plot twist: the leaderboard is showing the accuracy in percent
2247,@rasbt,2022-11-02 22:25:58+00:00,https://twitter.com/rasbt/status/1587934065482948610,"@lies_and_stats @tunguz @PCacioppi I heard Mercurial is quite intuitive. But given that 99% of the open source world uses Git, I would stick with it"
2248,@rasbt,2022-11-02 21:52:47+00:00,https://twitter.com/rasbt/status/1587925717676851203,@PyTorch @soumithchintala @ibrahimatlinux Less than month away! Looking forward to it! ü´∂
2249,@rasbt,2022-11-02 21:49:00+00:00,https://twitter.com/rasbt/status/1587924762319372288,"Ok last one (for now):
4 Finetuning II -- Update all weights. 

Code: https://t.co/ruijZ04wwD

Takes 50 min on a 1080Ti, but you can cut that significantly using multiple GPUs (e.g., 15 min if you have 4 x 1080Tis and set strategy=""ddp"") https://t.co/VkMn7fTVU3"
2250,@rasbt,2022-11-02 21:43:44+00:00,https://twitter.com/rasbt/status/1587923438408269828,@tunguz @PCacioppi I had the luxury that a member on my PhD committee back in 2011 said: I will only join your committee if you use version control. Everything else is history haha
2251,@rasbt,2022-11-02 21:41:21+00:00,https://twitter.com/rasbt/status/1587922837058166784,"""continued pretraining that incorporates a trainable prompt during multi-task learning, leads to improved promptability in both zero- and few-shot settings compared to existing methods, up to 31%"""
2252,@rasbt,2022-11-02 21:39:52+00:00,https://twitter.com/rasbt/status/1587922465417666561,"@DrGroftehauge @zhaofeng_wu @sameer_ hah yes, thanks, need to check that out!"
2253,@rasbt,2022-11-02 18:17:34+00:00,https://twitter.com/rasbt/status/1587871554519670785,"@PCacioppi @tunguz Fair. I meant more like that people got worried that Microsoft would ruin GitHub when they bought it in 2018. Btw I don't know any major open source library that is hosted on GitLab (at least in the Python, scientific computing, deep learning communities)"
2254,@rasbt,2022-11-02 18:13:57+00:00,https://twitter.com/rasbt/status/1587870644192133121,"@m_saharia @AcademicChatter Ah sorry, that was maybe unclear.

LastName is the last name of the first author, not the last name of the last author. I don't think there is a citation style that uses ""LastNameOfLastAuthor Year"""
2255,@rasbt,2022-11-02 18:09:45+00:00,https://twitter.com/rasbt/status/1587869588062093312,@jwvdm thanks!
2256,@rasbt,2022-11-02 18:07:16+00:00,https://twitter.com/rasbt/status/1587868961823145984,"@tunguz or, remember moving to GitLab?"
2257,@rasbt,2022-11-02 17:39:06+00:00,https://twitter.com/rasbt/status/1587861872362995713,@math_dandy @mmitchell_ai the only thing I know about it is that it has different instances / runs on different servers (kind of like World of Warcraft 15 years ago). It's probably not blockchain based.
2258,@rasbt,2022-11-02 17:32:12+00:00,https://twitter.com/rasbt/status/1587860138261626883,"@math_dandy @mmitchell_ai To be honest, I have no idea. I googled it but no clue if that's correct. https://t.co/uDKZPnUFRI"
2259,@rasbt,2022-11-02 17:29:59+00:00,https://twitter.com/rasbt/status/1587859578338828288,"@jwvdm Thanks for explaining! So when I understand correctly, an instance is a physical server someone maintains? Say you created an account on that instance and the maintainer shuts down the server next year. Can you then just move to a different instance, or is this not necessary?"
2260,@rasbt,2022-11-02 17:26:26+00:00,https://twitter.com/rasbt/status/1587858686936059904,"@Grady_Booch not bad, in contrast to the iPad it even has a calculator app!"
2261,@rasbt,2022-11-02 17:22:44+00:00,https://twitter.com/rasbt/status/1587857754999455746,"@mmitchell_ai Haha, same üòÜ. You lost me at blockchain ... üòÖ"
2262,@rasbt,2022-11-02 17:18:48+00:00,https://twitter.com/rasbt/status/1587856764959170560,"@svpino Yup, in contrast to newspapers like Washington Post or Wall Street journal you can actually read all the content without a subscription üòÜ"
2263,@rasbt,2022-11-02 17:15:46+00:00,https://twitter.com/rasbt/status/1587856002149675016,"@tunguz @svpino yup, evidence that twitter is still working ^^"
2264,@rasbt,2022-11-02 17:13:03+00:00,https://twitter.com/rasbt/status/1587855319597711360,@jae_w0o Whoa thanks üòä
2265,@rasbt,2022-11-02 16:46:47+00:00,https://twitter.com/rasbt/status/1587848707818590208,@Tiago_Data Very good question! There is currently no next edition in the works or planned. So this is a good time as any!
2266,@rasbt,2022-11-02 15:36:30+00:00,https://twitter.com/rasbt/status/1587831022049173511,@Ukerzel @Michael_J_Black @CSProfKGD but the problem is that it will still be misleading to members of other communities reading the paper
2267,@rasbt,2022-11-02 14:14:09+00:00,https://twitter.com/rasbt/status/1587810297779294209,"Flattered to learn this morning that my book is part of the ‚ú®Best Seller‚ú® sale until next week üòä (i.e., 33% off on Amazon) 
https://t.co/INNwcatbcX https://t.co/I0DdpUHE8j"
2268,@rasbt,2022-11-02 14:01:50+00:00,https://twitter.com/rasbt/status/1587807198691868672,"@mrclbschff good points. I did zero tuning here actually, and you can certainly get better results if you try harder. I just kept everything constant across the experiments to only change one thing at a time (and for baseline purposes)"
2269,@rasbt,2022-11-02 13:54:42+00:00,https://twitter.com/rasbt/status/1587805401390645249,"@ylecun Great work. Particularly the scale and speed are pretty impressive!
Btw do you know if ESMFold participated in CASP15 so that we can get a somewhat unbiased idea of its modeling performance compared to other approaches?"
2270,@rasbt,2022-11-02 13:45:08+00:00,https://twitter.com/rasbt/status/1587802993256284163,"1) Arxiv (and other platforms) should randomize author order upon page reload.

2) Instead of citing ""LastName et al. 2022"" let's cite as ""ShortTitle 2022""

Problem(s) solved!"
2271,@rasbt,2022-11-02 13:43:11+00:00,https://twitter.com/rasbt/status/1587802501713219584,"@WaltonStevenj @RuskEating @Michael_J_Black @CSProfKGD To be honest, when I write the first draft of something, I use this scheme internally for myself to keep track, haha"
2272,@rasbt,2022-11-02 13:42:27+00:00,https://twitter.com/rasbt/status/1587802317281181697,@Ukerzel @Michael_J_Black @CSProfKGD But this is not universal across fields and a decent chunk of people will essentially think you never did much work if your name starts with M as in Middle
2273,@rasbt,2022-11-02 13:40:27+00:00,https://twitter.com/rasbt/status/1587801816603000833,"@mrclbschff I unfreeze from the start, but yeah, I experimented with different schemes and you can actually get better results if you alternate the unfreezing between epochs. Was just keeping it simple here as a baseline"
2274,@rasbt,2022-11-02 13:39:15+00:00,https://twitter.com/rasbt/status/1587801514759929857,"@DrGroftehauge Sure, your mileage may vary. Unfreezing the last layer is worse than unfreezing the last two layers here. And yes, I remember that statement (was it the original BERT paper?). You can certainly try to unfreeze more. In practice, I find finetuning everything is usually better"
2275,@rasbt,2022-11-02 13:37:12+00:00,https://twitter.com/rasbt/status/1587800998545850370,"@Tinker_1081 The last 2 layers, actually. When I only unfroze the last layer, I only got 76% accuracy. Unfreezing the last two was much better (83%)"
2276,@rasbt,2022-11-02 00:06:38+00:00,https://twitter.com/rasbt/status/1587597013658394624,"Bitter lesson: computation time definitely correlates w. ACC here

2 Feature-based: 9 min, 83% acc
3 Finetuning I (last 2 layers): 20 min, 87% acc
4 Finetuning II (whole): 49 min, 93% acc

(Your mileage may vary based on the dataset; used DistilBERT + IMDB in the codes I shared)"
2277,@rasbt,2022-11-01 22:50:43+00:00,https://twitter.com/rasbt/status/1587577907366531072,"@RuskEating @Michael_J_Black @CSProfKGD Totally agree! Author name could be replaced by a paper short-title; that would also make it more informative. E.g., instead of ""XYZ et al. 2022"" write""Fewshot-video 2022"" or sth like that (where the paper is a few-shot learning method for video data)"
2278,@rasbt,2022-11-01 20:19:46+00:00,https://twitter.com/rasbt/status/1587539917785137153,@Earth2Ceres @elonmusk works!
2279,@rasbt,2022-11-01 20:15:05+00:00,https://twitter.com/rasbt/status/1587538739080871938,"@Michael_J_Black @CSProfKGD Good thread! Btw after all these years, I still find it baffling that something seemingly innocent such as authorship order can ruin good collaborations and friendships. 
We need a randomization feature on arxiv that scrambles the authorship order each time we refresh the page!"
2280,@rasbt,2022-11-01 20:08:43+00:00,https://twitter.com/rasbt/status/1587537138958172161,"@lmoroney Same boat. Anyways, I think it will be less of a status symbol and more of a spam filter then. Won't mind it."
2281,@rasbt,2022-11-01 20:07:02+00:00,https://twitter.com/rasbt/status/1587536713718669315,The feature-based approach for reference: https://t.co/qCzHNPOxs1
2282,@rasbt,2022-11-01 20:06:21+00:00,https://twitter.com/rasbt/status/1587536543018885124,"@elonmusk The tricky edge case where things might break:
1. someone pays for verification
2. gets the blue checkmark
3. and then changes their name to impersonate President XYZ

Hotfix: Don't allow name changes after verification? But that brings other issues ... Tricky!"
2283,@rasbt,2022-11-01 19:58:53+00:00,https://twitter.com/rasbt/status/1587534664851279873,"Last time, I showed you how to train a scikit-learn model on language transformer embeddings (aka the feature-based approach where we got 83% acc)

üöÄ On to method ""3 Finetuning I -- tuning output layers!"" Bam, 83% -&gt; 87%!
https://t.co/rlPMmEcRcy

(stay tuned for appr 4 tomorrow) https://t.co/FTQy3GFejQ"
2284,@rasbt,2022-11-01 15:52:04+00:00,https://twitter.com/rasbt/status/1587472548404633600,@alexrives nice! that looks exciting! looking forward to reading about it in more detail!!
2285,@rasbt,2022-11-01 13:07:04+00:00,https://twitter.com/rasbt/status/1587431028465012736,"#NeurIPS2022  is now &lt; 1 month away! Who's going? Looking forward to meet &amp; chat!

PS: @RobertLaurella &amp; I will be organizing a social: 
üéì""Industry, Academia, and the In-Betweens""üéß

Stop by and say hello üòä. Lots of stuff to talk about! (Details here: https://t.co/NFjn55UEZD) https://t.co/msr8EHdl2u"
2286,@rasbt,2022-11-01 12:57:13+00:00,https://twitter.com/rasbt/status/1587428549207724033,@Kaszanas @dendronhq Looks cool! Reminds me a bit of https://t.co/3zZWHAo6tw which some people recommended in the past!
2287,@rasbt,2022-11-01 12:55:48+00:00,https://twitter.com/rasbt/status/1587428192062787584,@akshay_pachaar Glad to hear!
2288,@rasbt,2022-11-01 12:55:04+00:00,https://twitter.com/rasbt/status/1587428007819595779,"@rpicatoste That's a good question. I am still in my mid-30's, so we will see ...üòÖ
This is different for everyone, but personally, I made a few lifestyle choices earlier this year that helped me getting back the same energy (+more) that I had as a student. We will see how long it lasts ^^"
2289,@rasbt,2022-11-01 01:48:28+00:00,https://twitter.com/rasbt/status/1587260250800930818,"@AlbertoAndreott haha, that's how my brain works. I like to organize things 

(PS: it's maybe also related to the fact that I studied biology during my undergrad üòÜ)"
2290,@rasbt,2022-11-01 01:41:50+00:00,https://twitter.com/rasbt/status/1587258583875571712,"@short_spy It's based on this basic principle afaik, but I am not sure how exactly it's implemented and whether it's 2x2"
2291,@rasbt,2022-11-01 01:40:10+00:00,https://twitter.com/rasbt/status/1587258160766717953,@prabhat933 wow thanks so much for the compliment and support üòä
2292,@rasbt,2022-11-01 01:39:54+00:00,https://twitter.com/rasbt/status/1587258094219837440,"@ChristophSchll3 @svpino There's a wide range of handwritten code. Think of Squarespace making webdevelopers obsolete. Or in other words, it may write better code than novices; it may not make experts obsolete though."
2293,@rasbt,2022-11-01 01:38:13+00:00,https://twitter.com/rasbt/status/1587257672197349378,"@AlbertoAndreott @svpino In either one, non-determinism can be an issue for sure. But for the 2nd one, yeah, humans also suffer from non-determinism (some people write better code then others; everyone can have a bad day sometimes, etc.)"
2294,@rasbt,2022-11-01 01:36:55+00:00,https://twitter.com/rasbt/status/1587257346174205952,"@AlbertoAndreott @svpino 2/2 
(1) a neural network model takes the place of previously handwritten software (quite wasteful and distrastous for certain apps, like a calculator; quite good for others, like object detectors)
(2) the network just writes the code. But yeah, also comes with certain issues ..."
2295,@rasbt,2022-11-01 01:34:30+00:00,https://twitter.com/rasbt/status/1587256735869329409,"@AlbertoAndreott @svpino üíØ. However, after my initial post (where I was thinking of something similar re calculator), I realized that ""Neural networks will eventually replace most code written by humans."" can come in two flavors, and I think @svpino meant the 2nd one ... 1/2"
2296,@rasbt,2022-11-01 01:32:52+00:00,https://twitter.com/rasbt/status/1587256326278750209,"@Kaszanas Wow, on GigaWord, it seems like the 2020 BART model (briefly discussed in my book chapter :P) is still SOTA  https://t.co/P1ZFTySX7r https://t.co/tnM7JkQbtW"
2297,@rasbt,2022-11-01 01:29:58+00:00,https://twitter.com/rasbt/status/1587255596402761730,@Kaszanas Haven't followed summarization too closely. I would maybe search for ROUGE benchmarks (ROUGE is the BLEU-equivalent for summarization)
2298,@rasbt,2022-10-31 15:19:09+00:00,https://twitter.com/rasbt/status/1587101879061839872,"@liuyao12 @svpino Yes, of course not! Maybe let's call it ""verified"" code haha"
2299,@rasbt,2022-10-31 15:18:54+00:00,https://twitter.com/rasbt/status/1587101815119794177,"@Vansh240103 @svpino hah, it's short for for ""think about calculators"""
2300,@rasbt,2022-10-31 14:04:59+00:00,https://twitter.com/rasbt/status/1587083212240654345,"@svpino Handwritten code will be an expensive luxury for critical applications where determinism matters. E.g., think calculators, banking &amp; payments, etc."
2301,@rasbt,2022-10-31 14:00:11+00:00,https://twitter.com/rasbt/status/1587082005426020352,"Since this was a frequently asked question, conceptually, tensor parallelism is implemented using block multiplication. Not sure what most people use, but there is https://t.co/zKH0SsTXcP for example (supports NumPy and PyTorch) https://t.co/6iWab4gqsl"
2302,@rasbt,2022-10-31 13:59:10+00:00,https://twitter.com/rasbt/status/1587081749615493121,@DrEliDavid Thanks @DrEliDavid üôå
2303,@rasbt,2022-10-31 13:44:11+00:00,https://twitter.com/rasbt/status/1587077980701999104,"Ahh, I know it's Halloween, but sorry that I scared some with this tweet, I definitely didn't mean to üôà! 
Was just a way of celebrating my 10-year twitterversary ü§ó
(and saying that I won't be switching to mastodon üôÉ) https://t.co/spL5tJVRNI"
2304,@rasbt,2022-10-31 13:24:18+00:00,https://twitter.com/rasbt/status/1587072977430093824,"@gordic_aleksa @karpathy Don't like the content? I thought that that's what the ""unfollow"" and ""mute"" buttons are for. But oh well, moving on ..."
2305,@rasbt,2022-10-31 13:17:22+00:00,https://twitter.com/rasbt/status/1587071230129147907,"@fchollet Imho, you can just use lists and follow the right people to filter for worthwhile content. 
Using lists, you can certainly build your own adventure, assuming (1) that you curate the list and (2) people on the list curate the content they (re)share"
2306,@rasbt,2022-10-31 13:05:20+00:00,https://twitter.com/rasbt/status/1587068204249145346,@V_J_S_1 thanks so much! I'll keep it coming üòä
2307,@rasbt,2022-10-31 13:04:48+00:00,https://twitter.com/rasbt/status/1587068068542521344,@nmvrodrigues Thanks! Glad to hear this!
2308,@rasbt,2022-10-31 13:03:58+00:00,https://twitter.com/rasbt/status/1587067859544449024,"@sudotimar @mrclbschff @karpathy yeah, exactly. I only consider blocking people if they actively harass me in some way. I mean everyone can use twitter however they like, but blocking people without cause has a bit of a gate-keeping quality to it."
2309,@rasbt,2022-10-31 13:01:47+00:00,https://twitter.com/rasbt/status/1587067309247676417,@subratac @uneetarjun @karpathy @JFPuget thanks for the encouraging words üòä
2310,@rasbt,2022-10-31 12:59:16+00:00,https://twitter.com/rasbt/status/1587066677350604800,@_krr12 It's basically a clone -- relatively similar functionality -- except that you have to choose a particular server for your account (which may or may not go away in the future). It's basically a more siloed approach. Does not really appeal to me atm and have no plans using it.
2311,@rasbt,2022-10-31 12:57:32+00:00,https://twitter.com/rasbt/status/1587066238391521281,"@el_ahmadyy @guysnovelutumba @v3n0m92 @rabbit ""Machine Learning with PyTorch and Scikit-Learn"" üòä https://t.co/dZzvgR9VIm"
2312,@rasbt,2022-10-31 12:55:44+00:00,https://twitter.com/rasbt/status/1587065788846018562,"@ZhenHao35473118 @michaeljanich yes, this."
2313,@rasbt,2022-10-30 18:07:24+00:00,https://twitter.com/rasbt/status/1586781832372277250,"@gmonce Yeah, I often add an adaline (adaptive linear neuron) 

Perceptron: classifier with threshold
Linear reg: can learn weights with SGD
Adaline: like linear reg but with threshold
Logistic regr: like adaline but with sigmoid activation
MLP: multiple log reg/sigmoid nets"
2314,@rasbt,2022-10-30 17:18:08+00:00,https://twitter.com/rasbt/status/1586769435179769858,"@mluebbecke Everything in moderation, of course, but I don't think that ditching watching TV and reading a book/studying instead is inherently unhealthy"
2315,@rasbt,2022-10-30 17:16:31+00:00,https://twitter.com/rasbt/status/1586769026180698116,"@KountayDwivedi I would say: use it at your own risk. According to various papers (https://t.co/VAXJRBMyzj), it works well, but it is more finicky and resource hungry. I would definitely only consider it if you find conventional methods too boring üòä"
2316,@rasbt,2022-10-30 17:15:01+00:00,https://twitter.com/rasbt/status/1586768651251761152,"@tulkenss That is a good point, I have not bechmarked this tbh! It's highly hardware dependent. On capable hardware, I'd say the LLM is definitely faster since it can more easily be parallelized and does not have the sequential-processing bottleneck."
2317,@rasbt,2022-10-30 16:55:15+00:00,https://twitter.com/rasbt/status/1586763676585000966,"@tymwol It's maybe the most intuitive one since that's what most people learn in colleges at first. But yeah, I can kind of see that."
2318,@rasbt,2022-10-30 16:50:27+00:00,https://twitter.com/rasbt/status/1586762466259877891,where linear regression = single layer neural network. https://t.co/29BrrqnDLv
2319,@rasbt,2022-10-30 16:47:40+00:00,https://twitter.com/rasbt/status/1586761766150848514,"@GermanicusCM üíØ! Since I teach in the stats department, linear regression is also a nice entry point for explaining (single layer) neural networks."
2320,@rasbt,2022-10-30 16:46:20+00:00,https://twitter.com/rasbt/status/1586761430866460675,"When teaching ML to a stats audience, linear regression is a nice entry point for neural nets:
In my mlxtend impl, u can toggle between the different ways for getting the weight params (coefficients):
- closed-form solution
- SGD
- QR decomposition
- SVD
https://t.co/bcaql70R67"
2321,@rasbt,2022-10-30 15:56:10+00:00,https://twitter.com/rasbt/status/1586748807932481548,"@ducha_aiki @thinkndcode @DSaience Same. Fun fact: I used GitLab in ~2011 before I created my GitHub account in ~2012. (We had a GitLab server at MSU, and as a student and private repos where free)"
2322,@rasbt,2022-10-30 15:30:39+00:00,https://twitter.com/rasbt/status/1586742384595210240,"@jfischoff Have not made an Instagram or TikTok account, so I can't confirm"
2323,@rasbt,2022-10-30 15:28:19+00:00,https://twitter.com/rasbt/status/1586741795840528392,@arronlacey Chicken-egg problem. Python is where the Deep Learning communities and libraries are.
2324,@rasbt,2022-10-30 15:24:08+00:00,https://twitter.com/rasbt/status/1586740743347081219,@thinkndcode @DSaience I am old enough to remember when everyone talked about quitting GitHub (and move to GitLab) when Microsoft took over
2325,@rasbt,2022-10-30 15:21:31+00:00,https://twitter.com/rasbt/status/1586740088507170818,"@TylerJBurch @roydanroy I can imagine that there will be a downscaling for sure with less and less in-person components. Sadly, governments already pay teachers a minimum wage, and I can see them cutting costs even further by cutting more staff etc"
2326,@rasbt,2022-10-30 15:08:54+00:00,https://twitter.com/rasbt/status/1586736910243864576,"@TylerJBurch @roydanroy ""Things require physical presence are the easiest answer:"" &amp; ""teaching""? I wouldn't bet on that"
2327,@rasbt,2022-10-30 15:08:51+00:00,https://twitter.com/rasbt/status/1586736900697620481,@roydanroy CEO
2328,@rasbt,2022-10-30 14:56:34+00:00,https://twitter.com/rasbt/status/1586733808459694083,"@DSaience haha thanks, and no worries, I am not planning to go anywhere (briefly checked out mastodon, but yeah, no worries; here's where the fun is at)"
2329,@rasbt,2022-10-30 14:38:10+00:00,https://twitter.com/rasbt/status/1586729175485915137,"@danofer Outpeforming roberta is pretty nice though. When I finetuned Roberta, the results were usually similar to DistilBERT +/- 2% accuracy"
2330,@rasbt,2022-10-30 14:30:14+00:00,https://twitter.com/rasbt/status/1586727179873812483,"@tunguz @karpathy I‚Äôve heard ""We're all researchers here"" used to express that we should be able to handle some crazy things because we have an open mind üôÉ"
2331,@rasbt,2022-10-30 14:30:02+00:00,https://twitter.com/rasbt/status/1586727128766320641,"@danofer Haven't looked into it. For me, it's the predictive performance / small memory footprint that I like about DistilBERT. Haven't compared it to miniLM. The latter may be lighter, but what's its predictive performance? DistilBERT gets like 95% acc on the IMDB dataset for example"
2332,@rasbt,2022-10-30 14:10:12+00:00,https://twitter.com/rasbt/status/1586722139280998405,"@uneetarjun @karpathy Thanks, that's quite a dilemma now ... super interested in Andrej Karpathy's content, but at the same time, I think I'll stick to @JFPuget's rule this time
https://t.co/NJChS97xhW"
2333,@rasbt,2022-10-30 14:02:29+00:00,https://twitter.com/rasbt/status/1586720195648884737,"@karpathy Sadly, I can't view it ... Hah, did you have a chance to ask why he blocks so many machine learning / AI people? https://t.co/UBtZWQOkPg"
2334,@rasbt,2022-10-30 13:57:38+00:00,https://twitter.com/rasbt/status/1586718976864059392,"@danofer Oh, it was so that I can then directly compare it to the fine-tuned DistilBERT (which I prefer due to my small GPU memory)"
2335,@rasbt,2022-10-30 13:56:13+00:00,https://twitter.com/rasbt/status/1586718621585260545,@SaiNikhileshRdy Thanks! This is very motivating to hear!
2336,@rasbt,2022-10-30 13:55:56+00:00,https://twitter.com/rasbt/status/1586718549845893123,@nishparadox Thanks üôå
2337,@rasbt,2022-10-30 13:43:30+00:00,https://twitter.com/rasbt/status/1586715419838226440,@roydanroy @aryehazan the quality of something is relative to its quantity
2338,@rasbt,2022-10-30 13:17:01+00:00,https://twitter.com/rasbt/status/1586708755323838464,"Just wanted to say a big THANK YOU to the amazing twitter ML community here! ‚ù§Ô∏è
Appreciate all the positive interactions on ML and open source!

We exchanged so much material over the years &amp; I learned a lot. I hope you did too!
No worries, not leaving. Just wanted to say thanks!"
2339,@rasbt,2022-10-29 16:53:31+00:00,https://twitter.com/rasbt/status/1586400849864974336,"@viajesubmarino ... but there will be more and more programs that offer you some structure, check-ins, and accountability to self-study topics in the future."
2340,@rasbt,2022-10-29 16:52:46+00:00,https://twitter.com/rasbt/status/1586400664149970944,@viajesubmarino There might also be a move towards guided self-studies. There are lots of awesome books (and digital courses) out there that are better and deeper than many university courses. Problem is that self-study requires more discipline ...
2341,@rasbt,2022-10-29 16:51:05+00:00,https://twitter.com/rasbt/status/1586400238713053184,@viajesubmarino They will probably keep existing. At least the bigger ones. I can see that there will be some (unvoluntary) consolidation though. Smaller colleges may not be able to compete with the higher-quality offerings of the bigger ones &amp; the internet
2342,@rasbt,2022-10-29 16:42:32+00:00,https://twitter.com/rasbt/status/1586398086795972608,**I hope you can forgive me that I skipped #1: training from scratch. I don't have that kind of budget üòÜ. And it's also not very productive üôÉ
2343,@rasbt,2022-10-29 16:37:37+00:00,https://twitter.com/rasbt/status/1586396849426124804,"Btw it's worth emphasizing that this approach already gets you 83% prediction accuracy, and it only takes &lt; 5 minutes! (Training an RNN from scratch gives you about the same performance but it is much more work!)"
2344,@rasbt,2022-10-29 16:30:05+00:00,https://twitter.com/rasbt/status/1586394954699448320,"Let's illustrate LLM training with a few hands-on examples! 

We'll start with the *Feature-based approach*: Training an sklearn random forest on the transformer embeddings -- a great baseline:
https://t.co/8ARAQVAviA

Tomorrow, we'll beat the baseline by finetuning in Lightning! https://t.co/1Yiawrb3N9"
2345,@rasbt,2022-10-29 16:09:24+00:00,https://twitter.com/rasbt/status/1586389750243643392,"@vboykis Oh yes, +1 on HTML, web stuff, and Rest APIs"
2346,@rasbt,2022-10-29 15:25:16+00:00,https://twitter.com/rasbt/status/1586378644338851840,"@iamsharmi_ sry, I never worked on fraud detection"
2347,@rasbt,2022-10-29 15:20:54+00:00,https://twitter.com/rasbt/status/1586377544156078080,"In 10 years, the world will be very different from today.

Once upon a time, it was okay to learn sth in school &amp; then apply it for the rest of your life. 

Today, to keep up and thrive with the rapid pace of change, it's pivotal to keep reinventing yourself and to keep learning."
2348,@rasbt,2022-10-29 14:44:00+00:00,https://twitter.com/rasbt/status/1586368256557740032,"@hardmaru As an academic and researcher, not having fully deterministic behavior was surely something I had to get used to at first. Over time, it's fine. The world is moving towards saving and reusing weights, so there is less need to rerun things."
2349,@rasbt,2022-10-29 14:41:31+00:00,https://twitter.com/rasbt/status/1586367631069782018,"@AllenDowney No worries, that's why they are called ""note""books. Notes are supposed to be messy."
2350,@rasbt,2022-10-29 14:37:09+00:00,https://twitter.com/rasbt/status/1586366532614963200,@iamsharmi_ Have worked on Graph neural nets with one of my former PhD students in the context of synthesizing organic molecules and also ligand discovery. It's an interesting subject for sure and pretty relevant in pharma right now
2351,@rasbt,2022-10-29 14:34:54+00:00,https://twitter.com/rasbt/status/1586365968871493633,@SaraBolouki A lot of research is focused on understanding how the human brain works / mimicking the human brain with neural networks / building neural networks that learn like humans. https://t.co/9qXJPKPZ1K
2352,@rasbt,2022-10-29 14:34:12+00:00,https://twitter.com/rasbt/status/1586365789405294593,@jrosell @predict_addict @FrankRHutter @tunguz @marktenenholtz @ph_singer I usually start with RFs as well. Requires no (/only little) tuning so it's a great baseline
2353,@rasbt,2022-10-29 14:32:25+00:00,https://twitter.com/rasbt/status/1586365342850469889,@MarkRyanMkm Ahhh how could I forget this. I am actually deep into this topic ... sometimes you can't see the forest for the trees (no pun intended)
2354,@rasbt,2022-10-29 14:31:24+00:00,https://twitter.com/rasbt/status/1586365087140392960,@leastsquared_ maybe should have said Ethics vs LLMs to be more clear :P
2355,@rasbt,2022-10-29 14:29:41+00:00,https://twitter.com/rasbt/status/1586364653046829058,"@cwizprod1 True! Imho it's a bit too hectic for me though. Not sure, but I lose the thread (no pun intended) because it kind of shows you everything, which is overwhelming when there are too many people on the server. Or maybe I am using it wrong, haha"
2356,@rasbt,2022-10-29 14:26:35+00:00,https://twitter.com/rasbt/status/1586363875926200325,"@shubham12et1062 hah, originally had TensorFlow in there, but I hit the 280 char limit so I had to shorten it to Keras"
2357,@rasbt,2022-10-29 12:45:01+00:00,https://twitter.com/rasbt/status/1586338314235219968,"One of the many ways to make models run faster is model compression. TIL that that there is a ""The Top 179 Model Compression Open Source Projects"" list! ü§Øhttps://t.co/S6zFaE238K"
2358,@rasbt,2022-10-28 23:27:09+00:00,https://twitter.com/rasbt/status/1586137523939516416,"@GharibiHadi Ah yes, Haiku vs Flax
I see what you did there üòè"
2359,@rasbt,2022-10-28 23:26:01+00:00,https://twitter.com/rasbt/status/1586137240270274560,"@ezkvishal üòÜ yes, how could I forget! 
Also 
Python vs R
Jupyter Notebook vs JupyterLab
Hugo vs Jekyll
PyCharm vs VSCode
Adam vs AdamW
ReLU vs GeLU
Frequentist vs Bayesian
..."
2360,@rasbt,2022-10-28 15:37:58+00:00,https://twitter.com/rasbt/status/1586019451438235649,"@unsorsodicorda @yaringal @tdietterich I looked into this a few months ago ... I don't get the appeal. You basically join someone's server and your account only works as long they keep it running? Why would I want to be restricted to someone's server? Nah, I am going to stay here. And if it burns down maybe LinkedIn"
2361,@rasbt,2022-10-28 15:30:18+00:00,https://twitter.com/rasbt/status/1586017519609196546,"@RahulBagal3002 hah, or let's just go back to machine learning üò∂"
2362,@rasbt,2022-10-28 15:28:04+00:00,https://twitter.com/rasbt/status/1586016957371142144,@DSaience A nearest-neighbor classifier with 12 parameters (the means and std devs to normalize the 6 input features üôÉ)
2363,@rasbt,2022-10-28 15:24:06+00:00,https://twitter.com/rasbt/status/1586015962524176384,"Instead of an AI Winter, it seems AI reached a Time Of Contempt:

- AI alignment vs building AI
- Academia vs industry
- Kaggle vs research
- Diffusion vs art
- Ethics vs NLP
- Keras vs PyTorch

Let's stay sane &amp; healthy and not get sucked into this mindset. No need to pick sides"
2364,@rasbt,2022-10-28 14:07:20+00:00,https://twitter.com/rasbt/status/1585996643446722562,"*ResNet-18 has 11.18 million params, not 11.18 params or course üòÖ"
2365,@rasbt,2022-10-28 14:01:22+00:00,https://twitter.com/rasbt/status/1585995140216532992,"@TommyTwoThumbs6 Haha yeah, that should be the tagline for every research paper published since 2015 or so."
2366,@rasbt,2022-10-28 13:57:00+00:00,https://twitter.com/rasbt/status/1585994040167649281,‚ÄúCoShNet: A Hybird Complex Valued Neural Network using Shearlets‚Äù (https://t.co/0aIUPkqhWu) ‚Äî a type of ConvNet with less than 50k params that beats ResNets-18 (11.18 params) and others! üò≥
2367,@rasbt,2022-10-28 12:59:16+00:00,https://twitter.com/rasbt/status/1585979513762369537,"@11Gunz I was more thinking before it becomes mainstream or a trend. E.g., there was a company that built everything around transformers ... and that worked even though there was already one or more papers on transformers. Doing that today would be quite the uphill battle though"
2368,@rasbt,2022-10-28 12:43:07+00:00,https://twitter.com/rasbt/status/1585975447560409088,"Especially true for AI: 
Don't follow the trend, otherwise you'll always be one step behind and probably feel bad about it.

Instead, either pick what 
1) is going to be the next trend (""Skate to where the puck is going to be..."")
2) you are most passionate about so you can excel"
2369,@rasbt,2022-10-28 12:42:32+00:00,https://twitter.com/rasbt/status/1585975302966181888,"@Sidsharmaa22 Hah, sorry, I can't answer that for you; you have to pick something that (also) matches your interests."
2370,@rasbt,2022-10-28 12:31:58+00:00,https://twitter.com/rasbt/status/1585972643874103296,"So true! 
(Collected lots of cool stuff for Ahead of AI #2, only one more week, stay tuned üé∂)"
2371,@rasbt,2022-10-28 12:14:15+00:00,https://twitter.com/rasbt/status/1585968184791736326,@giffmana *under the constraint that the proof assumes it's a shallow ReLU network with a infinitely wide hidden layer
2372,@rasbt,2022-10-28 12:11:11+00:00,https://twitter.com/rasbt/status/1585967412721192962,@hardmaru Making good memes is a form of art
2373,@rasbt,2022-10-28 12:09:59+00:00,https://twitter.com/rasbt/status/1585967110269784067,"@FrankRHutter @predict_addict hey @tunguz @marktenenholtz @ph_singer , is there a competition for small-medium sized tabular data that you'd recommend for testing new deep learning for tabular data methods (and comparing them to tree-based algos)?"
2374,@rasbt,2022-10-28 12:08:00+00:00,https://twitter.com/rasbt/status/1585966612477227009,"@AssemblyAI Glad you liked! I'm really grateful for all the positive feedback so far üòä
PS: Only one more week until the next issue!"
2375,@rasbt,2022-10-28 02:24:20+00:00,https://twitter.com/rasbt/status/1585819724478570496,"@Ron29465739 Good one. I was running out of space but I also simply forgot. 
RecSys should have definitely been on there. Maybe also Energy-based models. And AutoML perhaps."
2376,@rasbt,2022-10-27 21:26:31+00:00,https://twitter.com/rasbt/status/1585744776510537729,"@GJuantorena Actually, there are quite a lot of people interested in mimicking how the human brain works/learns. 

A few pointers from my list:
- https://t.co/UhySQPIIVr
- https://t.co/LDleIa0uSl
- https://t.co/M8nGnFiFYp"
2377,@rasbt,2022-10-27 21:14:56+00:00,https://twitter.com/rasbt/status/1585741864845643776,@MooseHornRiver I would have quite a list for each of those ... https://t.co/1Bb51VjzIm
2378,@rasbt,2022-10-27 21:13:55+00:00,https://twitter.com/rasbt/status/1585741608489668608,"@anas0164 üíØ agreed. That's why every ""2. Intro Data Science"" course worth its salt should have your (data)bases covered!"
2379,@rasbt,2022-10-27 20:57:47+00:00,https://twitter.com/rasbt/status/1585737549058019328,"@Slav636 a few hours every day, and you should be good in about 5-10 years"
2380,@rasbt,2022-10-27 20:51:17+00:00,https://twitter.com/rasbt/status/1585735911001972736,@predict_addict @FrankRHutter there is only one way to settle it üôÉ https://t.co/8UBsGCRoCw
2381,@rasbt,2022-10-27 20:49:08+00:00,https://twitter.com/rasbt/status/1585735371522203648,"It's not over until it's over! After the general top-10 below, it may make sense to specialize. In no particular order:

- MLOPs
- Causal Inference
- Reinforcement Learning
- Interpretable ML
- Probabilistic DL
- NLP
- Computer Vision
- Neuroscience
- Generative DL
- Graph NNs"
2382,@rasbt,2022-10-27 20:02:31+00:00,https://twitter.com/rasbt/status/1585723638955020288,"@rdshapiro Hm, I thought Jax prides itself for its functional design ... unless you are using Flax or Haiku, haha"
2383,@rasbt,2022-10-27 20:01:49+00:00,https://twitter.com/rasbt/status/1585723462168895488,@gbalderasaviles Planning to do so in the future! Would have to curate it though; there is so much stuff out there ...
2384,@rasbt,2022-10-27 19:59:49+00:00,https://twitter.com/rasbt/status/1585722957791637504,@uddupa @beenwrekt ouch üî•
2385,@rasbt,2022-10-27 17:32:37+00:00,https://twitter.com/rasbt/status/1585685915745255432,"@CalcCon Haha, yes. But kidding aside, it's super relevant for ML.
Nearest neighbor vs decision trees? Big-O analysis!
XGBoost vs LightGBM? Breadth-first vs depth-first search!
etc."
2386,@rasbt,2022-10-27 17:30:37+00:00,https://twitter.com/rasbt/status/1585685413389279234,"@gbalderasaviles I cover some topics in my books and classes for sure. But yeah, in this list above, I had dedicated resources in mind. At least 1 book (or course) on each topic. 
Anyways, I have a TOC of my recent book here if useful: https://t.co/4sYEOt09lN"
2387,@rasbt,2022-10-27 16:21:29+00:00,https://twitter.com/rasbt/status/1585668012631277570,"@rdshapiro üíØ! This would be a good follow-up on the Python course. Actually, I partly learned this in the Python CS class I took back in college.

Anyways, re object oriented design and patterns, Jax, Julia and Haskell users would like to have a word haha"
2388,@rasbt,2022-10-27 15:14:44+00:00,https://twitter.com/rasbt/status/1585651214267596800,@ArnaudovKrum üíØ! Also brings back memories. SQLite was literally the topic of my very first blog post a decade ago: https://t.co/BXp8RVIu0g
2389,@rasbt,2022-10-27 14:03:55+00:00,https://twitter.com/rasbt/status/1585633394175508480,"@beenwrekt ‚ÄúThe best minds of my generation are thinking about how to make people click ads.‚Äù 
You probably haven't seen the list of accepted papers at #NeurIPS2022 yet https://t.co/AAhdjOcyTF"
2390,@rasbt,2022-10-27 13:52:40+00:00,https://twitter.com/rasbt/status/1585630563922165762,"@PatrikPastor2 ""Tell me where is the demand for AI (except of automotive, auto drivers, this is well known)"" --&gt; computational biology, drug design &amp; discovery, ..."
2391,@rasbt,2022-10-27 13:40:59+00:00,https://twitter.com/rasbt/status/1585627621320269824,"@Al_levity adding mindful meditation to the list, lol"
2392,@rasbt,2022-10-27 13:34:33+00:00,https://twitter.com/rasbt/status/1585626004449525760,"@lfstevens For parallel computing, I think it needs to come after linear algebra to fully appreciate it and get the most out of it. E.g., for tensor parallelism you'd need to understand block multiplication (https://t.co/UlDufLKtPL) etc."
2393,@rasbt,2022-10-27 12:43:50+00:00,https://twitter.com/rasbt/status/1585613239278264320,"@DebarpanBhatta8 Yeah, we had to use the matrix cookbook  in an advanced data mining class in grad school. It was tough. I would say matrix calculus is still my weak spot. I wish I knew a resource I could recommend on that."
2394,@rasbt,2022-10-27 12:42:14+00:00,https://twitter.com/rasbt/status/1585612839145832448,"@OceanYumnam Books for sure. Because I can better pace myself. When I took math classes in college, I spent 99% of my attention just copying things from the board so that I can read it at home. 
I have the same issue for video lectures. Somehow it's harder for me to focus compared to books."
2395,@rasbt,2022-10-27 12:40:51+00:00,https://twitter.com/rasbt/status/1585612491777875969,@ArnaudovKrum üíØ! I thought of it as an Intro Data Science topic actually.
2396,@rasbt,2022-10-27 12:39:25+00:00,https://twitter.com/rasbt/status/1585612128001687552,"@soaiworld haha, they probably also spell Stable Diffusion as ""NFT 2.0"""
2397,@rasbt,2022-10-27 12:36:25+00:00,https://twitter.com/rasbt/status/1585611372590731264,"@lfstevens Sure, for if you have a stronger MLOps focus, then maybe yes. Calculus is still somewhat important of course. Saves you from gotchas when working with autograd."
2398,@rasbt,2022-10-27 12:35:11+00:00,https://twitter.com/rasbt/status/1585611064770793476,"@_krr12 Personally, I recommend intro to DS and ML courses first to see the big picture and become motivated to study the respective math classes. Also, intro DS material usually covers intro math materials"
2399,@rasbt,2022-10-27 12:33:43+00:00,https://twitter.com/rasbt/status/1585610695797784578,"@enkhtur Yeah, it's a marathon, not a sprint. That's why I also put intro to data science and machine learning so early. That way you can already have some fun early on. And otherwise, you'd lose motivation imho :)"
2400,@rasbt,2022-10-27 12:32:05+00:00,https://twitter.com/rasbt/status/1585610282533101571,"@lhwgwg I learned subversion (svn) before git because that was what was used in my lab back then. While I think mecurial is more user friendly, I would 100% use and recommend git ... that's because 99% of the open source and scientific computing world uses it, and u need it to contribute"
2401,@rasbt,2022-10-27 12:19:25+00:00,https://twitter.com/rasbt/status/1585607095864508416,"@setti You need calculus to understand (and proof) results in statistics. Even p-values are areas under the curve, and you would need integration for these."
2402,@rasbt,2022-10-27 12:17:19+00:00,https://twitter.com/rasbt/status/1585606569462472706,"@kenchamadhu 2/2 So, instead of writing materials on math fundamentals, I am instead focusing more on machine learning itself. (1) Making it more accessible, and (2) covering more advanced topics. Those 2 things are what I am currently working on."
2403,@rasbt,2022-10-27 12:15:45+00:00,https://twitter.com/rasbt/status/1585606173553827843,"@kenchamadhu I tried writing one but aborted it. The reason is that math fundamdentals for ML, in my opinion, are best learned by considering dedicated math resources. E.g., you will learn more Gilbert Strang's course on Linear Algebra than from any ""Linear algebra for ML"" resource 1/2"
2404,@rasbt,2022-10-26 23:39:15+00:00,https://twitter.com/rasbt/status/1585415793936068608,"@v3n0m92 One day, one day... just have to curate it a bit"
2405,@rasbt,2022-10-26 23:38:42+00:00,https://twitter.com/rasbt/status/1585415656438218752,"@sebguz31 actually, I think learning linear algebra is A LOT OF FUN:
https://t.co/BQBuCUe6HZ"
2406,@rasbt,2022-10-26 23:34:56+00:00,https://twitter.com/rasbt/status/1585414709498486784,"@akshay_pachaar Yeah, you would lose motivation very quickly if you started with just math (not everyone, but that's probably true for most people, me included üòÖ)"
2407,@rasbt,2022-10-26 23:33:53+00:00,https://twitter.com/rasbt/status/1585414444217413634,"@CJW1962 My journey was R -&gt; JavaScript -&gt; Python -&gt; C++, it was fine."
2408,@rasbt,2022-10-26 23:33:15+00:00,https://twitter.com/rasbt/status/1585414284468965377,"@avniakyol1989 Because you won't get far in your career without knowing how to use Git and collaborate on GitHub. 

Didn't exist back then, but the GitHub docs look good: https://t.co/uVy6oMOsan

For a more detailed coverage, the Git book: https://t.co/3Z0Mr5W7uT (that's what I used back then)"
2409,@rasbt,2022-10-26 23:30:43+00:00,https://twitter.com/rasbt/status/1585413645303177216,"@tunguz Intro to Data Science üòè 
(or, if that course didn't cover it, Intro to Machine Learning)"
2410,@rasbt,2022-10-26 23:29:47+00:00,https://twitter.com/rasbt/status/1585413409864126465,"@BigBetAnalytics Haha, yes, that's the kind of stuff I am basically grokking atm"
2411,@rasbt,2022-10-26 21:22:22+00:00,https://twitter.com/rasbt/status/1585381344980635649,"@adbeketa Haha, I was thinking about putting it first, but then you don't have created any stuff yet that you can version control"
2412,@rasbt,2022-10-26 21:18:36+00:00,https://twitter.com/rasbt/status/1585380398640791555,"@vishal_balaji_ back in 2011, I worked in a lab where they just got a Tesla card for molecular dynamics and had the CUDA manual printed on the desk. I looked into it but gave up. Was too complicated for me back then. I dunno, depending on what you want to do, it can be relevant though"
2413,@rasbt,2022-10-26 21:14:13+00:00,https://twitter.com/rasbt/status/1585379296327049217,"@vishal_balaji_ I have a loose collection of articles etc. It's something where I learned the basics in CS in college back then, but at the same time it's also something I am just recently getting more into. I mean, the multi-GPU paradigms relevant for DL https://t.co/1KAiGxBmt4"
2414,@rasbt,2022-10-26 21:12:40+00:00,https://twitter.com/rasbt/status/1585378904340312065,"@vishal_balaji_ I have a loose collection of articles etc. I mean I learned the basics in CS in college back then, but also it's something I am just recently getting into. I mean, the multi-GPU paradigms relevant for DL."
2415,@rasbt,2022-10-26 21:11:09+00:00,https://twitter.com/rasbt/status/1585378521307750401,"@koval__alvi Oh I see. It'd say it's fine. Most state-of-the-art ML is tree-based. 
Linear algebra is definitely essential for Deep Learning though; hence, I placed it later."
2416,@rasbt,2022-10-26 20:54:49+00:00,https://twitter.com/rasbt/status/1585374411569647616,"@saltig_ai I would think of it as part of the Machine Learning and Deep Learning subjects/classes. However, it doesn't hurt to maybe have a separate list item for this as well. Good call."
2417,@rasbt,2022-10-26 20:53:42+00:00,https://twitter.com/rasbt/status/1585374132933259264,"@koval__alvi It is :). Actually, how I learned linear algebra is with the ""Coding the Matrix"" book, which was basically teaching linear algebra by re-implementing linear algebra concepts from scratch in Python: https://t.co/TH0GGCYGqK"
2418,@rasbt,2022-10-26 20:50:08+00:00,https://twitter.com/rasbt/status/1585373234899603456,"With things like
""5. Intro Algos &amp; Data Structures""
""9. Intro Proba &amp; Stats""...
I really mean dedicated classes that focus on the subject. The ""Intro"" is to indicate that we are talking about a few advanced undergrad courses here; not an advanced, proof-heavy grad level courses"
2419,@rasbt,2022-10-26 20:50:08+00:00,https://twitter.com/rasbt/status/1585373233280606208,"You may wonder why I put
""2. Intro Data Science"" 
before things like 
""5. Intro Algos &amp; Data Structures""
""9. Intro Proba &amp; Stats""...
Here, I really mean an intro data science course that gives you the big picture overview. Some basic EDA, stats, pandas data parsing etc."
2420,@rasbt,2022-10-26 20:46:01+00:00,https://twitter.com/rasbt/status/1585372197522010112,"My top-10 study list if I was learning machine learning again:

1. Python
2. Intro Data Science
3. Intro Machine Learning
4. Version Control
5. Intro Algos &amp; Data Structures
6. Intro Linear Algebra
7. Intro Calculus
8. Deep Learning
9. Intro Proba &amp; Stats
10. Parallel Computing"
2421,@rasbt,2022-10-26 13:05:46+00:00,https://twitter.com/rasbt/status/1585256371028533248,"@FrankRHutter 3/3 I do think what would help convince people is to compete in eg a Kaggle competition. I think if a new deep tabular DL method achieves top 10 performance, that would erase a lot of the skepticism. It‚Äôs probably ore effective than even publishing a paper on that."
2422,@rasbt,2022-10-26 13:03:54+00:00,https://twitter.com/rasbt/status/1585255904500645889,"@FrankRHutter 2/ that means other methods in the comparison are often improperly tuned. Or key datasets are not considered. On the flip side, we can‚Äôt ask other people or the community to do that based on code the researchers provide ‚Äî everyone is busy, and it would be a big time commitment"
2423,@rasbt,2022-10-26 13:01:58+00:00,https://twitter.com/rasbt/status/1585255414165557250,"@FrankRHutter Thanks for sharing, explaining, and making everything so transparent! Also great efforts re open source! Tbh; and that‚Äôs not criticism but more of an observation and suggestion: I think the skepticism is usually that researchers focus too much on their own method 1/"
2424,@rasbt,2022-10-26 12:56:00+00:00,https://twitter.com/rasbt/status/1585253913145769984,"@akbirkhan @nsgoodger Agreed, I totally forgot to mention RL and human-in-the-loop"
2425,@rasbt,2022-10-26 12:21:14+00:00,https://twitter.com/rasbt/status/1585245165190422529,"@soaiworld It‚Äôs not the automation that I find problematic but more like taking control away ‚Äî instead of developing our own ML models we will be limited to interacting with a few select models that a few select companies license to us. Maybe useful but not exciting or fun, haha"
2426,@rasbt,2022-10-26 12:19:22+00:00,https://twitter.com/rasbt/status/1585244694619246600,"@xamat Exactly. It‚Äôs kind of a user interface, which is nice. In a sense it removes barriers for people who were not previously using ML. On the other hand it also puts up new barriers because we can‚Äôt train models anymore, just consume them through prompt Interfaces."
2427,@rasbt,2022-10-26 12:16:03+00:00,https://twitter.com/rasbt/status/1585243860976140289,@zubairahmed_ai @ykilcher @A_K_Nain @alfcnz Yes. But the remarkable is almost perfect. Almost. The thing that‚Äôs  really missing is a Split View (reading content + notebook side by side; but maybe it‚Äôs also just too small for that and it wouldn‚Äôt work). Or and maybe a color eInk would be nice haha
2428,@rasbt,2022-10-26 12:11:52+00:00,https://twitter.com/rasbt/status/1585242806687125504,"@incognitoz_29 You can do either, and it also depends on the architecture. The difference here is that it‚Äôs not end to end. In the finetuning example you use backprop through the whole transformer (even you only train the last layers). Here, you can eg train a random forest on the embeddings"
2429,@rasbt,2022-10-26 12:08:35+00:00,https://twitter.com/rasbt/status/1585241981542109186,"@AhmadMustafaAn1 Yeah, that‚Äôs what I usually call feature-based approach (in the list above) ‚Äî I think this is sometimes referred to as finetuning as well, eg in the BERT paper"
2430,@rasbt,2022-10-26 01:52:03+00:00,https://twitter.com/rasbt/status/1585086825709740032,"@letsrebelagain Machine Learning with PyTorch and Scikit-learn: https://t.co/dZzvgQSkjM
The chapter is essentially a slightly extended, neater version of these videos"
2431,@rasbt,2022-10-26 01:50:57+00:00,https://twitter.com/rasbt/status/1585086548525342720,@PM_1729 Haha this is hilarious. Love the title
2432,@rasbt,2022-10-26 01:49:30+00:00,https://twitter.com/rasbt/status/1585086185075929090,"@zubairahmed_ai @ykilcher @A_K_Nain @alfcnz Problem is if you read a paper, you essentially need 2 of these devices: one for reading and annotating, and one as a notebook for writing, haha"
2433,@rasbt,2022-10-26 01:48:33+00:00,https://twitter.com/rasbt/status/1585085944012886017,"@zubairahmed_ai @ykilcher @A_K_Nain @alfcnz I moved on to Remarkable and been a happy user for almost a year. It's smaller, but I like it way better. The annotation / notetaking capabilities are way better. 
I use it for all my reading and writing when traveling. At home I use it for all my writing (not all reading)."
2434,@rasbt,2022-10-26 00:06:01+00:00,https://twitter.com/rasbt/status/1585060141778411520,"@GarrettRMooney @fishnets88 Wow that‚Äôs a really nice and lean example! Anyways, I will try to toy around with the embetter + DistilBert + LogReg Pipeline. Will put it on my long ‚Äúfun things to try on the weekend‚Äù list :)"
2435,@rasbt,2022-10-25 23:46:48+00:00,https://twitter.com/rasbt/status/1585055307914694656,"@AlbertoAndreott Thanks! And yeah, one day ... they are basically my drafts. I bookmark some of them with the intention to elaborate further in the future"
2436,@rasbt,2022-10-25 22:49:38+00:00,https://twitter.com/rasbt/status/1585040921103847424,@jasongfleischer or a conscious chatbot friend
2437,@rasbt,2022-10-25 22:37:49+00:00,https://twitter.com/rasbt/status/1585037943861030912,@GarrettRMooney Very cool stuff! You do not have a DistilBERT example by chance? üòÖ
2438,@rasbt,2022-10-25 22:31:37+00:00,https://twitter.com/rasbt/status/1585036385332838400,@prdeepakbabu omg totally forgot about this üôà. thanks!
2439,@rasbt,2022-10-25 22:21:49+00:00,https://twitter.com/rasbt/status/1585033919640252416,"@FrankRHutter Yeah, it's kind of analogous to the pre-training time of LLMs. One could argue, wouldn't it be fair to compare it to a pre-trained transformer (that is only fine-tuned on a target dataset)? But I guess transfer learning with tabular data is tricky, even for transformers."
2440,@rasbt,2022-10-25 22:19:28+00:00,https://twitter.com/rasbt/status/1585033325919420416,"@FrankRHutter @ilyaraz2 And XGBoost, LightGBM have been engineered for efficiency for many many years. I mean, that's kind of their selling point even (compared to vanilla gradient boosting)"
2441,@rasbt,2022-10-25 22:18:33+00:00,https://twitter.com/rasbt/status/1585033097867055106,"@FrankRHutter @ilyaraz2 Related to that, doing anything research-related that is slightly out of the box is always pretty slow via the commonly used DL frameworks. That's because it's a proof-of-concept, and we usually don't have the time to engineer the low-level things for efficiency"
2442,@rasbt,2022-10-25 22:10:49+00:00,https://twitter.com/rasbt/status/1585031149025624065,"@crude2refined ok ok, fair üòä"
2443,@rasbt,2022-10-25 21:59:31+00:00,https://twitter.com/rasbt/status/1585028305824407553,@csinva_ Agreed. I was grouping that under zero-shot /few-shot but yeah prompting doesn‚Äôt need to be that. Cool figure btw. Thanks for sharing!
2444,@rasbt,2022-10-25 20:52:03+00:00,https://twitter.com/rasbt/status/1585011328657199104,@letsrebelagain I have a bunch of video recordings here: https://t.co/JhY0KBoQD3 (there's also a chapter in my book)
2445,@rasbt,2022-10-25 20:50:32+00:00,https://twitter.com/rasbt/status/1585010947680538624,@jmwilt21 But why calling it Settings on iOS but System Settings on macOS?
2446,@rasbt,2022-10-25 20:46:39+00:00,https://twitter.com/rasbt/status/1585009971527266305,"@datacascadia It would be interesting to combine it with this: https://t.co/pQwzuJk5Lz
(haha, but who has the computational budget for that)"
2447,@rasbt,2022-10-25 20:43:47+00:00,https://twitter.com/rasbt/status/1585009248387633152,"@mermolenko more like prompt-hacking, haha. but good suggestion!"
2448,@rasbt,2022-10-25 20:42:18+00:00,https://twitter.com/rasbt/status/1585008874762825728,"@shriphani thanks! when I understand correctly, it's about the pre-training task? I.e., pre-training on a different domain than the target task? (Kind of a transfer-learning scheme for pre-training lol)"
2449,@rasbt,2022-10-25 20:23:44+00:00,https://twitter.com/rasbt/status/1585004201486487552,"@deliprao Ok fair, but it's also a very generic thing that would basically encompass all 6, wouldn't it? üòÜ"
2450,@rasbt,2022-10-25 20:13:20+00:00,https://twitter.com/rasbt/status/1585001587403264001,"6 Few-shot learning, learning from a few labeled examples. Either as an extension of the zero-shot example (with more Q&amp;A); or embed examples, then do a nearest neighbor search and select the most similar example. https://t.co/g2kVealnMP"
2451,@rasbt,2022-10-25 20:13:20+00:00,https://twitter.com/rasbt/status/1585001584307867648,"5 Zero-shot learning, make predictions without training data. Use a pre-trained model and provide a task via the model-prompt https://t.co/OxR2D4q05M"
2452,@rasbt,2022-10-25 20:13:19+00:00,https://twitter.com/rasbt/status/1585001581627723776,"4 Finetuning II, update all weights. Add randomly initialized output layers and train in a transfer-learning fashion. Here, update all model weights (the LLM base model as well as the output layers) https://t.co/sjwO2jVG6y"
2453,@rasbt,2022-10-25 20:13:19+00:00,https://twitter.com/rasbt/status/1585001579455074304,"3 Finetuning I, freeze all but output layer weights. Add randomly initialized output layers and train in a transfer-learning fashion. Only update the fully-connected output layer and keep the base LLM frozen. https://t.co/4e8KRvVEPv"
2454,@rasbt,2022-10-25 20:13:18+00:00,https://twitter.com/rasbt/status/1585001577248882688,"2 Feature-based, train a new model on embeddings (also considered ""finetuning""). Take a pre-trained transformer and cut off the last layer. Then, run LLM in inference mode and train a new classifier on the embeddings. https://t.co/JtzQdXqooj"
2455,@rasbt,2022-10-25 20:13:18+00:00,https://twitter.com/rasbt/status/1585001574908432385,"1 Train from scratch: the obvious candidate. This is not feasible since transformers require large amounts of data. So, we use unlabeled data for pretraining (as opposed to training from scratch in a supervised fashion) https://t.co/kjXAKFyE1A"
2456,@rasbt,2022-10-25 20:13:17+00:00,https://twitter.com/rasbt/status/1585001572719030272,"The 6 different ways of using a language transformer / LLM

1 Train from scratch
2 Feature-based: Train new model on embeddings
3 Finetuning I: Freeze all but output layer weights
4 Finetuning II: Update all weights
5 Zero-shot learning
6 Few-shot learning

Anything missing?
1/6"
2457,@rasbt,2022-10-25 19:07:02+00:00,https://twitter.com/rasbt/status/1584984901413396482,"@terrible_coder I think that‚Äôs exclusive to ExceptionGroups though, but yeah it‚Äôs a bit quirky. For reference: https://t.co/Iu5Z1EvVMt"
2458,@rasbt,2022-10-25 19:04:52+00:00,https://twitter.com/rasbt/status/1584984356359376896,@terrible_coder The Exception class? I think it‚Äôs not too bad given the context of things you can do with it:
2459,@rasbt,2022-10-25 18:53:52+00:00,https://twitter.com/rasbt/status/1584981586189352961,"Python got a significant speed boost, better error messages &amp; no quirky new syntax features? That‚Äôs a win-win-win!"
2460,@rasbt,2022-10-25 18:49:52+00:00,https://twitter.com/rasbt/status/1584980578344267776,@GaryMarcus *I write it in TextEdit and the copy &amp; paste into twitter web.
2461,@rasbt,2022-10-25 18:48:50+00:00,https://twitter.com/rasbt/status/1584980320574586881,@GaryMarcus TextEdit üòÖ. Is am not kidding.
2462,@rasbt,2022-10-25 18:42:05+00:00,https://twitter.com/rasbt/status/1584978620207943680,"@xamat Yup, he blocks all AI / deep learning people apparently. https://t.co/Ugm4PZYnzI"
2463,@rasbt,2022-10-25 18:24:05+00:00,https://twitter.com/rasbt/status/1584974091299454977,"@agvaughan Thanks for sharing. Not sure if this paper addresses it (haven't read it yet), but can it also acquire new knowledge? Like ""why is the stock market up today?"" (where today means 25 Oct, 2022), or is it still restricted to ""old"" data it was pre-trained on?"
2464,@rasbt,2022-10-25 18:18:18+00:00,https://twitter.com/rasbt/status/1584972636890988544,"@nelslindahl Yup. It's more of a interface &amp; product. It's probably useful for a lot of cases where conventional ML algorithm usage is not useful &amp; inaccessible. 
If you are a ML researcher, it's still boring though üòÖ"
2465,@rasbt,2022-10-25 16:42:01+00:00,https://twitter.com/rasbt/status/1584948404366344205,"@agvaughan An interesting middle ground would be this: instead of raw text input, pre-trained LLM takes an ‚Ñù^128 vector as input. ML tinkerers develop new algos and train models to produce better vector representations of raw text. (I.e., decoupling prompt representation learning and LLMP)"
2466,@rasbt,2022-10-25 15:58:29+00:00,https://twitter.com/rasbt/status/1584937452166270976,@lathropa I heard Altavista? üòÜ https://t.co/hFSyVsRCkV
2467,@rasbt,2022-10-25 15:16:27+00:00,https://twitter.com/rasbt/status/1584926872282238976,PS: *not exciting* does not imply *not useful* ü§´
2468,@rasbt,2022-10-25 15:14:58+00:00,https://twitter.com/rasbt/status/1584926500821692416,"@Sandbar101 hey, I didn't say it's not useful, it's just less fun if you are  programmer and/or deep learner üôÉ"
2469,@rasbt,2022-10-25 14:38:40+00:00,https://twitter.com/rasbt/status/1584917365162221569,@Onalytica whoa thanks for the mention
2470,@rasbt,2022-10-25 14:36:23+00:00,https://twitter.com/rasbt/status/1584916787577208833,@rolisz I think it is useful in the short term. It's not very exciting though (unless you are in the business of selling models and APIs perhaps)
2471,@rasbt,2022-10-25 14:32:52+00:00,https://twitter.com/rasbt/status/1584915905057783810,"@ankrgyl Good point, and that's what I was trying to get at. To me, using a machine learning model is a more interesting engineering problem than tweaking prompts. But I guess I would be less of a researcher but more of a SEO optimizer otherwise :P"
2472,@rasbt,2022-10-25 14:31:19+00:00,https://twitter.com/rasbt/status/1584915513515425796,@agvaughan Fair. But the big loss here is that no one (except a select few) will even be able to train or retrain. There are two sides of the coin: Making models more accessible while making the methods less accessible ü§∑‚Äç‚ôÇÔ∏è
2473,@rasbt,2022-10-25 13:36:54+00:00,https://twitter.com/rasbt/status/1584901820505329665,@SDAIA_KAUST_AI @XGBoostProject Or like search query engineering on Google search
2474,@rasbt,2022-10-25 13:36:07+00:00,https://twitter.com/rasbt/status/1584901620617330689,@animesh1977 Tweet engineering üòè
2475,@rasbt,2022-10-25 13:31:52+00:00,https://twitter.com/rasbt/status/1584900553636708352,@SDAIA_KAUST_AI @XGBoostProject we'll be back ...
2476,@rasbt,2022-10-25 13:29:41+00:00,https://twitter.com/rasbt/status/1584900004547891200,@SDAIA_KAUST_AI @XGBoostProject Some people might say that this ship has already sailed üôÉ
2477,@rasbt,2022-10-25 13:28:45+00:00,https://twitter.com/rasbt/status/1584899766500163584,"Tinkering with prompt engineering.

AI researchers &amp; engineers: ""How far can we push this before it starts to break?"" ü§î
 
AI alignment folks: ""How far can we push this before before it starts pushing back?"" üò±"
2478,@rasbt,2022-10-25 13:23:32+00:00,https://twitter.com/rasbt/status/1584898457529376769,@katnoria1 üíØ
2479,@rasbt,2022-10-25 13:21:08+00:00,https://twitter.com/rasbt/status/1584897849828876289,"@code_star Yeah, so basically the EDA behind prompt engineering."
2480,@rasbt,2022-10-25 13:09:00+00:00,https://twitter.com/rasbt/status/1584894798275964932,"@divergiment Hm, yeah, it could be the shift away from using machine learning algorithms to using machine learning models. As a tinkerer, I find it more interesting to play around with algorithms than models."
2481,@rasbt,2022-10-25 13:04:35+00:00,https://twitter.com/rasbt/status/1584893687410364419,"Also, imagine this future was true, and you found just the right prompting approach for a given model. Then, what do you do if advances in research prompt you (no pun intended) to work with a new pre-trained model?! üò∂"
2482,@rasbt,2022-10-25 13:04:35+00:00,https://twitter.com/rasbt/status/1584893684931530752,"I can't understand the hype/excitement around prompt engineering lately. 
If the future of deep learning research is to tweak the prompts of someone else's model, that'd be a pretty boring future. 
‚ù§Ô∏è‚Äçüî• I love building things from scratch myself ‚ù§Ô∏è‚Äçüî•"
2483,@rasbt,2022-10-25 11:42:22+00:00,https://twitter.com/rasbt/status/1584872998292815873,@paulabartabajo_ üíØ! I should frame that.
2484,@rasbt,2022-10-25 11:38:29+00:00,https://twitter.com/rasbt/status/1584872020612829184,"@cj_72_ Hm, I think I wrote about it a couple of times on Twitter but hard to find the thread now. It‚Äôs an interesting &amp; useful topic though (lots of students ask me about this) ‚Äî maybe a good candidate for the ‚Äúproductivity section‚Äù of my newsletter üòä"
2485,@rasbt,2022-10-25 00:17:41+00:00,https://twitter.com/rasbt/status/1584700688655056896,"@NaseemHM @zehavoc Many factors, but I'd say most of it comes down to experience. I should maybe write about it some time if it is helpful. But I'd say also non-high quality paper are sometimes worthwhile reading. Eg the GPT papers were not super high quality and still really worthwhile reading"
2486,@rasbt,2022-10-25 00:11:19+00:00,https://twitter.com/rasbt/status/1584699087588188161,"@NaseemHM @zehavoc No, they are way too messy üòÖ"
2487,@rasbt,2022-10-24 21:00:36+00:00,https://twitter.com/rasbt/status/1584651093044531203,@mpaepper Haha exactly üòÖ
2488,@rasbt,2022-10-24 20:57:41+00:00,https://twitter.com/rasbt/status/1584650357317070849,@togelius ouch
2489,@rasbt,2022-10-24 14:36:54+00:00,https://twitter.com/rasbt/status/1584554529231876096,@roydanroy ‚Äú1-min long Lightning talk‚Äù ‚Äî tell me you are addicting to TikTok without telling me you are addicted to TikTok
2490,@rasbt,2022-10-24 14:33:30+00:00,https://twitter.com/rasbt/status/1584553675694882817,@ItaDude @roydanroy I hope so
2491,@rasbt,2022-10-24 14:31:56+00:00,https://twitter.com/rasbt/status/1584553281228926976,@roydanroy One minute is ridiculously short. It would make more sense if they organizers put together a slide deck with rotating visual abstracts that rotate in 1-min intervals. Can actually have that on screens thorough out the conference venue
2492,@rasbt,2022-10-24 12:18:50+00:00,https://twitter.com/rasbt/status/1584519784586092545,@zehavoc This is a positive example where you eventually stumbled upon it the efficient way (it‚Äôs a method that works so it was mentioned in that review) as opposed to spending 80% of your week reading about and trying things that don‚Äôt work.
2493,@rasbt,2022-10-24 12:13:47+00:00,https://twitter.com/rasbt/status/1584518513925902336,@zehavoc And it‚Äôs also ok to potentially miss things. Trying to chase it all will just stress you out. Been there done that.
2494,@rasbt,2022-10-24 12:12:16+00:00,https://twitter.com/rasbt/status/1584518131393114114,"@zehavoc You know it when you see it I guess, esp if it‚Äôs important for your work."
2495,@rasbt,2022-10-24 12:08:02+00:00,https://twitter.com/rasbt/status/1584517066580971521,"@zehavoc 2/2 by letting articles sit on my list for a bit, I often end up ignoring lots of papers and saving valuable time; it makes me realize that papers that looked intriguing at first glance are actually not that relevant for me. And if I ever need them for sth, well I have the list"
2496,@rasbt,2022-10-24 12:06:04+00:00,https://twitter.com/rasbt/status/1584516571501760513,"@zehavoc Personally, I have topic lists (vision transformer, diffusion, CNN architecture, model evaluation,‚Ä¶) where I keep adding relevant articles when I see them. However I only pick a handful from each list each week based on my time budget 1/2"
2497,@rasbt,2022-10-24 12:01:54+00:00,https://twitter.com/rasbt/status/1584515522699218949,"@zehavoc Hot take: There are no thousands of ‚Äúhigh quality‚Äù papers, lol"
2498,@rasbt,2022-10-24 12:00:56+00:00,https://twitter.com/rasbt/status/1584515279518060544,"@tdietterich Yes! We‚Äôve been slowly edging into this directions vifem that many papers no consider a ‚Äútime/resource budget‚Äù for tuning, but yeah, it doesn‚Äôt take ease of use into account. That‚Äôs why it‚Äôs important that the method should be evaluated by people other than the authors themselves"
2499,@rasbt,2022-10-24 11:57:54+00:00,https://twitter.com/rasbt/status/1584514519526961152,"FAQ: ‚ÄúHow do I keep up with all the machine learning papers and news? It‚Äôs overwhelming!‚Äù

A: ‚ÄúThe world goes on even if you don‚Äôt read everything. It‚Äôs always better to engage with a small amount of high-quality resources than trying to consume it all.‚Äù"
2500,@rasbt,2022-10-24 11:52:59+00:00,https://twitter.com/rasbt/status/1584513280235560960,"@tylerneylon Yup, that would be one example. Tbh managing this would be one way journals could make themselves useful and relevant again"
2501,@rasbt,2022-10-24 11:51:43+00:00,https://twitter.com/rasbt/status/1584512962936868864,@hajivat Or just a comment section on arxiv :)
2502,@rasbt,2022-10-24 01:20:12+00:00,https://twitter.com/rasbt/status/1584354034139688960,the keyword isüçípicking
2503,@rasbt,2022-10-24 01:18:46+00:00,https://twitter.com/rasbt/status/1584353675459571712,"I do think that method benchmarking and verification should NOT BE DONE by the authors themselves. It should be done by the community/reviewers/a third party. 
This is to guarantee that the method is actually useable and more fairly compared to reference methods."
2504,@rasbt,2022-10-24 01:18:46+00:00,https://twitter.com/rasbt/status/1584353673735729152,"I think that modern ML/AI systems are just way more complicated than they used to. It's hard to control for all possible variables and variation. If you are proposing a new method, you are naturally biased towards putting more effort into making your method work well."
2505,@rasbt,2022-10-24 01:15:58+00:00,https://twitter.com/rasbt/status/1584352971797975041,"Yeah scientific publishing is on a downward slope when it comes to objective, scientific communication.
As of late, research papers have become more like advertisements. 
Don't get me wrong, many papers are still super useful when it comes to outlining new methods."
2506,@rasbt,2022-10-24 00:26:08+00:00,https://twitter.com/rasbt/status/1584340428018823170,"@svpino @fchollet Awesome üëè stuff üëè

Looking forward to thoroughly watching and enjoying it with my morning coffee ‚òïÔ∏è"
2507,@rasbt,2022-10-24 00:20:24+00:00,https://twitter.com/rasbt/status/1584338984980733952,"@MoKazamel @tunguz One of the aspects to consider is that each competition is only on a single dataset. Sure, it allows you to compare specific ML models, but it is kinda hard/impossible to fairly compare ML algorithms and general pipelines."
2508,@rasbt,2022-10-23 19:33:10+00:00,https://twitter.com/rasbt/status/1584266701364899840,"@DrGroftehauge @FrankRHutter It's not random weights, it needs to be pretrained on synthetic datasets https://t.co/2qf6wqXlBJ"
2509,@rasbt,2022-10-23 19:31:33+00:00,https://twitter.com/rasbt/status/1584266294245097472,"@FrankRHutter @DrGroftehauge Thanks, that's what I thought. For TabPFN, it's basically 
""training + inference - pretraining"" 
and for others 
""training + model selection + inference""
correct?"
2510,@rasbt,2022-10-23 19:29:30+00:00,https://twitter.com/rasbt/status/1584265778097885184,"@DrGroftehauge Just double checking, yeah, I don't think that chart shows inference time: https://t.co/mB13XVMpAx"
2511,@rasbt,2022-10-23 19:27:26+00:00,https://twitter.com/rasbt/status/1584265258650124288,"@DrGroftehauge maybe I misunderstood, but to me that chart was the training time on new training datsets for TabPFN vs training+hparam budget for other methods?"
2512,@rasbt,2022-10-23 19:22:13+00:00,https://twitter.com/rasbt/status/1584263947019960320,@predict_addict @tunguz Good point. From the paper it wasn‚Äôt clear if the encoding was done manually or part of the computational pipeline
2513,@rasbt,2022-10-23 19:16:27+00:00,https://twitter.com/rasbt/status/1584262493454540800,"@predict_addict @tunguz Ah yeah, I think it doesn't do well on categorical data at all (they had a chart on that in the appendix). Currently, they encode categorical data into arbitrary integers, which imply an ordering, so it's suboptimal."
2514,@rasbt,2022-10-23 19:15:08+00:00,https://twitter.com/rasbt/status/1584262165011124225,"@predict_addict @tunguz Yes for sure, and the approximate Bayesian inference approach is also a less trodden path, which is interesting!"
2515,@rasbt,2022-10-23 19:09:24+00:00,https://twitter.com/rasbt/status/1584260721461764096,"@predict_addict Thanks for sharing these insights. That's good to know! Yeah, papers are useful for method description, but you can never trust the numbers. Looking forward to @tunguz's curated tabular benchmark project! https://t.co/cB2lD3r3dt"
2516,@rasbt,2022-10-23 19:07:31+00:00,https://twitter.com/rasbt/status/1584260244456189952,"Computational performance caveats: This method seems to be very slow for inference: https://t.co/K1SYfImKuC

Training on the priors is also very costly (20h on 8 GPUs) ."
2517,@rasbt,2022-10-23 19:06:39+00:00,https://twitter.com/rasbt/status/1584260029510623235,"@ilyaraz2 Wow! Just read the paper this morning and was very intrigued, but this puts a big dent into the initial excitement. Thanks for sharing! Btw it was interesting that they didn't talk about inference speeds at all in the paper"
2518,@rasbt,2022-10-23 17:26:24+00:00,https://twitter.com/rasbt/status/1584234797815058432,@MortimerWerther @SamuelMullr might be able to explain
2519,@rasbt,2022-10-23 17:25:51+00:00,https://twitter.com/rasbt/status/1584234660883619840,"@gchrupala In a sense. it would be interesting to see kNN with a transformer encoding instead of e.g,. euclidean distance metrics on the raw feature space"
2520,@rasbt,2022-10-23 15:51:22+00:00,https://twitter.com/rasbt/status/1584210883659460608,"6/6 The researchers mention that the errors are uncorrelated to those of other methods; this makes TabPFN attractive for ensembling (a potentially interesting topic for future studies).
Link to paper: https://t.co/GHsZXhheAA
Link to code: https://t.co/yfEssNiVrx"
2521,@rasbt,2022-10-23 15:51:22+00:00,https://twitter.com/rasbt/status/1584210882179272704,"""One can simply design a dataset generating algorithm that encodes the desired prior"" -- how simple is ""simply""? üòÖ 5/6"
2522,@rasbt,2022-10-23 15:51:21+00:00,https://twitter.com/rasbt/status/1584210880484425728,Is the conventional hyperparameter tuning on a training dataset more laborious that the expensive prior-data fitting procedure? The prior fitting time is 20h on 8 GPUs. 4/6
2523,@rasbt,2022-10-23 15:51:21+00:00,https://twitter.com/rasbt/status/1584210878945431552,"What makes the method particularly appealing is that it doesn't require training, hyperparameter tuning, or cross-validation -- it only requires a single forward pass on a new training set. The caveat is that it requires synthetic datasets for the prior. 3/6"
2524,@rasbt,2022-10-23 15:51:21+00:00,https://twitter.com/rasbt/status/1584210877233758208,"While the method is based on Bayesian inference, it's well-known (see Judea Pearl's Book of Why) that causal mechanisms can't be obtained from observational data alone. As a clever workaround, theyapproximate the posterior predictive dist directly given a prior to sample from 2/6"
2525,@rasbt,2022-10-23 15:51:20+00:00,https://twitter.com/rasbt/status/1584210875455791104,"It's always exciting to add a new method to the deep tabular list: https://t.co/pWOAwqiTS0.  

Just read through the paper. It's an intriguing fresh take on deep learning for tabular data, combining approximate Bayesian inference and transformer tokenization. [1/6]"
2526,@rasbt,2022-10-23 14:50:50+00:00,https://twitter.com/rasbt/status/1584195649297604608,"@FrankRHutter Minor q regarding this figure: why showing catboost here and not XGBoost, LightGBM, SAINT, which you were comparing against in the other plots. Catboost is usually known for categorical data, and in this 2D example you show it on a numerical dataset."
2527,@rasbt,2022-10-23 14:47:26+00:00,https://twitter.com/rasbt/status/1584194794284122114,"@FrankRHutter @SamuelMullr Could you help me understand the tokenization scheme üòÖ? Suppose you have a dataset w 5 features: 3 numerical and 2 categorical. That means for each training ex you have a dxk matrix where k=5, d=embedding size? U said u didn't do hparam tuning. How did u choose d?"
2528,@rasbt,2022-10-23 14:35:57+00:00,https://twitter.com/rasbt/status/1584191905721876482,"@FrankRHutter Just read through the paper, awesome fresh idea combining approximate Bayesian inference and transformers for tabular data! Re the 1k in your tweet: when I understood correctly, the synthetic datasets for the priors were up to 1024 ex, but in the paper you are referring to 2k? https://t.co/WjaXjZyi3N"
2529,@rasbt,2022-10-23 13:44:23+00:00,https://twitter.com/rasbt/status/1584178926951182336,"@guysnovelutumba @tunguz Random forests and logistic regression baselines; LightGBM and XGBoost when you have some time to max m#performance; finally, feel experimental and select some from if you find tree-based methods boring üòÖ: https://t.co/VAXJRC49qR"
2530,@rasbt,2022-10-23 13:41:37+00:00,https://twitter.com/rasbt/status/1584178231707504642,@dbenyamin Nice! I actually had to review a research grant on FPGAs once but most admit that I never got into this topic. Very fascinating though!
2531,@rasbt,2022-10-23 13:40:22+00:00,https://twitter.com/rasbt/status/1584177916891406336,"@MuzafferKal_ Yup, cases where m=n. For 4.2 it‚Äôs not required"
2532,@rasbt,2022-10-23 13:38:26+00:00,https://twitter.com/rasbt/status/1584177428670607360,"@enteatenea Yeah, for sure, but I think for supervised learning purposes text data augmentation is usually more useful than synthetic data. In my experience, synthetic data is usually more helpful in tabular and image contexts"
2533,@rasbt,2022-10-23 13:35:29+00:00,https://twitter.com/rasbt/status/1584176686551031809,@Nitin_wysiwyg @Loopifyyy Sure what I meant was more like ‚Äúa video game is not about video-like graphics and realism; don‚Äôt forget to also have fun and interesting gameplay elements‚Äù
2534,@rasbt,2022-10-22 13:12:40+00:00,https://twitter.com/rasbt/status/1583808555685007362,"@tunguz Nah, deep learning for tabular data is more like 
""Have spare GPUs? How to layer for cold weather."" üòÜ"
2535,@rasbt,2022-10-22 13:08:44+00:00,https://twitter.com/rasbt/status/1583807566621966336,"@Loopifyyy Nice, but it looks like there is more *video* than *game*"
2536,@rasbt,2022-10-22 13:01:27+00:00,https://twitter.com/rasbt/status/1583805733056831488,@irhumshafkat Wow this looks amazing at first glance! Bookmarked and exported to my ereader. Looking forward to reading it more thoroughly! Looks like great work! üôå
2537,@rasbt,2022-10-22 12:49:18+00:00,https://twitter.com/rasbt/status/1583802676395257856,@kushashwa @joshuastarmer @lantiga Model compression ^^ https://t.co/JJK8t4sLts
2538,@rasbt,2022-10-22 12:28:13+00:00,https://twitter.com/rasbt/status/1583797372823314432,@ryanpholbrook @joshuastarmer @kushashwa @lantiga @ph_singer @ybabakhin Sounds fun! Need to check that out! Thanks for sharing!
2539,@rasbt,2022-10-22 12:25:45+00:00,https://twitter.com/rasbt/status/1583796750057291776,"And since number 4 caused some confusion last time, here's a cleaned-up version as a bonus üòä https://t.co/LyNNFURGhm"
2540,@rasbt,2022-10-22 12:23:08+00:00,https://twitter.com/rasbt/status/1583796091707076610,"Let me amend this fascinating tour of linear algebra by adding number 5: ‚ú®block multiplication ‚ú®

(Super relevant topic, think of large language models and tensor parallelism where we want to split a large weight matrix across devices for distributed training) https://t.co/bEts9nWWw0"
2541,@rasbt,2022-10-22 12:16:23+00:00,https://twitter.com/rasbt/status/1583794392791277568,"@joshuastarmer @kushashwa @lantiga the State of AI also picked up this story a few weeks ago, so I am not the only one noticing it I guess https://t.co/VWTMWAUGC1"
2542,@rasbt,2022-10-22 12:13:58+00:00,https://twitter.com/rasbt/status/1583793785989115904,"@joshuastarmer @kushashwa @lantiga If you are specifically interested in LLMs, there are lots and lots of alternatives for scaled-dot product attention, but no one is using them, lol. https://t.co/kh8oU1i91k"
2543,@rasbt,2022-10-22 12:11:28+00:00,https://twitter.com/rasbt/status/1583793156666978305,"@joshuastarmer @kushashwa @lantiga For training, there are also lots of tweaks you can do: https://t.co/muS4HtuHPO"
2544,@rasbt,2022-10-22 12:10:01+00:00,https://twitter.com/rasbt/status/1583792791884541953,"@joshuastarmer @kushashwa @lantiga Then, there are model compression techniques -- model size is usually very correlated with speed as well: https://t.co/q3ukFGh6lw"
2545,@rasbt,2022-10-22 12:09:13+00:00,https://twitter.com/rasbt/status/1583792588192354304,"@joshuastarmer @kushashwa @lantiga One of my favorite blog posts on this topic (and one of my favorite go-to transformers that I use(d) in research projects, haha): https://t.co/L3R92lqG19"
2546,@rasbt,2022-10-22 12:08:26+00:00,https://twitter.com/rasbt/status/1583792393421062145,"@joshuastarmer @kushashwa @lantiga Are you interested in techniques that speed up training or inference? Or both? For inference, I have a list of essential techniques here (need to search for the terms on Google Scholar for most recent papers): https://t.co/z4JJuzXTp4)"
2547,@rasbt,2022-10-22 12:04:57+00:00,https://twitter.com/rasbt/status/1583791516900012033,@jrzaurin @tunguz @FrankRHutter @903124S @RichmanRonald Wow so glad to hear you are liking this. Actually it is very flattering to hear that you even discuss it in your meetings üòä
2548,@rasbt,2022-10-22 12:01:43+00:00,https://twitter.com/rasbt/status/1583790701309227008,@jrzaurin @tunguz @FrankRHutter @903124S @RichmanRonald Awesome thanks for sharing! Will check it out and add it to the software section of the deep tabular chronology section. Actually both yours and @tunguz‚Äôs repo ^^
2549,@rasbt,2022-10-21 20:03:34+00:00,https://twitter.com/rasbt/status/1583549575054622720,@astronemir @eLife I get your concerns regarding scraper. But I guess then they need to re-run the scrapers periodically. I think that's more of a scraper issue; we shouldn't hold back progress on the broken publishing front because of those scrapers üòÖ
2550,@rasbt,2022-10-21 20:01:51+00:00,https://twitter.com/rasbt/status/1583549145906044928,"@astronemir @eLife If the pre-final versions are available, I don't think that's a bad thing. Key here is that the reviews are also available. If it's a tiny flaw someone detected and you read the paper along with the reviews, I don't see an issue why the article shouldn't be public pre-revision"
2551,@rasbt,2022-10-21 19:52:04+00:00,https://twitter.com/rasbt/status/1583546681928216576,"@tunguz @FrankRHutter @903124S @RichmanRonald Haha, I totally forget that GitHub stars are a thing! And yes, sure, done, I hope this helps with increasing the motivation to make it happen üòä"
2552,@rasbt,2022-10-21 19:30:54+00:00,https://twitter.com/rasbt/status/1583541356995440641,"@MorafahMahdi Yup! Riding on the waves of success behind diffusion and models and transformers, there‚Äôs been lots of new methods on this front lately: https://t.co/VAXJRBN6oR"
2553,@rasbt,2022-10-21 18:38:13+00:00,https://twitter.com/rasbt/status/1583528098997624838,@vboykis 7am! Did they mean Nutella break*fast*? üòÜ
2554,@rasbt,2022-10-21 18:28:05+00:00,https://twitter.com/rasbt/status/1583525546113175552,"@ammaryh92 Short term, no. We still need those tree-based methods as robust baselines. They work and are simpler to use imho. Longer term: maybe yes, but it is not certain at this point."
2555,@rasbt,2022-10-21 18:12:13+00:00,https://twitter.com/rasbt/status/1583521554629287936,@imgrohit @LightningAI @joshuastarmer Haha yes üíØ! It actually makes you look forward to (as opposed to dreading) Monday morning meetings ‚ò∫Ô∏è
2556,@rasbt,2022-10-21 17:57:33+00:00,https://twitter.com/rasbt/status/1583517862718631936,*link to the paper: Language Models are Realistic Tabular Data Generators https://t.co/SQq1G1N9eG
2557,@rasbt,2022-10-21 17:55:22+00:00,https://twitter.com/rasbt/status/1583517314443460608,"Wow, below is the 2nd paper shared today on deep tabular methods! 
The deep learning from tabular data research field is on fire today üî•!

(PS: And don't forget about diffusion models for tabular data: https://t.co/CaEWyMyqnK üòÅ) 

(PPS: My reviews will follow soon üòä)"
2558,@rasbt,2022-10-21 17:44:29+00:00,https://twitter.com/rasbt/status/1583514573122179072,@mhajabri @tunguz @FrankRHutter @903124S @RichmanRonald @GaelVaroquaux That's a good one. Also recently discussed it here ^^ https://t.co/9t989d6sqj
2559,@rasbt,2022-10-21 16:20:41+00:00,https://twitter.com/rasbt/status/1583493484862140417,"@moyix For me it‚Äôs often true as implementing it step by step is a good way of taking the time to understand it properly. That being said, it‚Äôs also a time sink and not very efficient."
2560,@rasbt,2022-10-21 16:16:29+00:00,https://twitter.com/rasbt/status/1583492430296645635,"@dvassallo üíØ! Often wish my day / schedule would be more flexible, but a regular wake/sleep schedule has become a non-negotiable for me. Consistency is key. Have been experimenting with a regular 9:30 pm to 6 am bed time and feel like I have as much energy I had as an undergrad back then!"
2561,@rasbt,2022-10-21 15:19:16+00:00,https://twitter.com/rasbt/status/1583478030928076800,@Diadochokinetik @hardmaru @karpathy @lexfridman Thanks for your supportive words üôè
2562,@rasbt,2022-10-21 15:17:03+00:00,https://twitter.com/rasbt/status/1583477473081032705,@anaganath Guess what I am doing sometime this weekend üôÑ https://t.co/wnFQ9gyM1i
2563,@rasbt,2022-10-21 14:16:30+00:00,https://twitter.com/rasbt/status/1583462232025083906,@tunguz @FrankRHutter @903124S @RichmanRonald Awesome initiative üëè ! Bookmarked that repo!
2564,@rasbt,2022-10-21 14:02:21+00:00,https://twitter.com/rasbt/status/1583458671345868800,@eerac Totally! The emphasis is on ‚ÄúA LOT‚Äù of fussing. I hates training GANs. Good riddance üòÖ
2565,@rasbt,2022-10-21 13:52:46+00:00,https://twitter.com/rasbt/status/1583456263110680576,@Sriraam_UTD Yeah! I remember reading  a paper ~1 year ago that focused on a DL architecture that lets domain experts encode constraints and guidance in the architecture. Cool stuff!
2566,@rasbt,2022-10-21 13:49:07+00:00,https://twitter.com/rasbt/status/1583455341454364684,@RichmanRonald @FrankRHutter @tunguz Whoa thanks üòç!!! Excited to add it to the list at https://t.co/VAXJRC49qR
2567,@rasbt,2022-10-20 17:04:03+00:00,https://twitter.com/rasbt/status/1583142011409862656,Full story here: https://t.co/spja3E5zRO
2568,@rasbt,2022-10-20 17:02:07+00:00,https://twitter.com/rasbt/status/1583141525071855616,"Whoa, way to go @eLife! This is the way! ML journals and conferences, pls take note. https://t.co/EBnCOraR8V"
2569,@rasbt,2022-10-20 16:57:55+00:00,https://twitter.com/rasbt/status/1583140469197877248,@michaelhoffman @GreeneScientist @eLife eLife ELI5 pls (no pun intended)
2570,@rasbt,2022-10-20 15:46:24+00:00,https://twitter.com/rasbt/status/1583122468419809281,@marktenenholtz Nice! Glad to hear they finally have multi-GPU support üéâ
2571,@rasbt,2022-10-20 14:31:34+00:00,https://twitter.com/rasbt/status/1583103638326894593,"@16363725q @hardmaru @karpathy @lexfridman Wow, I am really baffled to hear this.  supporting or excusing the Russian invasion is very saddening and deeply concerning"
2572,@rasbt,2022-10-20 13:16:45+00:00,https://twitter.com/rasbt/status/1583084810041724930,"@ljbuturovic I agree. On the flipside, isn't it a technique that you should (almost) always use anyways? I.e., it's a fundamental technique, like normalizing your data is a fundamental technique when you work with neural nets."
2573,@rasbt,2022-10-20 13:09:05+00:00,https://twitter.com/rasbt/status/1583082878484635649,"@16363725q @hardmaru @karpathy @lexfridman oops, actually had no idea. wasn't listening to his podcasts for 1-2 years or so since he blocked me"
2574,@rasbt,2022-10-20 13:07:20+00:00,https://twitter.com/rasbt/status/1583082439399813120,"@bindureddy Interesting point! Actually, I would say Langevin dynamics &amp; denoising autoencoders were more influential for diffusion models. Although GANs (and the frustration from training them) were probably inspiring as well!"
2575,@rasbt,2022-10-20 12:45:00+00:00,https://twitter.com/rasbt/status/1583076818978242560,@hardmaru @karpathy @lexfridman FAQ: ‚ÄúWhy did I get blocked?‚Äù üòÜ https://t.co/4bjWAgl826
2576,@rasbt,2022-10-20 12:39:00+00:00,https://twitter.com/rasbt/status/1583075308923629568,@nachimak28 @bindureddy Like ‚Äúthought leader‚Äù üòÜ
2577,@rasbt,2022-10-20 12:38:14+00:00,https://twitter.com/rasbt/status/1583075115259949056,"@sqcai ""The exception that proves the rule"" üòÑ"
2578,@rasbt,2022-10-20 12:33:15+00:00,https://twitter.com/rasbt/status/1583073861934862336,@bindureddy Is being an AI influencer a good or a bad thing ü§îüôÉ
2579,@rasbt,2022-10-20 12:30:02+00:00,https://twitter.com/rasbt/status/1583073051054571520,"Also, what happened to Capsule networks?"
2580,@rasbt,2022-10-20 12:28:59+00:00,https://twitter.com/rasbt/status/1583072787307974656,"@CSProfKGD @adjiboussodieng Yeah, it‚Äôs been some time, but now that you say that ‚Ä¶ ü§î"
2581,@rasbt,2022-10-20 12:27:02+00:00,https://twitter.com/rasbt/status/1583072297862066176,"@adjiboussodieng @CSProfKGD Haha, üíØ. Like, ‚Äúhey remember RNNs?‚Äù"
2582,@rasbt,2022-10-20 12:22:19+00:00,https://twitter.com/rasbt/status/1583071112732475395,@ljbuturovic I would say that cross-validation helps with assessing the performance fairly. However what do you then do if the performance is worse than expected? So the list above is a list of approaches to try to improve performance for (let‚Äôs say accurately) cross validated models
2583,@rasbt,2022-10-20 12:19:56+00:00,https://twitter.com/rasbt/status/1583070510996652032,"@GopakumarG @LightningAI Hm it‚Äôs more of a sanity check, you are not using the test labels here"
2584,@rasbt,2022-10-20 01:47:10+00:00,https://twitter.com/rasbt/status/1582911268196794369,@ezkvishal or generative modeling :)
2585,@rasbt,2022-10-20 01:46:56+00:00,https://twitter.com/rasbt/status/1582911211460472833,"@ChrisPliakos Ooph, yeah, I wish I had that ready at the tip of my fingers. I'll have to maybe write that up some time and recommend a few resources along with it. Definitely too much for a Twitter thread though üòÖ"
2586,@rasbt,2022-10-20 01:46:02+00:00,https://twitter.com/rasbt/status/1582910985559764993,"@cristi_vicas @ml_visoft I agree. Hah, but you can get very far these days with self-supervised learning. Particularly in NLP."
2587,@rasbt,2022-10-20 01:44:52+00:00,https://twitter.com/rasbt/status/1582910690255261696,"@alfarabyab Totally. I would say it falls under the category of data augmentation via ""synthetic data"""
2588,@rasbt,2022-10-20 01:44:23+00:00,https://twitter.com/rasbt/status/1582910570659188736,"@mazumdarabhinav To be honest, that's something I had to read up about üòÖ
https://t.co/VOITFDhnre"
2589,@rasbt,2022-10-20 01:43:38+00:00,https://twitter.com/rasbt/status/1582910382640726017,"@CalcCon hah yeah, it's been some time and I actually had to look that one up https://t.co/oCG4zyF6I1"
2590,@rasbt,2022-10-20 01:40:27+00:00,https://twitter.com/rasbt/status/1582909579486429185,"@RoskoNU yeah, or one might consider it as augmentation via ""synthetic data"""
2591,@rasbt,2022-10-20 01:39:12+00:00,https://twitter.com/rasbt/status/1582909266780098564,"@michaelaye Hm, in short, I would say it's a setting where you looked at learning curves and found that the model would substantially benefit from additional data"
2592,@rasbt,2022-10-20 01:37:40+00:00,https://twitter.com/rasbt/status/1582908878412713985,"@_Kcnarf hm yeah, that's a good question and good point! I would say that's typically a heuristic-based approach. One could consider that as weakly supervised (if it's an inaccurate heuristic) or self-supervised (if the label comes from something that is already inherent in the data)"
2593,@rasbt,2022-10-20 01:36:02+00:00,https://twitter.com/rasbt/status/1582908469321269248,@LeszBuk totally!
2594,@rasbt,2022-10-20 01:35:33+00:00,https://twitter.com/rasbt/status/1582908347610603522,"@O_igggy @DHolzmueller hm, maybe more like ""synthetic data"" generation"
2595,@rasbt,2022-10-20 01:27:18+00:00,https://twitter.com/rasbt/status/1582906268796477441,"@docs2info Good one! Considering the recent tooling and focus around this, I would maybe consider this as part of the data-centric AI wave."
2596,@rasbt,2022-10-20 01:26:19+00:00,https://twitter.com/rasbt/status/1582906024494649346,"@ayirpelle Thanks, that's a good one! I would say that contrastive learning (next to self-prediction methods like masked autoencoding) is one of the big subcategories of self-supervised learning."
2597,@rasbt,2022-10-19 20:39:40+00:00,https://twitter.com/rasbt/status/1582833884517240834,"@yudapearl Agreed. Regarding transfer learning, I think one can see it both ways: there is the lofty goal of knowledge transfer, and there is the hard, practical truth which consists of retraining one or more layers on a different dataset.
Thanks for the references btw, very useful!"
2598,@rasbt,2022-10-19 19:37:37+00:00,https://twitter.com/rasbt/status/1582818270574391303,@DSaience I am actually curious what gives you more FOMO: not learning ML or learning ML and realizing how vast and fast moving it is üôÉ
2599,@rasbt,2022-10-19 19:29:29+00:00,https://twitter.com/rasbt/status/1582816221594279936,"@karpathy Hah, yeah, in hindsight ‚Äúhaphazard‚Äù is spot on ‚Äî the nicer way to put it is ‚Äúahead of its time‚Äù üôÉ. And in a sense it‚Äôs the opposite approach that the perceptron papers took in the 1950s üòÜ"
2600,@rasbt,2022-10-19 18:12:55+00:00,https://twitter.com/rasbt/status/1582796956145168384,@KyleCranmer üíØ!
2601,@rasbt,2022-10-19 16:27:29+00:00,https://twitter.com/rasbt/status/1582770422793191424,"@kchonyc Haha. Also, the key difference between biologists and CS-AI people is that they (re)discover not reinvent things üòÜ"
2602,@rasbt,2022-10-19 16:24:09+00:00,https://twitter.com/rasbt/status/1582769582544068608,Maybe we can add @yudapearl ‚Äòs causal path diagrams to the list one day üòä
2603,@rasbt,2022-10-19 16:23:34+00:00,https://twitter.com/rasbt/status/1582769436838068228,"@ramin_m_h @maosbot Ah yes, inductive biases; adding convolutional layers to ViTs :P"
2604,@rasbt,2022-10-19 16:18:46+00:00,https://twitter.com/rasbt/status/1582768229151145985,"@1point618boy @maosbot I think, the simplest and model-agnostic implementation of that would be oversampling/dynamic sampling. Or replacing cross entropy with a focal loss in case of any standard neural network classifier."
2605,@rasbt,2022-10-19 16:06:49+00:00,https://twitter.com/rasbt/status/1582765220669579265,"@adjiboussodieng Ah yes, totally! Maybe that could go into a new category along the lines of ‚Äú‚Äòbootstrapping‚Äô the training set‚Äù (synthetic data, data augmentation, sampling, ‚Ä¶)"
2606,@rasbt,2022-10-19 16:04:13+00:00,https://twitter.com/rasbt/status/1582764565015986177,"@DHolzmueller Nice ones, yes! Initial reaction was that meta-learning is a subcategory of few-shot learning but I totally forgot about the other kind of meta-learning üòÜ"
2607,@rasbt,2022-10-19 16:02:40+00:00,https://twitter.com/rasbt/status/1582764175209529344,@masonkadem Like using focal loss? Yeah I can see that as a separate category
2608,@rasbt,2022-10-19 16:01:23+00:00,https://twitter.com/rasbt/status/1582763852357578753,@bozavlado That‚Äôs a good point as well!
2609,@rasbt,2022-10-19 16:00:28+00:00,https://twitter.com/rasbt/status/1582763620886536194,"@bozavlado Good one, I would group that under transfer learning but yeah maybe it should be a separate category"
2610,@rasbt,2022-10-19 15:20:18+00:00,https://twitter.com/rasbt/status/1582753515515961344,@DSaience Good point! I always thought of it as semi-supervised learning.
2611,@rasbt,2022-10-19 15:15:15+00:00,https://twitter.com/rasbt/status/1582752240967643136,"The 7 approaches for dealing with limited labeled data in supervised machine learning settings:

1 Transfer learning
2 Self-supervised learning
3 Semi-supervised learning
4 Active learning
5 Few/zero-shot learning
6 Weakly-supervised learning
7 Label more data!

Anything missing?"
2612,@rasbt,2022-10-19 14:38:52+00:00,https://twitter.com/rasbt/status/1582743088606646272,@nmvrodrigues In semi supervised learning you incorporate the confidence of you model itself; and for self supervised learning you use self-labeling. So I wouldn‚Äôt group them necessarily as weakly supervised. But yeah there are maybe weakly supervised flavors where you have some overlap
2613,@rasbt,2022-10-19 14:37:01+00:00,https://twitter.com/rasbt/status/1582742623269552128,"@nmvrodrigues There are at least 5 methods/approaches/techniques to work with limited data. You named two other ones üòä. However, I would see them as separate from weakly supervised learning since for those you don‚Äôt use heuristics to create more or less correct labels"
2614,@rasbt,2022-10-19 12:55:59+00:00,https://twitter.com/rasbt/status/1582717194508546048,"@ylecun Plus, in certain contexts, especially outside seminars, conferences, etc. it is also not a ""well-meaning"" exercise but more of a ""gotcha"" type of activity. No need to engage in all of it."
2615,@rasbt,2022-10-19 12:54:37+00:00,https://twitter.com/rasbt/status/1582716852131663872,"@ylecun I think that's a healthy way forward! In academia, we are trained to debate other people's viewpoints. It's a sport to find flaws and poke holes. Usually, it's a well-meaning exercise to improve the status quo (here: research). But yeah, sometimes too much is too much."
2616,@rasbt,2022-10-19 12:48:25+00:00,https://twitter.com/rasbt/status/1582715291813163008,"@danofer yes, actually, in many cases the the heuristics and the explicit rules are one and the same"
2617,@rasbt,2022-10-19 12:46:09+00:00,https://twitter.com/rasbt/status/1582714720225615876,@Centropy3 @Sidsharmaa22 @joshuastarmer Double BAM! @joshuastarmer is gold!
2618,@rasbt,2022-10-19 12:37:22+00:00,https://twitter.com/rasbt/status/1582712510997680131,"@GopakumarG @LightningAI What about mitigation methods? 
(1) Try to remove features one by one and recheck the accuracy. Maybe there is information leak in some of the features.
(2) If that doesn't help, try to remove training instances that are too different from the test data."
2619,@rasbt,2022-10-19 12:35:22+00:00,https://twitter.com/rasbt/status/1582712008125734919,"@GopakumarG @LightningAI If your test performance is much worse than the training performance, consider adversarial validation: 
create a target label ""partition"": train=0, val=1, test=2. Train the clf on the training data &amp; try to predict the partition. In case of high accuracy the data is badly sampled"
2620,@rasbt,2022-10-19 12:29:39+00:00,https://twitter.com/rasbt/status/1582710567189745665,@isaacfab00 @LightningAI 2/2 This is probably because in academia we only care about test set performance and don't actually need to use our models after reporting benchmark performance in our paper.
2621,@rasbt,2022-10-19 12:28:50+00:00,https://twitter.com/rasbt/status/1582710361580765186,"@isaacfab00 @LightningAI Same! I typically recommend using the combined dataas well (https://t.co/aYvW1694Bd), except using the validation set of k-fold CV for identifying best params.
Interestingly enough, training on the combined dataset confuses most people; 1/2 https://t.co/U6MWtrj89U"
2622,@rasbt,2022-10-19 12:25:14+00:00,https://twitter.com/rasbt/status/1582709458748469248,"*there is the whole field of weakly supervised learning though, where we use some approximate approach to provide noisy / imprecise target labels to jumpstart your supervised learning pipeline."
2623,@rasbt,2022-10-19 12:25:14+00:00,https://twitter.com/rasbt/status/1582709457208778753,"When creating hand-labeled data sets is unfeasible for supervised learning (or fine-tuning) we can use heuristics to create labels: Eg ""Subject: You've been chosen!"" -&gt; SPAM. 
Common Q: Why using ML then at all? Heuristics usually only cover a small fraction of the data reliably."
2624,@rasbt,2022-10-19 02:07:40+00:00,https://twitter.com/rasbt/status/1582554039564181504,"@airwoz @Sidsharmaa22 2/2 I don't recall the exact timeline; it's years since I read the papers. But Friedman's gradient boosting came before that afaik. I.e., GB 2001 whereas SAMME was 2006?"
2625,@rasbt,2022-10-19 02:06:09+00:00,https://twitter.com/rasbt/status/1582553659459584000,@airwoz @Sidsharmaa22 The multi-class adaboost algorithm (SAMME) also exists as a separate paper (https://t.co/uGXrrarXgg); I remember because I had one student developing a modified version as a class project once :P 1/2
2626,@rasbt,2022-10-18 21:49:51+00:00,https://twitter.com/rasbt/status/1582489161440763905,"@momarnasir @ylecun @Grady_Booch not an expert in this, but a royalty-based model could be a win-win: if the company profits, the artists profit. Also, saves the company legal fees fighting of copyright lawsuits, and maybe artists would be willing to contribute higher-res, non-watermarked versions to a database"
2627,@rasbt,2022-10-18 20:11:09+00:00,https://twitter.com/rasbt/status/1582464322546339840,"@ylecun @Grady_Booch Sure, but it doesn‚Äôt mean that when artists are concerned, we (AI researchers) have to respond with counterpoints that alienate artists. The world would be a better place if we listened &amp; were sympathetic to these concerns. 
Kudos to the 1st company that‚Äôll pay artists royalties."
2628,@rasbt,2022-10-18 16:46:34+00:00,https://twitter.com/rasbt/status/1582412836013506561,"@bernhardsson Yes, oil as in ‚Äúnew oil painting‚Äù"
2629,@rasbt,2022-10-18 16:42:54+00:00,https://twitter.com/rasbt/status/1582411914730426375,@giffmana @deliprao @MetaAI 20 thousand thousands ü§Ø
2630,@rasbt,2022-10-18 16:40:47+00:00,https://twitter.com/rasbt/status/1582411379733954563,@deliprao @MetaAI I have an idea of what that amazing thing could look like: a blazing fast CI solution for the PyTorch repo to encourage contributions &amp; a more comprehensive torch hub space for pretrained models üöÄ
2631,@rasbt,2022-10-18 16:10:27+00:00,https://twitter.com/rasbt/status/1582403744834035712,@LightningAI your gentle reminder not to tune your model on the test set üò¨
2632,@rasbt,2022-10-18 15:12:15+00:00,https://twitter.com/rasbt/status/1582389100161953792,"@beenwrekt @PrincetonUPress Congrats üéâ! Was just skimming the TOC, and seems both compact &amp; comprehensive. I am particularly interested in the causality-related chapters. Will be getting a copy üòä"
2633,@rasbt,2022-10-18 14:54:53+00:00,https://twitter.com/rasbt/status/1582384728677965827,"@ZachariahNKM Huh, that's a cool insight! I actually never thought about that! Thanks for sharing!"
2634,@rasbt,2022-10-18 14:05:28+00:00,https://twitter.com/rasbt/status/1582372294454038530,"@moyix The most awesome idea I heard in a long time üëè! 
(The final thesis is then an arxiv article + blogpost documenting the lessons and challenges for the future generations)"
2635,@rasbt,2022-10-18 13:00:39+00:00,https://twitter.com/rasbt/status/1582355979991019521,"@Sidsharmaa22 Shameless plug: For the idea behind gradient boosting, I have a section on how gradient boosting for classification works in my book; I think that's the only resource that describes it for classification, not regression (couldn't find anything else when I was writing this)"
2636,@rasbt,2022-10-18 12:59:22+00:00,https://twitter.com/rasbt/status/1582355657688170497,"@Sidsharmaa22 I would start with the original gradient boosting paper (""Greedy function approximation""). Then, the XGB and LightGBM papers -- they are ""hacks"" (in a positive sense) that make it work well in practice."
2637,@rasbt,2022-10-18 12:50:35+00:00,https://twitter.com/rasbt/status/1582353448208830466,"This!
PS: here's some trivia about XGBoost &amp; LightGBM since their diff is a FAQ in class: 

XGBoost's trees are based on breadth-first search, comparing diff features at each node.

LightGBM performs depth-first search, focusing on a single feature &amp; growing the tree from there."
2638,@rasbt,2022-10-18 12:45:39+00:00,https://twitter.com/rasbt/status/1582352205222359042,"@SaraBolouki Good question. That was back in 2012. Not sure if that class still requires matlab. Tbf, another Pattern Rec class I took in grad school (same year) was also based on matlab, but the prof also let me submit the homework in PyTorch -- only the results mattered, which was nice!"
2639,@rasbt,2022-10-18 12:44:11+00:00,https://twitter.com/rasbt/status/1582351836249325569,"@FaisalAlsrheed Glad to hear üôå! November is only a few weeks away, and I can't wait to share the next issue! (Btw that's a nice and impressive collection of decks! Kudos!)"
2640,@rasbt,2022-10-18 02:02:46+00:00,https://twitter.com/rasbt/status/1582190418154106880,"@DavidClark314 @karpathy I was at an in-person data science seminar once by one of the reddit data scientists &amp; app developers. Lots of focus on A/B testing rather than just rational design.
That was like ~6 years ago. Looks like nothing really changed. 
(DS-wise, was an interesting seminar though, lol)"
2641,@rasbt,2022-10-18 00:14:08+00:00,https://twitter.com/rasbt/status/1582163082029461504,@joshuastarmer Awesome topic choice! It‚Äôs one of these tricks of the trade that is often used in practice but is missing from most ML curricula! üòä
2642,@rasbt,2022-10-17 19:40:17+00:00,https://twitter.com/rasbt/status/1582094164849618944,"@mpaepper I think key is to include good &amp; comprehensive unit tests. But yeah, I totally agree"
2643,@rasbt,2022-10-17 19:27:43+00:00,https://twitter.com/rasbt/status/1582091003900854272,"@GitHubNext Oh no worries, and thanks for the note! The fact that it works at all is already pretty magical. I thought this maybe just slipped through the cracks."
2644,@rasbt,2022-10-17 18:49:47+00:00,https://twitter.com/rasbt/status/1582081455173570562,"@arian4n Hah yes, totally! I thought I was the only one finding this weird"
2645,@rasbt,2022-10-17 15:27:49+00:00,https://twitter.com/rasbt/status/1582030627984969728,"@GitHubNext This is great, but one question: why is the code output on the right not shown in the same mono space font (or any mono space font) as the content on the left? It‚Äôs a bit hard to read the translated code imho."
2646,@rasbt,2022-10-17 15:19:27+00:00,https://twitter.com/rasbt/status/1582028524223102978,@muralijnu1 @tunguz @xamat Random forests. I have also seen people bagging XGBoost; search for ‚Äúbagging of Xgboost‚Äù on Google Scholar for example
2647,@rasbt,2022-10-17 15:10:02+00:00,https://twitter.com/rasbt/status/1582026155582160896,@tunguz @xamat * and bag &amp; bootstrap them!
2648,@rasbt,2022-10-17 15:06:52+00:00,https://twitter.com/rasbt/status/1582025355631550465,@xamat @tunguz On top of that (no pun intended) kagglers like to stack them
2649,@rasbt,2022-10-17 15:04:26+00:00,https://twitter.com/rasbt/status/1582024746455027712,"Re Copilot: I think I finally get it.

Took a data mining class in grad school where I had to submit my homework in MATLAB. 

I could solve it in Python üêç in no time. But then translating the code to MATLAB for submission was the hard part üò≠

This would have been godsend!"
2650,@rasbt,2022-10-17 14:24:21+00:00,https://twitter.com/rasbt/status/1582014655936880641,@Jake_Color üíØ! I do the same thing!
2651,@rasbt,2022-10-17 13:13:25+00:00,https://twitter.com/rasbt/status/1581996807076208645,"This! Many people dismiss memorization. 
Sure, ""understanding"" a concept &gt; than memorizing facts.
But memorized facts are often a great thing to have in the back of your head -- makes it easier to find quirks &amp;  bugs in your work. 
That's why I add lots of trivia to my Anki decks https://t.co/VCWjZxJ7ci"
2652,@rasbt,2022-10-17 13:01:36+00:00,https://twitter.com/rasbt/status/1581993831288823811,"@_florianmai @francoisfleuret @Smerity 4/4 Or, in other words, if I were to run @tunguz's LSTM, I am fairly certain that I'd introduce certain biases; whether it's because I don't give it that much attention (no pun intended), because I don't have the same expertise, etc."
2653,@rasbt,2022-10-17 12:59:43+00:00,https://twitter.com/rasbt/status/1581993360939622402,"@_florianmai @francoisfleuret @Smerity 3/ but often ""x of y"" is not the optimal setting for the other methods, thus resulting in a biased comparison. It's fairer to just let multiple people try their best to make a method work on a benchmark dataset / Kaggle competition."
2654,@rasbt,2022-10-17 12:58:29+00:00,https://twitter.com/rasbt/status/1581993048057470979,"@_florianmai @francoisfleuret @Smerity 2/ so they spend a lot of time on that particular method to make it work as well as possible. Now, once that's done, they run other methods rather half-heartedly. I.e., if I need x of y to make the new method work well, they will use a similar settings for the other methods ..."
2655,@rasbt,2022-10-17 12:57:11+00:00,https://twitter.com/rasbt/status/1581992720431599618,"@_florianmai @francoisfleuret @Smerity *A little add-on: I think that independent benchmarks where a single person/team focuses on only their particular, chosen method is often more unbiased than an academic study. The problem of academic studies is that a person/group wants to establish a new method, 1/n"
2656,@rasbt,2022-10-17 12:53:20+00:00,https://twitter.com/rasbt/status/1581991750939574273,"@_florianmai @francoisfleuret @Smerity 2/2 It There are already studies showing that transformers perform better than pretrained LSTMs. Since we were talking about BERT, we can consider the original BERT paper: https://t.co/D4DWdWK1Dy"
2657,@rasbt,2022-10-17 12:48:28+00:00,https://twitter.com/rasbt/status/1581990526714138626,"@_florianmai @francoisfleuret @Smerity Sure. If this was an academic study I'd agree. But if someone claims on a Kaggle competition that the LSTM is better, I think that's up to the person pretraining their LSTM properly. Training someone else's method almost always gives biased results due to lack in motivation 1/2"
2658,@rasbt,2022-10-16 20:24:02+00:00,https://twitter.com/rasbt/status/1581742785194958849,"@suzatweet @karpathy The original, I watched it so many times. I was positively surprised by 2049 and like it a lot, too."
2659,@rasbt,2022-10-16 19:00:23+00:00,https://twitter.com/rasbt/status/1581721734796804096,"@CalcCon @tunguz yap, it looks like it. there's a test_labels. csv. zip in the dataset folder"
2660,@rasbt,2022-10-16 18:03:35+00:00,https://twitter.com/rasbt/status/1581707441753817090,@karpathy Blade Runner!
2661,@rasbt,2022-10-16 17:55:10+00:00,https://twitter.com/rasbt/status/1581705324473749504,@officialKrishD @tunguz Thanks ü´∂üòä
2662,@rasbt,2022-10-16 17:48:46+00:00,https://twitter.com/rasbt/status/1581703711705169921,@_florianmai @francoisfleuret Maybe let's rephrase it like this: It's always possible to find &amp; fine-tune a transformer model such that it outperforms the best LSTM model on that same language modeling task.
2663,@rasbt,2022-10-16 17:47:40+00:00,https://twitter.com/rasbt/status/1581703434952404993,"@_florianmai @francoisfleuret Of course you can't take this statement 100% literally. Otherwise you can always create counter-examples. E.g., one fine-tune the transformer improperly and create countless examples where the transformers would  underperform."
2664,@rasbt,2022-10-16 17:47:12+00:00,https://twitter.com/rasbt/status/1581703318887284737,"@_florianmai @francoisfleuret And in the same table above, you see transformers outperforming that LSTM."
2665,@rasbt,2022-10-16 17:32:41+00:00,https://twitter.com/rasbt/status/1581699666768371713,"@_florianmai How do you define ""pretrained LSTMs""? GloVE is a kind of pre-training. Or full transfer learning, or self-supervised learning? I'd say an interesting experiment would be running ULMFiT on that Kaggle dataset. Here's a relatively easy impl. you could try: https://t.co/jrSQHnJoWf"
2666,@rasbt,2022-10-16 16:41:09+00:00,https://twitter.com/rasbt/status/1581686697812963329,@deliprao @francoisfleuret Most people do use scaled dot product attention though (aka ‚Äúvanilla‚Äù self-attention). I think it‚Äôs probably because the MLP layers are more of a bottleneck then the self attention itself
2667,@rasbt,2022-10-16 16:38:07+00:00,https://twitter.com/rasbt/status/1581685931756908545,@_florianmai It‚Äôs really not
2668,@rasbt,2022-10-16 14:48:55+00:00,https://twitter.com/rasbt/status/1581658453466320896,@SapkotaTsuman @francoisfleuret The recent State of AI 2022 picked that up as well https://t.co/9MMGd7JpCK https://t.co/PxBQglMpAX
2669,@rasbt,2022-10-16 14:46:46+00:00,https://twitter.com/rasbt/status/1581657912304246784,"@SapkotaTsuman @francoisfleuret Yes üíØ. In practice, memory doesn't seem to be a big deal for most so people mostly ignore these though https://t.co/Ggja5jI6N9"
2670,@rasbt,2022-10-16 14:18:34+00:00,https://twitter.com/rasbt/status/1581650814820491264,"@EnesGokce01 @rupspace Yes, well said."
2671,@rasbt,2022-10-16 13:27:34+00:00,https://twitter.com/rasbt/status/1581637980476743686,"@francoisfleuret Regarding weaknesses; hm, yeah, GPU memory requirements for fine-tuning perhaps. Or maybe the limited-length contexts (usually 512 tokens) -- but it's not that RNNss can deal with longer sequences (theoretically yes, but they are also quite forgetful despite LSTMs)"
2672,@rasbt,2022-10-16 13:25:21+00:00,https://twitter.com/rasbt/status/1581637423607709698,"@francoisfleuret Yes &amp; Yes. An empirical observation that I've never seen / experienced an LSTM outperforming a transformer on a language task. And with ""time series"" I was paraphrasing that you are better of skipping LSTMs for natural language processing tasks."
2673,@rasbt,2022-10-16 12:49:01+00:00,https://twitter.com/rasbt/status/1581628276941864962,"@lies_and_stats @tunguz üíØ! Yes I did üòä

https://t.co/GJEdFy1sc5"
2674,@rasbt,2022-10-16 12:47:19+00:00,https://twitter.com/rasbt/status/1581627852109201410,@MatthBogaert @tunguz Yeah I agree. No didn‚Äôt try it yet because I wasn‚Äôt sure if the Kaggle GPU could handle it. It probably can but I wanted something relatively small that finishes in like a handful of hours on Kaggle so that I don‚Äôt have to wait all weekend lol
2675,@rasbt,2022-10-16 12:45:48+00:00,https://twitter.com/rasbt/status/1581627470264299520,@ricardoaraujo @davisblalock @tunguz That‚Äôs a good question; the problem is that I don‚Äôt think there are any publicly available LSTMs that have been pretrained in a self-supervised fashion.
2676,@rasbt,2022-10-16 12:44:42+00:00,https://twitter.com/rasbt/status/1581627190407761920,"@CalcCon @tunguz Good find! Hm, 98.2. Not bad but not better. I do think with a regular BERT (or Roberta or anything newer) you can easily get 99. But DistilBert is my got to as a convenient baseline since it‚Äôs small and runs on my old, small GPUs"
2677,@rasbt,2022-10-16 12:41:07+00:00,https://twitter.com/rasbt/status/1581626288707874816,"@ryan_chesler @marktenenholtz @tunguz Yes, it‚Äôs with a pre trained BERT. Sure you can design a study and use pre-trained LSTM models and compare; would be interesting.
For a practical scenario, do you know any publicly available LSTMs that have been pertained on a large corpus in self-supervised fashion?"
2678,@rasbt,2022-10-15 18:56:41+00:00,https://twitter.com/rasbt/status/1581358416433655808,"@CalcCon @tunguz Sure, Bert is a 4 year old model. Not claiming it's the best. 
Haha, but I already spent my morning running this thing. It's your turn now to try XLNet and let us know what you find ‚ò∫Ô∏è"
2679,@rasbt,2022-10-15 18:53:54+00:00,https://twitter.com/rasbt/status/1581357717486084096,"@davisblalock @tunguz They are good points, but each of these things would be a pretty involved research project with many ablation studies. In the end, the question was simply transformer &gt; LSTM for text; the questions you raise are interesting follow-up details."
2680,@rasbt,2022-10-15 18:52:04+00:00,https://twitter.com/rasbt/status/1581357254783078400,"@tunguz maybe also combine your preprocessing code with the transformer. I just omitted it because I didn't have that much time this morning and your code looked rather involved with the binaries and so forth. But yeah, I think you can probably get that running more easily"
2681,@rasbt,2022-10-15 18:44:11+00:00,https://twitter.com/rasbt/status/1581355270936334337,"@marktenenholtz @tunguz Been there, done that on smaller datasets. Transformers are probably always going to be superior on text datasets of all sizes. https://t.co/Cm0nTNSkeX

(Haven't looked at ULMFiT and ELMO though; are they still relevant?)"
2682,@rasbt,2022-10-15 18:31:59+00:00,https://twitter.com/rasbt/status/1581352201020399616,"@tunguz Oh yeah, here you go, have fun ‚ò∫Ô∏èhttps://t.co/rYlQmwnsCd

(PS: You can maybe also start by just running it a few more epochs. That was just arbitrary so that it finished in a few hours because I gotta go, haha)"
2683,@rasbt,2022-10-15 18:28:19+00:00,https://twitter.com/rasbt/status/1581351277686312960,"@tunguz Hah, yeah, also look at how lean and simple the code is. The hyperparameter settings are arbitrary. Spend a few hours tuning, and you can probably get ~0.99. 
But yeah, I didn't intend to spend my whole weekend on that ‚ò∫Ô∏è"
2684,@rasbt,2022-10-15 18:27:03+00:00,https://twitter.com/rasbt/status/1581350959921254400,"I stand by my point: For text datasets, anywhere from 100 examples to 1 million examples (and beyond), LSTMs are outdated. Use a simple logistic regression model + BoW as a baseline; then use an off-the-shelf transformer. LSTM is only relevant for time series."
2685,@rasbt,2022-10-15 18:27:03+00:00,https://twitter.com/rasbt/status/1581350958319435777,"No data engineering, nothing. Also take a look at my relatively straight-forward code: https://t.co/tESqwQ4TlH

Now, compare that to all the data engineering and tweaking that had to go into the LSTM ü§Ø: https://t.co/t8FhuWx98a"
2686,@rasbt,2022-10-15 18:27:02+00:00,https://twitter.com/rasbt/status/1581350956910116864,"Here's the code if you want to take a look: https://t.co/D8gVs7ebqH

I started it this morning and it took 4.5 h to run. I ran it in the Kaggle environment.

Again, I want to emphasize that I didn't do any feature engineering, no tweaking. This is literally the first model"
2687,@rasbt,2022-10-15 18:20:58+00:00,https://twitter.com/rasbt/status/1581349428161495040,"Challenge accepted! To show that BERT &gt; LSTM, I just ran an off-the-shelf DistilBert model &amp; got almost identical perf (0.985 vs 0.986) on the 1st try -- didn't tweak anything.
With more time, I'd probably beat it easily.
(How many hours did you spent on the data &amp; LSTM @tunguz?) https://t.co/Sxm5sXrqWH"
2688,@rasbt,2022-10-15 15:54:25+00:00,https://twitter.com/rasbt/status/1581312547810312192,@marktenenholtz üòá
2689,@rasbt,2022-10-15 15:27:13+00:00,https://twitter.com/rasbt/status/1581305701283946497,"@CalcCon @SapkotaTsuman @tunguz üíØ. That was my original point as well, which why I was surprised we were having this discussion ^^ https://t.co/8k1lPGmKns"
2690,@rasbt,2022-10-15 15:26:22+00:00,https://twitter.com/rasbt/status/1581305489731698688,"@CalcCon @SapkotaTsuman @tunguz no hard feeling, but I would say probably should let the SVM discussion go and do other things üòä. Anyways, was a good discussion and I like the back and forth; it's a good way to exchange views and experiences and learn new things"
2691,@rasbt,2022-10-15 15:21:27+00:00,https://twitter.com/rasbt/status/1581304250092556291,"@CalcCon @SapkotaTsuman @tunguz The thing is that we were talking about nonlinear SVMs, but then you mentioned you only talk about linear SVM and everything got confusing. Not that I disagree with your linear SVM arguments, but you were responding to a thread on nonlinear SVMs and that got very confusing."
2692,@rasbt,2022-10-15 15:19:23+00:00,https://twitter.com/rasbt/status/1581303730669965314,"@CalcCon @SapkotaTsuman @tunguz I agree that kernel SVMs on GPUs are more feasible now. I mean there are two bottlenecks: 1) the memory requirement for the n^2 distance matrix. Can be solved with recomputing distances on the fly. If that's implemented in the algo, GPUs can of course be an option for large data"
2693,@rasbt,2022-10-15 15:13:13+00:00,https://twitter.com/rasbt/status/1581302179154915328,@CalcCon @SapkotaTsuman @tunguz https://t.co/JDfMauqtvc
2694,@rasbt,2022-10-15 15:09:39+00:00,https://twitter.com/rasbt/status/1581301282341429248,@CalcCon @SapkotaTsuman @tunguz I don't think any of them will result in sparse gram matrices
2695,@rasbt,2022-10-15 15:07:32+00:00,https://twitter.com/rasbt/status/1581300749610668032,"@CSProfKGD @ducha_aiki Yes, thanks for saying that. I feel the same way. It's also way easier to format your paper using this layout template compared to double-column. Esp. if you have longer equations."
2696,@rasbt,2022-10-15 15:06:20+00:00,https://twitter.com/rasbt/status/1581300446660263936,"@SapkotaTsuman @tunguz @CalcCon This general thread is also a bit confusing btw . It started started w ""How much slower are the non-linear SVMs?""
https://t.co/80CckUYbc8
and then immediately below ""The non-linear SVM is useless nonsense"" 

But then then everyone else was talking about linear SVMs. I lost track."
2697,@rasbt,2022-10-15 15:03:16+00:00,https://twitter.com/rasbt/status/1581299674245255168,@SapkotaTsuman @tunguz @CalcCon Yeah you can find sparse kernels. I was thinking about the default RBF kernel for nonlinear SVMs. Keeping the pairwise gram matrix is expensive if you have a large training set.
2698,@rasbt,2022-10-15 13:31:41+00:00,https://twitter.com/rasbt/status/1581276627920916486,"@ducha_aiki @CSProfKGD Fair, but take the most popular machine learning paper publication venue: NeurIPS. It‚Äôs single column and despite that it‚Äôs very readable to me. I also love the margin for note taking, which is what many double column paper layouts lack"
2699,@rasbt,2022-10-14 21:12:57+00:00,https://twitter.com/rasbt/status/1581030322103144448,"@JayHadHope @deliprao I actually didn‚Äôt have nausea or headaches (only tried it for 30 min though) but I just didn‚Äôt like having it on my head. Heavy, stuffy, etc. I can‚Äôt imagine wearing it regularly tbh."
2700,@rasbt,2022-10-14 19:43:09+00:00,https://twitter.com/rasbt/status/1581007722517929990,"@CalcCon @tunguz Exactly, thanks! That was what I was originally talking about."
2701,@rasbt,2022-10-14 19:38:48+00:00,https://twitter.com/rasbt/status/1581006627389378560,@CalcCon @tunguz I am totally getting lost now but weren't we talking about nonlinear kernel SVMs? https://t.co/iGo98Cwlb5
2702,@rasbt,2022-10-14 19:37:22+00:00,https://twitter.com/rasbt/status/1581006268507955200,"@CalcCon @tunguz Nice, I should really check that out some time. Sorry, @tunguz &amp; @CalcCon, my claims above were all assuming the traditional implementation (LIBSVM and/or sklearn)"
2703,@rasbt,2022-10-14 19:31:54+00:00,https://twitter.com/rasbt/status/1581004890318376960,@CalcCon @tunguz Except liblinear only works for the linear case not RBF kernels!?
2704,@rasbt,2022-10-14 19:30:57+00:00,https://twitter.com/rasbt/status/1581004653801504768,@tunguz @CalcCon I was more thinking about the pairwise kernel matrix
2705,@rasbt,2022-10-14 17:58:44+00:00,https://twitter.com/rasbt/status/1580981444012216320,"@deliprao My partner got a quest 2 from work, I tried it and absolutely don‚Äôt like it. Sure looks cool for 10 minutes but it‚Äôs so uncomfortable. I am open to trying again once they come in the size of regular (sun)glasses"
2706,@rasbt,2022-10-14 17:24:46+00:00,https://twitter.com/rasbt/status/1580972896876662785,@tunguz @CalcCon I don't think it should/will be sparse ü§î
2707,@rasbt,2022-10-14 17:15:48+00:00,https://twitter.com/rasbt/status/1580970641440006144,"@tunguz @CalcCon Yap, please do and try it on the exact same Toxicity dataset above with a reasonable vocab size. I want to see how that handles a 100,000^2 matrix"
2708,@rasbt,2022-10-14 17:13:07+00:00,https://twitter.com/rasbt/status/1580969965385322496,"@CalcCon @tunguz Well, it certainly doesn't work on my computer with 64 Gb RAM."
2709,@rasbt,2022-10-14 17:10:58+00:00,https://twitter.com/rasbt/status/1580969424260984833,"@tunguz @CalcCon non-linear SVM wouldn't even work for this, even for inference because of the memory requirements for BoW."
2710,@rasbt,2022-10-14 17:05:23+00:00,https://twitter.com/rasbt/status/1580968018536194050,"@johnny_glatt @CalcCon @tunguz For generative models, yes, but not for predictive models like the classification model we were originally talking about above :P"
2711,@rasbt,2022-10-14 17:04:31+00:00,https://twitter.com/rasbt/status/1580967800490717184,"@CalcCon @tunguz Yup, I don't disagree. (But we are still talking about a kaggle competion above :P) https://t.co/4gfrjZySSx"
2712,@rasbt,2022-10-14 16:59:31+00:00,https://twitter.com/rasbt/status/1580966541193269251,@CalcCon @tunguz Btw you do know that Google itself switched to BERT for search a few years ago? It's all doable with low latency.
2713,@rasbt,2022-10-14 16:58:16+00:00,https://twitter.com/rasbt/status/1580966229094805528,"@CalcCon @tunguz Fair, I agree. But this is a Kaggle competition! üòÜ"
2714,@rasbt,2022-10-14 15:03:22+00:00,https://twitter.com/rasbt/status/1580937312003031041,"@CSProfKGD There is a reason books have a single column format. Way more pleasant to read. Double column makes only sense if you want to save printing costs (newspapers, physical magazines)"
2715,@rasbt,2022-10-14 15:01:37+00:00,https://twitter.com/rasbt/status/1580936874167652354,@CSProfKGD @DrMachinestein But that‚Äôs just because the guidelines are silly. If you set the page limit to 8 page double column or 10 page single column it would solve the problem.
2716,@rasbt,2022-10-14 14:59:16+00:00,https://twitter.com/rasbt/status/1580936281835855872,@LukasGalke @tunguz Plus it kinda sucks on small datasets (see below)
2717,@rasbt,2022-10-14 14:57:49+00:00,https://twitter.com/rasbt/status/1580935918508130306,@LukasGalke @tunguz If you have the resources for BoW + MLP (given reasonable vocabulary sizes) you probably also have the resources for DistilBert
2718,@rasbt,2022-10-14 13:20:37+00:00,https://twitter.com/rasbt/status/1580911453359308801,"@simransrahman they do a good job at confusing the general public &amp; feeding the public outrage machine while, at the same time, publishing an embarrassing article so that no researcher takes them seriously anymore."
2719,@rasbt,2022-10-14 13:08:01+00:00,https://twitter.com/rasbt/status/1580908284902789121,"@giffmana @M2lSchool Weekend ahead, great timing! üçø"
2720,@rasbt,2022-10-14 13:02:27+00:00,https://twitter.com/rasbt/status/1580906881627066371,@tunguz @adhinga_fred Nice thanks!
2721,@rasbt,2022-10-14 13:01:17+00:00,https://twitter.com/rasbt/status/1580906590076796928,"Yes, in other words, AlphaFold skips the actual ""folding"" part. 

(Continuing with my coffee analogy I made before: based on the ingredients &amp; instructions, it could predict how the coffee would look like/taste, but it wouldn't learn the sequence of actions required to make it!)"
2722,@rasbt,2022-10-14 12:57:29+00:00,https://twitter.com/rasbt/status/1580905634882457600,"@parker_brydon Feel free to use it as a blueprint for any kind of app / ML model! Also, if someone wants a bottom-up view regarding Lightning, here it is: https://t.co/LKeu5EtQxm"
2723,@rasbt,2022-10-14 12:56:00+00:00,https://twitter.com/rasbt/status/1580905258766594049,"@adhinga_fred @tunguz Actually, I think it would make sense to share your dataset with us @tunguz, unless you didn't spend any time on modifying it. Otherwise, if we just quickly ran a DistilBert on it, it would not take any extras like dataset preprocessing &amp; engineering into account (if applicable)"
2724,@rasbt,2022-10-14 12:54:08+00:00,https://twitter.com/rasbt/status/1580904791139504129,@TheSeaMouse just wow üò¨
2725,@rasbt,2022-10-14 12:51:59+00:00,https://twitter.com/rasbt/status/1580904248983703552,"@parker_brydon Cool! If you give it a try, I am curious to hear your feedback! Btw you can use that as a blueprint for other types of models as well. And if you are curious how the Lightning Framework works under the hood, I have a bottom-up explanation here: https://t.co/LKeu5EtQxm"
2726,@rasbt,2022-10-14 12:50:15+00:00,https://twitter.com/rasbt/status/1580903814634573828,@python_engineer @AssemblyAI Thanks üôå
2727,@rasbt,2022-10-14 12:49:47+00:00,https://twitter.com/rasbt/status/1580903694081458176,@Iseefire000 @d_v_dlee Btw I think ONNX runtimes even supports quantization down to 8 bit (haven't tried that in practice though yet)
2728,@rasbt,2022-10-14 02:11:40+00:00,https://twitter.com/rasbt/status/1580743108513304576,"@mariofilhoml Haha! The bigger picture is of course that were are trying to make the deployment easier via Lightning ... which is not necessarily helping with the addition issue lol.

And yeah ... stay tuned, we will have another fun app coming out soon! üòä"
2729,@rasbt,2022-10-14 02:02:24+00:00,https://twitter.com/rasbt/status/1580740776061206529,@ArturSilic @tunguz I don't disagree üòä
2730,@rasbt,2022-10-14 01:41:17+00:00,https://twitter.com/rasbt/status/1580735462645280768,"@aniketvartak 2/2 I think knowledge distillation is quite rare. But both pruning and tensor decomposition are probably common; e.g., consider DistilBert, SqueezeNet, MobileNet ... all were popular architectures at some point."
2731,@rasbt,2022-10-14 01:39:46+00:00,https://twitter.com/rasbt/status/1580735078980018177,"@aniketvartak there are different types of quantization, but I do e.g. quantization-aware training all the time. For inference, dynamic quantization is also quite common. I don't have numbers on these things though.  1/2"
2732,@rasbt,2022-10-14 01:35:06+00:00,https://twitter.com/rasbt/status/1580733904511676416,"@Machine01776819 Huh, interesting, I thought I have seen the Sparse Weight Activation acronym but no, that's stochastic weight averaging; need to look into this other type of SWA. Thanks for sharing."
2733,@rasbt,2022-10-13 21:51:49+00:00,https://twitter.com/rasbt/status/1580677716650909696,*for model compression. Where is the edit button when you need it!? üòÜ
2734,@rasbt,2022-10-13 21:43:35+00:00,https://twitter.com/rasbt/status/1580675645134495744,"4) Low-rank tensor decomposition (/low-rank factorization) is about reducing tensor (/matrix) sizes. A popular example is the depthwise separable convolution of MobileNet, decomposing a standard conv layer into a 3x3 depthwise + 1x1 pointwise convolution https://t.co/qgvay348af https://t.co/cvCoQY6exa"
2735,@rasbt,2022-10-13 21:43:35+00:00,https://twitter.com/rasbt/status/1580675643242876928,"3) In knowledge distillation, we train a large ""teacher"" net &amp; train a smaller ""student"" net on the labels (or calibrated probas) produced by the teacher. The goal is for the student to match or outperform the teacher with fewer params.
Great survey here: https://t.co/p68Z7GKOix https://t.co/i86inDUhHx"
2736,@rasbt,2022-10-13 21:43:34+00:00,https://twitter.com/rasbt/status/1580675640831152130,"2) Pruning is about removing nodes to reduce the total # of parameters. In practice, we don't really ""remove"" the nodes but zero the weights to induce sparsity &amp; lower storage req. The common &amp; classic example is The Lottery Ticket Hypothesis literature, https://t.co/XouGEsRxfx https://t.co/NGUnxVMiCy"
2737,@rasbt,2022-10-13 21:43:34+00:00,https://twitter.com/rasbt/status/1580675638695845889,"1) Quantization is probably the most widely used method today. Switching from, e.g., 32-bit to 16-bit precision reduces your storage needs by ~half. (There are different quantization paradigms, but that's a story for another time!
My favorite example here: https://t.co/xoXE0AUjxu https://t.co/K899Aifz5H"
2738,@rasbt,2022-10-13 21:43:33+00:00,https://twitter.com/rasbt/status/1580675636447784961,"Improving model inference speeds round #2.

Let's have a look at the 4 common approaches to model compression! 

1) Quantization
2) Pruning
3) Knowledge Distillation
4) Low-rank tensor decomposition

(Anything missing?)

1/4 üëá"
2739,@rasbt,2022-10-13 21:05:57+00:00,https://twitter.com/rasbt/status/1580666172663418880,"@tunguz That's fair, even DistilBert requires a GPU with like &gt;8 Gb VRAM and maybe 2-3 hours for fine-tuning. Not sure what the Kaggle resources are for those competitions."
2740,@rasbt,2022-10-13 21:04:42+00:00,https://twitter.com/rasbt/status/1580665857440509952,"@tunguz Sure, but what's the gap between BoW+LR and a transformer (e.g., DistilBert) you are observing? I have yet to see a small dataset problem where transformers are worse than BoW"
2741,@rasbt,2022-10-13 20:58:53+00:00,https://twitter.com/rasbt/status/1580664395360653312,"@tunguz But you know what, I will actually try to run that some time this month and let you know ;)"
2742,@rasbt,2022-10-13 20:55:25+00:00,https://twitter.com/rasbt/status/1580663520483774464,"@tunguz BoW is a good baseline to start with. Would definitely recommend that, sure. But it's not necessarily a good model in terms of predictive performance. 
Yes, I should do that some time!
In the meantime: just curious, you had no luck with transformers on Kaggle yet?"
2743,@rasbt,2022-10-13 20:46:35+00:00,https://twitter.com/rasbt/status/1580661296852520960,"@tunguz Haha, yeah, I really should seriously get into Kaggle one day. But yeah, here are some results. In my experience, LSTM is horrible for small datasets. https://t.co/pBE3Kx13Z4"
2744,@rasbt,2022-10-13 20:39:26+00:00,https://twitter.com/rasbt/status/1580659499521970176,"@tunguz Yeah, that‚Äôs what I used to think before I fine tuned my first DistilBert model on a small target dataset. Beats LSTMs any time, whether you have 100 or 100,000 training examples"
2745,@rasbt,2022-10-13 18:16:38+00:00,https://twitter.com/rasbt/status/1580623563396374528,@AndreTI Kind of a related topic https://t.co/RzfqA9nhIl
2746,@rasbt,2022-10-13 18:03:38+00:00,https://twitter.com/rasbt/status/1580620292229324800,"@boztank @ylecun It's been a decade, but does anyone remember Microsoft Kinect? 

I wonder how much could be achieved with today's AI &amp; camera and sensor technology alone, so we could circumvent the need for any kind of annoying wearables.

https://t.co/v4cMKKLdxD"
2747,@rasbt,2022-10-13 17:24:32+00:00,https://twitter.com/rasbt/status/1580610450592448512,"@CalcCon Interesting, didn't know it was the same author. My guess they probably hired Jumper to add more physics-based components in Alphafold 2 (if you compare it to the original 2018 Alphafold, which was a very different, even more ML-heavy paradigm)."
2748,@rasbt,2022-10-13 17:06:11+00:00,https://twitter.com/rasbt/status/1580605831946461188,*All open source btw. You can clone it and run it on your own hardware.
2749,@rasbt,2022-10-13 17:05:40+00:00,https://twitter.com/rasbt/status/1580605704200941568,"Glad you liked the app! Hah but the real reason we built this was to illustrate the path from model -&gt; production. Being a researcher, that's a whole new playground for me üòä

Involves
- a UI
- REST endpoint
- Concurrency &amp; autoscaling
- dynamic batching

https://t.co/Mulqo30GIP"
2750,@rasbt,2022-10-13 15:13:19+00:00,https://twitter.com/rasbt/status/1580577428531187712,"@AndreTI there already are RL-from-video papers, together with autoregressive video models there's conceptually maybe an opportunity to build a system that can generate and learn new tasks by itself. But yeah, I can't really see this working practice in foreseeable future."
2751,@rasbt,2022-10-13 15:04:48+00:00,https://twitter.com/rasbt/status/1580575286772453379,"@AndreTI Currently, I can't see a way to solve this without stitching together several components, which is in my opinion not AGI but a fancy automation workflow."
2752,@rasbt,2022-10-13 14:56:57+00:00,https://twitter.com/rasbt/status/1580573312174133248,"@Raghav_66 üíØ. AGI is just for marketing &amp; funding purposes, haha"
2753,@rasbt,2022-10-13 14:56:12+00:00,https://twitter.com/rasbt/status/1580573120079204353,"@Ket_Cherie Computational models don't replace the actual wet lab experiments. It's like building a car, it's helpful to built a computational model / design first before you actually build it. Of course, you can't put that on the road without actually testing it"
2754,@rasbt,2022-10-13 14:54:58+00:00,https://twitter.com/rasbt/status/1580572812460232705,"@Ket_Cherie But the same can be said about any type of computational modeling, including molecular dynamics simulations -- they may account for hydration but it's not possible yet to model large scale biological systems (interactions, and large-scale crowding effects)"
2755,@rasbt,2022-10-13 13:09:49+00:00,https://twitter.com/rasbt/status/1580546348835041289,"Humans can go pick up coffee beans, grind them, boil water, read the instructions for an aeropress &amp; brew a nice cup of coffee. Good luck teaching that to an AI.
An AI can predict 3D structures of proteins by just looking at a bunch of letters. Good luck teaching that to a human."
2756,@rasbt,2022-10-13 12:57:47+00:00,https://twitter.com/rasbt/status/1580543321084399617,"@cwizprod1 I didn't see the prompt you used and the image comparison. Only a single image but I can't tell where this is from or what the prompt was. Could you explain more? (Btw, if you toggle the ""fast"" switch it will take a bit longer but generate higher quality outputs)"
2757,@rasbt,2022-10-13 12:55:37+00:00,https://twitter.com/rasbt/status/1580542774000365568,@BigBetAnalytics @cwizprod1 Thanks! Only future issues will be pushed out to the subscribers. There will be a new issue in November (first Monday of the month). But you can check out the previous issue on this page here: https://t.co/TmndH1bJVN
2758,@rasbt,2022-10-13 12:53:05+00:00,https://twitter.com/rasbt/status/1580542137883848704,"@CSkrishna @adayeoyh I still do caffeine, but more for the taste. 1 cup in the morning when I get up at 5:30 am, combined with a 20 minute book reading ritual ü´∂."
2759,@rasbt,2022-10-13 01:17:55+00:00,https://twitter.com/rasbt/status/1580367192562216960,"@cwizprod1 The outputs from StableDiffusion are not deterministic, it‚Äôs normal (and desired) that you get different outputs each time if that‚Äôs what you were wondering about? https://t.co/PZFP88cj2e"
2760,@rasbt,2022-10-13 01:12:02+00:00,https://twitter.com/rasbt/status/1580365714203893761,@cwizprod1 Thanks for the note! Should be fixed now!
2761,@rasbt,2022-10-12 20:29:27+00:00,https://twitter.com/rasbt/status/1580294599150825472,@roydanroy üî• üî•
2762,@rasbt,2022-10-12 19:49:42+00:00,https://twitter.com/rasbt/status/1580284593634058240,"@adayeoyh This is the way, if you want to maintain your productivity from ye goode olde college days while getting older and having fewer hours in the day üòÖ"
2763,@rasbt,2022-10-12 19:41:46+00:00,https://twitter.com/rasbt/status/1580282599448068097,@ijmiller2 @bluehost Nice! Thanks for beta testing. The silver lining of all this is that I feel like I am 2% closer to be being a web dev now üòÜ
2764,@rasbt,2022-10-12 19:34:46+00:00,https://twitter.com/rasbt/status/1580280838855409664,@mpaepper Hah thanks üòä
2765,@rasbt,2022-10-12 19:34:09+00:00,https://twitter.com/rasbt/status/1580280681141506048,@KyleCranmer @datascience_uw Cool initiative &amp; Feature L(a)unch üòÑ
2766,@rasbt,2022-10-12 19:21:10+00:00,https://twitter.com/rasbt/status/1580277413216276480,"@kchonyc If they lied about the ‚ÄúI can confirm that the manuscript has been read and approved by all named authors and that there are no other persons who satisfied the criteria for authorship but are not listed‚Äù checkbox, how can we trust the paper‚Äôs benchmark results ü§î"
2767,@rasbt,2022-10-12 19:02:20+00:00,https://twitter.com/rasbt/status/1580272676920123392,"@DSaience @ilyasut Haha AImazing, well done üëç"
2768,@rasbt,2022-10-12 18:37:58+00:00,https://twitter.com/rasbt/status/1580266542465716224,"@roydanroy *where Adaline is the first differentiable variant of the perceptron. 
And Adaline + logistic sigmoid function  = logistic regression.
And m * logistic regression ~ multilayer perceptron"
2769,@rasbt,2022-10-12 18:36:29+00:00,https://twitter.com/rasbt/status/1580266171151982592,"@roydanroy We have a whole course on linear regression. LR looks simple on the surface but it's a pretty deep topic and great intro to stats.

PS: Bonus, it's also a great component of a CS deep learning course. Linear regression + threshold function = Adaline (adaptive linear neuron)"
2770,@rasbt,2022-10-12 18:22:55+00:00,https://twitter.com/rasbt/status/1580262755076280320,@ilyasut *transformer*tive tech
2771,@rasbt,2022-10-12 17:47:19+00:00,https://twitter.com/rasbt/status/1580253796348723200,"@david_picard @trunghlt @roydanroy Similar to diffusion models and DiffDock, I mean it just beat reference docking methods by a huge margin (if the results are to be believed). If it generalizes well, it will inarguable have a huge impact on drug discovery and medicine"
2772,@rasbt,2022-10-12 17:45:01+00:00,https://twitter.com/rasbt/status/1580253219447398400,"@david_picard @trunghlt @roydanroy You can check out https://t.co/5HTfa7ky49

Or consider the papers that cited AlphaFold2. But having worked on drug discovery problems with pharma people in the past, I can tell you that a lot of the applications are proprietary and you won't find articles about that."
2773,@rasbt,2022-10-12 16:51:22+00:00,https://twitter.com/rasbt/status/1580239716128989185,"@ijmiller2 @bluehost Arg, looked normal to me -- probably due to cashing. But you were right, checked in another browser and there was indeed an issue. Can you try to refresh? I think I fixed it üò¨"
2774,@rasbt,2022-10-12 16:43:59+00:00,https://twitter.com/rasbt/status/1580237858773663747,"Want to generate Stable Diffusions images real fast?
Upon popular request, we just launched the Muse App on Lightning ‚ö°Ô∏è https://t.co/OySIXvQMf0 

Want to build and deploy your own app (maybe the next-gen video diffusion model)? Here's a hands-on tutorial: https://t.co/Mulqo2IxuH https://t.co/bvrOTKz4vE"
2775,@rasbt,2022-10-12 13:57:10+00:00,https://twitter.com/rasbt/status/1580195876261482499,@ijmiller2 And it should be back up! There was some incompatibility between Cloudflare and my Bluehost SSL. Just chatted with someone @bluehost and they fixed it in no time. Amazing customer service over there ‚ô•Ô∏è! It's really rare to get such knowledgable representatives these days!
2776,@rasbt,2022-10-12 13:22:01+00:00,https://twitter.com/rasbt/status/1580187031753601025,"Thanks for all the positive feedback on the newsletter so far!
ü´∂ 500 subscribers on the first day, I am really flattered! 

Upon popular request, I just added SSL (https)

PS: since you were curious, I am aiming for a monthly release, 1st Mon of the month
https://t.co/3tqsZtK950"
2777,@rasbt,2022-10-12 13:12:15+00:00,https://twitter.com/rasbt/status/1580184575866974208,"@ijmiller2 Thanks for the note. Yeah, I was playing with the SSL certificates to get the https working on my newsletter. Probably broke something. Will take a look at it later! Thanks! üôè"
2778,@rasbt,2022-10-12 13:10:57+00:00,https://twitter.com/rasbt/status/1580184248123740161,"@m__vaisakh @nirsd Awesome, thanks for the pointer!"
2779,@rasbt,2022-10-12 13:10:18+00:00,https://twitter.com/rasbt/status/1580184083799293953,"@david_picard @trunghlt @roydanroy One can argue that this functions as a proof of concept. Large language transformers have been adopted for important, groundbreaking applications in bio, e.g., ProteinBERT and AlphaFold 2. The same is true for diffusion models."
2780,@rasbt,2022-10-12 01:31:34+00:00,https://twitter.com/rasbt/status/1580008239609319426,@TaliaRinger *rust(y) book
2781,@rasbt,2022-10-11 22:57:20+00:00,https://twitter.com/rasbt/status/1579969428686778368,"@JFPuget Love these things! If you have a chance, I‚Äôd love to hear the top 5 things you did (preferable in sorted by impact)."
2782,@rasbt,2022-10-11 22:54:39+00:00,https://twitter.com/rasbt/status/1579968751348613120,"@ylecun @roydanroy Thanks for explaining, that's *fair* (no pun intended)"
2783,@rasbt,2022-10-11 22:47:04+00:00,https://twitter.com/rasbt/status/1579966842952908806,@venomsnake006 @ylecun @roydanroy a typo I made when I was squeezing everything into the character limit
2784,@rasbt,2022-10-11 22:41:29+00:00,https://twitter.com/rasbt/status/1579965438091755522,"@paul_rietschka @roydanroy Not sure it's just a $$$ problem. It's also due to the fact that clusters run on legacy software and are hard to use. E.g., here at UW-Madison we have GPUs, but it's really painful to use them in the current cluster env. Everyone hates it. Plus too many administrative hurdles."
2785,@rasbt,2022-10-11 22:39:12+00:00,https://twitter.com/rasbt/status/1579964865711837184,"@ylecun @roydanroy I wonder how much of this is due to some Big Tech companies (like Meta) disbanding their general AI research groups? So, people are looking for sth new: Some are forming startups, others try their luck in academia academia. Genuinely curious 
Image source: https://t.co/uC3F8SpVhs https://t.co/UV6AIqS1V0"
2786,@rasbt,2022-10-11 22:30:13+00:00,https://twitter.com/rasbt/status/1579962602150858752,"@paul_rietschka @roydanroy it's easy to point out issues, but implementing those is another thing -- if you don't work on said models it's maybe hard to say what's realistic and what's not.
Vice versa, if you don't see the critics working on these models themselves, it's easy to ignore &amp; dismiss the advice"
2787,@rasbt,2022-10-11 22:27:34+00:00,https://twitter.com/rasbt/status/1579961936602550272,"@paul_rietschka @roydanroy I am hoping the switch from ML tech -&gt; academia will balance that a bit. But that being said, the current situation maybe also explains the chasm between AI ethics in academia &amp; LLM developers. There is just this large disconnect atm, which is bad for both sides."
2788,@rasbt,2022-10-11 22:14:19+00:00,https://twitter.com/rasbt/status/1579958599807561728,@roydanroy And it does not only seem to be due to less access to compute resources https://t.co/G6zduPNWjN
2789,@rasbt,2022-10-11 22:04:56+00:00,https://twitter.com/rasbt/status/1579956239358111747,"@roydanroy Just read this in the just-released State of AI 2022 report:
""The chasm between academia and industry in large scale AI work is potentially beyond repair: almost 0% of work is done in academia."" 
Think what you like, large-scale AI is relevant &amp; I hope this will at least be 90/10"
2790,@rasbt,2022-10-11 21:56:44+00:00,https://twitter.com/rasbt/status/1579954176456822785,@AllenDowney Same for a certain Elsevier journal (which I also don't want to endorse) https://t.co/cH34jgt58C
2791,@rasbt,2022-10-11 21:54:32+00:00,https://twitter.com/rasbt/status/1579953621084798976,"@AllenDowney This is neat! 
PS: I don't want to promote the journal, but yeah, certain IEEE journals have been bugging me about submitting graphical abstracts a few years ago (I do think this was optional though)."
2792,@rasbt,2022-10-11 21:22:17+00:00,https://twitter.com/rasbt/status/1579945505454723074,"@zacharylipton ""Below 100B parameters &amp; probably harmless"""
2793,@rasbt,2022-10-11 20:25:04+00:00,https://twitter.com/rasbt/status/1579931108246163456,"@DSaience Hah, yes, thanks, that confirms my suspicion üòÜ! I was actually looking for counter examples for https://t.co/iBIURP4wcz"
2794,@rasbt,2022-10-11 20:17:47+00:00,https://twitter.com/rasbt/status/1579929276274864129,"@nirsd Ok ok. According to ""Masked Autoencoders Are Scalable Vision Learners"" https://t.co/EqpKbeyJmh self-prediction wins.
But I was actually looking for opinions and possibly having my mind changed üôÑ https://t.co/MCVKRi9J31"
2795,@rasbt,2022-10-11 20:07:00+00:00,https://twitter.com/rasbt/status/1579926563407433728,"When you want to train vision transformers and consider self-supervised learning ...
Self-prediction methods (e.g., masked autoencoding) usually perform better than contrastive learning (e.g., MoCo v3)! üî•"
2796,@rasbt,2022-10-11 19:05:00+00:00,https://twitter.com/rasbt/status/1579910958977536000,"ML engineers may not worry about overpopulation on MARS atm, but MARS is still worth thinking about in ML contexts:

1. Maintainability (versioning, docs, reproducibility)
2. Adaptability (upd w/o interrupts)
3. Reliability (adversarial attacks)
4. Scalability (hardware scaling)"
2797,@rasbt,2022-10-11 17:04:53+00:00,https://twitter.com/rasbt/status/1579880728451768321,"@mpaepper Awesome, thanks a lot. Will reach out to them and get that fixed!"
2798,@rasbt,2022-10-11 15:33:53+00:00,https://twitter.com/rasbt/status/1579857828080410627,@mpaepper Thanks a lot! Also thanks for offering your help with the subdomain. It looks like it's a Revue limitation (as per the settings below). Do you know if there is a way to still make it work? https://t.co/lmhXwdI4nq
2799,@rasbt,2022-10-10 20:23:55+00:00,https://twitter.com/rasbt/status/1579568429572718592,"@m_usmanrafique Wow, thanks! ü•∞üôå"
2800,@rasbt,2022-10-10 20:14:43+00:00,https://twitter.com/rasbt/status/1579566116535676928,"Excited to announce the launch of my newsletter! ‚ÄúAhead of AI #1 - A Diffusion of Innovations‚Äù https://t.co/SOnnQDxm4A

It features  insights into recent AI trends, research paper discussions, educational nuggets, productivity hacks, open source projects, highlights, humor &amp; more"
2801,@rasbt,2022-10-10 17:15:33+00:00,https://twitter.com/rasbt/status/1579521024814907392,"@AiSimonThompson Sure, I agree with you but at the same time, I still stand by my two points above. 
It's probably obvious that @huggingface is at the forefront of providing such models. And guess what ... https://t.co/jl2ngsdw27"
2802,@rasbt,2022-10-10 16:18:44+00:00,https://twitter.com/rasbt/status/1579506729821560832,"@CirnoBaka6 By that definition, you are excluding models like ProteinBERT (https://t.co/Sjv2od7gZ6), AlphaFold2, etc. though"
2803,@rasbt,2022-10-10 15:58:30+00:00,https://twitter.com/rasbt/status/1579501634597842944,"@__mharrison__ I think you can actually feed a PyTorch tensor into Numba directly these days, indeed!"
2804,@rasbt,2022-10-10 13:29:04+00:00,https://twitter.com/rasbt/status/1579464029617414145,The only reason to get into C these days is to develop custom C++ and CUDA extensions for PyTorch üôÉ
2805,@rasbt,2022-10-10 13:25:45+00:00,https://twitter.com/rasbt/status/1579463197664608257,"@hardmaru @StabilityAI Wow, top transfer of the season! Big congrats! üéâ
Looking forward to all the creative outputs that will come out of this üòä"
2806,@rasbt,2022-10-10 13:11:59+00:00,https://twitter.com/rasbt/status/1579459732427141121,@JesperDramsch Stable diffusion does just fine using UNet for upsampling üòù
2807,@rasbt,2022-10-10 13:10:53+00:00,https://twitter.com/rasbt/status/1579459453606584320,"This! In all these years, we didn‚Äôt see the need to label Unix, Linux, Windows etc ‚Äúfoundation software‚Äù. 

In ML ‚Äúfoundation model‚Äù serves exactly 2 purposes: 
1) an opportunity for academics to coin a new term as a citation grab. 
2) a fancy marketing term to sell you a service"
2808,@rasbt,2022-10-10 12:58:17+00:00,https://twitter.com/rasbt/status/1579456284386283521,@alkalait Funny coincidence that both Apple and the audacious researchers ‚Äúcoining‚Äù that term are affiliated with Stanford üôÉ
2809,@rasbt,2022-10-10 12:50:34+00:00,https://twitter.com/rasbt/status/1579454342121553921,@JonathanSumDL I mean people have been using GANs and VAEs for that in recent years. I can‚Äôt see why diffusion would be a worse choice üòä
2810,@rasbt,2022-10-10 12:49:25+00:00,https://twitter.com/rasbt/status/1579454054014808067,"@radenmuaz @suzatweet But I think it‚Äôs RL based, or at least not diffusion based?"
2811,@rasbt,2022-10-10 12:48:52+00:00,https://twitter.com/rasbt/status/1579453913362993154,"@MatthewHilling4 Nice, thanks, haven‚Äôt heard about most of those!"
2812,@rasbt,2022-10-10 12:47:48+00:00,https://twitter.com/rasbt/status/1579453647280566273,@rouli They train on the synthesized training data and then evaluate on the original test set. They do include a comparison with classifiers trained on the original training data as well as a control. It‚Äôs in the tweets further down.
2813,@rasbt,2022-10-09 18:19:49+00:00,https://twitter.com/rasbt/status/1579174813452496896,@udaylunawat @jeremyphoward Bummer that fastAGI is already taken (https://t.co/SBxRgS1Pdp)
2814,@rasbt,2022-10-09 15:35:43+00:00,https://twitter.com/rasbt/status/1579133515454898179,"@CalcCon wow, way before my time and super interesting!!"
2815,@rasbt,2022-10-09 14:38:12+00:00,https://twitter.com/rasbt/status/1579119039083073537,"Like the original gradient boosting algorithm and generative adversarial networks üî•. 
You can probably guess which one is which."
2816,@rasbt,2022-10-09 14:19:21+00:00,https://twitter.com/rasbt/status/1579114297846042626,"@deliprao @altryne I saw the intro video and was tempted at first, but the note-taking interface looks clumsy + I got used to be very efficient on the Remarkable after using it for ~1 year. Imho no need to upgrade/get a new one until someone introduces something comparable but with color e-ink."
2817,@rasbt,2022-10-09 14:05:44+00:00,https://twitter.com/rasbt/status/1579110868708884481,"13/13 Now, if you are curious to give it a try, the source code for TabDDPM is available here: https://t.co/OJVTkBYY9r"
2818,@rasbt,2022-10-09 14:05:43+00:00,https://twitter.com/rasbt/status/1579110866523672576,"12/13
In the privacy-section they analyze the ‚Äúdistance to closest record‚Äù (DCR) distribution. Looks pretty good; there is a substantial amount of non-zero distances.
2 caveats next to the missing axis labeling: what is the distance metric; why is this not done for GAN and VAE https://t.co/YBUm9k0tQr"
2819,@rasbt,2022-10-09 14:05:43+00:00,https://twitter.com/rasbt/status/1579110864371974150,"11/13
Now, thinking back of one of the previous figures that showed TabDDPM-synthetic data closely resembles the training data distribution. Hw do we know whether TabDDPM generates new data (vs just memorizing and duplicating)? https://t.co/XLW52qIhBU"
2820,@rasbt,2022-10-09 14:05:42+00:00,https://twitter.com/rasbt/status/1579110862454857728,"10/13
Another interesting tidbit: ‚Äú[‚Ä¶] the CatBoost model, which is the leading GBDT implementation providing state-of the-art performance on tabular tasks‚Äù. I believe @tunguz would have something to say about this üòÇ"
2821,@rasbt,2022-10-09 14:05:42+00:00,https://twitter.com/rasbt/status/1579110860207050753,"9/13
Interesting tidbit: SMOTE often outperformed the VAE- and GAN-based methods. Were they just not well tuned, or are they not that good at generating synthetic data?"
2822,@rasbt,2022-10-09 14:05:41+00:00,https://twitter.com/rasbt/status/1579110858151858176,"8/13
2) ML Efficiency part 3 -&gt; The same is true for gradient-boosted decision trees (here: CatBoost): they perform better when training on TabDDPM data https://t.co/K2SEmABBkr"
2823,@rasbt,2022-10-09 14:05:41+00:00,https://twitter.com/rasbt/status/1579110855249367040,"7/13
b) ML Efficiency part 2 -&gt; Across 15 datasets (columns) Weak classifiers (random forest, logistic regression, decision trees) perform better on TabDDPM synthetic data vs GAN or VAE synthetic data https://t.co/kLlH5JeZXH"
2824,@rasbt,2022-10-09 14:05:40+00:00,https://twitter.com/rasbt/status/1579110853546479616,"6/13
b) ML Efficiency part 1 -&gt; The author trained different models on the synthetic data; then they evaluated the performance of these models on non-synthetic test data"
2825,@rasbt,2022-10-09 14:05:40+00:00,https://twitter.com/rasbt/status/1579110851294146563,"5/13
There is a more quantitative evaluation of the distributions, but without axis labels, it is really hard to tell what the row and column values represent. Maybe a better analysis would be KS tests or KL terms for the individual synthetic-real feature pairs. https://t.co/EWliJZbbZO"
2826,@rasbt,2022-10-09 14:05:39+00:00,https://twitter.com/rasbt/status/1579110849247346690,"4/13
a) Qualitative comparison -&gt; How do the distributions of the synthetic data compare to the original training distributions? TabDDPM definitely does best here (but how much did the authors cherry-pick?) https://t.co/wTEvy42Nmh"
2827,@rasbt,2022-10-09 14:05:39+00:00,https://twitter.com/rasbt/status/1579110846847848449,"3/13
How do we know that TabDDPM outperforms previous state-of-the-art GAN- and VAE-based approaches? 

a) [Qualitative comparison] The synthetic data resembles the original data distribution more closely
b) [ML Efficiency] Classifiers trained on the synthetic data perform better"
2828,@rasbt,2022-10-09 14:05:38+00:00,https://twitter.com/rasbt/status/1579110844700692480,"2/13
TabDDPM uses multinomial diffusion for categorical (and binary) features ‚Äî adding uniform noise.

For numerical features, it uses the common Gaussian diffusion.

The reverse diffusion process is learned via a fully connected network (MLP) https://t.co/A8Nk1K3i3Z"
2829,@rasbt,2022-10-09 14:05:38+00:00,https://twitter.com/rasbt/status/1579110843081691136,"This week's update to the tabular list features (surprise, surprise)
üí´diffusion modelsüí´!

""TabDDPM: Modeling Tabular Data with Diffusion Models"" https://t.co/ghg553JOCy

Why is this useful &amp; interesting? 
1) Imbalanced data and oversampling;
2) Privacy.

How it works? 
üëá 1/13"
2830,@rasbt,2022-10-09 13:28:10+00:00,https://twitter.com/rasbt/status/1579101416316338177,Quoting what Deep Learning for Tabular Data researchers recently said about XGBoost
2831,@rasbt,2022-10-09 13:25:08+00:00,https://twitter.com/rasbt/status/1579100652390998018,@garybasin Take the day off and write a new book ‚úçÔ∏è
2832,@rasbt,2022-10-09 13:14:01+00:00,https://twitter.com/rasbt/status/1579097853431287808,"@budcolincoln Actually, I found those examples (like the protein-ligand docking one) impressive at first glance, but I am going to hold my horses on those ones for now. I want to see how they perform on real world (non benchmark) datasets first"
2833,@rasbt,2022-10-09 13:09:26+00:00,https://twitter.com/rasbt/status/1579096701172076545,@andrey_cheptsov @Grady_Booch Only if it doesn‚Äôt discover ‚Äúnbdev‚Äùfirst and dies by Jupyter kernel death üòÜ
2834,@rasbt,2022-10-08 19:02:47+00:00,https://twitter.com/rasbt/status/1578823237584433152,@ylecun @Grady_Booch Expertise does not imply following best practices
2835,@rasbt,2022-10-08 18:59:57+00:00,https://twitter.com/rasbt/status/1578822523805790208,The first AGI will be developed in a Jupyter notebook
2836,@rasbt,2022-10-08 18:46:52+00:00,https://twitter.com/rasbt/status/1578819230363185152,"@cHHillee Depends on the time scale. I think it will first continue to increase and then eventually decrease. Like @sama recently said, there probably won‚Äôt be any (major) prompt engineering anymore in like &gt; 5 years."
2837,@rasbt,2022-10-08 17:13:38+00:00,https://twitter.com/rasbt/status/1578795770027053057,"Yes, please!
üëá
https://t.co/0gREBZKFnO"
2838,@rasbt,2022-10-08 16:51:36+00:00,https://twitter.com/rasbt/status/1578790224662245376,@_nateraw Wow awesome work üôå
2839,@rasbt,2022-10-08 16:24:41+00:00,https://twitter.com/rasbt/status/1578783450081161221,@tunguz https://t.co/SVnwMbMyF7
2840,@rasbt,2022-10-08 16:15:12+00:00,https://twitter.com/rasbt/status/1578781062989320192,@tunguz All sorts of mathematical proofs. I hate doing them by hand.
2841,@rasbt,2022-10-08 15:33:20+00:00,https://twitter.com/rasbt/status/1578770525593030656,@ctitusbrown I would do a Google Scholar search for search for ‚Äúprecision-recall trade-off tuning‚Äù. I think it‚Äôs pretty common among practitioners but I don‚Äôt know if there is a formal citation for it
2842,@rasbt,2022-10-08 15:20:30+00:00,https://twitter.com/rasbt/status/1578767295685750785,"@DZhang50 @tdietterich @rctatman Isn‚Äôt it the other way around, ie AI safety includes alignment? Not sure how credible these sources are but ‚ÄúAI alignment is a subfield of AI safety, the study of building safe AI systems.[6][18]‚Äú https://t.co/EjSAJv30ow"
2843,@rasbt,2022-10-08 14:42:37+00:00,https://twitter.com/rasbt/status/1578757764611833856,@JokrCantSpell Whoa what an epic list! Thanks!
2844,@rasbt,2022-10-08 14:38:32+00:00,https://twitter.com/rasbt/status/1578756734864105474,"@sonicdeath I didn‚Äôt know there was any impressive diffusion model for audio yet, any links?"
2845,@rasbt,2022-10-07 23:32:46+00:00,https://twitter.com/rasbt/status/1578528791478947840,"@1__manar0 @OpenAI Yes, that‚Äôs a big one. But it doesn‚Äôt use diffusion ‚Ä¶ was oh listing diffusion models otherwise we would have a very very long list haha üòÖ"
2846,@rasbt,2022-10-07 23:31:45+00:00,https://twitter.com/rasbt/status/1578528536813391873,@nacim_belkhir Oh yes! Although I think party wasn‚Äôt using a diffusion process
2847,@rasbt,2022-10-07 22:12:52+00:00,https://twitter.com/rasbt/status/1578508686166982659,"@BenBlaiszik Wow, very very impressive! I had no idea!"
2848,@rasbt,2022-10-07 21:51:19+00:00,https://twitter.com/rasbt/status/1578503260343717888,@TheZachMueller Whoa! And I‚Äôm curious what the prompt was. ‚ÄúMonkey Island on drugs‚Äù?
2849,@rasbt,2022-10-07 19:12:53+00:00,https://twitter.com/rasbt/status/1578463390690779136,@mmitchell_ai @SashaMTL Generated images or it didn‚Äôt happen üòÜ
2850,@rasbt,2022-10-07 18:17:06+00:00,https://twitter.com/rasbt/status/1578449352162320384,"@sleepinyourhat Awesome. What an important initiative. Would be interesting to finally see some advances in mitigation methods. So far, most things I have seen focused on exploratory data analysis and fingerpointing. Important to finally take the next step."
2851,@rasbt,2022-10-07 16:57:28+00:00,https://twitter.com/rasbt/status/1578429312612458502,"@mpaepper Oh, I thought people use UNet for that"
2852,@rasbt,2022-10-07 16:55:54+00:00,https://twitter.com/rasbt/status/1578428919111626752,"@gusthema Yes, haha, optimizing matrix multiplication makes a pretty foundational model -- although, in a different sense"
2853,@rasbt,2022-10-07 16:24:51+00:00,https://twitter.com/rasbt/status/1578421103541616645,"@gusthema 2/2 Technically, you could generate the protein structure with AlphaFold and then dock ligands with DiffDock for example. In many ligand and discovery projects, you don't have the structure (lots of GPCR-related ones for example), so that is actually a valuable combo."
2854,@rasbt,2022-10-07 16:23:24+00:00,https://twitter.com/rasbt/status/1578420738746220546,"@gusthema It's different, but they could go well together actually. AlphaFold is for predicting the protein structure (from an amino acid sequence -- a letter string). Diffdock is for finding a ligand pose in a protein binding pocket. 1/2"
2855,@rasbt,2022-10-07 16:18:53+00:00,https://twitter.com/rasbt/status/1578419601540382726,"@gusthema Thx! Regarding the tabular one, I actually have it printed on my desk -- saved it for the weekend to add it to the Tabular List (https://t.co/VAXJRC49qR)!

Another impressive one was the protein-ligand docking one: https://t.co/RsjFkuSDwp"
2856,@rasbt,2022-10-07 16:02:19+00:00,https://twitter.com/rasbt/status/1578415434344255488,"@rishabh16_ Thanks! Haven't had a chance to read it carefully yet, but it does look ViT-based though? In general, good call though, I think Video Diffusion Models https://t.co/s47KaJ3QZc should have made the list!"
2857,@rasbt,2022-10-07 15:59:27+00:00,https://twitter.com/rasbt/status/1578414712898785280,"@marccodess Yap, had similar thoughts too. I think Imagen and Imagen-Video are likely pushed out earlier than planned. I.e., they had several more iterations plans but cut it short to have the release not too far behind"
2858,@rasbt,2022-10-07 15:57:41+00:00,https://twitter.com/rasbt/status/1578414266490978304,"@gusthema DreamBooth and DreamFusion, how could I forget! Thanks! Parti is GAN-based though, no?"
2859,@rasbt,2022-10-07 15:56:12+00:00,https://twitter.com/rasbt/status/1578413894585851904,"@Ricardo_GaGu Ah yes, thanks, saw that the other day and totally forgot. Having developed scoring functions for docking during my PhD back then, I found the results they got super impressive."
2860,@rasbt,2022-10-07 15:42:17+00:00,https://twitter.com/rasbt/status/1578410390588989441,"@marksimi that's transformer-based deep Q-learning though, right?"
2861,@rasbt,2022-10-07 13:34:37+00:00,https://twitter.com/rasbt/status/1578378265135390721,@letonyo @nholzschuch 9 months since I called it üôÉ
2862,@rasbt,2022-10-07 13:33:59+00:00,https://twitter.com/rasbt/status/1578378103214276612,"@jarkko_malinen Ah yes, good one üëå"
2863,@rasbt,2022-10-07 13:28:56+00:00,https://twitter.com/rasbt/status/1578376833204211713,@PrasoonPratham It‚Äôs a seq2seq transformer though afaik
2864,@rasbt,2022-10-07 13:21:10+00:00,https://twitter.com/rasbt/status/1578374879229145088,GANs ‚Äî Generally antiquated networks
2865,@rasbt,2022-10-07 13:15:39+00:00,https://twitter.com/rasbt/status/1578373488225632258,The other possibility is VR. But who cares about VR besides that one company
2866,@rasbt,2022-10-07 13:13:06+00:00,https://twitter.com/rasbt/status/1578372847361495041,"And more importantly, what‚Äôs next? Skipping DALL-E Video for now and considering the recent Whisper release, you also think that OpenAI is currently working on an audio+video editing model focused on lip (re)syncing?"
2867,@rasbt,2022-10-07 13:13:05+00:00,https://twitter.com/rasbt/status/1578372844068966405,"Ok, so 9 months in we got

- DALL‚Ä¢E 2 [6 Apr 2022]
- Imagen [23 May 2022]
- Stable Diffusion [22 Aug 2022]
- Make-A-Video [29 Sep 2022]
- Imagen-video [6 Oct 2022]

Anything missing?"
2868,@rasbt,2022-10-07 13:04:30+00:00,https://twitter.com/rasbt/status/1578370685168418818,"@aniketmaurya @LightningAI @StableDiffusion Same, actually! What I found most impressive was also that this (and the original idea) was created and conceived by a relatively small team. It‚Äôs always refreshing to see that it‚Äôs possible to innovate and play alongside big tech even though you have fewer resources"
2869,@rasbt,2022-10-07 13:00:10+00:00,https://twitter.com/rasbt/status/1578369591885303808,"@_martinthoma Wow that‚Äôs a wonderful article, thanks for sharing!"
2870,@rasbt,2022-10-06 21:32:18+00:00,https://twitter.com/rasbt/status/1578136088652161025,@TaliaRinger I actually switched to decaf a while back and noticed that I just need something for my morning reading  ritual (it‚Äôs more the taste than the caffeine) ‚Äî I think decaf still has some caffeine though.
2871,@rasbt,2022-10-06 21:29:07+00:00,https://twitter.com/rasbt/status/1578135285807947785,"@CirnoBaka6 Yeah, tbf it‚Äôs more like ‚Äúdiscovered‚Äù by machine learning"
2872,@rasbt,2022-10-06 18:31:35+00:00,https://twitter.com/rasbt/status/1578090608757022721,@benml_ds @marktenenholtz You are right! Nice! https://t.co/yAsua79tq5
2873,@rasbt,2022-10-06 18:22:49+00:00,https://twitter.com/rasbt/status/1578088404180516864,@benml_ds @marktenenholtz But what's nice is the rfpimp package lets you run drop-column performance so you can compare it side by side.
2874,@rasbt,2022-10-06 18:20:36+00:00,https://twitter.com/rasbt/status/1578087843750084613,"@benml_ds @marktenenholtz * correction: they say ""We include permutation and drop-column importance measures that work with any sklearn model."" 
Anyways, the mlxtend version supports said ""feature_groups"""
2875,@rasbt,2022-10-06 18:17:07+00:00,https://twitter.com/rasbt/status/1578086969262866449,"@benml_ds @marktenenholtz Never heard of rfpimp, but based on a quick look (https://t.co/qM7tgYN0J9) it sounds like its specific to random forests. The implementation in mlxtend works with any (scikit-learn compatible) model."
2876,@rasbt,2022-10-06 18:04:20+00:00,https://twitter.com/rasbt/status/1578083749991940104,"@aniketmaurya @LightningAI @StableDiffusion Not that I don't like Stable Diffusion. Quite the opposite. But given that DALL-E (2) came first and produces slightly higher quality outputs, I am actually curious why someone would give it to Stable Diffusion here üòÖ"
2877,@rasbt,2022-10-06 18:02:06+00:00,https://twitter.com/rasbt/status/1578083191000276992,"@roydanroy @kchonyc 1) Imho editors should filter this out. 2) Based on my recent experiences, editors are extremely passive these days (lazy?) and almost always side with the reviewers. Very frustrating."
2878,@rasbt,2022-10-06 17:56:56+00:00,https://twitter.com/rasbt/status/1578081888916439042,@benml_ds @marktenenholtz I agree. As a fix for certain situations: You can group correlated features together and analyze those as feature groups. My implementation above supports that
2879,@rasbt,2022-10-06 17:54:53+00:00,https://twitter.com/rasbt/status/1578081373922942977,"@ChristophMolnar @marktenenholtz They are related in that they are both model agnostic, external methods you can apply based on manipulating feature columns. But yes, I agree, they are also different: (as a close analogy) they are different ~how k-fold cross-validation is different from evaluating on a test set."
2880,@rasbt,2022-10-06 17:39:46+00:00,https://twitter.com/rasbt/status/1578077569748025344,More details via @tunguz https://t.co/9CSzoFTsUX
2881,@rasbt,2022-10-06 17:36:32+00:00,https://twitter.com/rasbt/status/1578076756778663937,"Of course there are more than 5 ways to multiply matrices (https://t.co/epNJQ3QKYd).

And, of course, fast ones involve machine learning. https://t.co/qhvrtrteyO"
2882,@rasbt,2022-10-06 17:19:02+00:00,https://twitter.com/rasbt/status/1578072350486151178,"@Grady_Booch Whoa, 2022, what a crazy year ‚Ä¶"
2883,@rasbt,2022-10-06 17:16:41+00:00,https://twitter.com/rasbt/status/1578071760691511301,@dhirajkapila @prasetyaputraa Sry i actually only had those 3
2884,@rasbt,2022-10-06 16:12:26+00:00,https://twitter.com/rasbt/status/1578055593134358529,@tunguz ü§Ø
2885,@rasbt,2022-10-06 15:51:16+00:00,https://twitter.com/rasbt/status/1578050266095575044,@tunguz @Datanerdkim Check out hummingbird üòÜhttps://t.co/cmDYE1pbER
2886,@rasbt,2022-10-06 15:50:37+00:00,https://twitter.com/rasbt/status/1578050098977771520,"@tunguz Haha fun fact, there are 5 ways to multiply matrices
https://t.co/Bt8hq2l2H5"
2887,@rasbt,2022-10-06 15:01:16+00:00,https://twitter.com/rasbt/status/1578037681434480646,"@prasetyaputraa Awesome, hope you'll like it!!"
2888,@rasbt,2022-10-06 15:00:47+00:00,https://twitter.com/rasbt/status/1578037560462348289,@michaeljanich It's not supported yet afaik
2889,@rasbt,2022-10-06 15:00:02+00:00,https://twitter.com/rasbt/status/1578037369475067908,"@unsorsodicorda @hackmdio Thanks, I will keep that in mind! It would probably not happen in the foreseeable future (like this year), but thanks for offering!"
2890,@rasbt,2022-10-06 14:58:25+00:00,https://twitter.com/rasbt/status/1578036962467921921,"@marktenenholtz Same! Or, actually, I prefer permutation importance since it doesn't require retraining 
(have an implementation here: https://t.co/5fyL81kL1o). 
For LOFO, you end up with m models, where m is the number of features. Any thoughts/experiences with LOFO vs permutation importance?"
2891,@rasbt,2022-10-05 21:37:08+00:00,https://twitter.com/rasbt/status/1577774915339620352,"@JJensenOnCS Hard to tell, it‚Äôs kind of blurry along that soft margin"
2892,@rasbt,2022-10-05 16:05:19+00:00,https://twitter.com/rasbt/status/1577691410567938049,"@_gngdb CosineAnnealingLR is based on the SGDR paper but only implements the cosine annealing part. Maybe ""vanilla restarts"" is the better word, dunno. Or, maybe ""restarts"" is an entirely confusion term for CosineAnnealingLR; just ""warm restart"" (SGDR) vs cyclic (the cosine part of SGDR)"
2893,@rasbt,2022-10-05 15:56:19+00:00,https://twitter.com/rasbt/status/1577689148944748544,"@ID_AA_Carmack For training? I think mostly surface-level tweaks (https://t.co/plSYHWL7qO).

For inference, I think Keras has a custom XLA-based GPU compilation. More interesting: AITemplate based on vertical, horizontal memory fusions, I think they get &gt;10x speedups (https://t.co/ylkrTDN2AS) https://t.co/7lWPkPiJux"
2894,@rasbt,2022-10-05 15:40:03+00:00,https://twitter.com/rasbt/status/1577685054398005250,"@_gngdb Yes, that's cosine annealing with warm restarts (i.e., CosineAnnealingWarmRestarts); in my plot I have the regular restarts (i.e., CosineAnnealingLR). Not sure which one is more common though; personally, I don't really notice a difference in practice"
2895,@rasbt,2022-10-05 15:25:28+00:00,https://twitter.com/rasbt/status/1577681382863667201,"@CSProfKGD wohoo, happy 10th anniversary! On to the next 20+! üòä"
2896,@rasbt,2022-10-05 15:07:20+00:00,https://twitter.com/rasbt/status/1577676818995449856,Good predictions need not have good explanations https://t.co/qPGxhEq3sG
2897,@rasbt,2022-10-05 14:36:52+00:00,https://twitter.com/rasbt/status/1577669154718597122,@burkov @Grady_Booch I think mostly only AI &amp; machine learning researchers and educators
2898,@rasbt,2022-10-05 14:33:05+00:00,https://twitter.com/rasbt/status/1577668202326261760,"@ph_singer @JFPuget @code_star ah yes, sry, don't know why I said decay rate."
2899,@rasbt,2022-10-05 14:30:41+00:00,https://twitter.com/rasbt/status/1577667598141071367,"@unsorsodicorda I agree ... maybe one day ... it's just this dilemma that I am trying to do too many things, haha. Since summer, I am trying to find better focus by working on fewer (but bigger) things üòÖ"
2900,@rasbt,2022-10-05 14:29:05+00:00,https://twitter.com/rasbt/status/1577667194749583360,@Grady_Booch @vandotorres just to clarify: we are both blocked https://t.co/XRmI3ZYH2a
2901,@rasbt,2022-10-05 14:26:49+00:00,https://twitter.com/rasbt/status/1577666625670713351,"@JFPuget @code_star @ph_singer * oh, I think you answered it here: https://t.co/bfYO1aeXBP. Curious though how you would choose the initial number of steps? With early stopping, you can set it arbitrarily large. But with your approach, you'd have a fixed number. Any good heuristic to choose that fixed number?"
2902,@rasbt,2022-10-05 14:25:25+00:00,https://twitter.com/rasbt/status/1577666272782913537,"@JFPuget @code_star @ph_singer 2/2 So, based on your suggestion, would you keep the epoch number fixed (like 110 in this plot) and just adjust the decay rate until the last epoch has peak validation performance. Or would you also (based on some criterion) change the # of epochs in addition to the decay rate?"
2903,@rasbt,2022-10-05 14:23:33+00:00,https://twitter.com/rasbt/status/1577665800537874434,"@JFPuget @code_star @ph_singer Thanks! So, in practice, I basically I let it run a long time and then pick those 3 checkpoints and compare them on a different dataset to choose the model. 1/2 https://t.co/9ZA5NwfTiI"
2904,@rasbt,2022-10-05 14:16:57+00:00,https://twitter.com/rasbt/status/1577664142424539137,@framart1 good point
2905,@rasbt,2022-10-05 01:16:52+00:00,https://twitter.com/rasbt/status/1577467825274265600,"@ssshukla26 thanks so much, it feels really nice &amp; motivating to hear this. glad you are getting something useful out of it üôå"
2906,@rasbt,2022-10-05 01:10:24+00:00,https://twitter.com/rasbt/status/1577466197435899906,"@synapticarbors I do run Adam w/o scheduler as another baseline. Or in many projects I just use Adam to keep things simple. Usually I can see a noticeable benefit of SGD + scheduler compared to vanilla SGD, I usually don't get that noticeable improvement when using Adam though."
2907,@rasbt,2022-10-04 23:45:39+00:00,https://twitter.com/rasbt/status/1577444871832485888,@ssshukla26 I will cover it separately in a different video in the future! Stay tuned!
2908,@rasbt,2022-10-04 23:24:59+00:00,https://twitter.com/rasbt/status/1577439670547677184,"@BlackHC I tried things like torch.optim. lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5)
but that flattens out too much, and higher patiences doesn't sometimes flatten enough."
2909,@rasbt,2022-10-04 23:22:23+00:00,https://twitter.com/rasbt/status/1577439015518625792,"@BlackHC I just base it on the number of epochs and eyeball it. You can treat it as a hyperparameter or swap it with DecayOnPlateau, but I never saw a noticeable difference."
2910,@rasbt,2022-10-04 22:49:07+00:00,https://twitter.com/rasbt/status/1577430646258925568,"@unsorsodicorda Arg, yeah, I have a half-way finished draft somewhere on my other computer and never got around to finishing it. Got distracted with other things, and then I kind of dropped it to make more room/time for other stuff üòÖ
(PS: Yes, that's correct!)"
2911,@rasbt,2022-10-04 22:43:27+00:00,https://twitter.com/rasbt/status/1577429217553571840,"I still think that step decay isn't too bad. I will probably stick to my 3 step procedure
1) baseline w/o scheduler
2) step decay
3) cosine annealing

But I learned a lot, namely not to use the cosine with restarts -- cosine annealing with batch step w/o restarts is indeed better"
2912,@rasbt,2022-10-04 22:43:26+00:00,https://twitter.com/rasbt/status/1577429214755573761,"As a little takeaway from the learning rate scheduler discussion, I ran some experiments ...

I will probably stick to my 3-step approach (see below), but this was a very informative discussion!

Code here if someone wants to toy around with it: https://t.co/YYZInNUP1Y https://t.co/fklfdB6pph"
2913,@rasbt,2022-10-04 21:43:49+00:00,https://twitter.com/rasbt/status/1577414211365638152,"@JayAlammar @alfcnz Just skimmed it ... and wow, this is really awesome work! Just wow! Excited to take it for a deeper dive this weekend!"
2914,@rasbt,2022-10-04 17:50:24+00:00,https://twitter.com/rasbt/status/1577355469102120960,"@xamat In my opinion the two don‚Äôt need to intersect, but I think per popular definition they do. Eg quoting Wikipedia ‚Äú(Academic sources reserve ""weak AI"" for programs that do not experience consciousness or do not have a mind in the same sense people do.)‚Äù https://t.co/2AO4EQgKzC"
2915,@rasbt,2022-10-04 17:46:08+00:00,https://twitter.com/rasbt/status/1577354396605849602,"@xamat from a business perspective, you probably just want a really good model that can predict protein structures, fly airplanes, trade stocks etc. No need to have these models be ‚Äúconsciousness‚Äù. On the other hand, including a ‚Äútowards AGI‚Äù probably helps selling the inference API"
2916,@rasbt,2022-10-04 17:41:57+00:00,https://twitter.com/rasbt/status/1577353343105646599,"@xamat Tbh nothing wrong with that approach. Personally, I am also more interested in building better and more useful narrow AI. Above, I was just saying that people interested in AGI are taking a weird approach. Or, they may just use AGI for marketing purposes, I dunno"
2917,@rasbt,2022-10-04 17:39:14+00:00,https://twitter.com/rasbt/status/1577352660570750988,"@xamat If people were truly interested they would be looking into modeling causal relationships between variables. However, the current approach seems to be throwing more parameters at it and hoping causality is sth you can get from the data."
2918,@rasbt,2022-10-04 17:32:39+00:00,https://twitter.com/rasbt/status/1577351003480985600,"@DSaience Ha yeah, there‚Äôs a lot of branching in that thread. This path takes you there"
2919,@rasbt,2022-10-04 16:48:59+00:00,https://twitter.com/rasbt/status/1577340015339864065,@Nitin_wysiwyg @code_star @MosaicML Great point. Maybe the default behavior should be changed to choosing the early stopping point from the right rather than the left? ü§î
2920,@rasbt,2022-10-04 16:41:25+00:00,https://twitter.com/rasbt/status/1577338107875188736,"If you feel like going down a little rabbit hole (a very useful one), this is the thread! 
TIL that I was using cosine annealing ""all wrong"" (with restarts) and learned sth new. 
Amazing example of ensemble learning -- me learning from an ensemble of experts! ü´∂ https://t.co/kZi2JYBBPE"
2921,@rasbt,2022-10-04 16:33:09+00:00,https://twitter.com/rasbt/status/1577336027483611137,"@Nitin_wysiwyg @code_star It depends. These days, I usually start with the learning rate suggested by a learning rate finder (based on the loss values, pick the point of the steepest downward slope) and do some tweaking (up and down) from there. https://t.co/RYT1CyLLlQ"
2922,@rasbt,2022-10-04 16:30:37+00:00,https://twitter.com/rasbt/status/1577335391425888258,@Nitin_wysiwyg @code_star @ph_singer @JFPuget yeah the curves were expected -- it was cosine annealing with restarts. just learned restarts are more finicky though and you are probably better off without them!
2923,@rasbt,2022-10-04 14:45:02+00:00,https://twitter.com/rasbt/status/1577308819704762371,"@code_star @ph_singer @delai50 That maybe explains my not-so-awesome experience with cosine annealing haha. Thanks for your patience @code_star and @ph_singer. Always awesome to learn sth new! (Not better than the step decay yet, but I just plugged it in quickly) https://t.co/J3EvC2KQ8b"
2924,@rasbt,2022-10-04 14:37:26+00:00,https://twitter.com/rasbt/status/1577306908263960579,@ph_singer @code_star I.e. I thought the left was the classical one. So you would basically change T_max to the number of epochs. I think I got it https://t.co/yv9iIVn2HJ
2925,@rasbt,2022-10-04 14:30:45+00:00,https://twitter.com/rasbt/status/1577305225345601536,"@ph_singer @code_star Ohhh, thanks! That was probably my misconception. I thought the classical one would be torch.optim. lr_scheduler.CosineAnnealingLR (https://t.co/bG50tcvzcB) and the warm restart one would be torch. optim. lr_scheduler. CosineAnnealingWarmRestarts (https://t.co/8ppmhW0VpS)"
2926,@rasbt,2022-10-04 14:24:50+00:00,https://twitter.com/rasbt/status/1577303737667813381,"@ph_singer @code_star @JFPuget Sharing the learning rate plot for the regular cosine decay (left plot above), anything wrong with it? (Genuine question, I am pretty new to cosine annealing) https://t.co/Ev5aAPc5xA"
2927,@rasbt,2022-10-04 14:22:52+00:00,https://twitter.com/rasbt/status/1577303241594912769,"@ph_singer @code_star @JFPuget Thanks! Was just double-checking, it was actually without warm restarts. I did try warm restarts though. For comparison, the original (left) without warm restarts and the warm-restart one (right) https://t.co/KulPNkw7CX"
2928,@rasbt,2022-10-04 14:20:40+00:00,https://twitter.com/rasbt/status/1577302689922404354,"@suspiciousturtl a great, recent, and healthy example is PyTorch moving to the Linux Foundation: https://t.co/NJmmpdAjnr"
2929,@rasbt,2022-10-04 14:15:51+00:00,https://twitter.com/rasbt/status/1577301474698317832,@tbeetech Oh this is all just for educational purposes.
2930,@rasbt,2022-10-04 01:26:42+00:00,https://twitter.com/rasbt/status/1577107914572996608,"@Nitin_wysiwyg @code_star @ph_singer @JFPuget Wait, what spikes are we talking about. You mean these spikes here right? https://t.co/6uvSWPPB9O"
2931,@rasbt,2022-10-04 01:16:20+00:00,https://twitter.com/rasbt/status/1577105303136444416,"@Nitin_wysiwyg @code_star @ph_singer @JFPuget Good call, and yes, totally. In this case drop_last=True was already set though. It's a relatively small dataset 20,000 and a small batch size (32); maybe there is a particular set of data points that are kind of outliers"
2932,@rasbt,2022-10-03 23:13:31+00:00,https://twitter.com/rasbt/status/1577074396522434560,@code_star Thanks! I will let you know! And no worries about the rough edges: I may actually adopt only the general settings ‚Äî it‚Äôs probably easier to port that into my code than vice versa. Thanks a lot for sharing!!
2933,@rasbt,2022-10-03 23:08:54+00:00,https://twitter.com/rasbt/status/1577073234683432961,"@code_star Awesome, thanks so much! Will check it out and toy around with that this week and see what I find!"
2934,@rasbt,2022-10-03 23:01:16+00:00,https://twitter.com/rasbt/status/1577071312811409409,"@code_star I mean no rush, but I definitely think the way I use it is bad and I‚Äôd like to learn to up-level my skills in that respect some time üòÖ"
2935,@rasbt,2022-10-03 22:56:41+00:00,https://twitter.com/rasbt/status/1577070159000260609,@code_star Do you have an example in a public repo somewhere for which I could glance at your setup? üòÖ
2936,@rasbt,2022-10-03 22:54:38+00:00,https://twitter.com/rasbt/status/1577069644279558144,@code_star @ph_singer @JFPuget I think so. Need to check later when I am back on my computer.
2937,@rasbt,2022-10-03 22:35:03+00:00,https://twitter.com/rasbt/status/1577064718355009536,"@code_star Actually, if you use the epoch tuning strategy, I find it more work (resource wise) because you have to rerun models ü§î"
2938,@rasbt,2022-10-03 22:33:34+00:00,https://twitter.com/rasbt/status/1577064343128408064,"@joorosa12185462 @Grady_Booch It‚Äôs strange. Haha maybe I talk too much about machine learning and deep learning ü§∑‚Äç‚ôÇÔ∏è. Anyways, not worth stressing over. But thanks!"
2939,@rasbt,2022-10-03 22:23:12+00:00,https://twitter.com/rasbt/status/1577061733956739073,"@Grady_Booch Hah, welcome to the club! üôå"
2940,@rasbt,2022-10-03 22:20:50+00:00,https://twitter.com/rasbt/status/1577061140718178306,"@code_star @ph_singer @JFPuget Also, Test accuracy is 89.5, not much overfitting to the validation set."
2941,@rasbt,2022-10-03 22:20:05+00:00,https://twitter.com/rasbt/status/1577060949651247105,"@code_star @ph_singer @JFPuget PS: this is a random example, I eventually got it to not overfit too much. It‚Äôs just to illustrate the point. So here is one on the same dataset with step scheduler again but less overfitting and also 90% validation acc (same as cosine annealing) https://t.co/cmAh6FyXRP"
2942,@rasbt,2022-10-03 22:16:58+00:00,https://twitter.com/rasbt/status/1577060165840302080,"@code_star Random example from earlier today. 1% performance improvement w cosine annealing (epoch 50) over step decay. (Maybe I am not using cosine decay correctly though). I remember @ph_singer and @JFPuget recommending epoch tuning, but I still have bad experience with that, like below https://t.co/ljXdhp6me1"
2943,@rasbt,2022-10-03 22:09:52+00:00,https://twitter.com/rasbt/status/1577058379083620352,"@code_star I often use and compare both now. Step 1: no scheduler as baseline, step 2: step decay, step 3: cosine annealing. Tbh I don‚Äôt notice a big difference between 2 &amp; 3 in most scenarios."
2944,@rasbt,2022-10-03 19:16:06+00:00,https://twitter.com/rasbt/status/1577014648490307585,"Thanks for the kind invitation, @anacondainc! As a big fan and user ever since, this was a big honor for me!"
2945,@rasbt,2022-10-03 19:16:05+00:00,https://twitter.com/rasbt/status/1577014646631907329,"Spoiler alert: Regarding numerical computing and openness, I'd say we are just getting started!! 

10 years ago, we were just putting things on GitHub, hoping they were useful. Now, we are in Phase II, where we learn how to maintain things and organize sustainable communities!"
2946,@rasbt,2022-10-03 17:39:49+00:00,https://twitter.com/rasbt/status/1576990418750709761,@AssemblyAI Glad you liked the post! Makes me nostalgic of ye goode olde statistical pattern rec class I studied back then ‚ò∫Ô∏è
2947,@rasbt,2022-10-03 14:48:41+00:00,https://twitter.com/rasbt/status/1576947350869659648,@nunomgarcia No they work for rectangular matrices as well. Even the 4th one if you use the outer product
2948,@rasbt,2022-10-03 14:46:03+00:00,https://twitter.com/rasbt/status/1576946689180434439,"@harpreet_utd @svpino Not sure if one is better than the other. I would use the HF one for HF models, and vice versa. Afaik the HF Trainer is based on the Lightning Trainer. At least that was true for the original versions. I think it is now more specific to transformer models"
2949,@rasbt,2022-10-03 14:43:06+00:00,https://twitter.com/rasbt/status/1576945947212337152,"@MuzafferKal_ @AndrewBeanAI Haha, yeah, and fancy broadcasting. np. dot is the Swiss army knife of array computing."
2950,@rasbt,2022-10-03 14:42:16+00:00,https://twitter.com/rasbt/status/1576945737161531392,@SatanShaitan pictures or it didn't happen
2951,@rasbt,2022-10-03 14:41:27+00:00,https://twitter.com/rasbt/status/1576945531179651073,"@rather__aarif Just watched the whole thing yesterday night, and that was pretty awesome! Btw he has yet another way (maybe not a completely new way because it's recursive), but pretty cool https://t.co/kE8NA0oG9t"
2952,@rasbt,2022-10-03 14:39:40+00:00,https://twitter.com/rasbt/status/1576945081839681536,"@Asael_am @ronmortadella @jmschreiber91 I don't know what you mean by trascendental, but beyond the mechanics, they come with nice, interesting interpretations. https://t.co/Arywy8wS4W"
2953,@rasbt,2022-10-02 19:35:34+00:00,https://twitter.com/rasbt/status/1576657158913282048,"@AndrewBeanAI yeah, I think that's in the same vein as https://t.co/RokvgbBV4X"
2954,@rasbt,2022-10-02 19:09:35+00:00,https://twitter.com/rasbt/status/1576650621121626112,"@nishparadox yeah, it's essentially a linear transformation, which then allows for alls sorts of compressions, expansions, reflections, shears, etc. Like you said, it's an interesting perspective to think about the matmul for computing the pre-activations of a hidden layer as a linear transf."
2955,@rasbt,2022-10-02 19:04:36+00:00,https://twitter.com/rasbt/status/1576649367272161280,"@MuzafferKal_ Oh, I see what you mean now! Yeah, that's a fair point. Maybe should write matrix multiplication? But then that sounds recursive, haha. I honestly don't know the subtleties, but I think an outer product is different because like you said it doesn't require the same number of ele"
2956,@rasbt,2022-10-02 19:00:49+00:00,https://twitter.com/rasbt/status/1576648413537763328,Jupyter notebook if someone wants to toy around with it: https://t.co/xElS3hAahM
2957,@rasbt,2022-10-02 18:53:53+00:00,https://twitter.com/rasbt/status/1576646668300472320,"@MuzafferKal_ Hm, but for the dot product / matmul between column vector (mx1 matrix) and row vector (px1 matrix), you still need m=p? But good call, why not use the outer product. That's then a 5th way I'd say. Thanks!! https://t.co/FyUsraK5c4"
2958,@rasbt,2022-10-02 15:26:36+00:00,https://twitter.com/rasbt/status/1576594507583303682,@rather__aarif This is awesome!
2959,@rasbt,2022-10-02 15:24:33+00:00,https://twitter.com/rasbt/status/1576593990400425985,"@JiangtangHu Oh yes, expanding the dot-product into a for-loop, one of my favorite examples of vectorization."
2960,@rasbt,2022-10-02 15:21:45+00:00,https://twitter.com/rasbt/status/1576593283035254784,Another beautiful example highlighting the beauty of looking at algorithms through the lens of linear algebra is the geometric interpretation of weight vectors ‚ù£Ô∏èhttps://t.co/h8WLfkNM0t https://t.co/9pwKAf3zpb
2961,@rasbt,2022-10-02 14:38:36+00:00,https://twitter.com/rasbt/status/1576582426482335744,"@JesperDramsch @ManuelDeLanda Actually, PyTorch has a C++ API, aka LibTorch: https://t.co/QdyQH4Yo3g. Fun fact: the Python overhead is negligible. Running PyTorch in Python vs C++ is a ~10% performance difference."
2962,@rasbt,2022-10-02 14:36:09+00:00,https://twitter.com/rasbt/status/1576581809458262018,"@JulienMouchnino @xamat You have to append the ""¬∑E-2-prompt-book-v1.02.pdf"" to the address. The twitter URL parser doesn't include it in the URL link"
2963,@rasbt,2022-10-02 14:34:51+00:00,https://twitter.com/rasbt/status/1576581484353241088,"In deep learning, we often accept matrix multiplications as just a tool for computing the weighted inputs for the hidden nodes.

However, if you pause to think more deeply, there's a certain beauty in linear algebra ü´∂

E.g., did you know there are 4 ways to multiply 2 matrices? https://t.co/PQh6oC2LOw"
2964,@rasbt,2022-10-02 14:32:23+00:00,https://twitter.com/rasbt/status/1576580859641020418,"@JFPuget @oliver_batch Tbh they looked quite cool back in 2012. Today, I'd say the design doesn't look terrible but quite dated (always reminds me of the Ford Fusion). Esp if you compare it to modern electric cars like Rivian, Taycan, or even the Mach-E"
2965,@rasbt,2022-10-01 17:57:51+00:00,https://twitter.com/rasbt/status/1576270181680427008,"@roydanroy Same, my PhD advisor, Leslie Kuhn, was also pivotal to my career, encouraging and supporting me in all the things I am doing now! Very grateful for her caring career  guidance!"
2966,@rasbt,2022-10-01 17:50:42+00:00,https://twitter.com/rasbt/status/1576268380738564096,"@PRONOjits Happy October! 

ü™ô It's already 20 years since Coinbase launched and I still don't care about crypto.

üê£ And it's already 20 years since I joined Twitter!

Also, RIP GAN research, which died 10 years ago."
2967,@rasbt,2022-10-01 16:30:23+00:00,https://twitter.com/rasbt/status/1576248169561673733,"@xamat Also, TIL that there's a DALL-E prompt book https://t.co/KWNCMp90bW¬∑E-2-prompt-book-v1.02.pdf https://t.co/izVrhMTosb"
2968,@rasbt,2022-10-01 13:26:36+00:00,https://twitter.com/rasbt/status/1576201918908506112,"@roydanroy Yup, former grad student interned there. Heard it's actually a great &amp; fun team! And yes, they also submit papers to arxiv."
2969,@rasbt,2022-10-01 13:18:47+00:00,https://twitter.com/rasbt/status/1576199953390522369,"@ilyasut no, that's inception. i mean the movie"
2970,@rasbt,2022-10-01 13:12:53+00:00,https://twitter.com/rasbt/status/1576198467269328896,"Happy October! 

üëæ It's only 10 years since AlexNet won ImageNet (aka ""the birthday of deep learning"")

üê£ And it's already 10 years since I joined Twitter!

""Coincidence"" is a nice word"
2971,@rasbt,2022-10-01 13:01:47+00:00,https://twitter.com/rasbt/status/1576195674076377088,@LandupDavid üíØ! Just add a few more conv layers + global avg pooling and drop the fully-connected layers.
2972,@rasbt,2022-09-30 22:33:09+00:00,https://twitter.com/rasbt/status/1575977076431065088,"@_mb46_ You mean re why CNNs are small? That's basically due to parameter sharing and sparse connectivity. 
(Whether these inductive biases came from making it computational feasible back then, or whether the small size is just a nice side-effect of these inductive biases, that I dunno)"
2973,@rasbt,2022-09-30 21:40:57+00:00,https://twitter.com/rasbt/status/1575963939677970434,@leonpalafox @arkosiorek A Song of Stress and Ire
2974,@rasbt,2022-09-30 21:37:59+00:00,https://twitter.com/rasbt/status/1575963192001323008,4-layer multilayer perceptron https://t.co/gHGFkVTaWq
2975,@rasbt,2022-09-30 21:35:03+00:00,https://twitter.com/rasbt/status/1575962453506404353,"@alfcnz Awesome! Great start into the weekend, I guess!? üéâ

PS: Also can't wait for the book release!! üôå"
2976,@rasbt,2022-09-30 21:32:37+00:00,https://twitter.com/rasbt/status/1575961840819253249,sometimes I forget to appreciate how small CNNs can be https://t.co/AxzLPweAFw
2977,@rasbt,2022-09-30 20:20:46+00:00,https://twitter.com/rasbt/status/1575943759023439884,"@Buntworthy Haha, having worked with tabular datasets &amp; the one gazillion DataFrame libraries, I actually welcomed the simplicity of image data and arrays"
2978,@rasbt,2022-09-30 19:45:20+00:00,https://twitter.com/rasbt/status/1575934842835177472,"@akashpalrecha98 Guilty üòÖ 
https://t.co/dz86ztVGdh"
2979,@rasbt,2022-09-30 19:32:49+00:00,https://twitter.com/rasbt/status/1575931694195957760,@marktenenholtz @giffmana @wightmanr @ducha_aiki Or back in grad school when everyone was trying to configure Spark when you could just run it on a different machine using pandas üòÜ
2980,@rasbt,2022-09-30 19:27:44+00:00,https://twitter.com/rasbt/status/1575930411360083969,@arkosiorek The Game of Grants
2981,@rasbt,2022-09-30 18:51:05+00:00,https://twitter.com/rasbt/status/1575921191050584064,@gasteigerjo @TmlrOrg I.e. the ability to fine-tune on a target dataset w/o much effort is a form of generalizability as well.
2982,@rasbt,2022-09-30 18:49:54+00:00,https://twitter.com/rasbt/status/1575920893372428288,"@gasteigerjo @TmlrOrg Interesting work! It‚Äôs kind of an interesting point ‚Ä¶ on the one hand a scientists would like to have generalizable methods (force fields for molecular dynamics come to mind), on the other hand the strength of machine learning is that it is highly customizable to the given data"
2983,@rasbt,2022-09-30 18:37:20+00:00,https://twitter.com/rasbt/status/1575917729919516692,"@moyix Hah, I‚Äôd say Dhariwal and Nichol already called it back in 2021. I had no clue until recently like early 2022 üòÜ https://t.co/YJfetpABih"
2984,@rasbt,2022-09-30 18:16:44+00:00,https://twitter.com/rasbt/status/1575912545331818496,"@kchonyc Imho you gave the (only) correct answer ‚Ä¶ Spoiler: it depends! 

PS: üíØknow what you mean haha.üòÜ"
2985,@rasbt,2022-09-30 18:06:26+00:00,https://twitter.com/rasbt/status/1575909952371449856,"@bodonoghue85 Let's not forget to thank Leibniz (1676), Linnainmaa (1970), and many others for paving the way! https://t.co/412T1PXFPw"
2986,@rasbt,2022-09-30 14:44:26+00:00,https://twitter.com/rasbt/status/1575859117557940224,"""researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation"" 
-- Richard Sutton, DeepMind  https://t.co/Z6ONbOrK6C"
2987,@rasbt,2022-09-30 14:41:48+00:00,https://twitter.com/rasbt/status/1575858455902007296,https://t.co/Xa2FyAGXnO
2988,@rasbt,2022-09-30 14:41:17+00:00,https://twitter.com/rasbt/status/1575858327418195972,a big mistake in old school ML is thinking that Moore's Law only applies to Intel¬Æ chips
2989,@rasbt,2022-09-30 14:30:51+00:00,https://twitter.com/rasbt/status/1575855699988709378,@gurdeepmaurya @beenwrekt They sure seem interested when they write grant proposals though üôÉ
2990,@rasbt,2022-09-29 21:00:14+00:00,https://twitter.com/rasbt/status/1575591304645423104,"@ccaballeroh10 üíØ! This goes back to Breiman's ""Two Cultures"" paper I'd say

https://t.co/UHq0CcuNo7"
2991,@rasbt,2022-09-29 18:58:13+00:00,https://twitter.com/rasbt/status/1575560595767640064,"@BenBlaiszik @MaximZiatdinov different company, but AlphaFold2 comes to mind"
2992,@rasbt,2022-09-29 18:57:23+00:00,https://twitter.com/rasbt/status/1575560387348811776,https://t.co/6XUWiyriDY
2993,@rasbt,2022-09-29 18:55:51+00:00,https://twitter.com/rasbt/status/1575560001367597057,@h3techdev @daniela_witten joking not joking üòÜ https://t.co/KAgsNe26Jj
2994,@rasbt,2022-09-29 18:36:35+00:00,https://twitter.com/rasbt/status/1575555154417692672,"Speaking of generating videos, our machine learning newsletter also features a video summary now!
Yes, it looks like perfect training data for generative AI research &amp; Make-A-Video apps, doesn't it? üòÜ"
2995,@rasbt,2022-09-29 17:09:43+00:00,https://twitter.com/rasbt/status/1575533292308365314,@daniela_witten Single layer neural networks üôÉ
2996,@rasbt,2022-09-29 17:07:55+00:00,https://twitter.com/rasbt/status/1575532839680053248,@hardmaru I am staying tuned for ‚Äútext-to-robot‚Äù
2997,@rasbt,2022-09-29 17:04:48+00:00,https://twitter.com/rasbt/status/1575532055521280004,"@beenwrekt Yup, this is what you get when the most brilliant minds in academia only work on toy datasets ü§∑‚Äç‚ôÇÔ∏è"
2998,@rasbt,2022-09-29 16:58:28+00:00,https://twitter.com/rasbt/status/1575530461245460480,@JFPuget Isn‚Äôt that the default on Reddit? I.e. each comment starts with 1 upvote.
2999,@rasbt,2022-09-29 16:28:21+00:00,https://twitter.com/rasbt/status/1575522881789902854,the ML world does not stand still üòµ‚Äçüí´
3000,@rasbt,2022-09-29 15:52:02+00:00,https://twitter.com/rasbt/status/1575513743634595840,"@zzdjb_desu I wish. I think it mostly comes down to the ""who is the reviewer"" lottery. Also, in my experience, reviewers don't read jorunal guidelines. E.g., if you submit a 7 page paper to a journal with a 7-page limit, reviewers still ask to add a ton of extra stuff &amp; put in the main paper"
3001,@rasbt,2022-09-29 15:49:12+00:00,https://twitter.com/rasbt/status/1575513029671849984,"@mohakbpatel If you make a few strong assumptions, I have an explanation here (at ~ minute 5:00) https://t.co/PocCKBi0WK"
3002,@rasbt,2022-09-29 15:46:25+00:00,https://twitter.com/rasbt/status/1575512330993008641,"@liuyao12 @Kaszanas yeah, that is a good suggestion"
3003,@rasbt,2022-09-29 15:45:04+00:00,https://twitter.com/rasbt/status/1575511991174807557,"@sugatoray Since reviewers are not anonymous to editors and vice versa, this was probably a politics thing."
3004,@rasbt,2022-09-29 15:44:20+00:00,https://twitter.com/rasbt/status/1575511802976387074,"@sugatoray These things happen, and I am mostly disappointed by the Editor, who did a poor job imho. In this case, we had 1 reviewer in strong favor, and this reviewer #2 with weird demands. I asked for a 3rd reviewer who can give an unbiased opinion but the editor just rejected"
3005,@rasbt,2022-09-29 15:43:05+00:00,https://twitter.com/rasbt/status/1575511488353148929,"@sugatoray The reviewer was probably the developer of at least one of these not closely related methods and wanted them included. Based on the results, our method was better, so my guess is that the reviewer was then still rejecting so their method doesn't look worse."
3006,@rasbt,2022-09-29 15:41:39+00:00,https://twitter.com/rasbt/status/1575511130776158208,"@sugatoray The ridiculous thing is that this was the 2nd round, after adding all the experiments the reviewer asked for. Except that I used the other methods' result directly from their paper because they didn't share their source code, it was impossible to rerun their method."
3007,@rasbt,2022-09-28 21:46:39+00:00,https://twitter.com/rasbt/status/1575240598247723008,"@wightmanr arg, I just tested this and you are right üò¢"
3008,@rasbt,2022-09-28 21:34:29+00:00,https://twitter.com/rasbt/status/1575237534396731393,@Kaszanas üíØ! I am actually really disappointed by the editor. Reviewer #1 really liked the paper; reviewer #2 wanted some non-closely related (probably their own) methods included. I asked for a 3rd reviewer but the editor just rejected due to not addressing unreasonable asks from R #2
3009,@rasbt,2022-09-28 21:31:32+00:00,https://twitter.com/rasbt/status/1575236794555461633,"Whoa, just noticed that PyTorch (1.10.0?) finally added ""same"" padding support in Conv2d (https://t.co/kyBtBbE33e). 
Why and how how did I miss that!? üôà https://t.co/vAwTj3CXVM"
3010,@rasbt,2022-09-28 20:06:19+00:00,https://twitter.com/rasbt/status/1575215346356985856,"@OmnesResNetwork It‚Äôs a tad better I‚Äôd say, but also a bit of the same thing. It does make sense for certain papers, sure üòä"
3011,@rasbt,2022-09-28 20:04:37+00:00,https://twitter.com/rasbt/status/1575214921088126976,"Me: we propose a new regularization technique improving all recent CNNs substantially. 
Reviewer: need to train a vision transformer on that dataset to claim SOTA. 
Me: wait, we didn‚Äôt say SOTA for CV at large + we are talking about CNNs. 
Editor: Do as reviewer 2 asked. Reject!"
3012,@rasbt,2022-09-28 16:29:14+00:00,https://twitter.com/rasbt/status/1575160717530918912,"@GiorgioMantova Or Stable Diffusion because they only compared to DALLE and VQGAN but not Imagen and various other GANs. And because they didn‚Äôt retrain DALLE on a different dataset. (‚ÄúOh wait, because DALLE source code is not publicly available? Doesn‚Äôt matter, I still want you to train it‚Äù)"
3013,@rasbt,2022-09-28 16:26:50+00:00,https://twitter.com/rasbt/status/1575160112150302720,@realeigenvalues In an ideal world they should if editors to a proper job. But yeah I‚Äôm this case I honestly was fed up with having to include unrelated &amp; unreasonable things because they might be the reviewer‚Äôs own pet method. Apparently my strategy did not work out. Reviewers are always right.
3014,@rasbt,2022-09-28 16:02:59+00:00,https://twitter.com/rasbt/status/1575154108444483585,"And ‚ÄúWe think that comparing xxx might be interesting to some readers, but it is not the primary focus. Also, we cannot run these experiments on different datasets as suggested due to the lack of code.‚Äù"
3015,@rasbt,2022-09-28 16:02:58+00:00,https://twitter.com/rasbt/status/1575154104942227456,"This was in response to my rebuttal text 
‚ÄúOur focus is on comparing our method with similar methods (xxx). [...] We want to emphasize that we do not make claims such as ""state-of-the-art"" in our paper and focus on a direct comparison with xxx &amp; xxx.‚Äù"
3016,@rasbt,2022-09-28 15:58:16+00:00,https://twitter.com/rasbt/status/1575152924459769856,@DSaience Sadly no. See the quote below.
3017,@rasbt,2022-09-28 15:47:03+00:00,https://twitter.com/rasbt/status/1575150101894422535,"-&gt; ""per the author's rebuttal, they 'do not make claims such as state-of-the-art' [...] For this reason, the paper makes no claims about how the proposed method compares to the state-of-the-art methods."""
3018,@rasbt,2022-09-28 15:47:03+00:00,https://twitter.com/rasbt/status/1575150099826614274,Meaningless because eg an ensemble method almost always beats a single model. Also you cannot compare exhaustively against all methods on all datasets ü§∑‚Äç‚ôÇÔ∏è
3019,@rasbt,2022-09-28 15:47:02+00:00,https://twitter.com/rasbt/status/1575150097704386560,"Whoa that's a new one: reviewer 2 rejected a paper today because I compared to recent &amp; related methods but didn't claim ""state-of-the-art"" -- I specifically avoided the term SOTA because it is meaningless. 

Lesson learned: just include the term SOTA &amp; claim your method is SOTA"
3020,@rasbt,2022-09-28 15:34:02+00:00,https://twitter.com/rasbt/status/1575146822863052803,@claud10contardo @JFPuget @JohnHolbein1 State-of-the-art. I literally got a paper rejected yesterday because I did not mention state-of-the-art. Ie the reviewer referenced me not using that word and because of that cannot accept the article.
3021,@rasbt,2022-09-28 14:36:23+00:00,https://twitter.com/rasbt/status/1575132317512867840,@karpathy This! And college math classes would be much more accessible this way!
3022,@rasbt,2022-09-28 14:33:43+00:00,https://twitter.com/rasbt/status/1575131643937017858,@elonmusk Alien Invasion Day? Can't wait!
3023,@rasbt,2022-09-28 14:30:29+00:00,https://twitter.com/rasbt/status/1575130831236071424,"@zacharylipton AI as in ""Airport Inspection""?"
3024,@rasbt,2022-09-28 14:28:01+00:00,https://twitter.com/rasbt/status/1575130209359118337,"@maosbot Maybe not ""flawed"" but ""limited"" (or ""narrow"") üôÉ"
3025,@rasbt,2022-09-28 14:23:19+00:00,https://twitter.com/rasbt/status/1575129030277451778,"@thegautamkamath Depends. The spontaneous thought (which of course doesn't apply universally) is
If it's a company paper: funding &amp; being the department manager.
If it's an academic paper: funding, possibly some writing, and contribution of the key idea(s)."
3026,@rasbt,2022-09-27 18:36:06+00:00,https://twitter.com/rasbt/status/1574830253926645760,"@LightningAI Taking a statistical pattern rec class in grad school and realizing that supervised learning can could automate away so many tedious tasks üí™ (was working on a ligand/drug-discovery pipeline back then).

Today, I still use many of these techniques as a Bayesline (no pun intended)"
3027,@rasbt,2022-09-27 18:17:54+00:00,https://twitter.com/rasbt/status/1574825675571302424,"@leonpalafox *Spoiler alert*
As if opinions could be changed üôÉ"
3028,@rasbt,2022-09-27 18:09:35+00:00,https://twitter.com/rasbt/status/1574823581389033473,‚òùÔ∏è btw. the resolution-upscaling of the image above is courtesy of said deep learning https://t.co/ALAsbBfPoR
3029,@rasbt,2022-09-27 18:05:38+00:00,https://twitter.com/rasbt/status/1574822590274740224,"The ""10-year AlexNet won ImageNet"" anniversary (aka birthday of Deep Learning) is 3 days away ...

... and the DL/symbolic AI research Twitter goes full-blown WOTI ü§∑‚Äç‚ôÇÔ∏è

(https://t.co/UrBkfdRntL) https://t.co/nAX2s1Wdcd"
3030,@rasbt,2022-09-27 14:51:18+00:00,https://twitter.com/rasbt/status/1574773680835641344,@AllenDowney Permutation &amp; randomization tests ftw!
3031,@rasbt,2022-09-27 14:39:26+00:00,https://twitter.com/rasbt/status/1574770694394728451,"Btw if you liked ""Statistical Modeling: The Two Cultures"", there is also a more recent take: ""Data science vs. statistics: two cultures?"" https://t.co/iILu18mJpu"
3032,@rasbt,2022-09-27 14:36:31+00:00,https://twitter.com/rasbt/status/1574769961763061762,@rather__aarif oops. Should be back up?
3033,@rasbt,2022-09-27 14:33:08+00:00,https://twitter.com/rasbt/status/1574769109895680001,"Yes! The ""Statistical Modeling: The Two Cultures"" paper is one of my favorites. 
Teaching a machine learning course in a statistics department, this is one of the first papers I reference to get everyone onto the same page :) https://t.co/TacGFMJURN"
3034,@rasbt,2022-09-27 14:24:31+00:00,https://twitter.com/rasbt/status/1574766943902601217,"@xamat One thing comes to mind here ""First they ignore you. Then they laugh at you. Then they fight you. Then you win"" (Gandhi). 
But yeah, to be honest, I feel like there is too much drama in the ML community. I would just let it go, it's really not worth stressing over other people"
3035,@rasbt,2022-09-27 00:22:42+00:00,https://twitter.com/rasbt/status/1574555091859697664,"@CalcCon @chrisalbon If you have a buggy notebook though, it's actually not inconvenient to run it in an interactive session. It's basically like an interactive post mortem debugger like `python -mpdb your_code.py`"
3036,@rasbt,2022-09-26 21:12:40+00:00,https://twitter.com/rasbt/status/1574507270343360528,"@jerrycxu @knitesh Yeah! Hah, maybe because it doesn‚Äôt matter for accuracy/ROC AUC tables in research papers and kaggle submissions :P"
3037,@rasbt,2022-09-26 16:20:48+00:00,https://twitter.com/rasbt/status/1574433820345933826,"@chrisalbon This! When students encounter weird bugs and show me their notebooks, I do a restart &amp; run all, and the issue goes magically away 95% of the time."
3038,@rasbt,2022-09-26 16:15:59+00:00,https://twitter.com/rasbt/status/1574432604585136132,@joshualeond @m_elantkowski @chrisalbon @MochiCardsApp Look cool! thanks for sharing
3039,@rasbt,2022-09-26 16:15:22+00:00,https://twitter.com/rasbt/status/1574432449534337024,"@mrclbschff No, I really dislike tikz üòÜ (I am not good enough at it, so for me it would be a massive time sink)"
3040,@rasbt,2022-09-26 16:14:20+00:00,https://twitter.com/rasbt/status/1574432189936287748,@boi67554 glad to hear that the explanations were clear and helpful!!
3041,@rasbt,2022-09-26 16:12:38+00:00,https://twitter.com/rasbt/status/1574431764331859969,"@benitocm1 @Centropy3 @tunguz yes, you could drop in the cross_val_score via sklearn there."
3042,@rasbt,2022-09-26 15:31:33+00:00,https://twitter.com/rasbt/status/1574421424227450887,"@unsorsodicorda still quicktime for the screen recording; it's the most robust imho (never crashed on me, knock on wood)"
3043,@rasbt,2022-09-26 15:00:26+00:00,https://twitter.com/rasbt/status/1574413593231200258,"@unsorsodicorda Yes that's correct! Just quicktime screen recording. Back then, I had limited time, a bad monitor, and an unfortunate 4:3 aspect ratio. Would look much better if I'd record that today, haha"
3044,@rasbt,2022-09-26 14:57:20+00:00,https://twitter.com/rasbt/status/1574412813711327237,@MikeStirner stay tuned ... ‚ò∫Ô∏è
3045,@rasbt,2022-09-26 14:56:12+00:00,https://twitter.com/rasbt/status/1574412527236255745,"@jerrycxu @JulienMouchnino @68kirk Platt scaling and isotonic regression definitely keep the monotonicity, yes. The only thing is you can maybe get ties, but that's rare."
3046,@rasbt,2022-09-26 14:55:06+00:00,https://twitter.com/rasbt/status/1574412249833299971,@unsorsodicorda I am uploading them directly to YouTube actually. This way you can swap and edit them later.
3047,@rasbt,2022-09-25 23:23:34+00:00,https://twitter.com/rasbt/status/1574177822813331458,"@vlordier @GoogleAI @DeepMind @OpenAI Ok, you may call this simple ASR, but this was actually truly useful to me. I can‚Äôt say the same thing about DALLE/Imagen or GPT/Chinchilla etc."
3048,@rasbt,2022-09-25 22:22:34+00:00,https://twitter.com/rasbt/status/1574162472843546626,"@sheraj_ilir Yeah, there is some overlap. E.g., the transformer lecture was indeed the template for the (more thorough) chapter on transformers in the book. Glad you like it! üôå‚ò∫Ô∏è"
3049,@rasbt,2022-09-25 22:19:29+00:00,https://twitter.com/rasbt/status/1574161695441920001,"@ItaDude Sorry, but I just checked and have to prove you wrong üòõ
(from https://t.co/yjItyW5MQZ) https://t.co/vv8xKHS2Sq"
3050,@rasbt,2022-09-25 22:10:18+00:00,https://twitter.com/rasbt/status/1574159385995214851,"@GiorgioMantova @chrisalbon Yeah, I can share them some day somehow"
3051,@rasbt,2022-09-25 22:10:01+00:00,https://twitter.com/rasbt/status/1574159313077256195,"@ZzimM @chrisalbon I currently only have decks for those topics, I did a purge ~last year to keep it rather simple https://t.co/7J3uiHo6sc"
3052,@rasbt,2022-09-25 22:08:14+00:00,https://twitter.com/rasbt/status/1574158863565193216,"@m_elantkowski @chrisalbon @MochiCardsApp I am putting in things I want to remember from various topic areas. Have about ~500 cards (but I did a reset like a year ago; before that I had many thousands). 
Regarding Mochi, does it sync with the Desktop Anki? https://t.co/Xft5Ng03oH"
3053,@rasbt,2022-09-25 20:19:12+00:00,https://twitter.com/rasbt/status/1574131426517204992,"@ammaryh92 üíØ. YT closed captions are really really bad. At least in my case. It can‚Äôt handle my voice at all. I used Descript and more recently Otter, which were far better. But whisper is another level. But yeah the CLI interface doesn‚Äôt allow live translations."
3054,@rasbt,2022-09-25 19:57:56+00:00,https://twitter.com/rasbt/status/1574126071867400199,@chrisalbon Anki of course!
3055,@rasbt,2022-09-25 19:25:49+00:00,https://twitter.com/rasbt/status/1574117990747885569,"@predict_addict Thanks for sharing! Something to dig into some time! I hate to be this person, but well, since it's below the said thread ...  as reviewer would ask ""how does this compare to I-splines""?"
3056,@rasbt,2022-09-25 19:21:42+00:00,https://twitter.com/rasbt/status/1574116956218736640,"Couldn't fit it into the original tweet above, but if you are interested &amp; find it useful, here is the simple script to automate the subtitle generation from video files: 
https://t.co/tNiHMFuJaS"
3057,@rasbt,2022-09-25 19:21:42+00:00,https://twitter.com/rasbt/status/1574116954159435778,"After some more experiments with OpenAI's whisper &amp; I continue being impressed! üëå
So impressed that I let my GPUs do some crunching over the wknd. 
Tada, all subtitles (closed-captions) of the 170 vids in my DL course are whisper-based now üöÄ https://t.co/8FhMfL6v3N

Script üëá"
3058,@rasbt,2022-09-25 17:14:21+00:00,https://twitter.com/rasbt/status/1574084905675407360,"@FrankRHutter In either case, I'd say this is a hardware limitation. S.o. could probably make it work on a 32 gig V100 cloud instance w/o problems."
3059,@rasbt,2022-09-25 17:12:19+00:00,https://twitter.com/rasbt/status/1574084394809180165,"@FrankRHutter Has been some time and need to find the code to say more. But in general, I'd say CPU vs GPU RAM is not a fair comparison as CPU usually requires more RAM since it doesn't support mixed precision training etc."
3060,@rasbt,2022-09-25 14:40:42+00:00,https://twitter.com/rasbt/status/1574046240848973828,@DavidSKrueger Because the classic ‚Äúoverpopulation on Mars‚Äù analogy still holds
3061,@rasbt,2022-09-25 13:41:41+00:00,https://twitter.com/rasbt/status/1574031388143230976,"@radekosmulski @JFPuget Awesome post!! If you ever run out of topics, I have a reading list for you haha https://t.co/VAXJRBMyzj"
3062,@rasbt,2022-09-25 13:38:51+00:00,https://twitter.com/rasbt/status/1574030674016849922,"Do you like cherry picking üçí? 

Then generative models (here: language transformers and diffusion models for images) can be a lot of fun. 

But don‚Äôt let them loose in real world applications w/o supervision. Research idea: Maybe we need to bring back ‚Äúdiscriminators‚Äù for those?"
3063,@rasbt,2022-09-24 22:20:48+00:00,https://twitter.com/rasbt/status/1573799639815491584,"@422Christopher @svpino I hope so! I have a chapter on traditional ML for sentiment classification, one on recurrent neural nets (an older deep learning architecture), and one on transformers (the most modern way)."
3064,@rasbt,2022-09-24 15:11:31+00:00,https://twitter.com/rasbt/status/1573691606967910402,@CSProfKGD Awesome collection! Btw Ithink every department should have a ‚Äúpresentation 101‚Äù class. Mandatory for both students and professors üòõ. @alfcnz teaching it üòÅ
3065,@rasbt,2022-09-24 13:23:37+00:00,https://twitter.com/rasbt/status/1573664451861028865,@ylecun @mustafasuleymn Totally. Even prohibitively large resource requirements won‚Äôt stop anyone. I mean how long did it take for neo-GPT and Stable Diffusion to follow their proprietary counterparts. Not even multiple months really.
3066,@rasbt,2022-09-24 13:18:06+00:00,https://twitter.com/rasbt/status/1573663064045633539,"@thegautamkamath Tablets ftw. Actually allowing me to neatly erase things while I work things out was really a game cha get for me. That being said, I usually prefer derivations &amp; exploration through coding."
3067,@rasbt,2022-09-24 13:03:48+00:00,https://twitter.com/rasbt/status/1573659465559248896,"@alxblzs @svpino Thanks so much, it feels really good to hear that üòä"
3068,@rasbt,2022-09-24 13:02:55+00:00,https://twitter.com/rasbt/status/1573659245349830656,@acosta_guille @svpino I think that‚Äôd be awesome. I am sure the publisher would also be excited if someone worked on that
3069,@rasbt,2022-09-24 12:57:40+00:00,https://twitter.com/rasbt/status/1573657922143494145,"@iodowilson @svpino Other than that the only laptop with reasonable specs for deep learning I know is this one https://t.co/BfqBt3Lg1F. I am not affiliated, it‚Äôs just the only one I am aware of. I‚Äôd probably not buy anything like that and go for a MacBook Air and cloud resources (or desktop)"
3070,@rasbt,2022-09-24 12:55:22+00:00,https://twitter.com/rasbt/status/1573657342469672963,"@iodowilson @svpino I probably wouldn‚Äôt get a laptop for training deep neural networks. Due to heat issues, and for many real world scenarios you‚Äôd have to have it running multiple days without being able to do much else on the computer. I would consider cloud resources for the heavy lifting"
3071,@rasbt,2022-09-24 12:53:17+00:00,https://twitter.com/rasbt/status/1573656820547260416,"@iodowilson @svpino made sure that most of the stuff runs in reasonable time on CPU actually, no worries. Otherwise there we also have pointers to cloud resources for GPU computing (your GPU is generally good but it‚Äôs a bit low on RAM when it comes to deep learning)"
3072,@rasbt,2022-09-24 12:23:14+00:00,https://twitter.com/rasbt/status/1573649256744894464,@NaseemHM For computer vision benchmarks I would refer to @wightmanr ‚Äòs TIMM https://t.co/Ow8PHbtYYC
3073,@rasbt,2022-09-24 12:19:05+00:00,https://twitter.com/rasbt/status/1573648210928828416,"@68kirk Yeah I see it more as a 2-step procedure. Train a model with good predictive performance, then apply post-hoc methods for calibration"
3074,@rasbt,2022-09-24 12:17:27+00:00,https://twitter.com/rasbt/status/1573647801451483139,@svpino Thanks so much for the kind words üôå
3075,@rasbt,2022-09-24 12:15:33+00:00,https://twitter.com/rasbt/status/1573647322294149121,@roydanroy DeblurGAN https://t.co/mEFl50NFOe
3076,@rasbt,2022-09-23 21:57:34+00:00,https://twitter.com/rasbt/status/1573431405958549507,"@cobra_winfrey @LightningAI Wohoo, welcome to the team! üéâ‚ö°Ô∏è"
3077,@rasbt,2022-09-23 18:43:48+00:00,https://twitter.com/rasbt/status/1573382640257957890,"@m_elantkowski Or, calculating the least squares coefficients (params, weights) in linear regression via

üìà  covariance divided by variance = statistics
üìê  closed form solution = linear algebra
ü§ñ  gradient descent = ML
 
but just kiddingüòÜ, I actually agree with you there."
3078,@rasbt,2022-09-23 18:29:58+00:00,https://twitter.com/rasbt/status/1573379159052750848,"Challenge question, how about NODE (Neural Oblivious Decision Ensembles), i.e., combining decision trees and deep neural networks such that they are trainable üòÜ (https://t.co/JkFNi6i3O2). 
I guess that turns it into a multi-label classification problem üòâ"
3079,@rasbt,2022-09-23 18:27:17+00:00,https://twitter.com/rasbt/status/1573378483824496641,"How would we take this further?

üå≤üå≤  Random forests &amp; bagging = Statistics (bootstrapping)

üå≤üå≤  Adaptive boosting = computer science? (optimization &amp; metaheuristics?) 

üå≤üå≤ Gradient boosting = (Calculus based) statistics (gradients, least squares, log-loss)"
3080,@rasbt,2022-09-23 18:20:52+00:00,https://twitter.com/rasbt/status/1573376871294816258,"That's an interesting question. For decision trees it's kind of fun one to think about ü§î. I'd say

üå≤ ID3/Q4.5 = computer science (information theory / entropy); 

üå≤ CART = statistics (Gini impurity; based on probability scores)

(~same concept yet different interpretation)"
3081,@rasbt,2022-09-23 18:05:17+00:00,https://twitter.com/rasbt/status/1573372947754274817,"@Diadochokinetik Yeah, actually also used it in my book for building a simple web app (https://t.co/aptHk61WEx) 

https://t.co/u5WfDGivc9"
3082,@rasbt,2022-09-23 18:00:13+00:00,https://twitter.com/rasbt/status/1573371675101761543,@FreakX19 yes
3083,@rasbt,2022-09-23 15:36:07+00:00,https://twitter.com/rasbt/status/1573335411681894404,@SergeyFeldman Yes!! üíØ
3084,@rasbt,2022-09-23 14:59:28+00:00,https://twitter.com/rasbt/status/1573326184921841665,@Ukerzel @mariofilhoml I'd say the hyperparameter space was much smaller though :P
3085,@rasbt,2022-09-23 14:52:48+00:00,https://twitter.com/rasbt/status/1573324507812888576,"Awesome thread on model calibration! 

In addition to Platt scaling and isotonic regression, I recently discovered I-Splines, which look like a nice thing to add to the arsenal of calibration techniques. 

There's a great post about it here: https://t.co/5oqFX9UFK1"
3086,@rasbt,2022-09-23 14:48:28+00:00,https://twitter.com/rasbt/status/1573323416358498304,"@proflog @CSProfKGD @TilburgU @TilburgU_TiSEM Nice! Sounds like a much needed, fun event. There are rejections due to silly mistakes &amp; silly reviewers--in either case, a place to share (and vent) will probably help with coping &amp; improving! (Both as a student &amp; faculty, paper rejections were among the most stressful things!)"
3087,@rasbt,2022-09-23 14:41:31+00:00,https://twitter.com/rasbt/status/1573321667761381376,"SQLite started my blogging career about 1 decade (!) ago (https://t.co/BXp8RVIu0g)!

Honestly, 5 years ago I thought it would be abandoned by 2022! üòÖ

But no, it just got a little update resulting in a 4.2X speedup üöÄ
""SQLite: Past, Present, and Future"" https://t.co/wn89JjjPiC"
3088,@rasbt,2022-09-23 14:32:11+00:00,https://twitter.com/rasbt/status/1573319319366385666,This might well be the cleanest and clearest PyTorch coding tutorial I've seen so far. Double BAM!!
3089,@rasbt,2022-09-23 14:28:44+00:00,https://twitter.com/rasbt/status/1573318453540560897,"@FrankRHutter Thanks for clarifying! I'd still stay including it probably wasn't a fair comparison since that may make it look worse than it really is. 
Just curious, what memory did your machine have? I recall running NODE on my 2018 workstation ~last year (1080Ti with 11 Gb VRAM)."
3090,@rasbt,2022-09-23 14:23:47+00:00,https://twitter.com/rasbt/status/1573317205894500352,"@FrankRHutter Yes sure, no worries, wasn't talking about claims. But yeah, I guess that searching for regularization cocktails can also improve other architectures üòä. Interesting future study &amp; food for thought for the next kaggle competitionüöÄ"
3091,@rasbt,2022-09-23 00:55:38+00:00,https://twitter.com/rasbt/status/1573113827117391872,"@mariofilhoml It would be interesting to see a similar plot including a sweep over the 13 regularization techniques from that other paper, maybe even going up to 1000 iters and seeing what happens üòÜ."
3092,@rasbt,2022-09-23 00:53:49+00:00,https://twitter.com/rasbt/status/1573113370378739712,"@mariofilhoml I have a similar gut feeling. The one counterpoint though is in this figure from https://t.co/qqOGJsfCsN. On the other hand, maybe 100 iterations are not enough for these large hyperparameter spaces. https://t.co/9M265MUfII"
3093,@rasbt,2022-09-22 23:56:29+00:00,https://twitter.com/rasbt/status/1573098943772491776,"@nmvrodrigues Yes, that's definitely bad. Could be anything so that number is pretty meaningless. I've also noticed a bad habit in ML where people do refer to things as 95% CI but don't specify how they computed the CI -- there are so many ways to do this https://t.co/CWcHmjqNQ4"
3094,@rasbt,2022-09-22 18:46:14+00:00,https://twitter.com/rasbt/status/1573020864924491777,"@TaliaRinger I got a FaceTime call from my mother (""Mama is calling"") during one of my first talks back when I was a PhD student. I would laugh about it today, but I was pretty embarrassed back then üòÜ. 
It was a good icebreaker though and the audience thought it was hilarious"
3095,@rasbt,2022-09-22 18:07:21+00:00,https://twitter.com/rasbt/status/1573011079726350336,"@CalcCon Unfortunately no; it's only the experiment code. On the other hand, they were all relatively quick to run I'd say, because it's tabular datasets and small models."
3096,@rasbt,2022-09-22 17:31:20+00:00,https://twitter.com/rasbt/status/1573002018532229120,"@ChristophMolnar I also just remembered GANs and capsule nets üòõ
https://t.co/XBxV3rfkFx"
3097,@rasbt,2022-09-22 14:52:55+00:00,https://twitter.com/rasbt/status/1572962149902815232,"@CamiloC06674659 @ChristophMolnar Thanks, glad you like it overall! And see, if I spent more space on SVMs, the ensemble section would have to be a lot denser even üòã"
3098,@rasbt,2022-09-22 14:44:10+00:00,https://twitter.com/rasbt/status/1572959948996489217,"@CamiloC06674659 @ChristophMolnar Hah, yes, but I am not teaching that in my classes."
3099,@rasbt,2022-09-22 14:30:50+00:00,https://twitter.com/rasbt/status/1572956592923893763,"@ricardoaraujo @ChristophMolnar So, I'd make the trade-off and go directly from perceptron -&gt; logistic regression (not guaranteed max margin, but large margin at least) because max likelihood is relevant for both GBMs and neural nets"
3100,@rasbt,2022-09-22 14:29:59+00:00,https://twitter.com/rasbt/status/1572956378108493824,"@ricardoaraujo @ChristophMolnar Sure, but there is always finite time in a class; in an ideal world I would cover it, but than it has to come at the expense of other, more relevant topics. E.g., I don't know any intro ML class that teaches gradient boosting machines for classification."
3101,@rasbt,2022-09-22 14:24:05+00:00,https://twitter.com/rasbt/status/1572954894406979587,"@JulienMouchnino Yeah, it has a simple CLI and works w/o problems for me on macOS; I don't have a Windows computer so I am not sure about the installation there."
3102,@rasbt,2022-09-22 13:22:12+00:00,https://twitter.com/rasbt/status/1572939320121753600,@JulienMouchnino You can find the command I used in the upper right of the figure above
3103,@rasbt,2022-09-22 13:17:10+00:00,https://twitter.com/rasbt/status/1572938052674392066,@ChristophMolnar SVMs are sth you won‚Äôt find in my syllabus (anymore) is all I am saying üôÉ
3104,@rasbt,2022-09-22 13:15:57+00:00,https://twitter.com/rasbt/status/1572937747882737666,"@leonpalafox @ChristophMolnar Yeah I agree, I remember when nonlinear kernels were all the rage. But in practice they don‚Äôt scale very well due to their O(n^2) complexity. Both training and inference."
3105,@rasbt,2022-09-22 13:10:27+00:00,https://twitter.com/rasbt/status/1572936362096992257,@leonpalafox @ChristophMolnar If you consider sparse problems like bag of word vectors you can sometimes see a more noticeable difference for hinge loss as well. But yeah on most problems the solutions (boundaries) are similar which is why I find SVMs a bit redundant
3106,@rasbt,2022-09-22 13:07:00+00:00,https://twitter.com/rasbt/status/1572935495092674562,"@leonpalafox @ChristophMolnar Hmm, no that can‚Äôt be. I think it‚Äôs impossible because of the log loss vs hinge loss. You may get identical classifications on some datasets, but in general it‚Äôs similar not identical. (Another thing are of course the probability scores of you care about them)"
3107,@rasbt,2022-09-22 12:47:57+00:00,https://twitter.com/rasbt/status/1572930701682479105,"@leonpalafox @ChristophMolnar That being said, I still throw in a nonlinear kernel SVM for small datasets (actually just did that last weekend). It‚Äôs useful &amp; still had its place. Eg a well-tuned RBF SVM is always a good sanity check / baseline to make sure your XGBM or neural net models are properly tuned."
3108,@rasbt,2022-09-22 12:45:24+00:00,https://twitter.com/rasbt/status/1572930059593469953,"@leonpalafox @ChristophMolnar I sometimes throw in a linear SVM because it‚Äôs cheap, but when both are properly tuned and regularized, I find that the results are indistinguishable from logistic regression. Imho nonlinear kernel SVMs are outdated and scale horribly; almost always GBMs &amp; MLP are a better choice"
3109,@rasbt,2022-09-21 19:47:07+00:00,https://twitter.com/rasbt/status/1572673801175060481,"@Pin__Terest Yup, I am impressed that it can handle technical jargon like RNN and LSTM etc."
3110,@rasbt,2022-09-21 19:35:39+00:00,https://twitter.com/rasbt/status/1572670915866988545,"Was curious and just gave it a try. It's legit &amp; works great. 
Here a comparison using a random video of mine (L19.3 RNNs with an Attention Mechanism: https://t.co/wWP6ncVAos)

(I am not affiliated with any of this) https://t.co/yyvguxfATH"
3111,@rasbt,2022-09-21 18:31:54+00:00,https://twitter.com/rasbt/status/1572654870825693187,"@Centropy3 @tunguz On that note, wasn't the trend a few years ago to keep the learning rate fixed but adjust the epochs, where learning rate is more of a ""how many epochs can you afford computationally"" param?"
3112,@rasbt,2022-09-21 17:45:01+00:00,https://twitter.com/rasbt/status/1572643074219642881,"@tunguz @TechCrunch Yeah, definitely weird."
3113,@rasbt,2022-09-21 17:43:40+00:00,https://twitter.com/rasbt/status/1572642734405554178,@tunguz Awesome! Thanks! and bookmarked!
3114,@rasbt,2022-09-21 17:42:57+00:00,https://twitter.com/rasbt/status/1572642554558160896,@tunguz @TechCrunch Asterisk: that‚Äôs the macOS AppStore version. It remains free if you download it via their website.
3115,@rasbt,2022-09-21 16:41:52+00:00,https://twitter.com/rasbt/status/1572627180554797057,"@RexDouglass Personally, I've recently become a fan of MCC üòä: https://t.co/NzvhC5FbuI. It'd be nice to include the comparison for additional metrics like you suggest (maybe in the appendix). On the other hand, to keep things simple, I think BAccuracy is a fine choice for a general audience"
3116,@rasbt,2022-09-21 16:35:42+00:00,https://twitter.com/rasbt/status/1572625626984583168,@RexDouglass I see. So you are more interested in ROC. On the other hand ROC AUC would not be affected by calibration though ü§î (at least for platt scaling and mostly for isotonic regression; I-splines could slightly effect that)
3117,@rasbt,2022-09-21 16:29:37+00:00,https://twitter.com/rasbt/status/1572624096638246913,"@RexDouglass * Also, they did mention that their datasets were quite balanced."
3118,@rasbt,2022-09-21 16:28:57+00:00,https://twitter.com/rasbt/status/1572623931764510720,"@RexDouglass 2/2 Re balanced accuracy, there are 2 ways you compute it (https://t.co/YALnzdGjiA), and I am not sure which one they used. I do like it (actually both).
Also, I think calibration is a separate problem because you can to it as a post-hoc procedure."
3119,@rasbt,2022-09-21 16:28:28+00:00,https://twitter.com/rasbt/status/1572623806551986178,"@RexDouglass Thanks for the paper; haven't read this yet and it sounds intriguing. Haha, not trying to do a rebuttal here, but a few thoughts 1/2"
3120,@rasbt,2022-09-21 16:21:48+00:00,https://twitter.com/rasbt/status/1572622130746892289,"@RexDouglass Good points. Actually, all your points (except 2) are basically addressed in this figure here. (Okay, for 3, it's based on relative ranks rather than absolute diffs, but that makes more sense across datasets): https://t.co/5m8bFTi1m9"
3121,@rasbt,2022-09-21 16:16:43+00:00,https://twitter.com/rasbt/status/1572620852235235328,"Something to look into: I am curious how they applied these to tabular datasets since these are originally for image dataü§î. E.g., how would you apply Cut-Out to a tabular dataset? Just masking entries? (Any pointers @FrankRHutter?) https://t.co/P5w7or4Sh6"
3122,@rasbt,2022-09-21 16:14:10+00:00,https://twitter.com/rasbt/status/1572620209768337412,"@rezar Not sure which benchmark you mean. But regarding LightGBM, that was unfortunately not included in this study."
3123,@rasbt,2022-09-21 16:06:07+00:00,https://twitter.com/rasbt/status/1572618182887903234,"@TheZachMueller Oh, forgot to mention the GitHub link: https://t.co/FHRbqFlcz6. Here you go, enjoy the distraction üòâ"
3124,@rasbt,2022-09-21 15:59:14+00:00,https://twitter.com/rasbt/status/1572616452934631425,"[9/9]
Now, the interesting question, is this an appropriate selection of hyperparameters and ranges for XGBoost, @tunguz? https://t.co/Fd2nZw4gtV"
3125,@rasbt,2022-09-21 15:59:14+00:00,https://twitter.com/rasbt/status/1572616451193982977,"[8/9]
Caveats: the authors included NODE in the comparison but used did not tune its hyperparameters. Also, the regularization techniques were not applied to the other neural network architectures (TabNet and NODE)."
3126,@rasbt,2022-09-21 15:59:14+00:00,https://twitter.com/rasbt/status/1572616449704984579,"[7/9]
The comparison spans 40 tabular datasets for classification, ranging from 452 to 416,188 examples. In 19 out of the 40 datasets, an MLP with a mix regularization techniques outperformed any other method evaluated in this study."
3127,@rasbt,2022-09-21 15:59:13+00:00,https://twitter.com/rasbt/status/1572616447297490945,"[6/9]
And here are the frequencies of the different techniques being used across the different datasets. Note that the regularization cocktail search was part of the hyperparameter search &amp; tuning procedure. https://t.co/Ze30C57QFA"
3128,@rasbt,2022-09-21 15:59:13+00:00,https://twitter.com/rasbt/status/1572616445309386752,"[5/9] 
Augmentation: 
(10) Mix-Up (https://t.co/190mCraKCz)
(11) Cut-Mix (https://t.co/KZKu3quV2x)
(12) Cut-Out (https://t.co/x7NSPSRVb6)
(13) FGSM adversarial learning (https://t.co/Zrou7SS7gR)"
3129,@rasbt,2022-09-21 15:59:12+00:00,https://twitter.com/rasbt/status/1572616443505557512,"[4/9] 
Structural regularization and linearization: 
(7) Skip connections (https://t.co/9kNHuc2GCl)
(8) Shake-Drop (https://t.co/YuEMsnTP22)
(9) Shake-Shake (https://t.co/HW5h3cyWrg)"
3130,@rasbt,2022-09-21 15:59:12+00:00,https://twitter.com/rasbt/status/1572616441685512194,"[3/9] 
Ensembling techniques: 
(5) Dropout (https://t.co/egpreHOA68)
(6) Snapshot ensembles (https://t.co/HnQYeMm3RV)"
3131,@rasbt,2022-09-21 15:59:11+00:00,https://twitter.com/rasbt/status/1572616439722348544,"[2/9] These 13 regularization techniques were considered in this study

Implicit: 
(1) BatchNorm (https://t.co/UwWufPdbFR)
(2) stochastic weight averaging (https://t.co/S4LsGICsnH)
(3) Look-ahead optimizer (https://t.co/15PXEBz80X)
(4) Weight decay (https://t.co/f0Jt16uKhn)
..."
3132,@rasbt,2022-09-21 15:59:11+00:00,https://twitter.com/rasbt/status/1572616437977546754,"How can you beat XGBoost, CatBoost, and TabNet on tabular data? 
Use a cocktail of 13 modern regularization techniques! (https://t.co/Nvzm8RjK1M)
[1/9] https://t.co/l7pRD4rJMH"
3133,@rasbt,2022-09-21 13:38:12+00:00,https://twitter.com/rasbt/status/1572580958892879872,"@ChristophMolnar Both the normal approximation and bootstrapping of the test set contained the true parameter (accuracy) ~95% of the time for 95% CI's. This is tested on many, many independent test sets without dataset overlap."
3134,@rasbt,2022-09-21 13:37:01+00:00,https://twitter.com/rasbt/status/1572580662582071296,"@ChristophMolnar I didn't find this to be true in practice. I ran several simulation studies with 10-100 million data points. 
Some results 1/2

1) Normal approximation: 95.6%
2) Bootstrap, 1-sample CI: 98.5%
3) Bootstrap, percentile: 98.0%
4) Bootstrap, .632: 83.2%
5) Bootstrap test set: 94.5%"
3135,@rasbt,2022-09-21 13:30:06+00:00,https://twitter.com/rasbt/status/1572578922428248065,"@ZachariahNKM @ChristophMolnar Haha, yeah I am not arguing against conformal predictions. Quite the contrary. I just think that there are two different questions / application areas."
3136,@rasbt,2022-09-21 13:24:09+00:00,https://twitter.com/rasbt/status/1572577425221099520,"@ZachariahNKM @ChristophMolnar But aren't conformal prediction scores computed on a data-point level, i.e., they yield the uncertainty of predictions? How do you compare different classifiers across different datasets using conformal prediction scores?"
3137,@rasbt,2022-09-21 13:15:41+00:00,https://twitter.com/rasbt/status/1572575292681752580,"@mpaepper @JFPuget the best debugging check so far for me is checking whether I can achieve that 100% training accuracy when training on a single, small batch (like ~32 training examples)"
3138,@rasbt,2022-09-21 12:56:12+00:00,https://twitter.com/rasbt/status/1572570387816521728,"@ChristophMolnar but yeah, pleasing reviewers is an uphill battle üòÖ. I think I may drop academic paper writing &amp; reviewing for good, life is too short üòÜ"
3139,@rasbt,2022-09-21 12:53:33+00:00,https://twitter.com/rasbt/status/1572569722985783308,"@ChristophMolnar Another thing that became a point of confusion: when I use confidence intervals to report uncertainty estimates of perf metrics (eg accuracy), people recently started suggesting that I should use conformal predictions instead. But those are prediction intervals; apples &amp; oranges"
3140,@rasbt,2022-09-20 23:29:01+00:00,https://twitter.com/rasbt/status/1572367254540681216,@paul_rietschka @mlinpractice Or Swift for ML
3141,@rasbt,2022-09-20 23:28:43+00:00,https://twitter.com/rasbt/status/1572367179319808000,@paul_rietschka @mlinpractice Just came here to say: remember Julia? üòÜ
3142,@rasbt,2022-09-20 21:59:59+00:00,https://twitter.com/rasbt/status/1572344848488742912,@chrisalbon The big red flag üö©: their main business is centered around that self help book
3143,@rasbt,2022-09-20 21:56:17+00:00,https://twitter.com/rasbt/status/1572343918871576580,@owen_ozkan It‚Äôs a totally legit question and it‚Äôs definitely good to ask üëç
3144,@rasbt,2022-09-20 19:54:09+00:00,https://twitter.com/rasbt/status/1572313183653863425,"@owen_ozkan Yes, sorry. That's to keep the price down. We looked into that, but via amazon, it would have made the book unaffordable for most :( https://t.co/BCFqNoKUPr"
3145,@rasbt,2022-09-20 19:51:28+00:00,https://twitter.com/rasbt/status/1572312505908883456,@StephanSturges @permutans @NVIDIAGeForce they probably want you to use nvlink for that
3146,@rasbt,2022-09-20 18:31:42+00:00,https://twitter.com/rasbt/status/1572292434041896960,@sh_reya Nice! Just recently finished @chipro‚Äòs. Designing ML Systems book and this looks like an excellent follow-up!!
3147,@rasbt,2022-09-20 18:28:59+00:00,https://twitter.com/rasbt/status/1572291751225790466,@dabeaz That goes for both user interfaces and unregularized machine learning models üòÜ
3148,@rasbt,2022-09-20 18:20:21+00:00,https://twitter.com/rasbt/status/1572289575464144896,"@LightningAI @princeton_nlp @danqi_chen just remembered a conversation at a conference back in 2019 where asked me about implementing capsule nets for their cybersecurity related models. Back then I strongly advised to stay away from that. I still think that was good advice, but anyways what happened to capsule nets!?"
3149,@rasbt,2022-09-20 18:09:15+00:00,https://twitter.com/rasbt/status/1572286784071172099,@simonw https://t.co/zaLRvIsgg1
3150,@rasbt,2022-09-20 17:21:06+00:00,https://twitter.com/rasbt/status/1572274665367764992,@sidradcliffe @AiBeginners @permutans @NVIDIAGeForce Oh but up to 2x is quite different from 2-4x üôÉ
3151,@rasbt,2022-09-20 16:37:41+00:00,https://twitter.com/rasbt/status/1572263740191707136,"@AiBeginners @permutans @NVIDIAGeForce ah yes, I sometimes forget that you can use the same cards for video gaming as well üòÜ"
3152,@rasbt,2022-09-20 15:58:34+00:00,https://twitter.com/rasbt/status/1572253895589613569,"@JonathanSumDL You are also not wrong though; if you take the left plot and apply strong dropout, you can force the train/test accuracy be similarly close, but e.g., hovering around 60% -- in that case that would be underfitting."
3153,@rasbt,2022-09-20 15:57:17+00:00,https://twitter.com/rasbt/status/1572253574268350465,@permutans @NVIDIAGeForce Thanks. 2-4x faster sounds like a lot ü§Ø. Probably biggest year-to-year gain I've seen.
3154,@rasbt,2022-09-20 15:45:14+00:00,https://twitter.com/rasbt/status/1572250539055894530,"@ItaDude @JFPuget sure, that's basically logistic regression then"
3155,@rasbt,2022-09-20 15:30:14+00:00,https://twitter.com/rasbt/status/1572246766556151809,"@NVIDIAGeForce Awesome! Does anyone have a tl;dr in terms of 
1) VRAM
2) relative performance compared to the RTX 3090?"
3156,@rasbt,2022-09-20 15:26:31+00:00,https://twitter.com/rasbt/status/1572245831561904131,"@JFPuget Also: it's a feature, not a bug üòÅ"
3157,@rasbt,2022-09-20 15:25:48+00:00,https://twitter.com/rasbt/status/1572245647981707266,"@JFPuget Yes, I once forgot to insert activation functions at all layers but one, and the predictions / results were great üòÜ"
3158,@rasbt,2022-09-20 14:01:05+00:00,https://twitter.com/rasbt/status/1572224328888102919,"@hardmaru Now that's an interesting application of ""generative"" modeling"
3159,@rasbt,2022-09-20 13:53:05+00:00,https://twitter.com/rasbt/status/1572222315257270272,"@DrGroftehauge I meant LayerNorm above. But yes, some people put BatchNorm after the activation. The original paper proposes to put it before the activation, though, and I think that's the most common way."
3160,@rasbt,2022-09-20 12:42:24+00:00,https://twitter.com/rasbt/status/1572204527058550784,"@marccombalia I agree with you. I believe the counter argument was that you want to normalize what goes into the layer so that you have the weights of the next layer on the right scale, or sth like that. I think there was a paper on that a few years ago but I can‚Äôt find it at the moment."
3161,@rasbt,2022-09-20 12:40:24+00:00,https://twitter.com/rasbt/status/1572204023670870016,"@DrGroftehauge I‚Äôve actually never seen them after the activation, only before. For some reason there was this discussion about batchnorm AFTER activation a few years back. I think there was even a paper on it."
3162,@rasbt,2022-09-20 12:37:52+00:00,https://twitter.com/rasbt/status/1572203387768414211,@JonathanSumDL Not true imho. There can be underfitting but it doesn‚Äôt imply underfitting. Eg think of a scenario where you have 100% training accuracy and 100% test accuracy. That‚Äôs not underfitting.
3163,@rasbt,2022-09-20 01:11:45+00:00,https://twitter.com/rasbt/status/1572030721845334018,"@giffmana Yes, and if you want to get ahead of the competition, the best bang for the buck is collecting &amp; curating better data."
3164,@rasbt,2022-09-19 23:03:50+00:00,https://twitter.com/rasbt/status/1571998531614908417,@paul_rietschka I seriously appreciate these takes though because I do feel old sometimes thinking about these things üòÜ
3165,@rasbt,2022-09-19 22:57:57+00:00,https://twitter.com/rasbt/status/1571997048182046721,"@paul_rietschka And this: https://t.co/tankPOIfhk

""Our initial exploration reveals frequent crashes in model training when directly replacing all LN layers with BN [...] We therefore propose to add a BN layer in-between the two linear layers in the FFN block ..."""
3166,@rasbt,2022-09-19 22:56:39+00:00,https://twitter.com/rasbt/status/1571996723769233408,"@paul_rietschka Actually, I was more thinking of all the transformer people this time üòÖ. I actually just saw this: https://t.co/Y1GJOIPxfs
""systematic study of NLP transformer models to understand why BN has a poor performance, as compared to LN [...] instability, if BN is naively implemented"""
3167,@rasbt,2022-09-19 22:51:35+00:00,https://twitter.com/rasbt/status/1571995445420752897,"Thanks, everyone! That's settled then. Despite the little excursions, we still use it like we did originally in 2015.
And yes, it also still works as well as I remember it üòÅ https://t.co/ZZu9d4GXMZ"
3168,@rasbt,2022-09-19 21:13:15+00:00,https://twitter.com/rasbt/status/1571970699182342144,@Pin__Terest @ducha_aiki And I also wonder if BatchNorm is actually even still relevant (and whether that's something that can be removed from the syllabus in favor of other topics) now that most people rely on LayerNorm.
3169,@rasbt,2022-09-19 21:11:17+00:00,https://twitter.com/rasbt/status/1571970204401537024,@Pin__Terest @ducha_aiki Another reason is that I was just going through some of my old slides and was wondering if sth has changed since the last time I looked at it 2 years ago. https://t.co/2FKKMb9cXo
3170,@rasbt,2022-09-19 20:55:30+00:00,https://twitter.com/rasbt/status/1571966235461689344,@ducha_aiki this is the right answer!
3171,@rasbt,2022-09-19 20:52:59+00:00,https://twitter.com/rasbt/status/1571965602033553410,"Sorry, need to settle a debate and am curious about the status quo in 2022. 
Say you consider using BatchNorm for some reason; do you apply it before or after the activation function?"
3172,@rasbt,2022-09-19 19:38:54+00:00,https://twitter.com/rasbt/status/1571946955001196550,@NickLitwinowDS @huggingface @_lewtun @lvwerra @Thom_Wolf a pretty good book indeed üëå
3173,@rasbt,2022-09-19 18:47:57+00:00,https://twitter.com/rasbt/status/1571934132875173888,@CSProfKGD + you shouldn't need (crazy amounts of) caffeine to function.
3174,@rasbt,2022-09-19 18:47:13+00:00,https://twitter.com/rasbt/status/1571933951240933376,@CSProfKGD Focus on working reasonable hours and maintaining a healthy work/life/sleep balance. It will pay off in the long run.
3175,@rasbt,2022-09-19 18:33:42+00:00,https://twitter.com/rasbt/status/1571930549169823745,"@leonpalafox @trekkinglemon @docmilanfar @roydanroy For most positions I agree. Anyways, one of my best friends had this on his job requirement for an industry position. The job is related to implementing &amp; improving ideas from research papers; I guess the rationale is maybe having more experience dealing with research papers."
3176,@rasbt,2022-09-19 17:43:59+00:00,https://twitter.com/rasbt/status/1571918038936522755,@zetalyrae C.W. Longbottom captures this well
3177,@rasbt,2022-09-19 17:36:17+00:00,https://twitter.com/rasbt/status/1571916098810806272,@tunguz Omg programmers really love their framework wars üòÜ
3178,@rasbt,2022-09-19 17:29:14+00:00,https://twitter.com/rasbt/status/1571914323718729729,"@leonpalafox @trekkinglemon @docmilanfar @roydanroy Sure, there are cases where I heard that it‚Äôs a time where you can get some valuable experience before being thrown into the ‚Äúreal‚Äù job market. It‚Äôs just that as a PhD student all postdoc as I knew at that point were complaining so I knew that that‚Äôs probably sth to avoid"
3179,@rasbt,2022-09-19 17:25:16+00:00,https://twitter.com/rasbt/status/1571913327332282369,"@leonpalafox @trekkinglemon @docmilanfar @roydanroy Some job listings in industry require a PhD degree. On the other hand: there is no postdoc degree, and I haven‚Äôt seen postdoc experience on any industry job listing. Tbh I heard so many bad things about postdoc experiences that I would indeed not consider it."
3180,@rasbt,2022-09-19 15:59:06+00:00,https://twitter.com/rasbt/status/1571891642394705920,"@fchollet Arg, sorry to hear, that sounds like a frustrating start into the new week üôÅ. 
For moments like this, I bookmarked @DynamicWebPaige's advice: https://t.co/OpXqVvstCn"
3181,@rasbt,2022-09-19 14:08:30+00:00,https://twitter.com/rasbt/status/1571863807261118465,@CSProfKGD Depends on your interests and personality type. You can only be successful if you enjoy what you are doing.
3182,@rasbt,2022-09-19 12:47:48+00:00,https://twitter.com/rasbt/status/1571843498403561474,"@pegoraro_marco 8 months to be precise. Coincidentally, it‚Äôs also the same time thats passes between submitting a paper to NeuIPS and presenting that idea at the conference (if accepted)"
3183,@rasbt,2022-09-18 18:40:18+00:00,https://twitter.com/rasbt/status/1571569821334093828,"@Heptoop Wow, thanks so much for the kind words! It feels very motivating to hear that üòä! Hope the course will be useful to you!!

PS: There will be more (some time Q4 2022) https://t.co/L9ptPklKt3"
3184,@rasbt,2022-09-18 18:33:39+00:00,https://twitter.com/rasbt/status/1571568148603625472,"@tdietterich @deliprao Yes, totally. If I remember correctly, AlphaFold v1 used a ResNet-like architecture for the contact maps -- not a new idea, I saw a 2017 seminar based on a similar approach. Besides incl physics-based energy potentials, in AlphaFold v2 they used (surprise, surprise) transformers."
3185,@rasbt,2022-09-18 16:39:40+00:00,https://twitter.com/rasbt/status/1571539464023080961,"@charles_irl Fair, but then how many people use multi-GPU setups for their model in an inference setup? (Not a trick question, I am honestly curious; heard that people usually switch to cheaper, smaller, lower latency hardware for production)"
3186,@rasbt,2022-09-18 16:36:45+00:00,https://twitter.com/rasbt/status/1571538731122790401,"@Heptoop @ChristophMolnar That's fair, I agree. But then, isn't the context of the group still in the spirit of interpretability?"
3187,@rasbt,2022-09-18 15:27:30+00:00,https://twitter.com/rasbt/status/1571521301126193154,@github A 486 that my family bought used in the late 90s for &lt; $100
3188,@rasbt,2022-09-18 15:23:00+00:00,https://twitter.com/rasbt/status/1571520170136305667,"@tdietterich @roydanroy @tetraduzione @NeurIPSConf Other than that, it's probably easier from an organizational perspective. Also, why lump so many different subfields into one conference? Sure, it encourages cross-pollination across fields, but at the same time I feel like it's all grown beyond reasonable proportions."
3189,@rasbt,2022-09-18 15:21:16+00:00,https://twitter.com/rasbt/status/1571519734473957376,"@tdietterich @roydanroy @tetraduzione @NeurIPSConf Everyone has different prefences, sure. For me, it is somewhat like a sensory overload. I feel like conferences with 500 attendees are already chaotic."
3190,@rasbt,2022-09-18 15:10:06+00:00,https://twitter.com/rasbt/status/1571516924986531853,@roydanroy @tdietterich @tetraduzione @NeurIPSConf I'd say also extend the lottery aspect to posters and speakers. No need to have ~1500 people presenting. There is nothing more demotivating for a student than putting lots of work into a talk or poster and having like &lt; 5 people attending.
3191,@rasbt,2022-09-18 15:00:08+00:00,https://twitter.com/rasbt/status/1571514416495218688,@akbirthko Yes exactly üòÜ
3192,@rasbt,2022-09-18 14:59:47+00:00,https://twitter.com/rasbt/status/1571514326065811458,"@LeopolisDream Personally, the first thing that comes to mind are stacked denoising autoencoders from way before self-supervised learning https://t.co/sABA8bu5yg"
3193,@rasbt,2022-09-18 14:49:09+00:00,https://twitter.com/rasbt/status/1571511649017683970,"Hah, this was a genuine question back in the day. Looked like that paper was onto something. I guess this ship has sailed. 
RIP GAN."
3194,@rasbt,2022-09-18 14:27:11+00:00,https://twitter.com/rasbt/status/1571506121013137408,@JaidevShah4 Thanks for the kind words!
3195,@rasbt,2022-09-18 14:26:14+00:00,https://twitter.com/rasbt/status/1571505883259052032,"@JaidevShah4 Imho, you don't have to study or get a degree in education to be an effective teacher. E.g., thinking of Gilbert Strang; imho he is one of the best and effective teachers I know. And afaik, he didn't study Education to become good at it. It seems motivation is the main factor."
3196,@rasbt,2022-09-18 14:22:14+00:00,https://twitter.com/rasbt/status/1571504877314117633,"@ZainulA40877140 Yeah, based on my own experience, like with everything in life, some people are better and one thing, others are better at other things. I think this is largely a matter of interest and motivation."
3197,@rasbt,2022-09-18 14:19:37+00:00,https://twitter.com/rasbt/status/1571504217202003968,"@okukuson 4/4 Same for my book https://t.co/dZzvgRatxU. The first 10 chapters are traditional ML, the remaining 9 chapters are DL."
3198,@rasbt,2022-09-18 14:18:09+00:00,https://twitter.com/rasbt/status/1571503849206173696,"@okukuson 3/ That's usually also how I structure my courses (Intro to ML, then Intro to DL): https://t.co/OcL9XWoNIV"
3199,@rasbt,2022-09-18 14:17:26+00:00,https://twitter.com/rasbt/status/1571503670063407117,"@okukuson 2/ this gives you an opportunity to focus more on the procedure and broader concepts, plus it requires less hardware resources. Then, with a solid foundation of traditional ML as a baseline, it is easier to get into DL"
3200,@rasbt,2022-09-18 14:16:14+00:00,https://twitter.com/rasbt/status/1571503365447684097,"@okukuson They are definitely related! You can think  of DL as a subset of ML. I.e., DL is the subset of ML that is focused on training neural networks.
I recommend starting with non-DL ML, because the classic algorithms are a bit simpler to work with 1/n"
3201,@rasbt,2022-09-18 14:13:53+00:00,https://twitter.com/rasbt/status/1571502777649471493,"@marccombalia @kaggle It's not impossible or unreasonable though. CASP (https://t.co/zLHRUlZB77), i.e., where AlphaFold / AlphaFold 2 was first evaluated on, follows a similar model."
3202,@rasbt,2022-09-18 14:12:29+00:00,https://twitter.com/rasbt/status/1571502423004381184,@marccombalia @kaggle üíØ. A middle ground is also having a yearly competition (maybe as part of the yearly conference submission) for new methods based on private test set. The upside: authors should only have to focus on their own method. Downside: you would have to find people who test older methods
3203,@rasbt,2022-09-18 14:08:13+00:00,https://twitter.com/rasbt/status/1571501347647668225,"@tulkenss Agreed! But ideally you want to play them both anyways for the full story :). Starting with Ages as a warm-up because I remember Seasons was a bit trickier.

And I think you are right, the timing was bad. Minish Cap on the GBA is also one of my all time favorites btw!"
3204,@rasbt,2022-09-17 23:48:39+00:00,https://twitter.com/rasbt/status/1571285034304151554,"@ylecun Fair point, ""Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion"" by @hugo_larochelle and colleagues is from 2010 (https://t.co/sABA8bu5yg), and I am not sure if there are even earlier references"
3205,@rasbt,2022-09-17 17:57:24+00:00,https://twitter.com/rasbt/status/1571196638034595840,"MLxtend 0.21.0 is out! 
The ""feature groups"" release: now you can specify feature groups in feature permutation importance and feature selection.

An important thing if you one-hot encode categorical vars!

Huge thanks to @sarajpoor for the contribs! 

üîóhttps://t.co/LnZmnOwUH8 https://t.co/3hhsJv9qad"
3206,@rasbt,2022-09-17 17:09:39+00:00,https://twitter.com/rasbt/status/1571184622259552262,I always tell my students: making the exam is harder than taking the exam üòÜ
3207,@rasbt,2022-09-17 16:34:24+00:00,https://twitter.com/rasbt/status/1571175748219584515,"@matloff @marktenenholtz Hah. And don't get me started with term ""inference"""
3208,@rasbt,2022-09-17 15:45:31+00:00,https://twitter.com/rasbt/status/1571163449643700224,"@matloff @marktenenholtz I think I see what you mean though, i.e., distinguishing between an experiment design vs just data extraction &amp; processing."
3209,@rasbt,2022-09-17 15:38:20+00:00,https://twitter.com/rasbt/status/1571161639021383687,"@tdietterich @matloff @marktenenholtz Hm ok, the term ""designed"" is maybe too general. But if you have something like Iris, where someone like Edgar Anderson took a ruler, measured the flower dimensions, and put everything nicely into a table / matrix, isn't that sort of ""designed""?"
3210,@rasbt,2022-09-17 14:42:20+00:00,https://twitter.com/rasbt/status/1571147548999708672,"After getting a major manuscript done this morning, treat yourself and relax üòä https://t.co/l3gy9WzYVp"
3211,@rasbt,2022-09-17 14:03:05+00:00,https://twitter.com/rasbt/status/1571137668838486016,@EsmalHaj All 4 methods above could potentially run across multiple machines. Eg the simplest parallelism (distributed data parallel in PyTorch) already supports multiple GPUs across multiple machines in a network by default). And most others are drop-in replacements that do the same
3212,@rasbt,2022-09-17 13:58:43+00:00,https://twitter.com/rasbt/status/1571136570094424064,@Chemobioinfo The question is not ‚Äú*how* we should evaluate‚Äù but rather ‚Äú*who*should evaluate‚Äù
3213,@rasbt,2022-09-17 13:56:32+00:00,https://twitter.com/rasbt/status/1571136022096023553,"@marccombalia 3/3 2) back to addressing this issue re leaderboard and paper review context, this could be addressed by having an editor actually reading the paper and making relative comparisons among single models (excluding the ensembles) from the leaderboard, right?"
3214,@rasbt,2022-09-17 13:54:35+00:00,https://twitter.com/rasbt/status/1571135529131081731,@marccombalia 2/ one peer  reviewer criticized that I didn‚Äôt compare said ensemble method in the comparison. In my opinion it is silly to compare single models to ensembles.
3215,@rasbt,2022-09-17 13:53:40+00:00,https://twitter.com/rasbt/status/1571135301141270530,"@marccombalia Oh, so the problem would be that there is no fair comparison because winning solutions would be ensembles? 1) I agree, actually in a paper I didn‚Äôt compare my method to another method once because the other method was an ensemble of 1 CNN per class. I thought this was silly 1/n"
3216,@rasbt,2022-09-17 13:51:10+00:00,https://twitter.com/rasbt/status/1571134669533609985,@matloff @marktenenholtz Are we talking about https://t.co/xUSdbQgXZs? Actually curious to learn more and hear why you‚Äôd call it a misnomer
3217,@rasbt,2022-09-17 13:48:50+00:00,https://twitter.com/rasbt/status/1571134083811647491,"@__mharrison__ @jeremyphoward @quarto_pub Curious to hear more! What are the bottlenecks, and is your website static?"
3218,@rasbt,2022-09-16 20:53:47+00:00,https://twitter.com/rasbt/status/1570878639105003520,@roydanroy Latex math or it didn‚Äôt happen
3219,@rasbt,2022-09-16 20:52:24+00:00,https://twitter.com/rasbt/status/1570878290801598464,"@jeremyphoward @quarto_pub This decision is actually really admirable &amp; applaudable. It‚Äôs hard to let things go after investing lots of time into it. 
Reminds me a bit of prettyplotlib and seaborn, and theano &amp; TensorFlow (also that one is maybe controversial üòÖ)"
3220,@rasbt,2022-09-16 20:34:51+00:00,https://twitter.com/rasbt/status/1570873872882466817,@Plinz But the magnetic strip on the Costco membership card ‚Ä¶ that‚Äôs the real issue! üòÜ
3221,@rasbt,2022-09-16 20:33:17+00:00,https://twitter.com/rasbt/status/1570873478676631552,"@Plinz According the Apple you are supposed to be using Apple Pay I guess üòÖ. 
Not a fan or user of MagSafe, but seriously, I think the last time I had to  used# the magnetic strip on my credit card was 2016. It‚Äôs all Tap to Pay now (and the other chip before that)."
3222,@rasbt,2022-09-16 20:02:38+00:00,https://twitter.com/rasbt/status/1570865765053763584,@stanislavfort @SamuelAinsworth @siddhss5 Bookmarked üçø
3223,@rasbt,2022-09-16 18:55:17+00:00,https://twitter.com/rasbt/status/1570848817658077184,@matloff @marktenenholtz Yeah but ‚Äúdesign matrix data‚Äù is a bit unwieldy üòÜ
3224,@rasbt,2022-09-16 18:49:53+00:00,https://twitter.com/rasbt/status/1570847459722821633,@jrosell @marktenenholtz @ylecun That‚Äôs a good point. Totally forgot about ads. It might actually o looking text above vision but depends on whether we count Pagerank as an ML model :P
3225,@rasbt,2022-09-16 18:46:47+00:00,https://twitter.com/rasbt/status/1570846676612681730,@ylecun 7. Denoising Autoencoders. I‚Äôd say without these we probably wouldn‚Äôt have impactful generative approaches like GANs or diffusion models today.
3226,@rasbt,2022-09-16 18:41:21+00:00,https://twitter.com/rasbt/status/1570845310574022657,@jrosell @marktenenholtz @ylecun https://t.co/h50K5kX4br
3227,@rasbt,2022-09-16 18:39:38+00:00,https://twitter.com/rasbt/status/1570844876413227008,"@marktenenholtz Educated guess: 
Tabular (stock market, insurance, and financial data) &gt; vision (OCR, quality assurance, medical imaging) &gt; text (chatbots, sentiment analysis, sorting &amp; categorization)"
3228,@rasbt,2022-09-16 18:34:49+00:00,https://twitter.com/rasbt/status/1570843664058044418,@marktenenholtz One thing for sure: vision models have literally seen a lot of $$$. Weren‚Äôt @ylecun ‚Äòs CNNs used by ATMs since the late 1980‚Äôs?
3229,@rasbt,2022-09-16 15:20:50+00:00,https://twitter.com/rasbt/status/1570794850223816704,"@ylecun 6. Deep Q-Learning.
Not a new idea per se, but I'd say quite a breakthrough.
(e.g., the Playing Atari with Deep Reinforcement Learning)"
3230,@rasbt,2022-09-16 15:16:26+00:00,https://twitter.com/rasbt/status/1570793742201925632,@JFPuget @ylecun Nice article in that vein: https://t.co/NFzqQDwrM7
3231,@rasbt,2022-09-16 14:44:04+00:00,https://twitter.com/rasbt/status/1570785594598649860,@MMA_mathematics I agree. Those are biased benchmarks
3232,@rasbt,2022-09-16 14:42:58+00:00,https://twitter.com/rasbt/status/1570785321058734080,"@MMA_mathematics Depends on the competition. Afaik, beyond just using private test set to get unbiased scores, some competitions do limit the number of submissions. Some competitions also only accept the method + executable notebook as a final submission etc. @tunguz &amp; @JFPuget may know more"
3233,@rasbt,2022-09-16 13:16:14+00:00,https://twitter.com/rasbt/status/1570763492873109507,"It's not a true test set if you had access to it during method development.
In an ideal world, authors should submit the method not the test set scores. Let an independent committee check the performance. Not feasible? Consider using e.g., Kaggle for that."
3234,@rasbt,2022-09-15 21:17:06+00:00,https://twitter.com/rasbt/status/1570522119309783043,Born To restart &amp; Run
3235,@rasbt,2022-09-15 20:26:15+00:00,https://twitter.com/rasbt/status/1570509323205505024,"@MozejkoMarcin Arg, sorry to hear. A simple, new method that works better while being simple is the best method in practice imho. Reminds me of my all time favorite review comment"
3236,@rasbt,2022-09-15 20:21:38+00:00,https://twitter.com/rasbt/status/1570508160556994566,@alfcnz But congrats üéâ  on getting it to work. Best feeling!
3237,@rasbt,2022-09-15 20:21:09+00:00,https://twitter.com/rasbt/status/1570508038490193920,@alfcnz So excited for the book! I am sure we will all love üíï the text and chapters! Don‚Äôt worry about adding the code examples as a bonus later on!
3238,@rasbt,2022-09-15 16:32:25+00:00,https://twitter.com/rasbt/status/1570450474352115713,"@ChristophMolnar Nice thread! Q: how does correlation ruin interpretation via feature permutation importance, for example, if you shuffle features as groups like you would do with features from a one hot encodings? The problem is that there are too many overlapping groups to define I guess?"
3239,@rasbt,2022-09-15 16:15:58+00:00,https://twitter.com/rasbt/status/1570446333621698562,"@akshay_pachaar Ah yes, I think the advantage is that you can make it fit this way when your layers themselves are too large to fit onto a single GPU."
3240,@rasbt,2022-09-15 16:14:38+00:00,https://twitter.com/rasbt/status/1570446000220676096,"@akshay_pachaar Re Tensor Parallelism: tumbled upon it here https://t.co/TX2wNGyiSr

Also mentioned in the GPT-3 paper: ""we use a mixture of model parallelism within each matrix multiply and model parallelism across the layers of the net"" https://t.co/owuX2OrzuQ

(not sure how to implement üòÖ)"
3241,@rasbt,2022-09-15 16:00:42+00:00,https://twitter.com/rasbt/status/1570442494588112896,"[5/5] 
Bonus: 4) Tensor parallelism. It's basically a flavor of model parallelism, but instead of dividing the neural network by layer (horizontally), you divide the tensors themselves (vertically). E.g., put half of a weight layer on one GPU, and the other onto another GPU"
3242,@rasbt,2022-09-15 16:00:42+00:00,https://twitter.com/rasbt/status/1570442492566441985,"[4/5] 
3) Pipeline parallelism: related to model parallelism where you put different blocks of the model onto different GPUs(, and data parallelism where you split batches). But here you make those blocks run (somewhat) in parallel.

(Image credit: https://t.co/LHMUUK1rfJ) https://t.co/j4mH5EmMn5"
3243,@rasbt,2022-09-15 16:00:41+00:00,https://twitter.com/rasbt/status/1570442490343485441,"[3/5] 
2) Model parallelism: divide model onto separate GPUs; usually to deal with limited VRAM. Note it doesn't imply that the training happens in parallel!

How? L1. to('cuda:0'), L2. to('cuda:1') etc.

Tutorial: https://t.co/aPoKzTKTnW

(Image credit: https://t.co/JsXK6tOrYG) https://t.co/9UM2ntbtPN"
3244,@rasbt,2022-09-15 16:00:41+00:00,https://twitter.com/rasbt/status/1570442488334397440,"[2/5] 
1) Data parallelism: splits batches &amp; distributes those across several GPUs. Here, in each iteration, the gradient estimate (for the model update) is computed from as a weighted avg over sub-batches.
Eg via DataParallel or DistributedDataParallel (recommended) in PyTorch https://t.co/SMMO3mr0pq"
3245,@rasbt,2022-09-15 16:00:40+00:00,https://twitter.com/rasbt/status/1570442486501478402,"There are &gt;= 3 1/2 paradigms for training deep neural nets on multiple GPUs:

1) Data parallelism
2) Model parallelism
3) Pipeline parallelism
( 4) Tensor parallelism)

Which one(s) are you usually using; and anything missing?
[1/4]"
3246,@rasbt,2022-09-15 14:19:52+00:00,https://twitter.com/rasbt/status/1570417119707136000,"@giffmana @CSProfKGD Nice &amp; concise üëè. Haven't had Transformers for RL on my radar yet, thanks for the pointer!"
3247,@rasbt,2022-09-15 14:01:28+00:00,https://twitter.com/rasbt/status/1570412487048327172,"@emollick @ylecun Anecdotal evidence: half an hour on ye goode olde GameBoy Advance does way more for me than meditation when I am stressed. 
Has to be relatively simple / chill games though; more modern (current gen) games are more like a sensory overload that can actually cause more stress."
3248,@rasbt,2022-09-15 13:53:38+00:00,https://twitter.com/rasbt/status/1570410514601152514,"@bag_of_ideas @hardmaru @karpathy @Ageron Yea, that‚Äôs an interesting idea; have done that as an HW in my DL class once, but with multilayer perceptrons. To demonstrate that MLPs are column permutation invariant. I don‚Äôt remember CNN experiments but I suspect CNN would see a declined performance in contrast to MLPs"
3249,@rasbt,2022-09-14 21:47:58+00:00,https://twitter.com/rasbt/status/1570167498095337476,@CSProfKGD makes sense! But I actually didn't see your laptop at all in this pic!
3250,@rasbt,2022-09-14 21:44:21+00:00,https://twitter.com/rasbt/status/1570166588191707136,"@CSProfKGD That‚Äôs really nice, but I would put an asterisk on it as it doesn‚Äôt generalize well ‚Äî probably only works if you have a monitor in the back so that you know which slide you are on üòâ"
3251,@rasbt,2022-09-14 20:35:02+00:00,https://twitter.com/rasbt/status/1570149143917768704,"@AMULETAnalytics @bendee983 @vmirly Thanks! Glad you find it useful, and I hope your students do too!"
3252,@rasbt,2022-09-14 19:01:01+00:00,https://twitter.com/rasbt/status/1570125485648101376,"@SeanBannion Most popular undergrad course in this department:
Introduction to Dynamical Systems and Chaos -- How Complex Behavior can Arise from Simple Rules"
3253,@rasbt,2022-09-14 17:58:58+00:00,https://twitter.com/rasbt/status/1570109868593352704,@code_star @SelectStarMan papers will go to arxiv one way or the other üòÜ
3254,@rasbt,2022-09-14 16:53:32+00:00,https://twitter.com/rasbt/status/1570093403035303936,"@LightningAI @PyTorch @linuxfoundation Beides the big headlines, the supervised, semi- and self-supervised visual representation learning toolbox for mixup looks cool. Nice find! üëå

https://t.co/xLFm8xngsV"
3255,@rasbt,2022-09-14 16:45:51+00:00,https://twitter.com/rasbt/status/1570091467313397765,@SelectStarMan https://t.co/xpdqSlSlzh
3256,@rasbt,2022-09-14 16:44:19+00:00,https://twitter.com/rasbt/status/1570091082355974146,"@SelectStarMan haha, machine learners compute the population (not sample) variance :P"
3257,@rasbt,2022-09-14 16:42:19+00:00,https://twitter.com/rasbt/status/1570090576845934593,"@yuvalmarton Yeah, I like that! It will also decrease the time frame needed to announce the decisions, resulting in the accelerated dissemination of scientific knowledge!"
3258,@rasbt,2022-09-14 16:40:17+00:00,https://twitter.com/rasbt/status/1570090068991250436,@SelectStarMan The variance of a single data point is 0! Can't get better than that!
3259,@rasbt,2022-09-14 16:35:02+00:00,https://twitter.com/rasbt/status/1570088744354713600,@roydanroy @tunguz Yes please üôè. Btw I think your are sort of right. Vanilla gradient boosting (besides being slow) doesn‚Äôt nearly perform as well as practical ‚Äúhacks‚Äù like XGBoost and LightGBM. Or it could be that I never sampled hparams of vanilla GBMs thoroughly enough coz computational limits
3260,@rasbt,2022-09-14 16:29:10+00:00,https://twitter.com/rasbt/status/1570087270522277888,@nelhage My first suggestion when students report bugs or issues: do a‚ÄúRestart &amp; Run All‚Äù ‚Äî fixes 98% of issues in practice ;)
3261,@rasbt,2022-09-14 16:25:50+00:00,https://twitter.com/rasbt/status/1570086431170625545,"My proposal to improve the NeurIPS peer-review process next year: just assign a single reviewer per paper!

This addresses 3 issues: 
(1) the reviewer #2 issue, 
(2) the large variance, and 
(3) the shortage of suitable reviewers."
3262,@rasbt,2022-09-14 14:58:19+00:00,https://twitter.com/rasbt/status/1570064407593369606,"@alfcnz @ProfFeynman But to maintain an edge over others, he kept that selfishly to himself, which is why he only used white chalk in his public lectures"
3263,@rasbt,2022-09-14 01:42:43+00:00,https://twitter.com/rasbt/status/1569864188369203212,"@CSProfKGD 2/2 Why do I remember such random trivia one might ask ... Haha, when I gave my first ML tutorial ever (at @SciPyConf 2016), I mixed that up for some reason, and now it's stuck in my head forever üòÖ"
3264,@rasbt,2022-09-14 01:40:51+00:00,https://twitter.com/rasbt/status/1569863718258843653,"@CSProfKGD One more interesting tidbit: random forests are somewhat related to the random subspace method for decision forests (published ~3 years earlier). In the latter each tree gets a random subset of features whereas in random forests, each node gets a random subset of features. 1/2"
3265,@rasbt,2022-09-14 01:31:30+00:00,https://twitter.com/rasbt/status/1569861362775633921,"Wow! If this turns out to work reliably in practice, this is going to be huge. Possibly a game changer for collaborations, reusing independently models to create better generalizable models, and more. And Kaggle teams are also going to be busy this upcoming weekend ‚Ä¶"
3266,@rasbt,2022-09-13 23:47:22+00:00,https://twitter.com/rasbt/status/1569835160149049345,@charles_irl Guilty ü•π
3267,@rasbt,2022-09-13 22:13:15+00:00,https://twitter.com/rasbt/status/1569811472947249153,"You can now also train your PyTorch models on Apple GPUs via Lightning! 

pm = PyTorchModel()
lm = L. LightningModel(pm)
trainer = L. Trainer(accelerator=""mps"")
trainer. fit(model=lm, datamodule=dm)

https://t.co/2TKEH7kgzV

Thanks @justusschock @adrianwaelchli &amp; team üôå"
3268,@rasbt,2022-09-13 22:04:33+00:00,https://twitter.com/rasbt/status/1569809283189035015,"@marktenenholtz hah, *my* quick thought is: üíØ agree, it's the GBDT show. But if you are bored (and have the extra time), spice it up üòÜ 
https://t.co/VAXJRBMyzj"
3269,@rasbt,2022-09-13 17:21:44+00:00,https://twitter.com/rasbt/status/1569738111239815173,@CSProfKGD Look what happened to Random Forests ... everyone switched to gradient boosting since it was trademarked in 2006 üòÜ
3270,@rasbt,2022-09-13 16:33:41+00:00,https://twitter.com/rasbt/status/1569726016511438848,@sebineubauer @peterhoffmann @PyTorch @linuxfoundation @NumFOCUS @TheASF I had exactly similar thoughts. My guess is that Meta was already sponsoring Linux Foundation. Same for some other bigger companies using PyTorch. So the move was probably easier.
3271,@rasbt,2022-09-13 16:30:44+00:00,https://twitter.com/rasbt/status/1569725276262744065,"@DSaience ML is a fast moving field, or so they say üòá"
3272,@rasbt,2022-09-13 15:03:02+00:00,https://twitter.com/rasbt/status/1569703205486952450,@DSaience There are two YOLOv6's. I think one was released like a few months ago. üòÜ
3273,@rasbt,2022-09-13 14:54:06+00:00,https://twitter.com/rasbt/status/1569700956715077634,@fchollet He replaced Xavier
3274,@rasbt,2022-09-13 13:15:07+00:00,https://twitter.com/rasbt/status/1569676049314611203,"After the release of YOLOv7 two months ago, YOLOv6 was just released last week. You can't make this stuff up.
https://t.co/CC0vUTOGQU"
3275,@rasbt,2022-09-13 02:52:17+00:00,https://twitter.com/rasbt/status/1569519305448128512,"@T1mSp33d Mish, Swish, GELU ... they all look the same to me, kinda. All are not strictly monotonic ... I don't know what the practical significance of that is though :P https://t.co/gkWlGuBKBd"
3276,@rasbt,2022-09-13 02:51:54+00:00,https://twitter.com/rasbt/status/1569519208823943174,@ahatamiz1 Good point. They call it Swish in the plot. Afaik SiLU == Swish
3277,@rasbt,2022-09-12 23:43:40+00:00,https://twitter.com/rasbt/status/1569471839508004865,@fayyazhere keep me posted ^^
3278,@rasbt,2022-09-12 23:37:56+00:00,https://twitter.com/rasbt/status/1569470396176670720,There's a nice article on GELU with an explanation of the intuition behind it: https://t.co/KGw1Oxuhw3 -- maybe a regularizing effect is what makes it attractive from a theoretical standpoint
3279,@rasbt,2022-09-12 23:30:31+00:00,https://twitter.com/rasbt/status/1569468529518481413,@tonycapp @datacascadia Graphic from https://t.co/sM98CGNyv5
3280,@rasbt,2022-09-12 23:30:04+00:00,https://twitter.com/rasbt/status/1569468415085264897,"@tonycapp @datacascadia Thanks for sharing though! I honestly have no clue how PyTorch implements multiprocessing in detail (same for PyCUDA), so I may be wrong. But I think that in DDP, it's usually based on process spawning, but interactive environments only support process forking https://t.co/etSdcJGZTd"
3281,@rasbt,2022-09-12 23:24:35+00:00,https://twitter.com/rasbt/status/1569467035976974341,"@tonycapp @datacascadia I think there is a misunderstanding. It's not multi-GPU support per se, but the Distributed Data Parallel backend in particular. Data Parallel supports multiple GPUs in Jupyter without problem. Always has."
3282,@rasbt,2022-09-12 23:23:05+00:00,https://twitter.com/rasbt/status/1569466657793343488,@tonycapp @eggie5 Or my lazy_map / lazy_imap I hacked together back then https://t.co/v7R9GAMN4k. It occasionally did not work in Jupyter
3283,@rasbt,2022-09-12 23:21:54+00:00,https://twitter.com/rasbt/status/1569466363277889536,"@tonycapp @eggie5 Yes, it is very unstable. I think it may also be partly hardware dependent. I have been using multirprocessing (the module) a lot in the past but yeah, it occassionally broke. (Here's sth I used in grad school many years ago: https://t.co/WzYf9OWS0V -- scroll to the very bottom)"
3284,@rasbt,2022-09-12 22:41:44+00:00,https://twitter.com/rasbt/status/1569456252845182976,"@fayyazhere Could the V shape just be an artifact because you get the strongest gradient signals this way? (I mean in backprop, in the derivative)"
3285,@rasbt,2022-09-12 21:59:36+00:00,https://twitter.com/rasbt/status/1569445649032298496,"@DSaience Oh I see. ReLU is simpler, and in my experience, I don't find leaky ReLU makes a noticeable difference (sometimes better, but often also worse)"
3286,@rasbt,2022-09-12 21:50:47+00:00,https://twitter.com/rasbt/status/1569443432455864326,@DSaience I think it's LReLU (just below ReLU)
3287,@rasbt,2022-09-12 21:39:59+00:00,https://twitter.com/rasbt/status/1569440712206487552,"Actually, the training speed is quite good; paired with the fact that ReLU is boring, the predictive &amp; computational performance combo is probably a good selling point: https://t.co/xS91h6155s"
3288,@rasbt,2022-09-12 21:34:35+00:00,https://twitter.com/rasbt/status/1569439354157936640,"@shoyer Good point, that's fair. The substantially slower training times probably also matter a lot (esp if we consider LLMs) https://t.co/YdvYStsuMP"
3289,@rasbt,2022-09-12 21:07:50+00:00,https://twitter.com/rasbt/status/1569432622358745089,"Oh, and since I have you here, why is GELU so popular? Is it just because early LLMs started that trend, and it doesn't really matter? 
Like in the ConvNext paper: ""We find that ReLU can be substituted with GELU in our ConvNet too, although the accuracy stays unchanged"""
3290,@rasbt,2022-09-12 21:07:49+00:00,https://twitter.com/rasbt/status/1569432620152356865,"Based on that plot above, it looks like Pade Activation Unit (PAU) would be a good one. Never saw it in practice. Too complex? https://t.co/Nf1HJJ3Fjc"
3291,@rasbt,2022-09-12 21:07:49+00:00,https://twitter.com/rasbt/status/1569432617824710656,"When it comes to deep neural network hidden layer activation functions and you have to name 3, mine would be:
 
1) Logistic sigmoid (use only for teaching üòÜ)
2) ReLU (simple &amp; robust)
3) GELU (latest trend)

Looking at https://t.co/CRpvlfL3Kz, how come GELU is so popular though? https://t.co/pgFAjXrE1p"
3292,@rasbt,2022-09-12 20:29:20+00:00,https://twitter.com/rasbt/status/1569422933759561729,"@eggie5 It's a general limitation in PyTorch &amp; Jupyter (or interactive environments in general) related to multiprocessing, yes. My bad, since you were responding to my original tweet, I thought we were talking about neural network training ü§î"
3293,@rasbt,2022-09-12 19:59:12+00:00,https://twitter.com/rasbt/status/1569415349761622017,"@eggie5 It looks like this is also a modded Data Distributed Parallel version though? Or in other words, it's still true that you can't use it in PyTorch out of the box if you are running it in an interactive (or Jupyter) environment"
3294,@rasbt,2022-09-12 19:50:35+00:00,https://twitter.com/rasbt/status/1569413183344869377,"@eggie5 It depends. Data Parallel uses multithreading, so yes that would support GPUs since the beginning (but it's bad). 
Distributed Data Parallel is based on multiprocessing https://t.co/CaAT43r5yD"
3295,@rasbt,2022-09-12 19:32:32+00:00,https://twitter.com/rasbt/status/1569408640162975745,"@eggie5 In practice they do, no? They are interactive environments and hence there are certain limitations when you are trying to utilize multiple GPUs (since this requires multiprocessing) https://t.co/wGJPPQ7CP3"
3296,@rasbt,2022-09-12 18:07:23+00:00,https://twitter.com/rasbt/status/1569387208762658818,"@zacharylipton ""Wish I could do it digitally (10 monitors?)"" 
-&gt; Or one good high-res monitor (and potentially reading glasses) üòÖ"
3297,@rasbt,2022-09-12 17:55:21+00:00,https://twitter.com/rasbt/status/1569384183088447489,"I am a big Jupyter notebook fan, except when it comes to training deep neural nets. Why? No multi-GPU support üôÅ -- except Data Parallel, but that's bad.

Now, a little gamechanger: Lightning just added Distributed Data Parallel for PyTorch in Jupyter üòä 
https://t.co/vHKDD4x5Pq https://t.co/LkXNJxKrYH"
3298,@rasbt,2022-09-12 17:11:31+00:00,https://twitter.com/rasbt/status/1569373150416093184,"@amazingguo Mostly keyword ""search"" (on Google Scholar, I have it setup that it sends me emails with relevant papers according to some keywords). On Arxiv-Sanity, I go with the recommendations."
3299,@rasbt,2022-09-12 14:09:06+00:00,https://twitter.com/rasbt/status/1569327243582705668,"@fermatslibrary @CSProfKGD Found similar papers in my PhD advisor's archive. Don't have a picture at hand, but what was also mindboggling was that for graphical plots, they photographed the computer screen in a dark room. That was before printers were available to normal people."
3300,@rasbt,2022-09-12 14:02:59+00:00,https://twitter.com/rasbt/status/1569325705204211714,"@dimiboeckaerts @fchollet Read it a few weeks ago, and even though I am not a Keras user, I really enjoyed it. @fchollet is really great at describing things in an engaging way. Lots of interesting insights in there too."
3301,@rasbt,2022-09-12 13:57:42+00:00,https://twitter.com/rasbt/status/1569324375303720967,@OuterboundsHQ I don't want to picture reinforcement learning on this one üôà
3302,@rasbt,2022-09-12 13:54:30+00:00,https://twitter.com/rasbt/status/1569323572451241984,"@seanmylaw @stumpy_dev I think having both (somewhat detailed, more educational) tutorials and shorter example snippets is often what I prefer as a user. I think scikit-learn does a good job with that

Tutorials: https://t.co/Mxtok8RSRc

Examples: https://t.co/vIBJqx5ppI"
3303,@rasbt,2022-09-11 19:04:35+00:00,https://twitter.com/rasbt/status/1569039217895817216,"@MaartenvSmeden Hah, sure. I am not disagreeing with you. More like ""not a bad metric, but maybe not the most useful one"" :P"
3304,@rasbt,2022-09-11 18:57:04+00:00,https://twitter.com/rasbt/status/1569037326294159361,"@MaartenvSmeden I think precision-recall curves or average precision are usually more useful in many scenarios. 

Actually I am also a fan of MCC now, https://t.co/NNxIwHrXXq"
3305,@rasbt,2022-09-11 16:49:36+00:00,https://twitter.com/rasbt/status/1569005248605298689,@JFPuget @xamat So true. That‚Äôs the only way I can keep my FOMO in check. I usually bookmark all interesting papers but only end up reading like 0-3 a week. Once a quarter when I go through my ‚Äúwant to read list‚Äù I can basically purge 99% w/o missing anything super important üòÜ
3306,@rasbt,2022-09-11 15:41:49+00:00,https://twitter.com/rasbt/status/1568988189968187399,@amazingguo Mostly Google Scholar searches and Arxiv-Sanity
3307,@rasbt,2022-09-11 14:19:02+00:00,https://twitter.com/rasbt/status/1568967357699354624,@chrisalbon Pics or it didn't happen üòÜ
3308,@rasbt,2022-09-11 14:17:59+00:00,https://twitter.com/rasbt/status/1568967092535181312,"This morning:
Found two new deep tabular learning papers I previously missed.
Got all excited, printed those, got my morning coffee &amp; sat down in my fav chair.

Plot twist:
TaBERT https://t.co/LYHmLNGLtJ &amp; TAPAS  https://t.co/HAcvYWHie1
were not about that kind of tabular data ü§¶‚Äç‚ôÇÔ∏è https://t.co/G7qA81RsT3"
3309,@rasbt,2022-09-11 01:23:51+00:00,https://twitter.com/rasbt/status/1568772276245434369,"@machsci Hah, the hard part is the willpower it takes to do it in the first place, and to stay focused"
3310,@rasbt,2022-09-11 01:22:53+00:00,https://twitter.com/rasbt/status/1568772030761242625,@vtmicah @chrisalbon Hah same. Slack was always already a lot for me. Discord is sensory overload üòÖ
3311,@rasbt,2022-09-11 01:21:08+00:00,https://twitter.com/rasbt/status/1568771590149611522,@hsuyab No it‚Äôs definitely something I want to do one day. Thx for suggesting :)
3312,@rasbt,2022-09-10 18:07:28+00:00,https://twitter.com/rasbt/status/1568662456096157696,@hsuyab Hah yeah! O my thing is  I am looking for ways to reduce my project list not to grow it üòÜ but yeah it would be fun  üòÑ
3313,@rasbt,2022-09-10 15:32:36+00:00,https://twitter.com/rasbt/status/1568623480672772096,"@hsuyab Good suggestion, maybe for the next one :)"
3314,@rasbt,2022-09-10 15:27:11+00:00,https://twitter.com/rasbt/status/1568622117876539396,"4) use the code to train an actual model and make sure it works

5) (bonus) upload the code to GitHub so that you can easily reference and re-use it in the future (https://t.co/CG7X6H9naV)"
3315,@rasbt,2022-09-10 14:56:02+00:00,https://twitter.com/rasbt/status/1568614280945180675,"@unsorsodicorda yes, I saw that they cited my papers and I wanted to give it a try. It's this one https://t.co/Xwtbkx1k0U"
3316,@rasbt,2022-09-10 14:40:24+00:00,https://twitter.com/rasbt/status/1568610345496756225,"Haha, based on the for-loops in the figure above, you can probably tell that I think more like a programmer than a math person ü´¢"
3317,@rasbt,2022-09-10 14:40:24+00:00,https://twitter.com/rasbt/status/1568610344431386624,"For this, I would usually take a ""notebook"", write down the key equations, come up with a simple example, and then taking a stab at it. 
For me, key is to implement it as simple as possible, and then refine it one step at a time."
3318,@rasbt,2022-09-10 14:38:43+00:00,https://twitter.com/rasbt/status/1568609922224459776,"@chrisalbon arg, yeah, the delays ... sorry to hear üôÅ"
3319,@rasbt,2022-09-10 14:37:55+00:00,https://twitter.com/rasbt/status/1568609720486830082,"And in addition to just reading a paper, one of the best exercises is to (re)implement it--of course don't do it for every paper.

My process for this is to go about it incrementally. E.g., the steps I just went through this morning to implement a loss function. 1 step at a time: https://t.co/kYa1eHKOmx"
3320,@rasbt,2022-09-10 14:32:40+00:00,https://twitter.com/rasbt/status/1568608401084583938,@chrisalbon how did it go?
3321,@rasbt,2022-09-10 02:34:04+00:00,https://twitter.com/rasbt/status/1568427557950726144,@chrisalbon Good luckü§û
3322,@rasbt,2022-09-10 02:30:08+00:00,https://twitter.com/rasbt/status/1568426566925053953,"@chrisalbon Is this in Amsterdam by chance? Yeah maybe not a bad idea. Was there for a layover couple of weeks ago, and the passport check took like forever due to congestion. Took probably 1-2 hours to get through the lines. Not an airline but more of an airport problem"
3323,@rasbt,2022-09-09 23:05:47+00:00,https://twitter.com/rasbt/status/1568375139871457282,"@paul_rietschka Maybe I am not reading your sentences right. You are making two separate statements? I am confused by ""finicky"" and ""just"", haha. Are you saying that cosine annealing is or is not a finicky scheduler?"
3324,@rasbt,2022-09-09 19:48:49+00:00,https://twitter.com/rasbt/status/1568325572194869248,"@__mharrison__ @CalcCon Super useful to know, thanks for sharing!"
3325,@rasbt,2022-09-09 19:04:21+00:00,https://twitter.com/rasbt/status/1568314383872233472,@CalcCon Curious too. Any recommendations @__mharrison__ ?
3326,@rasbt,2022-09-09 18:10:20+00:00,https://twitter.com/rasbt/status/1568300790699147271,"@BendikAF [2/2]
3) Now try cosine + warm restarts + decay. This should again improve. A decay rate of ~0.5 is a good default (?) but yeah, it's a hparam.

But take my advice with a grain of salt üòÖ. I would listen to the Kaggle experts like @ph_singer @tunguz @JFPuget @bhutanisanyam1 here"
3327,@rasbt,2022-09-09 18:07:39+00:00,https://twitter.com/rasbt/status/1568300116070793216,"@BendikAF Not a stupid question at all. Tbh I am not an expert in maxing performance this way, but I usually have best luck with the following approach

1) just use SGD and ADAM for comparison purposes

2) add a step scheduler to 1); it should improve, otherwise you have bad settings
[1/2]"
3328,@rasbt,2022-09-09 17:54:06+00:00,https://twitter.com/rasbt/status/1568296704755077120,"If someone has too much time this weekend, a similar plot but with Kaggle winning solutions would be nice.
Source: https://t.co/HiveSeqBR4

PS: SGD+scheduler FTW https://t.co/rcawMqpcFl"
3329,@rasbt,2022-09-09 17:23:24+00:00,https://twitter.com/rasbt/status/1568288980105400320,"@ChristophMolnar Basically true for any ML subfield these days üòÖ. To keep up with everything published in your field, you have to specialize in a sub-subfield üòÜ"
3330,@rasbt,2022-09-09 16:08:31+00:00,https://twitter.com/rasbt/status/1568270132631175168,@LeahAWasser and of course it's open source https://t.co/7TdiO8ejhE
3331,@rasbt,2022-09-09 16:07:49+00:00,https://twitter.com/rasbt/status/1568269955497623553,"@LeahAWasser VS Code. As a previous Atom user (many years ago), it has a similar feel, is super extensible via plugins, and is a loooot snappier"
3332,@rasbt,2022-09-09 14:43:12+00:00,https://twitter.com/rasbt/status/1568248660865187840,@ai__pub Things that can slip through if things are not easily reproducible anymore üôÑ
3333,@rasbt,2022-09-09 14:40:47+00:00,https://twitter.com/rasbt/status/1568248055656333314,"@pcastr @CSProfKGD I'd go with TMLR. Read their announcement post, and it was very refreshing to see some of the new ideas they are trying. I also heard good things from people who already submitted there."
3334,@rasbt,2022-09-09 14:16:00+00:00,https://twitter.com/rasbt/status/1568241819552555008,"@A_K_Nain @LightningAI yeah, agreed, it's a good default!"
3335,@rasbt,2022-09-09 13:32:41+00:00,https://twitter.com/rasbt/status/1568230917742776321,@subratac @casademalafama @Muay_Khaoboy Actually not exactly. The swap is between two samples from the dataset but still within the same column. I misunderstood this at first. Here's an illustration of how it should work: https://t.co/65JXCzJfBJ
3336,@rasbt,2022-09-09 13:19:25+00:00,https://twitter.com/rasbt/status/1568227578183303168,"@A_K_Nain Agree! Not a dealbreaker for me since I can easily set this manually. E.g. in @LightningAI with 2 lines of code
 
import lightning as L
L.seed_everything(123)
trainer = L.Trainer(..., deterministic=True)

Just wish determinism would be the default. Jax is nice in that respect."
3337,@rasbt,2022-09-09 13:13:56+00:00,https://twitter.com/rasbt/status/1568226197422673920,"@JZombij @JFPuget Hm, off top of my head I dunno how this could happen with the current implementation of F.cross_entropy ü§î"
3338,@rasbt,2022-09-09 03:03:53+00:00,https://twitter.com/rasbt/status/1568072672466157578,@JFPuget Negative labels? Binary cross entropy in PyTorch doesn't have the same safeguards as multi-category cross-entropy https://t.co/DH7LRVExzd
3339,@rasbt,2022-09-09 01:55:35+00:00,https://twitter.com/rasbt/status/1568055483814084608,"Great, informative thread on Tensor Cores &amp; matmuls, how to leverage them (if your hardware supports it), and why their existence is somewhat restricting."
3340,@rasbt,2022-09-09 01:53:16+00:00,https://twitter.com/rasbt/status/1568054901535645696,"@cHHillee Very nice thread! Thanks for sharing! 
In the figure above, that means that the tensor core is even more specific/restricted as it does the whole affine map (not just the matmul)?"
3341,@rasbt,2022-09-08 18:25:14+00:00,https://twitter.com/rasbt/status/1567942149374631936,"@BodoBrueckner @tunguz whoa, 15 years ahead of its time!"
3342,@rasbt,2022-09-08 17:22:25+00:00,https://twitter.com/rasbt/status/1567926343823757314,"@3scorciav Actually, I kind of got used to it in everyday life. haha, but when it comes to writing a book or making slides for a course, there is nothing more annoying than forgetting to set a random seed and then trying to recreate a plot because you didn't save it in high res"
3343,@rasbt,2022-09-08 17:12:48+00:00,https://twitter.com/rasbt/status/1567923923429511169,"@3scorciav Not discouraged but certainly confused. If you are not familiar with this, you‚Äôd think there‚Äôs a bug in your code if you can‚Äôt reproduce your own results the next day (or someone‚Äôs research or tutorial)."
3344,@rasbt,2022-09-08 16:52:57+00:00,https://twitter.com/rasbt/status/1567918927044554752,@PCacioppi @tunguz Hah it‚Äôs not for me; exclusively take cold showers and my preferred setting is basically ‚Äúas cold as it gets‚Äù
3345,@rasbt,2022-09-08 16:44:31+00:00,https://twitter.com/rasbt/status/1567916806383325185,@tunguz I give it 5 more years until they take inspiration from electric car interiors and start replacing them with touchscreens üòï
3346,@rasbt,2022-09-08 15:56:29+00:00,https://twitter.com/rasbt/status/1567904715312173064,"@HamelHusain @amuellerml @natfriedman Hah, yes. I'd say the name copilot is also quite fitting (vs. autopilot) :P"
3347,@rasbt,2022-09-08 14:05:57+00:00,https://twitter.com/rasbt/status/1567876902005743616,"*this goes beyond the random seed that Tf/Keras is now setting in their initializer of course. Above, I am just trying to make a point that you have to go a whole extra mile if you care a bit about deterministic behavior &amp; reproducible results. (And then there's the hardware ...)"
3348,@rasbt,2022-09-08 14:04:23+00:00,https://twitter.com/rasbt/status/1567876507153874944,"[3/3] Sure, you can fix that to some extend (PyTorch and PyTorch Lightning examples below), but I feel like this should be the default behavior. https://t.co/NPZV8NhrIN"
3349,@rasbt,2022-09-08 14:04:23+00:00,https://twitter.com/rasbt/status/1567876505442607104,"[2/3] Right now, rerunning code and experiments (by default) will always yield different results (even if you use a CPU / the same hardware). 
This is pretty confusing for most newcomers."
3350,@rasbt,2022-09-08 14:04:22+00:00,https://twitter.com/rasbt/status/1567876503475523588,"The move towards deterministic behavior even if the (weight) initializer is unseeded is pretty cool. 

Think of all the practical scenarios where researchers adopt DL in their projects, or people want to follow along online tutorials etc. [1/3]"
3351,@rasbt,2022-09-08 13:37:06+00:00,https://twitter.com/rasbt/status/1567869642286272512,"@Ihor_Bobak Interesting. Just curious, before you rewrote anything, did you consider using e.g., PyTorch through the C++ API?"
3352,@rasbt,2022-09-08 13:36:03+00:00,https://twitter.com/rasbt/status/1567869377877360641,"@_sour__cherry_ Oh yeah, using better accelerators or hardware in general is probably THE most obvious thing. Should have probably been top 1 on that list. Haha, surprised no one mentioned that yet"
3353,@rasbt,2022-09-08 13:34:49+00:00,https://twitter.com/rasbt/status/1567869063879090176,"@stoyanpstoyanov Good suggestion, but I'd say pruning falls into the same category as knowledge distillation and low-rank factorization, etc. as it changes the model architecture"
3354,@rasbt,2022-09-08 13:33:30+00:00,https://twitter.com/rasbt/status/1567868734236229632,"@ullmanalex You mean graph features as in feature engineering (not as in optimizing the computation graph?). Yeah, I did that quite a bit in molecular modeling contexts. Although, for that, I now shifted more towards graph NNs https://t.co/gfgF8SQ8B1"
3355,@rasbt,2022-09-08 13:31:30+00:00,https://twitter.com/rasbt/status/1567868232215810048,"@BendikAF @nsanda10 It's bascially ""what's learnable for that particular model"". I like the convergence of train+validation in the end, are you using a scheduler? Which one?"
3356,@rasbt,2022-09-08 13:30:06+00:00,https://twitter.com/rasbt/status/1567867877616672770,"@vlordier @SongHan_MIT Awesome, didn't know this existed. Happily bookmarking it for my future courses list"
3357,@rasbt,2022-09-08 13:28:45+00:00,https://twitter.com/rasbt/status/1567867538033311744,"@pommedeterre33 Yeah my post above is barely scratching the surface using an intuitive example. A better (&amp; more complicated) examples would be lower-level ones. 
I forgot the impl details, but I think the cross_entropy in PyTorch under the hood is doing that (compared to Softmax+loglikelihood)"
3358,@rasbt,2022-09-08 13:26:03+00:00,https://twitter.com/rasbt/status/1567866859151663105,"@MehdiAllahyari Yeah, check this out: ""Scaling up BERT-like model Inference on modern CPU - Part 1"" https://t.co/73RbUgCq4i"
3359,@rasbt,2022-09-08 13:10:16+00:00,https://twitter.com/rasbt/status/1567862889364463616,"@amuellerml @natfriedman As long as Python, JS, Swift, Rust etc remain the most dominant languages for their respective tasks we (and machines) write code for humans not for machines. 

Writing Python code for a machine is probably like an accountant still using an abacus."
3360,@rasbt,2022-09-08 12:55:35+00:00,https://twitter.com/rasbt/status/1567859192022683650,"@benkellyone Hah, I am actually using Otter quite a lot for generating subtitles (closed captions) for my own videos. It‚Äôs the only platform that can deal with both my accent and technical math/ML jargon (looking at you, YT!)"
3361,@rasbt,2022-09-08 12:52:12+00:00,https://twitter.com/rasbt/status/1567858342403399682,@akshay_pachaar @LightningAI Hah I am very flattered by the kind words ‚ò∫Ô∏è. Love your informative contents &amp; keep up the good work üôå
3362,@rasbt,2022-09-08 02:37:00+00:00,https://twitter.com/rasbt/status/1567703521574752258,@josepjaume @DynamicWebPaige @gitpod @OnDeck Well this way I could actually be productive on an airplane (I am too tall for using a laptop on most planes) ‚Ä¶ except that it also has games on it üòá
3363,@rasbt,2022-09-08 02:33:42+00:00,https://twitter.com/rasbt/status/1567702689638715393,"@rrherr @_brohrer_ After R, I think JavaScript was the first language I learned (I think even before Python). Back then, I thought JS would be replaced within a decade or so. Oh boy was I wrong üòÇ"
3364,@rasbt,2022-09-08 02:22:21+00:00,https://twitter.com/rasbt/status/1567699833099624448,@fchollet The deterministically behaving  unseeded initializer is actually a great idea. Something I wish all frameworks would do (and sth that should have been done by all frameworks from the beginning). This has the potential to avoid so much confusion and gotchas for new users.
3365,@rasbt,2022-09-08 01:59:58+00:00,https://twitter.com/rasbt/status/1567694200979734529,@ml_angelopoulos @kchonyc @stats_stephen This is really great üëè! Excited to spend some time working through the hands on examples!
3366,@rasbt,2022-09-08 01:58:14+00:00,https://twitter.com/rasbt/status/1567693765220995077,@TaliaRinger Not sure but I guess my advice would be to somehow emphasize that it is interactive as possible somehow
3367,@rasbt,2022-09-08 01:55:09+00:00,https://twitter.com/rasbt/status/1567692989706682368,"@TaliaRinger Only years later when I started undergrad, I realized that this was actually how things are often done üòÖ, and in hindsight i was thinking that the person did a normal presentation ‚Äî it was just unusual back then, the way it was just one person talking and not very interactive."
3368,@rasbt,2022-09-08 01:51:33+00:00,https://twitter.com/rasbt/status/1567692082143236097,"@TaliaRinger So cool! Personally, I never have but we had a postdoc giving a talk back when I was in Highschool. All I remember was that we thought her slides were weird (because in Highschool teachers didn‚Äôt use slides, so that was a weird new thing). Do school teachers do slides these days?"
3369,@rasbt,2022-09-08 01:26:26+00:00,https://twitter.com/rasbt/status/1567685761268424704,@akshay7 @radekosmulski This!
3370,@rasbt,2022-09-08 00:14:31+00:00,https://twitter.com/rasbt/status/1567667662884323328,@TiptonSolar I would exclude that from the list because that's done during training as well
3371,@rasbt,2022-09-08 00:13:12+00:00,https://twitter.com/rasbt/status/1567667330771042307,"@GuvercinGoktug It might also be something that the JIT in TorchDynamo does, but honestly dunno, I am just learning this side of things https://t.co/HTB1o67vIO"
3372,@rasbt,2022-09-08 00:12:14+00:00,https://twitter.com/rasbt/status/1567667089216774144,"@SurdoiuT @ptullochott Wow,  30 times speedup here. Learning lots of new things here. Thanks!"
3373,@rasbt,2022-09-07 22:15:25+00:00,https://twitter.com/rasbt/status/1567637689469378561,"@subratac @casademalafama @Muay_Khaoboy Yeah, I think that maybe the idea here is that different columns measure different things (maybe on different magnitudes if not normalized) and swapping across columns could be a bit of a mess. So, you are essentially swapping values in that column with ""reasonable"" values"
3374,@rasbt,2022-09-07 18:25:57+00:00,https://twitter.com/rasbt/status/1567579944628240386,@python_ds https://t.co/nNol8CqpLA
3375,@rasbt,2022-09-07 16:56:06+00:00,https://twitter.com/rasbt/status/1567557331604443138,"@TheFucking22 In the denoising autoencoder context, I suppose one is the feature input, the other is the ground truth. 
For a classifier, I wonder if you just use that as a regular batch (with the same labels) to learn better/more robust embeddings as a form of regularlization"
3376,@rasbt,2022-09-07 16:48:56+00:00,https://twitter.com/rasbt/status/1567555529483878405,"@ptullochott Oh yes, optimizing read access. Good point."
3377,@rasbt,2022-09-07 16:28:42+00:00,https://twitter.com/rasbt/status/1567550435841409026,"@_krr12 Good point. I would put that into a separate category with pruning etc, because the result is essentially a different architecture."
3378,@rasbt,2022-09-07 15:21:35+00:00,https://twitter.com/rasbt/status/1567533545157001217,Thx to @JFPuget pointing out my misunderstanding -- I originally thought the swapping is among two different columns (like feat1 and feat2).
3379,@rasbt,2022-09-07 15:19:33+00:00,https://twitter.com/rasbt/status/1567533034798211072,"It's worth clarifying (since the original tweet above looks misleading) that it doesn't literally swap columns but row values of a column. E.g., if you have two batches you exchange row data among the same columns. Probably easier to see in a figure:

https://t.co/gov9CwaUtX"
3380,@rasbt,2022-09-07 15:07:47+00:00,https://twitter.com/rasbt/status/1567530072147464193,"@JFPuget Ok, here is a more detailed illustration of how I interpret the code: https://t.co/ZBw9ForlgQ"
3381,@rasbt,2022-09-07 14:40:52+00:00,https://twitter.com/rasbt/status/1567523301009801223,"@mpaepper Ah good one. Sry, that's really beyond my current knowledge, but would that go hand in hand with loop tiling; i.e,. in its current implementation, it would be a trace reordering?"
3382,@rasbt,2022-09-07 14:38:02+00:00,https://twitter.com/rasbt/status/1567522587000848384,@JFPuget But then the values in each column (same column but from different training examples) are different? Maybe I should implement that thing on a toy dataset for visualization to help the discussion / get a better grasp.
3383,@rasbt,2022-09-07 14:34:58+00:00,https://twitter.com/rasbt/status/1567521813290172419,"@jnearestn hah thanks, I love those kind of lectures!"
3384,@rasbt,2022-09-07 14:34:12+00:00,https://twitter.com/rasbt/status/1567521622797520902,"@JFPuget ohh, I see. I thought that gen1 and gen2 (that is batch 1 and batch 2) can be from different samples. Thanks"
3385,@rasbt,2022-09-07 14:31:55+00:00,https://twitter.com/rasbt/status/1567521047221604353,@JFPuget @_NNJJPP_ https://t.co/i5StrnsgST
3386,@rasbt,2022-09-07 14:30:33+00:00,https://twitter.com/rasbt/status/1567520704676995072,@JFPuget A picture says more than 1000 words. The way I see it is https://t.co/8j5LDAFMOg
3387,@rasbt,2022-09-07 14:20:49+00:00,https://twitter.com/rasbt/status/1567518255169912835,[6/6] (5) Quantization essentially reduces the precision (and typically casts floats-&gt;ints) to speed up computation &amp; lowering memory requirements (while maintaining accuracy). Borderline-included it as it can reduce the accuracy of your model. Tutorial: https://t.co/0qlip772Uj
3388,@rasbt,2022-09-07 14:20:49+00:00,https://twitter.com/rasbt/status/1567518253857099776,"[5/6] (4) Operator fusion: here, if you have multiple loops, you try to merge those into one. (A classic example is calculating the mean and standard deviation in one pass). 
There was another nice example in the DANets paper I recently posted about (https://t.co/HrguYMLhFs): https://t.co/ogSXqa6hiL"
3389,@rasbt,2022-09-07 14:20:49+00:00,https://twitter.com/rasbt/status/1567518252141518852,"[4/6] (3) Loop tiling. I actually only just learned about this recently (thx to #MLSystemsBook). Something that is still slightly above my head ü§Ø: essentially, you change the data accessing order in a loop to leverage the hardware's memory layout &amp; cache https://t.co/1n73teO6cU https://t.co/M5lvKOmb5T"
3390,@rasbt,2022-09-07 14:20:48+00:00,https://twitter.com/rasbt/status/1567518250568671234,[3/6] (2) Vectorization is a classic that probably doesn't need much explanation. In a nutshell this involves replacing costly for-loops with ops that apply the same operations to multiple elements. You probably already do that automatically if you are using linalg/a DL framework https://t.co/fumJ8Gi5gm
3391,@rasbt,2022-09-07 14:20:48+00:00,https://twitter.com/rasbt/status/1567518249071378432,[2/6] (1) Parallelization (in an inference context) essentially means splitting the batches you want to predict on into chunks; the chunks are then processed in parallel. PyTorch has a nice tutorial on that here: https://t.co/aPoKzTKlyo https://t.co/OOdI9raKS5
3392,@rasbt,2022-09-07 14:20:47+00:00,https://twitter.com/rasbt/status/1567518247708200961,"Some techniques for optimizing inference speeds (without changing the model architecture):

(1) Parallelization
(2) Vectorization
(3) Loop tiling
(4) Operator fusion
(5) Quantization

Anything missing?

[1/6]"
3393,@rasbt,2022-09-07 13:39:33+00:00,https://twitter.com/rasbt/status/1567507866919084033,"@casademalafama @Muay_Khaoboy Yeah, basically a data augmentation technique."
3394,@rasbt,2022-09-07 13:38:09+00:00,https://twitter.com/rasbt/status/1567507515671298048,"@_NNJJPP_ @JFPuget I don't think so. Bootstrapping implies sampling with replacement. Here, it's more like column-wise shuffling."
3395,@rasbt,2022-09-07 13:37:28+00:00,https://twitter.com/rasbt/status/1567507343797100546,"@JFPuget Yes, sorry, tweet char limits. Of course, swapping feature values across columns, not entire columns."
3396,@rasbt,2022-09-07 13:35:53+00:00,https://twitter.com/rasbt/status/1567506946046951424,"@danofer Haha, no worries, can totally understand. Maybe one day ..."
3397,@rasbt,2022-09-07 13:35:02+00:00,https://twitter.com/rasbt/status/1567506732645072896,"@danofer @KravitzEl @Muay_Khaoboy Hah, yes, reminds me of a recommendation along the lines of ""participate on Kaggle to learn, not to win"" üòÜ"
3398,@rasbt,2022-09-07 13:33:27+00:00,https://twitter.com/rasbt/status/1567506333406044161,"@vicspam @tdietterich Good point. It's a common one on Kaggle. For those unfamiliar: you mix training and test data, and you assign Then, you train a model trying to predict whether data comes from the training or the test set. If you can predict the membership correctly, then there's something fishy"
3399,@rasbt,2022-09-07 02:43:13+00:00,https://twitter.com/rasbt/status/1567342697974829056,"@Muay_Khaoboy Yeah, that‚Äôs what I am suspecting. Not aware of any formal investigation (beyond mixup of course); hence crowdsourcing üòÖ"
3400,@rasbt,2022-09-07 02:38:56+00:00,https://twitter.com/rasbt/status/1567341620084854785,"@Muay_Khaoboy @KravitzEl Yeah, I suspect that it maybe helps with building more robust (generalizable) embeddings. Probably definitely a technique to reduce overfitting. I just wonder if that can help with other methods as well ü§î"
3401,@rasbt,2022-09-07 02:13:53+00:00,https://twitter.com/rasbt/status/1567335314846359552,"Going down some deep rabbit holes here and learning new things ... 
Seems like a successful Kaggle strategy is randomly swapping cols in a tabular dataset (~like mix-up, but w/o including the labels). 
Anyone tried this for a serious project with a non-deep learning tabular algo? https://t.co/31amikDBNT"
3402,@rasbt,2022-09-06 19:16:59+00:00,https://twitter.com/rasbt/status/1567230401029996545,"@santiagobasulto @PacktPublishing Arg, sorry to hear :(. @PacktPublishing can hopefully help with that. Afaik the Amazon copies are print-on-demand, and it could be a broken Amazon printer issue as well."
3403,@rasbt,2022-09-06 16:48:15+00:00,https://twitter.com/rasbt/status/1567192968938885122,"@francoisfleuret Haha, this. I recently drove a 12 foot moving truck. Parking wasn‚Äôt pretty but I made it without incident. üôÉ"
3404,@rasbt,2022-09-06 16:08:40+00:00,https://twitter.com/rasbt/status/1567183007731130369,"@vijaybsubedi Yes, sry https://t.co/JaFSbCI9pA"
3405,@rasbt,2022-09-06 16:07:31+00:00,https://twitter.com/rasbt/status/1567182716784844800,"@mt0rm0 That's true! Nowadays, I try to focus only on papers that are somewhat directly related to a project at hand."
3406,@rasbt,2022-09-06 02:19:46+00:00,https://twitter.com/rasbt/status/1566974407255498752,"@machsci @michaelwaskom @__mharrison__ Rabbit hole üêá.
The front light display of the Onyx seems also super interesting for evening reading (https://t.co/osdt8sSW87). 

But no, I‚Äôll be disciplined and try to wait for the first good color e-ink üòÖ"
3407,@rasbt,2022-09-06 01:51:09+00:00,https://twitter.com/rasbt/status/1566967206063357953,"@machsci @michaelwaskom @__mharrison__ Oh wow, thanks for sharing, had no idea this existed. The ceramic never-replace nib of the Supernote does sound really intriguing actually. Probably not worth switching if you already have one; but if I would buy one today, the Supernote does look like a good alternative"
3408,@rasbt,2022-09-06 01:38:01+00:00,https://twitter.com/rasbt/status/1566963899836125190,@paul_rietschka Tbh I am just waiting for a good color e-ink tablet as my primary reader (whereas I will probably keep my current b/w e-ink as my notepad)
3409,@rasbt,2022-09-06 01:32:07+00:00,https://twitter.com/rasbt/status/1566962415027240960,"@Muay_Khaoboy hah, yeah, same. I hope it's at least linear SVM"
3410,@rasbt,2022-09-06 01:28:32+00:00,https://twitter.com/rasbt/status/1566961513922969602,"@paul_rietschka And amazingly expensive for just reading and writing üòÜ (I know, I could do more on it, but I really just want something for replacing pen and paper)"
3411,@rasbt,2022-09-06 01:25:47+00:00,https://twitter.com/rasbt/status/1566960823427293184,"And here are the results from the ""Your fav machine learning technique, algorithm, or tool (1 or 2 words)"" survey question 

Hah, if I had to pick 1 algo for the lonely island, it'd probably be random forest as well (a simple, kind-of-worry-free baseline)

https://t.co/iWbsNZKaWA https://t.co/yTqlwvZRmF"
3412,@rasbt,2022-09-06 01:07:43+00:00,https://twitter.com/rasbt/status/1566956276462092291,"Alright, that was fun! Just closed the poll and randomly sampled the winners:
@SwetaBioX
@prasetyaputraa 
@Ryan_Dreifuerst
Will be in touch via DM :)"
3413,@rasbt,2022-09-06 00:59:17+00:00,https://twitter.com/rasbt/status/1566954151925497856,"@paul_rietschka Well, I already use my e-ink tablet for note-taking; so, you saying that I maybe need to buy a second tablet so that I can have them side-by-side? My partner will kill me ü§£"
3414,@rasbt,2022-09-06 00:56:32+00:00,https://twitter.com/rasbt/status/1566953463547924481,"@michaelwaskom @__mharrison__ It's great, helps me focus much better &amp; writing feels way better vs a regular tablet. 
But tbf, let me mention the downsides : (1) the cloud-sync has a subscription model now; (2) e-ink contrast is not super high compared to regular paper; could have used an optional light"
3415,@rasbt,2022-09-05 23:42:59+00:00,https://twitter.com/rasbt/status/1566934950271762438,"@TaliaRinger ""Automation"" is already taken by COBOL in the 1960's üòÜ"
3416,@rasbt,2022-09-05 23:38:36+00:00,https://twitter.com/rasbt/status/1566933848335720449,"@MortimerWerther Yes, kind of. It was a long weekend here in the US üòÅ"
3417,@rasbt,2022-09-05 21:14:00+00:00,https://twitter.com/rasbt/status/1566897460311646218,"@john_lam Thanks for sharing! Yeah, this is definitely somewhat related to what I do. When I am research a topic, I usually start by collecting resources; then I read through all the resources and take ""the take-aways"" notes. On the 3rd pass I would come back and read things in detail"
3418,@rasbt,2022-09-05 21:11:50+00:00,https://twitter.com/rasbt/status/1566896914079039489,"@marksimi @akshay_pachaar That's a great list! Especially if you read the paper ""holistically"". One little thing to add: Also don't force yourself to be a completionist. Sometimes, I read a paper for a specific context (how did they solve xyz differently?) where I'd say skip some of the steps :)"
3419,@rasbt,2022-09-05 21:08:05+00:00,https://twitter.com/rasbt/status/1566895971338010625,"@__mharrison__ @michaelwaskom [2/2] ... that it's more convenient for notetaking at home; otherwise, I would have to have 2 tablets: one for the paper itself, one for notetaking. I also read papers on the tablet, but yeah, 1 tablet for both (a) reading+annotating and (b) blank-slate writing is not ideal :P"
3420,@rasbt,2022-09-05 21:06:31+00:00,https://twitter.com/rasbt/status/1566895577106882561,@__mharrison__ @michaelwaskom I am still using it! Actually pretty heavily and still like it :). I 100% replaced all paper notebooks since January. The reason why I print certain things on paper is 1/2
3421,@rasbt,2022-09-05 16:01:48+00:00,https://twitter.com/rasbt/status/1566818891313078272,"@JFPuget Does that include ML related topics, such as ""attention is all you need""? üòÜ"
3422,@rasbt,2022-09-05 14:32:20+00:00,https://twitter.com/rasbt/status/1566796378268962820,"@akshay_pachaar [4/4] Then, if I decide the paper is worthwhile &amp; I'm interested in details, I do a second pass taking notes this time; I usually mostly focus on things that are relevant to a given project &amp; I rarely waste time on general notes (coz the gist is in the paper's abstract anyway)"
3423,@rasbt,2022-09-05 14:30:56+00:00,https://twitter.com/rasbt/status/1566796023762227200,"@akshay_pachaar [3/4] To me, it's most effective to read through the paper without taking notes at first (highlighting a few odd things is ok). Then, from memory, summarize what the paper is about / what you got out of it."
3424,@rasbt,2022-09-05 14:30:28+00:00,https://twitter.com/rasbt/status/1566795908553084928,"@akshay_pachaar [2/4] These days, I often then read the paper sequentially. I try to avoid taking notes in the first pass because it is pretty distracting. Also, you'd end up taking notes of trivial things, bogging you down."
3425,@rasbt,2022-09-05 14:29:27+00:00,https://twitter.com/rasbt/status/1566795651651862531,"@akshay_pachaar Sure! First, I'd say there is no one or right way to read a paper. It depends on what you want to get out of it. General things that help me are: after reading the abstract, I am going through the figures and tables (before reading it in detail). 1/4"
3426,@rasbt,2022-09-05 14:22:06+00:00,https://twitter.com/rasbt/status/1566793802358161414,"Hah, the downside of a vacation: I just noticed my printer heads got clogged up. (Flushing it fixed it!) 
Good excuse to get back into the ""at least 1 paper per week"" routine üòÜ https://t.co/yq1I2V9hqV"
3427,@rasbt,2022-09-05 14:15:30+00:00,https://twitter.com/rasbt/status/1566792140658720768,"@25shadesofblack @karpathy Yeah I am open to it, but at the same time, I am not sure if I want to start an Amazon Prime subscription just for satisfying my FOMO, haha. Will probably revisit it later this winter once all the episodes are out"
3428,@rasbt,2022-09-05 13:58:52+00:00,https://twitter.com/rasbt/status/1566787954806226945,"@john_lam I read Cal Newport's Digital Minimalism book, but I honestly don't know/can't remember the ""deliberate practice exercise"" aspect of it. Actually, it's more like ""shared notes"" -- I am very interested in the topic, and people often ask me about it, so why not sharing it üòÖ"
3429,@rasbt,2022-09-05 13:57:06+00:00,https://twitter.com/rasbt/status/1566787510679879682,"@deepakns @aureliengeron @fchollet @lak_luster @svpino @chipro @abhi1thakur Thanks for the kind words, and I am wishing you a Happy Teacher's Day, too!!! üôå"
3430,@rasbt,2022-09-04 18:43:41+00:00,https://twitter.com/rasbt/status/1566497244156674050,@marktenenholtz And then there is Kaggle if you don‚Äôt know what to do with your extra time and energy üòÜ
3431,@rasbt,2022-09-04 17:56:17+00:00,https://twitter.com/rasbt/status/1566485315250016256,"@TaliaRinger haha, just order a regular coffee; it's tiny (don't want to know what an espresso looks like) but so good.

https://t.co/cw3aUCg2Q6"
3432,@rasbt,2022-09-04 17:49:19+00:00,https://twitter.com/rasbt/status/1566483559388520448,"@olgias @_akhaliq @CSProfKGD Haha, yeah. Afaik it was my first true vacation since my undergrad like 12 years ago. It's really not feasible in academia (at least pre-tenure, or so they say, haha)"
3433,@rasbt,2022-09-04 16:07:56+00:00,https://twitter.com/rasbt/status/1566458047047745536,"@CSProfKGD Anyways, sounds and looks like this was designed by a gen Z multi-screen multitasker üòÜ. 
I dunno, maybe I am old, but in both cases I would have preferred a bigger view. (left: bigger projector + pull down screen; right: simply 1 bigger screen)"
3434,@rasbt,2022-09-04 15:54:04+00:00,https://twitter.com/rasbt/status/1566454557676392449,"@CSProfKGD Wait what. What's even the point of this dual projector / screen setup? One as a backup, or can you show different things on both screens?"
3435,@rasbt,2022-09-04 15:52:35+00:00,https://twitter.com/rasbt/status/1566454182793601025,@gabrielpeyre @CSProfKGD The many faces of PCA üòÜ
3436,@rasbt,2022-09-04 15:46:01+00:00,https://twitter.com/rasbt/status/1566452530342682626,"@_akhaliq @CSProfKGD Just got back from a vacation last week, and wow, Stable Diffusion, now Optimized Stable Diffusion, ... things are moving really fast these days ü§Ø"
3437,@rasbt,2022-09-04 15:02:01+00:00,https://twitter.com/rasbt/status/1566441457984192514,"@YiHan96461195 2/2 Forced early stopping, imho is always bad; particularly because your model could experience double-descent.
Anyways, in practice, it's even better to use a scheduler (e.g. cosine decay) and tune the model to convergence (CC @ph_singer)"
3438,@rasbt,2022-09-04 15:00:29+00:00,https://twitter.com/rasbt/status/1566441074930978816,"@YiHan96461195 Early stopping on the validation accuracy/loss? I usually do let the training run until it converges, and then I use the best model checkpoint (based on validation accuracy) to select my model. 1/2"
3439,@rasbt,2022-09-04 14:58:52+00:00,https://twitter.com/rasbt/status/1566440666401480713,"@CamasRamses Arg, sorry to hear. Maybe @PacktPublishing can help!"
3440,@rasbt,2022-09-04 14:57:09+00:00,https://twitter.com/rasbt/status/1566440235860480003,"@radekosmulski @sardinan_guy @JFPuget Most importantly, conda and mamba should give the same results though; so, the only downside is basically the speed. How would beginners figure this out? They don't have to. If they use plain miniconda/-forge, someone will point it out to them eventually :P"
3441,@rasbt,2022-09-04 14:55:30+00:00,https://twitter.com/rasbt/status/1566439820372676617,@radekosmulski @sardinan_guy @JFPuget 100% agree. I think the best way forward would be to make libmamba the default solver. https://t.co/Jem1nTvc3L
3442,@rasbt,2022-09-04 14:52:19+00:00,https://twitter.com/rasbt/status/1566439019206025216,"@WickedViper23 Wait what, only the 1st answer is somewhat related üòÜ. 7-10 have nothing to do with basic checks; they are basically hyperparameter tuning steps ü§î."
3443,@rasbt,2022-09-04 14:50:19+00:00,https://twitter.com/rasbt/status/1566438512580182016,@AndreHanselow Thanks a lot üôå. Added it to my reading list as a potential candidate for this list!
3444,@rasbt,2022-09-04 14:49:08+00:00,https://twitter.com/rasbt/status/1566438215111909376,"@Tinker_1081 2/2 in this case, more examples for those classes, augmentation, and/or a focal loss could be things to try. If there is a general problem across classes, that's a very different can of worms."
3445,@rasbt,2022-09-04 14:48:05+00:00,https://twitter.com/rasbt/status/1566437953777401856,"@Tinker_1081 Yes, collecting more data -- if possible -- is the best thing you can do. Other than that, it really depends on details, and confusion matrices can give additional insights. Like when 2 classes (like 5 and 6) are most often confused; focusing on those makes most sense 1/2"
3446,@rasbt,2022-09-03 19:51:29+00:00,https://twitter.com/rasbt/status/1566151916459098119,@sardinan_guy @JFPuget @radekosmulski Yeah the mamba solver is way faster
3447,@rasbt,2022-09-03 19:46:50+00:00,https://twitter.com/rasbt/status/1566150746172686337,"@rationalcypher @svpino In an ideal world, I agree! The bottleneck is really the additional time &amp; effort it would take, plus your skills kind of atrophy in your less-favorite tool üòÖ"
3448,@rasbt,2022-09-03 19:45:31+00:00,https://twitter.com/rasbt/status/1566150414172622857,"@JFPuget @radekosmulski Same. I actually prefer miniforge, which is essentially conda with conda-forge as the default channel: https://t.co/OKx3RDLEst"
3449,@rasbt,2022-09-03 16:17:31+00:00,https://twitter.com/rasbt/status/1566098069598470149,"@Ashwin_S18 Haha, no üòÜ. That's why I only ask for the twitter handle (so I can DM for shipping details) &amp; don't ask for names and addresses etc. 

Regarding the favorite ML thingy question; I want to do a little fun thing with this that I post here on Monday üòÖ."
3450,@rasbt,2022-09-03 16:07:14+00:00,https://twitter.com/rasbt/status/1566095481268482048,"@DrJHoward @WickedViper23 Haha, yes. Or even just Adam. For some reason, it sometimes (often) works better than AdamW for me."
3451,@rasbt,2022-09-03 15:37:13+00:00,https://twitter.com/rasbt/status/1566087927519649792,@akash_dugam I have a little write-up about it here üòÅ: https://t.co/WsT2MvUom4
3452,@rasbt,2022-09-03 15:35:56+00:00,https://twitter.com/rasbt/status/1566087607389487112,@deanabb üíØ. The precision-recall trade-off :)
3453,@rasbt,2022-09-03 15:35:31+00:00,https://twitter.com/rasbt/status/1566087500338176001,@nevgeniev @karpathy I heard good things about WoT but I am always careful with movie/TV show adaptions of books I liked. They can kind of ruin it for me. I think the old LOTR trilogy and GoT were probably the only exception so far.
3454,@rasbt,2022-09-03 15:33:36+00:00,https://twitter.com/rasbt/status/1566087019008344067,@__nxhx__ Good one. Probably a step 0) :)
3455,@rasbt,2022-09-03 15:32:46+00:00,https://twitter.com/rasbt/status/1566086808542265345,"@WesleyW16195443 @nishparadox @karpathy It's more like there is House of the Dragon, Westworld, and Rings of Power, Wheel of Time, ... but I really only have time for one of those I guess üòÖ"
3456,@rasbt,2022-09-03 15:31:34+00:00,https://twitter.com/rasbt/status/1566086508322381826,"@francoisfleuret @rabinadk1 @LightningAI @PyTorch Yeah, I think it makes sense to have `with torch. no_grad()` and `.eval() ` as too independent things. with `torch.inference_mode()` there is maybe a missed opportunity to automatically put a model into .eval mode. Or maybe that's just to avoid unexpected side-effects. Hm."
3457,@rasbt,2022-09-03 15:27:49+00:00,https://twitter.com/rasbt/status/1566085564897656835,@shiwangi27 Good one. I would usually check for imbalance prior. Or part of step 3 where I implement the zero-rule baseline. Good remedy suggestions btw!
3458,@rasbt,2022-09-03 15:24:36+00:00,https://twitter.com/rasbt/status/1566084754621038594,"@MarkGoodhead1 @bernhardsson wow, nice, never heard of it. Need to try it some time. Thanks!"
3459,@rasbt,2022-09-03 15:24:11+00:00,https://twitter.com/rasbt/status/1566084650329640960,"@udaylunawat I'd say ""the usual"" way is more efficient to start with, because one-vs-rest requires an ensemble, which can be expensive with DNNs"
3460,@rasbt,2022-09-03 15:22:02+00:00,https://twitter.com/rasbt/status/1566084106462584834,@JordiClive Great suggestion! I usually do it if things are not working as well as I expect ( https://t.co/q5615Se0zm)
3461,@rasbt,2022-09-03 15:21:02+00:00,https://twitter.com/rasbt/status/1566083854666014720,"@rcsaxe Oh yes, I like doing that as well. I am lazy though and only do it if there are issues. E.g., if my model is not substantially better than the baseline.  https://t.co/q5615Se0zm"
3462,@rasbt,2022-09-03 15:17:35+00:00,https://twitter.com/rasbt/status/1566082987627782146,"@Shoelim8 Yes, and start with baselines!"
3463,@rasbt,2022-09-03 15:08:48+00:00,https://twitter.com/rasbt/status/1566080779154866180,@aallpp83 That was in a previous book :). I summarized some of my thoughts in this section here: https://t.co/F4cHj7qJeJ
3464,@rasbt,2022-09-03 14:42:42+00:00,https://twitter.com/rasbt/status/1566074209041891328,@Abhijit_Deo1 @svpino ... ü§î
3465,@rasbt,2022-09-03 14:41:31+00:00,https://twitter.com/rasbt/status/1566073910730399745,"Doing a Back-to-school ü•≥ book giveaway üìö,
giving away 3 signed copies of my Machine Learning with PyTorch and Scikit-Learn book.
(For free, shipping to your door anywhere in the world!)

Your Twitter handle Is All I Need (by Monday) for a random draw: https://t.co/lOTwdLFmwi https://t.co/t7r5uI4XkZ"
3466,@rasbt,2022-09-03 14:13:53+00:00,https://twitter.com/rasbt/status/1566066956012224513,@svpino * similar to my research papers
3467,@rasbt,2022-09-03 14:13:21+00:00,https://twitter.com/rasbt/status/1566066821681274880,"@svpino My old books were based on TensorFlow, my new book is based on PyTorch ‚Ä¶ is all I‚Äôm saying üôÉ"
3468,@rasbt,2022-09-02 21:09:19+00:00,https://twitter.com/rasbt/status/1565809118836916224,@CalcCon What are your go-to mitigations to lower alpha? Layer-wise pre/post-training? Or do you see it more of a general diagnostic for model selection?
3469,@rasbt,2022-09-02 21:07:40+00:00,https://twitter.com/rasbt/status/1565808701403021315,"@CalcCon Wow, awesome. Saving &amp; will be trying this in my next research project! Thanks a lot! üôå"
3470,@rasbt,2022-09-02 20:56:48+00:00,https://twitter.com/rasbt/status/1565805966758744068,"@CalcCon whoa, good one. would you also do this for very deep nets (100+ layers) and if you have skip connections?"
3471,@rasbt,2022-09-02 20:43:28+00:00,https://twitter.com/rasbt/status/1565802612515012609,"@alepiad Good one! For text problems, there are also dictionary-based classifiers that don't rely on ML. They also make good, simple baselines: https://t.co/XJYiufUuBn"
3472,@rasbt,2022-09-02 20:41:52+00:00,https://twitter.com/rasbt/status/1565802208041525252,"@nsanda10 if you still see a slope (like on the left), that means the model hasn't converged, yet. It could still learn sth useful from the training data. https://t.co/rWBlo85dxt"
3473,@rasbt,2022-09-02 20:35:49+00:00,https://twitter.com/rasbt/status/1565800688042532866,"@hssn_20 @bernhardsson @yutianc whoa, good timing. that'd be a great long-weekend read. thanks!"
3474,@rasbt,2022-09-02 20:32:23+00:00,https://twitter.com/rasbt/status/1565799821923045377,"@charles_irl @Gradio Ah yes, good one! For student class projects, when students worked on problems like parsing handwritten latex math or sign language, I usually recommended a demo with a submission component where they could check actual real-world pictures (from other students)."
3475,@rasbt,2022-09-02 20:27:51+00:00,https://twitter.com/rasbt/status/1565798682838155267,"[7/7]

If this was a top-6, what technique/analysis/exploration would you add? üòä"
3476,@rasbt,2022-09-02 20:27:51+00:00,https://twitter.com/rasbt/status/1565798680816488451,"[6/7]
5) Plot at a confusion matrix

Similarly, I find it useful to look at confusion matrices. Sometimes interesting/weird pattern emerge, which often leads to interesting insights. https://t.co/MmiWnrKsb7"
3477,@rasbt,2022-09-02 20:27:50+00:00,https://twitter.com/rasbt/status/1565798679256207365,"[5/7]
4) Look at failure cases

It's always useful to check what cases the model gets wrong. Sometimes, there is something useful that can be learning from this analysis (incl. detecting mislabeled data)
A little utility function here: https://t.co/xWXYXkrQbV https://t.co/WVvmXJGk9M"
3478,@rasbt,2022-09-02 20:27:50+00:00,https://twitter.com/rasbt/status/1565798677230370818,"[4/7]
3) Compare accuracy to a zero-rule baseline

Here, I check that the validation accuracy is substantially better than a baseline based on always predicting the majority class (aka zero-rule classifier) https://t.co/7m52CFjOBk"
3479,@rasbt,2022-09-02 20:27:50+00:00,https://twitter.com/rasbt/status/1565798675586097154,"[3/7]

2) Check for overfitting

Another classic. We typically don't want the gap between training and validation accuracy to be too large (left: bad, right: better) https://t.co/XimXaga0Zt"
3480,@rasbt,2022-09-02 20:27:49+00:00,https://twitter.com/rasbt/status/1565798673820311562,"[2/7]

1) Making sure training loss converged
=&gt; that's a classic. We typically want to see that the loss plateaus
(Left: bad; right: better) https://t.co/0fswuYyizt"
3481,@rasbt,2022-09-02 20:27:49+00:00,https://twitter.com/rasbt/status/1565798671781961728,"My top 5 basic checks when training deep learning models

1) Make sure training loss converged
2) Check for overfitting
3) Compare accuracy to a zero-rule baseline
4) Look at failure cases
5) Plot at a confusion matrix

6) &lt;fill in the blank; what's your fav I am missing?&gt;

[1/7]"
3482,@rasbt,2022-09-02 19:13:58+00:00,https://twitter.com/rasbt/status/1565780090264461312,"@meickenberg @TylerJBurch @bernhardsson @mechcoder Thanks for sharing! It's also available through sklearn and works quite well (but still, I had better luck with regular randomized search).

https://t.co/ojiJTk8SwT

https://t.co/InT1IKjWTB"
3483,@rasbt,2022-09-02 18:15:07+00:00,https://twitter.com/rasbt/status/1565765279472386050,"@bernhardsson Actually, I remembered that I also have a few templates here if useful: https://t.co/gf7qzZ5BZc"
3484,@rasbt,2022-09-02 18:08:36+00:00,https://twitter.com/rasbt/status/1565763639608492032,"@bernhardsson I feel like scikit-learn is often underappreciated these days. 
It has a lot of nice, simple utilities that will come in handy in DL projects as well. E.g., you can just use the ParameterSampler for arbitrary contexts (like creating your python cmdline args or bash scripts) https://t.co/PTalES0Wwu"
3485,@rasbt,2022-09-02 17:57:31+00:00,https://twitter.com/rasbt/status/1565760848915750915,"@bernhardsson It really depends üòÖ. When it‚Äôs a conventional ML project I‚Äôd use the sklearn class. I also sometimes use it to create bash scripts for cluster submissions. I used optuna as well. Regarding script submission, when I use cloud resources https://t.co/ufnsjwGMZf has that built in"
3486,@rasbt,2022-09-02 17:52:47+00:00,https://twitter.com/rasbt/status/1565759658962440192,@bernhardsson Random search. Never had any luck with Bayesian opt. It‚Äôs also too slow because you can‚Äôt easily parallelize the runs. For small projects I would also use grid search.
3487,@rasbt,2022-09-02 16:19:51+00:00,https://twitter.com/rasbt/status/1565736269786877958,"@CSProfKGD ü§Ø

Haha, sorry, I don't want to ruin it for you, but macOS 13 (Ventura) will be released later this month üôÉ"
3488,@rasbt,2022-09-02 14:59:19+00:00,https://twitter.com/rasbt/status/1565716003459309568,@GaryMarcus Sidestepping peer-reviewing is not a solution either. It's complicated.
3489,@rasbt,2022-09-02 14:57:55+00:00,https://twitter.com/rasbt/status/1565715649749450753,"@GaryMarcus üíØ agree with you. I have been frustrated with  (and disillusioned by) the peer-review system since I started grad school. And it's only gotten worse. It's actually kind of why I am ""taking a break"" from reviewing. It's really due for an overhaul."
3490,@rasbt,2022-09-02 14:12:04+00:00,https://twitter.com/rasbt/status/1565704114243264512,"@GaryMarcus Similar issue with confidence intervals and hypothesis testing etc. Imho, the problem is maybe not the tool, maybe not the researchers, but the lack of a diverse set of peer-reviewers?"
3491,@rasbt,2022-09-02 13:34:06+00:00,https://twitter.com/rasbt/status/1565694558868045824,"As the semester is about to start and you are looking for new resources for your ML syllabus, here's an excellent list of resources on pressing ML topics:

- Interpretability &amp; Explainability 
- Fairness
- Adversarial ML
- Differential Privacy
- Causality

https://t.co/g21xwSlr54"
3492,@rasbt,2022-09-02 13:32:38+00:00,https://twitter.com/rasbt/status/1565694189626695680,@paul_rietschka Haha yes. I am so sorry but I never watched Star Trek. üò¨ü§´
3493,@rasbt,2022-09-02 12:37:48+00:00,https://twitter.com/rasbt/status/1565680390731350020,@JFPuget @MuzafferKal_ @scottlegrand https://t.co/nmjpuTUn7o
3494,@rasbt,2022-09-02 12:30:59+00:00,https://twitter.com/rasbt/status/1565678676062212096,"@aryan_raveshia @karpathy Phew, that doesn‚Äôt sound too bad then :)"
3495,@rasbt,2022-09-02 12:29:58+00:00,https://twitter.com/rasbt/status/1565678418116706306,"‚ÄúData! Data! Data! I cannot make bricks without clay‚Äù ‚Äî Sherlock Holmes (The Adventure of the Copper Beeches, 1892)"
3496,@rasbt,2022-09-02 11:13:57+00:00,https://twitter.com/rasbt/status/1565659286570733569,"@karpathy Hah, thanks for the warning. It‚Äôs kind of what I feared. Skipping this then. üòñ
Related topic: any comment on the GoT prequel?"
3497,@rasbt,2022-09-02 02:35:17+00:00,https://twitter.com/rasbt/status/1565528761331859456,"@k_saifullaah @amy_tabb One thing though: I would not expect to run serious DL models on the laptop. It‚Äôs a fast machine for everyday tasks, but for serious DL training you really need GPUs ‚Äî I don‚Äôt think this can be done on any laptop"
3498,@rasbt,2022-09-02 02:32:15+00:00,https://twitter.com/rasbt/status/1565527996798308352,"@k_saifullaah @amy_tabb For my scientific computing needs, I am also all set. It‚Äôs been at least half a year since I had issues with some library that wasn‚Äôt supported yet. Recently, it‚Äôs been all good for me."
3499,@rasbt,2022-09-02 02:30:53+00:00,https://twitter.com/rasbt/status/1565527654593445892,"@k_saifullaah @amy_tabb I have an M1 air (private) and M1 Pro (work); they are the best laptops I ever owned. Fast and great battery life. For PyTorch debugging, the CPU is already plenty fast, but Apple silicon (mps) support works pretty well now too."
3500,@rasbt,2022-09-02 01:48:39+00:00,https://twitter.com/rasbt/status/1565517023978872833,"@Plinz @DynamicWebPaige ‚ÄúAI wins state fair art contest, annoys humans‚Äù

When it came to Chess, Go, StarCraft II, and CASP, the press was a bit more enthusiastic üôÉ"
3501,@rasbt,2022-09-02 01:41:49+00:00,https://twitter.com/rasbt/status/1565515305731891200,"@CSProfKGD Ha yes, delegating 2.0 üòÜ"
3502,@rasbt,2022-09-02 01:40:38+00:00,https://twitter.com/rasbt/status/1565515009005916161,"@soumithchintala Ok, diffusion is a different beast, but for my recent small-scale projects, it‚Äôs been working like a charm (mostly)"
3503,@rasbt,2022-09-01 19:23:16+00:00,https://twitter.com/rasbt/status/1565420039834161155,"@chriswolfvision This will be a Turing test at its worst. The Turing test is already pretty flawed as a test because it‚Äôs super subjective. Well, and art ‚Ä¶"
3504,@rasbt,2022-09-01 17:51:03+00:00,https://twitter.com/rasbt/status/1565396835300216836,@soumithchintala Now it almost reads like Hooli Chat üëÄ
3505,@rasbt,2022-09-01 17:25:51+00:00,https://twitter.com/rasbt/status/1565390491084111872,"@sGx_tweets @LightningAI @PyTorch üíØ. Especially when using Dropout, BatchNorm etc!"
3506,@rasbt,2022-09-01 17:24:42+00:00,https://twitter.com/rasbt/status/1565390200838258689,"@francoisfleuret @rabinadk1 @LightningAI @PyTorch It's very similar to no_grad(), mainly disabling the gradient computation: https://t.co/QeSnZ419oD &amp; https://t.co/plMteIySNM"
3507,@rasbt,2022-09-01 16:31:17+00:00,https://twitter.com/rasbt/status/1565376759570305024,"@YassineAlouini @LightningAI @PyTorch On that note, inference_mode makes a lot of sense, but in practice, I haven't seen any noticeable difference. I.e., I'd say adopt inference_mode when you can, but no rush porting over old PyTorch code. Pls correct me if I'm wrong :P"
3508,@rasbt,2022-09-01 15:34:50+00:00,https://twitter.com/rasbt/status/1565362554637000710,"@tulkenss Stage 3: Automated stateful training.

Stage 4: Continual learning. In contrast to Stage 3, there is no fixed schedule. This requires a mechanism to trigger the update: Time-, performance-, volume-, or drift-based."
3509,@rasbt,2022-09-01 15:34:17+00:00,https://twitter.com/rasbt/status/1565362413964333056,"@tulkenss Stage 2: Automated retraining. Here, the focus is on maintaining and improving models"
3510,@rasbt,2022-09-01 15:34:01+00:00,https://twitter.com/rasbt/status/1565362349372055557,"@tulkenss Stage 1: Manual stateless retraining. The focus is on developing new models. So, updating models is low priority"
3511,@rasbt,2022-09-01 15:33:38+00:00,https://twitter.com/rasbt/status/1565362250810015744,"@tulkenss Thanks for sharing! I believe it's also depends on where the company is currently at in their cycle. 
E.g., also from the #MLSystemsBook: The 4 Stages of Continual Learning
1) Manual stateless retraining
2) Automated retraining
3) Automated stateful training
4) Continual learning"
3512,@rasbt,2022-09-01 15:30:37+00:00,https://twitter.com/rasbt/status/1565361491808636928,"@tomgoldsteincs A little bit late to the party, but this is an amazing thread üëå. üé© üé©off"
3513,@rasbt,2022-09-01 15:21:48+00:00,https://twitter.com/rasbt/status/1565359273416310785,"@LightningAI @PyTorch * alternatively, use the new 
`with torch.inference_mode()`
context."
3514,@rasbt,2022-09-01 15:21:15+00:00,https://twitter.com/rasbt/status/1565359135733997571,"@LightningAI @PyTorch Don't forget to disable gradient computation when evaluating your model or use it in practice! üòä

    for features, labels in dataloader:
        ...
        with torch. no_grad()*:
            logits = model(features)
        predictions = torch.argmax(logits, dim=1)"
3515,@rasbt,2022-09-01 13:02:19+00:00,https://twitter.com/rasbt/status/1565324172921823239,"@JFPuget @radekosmulski Whoa, just checking the rotten üçÖ rating and have no idea why I never heard of it before!"
3516,@rasbt,2022-09-01 12:58:42+00:00,https://twitter.com/rasbt/status/1565323259662389250,@roydanroy Detecting sarcasm is an open research problem
3517,@rasbt,2022-09-01 12:19:46+00:00,https://twitter.com/rasbt/status/1565313463227977729,"What's the difference between stateful and stateless training? Imagine a data stream. 
*Stateless* training retrains the model periodically (top). 
*Stateful* training updates the model using new batches of the data stream (bottom).

(my sketch is based on the #MLSystemsBook) https://t.co/5RHf0WmElX"
3518,@rasbt,2022-09-01 12:13:29+00:00,https://twitter.com/rasbt/status/1565311884395532289,"Stateful vs Stateless training? I heard most (?) companies stick with stateless training to avoid issues like catastrophic forgetting. Interesting counter example by Alex Egg (https://t.co/Ecvt902NJH). 
At Grubhub, stateful training resulted in 45x savings &amp; +20% metrics increase"
3519,@rasbt,2022-09-01 01:25:22+00:00,https://twitter.com/rasbt/status/1565148776616103936,@Cyrul1k üíØüëç
3520,@rasbt,2022-08-31 21:18:08+00:00,https://twitter.com/rasbt/status/1565086560495845379,@paul_rietschka they are not even on my syllabus üòÜ
3521,@rasbt,2022-08-31 20:27:29+00:00,https://twitter.com/rasbt/status/1565073812986675201,"@willigo09 @andrewgwils I actually worked on a research project once where we generated protein sequences with VAEs. This was pre-LLM. Didn't work that well. LSTMs were much better. We did also something similar for tabular datasets. But no, I don't think I can / want to share that haha"
3522,@rasbt,2022-08-31 20:20:43+00:00,https://twitter.com/rasbt/status/1565072112641085440,"@ralphbrooks Haha wow, mythbuster vibes here. Your answers are üëå"
3523,@rasbt,2022-08-31 20:16:35+00:00,https://twitter.com/rasbt/status/1565071068620115968,"@willigo09 @andrewgwils I actually still use RFs a lot -- they are a good, simple performance baseline. Regarding feature importances, I usually use a model agnostic permutation importance (to get model-specific importances). Figures show that for RF both methods are very similar https://t.co/5fyL81kL1o"
3524,@rasbt,2022-08-31 20:07:42+00:00,https://twitter.com/rasbt/status/1565068834775629832,"Exciting release! If you are like me &amp; prototype in Jupyter notebooks A LOT, you will also like the 
üî•Distributed Data Parallel support in Jupyter notebooks!üî•

trainer = pl.Trainer(accelerator=""gpu"", devices=2, strategy=""ddp_notebook"") üöÄ"
3525,@rasbt,2022-08-31 20:00:02+00:00,https://twitter.com/rasbt/status/1565066905588752386,"@andrewgwils Fair*. I was thinking about RBF kernel SVMs and the likes, which were (still) all the rage 8 years ago. And random forests were the hot new thing.

(*BayesOpt for hyperparameter tuning never really worked well for me, at this point I have given up on it. Too slow anyways)"
3526,@rasbt,2022-08-31 19:56:15+00:00,https://twitter.com/rasbt/status/1565065955625123841,"@marc_lelarge Fun fact: even today, ""The key differences between Python 2.7.x and Python 3.x with examples"" is one of my most frequently blog articles üòõ

https://t.co/Qg0NceykEy https://t.co/LN6KGVSyNi"
3527,@rasbt,2022-08-31 18:50:41+00:00,https://twitter.com/rasbt/status/1565049453098274817,"It's ~8 years for me too! Out of the 8 things that are/were popular,
4 stood the test of time (so far) ...
and 4 did not üî•-- can you guess which? üòÜ

1. XGBoost
2. Latent Dirichlet allocation
3. Jupyter notebooks
4. GANs
5. PyTorch
6. Scikit-learn
7. Kernel methods
8. Python 2.7"
3528,@rasbt,2022-08-31 15:54:25+00:00,https://twitter.com/rasbt/status/1565005094864699392,"@unsorsodicorda *""found"" as in founding/being a founder, or creating, lol"
3529,@rasbt,2022-08-31 15:52:37+00:00,https://twitter.com/rasbt/status/1565004642827878402,"@nmvrodrigues @tunguz This way, it's not just about the ""theoretical"" numbers but also how feasible the method is (do I have difficulties running it myself? Is it hard for me to find the ""best"" hyperparams?)"
3530,@rasbt,2022-08-31 15:51:02+00:00,https://twitter.com/rasbt/status/1565004242292801538,"@nmvrodrigues @tunguz Fair point. No guarantee. Personally, I don't put too much weight ""on the numbers"" in papers anymore. I read them because I am interested in the methodology, and then I will try them in my own projects to find out whether they are worthwhile."
3531,@rasbt,2022-08-31 14:40:45+00:00,https://twitter.com/rasbt/status/1564986557207019522,"How could I totally forget to add the Arxiv link üòÜ
https://t.co/HrguYMLhFs"
3532,@rasbt,2022-08-31 14:24:49+00:00,https://twitter.com/rasbt/status/1564982545921581059,"@unsorsodicorda Trying not to spoil it too much, its about two childhood friends who found a video game company. It's an interesting story following the ups and downs with lots of video game references in there"
3533,@rasbt,2022-08-31 14:23:19+00:00,https://twitter.com/rasbt/status/1564982169130385408,"[9/9] What's kind of interesting is that they say they didn't do hyperparameter tuning on DANet (but for all other methods). This kind of implies that DANet might be something that is easy (/easier) to use in practice? Anyways, their source code is here: https://t.co/JpVbHAhZ10"
3534,@rasbt,2022-08-31 14:23:19+00:00,https://twitter.com/rasbt/status/1564982167444361219,"[8/9] Finally, how well does DANet perform compared to other methods? Well, it seems that in 4 out of 7 cases it's the best method on the respective datasets.* https://t.co/SrwSai8CW1"
3535,@rasbt,2022-08-31 14:23:18+00:00,https://twitter.com/rasbt/status/1564982165896679425,"[7/9] More interestingly, can the masks actually group correlated features? The answer is also (somewhat) yes! (Note that there are two rows because they used to parallel masks; this is analogous to convolution channels) https://t.co/sHvITFZtUu"
3536,@rasbt,2022-08-31 14:23:18+00:00,https://twitter.com/rasbt/status/1564982164478984192,"[6/9] What about the masks, do they actually work? I.e., can the masks distinguish between target-relevant and target-irrelevant features? Based on this experiment with synthetic data, the answer is yes! https://t.co/rMpsWIqEXe"
3537,@rasbt,2022-08-31 14:23:18+00:00,https://twitter.com/rasbt/status/1564982162805428225,"[5/9] Does this shortcut actually help? Yes, and apparently it works better than ResNet- or DenseNet-style shortcuts here. https://t.co/mhFdEWTXfL"
3538,@rasbt,2022-08-31 14:23:17+00:00,https://twitter.com/rasbt/status/1564982161446506497,[4/9] Another little detail is that the blocks have shortcut connections adding back the raw features. This is different from the shortcuts in ResNet -- ResNet adds the previous layer's features whereas here the shortcut always adds the *raw* feature values. https://t.co/n29Weki0KU
3539,@rasbt,2022-08-31 14:23:17+00:00,https://twitter.com/rasbt/status/1564982160142090241,[3/9] The feature selection (step 1) groups correlated features using a sparse learnable mask (they use Entmax -- analogous to Softmax but sparsity inducing). The feature abstraction (step 2) is using a fully connected layer with attention (not shown) on the selected features. https://t.co/v5PlLuhF6o
3540,@rasbt,2022-08-31 14:23:17+00:00,https://twitter.com/rasbt/status/1564982158476845056,[2/9] The main idea behind DANets is to introduce an Abstract Layer (ABSTLAY) building block; multiple such blocks are then stacked to form a DANet. What does ABSTLAY do? It performs two steps: 1) feature selection and 2) feature abstraction. https://t.co/yqmjcuBSXz
3541,@rasbt,2022-08-31 14:23:16+00:00,https://twitter.com/rasbt/status/1564982156887310339,"Just added another paper to the ""tabular deep learning"" list -- intend to keep it up to date, and I previously missed DANets! DANets are centered around finding and grouping correlated features [right] -- something we usually would do manually [left]. How does that work? [1/9] https://t.co/djJ5mAmFGw"
3542,@rasbt,2022-08-31 13:17:08+00:00,https://twitter.com/rasbt/status/1564965510818717697,"@marktenenholtz Wow, thanks for the praise üôèüòÖ"
3543,@rasbt,2022-08-31 13:14:03+00:00,https://twitter.com/rasbt/status/1564964735736598529,"@abdulaziz_asz Huh, yeah, this hasn't occurred to me, yet. Quantification is quite a broad term to refer to the ""relative frequency of each class in the unlabelled data"". Thanks for the pointer!"
3544,@rasbt,2022-08-31 13:10:13+00:00,https://twitter.com/rasbt/status/1564963771923283968,"@sdztudhsh @maccaw Absolutely agree. I can totally see why artists are worried. I am thinking that this sort of tech progress is kind of inevitable though -- now that it's out, it's hard to roll it back. So, I am mainly wondering how artists could somehow adopt/benefit from this. It's tough."
3545,@rasbt,2022-08-31 13:07:39+00:00,https://twitter.com/rasbt/status/1564963125195165696,"A rare non-textbook recommendation: Tomorrow and Tomorrow and Tomorrow by Gabrielle Zevin.
Recently got it at the airport as my vacation read. üèñÔ∏èüìñ
Enjoyed it thoroughly! Maybe the best book I read in years.
üëçüëçüëç  Strong recommendation if you are into video games &amp; start-ups! https://t.co/Sr3NK5jW6P"
3546,@rasbt,2022-08-31 13:00:48+00:00,https://twitter.com/rasbt/status/1564961402485411842,"Another relatively popular tool I forgot:
https://t.co/OjzDTsF6mB"
3547,@rasbt,2022-08-30 21:56:47+00:00,https://twitter.com/rasbt/status/1564733897958727680,"@tdietterich @zacharylipton Wow thanks, I had no idea!"
3548,@rasbt,2022-08-30 19:10:54+00:00,https://twitter.com/rasbt/status/1564692153896505350,"@tdietterich @zacharylipton I should have called it ""suggestion"" üòÖ. Yeah, I thought that this was one of these older ideas that's often used in the real-world but doesn't have an official reference. I think I first heard about it in the context of anomaly detection back when I was a student."
3549,@rasbt,2022-08-30 17:00:26+00:00,https://twitter.com/rasbt/status/1564659319181828097,@pwang @LightningAI :)
3550,@rasbt,2022-08-30 16:20:13+00:00,https://twitter.com/rasbt/status/1564649197546110976,"@seanmylaw @zacharylipton @tdietterich @predict_addict Interesting. I think this is somewhat analogous to the idea of doing a hypothesis test (e.g., KS) on the probability scores (for the reference vs streaming window)."
3551,@rasbt,2022-08-30 14:42:57+00:00,https://twitter.com/rasbt/status/1564624722230403083,"@srchvrs Hmmm. Based on their write-up it seems like they are referring to nodes. However, the p3.16xlarge is a 8-GPU instance.  Not sure about how their instances work internally, but maybe their ml.p3.16xlarge multi-GPU instance involves multiple nodes ü§î"
3552,@rasbt,2022-08-30 14:02:04+00:00,https://twitter.com/rasbt/status/1564614434345082892,"If you are using AWS SageMaker, you can now get an almost linear training speed-up (wrt the number of instances) using PyTorch Lightning with DDP üëå
https://t.co/A5wENaLyk8

Experiments via a ml.p3.16xlarge SageMaker training instances: https://t.co/Qc7spIwwk6"
3553,@rasbt,2022-08-30 13:50:08+00:00,https://twitter.com/rasbt/status/1564611430741164040,"@JFPuget @MaartenvSmeden *I developed that view later ... in fact, I began thinking of logistic regression as ML when I compared it to perceptrons (both can be viewed as single layer neural nets) and AI when I learned about multilayer perceptrons."
3554,@rasbt,2022-08-30 13:48:30+00:00,https://twitter.com/rasbt/status/1564611019040858115,"@JFPuget @MaartenvSmeden [2/2] In addition, my first encounters with ...
- logistic regression was in a statistics class,
- naive Bayes and Bayesian networks was in a statistical pattern rec class
- Decision trees was in a data mining class

At first, I didn't associate it with ML or AI. üòÖ"
3555,@rasbt,2022-08-30 13:46:14+00:00,https://twitter.com/rasbt/status/1564610449718804490,"@JFPuget @MaartenvSmeden Actually, thinking about this more, I fell afoul of Larry Tesler's AI effect: ""AI is whatever hasn't been done yet."" 
In other words, if something appears trivial &amp; common we don‚Äôt call it AI anymore.
[1/2]"
3556,@rasbt,2022-08-30 13:43:11+00:00,https://twitter.com/rasbt/status/1564609680046972929,"""AI is whatever hasn't been done yet.""  ü§î
-- Larry Tesler's AI Effect"
3557,@rasbt,2022-08-30 13:36:15+00:00,https://twitter.com/rasbt/status/1564607935518593031,"@ammaryh92 @arnaudvl3 @zacharylipton @tdietterich Thx, @arnaudvl3, you summarized it nicely already ‚ò∫Ô∏è. To summarize
1) Covariate shift: P(x) changes but P(y|x) remains unchanged
2) Concept drift: P(y|x) changes but P(x) remains unchanged

Bonus:
3) Label shift: P(y) changes but P(x) remains unchanged"
3558,@rasbt,2022-08-30 12:44:25+00:00,https://twitter.com/rasbt/status/1564594893351174145,"@gurdeep101 @_willfalcon Yes! Thx! On that note (""unit tests for data""), two cool tools/libraries I stumbled upon recently:

- Great expectations, https://t.co/8jBF8npITS
- Deequ, https://t.co/R1PrHH6eVc"
3559,@rasbt,2022-08-30 12:43:41+00:00,https://twitter.com/rasbt/status/1564594707702898690,"@ElisonSherton @_willfalcon I'd say it's a general foundation for many subjects and courses that involve data science, programming, and machine learning. 
(Btw. we have something cool in the works, and I'd recommend to stay tuned; in the mean time, I have  courses on ML and DL here: https://t.co/OcL9XWoNIV)"
3560,@rasbt,2022-08-30 12:39:42+00:00,https://twitter.com/rasbt/status/1564593704999976960,"[3/3] ... I'd recommend browsing through the TOCs of the two most common tools for concept drift detection

- TorchDrift: https://t.co/m7Xjr1fxy3
- Alibi-detect: https://t.co/tkYUkBV5zY"
3561,@rasbt,2022-08-30 12:39:42+00:00,https://twitter.com/rasbt/status/1564593703779459072,"[2/3] Another common one: Bu et al's least squares density-difference estimation https://t.co/1dXHv2OGGr

Interested in more? ..."
3562,@rasbt,2022-08-30 12:39:41+00:00,https://twitter.com/rasbt/status/1564593702093430784,"There are many additional methods for concept drift detection. To highlight a few next to the statistical tests mentioned yesterday:
- @zacharylipton et al's black box shift estimation: https://t.co/tLCgIJW8mg
- @tdietterich's idea to use an old-vs-new classifier
[1/3]"
3563,@rasbt,2022-08-29 19:57:44+00:00,https://twitter.com/rasbt/status/1564341549571391493,"If you are in a computation-related field like 
- CS
- machine learning
- electrical engineering
- statistics
- data science
- bioinformatics
- ...
and I had to recommend 1 thing, it's 

*Start using Git &amp; GitHub as soon as possible, collaborate, and put your projects out there.*"
3564,@rasbt,2022-08-29 19:51:22+00:00,https://twitter.com/rasbt/status/1564339949750583303,"Fall semester is about to start next week! üéâ

üí°A recommended last-minute prep? Learn about essential computing tools that can make you more productive! 

üçø @_willfalcon &amp; I put together 10 short videos, from using the terminal to code collaboration:
https://t.co/6MQKcjXU2z"
3565,@rasbt,2022-08-29 18:50:17+00:00,https://twitter.com/rasbt/status/1564324577110593539,"@ID_AA_Carmack Hah. I was just visiting my parents for two weeks, and surprise, surprise, my 21-year-old GameBoy Advance still worked like a charm thanks to replaceable batteries üòÅ 
(Even if batteries had a ten-year lifespan, a GameBoy Advance SP would have been dead üôÉ)"
3566,@rasbt,2022-08-29 18:39:01+00:00,https://twitter.com/rasbt/status/1564321740297314308,@austinreynolds @chrisalbon It's specifically Germany. The rest of the EU is way more modern. I used my credit card for everything when I went to Poland in 2019 or Italy earlier this year.
3567,@rasbt,2022-08-29 17:47:03+00:00,https://twitter.com/rasbt/status/1564308662927114242,@francoisfleuret Is it fine for a human to look at / learn from / get inspired by content that is not under a license that allows it explicitly? üôÉ
3568,@rasbt,2022-08-29 17:41:25+00:00,https://twitter.com/rasbt/status/1564307247425097728,"@chrisalbon Just got back from Germany yesterday. Nothing really üòÖ. Have fun! üòä

(PS: airline asked US citizens for vacc records back and forth; but we think it was because of the Amsterdam layover)"
3569,@rasbt,2022-08-29 17:01:34+00:00,https://twitter.com/rasbt/status/1564297219326500866,"@PetervanderP Yes, you can have a parallel model that keeps updating as new data arrives. At certain intervals, you can then compare the updated model to the ""old"" model and make the swap if the performance is better on recent data. But yeah, the problem is your streaming data requires labels"
3570,@rasbt,2022-08-29 16:49:33+00:00,https://twitter.com/rasbt/status/1564294193920483328,@WiImerarturo @Kasparov63 Agreed. I wonder though how artists can incorporate AI into their process. Similar to how photographers nowadays incorporate digital tools in their workflow. Another example is movie directors and CGI.
3571,@rasbt,2022-08-29 16:10:51+00:00,https://twitter.com/rasbt/status/1564284453983293441,"Makes me think of @Kasparov63's ""Deep Thinking"" on Deep Blue &amp; how AI transformed chess.

Chess engines haven't replaced human players; top players now heavily rely on chess engines in their preparation, resulting in record performances.

What would an artist/AI collab look like?"
3572,@rasbt,2022-08-29 13:45:54+00:00,https://twitter.com/rasbt/status/1564247975144337408,"@MontePhD It depends on the problem, model, and data. It's basically part of the experiment &amp; analysis pipeline to figure out whether retraining on all data with a weighting scheme or just training on recent data is better."
3573,@rasbt,2022-08-29 13:40:29+00:00,https://twitter.com/rasbt/status/1564246613786300416,"@JFPuget It's more extreme than that: there are many variants, but you'd essentially skip food for at least 1 entire day. As an experiment, I did that ~10 years ago in college for about a year. Wasn't too bad but also not sustainable."
3574,@rasbt,2022-08-29 13:35:38+00:00,https://twitter.com/rasbt/status/1564245394011348992,"@CSProfKGD And yet, sadly, I wouldn't be surprised if it's less than 10% of the cost of DALL¬∑E or Imagen üòÖ"
3575,@rasbt,2022-08-29 13:32:25+00:00,https://twitter.com/rasbt/status/1564244582933618689,"@RDub2 It depends on the problem you are working on. Netflix, Uber, Tesla, etc have to retrain/optimize models on a daily basis. It's necessary."
3576,@rasbt,2022-08-29 13:29:28+00:00,https://twitter.com/rasbt/status/1564243842014093312,@aertherks Do I understand this correctly: train 2 NNs (identical architecture) on the the same training set; the difference between them would be a proxy for how much the model would suffer from concept drift in the future? ü§î
3577,@rasbt,2022-08-29 13:26:40+00:00,https://twitter.com/rasbt/status/1564243135504568322,@ThomasViehmann @PyTorch @orobix I had no idea this existed! Thanks for sharing!
3578,@rasbt,2022-08-29 13:24:20+00:00,https://twitter.com/rasbt/status/1564242546817220608,"@arnaudvl3 @DanielCanueto Nice, thanks! I assume it's already available via alibi-detect?"
3579,@rasbt,2022-08-29 13:22:55+00:00,https://twitter.com/rasbt/status/1564242194160025600,@Sam_Tracey76 @alfcnz Oops üòÇ
3580,@rasbt,2022-08-29 13:22:01+00:00,https://twitter.com/rasbt/status/1564241965541167104,"@tdietterich Ahh, I misread! I see what you mean now! Yeah, that's a good approach as well. Afaik, something similar is often  used for out-of-distribution detection as well."
3581,@rasbt,2022-08-29 13:19:15+00:00,https://twitter.com/rasbt/status/1564241270750461953,"@alfcnz Ahh, sorry, I forgot that there is 1 dark mode user üòÖüò¨üòÜ"
3582,@rasbt,2022-08-28 22:08:17+00:00,https://twitter.com/rasbt/status/1564012017425567747,"@tdietterich That's a good idea. I think the limitation with that though, in many production settings, is to get the labels for the recent data"
3583,@rasbt,2022-08-28 21:40:22+00:00,https://twitter.com/rasbt/status/1564004990599004164,"@JulienMouchnino @svpino Another recent, related thread: https://t.co/DCrVGD2Vhr"
3584,@rasbt,2022-08-28 21:34:53+00:00,https://twitter.com/rasbt/status/1564003610589073408,"[10/10] 4. Detect change in margin density of response distribution using a learned threshold.
This combines the previous two methods, but involves a threshold. Due to the k-fold procedure, it's a bit more involved to fit it into a tweet"
3585,@rasbt,2022-08-28 21:34:52+00:00,https://twitter.com/rasbt/status/1564003609469243395,"[9/10] 3. Statistical test for change in margin density of response variable
Similar to the approach above, except that we focus on a smaller window (margin) instead of looking at the whole distribution https://t.co/0vS6uFEgH8"
3586,@rasbt,2022-08-28 21:34:52+00:00,https://twitter.com/rasbt/status/1564003607732977664,"[8/10] 2. Statistical test for change in response variable
Similar as above, but here we apply the classifier to the data from a reference window and the recent data from a data stream and look at the predicted scores / probabilities https://t.co/jmcqr91VUf"
3587,@rasbt,2022-08-28 21:34:52+00:00,https://twitter.com/rasbt/status/1564003605572730885,"[7/10] 1. Statistical test for change in feature space
This is essentially classic hypothesus testing, checking whether two distributions are the same. E.g., using a Kolmogorov-Smirnov (KS) test for continuous features or a Chi-squared test for categorical features https://t.co/9F5m8l236W"
3588,@rasbt,2022-08-28 21:34:51+00:00,https://twitter.com/rasbt/status/1564003603719016448,[6/10] The article mentioned above at https://t.co/3IYhnFVSn1 focuses on techniques that do not require labeled data. Below is a summary ...
3589,@rasbt,2022-08-28 21:34:51+00:00,https://twitter.com/rasbt/status/1564003602544599040,"[5/10] Now, the easiest way to detect concept drift (which requires retraining) is to monitor a performance metric (like accuracy). However, this is often not feasible as it requires labeled data."
3590,@rasbt,2022-08-28 21:34:50+00:00,https://twitter.com/rasbt/status/1564003601248305153,"[4/10] In ""real"" concept drift, the conditional label distribution p(class | feature). If this happens, there is usually no way around retraining your model: https://t.co/4VLpTrxKHB"
3591,@rasbt,2022-08-28 21:34:50+00:00,https://twitter.com/rasbt/status/1564003600002588672,"[3/10] In a nutshell, feature drift describes the change in the input feature distribution over time. In rare cases, this is not harmful (subpanel to the right), but in most cases, it will require retraining the model (subpanel in the center) https://t.co/ZFoya8ENKR"
3592,@rasbt,2022-08-28 21:34:50+00:00,https://twitter.com/rasbt/status/1564003599021182979,"[2/10] There are two main flavors of concept drift: feature drift and ""real"" concept drift. 
There's an excellent article  here that illustrates this in more detail: https://t.co/3IYhnFVkxt"
3593,@rasbt,2022-08-28 21:34:50+00:00,https://twitter.com/rasbt/status/1564003597355991041,"In practice, a trained machine learning model is never final -- concept drift will inevitably cause a performance decline of a production model over time. [1/10] https://t.co/0mwmc4ODpw"
3594,@rasbt,2022-08-28 20:34:11+00:00,https://twitter.com/rasbt/status/1563988336162783244,@JulienMouchnino @svpino Here is one of our many discussions on that topic üòÜ
3595,@rasbt,2022-08-27 08:12:31+00:00,https://twitter.com/rasbt/status/1563439300674326528,"This. 
‚†Ω‚°ùCompression is essentially about identifying redundancies -- in other words, it's about finding patterns. ‚†∑‚°ü
And the identification of patterns requires some sort of intelligence. 
Btw (artificial) intelligence also doesn't imply that it's machine / deep learning"
3596,@rasbt,2022-08-26 15:17:14+00:00,https://twitter.com/rasbt/status/1563183795578486787,"@thegautamkamath A decent chunk. Maybe 40%. All papers that contribute (1) new ideas, (2) don‚Äôt make false novelty claims, and (3) are technically correct. 

If authors new that there is no acceptance percentage, they would probably write fewer papers that are bad wrt (2)."
3597,@rasbt,2022-08-26 14:54:56+00:00,https://twitter.com/rasbt/status/1563178183821668352,"@francoisfleuret @CSProfKGD Yeah, would also need to know the hardware and drivers etc. wrt determinism."
3598,@rasbt,2022-08-26 14:05:24+00:00,https://twitter.com/rasbt/status/1563165720027865089,"@random_walker Nah, but the roles will change. I predict that the radiologists will be the ones training AI systems on radiology data in a few years"
3599,@rasbt,2022-08-26 13:58:15+00:00,https://twitter.com/rasbt/status/1563163920503676931,@beenwrekt For 99% of biomed journals you could upload your article to arxiv. Restriction is that it can‚Äôt have the final layout that the publisher applied. ML journals usually don‚Äôt layout articles for you (you use a template) so it‚Äôs not that different. But yeah I hate the ‚Äúpay for OA‚Äù
3600,@rasbt,2022-08-26 13:54:12+00:00,https://twitter.com/rasbt/status/1563162901204336641,"@awgaffney Isn‚Äôt it the opposite? The ‚Äúpay for open-access‚Äù already exists and is somewhat widespread. Per this order, authors will be allowed to upload articles to open-access archives like PubMed irregardless of the journal publication mode (and ignoring the 12 month embargo)"
3601,@rasbt,2022-08-25 11:58:23+00:00,https://twitter.com/rasbt/status/1562771366642073601,"@alfcnz @jon_barron Yeah, and the older I get the more I find it weird how we spend our time arguing about terminology and putting things into buckets. I think the ML field has shown that you can still get lots of things done when you reinvent and mislabel things üòú"
3602,@rasbt,2022-08-25 11:56:13+00:00,https://twitter.com/rasbt/status/1562770823894552582,"@dsc_lutz I mean there is no free lunch, there are so many different problem cases and contexts. That‚Äôs why there are so many algorithms that followed linear and logistic regression, and people don‚Äôt stop creating new ones"
3603,@rasbt,2022-08-24 08:43:45+00:00,https://twitter.com/rasbt/status/1562359997362831360,"@BenVanCalster @Richard_D_Riley But honestly, I would just calibrate the model. E.g. use CalibratedClassifierCV with Platt scaling. It's something you can do independently of the model fitting, which is why I mentioned that it's a separate problem."
3604,@rasbt,2022-08-24 08:42:00+00:00,https://twitter.com/rasbt/status/1562359559351664640,@BenVanCalster @Richard_D_Riley It depends on the majority voting approach. If you use hard labels (the actual class labels) over soft labels (probabilities / scores) then calibration doesn't matter.
3605,@rasbt,2022-08-24 08:39:57+00:00,https://twitter.com/rasbt/status/1562359040000331776,@HamelHusain üòÖ
3606,@rasbt,2022-08-24 08:38:34+00:00,https://twitter.com/rasbt/status/1562358692300963840,@JulienMouchnino I have a video explaining recursive feature selection (RFE) here: https://t.co/klbeCSqX2p
3607,@rasbt,2022-08-24 08:37:13+00:00,https://twitter.com/rasbt/status/1562358353631887360,"@leonpalafox @ZetaOf1 Yes, I think it is for sure less prone to overfitting due to the additional randomness in RF that makes the trees less correlated. (That's according the original formula in Breiman's paper). But I am not aware of a paper including gradient boosting"
3608,@rasbt,2022-08-24 08:34:48+00:00,https://twitter.com/rasbt/status/1562357747840172032,"@vidalthi @GioeleLaManno Very interesting, thanks! Bookmarked!"
3609,@rasbt,2022-08-24 08:33:56+00:00,https://twitter.com/rasbt/status/1562357529828524032,"@Artekkersz Yeah, I agree. There is no one-size-fits all approach across all applications and datasets. It would be interesting to follow up on this analysis and see how close you can get to the results by using cheaper univariate feature selection techniques."
3610,@rasbt,2022-08-24 08:29:34+00:00,https://twitter.com/rasbt/status/1562356426953134080,"@JagersbergKnut Imho, RF is so easy to apply these days that I'd say always consider both baselines, logistic regression and RF. Comparing these will also give you (some) insights into whether you are dealing with a linear / nonlinear problem."
3611,@rasbt,2022-08-24 08:27:24+00:00,https://twitter.com/rasbt/status/1562355883539038208,"@dsc_lutz Thanks for the note. I'd say that's probably an issue with ML in general. Curious, what do you do in those cases, use heuristics instead of ML?"
3612,@rasbt,2022-08-23 14:25:33+00:00,https://twitter.com/rasbt/status/1562083626782806020,"@KirovDoc Sorry, I am not an R user. In sklearn you can use https://t.co/P2wL33EHX6"
3613,@rasbt,2022-08-23 14:05:36+00:00,https://twitter.com/rasbt/status/1562078607505235969,@bhutanisanyam1 @ph_singer @h2oai Impressive record @ph_singer üëå. Looking forward to a Kaggle/practical tips and advice book from you one day!
3614,@rasbt,2022-08-23 13:52:48+00:00,https://twitter.com/rasbt/status/1562075385612963844,"@vykthur For deployment, you might like hummingbird, which decomposes the RF into matrix multiplications (using PyTorch) https://t.co/cmDYE1pbER"
3615,@rasbt,2022-08-23 13:43:25+00:00,https://twitter.com/rasbt/status/1562073023058006018,@paul_rietschka @mark_l_watson Because life would be boring otherwise
3616,@rasbt,2022-08-23 13:40:37+00:00,https://twitter.com/rasbt/status/1562072321141231616,"@therriaultphd As shown in the figure above, RF has probably the smallest slope (besides SAINT maybe, but that one doesn‚Äôt have a good performance to begin with)"
3617,@rasbt,2022-08-23 13:38:44+00:00,https://twitter.com/rasbt/status/1562071844869574656,"@TheFucking22 No, that‚Äôs not what I mean. I mean that it has good out of the box performance compared to other methods"
3618,@rasbt,2022-08-23 13:38:06+00:00,https://twitter.com/rasbt/status/1562071685519613953,"@therriaultphd Haha no, we are talking about good out-of-the-box performance. Of course you may want to tune your random forest at some point if you want to use it for anything but a baseline"
3619,@rasbt,2022-08-23 13:12:19+00:00,https://twitter.com/rasbt/status/1562065196155392000,"@statsepi @Georg__Heinze @Richard_D_Riley Sure, for some applications it‚Äôs useful, but there is CalibratedCVClassifier ü§∑‚Äç‚ôÇÔ∏è  https://t.co/P2wL33EHX6"
3620,@rasbt,2022-08-23 12:57:36+00:00,https://twitter.com/rasbt/status/1562061492295540738,"@imogenispuzzle I remember seeing a bunch of implementations and papers, eg https://t.co/F4teb16oc9"
3621,@rasbt,2022-08-23 12:54:53+00:00,https://twitter.com/rasbt/status/1562060812189048833,"@mark_l_watson Actually, I am not saying that using a baseline implies that you shouldn‚Äôt try other methods üòÖ"
3622,@rasbt,2022-08-23 12:44:53+00:00,https://twitter.com/rasbt/status/1562058292817428480,"@Richard_D_Riley Hm yeah, but classifier calibration is a separate problem"
3623,@rasbt,2022-08-23 12:43:20+00:00,https://twitter.com/rasbt/status/1562057905439916032,@agrover112 Yes. Apparently from the current default to 1.0 (100% of the features; like bagging)
3624,@rasbt,2022-08-23 11:38:33+00:00,https://twitter.com/rasbt/status/1562041600154427392,"@DrGroftehauge Oh, you mean using the synthetic datasets for this figure? Yeah, that would be useful, I agree. I think the author wanted to also look at real-world datasets. Here's a figure with the artificial-noise dataset: https://t.co/OboVHF7A6y"
3625,@rasbt,2022-08-23 11:29:54+00:00,https://twitter.com/rasbt/status/1562039423633596416,"@kahachoevan @ZetaOf1 I mean, everyone exaggerates a bit in their papers üòÜ"
3626,@rasbt,2022-08-23 11:27:28+00:00,https://twitter.com/rasbt/status/1562038811730841603,"@DrGroftehauge The features are noisy. In this case, either the internal or external feature selection would ignore the noise features."
3627,@rasbt,2022-08-23 11:26:36+00:00,https://twitter.com/rasbt/status/1562038591404101632,"@eskayML Personally, I like permutation-based importance evaluation: https://t.co/5fyL81kL1o"
3628,@rasbt,2022-08-23 11:25:45+00:00,https://twitter.com/rasbt/status/1562038380963184640,"@ogrisel @AlistairHaimes Hm yeah, there's never a one-size-fits all solution. Honestly, this max_features=1.0 is very misleading/confusing though. Sorry, not a fan ü´§"
3629,@rasbt,2022-08-23 11:20:47+00:00,https://twitter.com/rasbt/status/1562037130800644096,Tagging @GertjanVerhoev1 who wrote this excellent article
3630,@rasbt,2022-08-23 11:19:16+00:00,https://twitter.com/rasbt/status/1562036745612533764,"@prit_chak Ahhh, yes, of course. Number of trees at each node doesn't make sense, haha"
3631,@rasbt,2022-08-23 11:19:11+00:00,https://twitter.com/rasbt/status/1562036725911781377,"*I meant number of ""features"" not ""trees"" per node of course üòÖ"
3632,@rasbt,2022-08-23 11:17:54+00:00,https://twitter.com/rasbt/status/1562036405534167040,"@ShoaibAshraf83 In a sense, you have a ""population"" of trees, but other than that, RF are totally different from genetic algorithms. I have an explanation here: https://t.co/BByCLfXYyG"
3633,@rasbt,2022-08-23 11:16:38+00:00,https://twitter.com/rasbt/status/1562036086452486145,"@parker_brydon Yes, that's why I would usually do both logistic regression (because it's a linear model) and RF (because it's not a linear model)"
3634,@rasbt,2022-08-23 09:23:27+00:00,https://twitter.com/rasbt/status/1562007601348485121,"@tianbao_li In my experience gradient boosting algos (XGboost etc.) require more hparam tuning to get good performance out of them. However, according to https://t.co/qqOGJsfCsN, it's apparently not true anymore and the defaults work often fine, too https://t.co/6xbqZ9TLmJ"
3635,@rasbt,2022-08-23 09:17:17+00:00,https://twitter.com/rasbt/status/1562006050965954561,"@_joaogui1 Agreed! I think in many industry settings, the concern is more on the i Terence performance though; also, I‚Äôd you already have a bunch of models from hparam tuning anyway, this paper suggests that combining them via averaging might be a good idea"
3636,@rasbt,2022-08-23 08:31:44+00:00,https://twitter.com/rasbt/status/1561994588314820608,@Plinz @ai__pub @tdietterich That's actually a really good one üëå. Also allows moving goalposts when needed.
3637,@rasbt,2022-08-23 08:26:34+00:00,https://twitter.com/rasbt/status/1561993287149436929,"@AlistairHaimes Top off my head, I think Breiman had some theoretical justification for this. Roughly, it's to make the individual trees more uncorrelated (than bagging) but still have good performance. Have a short discussion about the trade-off here at min 20:42 (https://t.co/BByCLfXYyG)"
3638,@rasbt,2022-08-23 07:54:22+00:00,https://twitter.com/rasbt/status/1561985183229812737,"@paul_rietschka Actually, I didn't. So for regression, RF in sklearn defaults to bagging? Interesting ü§î"
3639,@rasbt,2022-08-23 07:49:40+00:00,https://twitter.com/rasbt/status/1561983999261773824,"@alfcnz @jon_barron But then each perceptron, logistic regression, linear regression model etc. would be a 2-layer neural network. That'd be weird ü§î"
3640,@rasbt,2022-08-23 07:48:53+00:00,https://twitter.com/rasbt/status/1561983803379392512,@alfcnz @francoisfleuret @jon_barron Nitpick: Logistic regression is actually more closely related to an MLP (compared to perceptrons vs MLPs). And logistic regression is differentiable
3641,@rasbt,2022-08-23 07:46:01+00:00,https://twitter.com/rasbt/status/1561983079362826241,"[5/5] In conclusion, RFs show great out-of-the-box performance on many datasets (see 'noisy' Iris example below). But it doesn't hurt to try increasing the number of features at each node (default: square root of the number of feats), making it more similar to bagging. https://t.co/oJeRK28Oag"
3642,@rasbt,2022-08-23 07:46:00+00:00,https://twitter.com/rasbt/status/1561983077580169216,"[4/5] However, you can see an identical improvement with feature selection (here: RFE = recursive feature elimination): https://t.co/OBu9RX3HF1"
3643,@rasbt,2022-08-23 07:46:00+00:00,https://twitter.com/rasbt/status/1561983075856384000,"[3/5] According to ""Hyperparameters and Tuning Strategies for Random Forest"" (Probst, Wright, Boulesteix 2019), the number of trees at each node (here called ""mtry"") is the most influential hyperparameter for random forests. Increasing it improves perf in the presence of noise: https://t.co/DJhkUJAOni"
3644,@rasbt,2022-08-23 07:45:59+00:00,https://twitter.com/rasbt/status/1561983074128334851,"[2/5] ‚Ä¶ even though RF performs an implicit feat sele (via the splitting criterion at each node), it's not immune to irrelevant features. 
Here's a nice discussion &amp; investigation by Gertjan Verhoeven: https://t.co/jmHFBZx9fC. 
Perf decreases after adding 100 &amp; 500 noise feats: https://t.co/II7vfFHO6J"
3645,@rasbt,2022-08-23 07:45:59+00:00,https://twitter.com/rasbt/status/1561983072714752000,"Random Forest is my favorite baseline algorithm (alongside Logistic Regression). It‚Äôs great because it can handle nonlinear problems and has good out-of-the-box performance (RF doesn‚Äôt require tuning). But ‚Ä¶
[1/5]"
3646,@rasbt,2022-08-23 07:30:56+00:00,https://twitter.com/rasbt/status/1561979287607074817,@roydanroy What's a similarly succinct term for the elitist academic ML gatekeeper?
3647,@rasbt,2022-08-22 16:53:05+00:00,https://twitter.com/rasbt/status/1561758369429348352,@marktenenholtz Yes that‚Äôs a good point. Might make most sense in combination with k-fold cross validation. However in the paper they also did that with different hyperparameter settings
3648,@rasbt,2022-08-22 16:48:39+00:00,https://twitter.com/rasbt/status/1561757253203464192,"@_joaogui1 But yeah, I think the model averaging and single large model ideas are not I compatible though. Why not both?"
3649,@rasbt,2022-08-22 16:46:50+00:00,https://twitter.com/rasbt/status/1561756793809690624,@_joaogui1 The single large model vs multiple small models would be counter to this from an inference speed perspective
3650,@rasbt,2022-08-22 11:33:29+00:00,https://twitter.com/rasbt/status/1561677938390597632,"@_joaogui1 Thanks for the pointer! I would have to look at it again when I get back home, but I think the focus was usually on training the model as an ensemble vs building an ensemble from fine tuned models"
3651,@rasbt,2022-08-22 10:19:01+00:00,https://twitter.com/rasbt/status/1561659195438546945,"@davisblalock Awesome, thanks!"
3652,@rasbt,2022-08-22 08:47:18+00:00,https://twitter.com/rasbt/status/1561636114280087552,"@e_d_andersen If you are a Python user, I suppose you can get by with arrays and deques."
3653,@rasbt,2022-08-22 08:42:10+00:00,https://twitter.com/rasbt/status/1561634822136659971,"@TheRandomMtrix Yeah, also statistical bias is a concrete data analysis whereas under-/overfitting is more of an observation."
3654,@rasbt,2022-08-22 08:39:00+00:00,https://twitter.com/rasbt/status/1561634028876435458,"[3/3] *Greedy soups are ensembles where the models are added sequentially: if it improves the performance on a held-out validation set, then the model is added to the ensemble. It improves the overall test set acc (see above) at the cost of slightly worse out-of-distr performance"
3655,@rasbt,2022-08-22 08:39:00+00:00,https://twitter.com/rasbt/status/1561634026921803776,"[2/3] In the Model Soup paper, the researchers find that by averaging the weights of fine-tuning large pre-trained models you get the best of both worlds: good (ensemble) performance and fast (single model) inference. https://t.co/a88z95VrPY https://t.co/4eEhsfydb4"
3656,@rasbt,2022-08-22 08:38:59+00:00,https://twitter.com/rasbt/status/1561634024556318720,"Ensembles perform better than individual models (https://t.co/JXArY07gOr). 

But ensembles are often disliked in production because they are more complicated to deploy and harder to maintain.
[1/3]"
3657,@rasbt,2022-08-22 05:21:38+00:00,https://twitter.com/rasbt/status/1561584359760592897,@ZefsGuides ‚ÄúUndercutting‚Äù is an iOS term that stands for underfitting if you accidentally let autocorrect do its thing
3658,@rasbt,2022-08-21 19:36:10+00:00,https://twitter.com/rasbt/status/1561437021511483392,"@unography I think so. Besides the higher expressiveness, the second advantage would be higher sampling efficiency"
3659,@rasbt,2022-08-21 19:11:35+00:00,https://twitter.com/rasbt/status/1561430834493931520,@leonpalafox Maybe the original Stable Diffusion paper: https://t.co/BL2oCthgZJ
3660,@rasbt,2022-08-21 18:51:03+00:00,https://twitter.com/rasbt/status/1561425666243002374,"If you are curious about the variance/bias terminology, I have a video explaining it via variance-bias decomposition here https://t.co/qCsqPzdQ2f"
3661,@rasbt,2022-08-21 18:51:02+00:00,https://twitter.com/rasbt/status/1561425662417813505,"Agreed. There is a difference between variance/bias and overfitting/underfittjng though. 
They don‚Äôt mean exactly the same thing but are somewhat ‚Äúcorrelated‚Äù. Have a short video on it here (https://t.co/N55ONL48HX). 
In practice, using over-/undercutting is probably more useful."
3662,@rasbt,2022-08-21 18:29:01+00:00,https://twitter.com/rasbt/status/1561420119892541440,"Super effective explanation of Stable Diffusion in less than 280 char, plus a figure that is worth a thousand words üëå"
3663,@rasbt,2022-08-21 14:43:11+00:00,https://twitter.com/rasbt/status/1561363290445463553,@tunguz Haha I actually haven‚Äôt tried DALL‚Ä¢E at all ‚Äî I am following so many people on Twitter that I‚Äôve already seen pretty much everything w/o having to submit a single prompt ü§™
3664,@rasbt,2022-08-21 14:40:44+00:00,https://twitter.com/rasbt/status/1561362672561672194,"@tunguz Unless people start open sourcing  their experiment code upon publishing their papers, I am worried that it already is a thing ü•≤"
3665,@rasbt,2022-08-21 14:36:55+00:00,https://twitter.com/rasbt/status/1561361711000682498,"@sdztudhsh @ylecun My main point though is that I welcome this kind of progress as an AI person but at the same time I also feel bad for artists and can completely understand their concern.  Generally, instead of taking an arrogant stance, it‚Äôd be nice to be less alienating towards people affected"
3666,@rasbt,2022-08-21 14:32:58+00:00,https://twitter.com/rasbt/status/1561360719307841536,"@sdztudhsh @ylecun Sure, it‚Äôs not a perfect analogy. But in a somewhat similar manner, it would require the majority of people to pivot and adopt the new technology (artists adopting AI for certain purposes; similar to how some medical doctors adopt AI for certain applications etc)"
3667,@rasbt,2022-08-21 10:44:46+00:00,https://twitter.com/rasbt/status/1561303290339643392,"@karpathy Haven't read any of those, but another somewhat interesting list I just randomly stumbled upon: https://t.co/sl2S5JhKcA"
3668,@rasbt,2022-08-21 09:40:50+00:00,https://twitter.com/rasbt/status/1561287201115209730,"Periodic reminder to check out Einsum
https://t.co/5g6u7BUDuE"
3669,@rasbt,2022-08-21 09:39:09+00:00,https://twitter.com/rasbt/status/1561286774680322049,@JFPuget Named tensors ftw! (Although I think this looks like it was abandoned a few versions ago).
3670,@rasbt,2022-08-21 09:33:08+00:00,https://twitter.com/rasbt/status/1561285262608670722,"@fayyazhere Yes, that‚Äôs a good way to put it."
3671,@rasbt,2022-08-21 09:31:11+00:00,https://twitter.com/rasbt/status/1561284770423869441,"@ylecun So many examples of that in history: theatre and movies, paintings and photography, etc.
Anyways, it should be possible to see both sides of the coin: of course the advancement in tech is amazing, but it‚Äôd also be nice to show some compassion for those artists who are worried"
3672,@rasbt,2022-08-20 07:45:46+00:00,https://twitter.com/rasbt/status/1560895855896444933,@JFPuget @datametrician @RAPIDSai @XGBoostProject @zstats Good to know! Via conda or pip? I think via the conda-forge channel you have to specify the gpu version with a suffix. But maybe that‚Äôs the RapidsAI one then.
3673,@rasbt,2022-08-20 06:22:38+00:00,https://twitter.com/rasbt/status/1560874933001097217,@le__gab I‚Äôd say that‚Äôs fine. It‚Äôs probably more important how you set up the experiments to obtain multiple samples for either CI‚Äôs or IQR‚Äôs
3674,@rasbt,2022-08-20 06:18:33+00:00,https://twitter.com/rasbt/status/1560873906818502656,@dataengines Thanks for sharing. That‚Äôs what a love about twitter: someone always shares something I didn‚Äôt know about! Bookmarked!
3675,@rasbt,2022-08-20 06:16:56+00:00,https://twitter.com/rasbt/status/1560873501317386241,"@le__gab Totally agree. I am not judgy when it comes to which method they use, but I hate it if people don‚Äôt *specify* which method they use"
3676,@rasbt,2022-08-19 13:38:16+00:00,https://twitter.com/rasbt/status/1560622177472647168,"@apachaves Haha yes, üíØ"
3677,@rasbt,2022-08-19 13:37:57+00:00,https://twitter.com/rasbt/status/1560622096551710720,@datametrician @JFPuget @RAPIDSai @XGBoostProject @zstats Thanks for explaining!
3678,@rasbt,2022-08-19 13:37:03+00:00,https://twitter.com/rasbt/status/1560621868595429376,"@ellisvalentiner @seanmylaw Yes, good explanation. Common use cases for confidence intervals are eg the uncertainty of the model performance (like accuracy of the model) whereas the prediction interval is more useful for estimating the uncertainty of a particular prediction"
3679,@rasbt,2022-08-19 08:17:32+00:00,https://twitter.com/rasbt/status/1560541461426409474,"@karpathy @unsorsodicorda Wohoo can‚Äôt wait to be back home, pour me a cup of coffee, and watch this on a quiet Saturday morning üòä"
3680,@rasbt,2022-08-19 08:16:18+00:00,https://twitter.com/rasbt/status/1560541152172036099,"@JFPuget @RAPIDSai ‚ÄúTraining takes seconds or minutes with XGB (on GPU of course.) @RAPIDSai rocks.‚Äù Both are obviously true üòä. Curious, are you referring to a RapidsAI version of XGBoost, or you are mentioning it re some others ML algos you are using atm?"
3681,@rasbt,2022-08-19 08:13:26+00:00,https://twitter.com/rasbt/status/1560540428067393537,"If you care more about prediction intervals, also see conformal predictions üëå https://t.co/EHjYHrDcrH"
3682,@rasbt,2022-08-19 08:11:52+00:00,https://twitter.com/rasbt/status/1560540033530085376,"‚ÄúWhat are some ‚Äòimportant‚Äô problems in machine learning/AI?‚Äù (https://t.co/gp1Vx4lGM5). 

Top 1: ‚ÄúEstimating the uncertainty and confidence interval in AI/ML predictions.‚Äú
Got you covered with some techniques here: https://t.co/CWcHmjqg0w"
3683,@rasbt,2022-08-19 07:58:24+00:00,https://twitter.com/rasbt/status/1560536647460085760,Random find in my parent‚Äôs basements. This search engine cheat sheet does not even include Google yet üòÖ https://t.co/KXPyohwbZh
3684,@rasbt,2022-08-19 07:51:18+00:00,https://twitter.com/rasbt/status/1560534860485255168,"@LChoshen @nishparadox Yeah in addition to model averaging I also saw a paper on an extension of stochastic weight averaging for Bayesian model averaging. Might have been this one: https://t.co/JDtvmvHKip. Anyways it‚Äôs very specific to neural nets though, but the discussion of ensembles is much broader"
3685,@rasbt,2022-08-17 12:58:33+00:00,https://twitter.com/rasbt/status/1559887405439762432,@nishparadox https://t.co/iFNco49YIs
3686,@rasbt,2022-08-17 08:21:12+00:00,https://twitter.com/rasbt/status/1559817606785339392,@hackathorn Tbh I would probably look for textbooks over courses
3687,@rasbt,2022-08-17 08:19:14+00:00,https://twitter.com/rasbt/status/1559817115397406726,"@AmitMoscovich @tunguz Or in other words, if you start with practical machine learning and computing, you will make learning math and stats more rewarding. Of course it also has its downsides since people may not find time to study it later on, but yeah, life is full of trade offs"
3688,@rasbt,2022-08-17 08:17:38+00:00,https://twitter.com/rasbt/status/1559816708801675264,"@AmitMoscovich @tunguz That‚Äôs true. I gat your point that  at some point you might lack the focus and time tackling math subjects. On the other hand, I strongly believe that  most people who try to start with studying math will lose the motivation pretty quickly."
3689,@rasbt,2022-08-17 08:14:38+00:00,https://twitter.com/rasbt/status/1559815957601783808,@cnbhaskar55 Glad you like it! üôå
3690,@rasbt,2022-08-16 16:17:52+00:00,https://twitter.com/rasbt/status/1559575178387922944,@AnoopRKulkarni @tunguz Yeah I‚Äôd say you need both eventually. I‚Äôd say with a computational focus early on you can be more productive early on. Depends on what you want to do (research vs applications) but I think for the majority of jobs the computational aspects are more important to get going
3691,@rasbt,2022-08-16 14:11:29+00:00,https://twitter.com/rasbt/status/1559543371764572160,"@paul_rietschka @tunguz Yes, good one!"
3692,@rasbt,2022-08-16 13:56:56+00:00,https://twitter.com/rasbt/status/1559539711009603592,@xamat Interesting! Did you also notice a strong focus on molecular data (something that I have always been interested in and dabbled with a bit in recent years) or is it more general regarding graph structured data and graph databases?
3693,@rasbt,2022-08-16 13:51:58+00:00,https://twitter.com/rasbt/status/1559538459811119104,"It's no coincidence that the top-10 of SQuAD2.0 benchmark are all ensemble models: https://t.co/2uQvH1vSgL

The same is probably true among Kaggle score boards?"
3694,@rasbt,2022-08-16 13:45:09+00:00,https://twitter.com/rasbt/status/1559536746232168448,"Take at least one intro course that emphasizes breadth  over depth üÜö starting with mathematical courses. 
I think it's most productive to understand what's out there first. This gives you a better idea about which tool to choose for a given task &amp; which subareas to specialize in"
3695,@rasbt,2022-08-16 13:39:20+00:00,https://twitter.com/rasbt/status/1559535280041984003,"@tunguz I would update my priority list. E.g., I think nowadays things like version control and parallel computing are more important than math and stats if you want to get things done."
3696,@rasbt,2022-08-16 10:20:45+00:00,https://twitter.com/rasbt/status/1559485305631252481,"@arxivabs @lqh_4rt3mis Awesome! Thanks a lot! Currently traveling, but bookmarked this for a thorough read when I am back! Ha only the name is a bit unfortunate, DanNet was the original CNN that caused the DL break through https://t.co/P8oJex5Y8m"
3697,@rasbt,2022-08-16 07:51:44+00:00,https://twitter.com/rasbt/status/1559447804463964161,"@zacharylipton Yea, statisticians can be very (nit)picky about their terminology üëå (which I actually appreciate; much more clarity and less ambiguity and handwaviness)"
3698,@rasbt,2022-08-15 16:50:17+00:00,https://twitter.com/rasbt/status/1559220946589859841,"@JFPuget @kgourg @MaartenvSmeden For fairness, I think some things like logistic regression random forests are also things that originally came from statistics and where only later associated with ML and AI afaik"
3699,@rasbt,2022-08-15 16:43:27+00:00,https://twitter.com/rasbt/status/1559219229634732032,"@JFPuget @kgourg @MaartenvSmeden Yeah, I think it may be due to the fact that people want to associate AI with the more recent, flashy stuff. Maybe for funding reasons ü§î"
3700,@rasbt,2022-08-15 16:26:58+00:00,https://twitter.com/rasbt/status/1559215077722578950,"@DSaience I basically file the notes in the corresponding project folder/list, do it if it‚Äôs sth quick (check for package outside), or put it on my calendar. I use Notion for work projects as well btw. I have some more notes here: https://t.co/3HtDAgjkis"
3701,@rasbt,2022-08-15 15:57:49+00:00,https://twitter.com/rasbt/status/1559207742459494400,"The simple rationale for this email is something you can easily keep in sync on different devices and OS‚Äòs, and it‚Äôs something you usually check once or twice (or more) per day anyways so you are sure things get processed."
3702,@rasbt,2022-08-15 15:57:48+00:00,https://twitter.com/rasbt/status/1559207739410325506,"One of the best productivity tips is to capture ideas &amp;
 thoughts as conveniently as possible. (The GTD inbox concept.) 

Have been experimenting with so many different tools over the last decade; the one that worked and stuck is a simple Note to Self email app on phone &amp; laptop"
3703,@rasbt,2022-08-15 12:53:56+00:00,https://twitter.com/rasbt/status/1559161466695155715,@TheZachMueller @ducha_aiki Oh yeah I was thinking of 27 as max size. I can imagine smaller ones will work as well
3704,@rasbt,2022-08-15 12:50:00+00:00,https://twitter.com/rasbt/status/1559160477837565953,@TheZachMueller @ducha_aiki * But I am also sitting way too close to my monitors (maybe I am slightly far sighted) which is why 1080 looks so pixelated
3705,@rasbt,2022-08-15 12:48:29+00:00,https://twitter.com/rasbt/status/1559160098135629829,@spasskloppe * could be also serendipity though because I train way more classifiers than regression models
3706,@rasbt,2022-08-15 12:46:29+00:00,https://twitter.com/rasbt/status/1559159592973631488,"@TheZachMueller @ducha_aiki 1080 is not good anymore if you are used to a MacBook screen. Can tell you, from switching back and forth, that it will make you regret it"
3707,@rasbt,2022-08-15 12:45:42+00:00,https://twitter.com/rasbt/status/1559159395900166145,@spasskloppe Actually I never achieved double descent with small networks and regressives though. Usually I only sometimes saw with bigger CNN classifiers
3708,@rasbt,2022-08-15 12:41:00+00:00,https://twitter.com/rasbt/status/1559158213089673217,@ducha_aiki I would suggest 27‚Äù; had a 32‚Äù one (biggest one at Costco) for a year and didn‚Äôt like it because you have to constantly move your head. I suspect that‚Äôs even worse with a 48‚Äù TV. Btw 4K is nice. Tried the 5k studio display and it‚Äôs even nicer: looks like a MacBook screen in big
3709,@rasbt,2022-08-15 07:47:47+00:00,https://twitter.com/rasbt/status/1559084422552494080,@swiss_quant @deliprao Yes! You can also use Watermark in the terminal/shell or in any Python script. https://t.co/5m1ebqeEva
3710,@rasbt,2022-08-14 19:19:25+00:00,https://twitter.com/rasbt/status/1558896091063525384,"@paul_rietschka @NikaMelkozerova actually, I never tried a Starbucks in WI üòÖ. We have a lot of cute coffee shops here. Starbucks is usually a travel thing for me"
3711,@rasbt,2022-08-14 13:01:38+00:00,https://twitter.com/rasbt/status/1558801019924107264,Nice minimal implementation of the original denoising diffusion model by Ho et al (https://t.co/MH6joE8spd)
3712,@rasbt,2022-08-14 12:57:46+00:00,https://twitter.com/rasbt/status/1558800046027640833,@francoisfleuret Looks much better than my early-day GANs for sure.
3713,@rasbt,2022-08-14 12:56:32+00:00,https://twitter.com/rasbt/status/1558799734462095360,@francoisfleuret That‚Äôs actually really nice. Thanks for sharing the code. This will come in handy for teaching!
3714,@rasbt,2022-08-14 12:54:29+00:00,https://twitter.com/rasbt/status/1558799217153523712,@ph_singer @i_am_kiwi_kraze Could perhaps start with a post like https://t.co/52EkIzIEeq and then evolve into an book with accompanying code examples ü§ó
3715,@rasbt,2022-08-14 12:52:37+00:00,https://twitter.com/rasbt/status/1558798749710827521,"@ph_singer @i_am_kiwi_kraze Hah really wish there was a book on these best practices. I know there is the Kaggle book (and yes, I have a copy of it on my pile üòÖ) but I would really appreciate your collected thoughts and experiments on this."
3716,@rasbt,2022-08-14 11:48:09+00:00,https://twitter.com/rasbt/status/1558782526046486529,@danofer Nice find! Bookmarked. Love useful practical tips like these (esp those that are contrary to the textbook advice)
3717,@rasbt,2022-08-14 11:42:54+00:00,https://twitter.com/rasbt/status/1558781204882661376,"@NikaMelkozerova In Europe it makes absolutely zero sense to go to Starbucks, except of course, the WiFi if you are traveling üòÖ"
3718,@rasbt,2022-08-14 11:42:08+00:00,https://twitter.com/rasbt/status/1558781009893662722,"@NikaMelkozerova üíØIn the US, you would
either go to starbucks because you 

1Ô∏è‚É£ are traveling and need to use WiFi or 

2Ô∏è‚É£ because you want to get a sugary drink from the drive through. 

If I have to go (due to lack of alt.) and order coffee, the baristas would look at me weird: a coffee?"
3719,@rasbt,2022-08-14 11:34:59+00:00,https://twitter.com/rasbt/status/1558779212118388736,@KrasniqiEriseld @MaartenvSmeden You can do the same for linear regression and interpret it through the lenses of single-layer neural networks. It‚Äôs essentially a adaptive linear neuron (except that it doesn‚Äôt have a threshold function for prediction)
3720,@rasbt,2022-08-14 10:14:11+00:00,https://twitter.com/rasbt/status/1558758877323198464,"@JFPuget @MaartenvSmeden It‚Äôs ok, I think we would just get into an argument about this. People don‚Äôt have to argue all the time"
3721,@rasbt,2022-08-14 08:28:08+00:00,https://twitter.com/rasbt/status/1558732188840906752,@VictorButoi @tdietterich @percyliang Well yeah for the time being maybe. Imagine we called AlexNet etc Large Vision Models back then. I think that would have become quite confusing today. Who says it‚Äôs going be different with current LLMs? ü§∑‚Äç‚ôÇÔ∏è
3722,@rasbt,2022-08-14 07:34:21+00:00,https://twitter.com/rasbt/status/1558718656422367232,"@VictorButoi @tdietterich @percyliang If so unambiguous, I wonder why we don‚Äôt refer to ViTs as Large Vision Models?"
3723,@rasbt,2022-08-14 07:15:57+00:00,https://twitter.com/rasbt/status/1558714025315221505,"On a related note: ‚Äúthese days, I don‚Äôt hesitate to train a 20 million-plus parameter network ‚Ä¶ even if I have only 100 training examples ‚Ä¶ if you‚Äôre training a 1,000-parameter network on 100 examples, every parameter matters much more‚Ä¶‚Äù ‚Äî @AndrewYNg 

https://t.co/8HfKN8j1gU"
3724,@rasbt,2022-08-14 06:10:19+00:00,https://twitter.com/rasbt/status/1558697504853487618,@JFPuget @MaartenvSmeden It‚Äôs similar to data science in a sense where everyone has a slightly different interpretation. There is probably none where someone won‚Äôt nitpick haha. No need to define it here because it would just start an unproductive discussion I feel like.
3725,@rasbt,2022-08-13 21:21:05+00:00,https://twitter.com/rasbt/status/1558564320316997632,@JFPuget @MaartenvSmeden haha about to board an airplane and not ready to start another discussion
3726,@rasbt,2022-08-13 21:16:22+00:00,https://twitter.com/rasbt/status/1558563132985024512,@JFPuget @MaartenvSmeden I can tell you that logistic regression or a nearest neighbor classifier on Iris isn‚Äôt it
3727,@rasbt,2022-08-13 20:57:10+00:00,https://twitter.com/rasbt/status/1558558302673543168,@MaartenvSmeden Yeah that‚Äôs the problem I have with the Venn diagram that depicts ML as a subset of AI (vs the intersection of ML and AI)
3728,@rasbt,2022-08-13 20:49:26+00:00,https://twitter.com/rasbt/status/1558556354788446208,@bozavlado @ph_singer @ljbuturovic @radekosmulski @AllesistKode Just saying that epoch tuning via CV is very expensive.
3729,@rasbt,2022-08-13 20:25:06+00:00,https://twitter.com/rasbt/status/1558550232744476675,"@JFPuget @ph_singer @i_am_kiwi_kraze Yeah, there are many factors in play. Experience but also different objectives."
3730,@rasbt,2022-08-13 20:17:01+00:00,https://twitter.com/rasbt/status/1558548197458558983,"@hsami @chipro Yeah, I am planning to share a few of the interesting tidbits here over time. Will use the #MLSystemsBook for this."
3731,@rasbt,2022-08-13 20:00:19+00:00,https://twitter.com/rasbt/status/1558543993872568321,@ph_singer @i_am_kiwi_kraze Learning rate: yes. Regarding epochs: Just set the number of epochs crazy large and interrupt training when you think it's sufficiently converged.
3732,@rasbt,2022-08-13 19:59:05+00:00,https://twitter.com/rasbt/status/1558543685977006083,"@ph_singer @i_am_kiwi_kraze Yeah, that would be nice, I'd read that"
3733,@rasbt,2022-08-13 19:57:04+00:00,https://twitter.com/rasbt/status/1558543176532721664,"@ph_singer @i_am_kiwi_kraze Just out of curiosity, what would you do if you find the best epoch is not the last epoch. What are the things you would try next?"
3734,@rasbt,2022-08-13 19:55:50+00:00,https://twitter.com/rasbt/status/1558542868037369859,"@ph_singer @i_am_kiwi_kraze Re ""I know how to do good baselines by now"" -- yes, I believe you. However, not everyone has these skills. I don't think it's reasonable to expect that everyone is capable of tuning their models such that the last epoch is the best epoch."
3735,@rasbt,2022-08-13 19:51:56+00:00,https://twitter.com/rasbt/status/1558541883999125506,"@ph_singer @i_am_kiwi_kraze Because it is easy to shoot yourself in the foot if you have a bad hyperparameter setting in the scheduler.I usually do my projects incrementally, starting with the least complex thing first."
3736,@rasbt,2022-08-13 19:49:39+00:00,https://twitter.com/rasbt/status/1558541309543170048,"@JFPuget @ph_singer @i_am_kiwi_kraze I disagree with that. If you have a big compute and time budget, then maybe yeah, you can train things such that the last epoch == best epoch. Not everyone does that."
3737,@rasbt,2022-08-13 19:48:01+00:00,https://twitter.com/rasbt/status/1558540898849497089,"@ph_singer @i_am_kiwi_kraze You are assuming an ideal world where that's always the case. I hate to disagree, but I usually can't make that assumption. Often I also train things without a scheduler. E.g., thinking about baselines. With your approach you will be producing crappy baselines."
3738,@rasbt,2022-08-13 19:46:38+00:00,https://twitter.com/rasbt/status/1558540553851383808,"@srvmshr I see. If you are using the sklearn, you could also try the class_weight setting, and setting to ""balanced"" which makes this easier :)"
3739,@rasbt,2022-08-13 19:45:12+00:00,https://twitter.com/rasbt/status/1558540189391327233,"@Micha23908614 Usually I am very picky about that, must have been an oversight üòÖ. I think it's not page number 429 though, can you perhaps double-check the page number or post a screenshot if that's not too much effort."
3740,@rasbt,2022-08-13 19:40:21+00:00,https://twitter.com/rasbt/status/1558538971654852615,"@NickRMorgan Yeah, TeTra as in Tetra Pak. Missed naming opportunity"
3741,@rasbt,2022-08-13 19:38:24+00:00,https://twitter.com/rasbt/status/1558538480669626369,"@m_salti_ Yes, this should be pretty much equivalent"
3742,@rasbt,2022-08-13 19:37:37+00:00,https://twitter.com/rasbt/status/1558538282920620033,"@abeirami @litian0331 Just seeing the code in on GitHub, nice üëå https://t.co/HYvopfntgm"
3743,@rasbt,2022-08-13 14:46:51+00:00,https://twitter.com/rasbt/status/1558465108443111424,@jdegourville Do you do the resampling based on class frequency or do you also have additional/different criteria?
3744,@rasbt,2022-08-13 14:45:46+00:00,https://twitter.com/rasbt/status/1558464834353725440,"@machsci @ParisNLP @tunguz Sorry it was hard to put all that info into a single tweet üòÖ. In this tweet, it was less about combining performance metrics like PRE &amp; REC but more like task performances. E.g., think of a model serving recommendations that should optimize both relevancy and clicks"
3745,@rasbt,2022-08-13 14:42:29+00:00,https://twitter.com/rasbt/status/1558464010722451456,"@ph_singer @i_am_kiwi_kraze When I interpreted the question by 
@i_am_kiwi_kraze
 correctly, the question was related to how to avoid always selecting the last epoch, because you can't assume the last epoch is always the best epoch."
3746,@rasbt,2022-08-13 14:39:49+00:00,https://twitter.com/rasbt/status/1558463340032266240,@ph_singer @i_am_kiwi_kraze Saving each epoch is not feasible for modern neural networks. You'd run out of storage pretty quickly.
3747,@rasbt,2022-08-13 14:36:48+00:00,https://twitter.com/rasbt/status/1558462579554541570,"Another (obvious?) one is dynamic sampling: 
here, you resample strategically. 

üí° I.e., you oversample low- &amp; undersample the high-performing classes. 

Mentioned in Pouyanfar et al 2018: https://t.co/Eex5V5XjVi
(Potentially interesting to combine it with Two-phase learning!)"
3748,@rasbt,2022-08-13 14:30:33+00:00,https://twitter.com/rasbt/status/1558461004819963904,"@ph_singer @i_am_kiwi_kraze Well you still need to save the model corresponding to the best epoch, otherwise you would have to run the training twice. E.g., PyTorch (left) or PyTorch Lightning (right) code examples: https://t.co/R0ldjaNL5y"
3749,@rasbt,2022-08-13 14:25:17+00:00,https://twitter.com/rasbt/status/1558459681311432710,@i_am_kiwi_kraze @ph_singer @903124S @ljbuturovic @radekosmulski @AllesistKode Do you mean selecting the model corresponding to the best epoch after all the epochs are finished? Ie early stopping without actually stopping early? If yes see my code above. It‚Äôs also automated with a callback in PyTorch Lightning. If that‚Äôs useful I have examples I can share
3750,@rasbt,2022-08-13 12:22:59+00:00,https://twitter.com/rasbt/status/1558428904498536450,"@francoisfleuret No need to create a new tensor, just fill the existing one with 1's:

torch.fill_(x, 1.).unsqueeze(1)

or if you want to create a copy:

torch.fill(x, 1.).unsqueeze(1)

PS: Regarding elegance, also remove the whitespace around the ""="" in the function call -- a Python convention"
3751,@rasbt,2022-08-13 12:13:40+00:00,https://twitter.com/rasbt/status/1558426558137778182,@Vickitidrum That‚Äôs actually a neat idea: use all the available data to learn good representations; then worry about class imbalance in the classification context. Thanks for the pointer!
3752,@rasbt,2022-08-13 03:16:42+00:00,https://twitter.com/rasbt/status/1558291427599196161,"@tdietterich @percyliang For sure. But maybe I am too traditional here but I still prefer to refer to models via their architecture: RNN, CNN, Transformer, etc."
3753,@rasbt,2022-08-13 02:17:05+00:00,https://twitter.com/rasbt/status/1558276424443772928,"@abeirami @tatsu_hashimoto I like it, keeps things simple üòÜ"
3754,@rasbt,2022-08-13 02:16:47+00:00,https://twitter.com/rasbt/status/1558276348287897600,@ak_panda @tdietterich @percyliang Vision Transformer
3755,@rasbt,2022-08-13 02:11:21+00:00,https://twitter.com/rasbt/status/1558274980193910784,"@tdietterich @percyliang For LSSM: it's not bad, but why not just saying ""Transformer model"" to refer to models with a transformer-like architecture and training procedure? I don't think it's necessary to introduce a new term."
3756,@rasbt,2022-08-13 02:09:47+00:00,https://twitter.com/rasbt/status/1558274586495664129,"@tdietterich @percyliang I find ""ViT"" pretty ok. So, instead of LLM, maybe LaT (Language Transformer) would have been a better term in hindsight. I think the L in LLM is too ambiguous.
But yeah, Foundation Model is the worst and way to hype-y. Mark my words -- I won't use it in any professional articles"
3757,@rasbt,2022-08-13 01:56:25+00:00,https://twitter.com/rasbt/status/1558271221934034944,"Re transfer learning, that's also one case where deep tabular methods could potentially shine (compared to conventional tree-based ML such as XGBoost)."
3758,@rasbt,2022-08-13 01:54:33+00:00,https://twitter.com/rasbt/status/1558270754290106368,#MLSystemsBook
3759,@rasbt,2022-08-13 01:54:33+00:00,https://twitter.com/rasbt/status/1558270753073762304,"There are lots of resampling &amp; imputation techniques for imbalanced datasets. 
üí° An interesting (obvious?) idea is two-phase learning: train model on resampled (undersampled) data then fine-tune on original data.
Described in Lee at al: https://t.co/70PUK4JYNa
Anyone tried this?"
3760,@rasbt,2022-08-13 01:48:39+00:00,https://twitter.com/rasbt/status/1558269267329617922,Will tag tweets related to this via #MLSystemsBook for credit
3761,@rasbt,2022-08-12 22:47:23+00:00,https://twitter.com/rasbt/status/1558223653002698765,@napoperez1998 Glad to hear that you liked my book and it's been useful to your career üôå
3762,@rasbt,2022-08-12 22:04:59+00:00,https://twitter.com/rasbt/status/1558212980273184771,"@guysnovelutumba haha, wow, that's a lot of pressure with regard to making every tweet count üòÜ"
3763,@rasbt,2022-08-12 22:04:02+00:00,https://twitter.com/rasbt/status/1558212741197975553,"In case you are wondering what I am currently up to ... I am working on something really cool. No worries, no spoilers ... you will see later this year üòÖ https://t.co/xNh9RoO7yD"
3764,@rasbt,2022-08-12 21:04:55+00:00,https://twitter.com/rasbt/status/1558197864408535041,@marawanemara @deliprao @github Unrelated but reminds me of a friend in Germany who couldn't train neural nets because the computers auto-shutdown over night üò¨
3765,@rasbt,2022-08-12 20:52:35+00:00,https://twitter.com/rasbt/status/1558194760858337282,"I really mean it! I hope you are getting something useful out of my tweets. But I am also learning a lot from you as well! 
99% of the time I post something, there is someone who shares an interesting perspective or an additional resource that is super useful! üçª"
3766,@rasbt,2022-08-12 20:52:35+00:00,https://twitter.com/rasbt/status/1558194759491063814,"Wow, I am really flattered seeing that I have 100k followers ü§Ø
Thank you everyone! All the great discussions we had over the years. Wouldn't want to miss it! ‚ò∫Ô∏è 

Looking forward to so many more years of sharing resources &amp; insights on
ü§ñ Machine learning
üóíÔ∏è Research
üêç &amp; Python"
3767,@rasbt,2022-08-12 20:47:59+00:00,https://twitter.com/rasbt/status/1558193603909910528,"@el_ateifSara Awesome, thanks so much! For reference, if someone wants to check it out: https://t.co/RLDxSDKqLO"
3768,@rasbt,2022-08-12 18:28:39+00:00,https://twitter.com/rasbt/status/1558158538593259522,"@deliprao @github Hah, tricky. I hope the solution is NOT to have in-person &amp; on-paper coding tests again."
3769,@rasbt,2022-08-12 16:14:20+00:00,https://twitter.com/rasbt/status/1558124738375028741,@ParisNLP @tunguz It's basically just a fancy term for saying: always predict the most frequent class
3770,@rasbt,2022-08-12 15:48:42+00:00,https://twitter.com/rasbt/status/1558118285727698946,@tunguz Start with a zero-rule baseline
3771,@rasbt,2022-08-12 15:42:06+00:00,https://twitter.com/rasbt/status/1558116625039114240,@josh_tobin_ Haha by quoting it you are making it a commonly quoted statistic. I see what you did there üôÉ
3772,@rasbt,2022-08-12 15:38:20+00:00,https://twitter.com/rasbt/status/1558115676732248064,@DynamicWebPaige And at the same time also be able to focus. Basically they must be able to multi-task between single-tasking and multi-tasking üòÜ
3773,@rasbt,2022-08-12 15:36:52+00:00,https://twitter.com/rasbt/status/1558115307486601216,"@svpino @tunguz @jargnar Yeah, but I think the key is to evaluate across datasets. Diverse datasets and subtasks. That‚Äôs because real world use cases are also diverse."
3774,@rasbt,2022-08-12 15:24:48+00:00,https://twitter.com/rasbt/status/1558112272047800320,"""Nobody talks about all of the waiting in Data Science"" [Reddit Discussion] 

Hah, I don't think I was ever actively waiting. There are papers to read, next hyperparameter runs to set up, plots to plot, docs to write, and Twitter discussions to be had. üôÉ

https://t.co/HoFY1WwR04"
3775,@rasbt,2022-08-12 14:53:03+00:00,https://twitter.com/rasbt/status/1558104283391877121,"@drraug @ahatamiz1 Haha, of course not. I am just saying that most profs would tell you that it's a waste of time"
3776,@rasbt,2022-08-12 14:41:12+00:00,https://twitter.com/rasbt/status/1558101298926477313,"@903124S @ph_singer @ljbuturovic @radekosmulski @AllesistKode Well, the training loss always goes down (and validation loss often does too), but I am more concerned about overfitting, which is something that you usually don't solve with lowering the learning rate in my experience, but @ph_singer has more practical experience."
3777,@rasbt,2022-08-12 14:38:52+00:00,https://twitter.com/rasbt/status/1558100709941415936,"Oldie but goodie: 

‚ö†Ô∏è 67.97% of CIFAR-10 test images &amp; 16.04% ImageNet test images can be perturbed to at least one target class by modifying just one pixel (https://t.co/lCXt47YqWk).

Does anyone know of a similar study for ViT's? (If not, that's an easy paper right there üôÉ) https://t.co/qB5SIvjdAg"
3778,@rasbt,2022-08-12 14:29:55+00:00,https://twitter.com/rasbt/status/1558098458455818243,"@mariotelfig @xamat Yeah, absolutely. I think it was some sort of stacking classifier. In that sense, the optimization of the scores weights could be also automated via stacking :P"
3779,@rasbt,2022-08-12 14:29:19+00:00,https://twitter.com/rasbt/status/1558098307037237248,"@drraug @ahatamiz1 I don't think most PhD students have to worry about production settings at that point, yet. Actually, imho, most professors hate it when students focus too much on engineering things well."
3780,@rasbt,2022-08-12 14:26:07+00:00,https://twitter.com/rasbt/status/1558097503035301892,"@JulienMouchnino @chipro No theory, mostly practical advice."
3781,@rasbt,2022-08-12 14:24:49+00:00,https://twitter.com/rasbt/status/1558097174843514880,@ph_singer @ljbuturovic @radekosmulski @AllesistKode Fair. You also have more practical experience with schedulers than I have. But let's just assume you try to tune it such that the last epoch is best: what speaks against still employing code that selects based on the validation performance. In the ideal case those are equal then
3782,@rasbt,2022-08-12 14:22:25+00:00,https://twitter.com/rasbt/status/1558096570100629504,"@LonesPhoebe Essentially just training 2 different models and making predictions based on the combined score. E.g., if you predict a product to show to a customer, 1 score can be clicks and 1 score can be related to revenue or sth like that."
3783,@rasbt,2022-08-12 14:20:06+00:00,https://twitter.com/rasbt/status/1558095988635623424,"@parker_brydon @thomasjpfan No, I haven't seen comparisons. Maybe Thomas has done some. However, I do think that if you have count data the Poisson approach would probably be better than the rounding approach. I mean, it's similar to comparing regular (linear) Poisson regression with linear or ridge regr."
3784,@rasbt,2022-08-12 14:18:14+00:00,https://twitter.com/rasbt/status/1558095520043831297,@ph_singer @ljbuturovic @radekosmulski @AllesistKode This requires you to trust that you tuned the scheduler well.
3785,@rasbt,2022-08-12 14:16:41+00:00,https://twitter.com/rasbt/status/1558095127477985286,"@TheFucking22 @chipro I had the 1st edition (lower right corner) back then but I would probably go with the newest edition. I actually read it along side taking his class in grad school back then, but I think it works great as a standalone as well. Hope it held up well."
3786,@rasbt,2022-08-12 14:12:12+00:00,https://twitter.com/rasbt/status/1558094002993434626,"@mariotelfig Afaik the ""winning"" model was only the best model in terms of predictive performance. For the business goal, it was a terrible model. It didn't get deployed after all. I think @xamat had a nice blog post about that."
3787,@rasbt,2022-08-12 14:11:02+00:00,https://twitter.com/rasbt/status/1558093708809146369,"@mariotelfig Ensembles are always always performing better than individual models. But afaik as I know, they are often disliked in production because they are more complicated to deploy and not as easy to maintain. For customer-facing products, it also increases the latency."
3788,@rasbt,2022-08-12 14:09:03+00:00,https://twitter.com/rasbt/status/1558093210337136642,"@ph_singer @ljbuturovic @radekosmulski @AllesistKode If you don't select a single epoch per fold, you would have to run CV (multiple models) on many epoch numbers. I don't think this is at all feasible for most neural networks."
3789,@rasbt,2022-08-12 14:07:38+00:00,https://twitter.com/rasbt/status/1558092850067300353,"@ljbuturovic @radekosmulski @AllesistKode At the same time, neural networks can fluctuate a lot between epochs, and you still want to select a good training epoch for your candidate model. If you have 5-fold cross validation, you have 5 models, all with different random weights. Is the avg epoch a good epoch to choose?"
3790,@rasbt,2022-08-12 14:06:21+00:00,https://twitter.com/rasbt/status/1558092529375105024,"@ljbuturovic @radekosmulski @AllesistKode Yeah, I agree with you: a single validation set leaks more than the multiple validations sets from CV. I mean, with CV you are averaging over validation sets, which is more robust."
3791,@rasbt,2022-08-12 02:54:19+00:00,https://twitter.com/rasbt/status/1557923407605501952,"@ljbuturovic @radekosmulski @AllesistKode But CV is the validation set. I.e., instead of splitting the training set into multiple folds, you split the training set into a training + validation set. To me splitting the training set via CV or into a validation set is the same thing in terms of leakage."
3792,@rasbt,2022-08-12 01:52:45+00:00,https://twitter.com/rasbt/status/1557907913489915909,"@ljbuturovic @radekosmulski @AllesistKode Sure, but @radekosmulski argument would still hold that you leak information if you use cross-validation (multiple validation sets) to select the epoch"
3793,@rasbt,2022-08-11 23:00:31+00:00,https://twitter.com/rasbt/status/1557864567811751936,"@ahatamiz1 Of course. There is always only so much that can fit into a tweet. If you want to cover all the methods, scenarios, and ramifications, that's a review paper üôÉ"
3794,@rasbt,2022-08-11 21:13:12+00:00,https://twitter.com/rasbt/status/1557837562030563330,"@radekosmulski @AllesistKode This is not wrong. But if you imply we shouldn‚Äôt do that, what‚Äôs the point of a validation set? And how would you select the training epoch otherwise?  Imho selecting the best epoch based on validation performance is ok. Now, using the test set for model selection, yes that‚Äôs bad"
3795,@rasbt,2022-08-11 21:08:21+00:00,https://twitter.com/rasbt/status/1557836341358084105,@francoisfleuret Diffusion model is interchangeable with GAN in this tweet ü§£
3796,@rasbt,2022-08-11 21:06:02+00:00,https://twitter.com/rasbt/status/1557835756093284356,@ChidiOnum @akshay_pachaar @aureliengeron That‚Äôs ambitious üòÜ. The kaggle book has been on my pile for a few months now and I hope I‚Äôll eventually get to it as well üòÖ
3797,@rasbt,2022-08-11 20:13:02+00:00,https://twitter.com/rasbt/status/1557822420777680901,@kchonyc it could be. But I'd say in the typical case loss are apples and scores are oranges.
3798,@rasbt,2022-08-11 20:05:56+00:00,https://twitter.com/rasbt/status/1557820632917843971,@christi26164848 @chipro I'd say it can be for an ML expert who is an MLOps novice/beginner
3799,@rasbt,2022-08-11 18:28:17+00:00,https://twitter.com/rasbt/status/1557796057387524098,@deliprao Bookmarked! Thanks for sharing!
3800,@rasbt,2022-08-11 18:02:05+00:00,https://twitter.com/rasbt/status/1557789463396458496,"@emily_murnane Educational and social services are among the important things, and at the same time they are also the most underappreciated things üò©"
3801,@rasbt,2022-08-11 17:57:08+00:00,https://twitter.com/rasbt/status/1557788218120179715,"@JulienMouchnino @thomasjpfan Yes and no. Poisson regression is more for count data where you can quantify the distance. Like 1 + 2 = 3. For general ordered categorical data, I would use ordinal regression methods where you don't make an assumption about the (magnitude of the) distance between categories."
3802,@rasbt,2022-08-11 17:07:58+00:00,https://twitter.com/rasbt/status/1557775845799886849,"Did you know that you can now configure 
üéÑ random forests and HistGradientBoosting üéÑ 
in scikit-learn for Poisson regression (for working with count data)?
E.g.,
RandomForestRegressor(criterion=""poisson"")

Here's a recording of @thomasjpfan's talk
https://t.co/4NjauOvQPc"
3803,@rasbt,2022-08-11 16:56:53+00:00,https://twitter.com/rasbt/status/1557773055191130113,"@dan_biderman Oh yeah, üíØ! Multitask learning can definitely boost the performance of a model (even if you only care about a single task). Here, the context is more like a problem where you e.g., want to find the optimal product rank based on e.g., clicks &amp; revenues as objectives."
3804,@rasbt,2022-08-11 16:54:27+00:00,https://twitter.com/rasbt/status/1557772445003702273,@tegan_maharaj Plot twist: in industry ensembles are often discouraged though because for many consumer-facing models low-latency is more important than predictive accuracy üòÜ
3805,@rasbt,2022-08-11 16:53:27+00:00,https://twitter.com/rasbt/status/1557772191072243712,"@terrible_coder If you have an overarching objective that you can express as a combination of the individual scores, you could also throw an optimization algorithm at it, like Nelder-Mead https://t.co/O1bw1HWWUV"
3806,@rasbt,2022-08-11 16:09:56+00:00,https://twitter.com/rasbt/status/1557761242701463555,"@Kaszanas @francoisfleuret @CSProfKGD Would also be great if reviewers could get to see the updated manuscript with changes highlighted. In rebuttals authors often claim they'd do xyz, but how would you know that it actually happens?"
3807,@rasbt,2022-08-11 16:07:32+00:00,https://twitter.com/rasbt/status/1557760638574788609,"@deliprao Our PrivacyNet paper üëÄ
(https://t.co/BCrNkyQLxy) https://t.co/jRndVRwdrJ"
3808,@rasbt,2022-08-11 16:00:04+00:00,https://twitter.com/rasbt/status/1557758756838055937,@maximelabonne Or there are just some problems where this is way more natural. Like our Semi-adversarial network method where the multi-objective loss was essential. Another example is a variational autoencoder with the reconstruction loss and the KL divergence terms
3809,@rasbt,2022-08-11 15:52:03+00:00,https://twitter.com/rasbt/status/1557756741688954881,"@srchvrs Yes and no. I mean, ideally you have similar losses on the same magnitude. But on the other hand, the alpha/beta can be used for scaling. This is basically the same thing you do in e.g., a variational autoencoder where you combine MSE (or binary cross entropy) + the KL div term"
3810,@rasbt,2022-08-11 15:49:50+00:00,https://twitter.com/rasbt/status/1557756184148451328,@terrible_coder Sounds like you implemented a stacking classifier üòä
3811,@rasbt,2022-08-11 15:02:28+00:00,https://twitter.com/rasbt/status/1557744264062406657,@fmello93 @chipro Btw do we have an official hashtag for this? üòä
3812,@rasbt,2022-08-11 15:00:41+00:00,https://twitter.com/rasbt/status/1557743816248938496,"@fmello93 @chipro Yes, it's part of https://t.co/dNt9nJWb1u!"
3813,@rasbt,2022-08-11 14:59:02+00:00,https://twitter.com/rasbt/status/1557743398102368257,@maximelabonne A research setting where you want to maximize predictive performance.
3814,@rasbt,2022-08-11 14:57:27+00:00,https://twitter.com/rasbt/status/1557743002428141571,@mrigankanath_ I guess it depends on your objectives üôÉ. I'd say the weighted average approach wins in terms of maintainability and adaptability. The multitask approach may be better at predictive performance. It could also be better for latency in a consumer system. But it depends.
3815,@rasbt,2022-08-11 14:54:06+00:00,https://twitter.com/rasbt/status/1557742158421102592,"@kchonyc @Lunit_AI Hah, are these Pythons üêç in the background? ü§©"
3816,@rasbt,2022-08-11 14:50:31+00:00,https://twitter.com/rasbt/status/1557741254611329024,@mrigankanath_ Yup!
3817,@rasbt,2022-08-11 14:46:47+00:00,https://twitter.com/rasbt/status/1557740314328453121,"Food for thought: When optimizing multiple objectives, instead of training on
loss = Œ± loss + Œ≤ loss, 
it's easier to train 2 models &amp; combine their scores
score = Œ± score + Œ≤ score
üí° Makes the ML system easier to update and maintain; doesn't require retraining when Œ± &amp; Œ≤ change"
3818,@rasbt,2022-08-11 14:42:16+00:00,https://twitter.com/rasbt/status/1557739179005874176,@paul_rietschka @tunguz https://t.co/mRypCvTEMi
3819,@rasbt,2022-08-11 14:33:26+00:00,https://twitter.com/rasbt/status/1557736955470700546,"@TheSaddlePoint @vtuulos Haha, probably would have skipped that because of the buzzwordy ""Data Science"" in the title. But your tweet got me interested and will add it to my list!"
3820,@rasbt,2022-08-11 14:31:57+00:00,https://twitter.com/rasbt/status/1557736583977086984,"@TheFucking22 @chipro I can recommend ""Introduction to Data Mining"" by Pang-Ning Tan et al. It covers lots of the fundamental algorithms. It's language agnostic, but I recommend toying around with some of the models in code (preferably Python) as you read along."
3821,@rasbt,2022-08-11 14:27:40+00:00,https://twitter.com/rasbt/status/1557735503926947843,@popular_ML CC @david_macedo
3822,@rasbt,2022-08-11 14:25:58+00:00,https://twitter.com/rasbt/status/1557735075927965698,"@jlangenhagen @TheFucking22 @chipro There are basically two routes, the statistics and the machine learning route. I would say if you are more interested in the statistics route, pick R or Julia. But if you are serious about machine learning, Python is a must."
3823,@rasbt,2022-08-11 14:23:35+00:00,https://twitter.com/rasbt/status/1557734477316493312,"@jlangenhagen @TheFucking22 @chipro Disclaimer: The ISL book is an R-based textbook. Probably doesn't hurt to pick up R (fun fact: I used R in my first book 10 years ago, but I haven't touched it like 8 years -- except for a statistics class I was teaching 2 years ago; R was required via a pre-existing syllabus.)"
3824,@rasbt,2022-08-11 02:37:13+00:00,https://twitter.com/rasbt/status/1557556715285094400,"@chipro I should maybe clarify that it's not a hands-on tutorial book, but a book focused on the big picture and discussions about trade-offs.
I will be sharing some of the interesting nuggets I learned from it in the upcoming weeks as I transcribe my notes! 
In the meantime, AMA though"
3825,@rasbt,2022-08-11 01:19:27+00:00,https://twitter.com/rasbt/status/1557537143110729729,@tejuafonja Haha üíØ
3826,@rasbt,2022-08-11 00:14:09+00:00,https://twitter.com/rasbt/status/1557520711136182275,@MahtabSyed @chipro It's not a hands-on book but more like birds-eye view on all the contexts and challenges.
3827,@rasbt,2022-08-10 23:44:24+00:00,https://twitter.com/rasbt/status/1557513222705614849,"Just finished @chipro's excellent ML Systems book! Was reading it in 30min/day increments so it took me a while. 
üëå Can highly recommend it to anyone coming from academia and wanting to get a glimpse into the ML production world!
üìù Took lots of notes and can share my takeaways! https://t.co/rRqyt9QGcW"
3828,@rasbt,2022-08-10 22:13:36+00:00,https://twitter.com/rasbt/status/1557490374523895808,"@MuzafferKal_ @ItaDude @tunguz It's a bit technical, but I'd say @lilianweng 's https://t.co/4NJZzr9HKF"
3829,@rasbt,2022-08-10 20:15:11+00:00,https://twitter.com/rasbt/status/1557460574954463233,"If you are into computer vision and want to leverage synthetic data for training your models, NVIDIA just launched their Omniverse Replicator as an App on our Lightning platform! 
You can use right from the browser: https://t.co/QqLd3YCW8O https://t.co/QtK7VamUWZ"
3830,@rasbt,2022-08-10 20:05:23+00:00,https://twitter.com/rasbt/status/1557458105365061632,@ItaDude @tunguz yep!
3831,@rasbt,2022-08-10 18:24:38+00:00,https://twitter.com/rasbt/status/1557432751673982982,@tunguz Tbh I think the tides have turned and GANs are on the way out
3832,@rasbt,2022-08-10 18:23:50+00:00,https://twitter.com/rasbt/status/1557432548883664897,@tunguz @Zergylord On the autoencoder note: I remember a seminar from 2 years ago where there results from a modern variational autoencoder variant looked indeed indistinguishable from BigGan or whatever model was One of the SOTA ones back then
3833,@rasbt,2022-08-10 18:20:39+00:00,https://twitter.com/rasbt/status/1557431748522348545,@forrestbrazeal Hourly costs üòÜ
3834,@rasbt,2022-08-10 18:14:38+00:00,https://twitter.com/rasbt/status/1557430236249309184,"@SchmidhuberAI Nice work! Looking forward to taking it for a spin done day; had some neural architecture search related ideas from a couple of years ago, but I got too busy hacking it together back then üòÜ. A framework like this may lower the barrier here!"
3835,@rasbt,2022-08-10 18:11:26+00:00,https://twitter.com/rasbt/status/1557429431865643009,"@david_macedo Oh yeah, it‚Äôs just an overview; it‚Äôs essentially a reading list üòÖ. But I am planning to share more details if I ever get a chance üòä"
3836,@rasbt,2022-08-10 14:03:43+00:00,https://twitter.com/rasbt/status/1557367090939666432,Awesome work by @david_macedo !
3837,@rasbt,2022-08-10 14:03:08+00:00,https://twitter.com/rasbt/status/1557366945472827392,"Just saw this comprehensive thesis on deep learning for OOD data drop on arXiv: ""Towards Robust Deep Learning using Entropic Losses"" https://t.co/MKXq6hbwWZ. 
Lots to read here, but in a nutshell, it looks like the proposed IsoMax+ performs well and is relatively easy to use üëå https://t.co/aF3Kpyd6QN"
3838,@rasbt,2022-08-10 13:48:49+00:00,https://twitter.com/rasbt/status/1557363342062280708,"@hugo_le_moine_ I agree. There are some cool (but rare) synergies between evolutionary programming and the other side of machine learning, though. E.g., take @randal_olson's awesome TPOT library (https://t.co/TOcUl3zZcV) that uses a genetic algorithm to construct a machine learning pipeline."
3839,@rasbt,2022-08-10 13:24:41+00:00,https://twitter.com/rasbt/status/1557357265610473473,"@francoisfleuret @CSProfKGD Imho, asking for ""please don't forget to update the score if applicable"" is okay; asking for a specific score is not ok. I would consider that as an attempt to bias the reviewer."
3840,@rasbt,2022-08-10 13:14:03+00:00,https://twitter.com/rasbt/status/1557354590416388096,"@JFPuget @ID_AA_Carmack Usually, I am the same (or actually, that's maybe the first time someone blocked me that I am aware of), but for @ID_AA_Carmack I am happy to make an exception. I am not promoting the video but wanted to hear his thoughts and acknowledge that I enjoyed @ID_AA_Carmack's content"
3841,@rasbt,2022-08-10 13:09:22+00:00,https://twitter.com/rasbt/status/1557353414320865281,"@JFPuget @ID_AA_Carmack Actually, same. I heard he uses Twitter differently ü§∑‚Äç‚ôÇÔ∏è https://t.co/6Tqxd1yaLT"
3842,@rasbt,2022-08-10 02:53:56+00:00,https://twitter.com/rasbt/status/1557198534201548811,@dvassallo Which of those would you bring to a lonely island if you could only bring 2 things?
3843,@rasbt,2022-08-10 02:29:38+00:00,https://twitter.com/rasbt/status/1557192419560591360,"@ID_AA_Carmack Just finished listening to the whole thing! That's not a podcast episode, it's an audiobook, haha.
Enjoyed every little bit of it, though. Lot's of useful advice in there, thanks for sharing!
Good luck on the AI journey. Have fun working on it!"
3844,@rasbt,2022-08-10 01:26:12+00:00,https://twitter.com/rasbt/status/1557176454273712128,"Whoa, evolutionary algorithms are making a comeback!? 
Just saw the release of EvoTorch: https://t.co/npC7y7bMqr from NNAISENSE.
Efficient  neural architecture search? Feature selection for deep tabular methods? Looks like this opens a few interesting routes to explore."
3845,@rasbt,2022-08-09 18:25:09+00:00,https://twitter.com/rasbt/status/1557070494297427968,"@rbsahgal @Maxmatical Hm, maybe. Also, just changing the learning rate / using a learning rate scheduler can help. But re initializing from a local minimum, that's basically what you do anyway when you are fine-tuning/doing transfer learning"
3846,@rasbt,2022-08-09 18:11:19+00:00,https://twitter.com/rasbt/status/1557067014128238593,"@rbsahgal @Maxmatical but you are also right, like you said, there is of course variation from running things multiple times (see random seed below), and I still recommend it. But for different purposes https://t.co/1A1gHg4avB"
3847,@rasbt,2022-08-09 18:08:46+00:00,https://twitter.com/rasbt/status/1557066369845297152,"@rbsahgal @Maxmatical That is true. I usually run the model multiple times but not for epoch tuning. E.g., running the model on the left twice with 10 epochs and 25 epochs seems wasteful, why not running it once 25 epochs and then taking the model from the 10th epoch? https://t.co/vW8E8WA7s8"
3848,@rasbt,2022-08-09 15:34:20+00:00,https://twitter.com/rasbt/status/1557027505294508038,"@scientistswrite haha, mobile is usually not a problem ... do you know something similar for macOS?"
3849,@rasbt,2022-08-09 15:33:38+00:00,https://twitter.com/rasbt/status/1557027329431437314,@scientistswrite Really curious to give it a try. It sounds like Grammarly but for scientific writing!?
3850,@rasbt,2022-08-09 14:59:54+00:00,https://twitter.com/rasbt/status/1557018843305877505,"@gomezperaltaai On the contrary. It's one 100% the same concept: just change the number of output nodes to 1 and change the loss to MSE. 

I have done it here: https://t.co/dEMvFnSLYG"
3851,@rasbt,2022-08-09 14:53:35+00:00,https://twitter.com/rasbt/status/1557017250439335938,"@minigamedev I think it's really about different use cases also. It's also a lot about what you care about, prediction or inference"
3852,@rasbt,2022-08-09 14:30:39+00:00,https://twitter.com/rasbt/status/1557011480251449344,"@HaffendenHector I see. But I don't think always has to be super suspicious. First, I would try to train the same network with different initial random weights on the same fold and see what the natural variation"
3853,@rasbt,2022-08-09 14:28:42+00:00,https://twitter.com/rasbt/status/1557010988032999424,"@minigamedev And on a serious note, most classic statistics tools suck for regression on common, unstructred datasets. The example I provided is really just for visualization purposes. Real-world use cases are image or text dataset related. I mean take object detection like YOLO as an example"
3854,@rasbt,2022-08-09 14:26:12+00:00,https://twitter.com/rasbt/status/1557010359516643328,"@minigamedev Haha. And yeah, it's feasible to do does not not imply it's what you should do üôÉ"
3855,@rasbt,2022-08-09 14:24:29+00:00,https://twitter.com/rasbt/status/1557009927004209153,"@HaffendenHector In most cases it is normal that the network overfits at some point, so using the last epoch almost never makes sense. Sure, there are exceptions where you experience double-descent, but that's rare in my experience."
3856,@rasbt,2022-08-09 14:19:03+00:00,https://twitter.com/rasbt/status/1557008562148282370,@parker_brydon The network above is not even regularized.
3857,@rasbt,2022-08-09 14:18:08+00:00,https://twitter.com/rasbt/status/1557008329309831168,"@porestar &gt; Do you have a good resource to debunk this myth? 

My tweet above!? There are 10 data, and the networks has (50+50) + (50*25+25) + (25+1) = 1401 parameters. What additional evidence do you need?  üòÖ"
3858,@rasbt,2022-08-09 14:08:00+00:00,https://twitter.com/rasbt/status/1557005782570385408,"@Maxmatical Also, in PyTorch Lightning you can get that for free using a ModelCheckpoint callback: https://t.co/xyAr3ik1yq"
3859,@rasbt,2022-08-09 14:06:47+00:00,https://twitter.com/rasbt/status/1557005474804940800,"@Maxmatical Tuning the number of epochst sounds so wasteful. You can just choose a large number of epochs &amp; then select the best model based on the validation set performance. Way better than rerunning the model multiple times.

This is pretty easy to implement: https://t.co/qLrkP3wmjE https://t.co/wdhKQBogAL"
3860,@rasbt,2022-08-09 13:38:04+00:00,https://twitter.com/rasbt/status/1556998246085574658,"The Three Elements of PyTorch:
https://t.co/vJVaaBW8KZ"
3861,@rasbt,2022-08-09 13:36:19+00:00,https://twitter.com/rasbt/status/1556997807948587008,@FavourphilicVic üôÉ https://t.co/qwClterA5P
3862,@rasbt,2022-08-09 13:35:44+00:00,https://twitter.com/rasbt/status/1556997658413350917,@parker_brydon My educated guess: they tried various other methods before. They are bored. And they are open to trying something new.
3863,@rasbt,2022-08-09 13:34:52+00:00,https://twitter.com/rasbt/status/1556997442280857601,"üíØ I'd go so far and say: 1-3 always apply to any deep neural network.
2Ô∏è‚É£ It's a hyperparameter you should consider.
3Ô∏è‚É£ Not using early stopping (selecting the best epoch from the training run based on val performance) is shooting yourself in the foot
4Ô∏è‚É£ Goes w/o saying. Always!"
3864,@rasbt,2022-08-09 13:23:58+00:00,https://twitter.com/rasbt/status/1556994698664886275,"@JFPuget @giffmana @ducha_aiki üíØ! Related anecdote: 2 years ago, I gave a talk at the ML-focused seminar series at our computer science department. I mentioned that XGBoost is nowadays the way to go for tabular data. A senior CS faculty (who publishes at NeurIPS etc.) asked me what XGBoost was ü§∑‚Äç‚ôÇÔ∏è"
3865,@rasbt,2022-08-09 13:21:50+00:00,https://twitter.com/rasbt/status/1556994163857661953,"@JFPuget @giffmana @ducha_aiki Haha, the use of ""traditional"" was absolutely deliberate, and @JFPuget hit the nail on the head here üôÉ"
3866,@rasbt,2022-08-09 01:01:06+00:00,https://twitter.com/rasbt/status/1556807752542031874,"@tunguz Arg, I hate these silent bugs, but hey, that's actually a cool, simple example. Will bookmark this for when explaining why we don't use 16-bit encodings by default in (scientific) computing."
3867,@rasbt,2022-08-09 00:57:18+00:00,https://twitter.com/rasbt/status/1556806796437856256,"@WilderChange @karpathy @jackclarkSF When it comes to general tech news, Techmeme is usually pretty timely and thorough: https://t.co/ArbHN7qVg8"
3868,@rasbt,2022-08-09 00:55:49+00:00,https://twitter.com/rasbt/status/1556806421706145793,"Indeed a great resource. Esp. on all the recent LLM developments üëå
- NVIDIA's 30% LLM training efficiency boost
- The world's best language model from China
- Google's LLM-rule-based AI hybrid to improve code quality
- OpenAI article on 'filling sentences in the middle' for LLMs"
3869,@rasbt,2022-08-09 00:51:12+00:00,https://twitter.com/rasbt/status/1556805258776645633,"@srchvrs Yes, of course!"
3870,@rasbt,2022-08-09 00:49:58+00:00,https://twitter.com/rasbt/status/1556804946925719552,"@AllardJeffrey @Al_Grigor @radekosmulski Hah, I guess @Al_Grigor already answered it above üôÉ"
3871,@rasbt,2022-08-08 21:25:53+00:00,https://twitter.com/rasbt/status/1556753587631525891,@Jeande_d @minigamedev This is a very nice step-by-step tutorial!
3872,@rasbt,2022-08-08 19:36:01+00:00,https://twitter.com/rasbt/status/1556725939450658818,"@minigamedev Yeah, there is nothing special about. I am always surprised when people ask whether a neural network can be used for regression. I dunno, but there seems to be  common notion that neural networks are only for classification or so."
3873,@rasbt,2022-08-08 19:29:07+00:00,https://twitter.com/rasbt/status/1556724205542166529,"Another common myth: the number of training data points has to be larger than the number of model parameters.

Btw, the full code is here: https://t.co/KYYnlB4fn3"
3874,@rasbt,2022-08-08 19:27:37+00:00,https://twitter.com/rasbt/status/1556723826821681155,"Q: (How) can I use a deep neural network for regression?
A: Set the number of output nodes to 1 and use eg a MSE loss.  
Q: Is it dangerous?
A: Of course, be aware of overfitting. But note that neural networks don't always go crazy with data outside the training set range. https://t.co/lrOtufY9x8"
3875,@rasbt,2022-08-08 19:22:41+00:00,https://twitter.com/rasbt/status/1556722587232862210,@NishaDalal3 @tunguz k means?
3876,@rasbt,2022-08-08 16:00:22+00:00,https://twitter.com/rasbt/status/1556671670437412866,"As a reviewer, I shouldn't be the one judging whether to accept/reject a paper. If I don't have all the other submissions as a context, how/why should I make that call?"
3877,@rasbt,2022-08-08 15:58:39+00:00,https://twitter.com/rasbt/status/1556671237363048454,"@chrisalbon Haha, I was looking for specific examples üòÜ"
3878,@rasbt,2022-08-08 15:58:26+00:00,https://twitter.com/rasbt/status/1556671182111481857,"Or, let's remove scores altogether. Like on Kotaku. 
Forces the editor/AC to carefully read the review comments and lets the reviewer focus on their reviewer job: highlighting strengths and weaknesses, checking for technical correctness."
3879,@rasbt,2022-08-08 15:52:16+00:00,https://twitter.com/rasbt/status/1556669634228719616,@EmmaBostian üíØ
3880,@rasbt,2022-08-08 15:51:36+00:00,https://twitter.com/rasbt/status/1556669466355896320,@chrisalbon Spoilers please!
3881,@rasbt,2022-08-08 15:50:56+00:00,https://twitter.com/rasbt/status/1556669297442922496,@zicokolter Achievement unlocked!
3882,@rasbt,2022-08-08 15:50:02+00:00,https://twitter.com/rasbt/status/1556669071449620480,"@Al_Grigor @radekosmulski I feel you. If you want to spice it up and have time for tinkering, you can try some of the recently proposed deep learning architectures for tabular data: https://t.co/VAXJRBMyzj"
3883,@rasbt,2022-08-08 15:05:55+00:00,https://twitter.com/rasbt/status/1556657966455132162,@tunguz So maybe an overflow? I guess a mean would have worked?
3884,@rasbt,2022-08-08 14:55:09+00:00,https://twitter.com/rasbt/status/1556655257136021505,"@tunguz Huh, this sounds almost like a bug, or did you have extreme overflow/underflow? What would you consider a simple NumPy operation? Do you have a minimal example? Sorry, so many questions, but I would note this somewhere so that I can add it to my NumPy guide some time üòÖ"
3885,@rasbt,2022-08-08 14:44:31+00:00,https://twitter.com/rasbt/status/1556652581295898625,@DynamicWebPaige Dinosaurs ü¶ï
3886,@rasbt,2022-08-08 14:38:11+00:00,https://twitter.com/rasbt/status/1556650986458021893,"Recently, ""traditional"" computer visionists tried to revive ye goode olde convolutional neural nets:

""A ConvNet for the 2020s"" aka ConvNeXt (https://t.co/4ZBTcMtyX3).

Round 2Ô∏è‚É£: Sparse 51x51 kernels via ""More ConvNets in the 2020s"" (https://t.co/iv4hUsGXD5) https://t.co/1btl3Qbsbu"
3887,@rasbt,2022-08-08 14:15:43+00:00,https://twitter.com/rasbt/status/1556645335174373379,"@TheZachMueller Wow nice, I did not know that! I remember everyone hating on the Microsoft acquisition a few years ago, but the GitHub web UI has really improved in leaps and bounds since then!"
3888,@rasbt,2022-08-08 14:14:06+00:00,https://twitter.com/rasbt/status/1556644929492893696,"@waynejwerner Huh, that's not a bad idea. The only issue is how do you keep track of which repo belongs to which, or do you just keep the original name on your local computer?"
3889,@rasbt,2022-08-08 13:57:17+00:00,https://twitter.com/rasbt/status/1556640694521024514,"ü™µ One common issue related to open source collabs is how to keep your fork up to date.

üç¥ In a nutshell, to sync your fork, you 
1) add the upstream repo as aremote
2) git fetch upstream
3) git merge upstream/main

Wrote a step-by-step guide here:
https://t.co/xS5dESMNXw https://t.co/nrarvUh80H"
3890,@rasbt,2022-08-08 00:11:06+00:00,https://twitter.com/rasbt/status/1556432779650424832,"@jjerphan Thanks for the pointer, I think someone mentioned this once to me in a conversation but I never found the website"
3891,@rasbt,2022-08-07 20:33:41+00:00,https://twitter.com/rasbt/status/1556378065948876803,"@ItaDude Doesn't mean you have to create constantly, or a lot üòÖ. It's just another way of saying ""quality over quantity"" üòÜ"
3892,@rasbt,2022-08-07 20:29:53+00:00,https://twitter.com/rasbt/status/1556377107642699780,"Make something that brings more value to people than the effort it took you to create. 
That's how you add value to the community."
3893,@rasbt,2022-08-07 17:28:12+00:00,https://twitter.com/rasbt/status/1556331385723445249,"@tunguz A naive Bayes classifier. Was part of a Statistical Pattern Recognition course I took back then. 
(I think my 2nd one was k-nearest neighbors)"
3894,@rasbt,2022-08-07 17:17:32+00:00,https://twitter.com/rasbt/status/1556328702342008832,@aniketmaurya Rust!
3895,@rasbt,2022-08-07 16:54:28+00:00,https://twitter.com/rasbt/status/1556322897786015744,"Whether it's PyTorch, TensorFlow, or Jax ...
üëæ they are all array libraries under the hood using a NumPy-like API .
 
Before you dive into deep learning libraries, I highly recommend learning the NumPy basics!

https://t.co/SkStNbFy9u"
3896,@rasbt,2022-08-07 16:38:13+00:00,https://twitter.com/rasbt/status/1556318809186787330,@JackRoberts1989 I am using Juypyter notebooks as templates for markdown/mkdocs documentation. And this looks super useful actually -- can make it part of the .github workflow recipe for PRs.
3897,@rasbt,2022-08-07 16:36:53+00:00,https://twitter.com/rasbt/status/1556318472937869312,@FloodSmartCity üôÄ
3898,@rasbt,2022-08-07 16:36:13+00:00,https://twitter.com/rasbt/status/1556318306054946820,"@sjogren_rickard Ah yes, that's a good one"
3899,@rasbt,2022-08-06 21:10:45+00:00,https://twitter.com/rasbt/status/1556025003988115459,@TheFucking22 I have a short summary here: https://t.co/sNoGjsyPu3
3900,@rasbt,2022-08-06 21:09:43+00:00,https://twitter.com/rasbt/status/1556024746847903751,"@StreetEYE Thanks, bookmarked! Haven't heard of this."
3901,@rasbt,2022-08-06 19:38:48+00:00,https://twitter.com/rasbt/status/1556001865057320962,@doomie @DynamicWebPaige I'm sorry for their loss
3902,@rasbt,2022-08-06 19:31:00+00:00,https://twitter.com/rasbt/status/1555999903398219777,"üíØ‚ÄºÔ∏è
PCA is an oldie but goodie. Something that truly stood the test of time.

Some additional PCA-EDA related things that often come in handy: 
1Ô∏è‚É£ Factor loadings
2Ô∏è‚É£ Cumulative variance-explained plots
3Ô∏è‚É£ Correlation circles https://t.co/d32SNZzvVO"
3903,@rasbt,2022-08-06 19:17:42+00:00,https://twitter.com/rasbt/status/1555996554263203841,"@mdhvince üíØ
I do it manually (automatically), too. Muscle memory"
3904,@rasbt,2022-08-06 17:28:53+00:00,https://twitter.com/rasbt/status/1555969168817766402,"@tunguz I guess it's probably doable ... if you have a strong programming, computer science, statistics, and machine learning background as prerequisite"
3905,@rasbt,2022-08-06 16:05:13+00:00,https://twitter.com/rasbt/status/1555948116611850240,@leonpalafox @JulienMouchnino ü™µü™µ
3906,@rasbt,2022-08-06 15:16:22+00:00,https://twitter.com/rasbt/status/1555935822033059840,"@fractalfoxnode @arian_jamasb Works like a charm! (haha, well, you don't load all 200M structures at the same time üòÜ)"
3907,@rasbt,2022-08-06 14:53:21+00:00,https://twitter.com/rasbt/status/1555930028340281344,"Want to tinker with the 200M+ protein structures from AlphaFold in your favorite DataFrame format (pandas!)‚ÅâÔ∏è 

Thanks to a kind contribution by @arian_jamasb, this is now possible in the latest BioPandas dev version as of this morning!

https://t.co/CO6DnCcEb2 https://t.co/2fO7bBv172"
3908,@rasbt,2022-08-06 14:17:23+00:00,https://twitter.com/rasbt/status/1555920980094205952,"@RobertERitz @__mharrison__ @PCacioppi @porestar ""Different isn‚Äôt bad necessarily."" üíØ
This is the right answer. My first reaction was ""ugh, this looks bad"" but then at a 2nd glance, it looks actually really compact and efficient. It's actually cool stuff @__mharrison__ 
 (It's just me not using pandas to its full potential üòÖ)"
3909,@rasbt,2022-08-06 14:15:00+00:00,https://twitter.com/rasbt/status/1555920378324729860,@JulienMouchnino Haha Python is not JavaScript or CSS
3910,@rasbt,2022-08-06 14:14:02+00:00,https://twitter.com/rasbt/status/1555920134539280387,"@myjoyone Yeah, that's a good recommendation. Also had a black formatter in VSCode enabled that formatted the code upon saving. However, I actually found that a tad too distracting. 
It's like when I write blog posts, I usually just write, and then as the final step I would format it"
3911,@rasbt,2022-08-06 14:12:51+00:00,https://twitter.com/rasbt/status/1555919836420743169,"@deepclaudeart I am a bit late to the party, but I use black these days."
3912,@rasbt,2022-08-06 14:12:00+00:00,https://twitter.com/rasbt/status/1555919621701648384,"@turboCodr It's like: if the author doesn't even know about common Python conventions, how do I know that the rest of the code is any good?"
3913,@rasbt,2022-08-06 14:11:06+00:00,https://twitter.com/rasbt/status/1555919396714987520,"@turboCodr Maybe a chicken-egg problem, but I developed a really strong dislike for non-properly formatted code. Actually, there were some O'Reilly books I stopped reading because I couldn't handle the author's misuse of whitespaces."
3914,@rasbt,2022-08-06 14:07:54+00:00,https://twitter.com/rasbt/status/1555918592511819776,"@Ihor_Bobak @nassarhuda I think it is popular in academics and statistics departments as alternative to R for scaling purposes, but yeah, I haven't heard about anyone using it in production"
3915,@rasbt,2022-08-06 14:05:12+00:00,https://twitter.com/rasbt/status/1555917914351587331,@aasifnawaz007 Looks like they have instructions here in the Readme: https://t.co/ZVsLpYbR6R
3916,@rasbt,2022-08-06 13:52:47+00:00,https://twitter.com/rasbt/status/1555914788378648577,"@ludwig_stumpp I tried it many times. And I still can't put my finger on it. I guess I just prefer the simplicity and look.
(I do use VSCode for almost everything else though)"
3917,@rasbt,2022-08-06 13:50:23+00:00,https://twitter.com/rasbt/status/1555914182515728384,"‚≠ïÔ∏è The machine learning circle of life: using ML for monitoring your ML logs.

ü§Ø Fun fact: Log management is a $2.3 billion market! (https://t.co/FNIETriSj9) https://t.co/CdeDE01oNm"
3918,@rasbt,2022-08-05 21:25:29+00:00,https://twitter.com/rasbt/status/1555666327104376832,@GaelVaroquaux that's an excellent point
3919,@rasbt,2022-08-05 20:59:24+00:00,https://twitter.com/rasbt/status/1555659763085705216,"@BonoboPhilipp I was thinking of a ML class where the students have template notebooks that they have to fill out with correct solutions (boilerplate code given, crucial parts missing).
But yeah, what you said essentially: maybe teach readable code but also allow them to press the button :P"
3920,@rasbt,2022-08-05 19:55:53+00:00,https://twitter.com/rasbt/status/1555643775615209473,"@PiotrZelasko Interesting! May try this, but I worry it might be a bit too distracting üòÖ.
(For VSCode I also turned off formatting on save and defer it to a pre-commit hook now.)"
3921,@rasbt,2022-08-05 19:27:59+00:00,https://twitter.com/rasbt/status/1555636755390517248,"* I used to export notebooks to .py scripts to format them.

**This is also great for reading other people's code in collaborations or when grading Jupyter nb-based homework assignments! üòÜ"
3922,@rasbt,2022-08-05 19:27:58+00:00,https://twitter.com/rasbt/status/1555636753196847105,"Love using Jupyter nbs for teaching and really wish I discovered this earlier ...

Try 
‚å®Ô∏è conda install -c conda-forge jupyterlab_code_formatter black isort

It will add a handy button for black &amp; isort formatting INSIDE Jupyter Notebook/Lab (goodbye manual formatting!) https://t.co/g9qBIJ5MJu"
3923,@rasbt,2022-08-05 18:35:16+00:00,https://twitter.com/rasbt/status/1555623489083740163,"TorchDynamo: Another cool way of speeding up BERT in PyTorch up to 3-fold! 

It's based on kernel fusion (meaning: replacing a series of operations with a single one to reduce overhead). But no worries, no model code changes required!

https://t.co/ilnUwNMAZW https://t.co/SowslerU4P"
3924,@rasbt,2022-08-05 15:23:07+00:00,https://twitter.com/rasbt/status/1555575134634795010,@TheFucking22 Linux users ü§∑‚Äç‚ôÇÔ∏èüòÇ
3925,@rasbt,2022-08-05 15:19:34+00:00,https://twitter.com/rasbt/status/1555574237456486401,@TheFucking22 üëÄ can't wait to get my hands on the M2
3926,@rasbt,2022-08-05 15:12:36+00:00,https://twitter.com/rasbt/status/1555572486967795712,@__mharrison__ @dabeaz @porestar 2/2 But say you build this pipeline incrementally. What's the point of going back and rewriting it in this compact form vs having it as individual steps? I feel like it makes it harder to inspect for people who use / look at the code (or future self).
3927,@rasbt,2022-08-05 15:10:58+00:00,https://twitter.com/rasbt/status/1555572076374786048,"@__mharrison__ @dabeaz @porestar Didn't get to that chapter yet üòÖ. But yeah, data exploration and processing is usually very iterative &amp; interactive (at least how I do it). 1/2"
3928,@rasbt,2022-08-05 15:01:38+00:00,https://twitter.com/rasbt/status/1555569726063104000,"ü§î ""Professional ML engineers: How much of your day to day job involves math and proofs?""

üî• ""I've spent way more time installing cuda drivers than proving theorems""

(I think my last time proving a theorem was 2019/20ish, and I am not looking backüòÖ)

(https://t.co/H9uclC2H2T)"
3929,@rasbt,2022-08-05 14:40:53+00:00,https://twitter.com/rasbt/status/1555564506302107649,@danofer @KevinKaichuang and NLP!
3930,@rasbt,2022-08-05 14:40:23+00:00,https://twitter.com/rasbt/status/1555564377125920768,"@iandanforth Yes, that's a good way to approach it:
1) Zero-rule classifier as a baseline
2) Use a heuristic if applicable
2) Conventional ML model as baseline
4) A neural net
5) If neural net doesn't train well, try to overfit and debug"
3931,@rasbt,2022-08-05 14:38:39+00:00,https://twitter.com/rasbt/status/1555563940767227905,"@gusthema Yeah, an oldie but goodie. I think it goes back to @karpathy's excellent blog post ""A Recipe for Training Neural Networks"" https://t.co/m3WXaZyH7Z"
3932,@rasbt,2022-08-05 14:30:33+00:00,https://twitter.com/rasbt/status/1555561904730521612,"@ID_AA_Carmack @hardmaru Nice, looking forward to it! This may be the podcast episode that gets me back to listening to his channel."
3933,@rasbt,2022-08-05 14:01:11+00:00,https://twitter.com/rasbt/status/1555554515448958976,@__mharrison__ @porestar How do you even debug that? üòÖ
3934,@rasbt,2022-08-05 13:58:22+00:00,https://twitter.com/rasbt/status/1555553802882895872,"You are likely using DistilBert vs Bert due to the smaller memory footprint.

But check this out: 
ü¶æ 7x speed-up via quantization (32 bit floats -&gt; 8 bit ints) alone. 

Cost? A meager &lt;1% F1 score decrease ü§∑‚Äç‚ôÇÔ∏è

If you are not already quantizing... 
https://t.co/xoXE0BbUW4 https://t.co/GLRff3jALE"
3935,@rasbt,2022-08-04 20:24:15+00:00,https://twitter.com/rasbt/status/1555288526685609984,"@chris_j_beckham @PyTorchLightnin Yeah, minmax scaling within [-1, 1] range is a nice go-to. Also much less work for image data compared to z-score normalization (/standardization)"
3936,@rasbt,2022-08-04 20:15:00+00:00,https://twitter.com/rasbt/status/1555286200004534273,"Since this seriously helped a friend the other day: If your network doesn't learn, reduce the dataset to a small batch (eg 32 examples) and try to overfit on it. The loss should be near zero (because the network should be able to memorize it); if not, there's a bug in your code."
3937,@rasbt,2022-08-04 20:07:48+00:00,https://twitter.com/rasbt/status/1555284388878979072,"@PyTorchLightnin Surprised why a/any model doesn't perform well on a given task? 
Pick 100 random examples from the validation dataset and try to label them yourself; compare the labels to the given labels.
a) Good way to establish a baseline
b) Also a good exercise for discovering label issues"
3938,@rasbt,2022-08-04 20:04:47+00:00,https://twitter.com/rasbt/status/1555283629202460674,"@PyTorchLightnin Haha, there are so many! 
Adam, skip connections, He initialization, and to some extend BatchNorm -- they are all &gt; 7 years old and are still solid techniques to make things work well."
3939,@rasbt,2022-08-04 19:43:10+00:00,https://twitter.com/rasbt/status/1555278190381342721,"@porestar @__mharrison__ Haha, üíØ!"
3940,@rasbt,2022-08-04 14:02:25+00:00,https://twitter.com/rasbt/status/1555192436229562369,@__mharrison__ which programming language is this ü§Ø
3941,@rasbt,2022-08-04 13:59:48+00:00,https://twitter.com/rasbt/status/1555191778759872512,"@nachimak28 Awesome, glad to hear!"
3942,@rasbt,2022-08-04 13:43:32+00:00,https://twitter.com/rasbt/status/1555187682917208064,"@LukasGalke @eamonndunne yeah, that's a good question. My vague answer is that I guess that it's a mix of both and heavily dependents on the application."
3943,@rasbt,2022-08-04 13:40:51+00:00,https://twitter.com/rasbt/status/1555187008083054593,"You are machine learning in the wild, some of MUST be working with ordered labels ‚ÅâÔ∏è

I bet you are curious to learn more about 
""Using Deep Learning When Class Labels Have A Natural Order"" üòÅ #scipy2022 
https://t.co/SGKpqXAufF"
3944,@rasbt,2022-08-04 13:35:07+00:00,https://twitter.com/rasbt/status/1555185566249062400,"Wohoo, @SciPyConf 2022 talks are now all on YouTube!
üèñÔ∏è No weekend plans, yet? 
Here is the playlist for the Machine Learning &amp; Data Science Track: https://t.co/VcpL24YpGM"
3945,@rasbt,2022-08-04 13:22:36+00:00,https://twitter.com/rasbt/status/1555182415433310211,"@eamonndunne Actually, I think it means having that many model in production simultaneously at all times. E.g., Netflix deploys/updates 1000s of models every day. AWS deploys/updates a model every 10 seconds."
3946,@rasbt,2022-08-04 13:16:48+00:00,https://twitter.com/rasbt/status/1555180956184616962,"Interesting machine tidbit: Most companies don't deploy ""a"" machine learning model. 
ü§Ø 40% of companies have more than 50 machine learning models in production. 
And at big companies with &gt;25k employees, 41% have &gt;100 models in production! 
(Algorithmia: https://t.co/yCkdrqkQ4b)"
3947,@rasbt,2022-08-04 01:31:20+00:00,https://twitter.com/rasbt/status/1555003420079230976,"FYI: just stumbled upon this pretty cool baseline overview page for tabular, image, text, and audio data: https://t.co/iQQRZ8YHY0"
3948,@rasbt,2022-08-03 22:23:56+00:00,https://twitter.com/rasbt/status/1554956260856025089,"@NLPParrot Haha, was about to CC you @zacharylipton. Plot twist: just saw you are one of the co-authors. 
Anyways, looks great, bookmarked!!"
3949,@rasbt,2022-08-03 15:17:50+00:00,https://twitter.com/rasbt/status/1554849029405696000,"@jmschreiber91 @NumFOCUS Wait what, for real? From our last tweet convo I was 50/50 on whether this was sarcasm or not ... and eventually I decided this tweet was by @jmschreiber91 so this must be sarcasm. Anyways, that's an exciting development, wohoo ü•≥"
3950,@rasbt,2022-08-03 14:37:23+00:00,https://twitter.com/rasbt/status/1554838847653019653,"@chris_j_beckham @CSProfKGD @EugeneVinitsky That's sounds interesting &amp; tempting! But I am torn on this! Actually, I promised myself not to start any new projects until fall/winter (when I hope to have completed my current stack) üòÖ. Sorry, but I think I should say ""no"" for now üò∞"
3951,@rasbt,2022-08-03 14:04:56+00:00,https://twitter.com/rasbt/status/1554830683339493376,"@micahgoldblum @Harcel Good point. I think it could depend on the venue &amp; how ""traditional"" the reviewers are."
3952,@rasbt,2022-08-03 13:51:55+00:00,https://twitter.com/rasbt/status/1554827404601806851,"@Harcel Nope, unfortunately not. Have to resubmit some time. Lesson learned: Never use ""simple"" in a paper title."
3953,@rasbt,2022-08-03 13:43:42+00:00,https://twitter.com/rasbt/status/1554825339423055872,"PS: Also, in a similar vein, a lot of science isn't groundbreaking, and that's a good thing. A lot of scientific progress is made by solid, incremental research."
3954,@rasbt,2022-08-03 13:43:27+00:00,https://twitter.com/rasbt/status/1554825274713415680,"üíØ! Simplicity is a strength.

In a recent paper submission:

Reviewer 1: ""the proposed methods are simple yet effective in outperforming existing methods"" (accept)

Reviewer 2: ""the method is too simple, almost like a trick"" (reject)  ü§∑‚Äç‚ôÇÔ∏è"
3955,@rasbt,2022-08-03 13:29:28+00:00,https://twitter.com/rasbt/status/1554821757789511680,"@hugo_larochelle @kchonyc @BeEngelhardt @NailaMurray Nice, this is really awesome üéâ. I think decoupling paper submissions from presentation slots might be the way forward as the community keeps growing."
3956,@rasbt,2022-08-03 13:24:12+00:00,https://twitter.com/rasbt/status/1554820431001141251,"@chris_j_beckham @CSProfKGD @EugeneVinitsky I remember it as a nice &amp; easy read! Btw I feel you: every time I give a talk about ordinal methods for deep learning, there seems to be a lack of enthusiasm among the audience -- despite the fact that many real-world problems are ordinal, people prefer to throw classifiers at it"
3957,@rasbt,2022-08-03 13:20:01+00:00,https://twitter.com/rasbt/status/1554819379539369986,"Speaking of good baselines, here's a good rule of thumb: 

üìà If you think that machine learning will give you a 100% boost, then a heuristic will get you 50% of the way there.

(Source: Rules of machine learning, https://t.co/52EkIzIEeq)"
3958,@rasbt,2022-08-03 02:00:58+00:00,https://twitter.com/rasbt/status/1554648489350643712,Our new state-of-the-art method ...
3959,@rasbt,2022-08-03 01:51:58+00:00,https://twitter.com/rasbt/status/1554646224279687168,@chris_j_beckham @CSProfKGD @EugeneVinitsky *your
3960,@rasbt,2022-08-03 01:50:55+00:00,https://twitter.com/rasbt/status/1554645961787547649,"@chris_j_beckham @CSProfKGD @EugeneVinitsky PPS: It's been many years and I think there was a conceptual issue (dot product is position invariant), but nonetheless I think it worked quite well."
3961,@rasbt,2022-08-03 01:50:29+00:00,https://twitter.com/rasbt/status/1554645849745100801,"@chris_j_beckham @CSProfKGD @EugeneVinitsky PS: Small world! Your name sounds familiar (no, I am not referring to the soccer player). Actually implemented our squared error approach a while back (https://t.co/9h6HRrCcSk)."
3962,@rasbt,2022-08-03 01:47:31+00:00,https://twitter.com/rasbt/status/1554645103146303488,"@chris_j_beckham @EugeneVinitsky Actually, reviewers are obsessed with it as well. Funny coincidence: just got back reviews where the reviewer said we cannot say our method SOTA since we didn't compare it to xyz. Joke is that I specifically avoided the term SOTA and only compared to closely related methods. ü§∑‚Äç‚ôÇÔ∏è"
3963,@rasbt,2022-08-03 01:44:46+00:00,https://twitter.com/rasbt/status/1554644413745401856,@chris_j_beckham @CSProfKGD @EugeneVinitsky Thanks for this! üëå
3964,@rasbt,2022-08-03 01:41:26+00:00,https://twitter.com/rasbt/status/1554643573727002631,@CSProfKGD üíØ https://t.co/KyZ5DHPYWH
3965,@rasbt,2022-08-02 19:21:41+00:00,https://twitter.com/rasbt/status/1554548007558959104,"@yaroslavvb haha, sounds like reviewers #2 looked for a place to vent"
3966,@rasbt,2022-08-02 16:04:07+00:00,https://twitter.com/rasbt/status/1554498286714765319,@LeopolisDream Basically another form of overfitting :P
3967,@rasbt,2022-08-02 16:03:44+00:00,https://twitter.com/rasbt/status/1554498188916162566,"@tunguz The GitHub repo corresponding to the paper mentioned above shares the corrected test set labels (https://t.co/KREP6qa7Sq). Can't remember where (would have to search for it), but I am somewhat certain that there was another paper/repo that shared a corrected version"
3968,@rasbt,2022-08-02 15:57:45+00:00,https://twitter.com/rasbt/status/1554496686390738945,@AMULETAnalytics @joshuastarmer thanks for the kind words ü•∞
3969,@rasbt,2022-08-02 15:57:23+00:00,https://twitter.com/rasbt/status/1554496592958394370,"@JulienMouchnino Good question, I remember I talked about it in a couple of podcasts, e.g. somewhere in https://t.co/G4RA3T8lt8. But in general, I'd say the key is to organize resources and write them down somewhere but resist to read everything or you will end up wasting time on irrelevant stuff"
3970,@rasbt,2022-08-02 13:35:08+00:00,https://twitter.com/rasbt/status/1554460794116612098,@JulienMouchnino My guess is that it happened accidentally when the dataset was created.
3971,@rasbt,2022-08-02 13:26:18+00:00,https://twitter.com/rasbt/status/1554458573396234241,"A friendly reminder that the base error on CIFAR-100 is a whopping 5.85% due to mislabeling (https://t.co/fWOvTHPxRx). 

‚ö†Ô∏è This makes any model above 94.15% acc suspicious! 

üìµ Also, 10% of CIFAR-100 training set images are duplicated in the test set! (https://t.co/a5v4U0WnXI) https://t.co/JKtjm3YVJV"
3972,@rasbt,2022-08-02 13:09:42+00:00,https://twitter.com/rasbt/status/1554454392417427456,"@agustinilt Not a must, but I think it would be the most useful BSc. You can also get into ML from other fields, and e.g., Physics, Math, or Stats are useful BSc degrees to have if you want to work on ML from a more theoretical angle"
3973,@rasbt,2022-08-02 13:07:49+00:00,https://twitter.com/rasbt/status/1554453919782387714,@sinatv52 üíØ
3974,@rasbt,2022-08-01 23:06:21+00:00,https://twitter.com/rasbt/status/1554242158248579078,"‚ù§Ô∏è‚Äçüî• Machine learning is maybe the most fun but also the most challenging field 
üå± Building and maintaining math, programming, and software engineering foundations is one part. 
üî• The other part is ALWAYS catching up &amp; learning something new every day or getting left behind."
3975,@rasbt,2022-08-01 22:40:11+00:00,https://twitter.com/rasbt/status/1554235571735855105,@_florianmai you are reviewer #2?
3976,@rasbt,2022-08-01 21:23:52+00:00,https://twitter.com/rasbt/status/1554216368622522369,"@pipechuncho813 @joshuastarmer Thanks for your interest! Controversial topic these days, but I'd say Amazon (fastest shipping and usually lowest price https://t.co/vQv1P30OFR)"
3977,@rasbt,2022-08-01 17:02:09+00:00,https://twitter.com/rasbt/status/1554150504162369536,"@fchollet ""Invented"" new words or just translated proper nouns from the original English version -&gt; French? üòÜ"
3978,@rasbt,2022-08-01 16:53:08+00:00,https://twitter.com/rasbt/status/1554148236507680768,"@Dennis_PBS @joshuastarmer Wohoo, glad to hear you liked it!!"
3979,@rasbt,2022-08-01 15:53:48+00:00,https://twitter.com/rasbt/status/1554133304332492800,@joshuastarmer üëÄ
3980,@rasbt,2022-08-01 15:42:18+00:00,https://twitter.com/rasbt/status/1554130410027847681,@Ukerzel I agree that it doesn't really matter. There is also no right or wrong. Someone just brought up the discussion the other day and I am just surveying what the popular take on this is üòÖ
3981,@rasbt,2022-08-01 14:45:47+00:00,https://twitter.com/rasbt/status/1554116185771462656,"@mariotelfig 4 hours left, but so far, it looks like you win! üòÜ
https://t.co/7V0YWuighe https://t.co/1fGWWnA5vo"
3982,@rasbt,2022-08-01 14:13:05+00:00,https://twitter.com/rasbt/status/1554107956752486400,"Reviewers will ALWAYS ask you to add something. 
Before submitting your paper, remove one obvious experiment (e.g., an ablation study you already completed). After the rebuttal, just add it back. 
This saves you from unreasonable experiments.
Editors hate this one weird trick ü§∑‚Äç‚ôÇÔ∏è"
3983,@rasbt,2022-08-01 13:56:45+00:00,https://twitter.com/rasbt/status/1554103847462764545,"Multilayer perceptrons with 1 or 2 hidden layers are ...

(*deep learning if they use one or more techniques like BatchNorm, Dropout, skip connections, etc.)"
3984,@rasbt,2022-08-01 13:46:21+00:00,https://twitter.com/rasbt/status/1554101229969620996,@mariotelfig Maybe representation learning is not such a good term for identifying what differentiates deep learning from other types of machine learning. Coz you can also say that any stacking classifier is doing representation learning.
3985,@rasbt,2022-08-01 13:40:08+00:00,https://twitter.com/rasbt/status/1554099662663155717,"Yes! This includes one my favorite baselines: random forests. 
You can use

from cuml import RandomForestClassifier

as a drop-in replacement for scikit-learn's RandomForestClassifier"
3986,@rasbt,2022-08-01 02:37:58+00:00,https://twitter.com/rasbt/status/1553933023871115269,"@tdietterich * ""Replace"" is almost the wrong word, because if you update (""replace"") the article on arxiv, you can still cite a previous version if you want to."
3987,@rasbt,2022-08-01 02:36:37+00:00,https://twitter.com/rasbt/status/1553932686061965314,"@tdietterich As an author, what version do I want the audience to read? I think the answer is the most up to date version. I bet the authors would recommend the readers to read the updated journal version over the conference version; so it should also be used to update the arxiv conf version"
3988,@rasbt,2022-07-31 13:28:41+00:00,https://twitter.com/rasbt/status/1553734395969912832,"@mariotelfig Sure, that's maybe a philosophical debate similar to ""what is the definition of data science."" But a multilayer perceptron with one or two hidden layer is, to me, not ""deep"" enough to call it DL. And it also doesn't have the implicit ""representation learning"" CNNs have etc."
3989,@rasbt,2022-07-30 15:45:05+00:00,https://twitter.com/rasbt/status/1553406334351048705,"@srvmshr @askerlee @AdamWHarley *I think we need to introduce different levels of reviews: technical vs. conceptual to improve quality, and also to make best use of everyone's skills and time."
3990,@rasbt,2022-07-30 15:44:03+00:00,https://twitter.com/rasbt/status/1553406074362920960,"@srvmshr @askerlee @AdamWHarley 2/2 At the same time, not every type of review should be a accept/reject decision. Are some technical details not 100% fleshed out but correct? No reason for rejection, but still useful review information that the author could and should use to improve the paper."
3991,@rasbt,2022-07-30 15:42:58+00:00,https://twitter.com/rasbt/status/1553405800202264577,"@srvmshr @askerlee @AdamWHarley A few years ago üíØ agreed with this. But today I am not so sure anymore. There are things that more senior reviewers don't look at: is the code correct, do certain little nitpicky checks to improve the technical details. There is absolutely a place for that to improve science 1/2"
3992,@rasbt,2022-07-30 15:39:05+00:00,https://twitter.com/rasbt/status/1553404822560378881,"@Dahmane_Bnr Nice, thanks for the suggestion. There are already 2 or 3 method in the list that convert tabular data into 2D ""images"" for ConvNets, but I will have a look at the papers and see if it makes sense to add them! seems like lots of researchers proposed similar methods üòÜ"
3993,@rasbt,2022-07-29 20:52:16+00:00,https://twitter.com/rasbt/status/1553121249143955457,"@zacharylipton I see. Yeah, I agree. I think there is a big problem with hyping/overselling things in research atm."
3994,@rasbt,2022-07-29 20:45:29+00:00,https://twitter.com/rasbt/status/1553119543610032130,"@zacharylipton Just to make sure we are talking about the same thing here:  do you dislike (1) feature importance methods in general, (2) equating feature importance with explanation (w that I agree), (3) the prob with SHAP for certain models (non-0 values for noise features); or (4) sth else?"
3995,@rasbt,2022-07-29 20:29:15+00:00,https://twitter.com/rasbt/status/1553115458865356800,"@ChristophMolnar Sure, we actually had a discussion about that here the other day üòÖ https://t.co/I60YM5I7eE"
3996,@rasbt,2022-07-29 20:28:02+00:00,https://twitter.com/rasbt/status/1553115151720747009,"@zacharylipton *There is nothing wrong with the method the same way there is nothing wrong with accuracy as a metric. It computes the proportion of correct predictions. Nothing more nothing less. 
Sure, there a people who misuse/misquote SHAP etc. But there are also people who misuse ACC."
3997,@rasbt,2022-07-29 20:25:31+00:00,https://twitter.com/rasbt/status/1553114521090277378,"@zacharylipton If you compare SHAP and permutation importance (or drop-a-feature) side by side, you get a pretty high correlation. 
Consequently, you can use that as a proxy for how much the model relies on a given feature to make a prediction. There is nothing wrong with the method itself."
3998,@rasbt,2022-07-29 20:00:29+00:00,https://twitter.com/rasbt/status/1553108217785360384,"This is actually really amazing. üôå
With EfficientNetV2, you now get a model that achieves 98% Top-5 accuracy on ImageNet out of the box in few lines of code! https://t.co/Ryu2hXGrmk"
3999,@rasbt,2022-07-29 15:43:25+00:00,https://twitter.com/rasbt/status/1553043524974546944,"I am fighting overcommitment EVERY SINGLE DAY! It's hard.
Here is a little hack that actually helps (a bit)! https://t.co/jyjmJyilxL"
4000,@rasbt,2022-07-29 15:30:36+00:00,https://twitter.com/rasbt/status/1553040303006834688,"@hsuyab @tomgoldsteincs Haha, yes, in my lecture I actually refer to linear regression as a type of single-layer ""neural network"" indeed üòÜ"
4001,@rasbt,2022-07-28 21:53:36+00:00,https://twitter.com/rasbt/status/1552774300154974208,@tomgoldsteincs Neural Additive Models üòõ https://t.co/gVqX1YQU1Z
4002,@rasbt,2022-07-28 19:57:04+00:00,https://twitter.com/rasbt/status/1552744973283606530,"@xamat Hah, yeah, and search engines pretty much prepared us for this for years
https://t.co/Pn2EBvZJKf"
4003,@rasbt,2022-07-28 19:22:38+00:00,https://twitter.com/rasbt/status/1552736305448210436,@PyTorchLightnin Confidence intervals are missing
4004,@rasbt,2022-07-28 16:58:48+00:00,https://twitter.com/rasbt/status/1552700110668177409,"The ‚ú®Deep Learning for Tabular Data‚ú® chronology just got a big update! 
https://t.co/VAXJRBMyzj

Added 7 additional deep tabular methods to the list! (Marked as ""New Since Last Edit""). 

Thanks everyone for all the good paper recommendations! üôå"
4005,@rasbt,2022-07-28 16:51:25+00:00,https://twitter.com/rasbt/status/1552698250402095107,"@DHolzmueller Just read the paper and added it. This was actually a great suggestion, thanks again for bringing it up!"
4006,@rasbt,2022-07-28 16:35:57+00:00,https://twitter.com/rasbt/status/1552694358306160646,@YuraFiftyTwo Just checked out the papers and they are all great suggestions. Added them to the article. Thanks again!
4007,@rasbt,2022-07-28 13:55:45+00:00,https://twitter.com/rasbt/status/1552654042664300544,@RayBell_DTN haha wow
4008,@rasbt,2022-07-28 13:53:31+00:00,https://twitter.com/rasbt/status/1552653479709065222,"@manujosephv Great suggestions, just added both to the article. GATE was super recent, totally missed that! For AutoInt, I think its more aimed at recommender datasets, but I can't see why it can't be applied to regular tabular datasets as well, so I added that, too. Thanks again!"
4009,@rasbt,2022-07-27 12:12:32+00:00,https://twitter.com/rasbt/status/1552265679667138560,Made a video about this back then here: https://t.co/nJqVM72awA
4010,@rasbt,2022-07-27 12:11:52+00:00,https://twitter.com/rasbt/status/1552265510552838145,"I have a love-hate relationship with this paper üòÜ. When I shared it with my class they were more confused about transposed convolution than before. 
Had to wrap my head around this until I realized 
transposed convolution (top) == fractionally strided convolution (bottom) https://t.co/7AY0cjj559"
4011,@rasbt,2022-07-27 01:58:08+00:00,https://twitter.com/rasbt/status/1552111059552686080,"@xamat Maybe bright but very boring üôÉ. (Sorry, no offense if you are into SEO I guess üò¨)"
4012,@rasbt,2022-07-27 00:43:06+00:00,https://twitter.com/rasbt/status/1552092180424032256,@itamarst Thanks for sharing! Bookmarked and will check it out!
4013,@rasbt,2022-07-26 22:51:22+00:00,https://twitter.com/rasbt/status/1552064059918401538,"@LMalloy @roydanroy Sorry to hear :(. Sadly this happened to me before when I was a grad student. Resubmitted somewhere else and got luckier. Whether it's journals or conferences, academic publishing remains a lottery üò©"
4014,@rasbt,2022-07-26 22:48:17+00:00,https://twitter.com/rasbt/status/1552063284727136256,@roydanroy and they aren't cheap either üôÉ
4015,@rasbt,2022-07-26 22:47:35+00:00,https://twitter.com/rasbt/status/1552063107652009986,@roydanroy *aren‚Äôt awful.
4016,@rasbt,2022-07-26 22:25:28+00:00,https://twitter.com/rasbt/status/1552057542301319168,What do cookie cutters and bears have in common? üôÉ https://t.co/vZL4XP1p6r
4017,@rasbt,2022-07-26 13:24:38+00:00,https://twitter.com/rasbt/status/1551921438126383108,"@tushar__3 Nice, thanks, I will add it this week when I get a chance."
4018,@rasbt,2022-07-26 12:57:14+00:00,https://twitter.com/rasbt/status/1551914542220935168,"@tushar__3 Thanks for sharing! Do I understand this correctly: You first train XGBoost models and derive feature importances. Then, you use the feature importances to initialize the weights of a neural network (what type, multilayer perceptron?)"
4019,@rasbt,2022-07-26 12:41:42+00:00,https://twitter.com/rasbt/status/1551910632529739776,"@ljbuturovic I was more thinking of the experiments you ran along with the training logfiles. Not that I don't trust your results in particular, but I am nowadays too weary of papers that don't share the accompanying code to reproduce it."
4020,@rasbt,2022-07-26 03:11:25+00:00,https://twitter.com/rasbt/status/1551767114947641344,"@ljbuturovic Simple methods are the best baselines. Not only useful for ablation studies but they are usually also easier to implement and hence less error-prone, which is super valuable in practice."
4021,@rasbt,2022-07-26 03:03:20+00:00,https://twitter.com/rasbt/status/1551765082027212801,"@FaisalAlsrheed Thanks again for the pointers. Via the pytorch-tabular library I stumbled upon AutoInt, which is more geared towards recommender-system contexts but looks cool. Updated the article with a few more methods ... and will even more (by next weekend probably)"
4022,@rasbt,2022-07-26 01:33:19+00:00,https://twitter.com/rasbt/status/1551742427878268929,@ljbuturovic *Oh and do you have a code repository for this somewhere?
4023,@rasbt,2022-07-26 01:27:28+00:00,https://twitter.com/rasbt/status/1551740954037583872,"@ljbuturovic 2/2 Want to add your proposed method, but also want to provide a bit more context regarding how it differs. I think your method came before https://t.co/8lq15KVJPV when I see it correctly (and after 
https://t.co/ue0htyzj2z)"
4024,@rasbt,2022-07-26 01:26:23+00:00,https://twitter.com/rasbt/status/1551740681638625283,"@ljbuturovic Thx again for sharing! Was just skimming through your article &amp; based on my understanding, it's basically converting tab data into images as input to conventional 2D CNNs? 

Wonder if you could summarize how it differs from
https://t.co/8lq15KVJPV
&amp;
https://t.co/ue0htyzj2z
1/2"
4025,@rasbt,2022-07-26 01:21:29+00:00,https://twitter.com/rasbt/status/1551739449217875969,"@47apollo @ylecun @JFPuget Maybe the authors can chime in with the detailed info you are looking for! CC @JesseDodge
https://t.co/PN2jZfRuc9"
4026,@rasbt,2022-07-25 17:02:55+00:00,https://twitter.com/rasbt/status/1551613980514320386,"@GilmerValdes @tomgoldsteincs Yeah, I agree with that. Regarding the overfitting issue, that's hard to avoid though. For that you would need external validators or multiple Kaggle competitions."
4027,@rasbt,2022-07-25 16:42:14+00:00,https://twitter.com/rasbt/status/1551608776637161479,"@GilmerValdes @tomgoldsteincs The alternative is just keep using GB, which is fine, but it's also kind of boring when you are a researcher"
4028,@rasbt,2022-07-25 16:41:22+00:00,https://twitter.com/rasbt/status/1551608557786873856,"@GilmerValdes @tomgoldsteincs As I mentioned earlier, I recommend against using/starting with DL methods for tabular data when it comes to real-world problems. However, should people try to come up with new, weird, and creative ideas to see what works and what doesn't? The answer is also yes here imho."
4029,@rasbt,2022-07-25 16:39:31+00:00,https://twitter.com/rasbt/status/1551608091094949890,"@GilmerValdes @tomgoldsteincs Agree with you that it's not immediately obvious why they would work better. But I think the same was true when people developed other methods on general. It's about exploration at this point.
It doesn't have to be one or the other. E.g., consider NODE: https://t.co/JkFNi6i3O2"
4030,@rasbt,2022-07-25 16:28:30+00:00,https://twitter.com/rasbt/status/1551605321705164805,"@tlandgraf Just looked at the paper! It's actually a really nice one. I would say it's a bit out of scope wrt ""deep learning"" for tabular datasets, but I will surely mention it the next time I teach a lecture about nearest neighbor methods!"
4031,@rasbt,2022-07-25 16:05:49+00:00,https://twitter.com/rasbt/status/1551599612133359616,"@GilmerValdes @tomgoldsteincs Or in other words, results in papers are almost always biased in favor of the newly proposed method. Sure, there may be some papers where this is not the case, but even then it's impossible to know that it's not the case. Kaggle is a bit more objective."
4032,@rasbt,2022-07-25 16:04:26+00:00,https://twitter.com/rasbt/status/1551599265419595782,@GilmerValdes @tomgoldsteincs Yeah. I don't mind it too much though. I think most of the proposed methods are at least interesting. And whether it is truly better is hard to tell based on research papers anyway. We will know whether something is working well once people use it successfully on Kaggle.
4033,@rasbt,2022-07-25 15:57:08+00:00,https://twitter.com/rasbt/status/1551597425567174657,"@mikaelhuss Just added it here: https://t.co/aabvTx8RhK.
Thanks again! I am also particularly impressed by the large training sets they used for evaluation! https://t.co/wnMG3BOKmk"
4034,@rasbt,2022-07-25 12:53:55+00:00,https://twitter.com/rasbt/status/1551551317570732037,"@GilmerValdes @tomgoldsteincs 2/2 You can transfer certain information to a limited extend (meta-learning, hyperparameters, ensembles/stacking). 
Anyways, do you have any tree-based algorithms in mind that support conventional transfer learning? Just curious to hear &amp; want to add it to my repertoire."
4035,@rasbt,2022-07-25 12:52:51+00:00,https://twitter.com/rasbt/status/1551551050485833728,@GilmerValdes @tomgoldsteincs You can't easily change the structure of a tree. I remember there was a incremental random forest that could be probably used for transfer learning. But standard algorithms wouldn't support that 1/2
4036,@rasbt,2022-07-25 12:41:13+00:00,https://twitter.com/rasbt/status/1551548120928079872,"@YuraFiftyTwo Thanks, bookmarked and will check them out!"
4037,@rasbt,2022-07-25 12:40:37+00:00,https://twitter.com/rasbt/status/1551547970482569216,@DHolzmueller Thanks! Added to my list &amp; will take a look soon!
4038,@rasbt,2022-07-25 12:39:21+00:00,https://twitter.com/rasbt/status/1551547651354775552,"@HaffendenHector Hah, the lack of hype is a good or a bad thing? Btw glad you like the short write-up!!"
4039,@rasbt,2022-07-25 02:42:10+00:00,https://twitter.com/rasbt/status/1551397365298466818,"@isphus1973 Haha, nice timing. And I hope you are liking the book üòÜ!"
4040,@rasbt,2022-07-25 02:41:06+00:00,https://twitter.com/rasbt/status/1551397099543138305,"@manujosephv Awesome, thanks ‚ò∫Ô∏è! Looking forward to check those out tomorrow!"
4041,@rasbt,2022-07-24 23:23:48+00:00,https://twitter.com/rasbt/status/1551347445887602690,"@CSProfKGD I know it sounds counterintuitive, but I like the 16inch for  traveling. Of course the extra weight is annoying, but I like the extra screen estate and feel like I am way more productive on it. (Have a 16 inch MBP from work, and my private one is a 13 inch MBAir)."
4042,@rasbt,2022-07-24 23:18:16+00:00,https://twitter.com/rasbt/status/1551346052640432128,"@FaisalAlsrheed Thanks a lot, added it to the list of methods to check out later today / tomorrow morning üòä"
4043,@rasbt,2022-07-24 23:17:03+00:00,https://twitter.com/rasbt/status/1551345745810395136,"@ljbuturovic Thanks for sharing, bookmarked it and will check it out! üëå"
4044,@rasbt,2022-07-24 23:15:29+00:00,https://twitter.com/rasbt/status/1551345355266080770,"@kastnerkyle @ayirpelle Nice, thanks for the link! Bookmarked and will check it out!! üôå"
4045,@rasbt,2022-07-24 20:24:05+00:00,https://twitter.com/rasbt/status/1551302220636979200,"@V_J_S_1 üíØ! I do think it's worthwhile thinking about these things though. I mean, the status quo works well and all, but that's the only way you can make progress"
4046,@rasbt,2022-07-24 18:34:26+00:00,https://twitter.com/rasbt/status/1551274625878876160,"@tlandgraf Nice, have to check that out later!"
4047,@rasbt,2022-07-24 18:31:48+00:00,https://twitter.com/rasbt/status/1551273963141189633,"@mikaelhuss Nice, I remember NODE and knew I forgot something! Noted, bookmarked, and will add it later today! Thanks! üôå"
4048,@rasbt,2022-07-24 18:16:43+00:00,https://twitter.com/rasbt/status/1551270167350591488,@Frank37004246 I agree. I wouldn't make the claim that one is universally better than the other. I would say though that it is currently probably easier to get GBTs to work well on tabular data (in terms of resource and hyperparameter tuning budgets).
4049,@rasbt,2022-07-24 18:06:39+00:00,https://twitter.com/rasbt/status/1551267632199962625,"@Frank37004246 I haven't looked into those benchmarks, yet. I have mostly focused on data with independent features."
4050,@rasbt,2022-07-24 17:43:48+00:00,https://twitter.com/rasbt/status/1551261882341793792,"@Ukerzel Thanks! 
Vice versa, neural networks have been used a lot in computationaly biology, but in this case they were called deep learning although they were just multilayer perceptrons. E.g., this one comes to mind:  https://t.co/nZEkmd3wj8üòÜ.
Have to check out the paper you sent!"
4051,@rasbt,2022-07-24 17:15:43+00:00,https://twitter.com/rasbt/status/1551254813312163861,"@DrEliDavid Thanks, glad to hear! üôå"
4052,@rasbt,2022-07-24 17:05:48+00:00,https://twitter.com/rasbt/status/1551252319689400324,"A Short Chronology Of Deep Learning For Tabular Data:
https://t.co/VAXJRBMyzj

Deep tabular methods are an interesting research direction! So, this morning, I sat down and summarized my thoughts + the recent papers I read."
4053,@rasbt,2022-07-24 02:44:29+00:00,https://twitter.com/rasbt/status/1551035562680778755,"@JFPuget @RexDouglass That may be true. I can't recall much about analyzing overfitting in this paper (besides the tangentially related ""uninformative feature"" analysis)"
4054,@rasbt,2022-07-24 02:39:15+00:00,https://twitter.com/rasbt/status/1551034243194798090,"@JFPuget @RexDouglass Yeah, when you look at the 2D decision region plot, you would think that the RF would be way more likely to overfit. (I guess the MLP is maybe underfitting at this point) https://t.co/uvAsop1VTp"
4055,@rasbt,2022-07-24 02:35:19+00:00,https://twitter.com/rasbt/status/1551033255939506176,"@JFPuget @RexDouglass 2/2 Then, if we consider tree-based ensembles, the ensembling also helps of course with dealing with noise. Neural networks can also learn to ignore features, sure, but everything you learn with neural networks would usually require more data."
4056,@rasbt,2022-07-24 02:34:12+00:00,https://twitter.com/rasbt/status/1551032973645996032,"@JFPuget @RexDouglass Yeah I dunno, could be. In any case, the main point I was trying to make is that for tree-based methods it's probably easier to avoid uninformative features. 1st because nodes use 1 feature at a time 1/2"
4057,@rasbt,2022-07-24 02:26:47+00:00,https://twitter.com/rasbt/status/1551031106794934272,"@JFPuget @emrecgty @RexDouglass I think we were talking about ""simple decision"" trees if you scroll up"
4058,@rasbt,2022-07-24 02:25:32+00:00,https://twitter.com/rasbt/status/1551030794864529410,"@JFPuget @RexDouglass Actually the post I was responding talked about ""simple trees"""
4059,@rasbt,2022-07-24 02:23:09+00:00,https://twitter.com/rasbt/status/1551030194152132611,"@TarlowScott I agree with that. Lots of methods skipped. My guess is though that said methods just came out very recently and were not peer-reviewed yet, dunno."
4060,@rasbt,2022-07-24 02:22:06+00:00,https://twitter.com/rasbt/status/1551029927910277121,"@JFPuget @RexDouglass Maybe I should have said ""individual nodes"""
4061,@rasbt,2022-07-24 02:20:48+00:00,https://twitter.com/rasbt/status/1551029599945068546,@JFPuget @joao_semnome9 @RexDouglass How does that go if the 2nd feature is a noise or uninformative feature? I hope the tree is not doing that.
4062,@rasbt,2022-07-24 02:09:46+00:00,https://twitter.com/rasbt/status/1551026823588372484,"@agrover112 Actually I don't submit PRs for documentation errors/typos anymore except it's a small hobby library with minimal CI. Otherwise, I'd feel really bad about the wasted time &amp; resources."
4063,@rasbt,2022-07-24 02:08:50+00:00,https://twitter.com/rasbt/status/1551026589437247488,"@agrover112 Seems like that. There have been at least 2 or 3 deep learning libraries I contributed to where the PR for fixing a spelling (one word!) in the docs took literally more than a week because of the extensive CI runs, code reviews, etc."
4064,@rasbt,2022-07-24 02:02:43+00:00,https://twitter.com/rasbt/status/1551025050396119040,"@JFPuget @RexDouglass You are quoting it out of context, you dropped the ""into account"". Of course you can input feature combinations into a decision tree."
4065,@rasbt,2022-07-24 02:02:08+00:00,https://twitter.com/rasbt/status/1551024904019083267,@emrecgty @JFPuget @RexDouglass The types of decision trees I know split one feature at a time. There is no linear or nonlinear combination of features at a given split. You would have to create that yourself.
4066,@rasbt,2022-07-24 02:00:41+00:00,https://twitter.com/rasbt/status/1551024539307483137,"@joao_semnome9 @JFPuget @RexDouglass Yes, thank you. With ""trees don't take feature combinations into account"" I meant that they don't use or create feature combinations but split at one feature at a time."
4067,@rasbt,2022-07-23 18:21:33+00:00,https://twitter.com/rasbt/status/1550908994218299393,"@moajjem04 Haha fair, and linear regression trees fix your output range problem üòâ"
4068,@rasbt,2022-07-23 18:19:48+00:00,https://twitter.com/rasbt/status/1550908554621722625,"@radbrt @mphamner To me it should be that college teaches you everything you need to know to be employable and up to speed. If you just graduated, you shouldn't worry about catching up but rather about *staying* up to date."
4069,@rasbt,2022-07-23 18:18:13+00:00,https://twitter.com/rasbt/status/1550908156351578114,"@radbrt @mphamner I bet that 95% of students are stressed about job interviews though and have to study whatever the latest techniques are on their own. Imho, if you are a fresh college graduate, you shouldn't have to study to get up to speed for job interviews. Tells me there is something wrong."
4070,@rasbt,2022-07-23 18:11:49+00:00,https://twitter.com/rasbt/status/1550906545617211392,@radbrt @mphamner Sure. I am not arguing about fundamentals. They are essential. My perception is more like that syllabi need more frequent updates. Trimming stuff between the fundamentals and the state of the art.
4071,@rasbt,2022-07-23 18:07:01+00:00,https://twitter.com/rasbt/status/1550905338785927170,"@mphamner @radbrt 2/2 Also, universities should be teaching them about electric motors not combustion engines. There are still some people who want/need to know about combustion engines. There should be a course for that. But currently it's all backwards."
4072,@rasbt,2022-07-23 18:05:57+00:00,https://twitter.com/rasbt/status/1550905067020197889,"@mphamner @radbrt To me, it's like most people go to university because they want to know how to drive, but universities try to teach everyone how to build a combustion engine. Some will want/need to know how engines work. This should then be a follow-up course. 1/2"
4073,@rasbt,2022-07-23 17:54:20+00:00,https://twitter.com/rasbt/status/1550902144705912833,"@mphamner @radbrt Yeah, I think there is a big need for a revamp!"
4074,@rasbt,2022-07-23 17:51:38+00:00,https://twitter.com/rasbt/status/1550901466193432577,"@mphamner @radbrt I would never take away foundations. They are the most essential. But latest techniques are also important. E.g., if someone wants to learn about NLP, make the lecture about bag-of-words &amp; transformers. Don't make the lecture about bag-of-words &amp; RNNs."
4075,@rasbt,2022-07-23 17:47:04+00:00,https://twitter.com/rasbt/status/1550900314781675520,"@mphamner @radbrt Yeah, we need foundations and baselines. But latest algorithms are also important -- ultimately, we want out students to get a job. However, often, there is a lot in-between that can be cut -- personally I feel like they are important but not essential."
4076,@rasbt,2022-07-23 17:40:48+00:00,https://twitter.com/rasbt/status/1550898738276745218,"@mphamner @radbrt The problem I have with academia and university curricula is that everyone has such a hard time with letting old things go. We can't just squeeze in more topics every year. Honestly, I feel like a lot of courses need a good trimming of outdated methods."
4077,@rasbt,2022-07-23 16:39:19+00:00,https://twitter.com/rasbt/status/1550883266911260674,"@RexDouglass Sure. I think the authors did a good job here though. They balanced the datasets, and they also looked at the behavior when removing features and adding uninformative features. It's already a 33-page paper. I agree with what you describe, but that's a separate study."
4078,@rasbt,2022-07-23 16:14:34+00:00,https://twitter.com/rasbt/status/1550877040118833152,"@RexDouglass I agree with the overfitting aspect. I think it also helps that the tree-based models here are ensembles since trees (in random forests, they usually have unlimited depth) can actually also learn pretty complex functions. Also, trees don't take feature combinations into account"
4079,@rasbt,2022-07-23 15:57:36+00:00,https://twitter.com/rasbt/status/1550872769025425409,"@hugo_le_moine_ @ylecun @JFPuget Hah, doesn't Germany import nuclear power from France? That probably explains it üòÜ"
4080,@rasbt,2022-07-23 15:53:20+00:00,https://twitter.com/rasbt/status/1550871692997804038,"@PatrichTivoli @DGlaucomflecken Haha, actually that's the real deal. I can't do American coffee anymore."
4081,@rasbt,2022-07-23 15:49:25+00:00,https://twitter.com/rasbt/status/1550870710465298434,@machsci They didn't do one-hot encoding for HistGradientBoostingClassifier I suppose. That would explain its good performance. XGBoost doesn't really handle categorical data well last time I checked (a few months back): https://t.co/dqgzHEyk8Y
4082,@rasbt,2022-07-23 15:45:55+00:00,https://twitter.com/rasbt/status/1550869827652386819,@JulienMouchnino The number of trials in random search I suppose. Like 100 would be the best model after the 100th hyperparameter config they tried.
4083,@rasbt,2022-07-23 15:43:20+00:00,https://twitter.com/rasbt/status/1550869178759929857,"@DGlaucomflecken Based on my recent trip to Italy, I can confirm.
Left: regular (!) coffee ""to go""
Right: Americano https://t.co/A0rQ7cMzsL"
4084,@rasbt,2022-07-23 15:38:27+00:00,https://twitter.com/rasbt/status/1550867948222517253,@JulienMouchnino A transformer for tabular data from last year: https://t.co/TB1oQHetEb
4085,@rasbt,2022-07-23 15:37:39+00:00,https://twitter.com/rasbt/status/1550867747831169026,"@tunguz @radbrt In the paper, the authors mentioned that they truncated datasets to 10k. It's possible that some of the original datasets are useful for this collection, but yeah, I haven't checked the original sizes."
4086,@rasbt,2022-07-23 15:36:26+00:00,https://twitter.com/rasbt/status/1550867442183831553,"@HamTttttyy I tend to refer to chapters 1-10 of my book (ML with PyTorch &amp; Sklearn) as ""part 1"" because it's about general concepts of machine learning and conventional machine learning (not deep learning). 
The remaining 9 chapters (part 2) are about deep learning."
4087,@rasbt,2022-07-23 15:33:12+00:00,https://twitter.com/rasbt/status/1550866626937077761,"@_tjuer Actually, it might be plotted in R"
4088,@rasbt,2022-07-23 15:31:12+00:00,https://twitter.com/rasbt/status/1550866124576854016,"@tunguz Thanks for confirming. Sure, there may be outliers, but so far, I have similar experience based on my industry and consulting experience! https://t.co/zWVLShGhbN"
4089,@rasbt,2022-07-23 15:09:50+00:00,https://twitter.com/rasbt/status/1550860748464832513,"@radbrt 3/3
3) In industry, you have many companies collecting data over time. Here, you often work with ""accumulated"" datasets. It doesn't mean the data is easier to work with (rather the opposite). But there is usually more."
4090,@rasbt,2022-07-23 15:08:17+00:00,https://twitter.com/rasbt/status/1550860358679728135,"@radbrt 2/
2) If it's not a benchmark dataset, labs are relatively small in academia (compared to companies), and data is usually collected specifically for one or more studies."
4091,@rasbt,2022-07-23 15:07:14+00:00,https://twitter.com/rasbt/status/1550860092333080576,"@radbrt Yeah, that's my perception as well. I think this may be due to the following reasons:
1) In academia, we work with existing benchmark datasets (it would be weird to add more data to those over time, because then it would be hard to compare to previous literature.
1/"
4092,@rasbt,2022-07-23 14:12:07+00:00,https://twitter.com/rasbt/status/1550846223959080964,@Dhiraj_Ruler @CubeTales2108 Awesome! Looking forward to it!
4093,@rasbt,2022-07-23 14:08:55+00:00,https://twitter.com/rasbt/status/1550845415909638146,"@TheZachMueller @nlpmiha @bernhardsson Yeah, this is exactly what I had in mind. Sure, docstrings in code are a different beast. But for starters, I would be happy to just not wasting so many resources on running CI on documentation files upon typo fixes."
4094,@rasbt,2022-07-23 13:58:56+00:00,https://twitter.com/rasbt/status/1550842906608603142,@Dhiraj_Ruler @CubeTales2108 Do you have a blog post or article? Want to add it to my collection :)
4095,@rasbt,2022-07-23 13:41:19+00:00,https://twitter.com/rasbt/status/1550838473384693761,"@nlpmiha @bernhardsson Can't that be done based on the ""git commit"" / ""git log --raw""?"
4096,@rasbt,2022-07-23 13:34:33+00:00,https://twitter.com/rasbt/status/1550836767842000897,"[6/6] Link to the paper: 
""Why do tree-based models still outperform deep learning on tabular data?"" https://t.co/qqOGJsfCsN"
4097,@rasbt,2022-07-23 13:34:32+00:00,https://twitter.com/rasbt/status/1550836766214688769,"[5/6] For large(r) datasets (50k), however, the gap between tree-based ML and deep learning is much smaller.
However, the authors argue that large tabular datasets are rare. Do you agree? (I think it is somewhat true in academic collaboration but in industry?) https://t.co/zNqdPkfzHq"
4098,@rasbt,2022-07-23 13:34:32+00:00,https://twitter.com/rasbt/status/1550836764658524160,[4/6] Tree-based models are also a tad more robust to uninformative features. My guess is that's because tree-based models process features independently. https://t.co/PJA0mkN17N
4099,@rasbt,2022-07-23 13:34:32+00:00,https://twitter.com/rasbt/status/1550836763178012672,[3/6] The authors also looked at both numerical and mixed numerical &amp; categorical datasets (categorical features were one-hot encoded). The results hold: tree-based methods perform well https://t.co/fDhYTGemM0
4100,@rasbt,2022-07-23 13:34:31+00:00,https://twitter.com/rasbt/status/1550836761760337921,"[2/6] The plot above also nicely highlights one of my favorite points when talking to collaborators: If you use RF, you will often get good out-of-the-box performance! I am positively surprised that this is nowadays true for XGBoost as well! https://t.co/kLjaP1DWu5"
4101,@rasbt,2022-07-23 13:34:31+00:00,https://twitter.com/rasbt/status/1550836760128675840,"And the deep learning vs conventional machine learning for tabular data continues!
A new paper looks at 45 mid-sized datasets (10k examples) and finds that tree-based models (XGBoost &amp; random forests) still outperform deep neural networks on tabular datasets. [1/6] https://t.co/Xp1BDSHNtk"
4102,@rasbt,2022-07-23 13:13:07+00:00,https://twitter.com/rasbt/status/1550831375959396352,"This! And as a contributor to several libraries that involve elaborate CI setups with finicky TPU pods and GPU servers: do we really have to rerun all the tests when s.o. fixes a typo in the docs?
If feel like for CI 2.0 we should be thinking about these things."
4103,@rasbt,2022-07-23 12:59:24+00:00,https://twitter.com/rasbt/status/1550827922436624385,@47apollo @ylecun @JFPuget Details are in the paper
4104,@rasbt,2022-07-23 12:58:34+00:00,https://twitter.com/rasbt/status/1550827715015614464,"@AlZawqari Unfortunately, I know this feeling. As frustrating as this is, I do think though that you may actually still get it published sooner this way. Submitting to conferences often means that you have to do it a couple of times as it depends more on luck."
4105,@rasbt,2022-07-23 12:57:23+00:00,https://twitter.com/rasbt/status/1550827415945023490,"@simonkmtse Hah, yes, but that's easier said than done. People probably said the same thing when Random Forests and later XBoost took over logistic regression."
4106,@rasbt,2022-07-23 12:56:05+00:00,https://twitter.com/rasbt/status/1550827086566379522,@fgonzalez_v The one at the bottom of this stack
4107,@rasbt,2022-07-23 12:55:04+00:00,https://twitter.com/rasbt/status/1550826832664170496,"@Abdel_Bentorcha Unfortunately, no. I am working on a new course though that will have more hands-on exercises! üòä"
4108,@rasbt,2022-07-23 12:54:04+00:00,https://twitter.com/rasbt/status/1550826579080749057,"@nkourkou Yes, I am thinking of there are (better) incentives, there might a larger pool of reviewers available. And if there is  a larger pool of reviewers, editors can preferably select those who are qualified and tend to write good reviews."
4109,@rasbt,2022-07-22 22:37:03+00:00,https://twitter.com/rasbt/status/1550610905313984516,"We tried to use large language models for editing sequences while maintaining valid structures. This was/is actually super challenging, scientifically and engineering-wise. 
Hats off üé© to the researchers who accomplished something far more difficult and impressive! üöÄ"
4110,@rasbt,2022-07-22 22:33:23+00:00,https://twitter.com/rasbt/status/1550609981715759105,"Seriously a good idea. Based on my experience as editor, reviewer, and author so far, finding suitable reviewers who volunteer their time is usually the big bottleneck for timely publication. And it's getting worse. 
There are no incentives for reviewers. We need to fix this."
4111,@rasbt,2022-07-22 21:14:34+00:00,https://twitter.com/rasbt/status/1550590149641310211,"@thejuicywitcher I suppose machine learning could be (/ is being?) used for this üòÜ
https://t.co/7kIoPrD0ND"
4112,@rasbt,2022-07-22 20:48:13+00:00,https://twitter.com/rasbt/status/1550583517800710146,"@thejuicywitcher Haha, this is Twitter. 280 characters üôÉ. But yeah, I US -based regions vary a lot a good map here (Washington has like 24 g CO2 intensity, Missouri has 620 g): https://t.co/1nvJh8QuTY"
4113,@rasbt,2022-07-22 20:45:24+00:00,https://twitter.com/rasbt/status/1550582808678219777,"Happy learning üòä! I haven't read the Kaggle one yet, but if I may suggest an order: 
(1) Part 1 of my book for ML fundamentals
(2) Kaggle book for practicing
(3) Keras book for DL fundamentals
(4) Part 2 of my book for more algorithmic DL details, PyTorch, GNNs, and Transformers"
4114,@rasbt,2022-07-22 20:34:34+00:00,https://twitter.com/rasbt/status/1550580083236212740,@KayhanB21 üòÜthe default blinds in American apartments fixed that for me. You basically have to get up when the sun comes up.
4115,@rasbt,2022-07-22 20:32:09+00:00,https://twitter.com/rasbt/status/1550579473338228736,"@LukawskiKacper Maybe! I guess the independent of the day, the region itself probably matters much more. Like always using North West / Washington based on this map https://t.co/1nvJh8QuTY"
4116,@rasbt,2022-07-22 14:37:44+00:00,https://twitter.com/rasbt/status/1550490283388829699,"@zicokolter I haven't followed this particular incident, but as a general observation, I think issues related to errors and criticism could be easily resolved if conferences and publishers allowed revisions similar to arxiv."
4117,@rasbt,2022-07-22 14:29:32+00:00,https://twitter.com/rasbt/status/1550488216884617216,"@binbbaz Haha, fair. But you could probably buy a used iPad + read the color PDF copy for the price of a potential color print versionüòä"
4118,@rasbt,2022-07-22 13:44:23+00:00,https://twitter.com/rasbt/status/1550476856163450882,"@binbbaz No worries, I really wish we had a color print, too! But I am not sure if it is worth the increased costs üòÖ"
4119,@rasbt,2022-07-22 13:14:09+00:00,https://twitter.com/rasbt/status/1550469246521581569,"@binbbaz Ah sorry, actually it was $118 for 600 pages via their printers. To keep the book as affordable as possible, we opted for b/w. https://t.co/Gg4Lf4b0Uv"
4120,@rasbt,2022-07-22 13:12:49+00:00,https://twitter.com/rasbt/status/1550468909677117441,"@binbbaz Hi there. Yes, this is unfortunately normal. It was not possible to print the book in color at this page count. We were thinking about splitting it up into two volumes, but even then it would have been at least 60 dollar per volume and 120 dollars in total."
4121,@rasbt,2022-07-22 13:10:04+00:00,https://twitter.com/rasbt/status/1550468218866786304,"Also, check this out: Running machine learning experiments in France produces 3x less CO2 than in Germany. Nuclear power, I guess? @ylecun @JFPuget 

Full paper here: 
""Measuring the Carbon Intensity of AI in Cloud Instances""
https://t.co/W1b3Vc9JxR https://t.co/bikdHGyQtE"
4122,@rasbt,2022-07-22 13:09:21+00:00,https://twitter.com/rasbt/status/1550468040470536192,"Contrary to what grad school wants you to believe, staying up late to work on your ML projects is actually bad (for the environment). 
Training a model at midnight increases CO2 emissions by 7.7% compared to 6:00 am. 
https://t.co/W1b3Vc9JxR https://t.co/F2bWpX2tSe"
4123,@rasbt,2022-07-21 21:51:04+00:00,https://twitter.com/rasbt/status/1550236943874772992,"@EntraCod Yeah, so for encoder-decoder LSTMs (e.g., for translation) the limitation is that the network has to memorize the whole context in a single hidden state, which is not great. It's missing a lot of context when generating the output. Attention helps with that https://t.co/c63FanfzKY"
4124,@rasbt,2022-07-21 16:21:23+00:00,https://twitter.com/rasbt/status/1550153976561139712,@PyTorchLightnin Hm ... I would probably try to find my good old iPad and have them set up a new fingerprint üòÜ https://t.co/1TL81EUIVT
4125,@rasbt,2022-07-21 15:02:37+00:00,https://twitter.com/rasbt/status/1550134157526843392,@itsrainingdata The https://t.co/YrAYw3QbK4 is almost like that üòÜ
4126,@rasbt,2022-07-21 14:56:18+00:00,https://twitter.com/rasbt/status/1550132566711185410,"If you are a more visual person, here are some figures from my book üòä: 

(1) https://t.co/SUVGIXAhwX

(2) https://t.co/ryGBM9f1Fq https://t.co/jVxGjQv8i5"
4127,@rasbt,2022-07-21 14:51:50+00:00,https://twitter.com/rasbt/status/1550131440032968704,"A figure is worth a worth a thousand words &amp; symbols. No? 
It's impressive how the authors managed to describe transformers without the use of a single figure. But I will probably bookmark it anyways üòÖ

""Formal Algorithms for Transformers"" https://t.co/fiYqqVBOB8"
4128,@rasbt,2022-07-21 14:22:18+00:00,https://twitter.com/rasbt/status/1550124008821010435,"@paul_rietschka Haha sure, but do you know how many people complain that you cannot use @NotionHQ offline?"
4129,@rasbt,2022-07-21 14:15:06+00:00,https://twitter.com/rasbt/status/1550122197829570565,@paul_rietschka What I meant was Dask is great for processing but not really solving the storage issue.
4130,@rasbt,2022-07-21 14:00:49+00:00,https://twitter.com/rasbt/status/1550118603797671936,"@paul_rietschka DuckDB makes sense. Dask is cool too, but out of context? Maybe Dask + Parquet, or Dask + HDF5 or something like that. 
Afaik Zotero still uses SQLite. It's fine."
4131,@rasbt,2022-07-21 12:15:36+00:00,https://twitter.com/rasbt/status/1550092122602233856,"@JFPuget I do think it's useful to know about the broad concept though. It takes maybe 30-60 min to learn how to use it.  To me it's like regular expressions. Nothing I am using daily or should memorize. You know the basic concept though, and when you need it, you just look it up again."
4132,@rasbt,2022-07-21 12:12:40+00:00,https://twitter.com/rasbt/status/1550091384505487361,"You can learn the basics in an hour or so. 
And I think just understanding how it works on a conceptual level is super useful for programming in general (the concept behind indices and pointers).
Also, you never know when it will come in handy!"
4133,@rasbt,2022-07-21 12:10:19+00:00,https://twitter.com/rasbt/status/1550090796422029312,"Memory lane: My very first blog post (10 years ago!) was actually about SQL(ite) üòÜ 

SQLite ‚Äì Working with large data sets in Python effectively 
https://t.co/BXp8RVIu0g

Do I still use SQL on a daily basis? Nope. Would I still recommend learning it? Absolutely. https://t.co/kZeLehfY7J"
4134,@rasbt,2022-07-21 00:23:31+00:00,https://twitter.com/rasbt/status/1549912921219776512,"@KrzakalaF @ylecun Hah, the VS in slide header got my attention ... until the first bullet clarifies. Really should dive deeper into EBMs some time üöÄ. 
Rumors have it that @alfcnz has an amazing book in the works! üòä"
4135,@rasbt,2022-07-21 00:20:19+00:00,https://twitter.com/rasbt/status/1549912117075214337,@keunwoochoi @kchonyc Prost üçª
4136,@rasbt,2022-07-21 00:18:46+00:00,https://twitter.com/rasbt/status/1549911727965356032,"@giffmana Arg, hope you recover soon without any lingering symptoms! 
(From someone who was careful but already got it 3 times, my advice is take it easy as much as possible until you feel well; the more you rest the sooner you will hopefully fully recover!)"
4137,@rasbt,2022-07-21 00:13:38+00:00,https://twitter.com/rasbt/status/1549910437231198208,@ChristophR1996 @roydanroy üëå
4138,@rasbt,2022-07-20 22:40:34+00:00,https://twitter.com/rasbt/status/1549887015671701504,"@roydanroy Krizhevsky et al.'s ""ImageNet Classification with Deep Convolutional Neural Networks"" (2012, aka ""AlexNet"") was the first deep convolutional neural network to win computer vision contests. üî•üî•"
4139,@rasbt,2022-07-20 20:53:37+00:00,https://twitter.com/rasbt/status/1549860101015719944,"@TheOneRavenous I guess what they call the bag-of-freebies: a more robust loss function, a more efficient label assignment method, and a more efficient training  method. Also a new model re-parameterization approach that they refer to as ""planned re-parameterized convolution"" https://t.co/o1RtkadiUW"
4140,@rasbt,2022-07-20 19:25:10+00:00,https://twitter.com/rasbt/status/1549837840351203329,"If collaborating on GitHub alone is not already fun enough, GitHub also added some fun little Achievement badges. 
If you are a collector, what are your most fun &amp; exotic ones? 
(So far, I probably have to go with the YOLO one -- merging w/o review üôÑ) https://t.co/mcN2Qohg74"
4141,@rasbt,2022-07-20 19:01:36+00:00,https://twitter.com/rasbt/status/1549831909735366659,"@MetaAI Congrats, and that sounds interesting! I haven‚Äôt seen the paper (do you have a link?) but based on the figure, AlphaFold2 is only used for generating ‚Äúsynthetic‚Äù data? So a real-world use case would be predicting sequences from e.g. cryoEM data where the sequence is unavail.?"
4142,@rasbt,2022-07-20 17:29:40+00:00,https://twitter.com/rasbt/status/1549808776328482816,@alfcnz @hexygen Yes good catch!
4143,@rasbt,2022-07-20 17:28:34+00:00,https://twitter.com/rasbt/status/1549808495679217664,@hexygen @alfcnz I actually just see that I mistyped that and meant 1200% not 1500% üôÉ
4144,@rasbt,2022-07-20 17:27:49+00:00,https://twitter.com/rasbt/status/1549808308327940104,"@alfcnz @hexygen Based on the plot in the lower-left it's easiest to see, I think. They report 120% faster and it looks like a 2.2x speed-up."
4145,@rasbt,2022-07-20 17:25:40+00:00,https://twitter.com/rasbt/status/1549807768525225984,"@alfcnz @hexygen Yeah, I think the terminology is confusing. I am not disagreeing here."
4146,@rasbt,2022-07-20 17:21:15+00:00,https://twitter.com/rasbt/status/1549806654971076610,@hexygen @alfcnz Same. I think it‚Äôs the latter where 1500 percent means 15x ü§∑‚Äç‚ôÇÔ∏è
4147,@rasbt,2022-07-20 14:18:32+00:00,https://twitter.com/rasbt/status/1549760674439520256,"PS: If you are interested in real-time object detection with small datasets, our paper on Few-Shot Learning for Video Object Detection will be presented at ICPR 2022 next month!
https://t.co/kfDyyVEzrj"
4148,@rasbt,2022-07-20 14:14:40+00:00,https://twitter.com/rasbt/status/1549759701298167809,"Time and object detectors are running by so fast! 

Feels like I was using YOLOv3 just a few years ago. This month, YOLOv7 was released!

It's 1500% faster than a SWIN Transformer-based R-CNN (at the same accuracy) and 150% faster than YOLOv5!

https://t.co/fdHnzNPj2n https://t.co/byeT9ftAbT"
4149,@rasbt,2022-07-20 01:22:49+00:00,https://twitter.com/rasbt/status/1549565457786699782,"@HEPfeickert Thank! Oh yeah, that's usually what I do too with the high-level requirements. Thought there might be a more automated solution maybeüôÉ"
4150,@rasbt,2022-07-19 19:55:12+00:00,https://twitter.com/rasbt/status/1549483009740513284,"@nassarhuda @sugatoray * distributed training, transformers, it's all there when I search for it. However, I heard from a student who tried Julia a while back that it's way less mature and comprehensive compared to the PyTorch / TensorFlow ecosystem"
4151,@rasbt,2022-07-19 19:52:35+00:00,https://twitter.com/rasbt/status/1549482352585457666,@nassarhuda @sugatoray deep learning is currently really limited afaik
4152,@rasbt,2022-07-19 19:51:45+00:00,https://twitter.com/rasbt/status/1549482143583199233,@prabhat933 Glad to hear that the book was useful to you! And thanks for the kind compliment üòä
4153,@rasbt,2022-07-19 16:01:30+00:00,https://twitter.com/rasbt/status/1549424197218205696,"@therriaultphd @TessaRDavis haha, just have to be disciplined, disable issues and discussions, and not contribute to other open source projects I guess"
4154,@rasbt,2022-07-19 13:40:50+00:00,https://twitter.com/rasbt/status/1549388800106921984,"@tunguz @danilotat Actually no. It might sound counterintuitive but rather save it as DNA üß¨ , you still have the high cost &amp; very slow read &amp; write times but at least it‚Äôs more stable and you can transcribe it to make new RNA copies. And if you just care about the bases, conversion is trivial."
4155,@rasbt,2022-07-19 12:15:35+00:00,https://twitter.com/rasbt/status/1549367343586983937,"@nassarhuda Fair, the few Julia users I know use Jupyter notebooks as well, but I never met a hardcore R user who uses Jupyter notebook over R Markdown"
4156,@rasbt,2022-07-19 12:14:40+00:00,https://twitter.com/rasbt/status/1549367113852264449,"@nassarhuda I still remember when it was called IPython notebook (hence the .ipynb file extension) and it was rebranded to Julia when Julia was the hot new thing. Fast forwarding like a decade, I  think people who use Jupyter notebooks are still mostly Python üêç users."
4157,@rasbt,2022-07-19 12:11:47+00:00,https://twitter.com/rasbt/status/1549366387973447683,@TessaRDavis 11. Version control your code with GitHub
4158,@rasbt,2022-07-19 11:15:34+00:00,https://twitter.com/rasbt/status/1549352240292532227,"@JacquieLudwig @OpenAcademics Oh that sounds familiar üòÖ! Glad that there was a happy ending, and congrats on this big accomplishment!! üçæüéâ"
4159,@rasbt,2022-07-19 01:39:47+00:00,https://twitter.com/rasbt/status/1549207341777788929,@ZainulA40877140 That is true. I actually read at least half of my books on an ebook reader so that I can annotate them more easily.
4160,@rasbt,2022-07-19 01:38:44+00:00,https://twitter.com/rasbt/status/1549207076152434688,"@RishiSonthalia I think the best introduction to diffusion models is this blog post by @lilianweng: https://t.co/4NJZzr9HKF

And here is a nice, concise code implementation: https://t.co/xgcwj7OaGB"
4161,@rasbt,2022-07-19 01:35:59+00:00,https://twitter.com/rasbt/status/1549206383668695040,"@minguk_kang Thanks for the great work, really enjoyed it. And as far as I can tell, others did too :). I agree with you, I think GANs will not totally go away (I was exaggerating a bit, haha)"
4162,@rasbt,2022-07-19 01:34:29+00:00,https://twitter.com/rasbt/status/1549206008567943169,@HEPfeickert Btw. do you have a favorite tool or workflow for creating high-level dependency requirement.txt files? (Versus just dumping everything there.)
4163,@rasbt,2022-07-19 01:28:48+00:00,https://twitter.com/rasbt/status/1549204577655873542,@zacharylipton Intel Happy Hou¬Æ
4164,@rasbt,2022-07-19 01:13:12+00:00,https://twitter.com/rasbt/status/1549200649874710530,"@NormaPadron__ @therriaultphd That was a fun evening! And thanks for taking us the place!! Back in the Midwest, burritos üåØ will never be the same again. 
Haha I hope Amelia got her well-deserved vacation before she has to perform on camera again üêïüì∏"
4165,@rasbt,2022-07-17 21:53:11+00:00,https://twitter.com/rasbt/status/1548787927035138048,@HanchungLee And a counter-example would be PyTorch. It's quite messy tbh: https://t.co/64atCnMVFH
4166,@rasbt,2022-07-17 21:51:01+00:00,https://twitter.com/rasbt/status/1548787382463389696,"@HanchungLee Was thinking the same thing at first. But I think it makes sense if you have multiple high level modules within your package. 
Lightning would be one example: https://t.co/BffLxUXhOa"
4167,@rasbt,2022-07-17 21:35:53+00:00,https://twitter.com/rasbt/status/1548783571594317825,"To me, coding style and organization guidelines are analogous to grammar rules. 
Sure, you can probably still parse a sentence if the punctuation and spacing is wrong, but it's a lot more tedious and annoying. 

Excellent article with lots of good recs: https://t.co/XrXaUZrMiP"
4168,@rasbt,2022-07-17 19:19:33+00:00,https://twitter.com/rasbt/status/1548749263911456768,"I actually like what the structural bio community is doing with CASP (https://t.co/cJfwkGDFSa). Like applying a method to new data, and here the nice thing is that the whole community is doing it so you can directly compare. Makes things like AlphaFold2 a lot more trustworthy"
4169,@rasbt,2022-07-17 18:53:27+00:00,https://twitter.com/rasbt/status/1548742697049104385,"There are also lots of cases where video and book are complementary (overlapping but not 1:1). I think Gilbert Strang‚Äôs Linear Algebra is such an example. 
Hah, or, shameless plug, my own book and courses"
4170,@rasbt,2022-07-17 18:50:00+00:00,https://twitter.com/rasbt/status/1548741829071339526,"But I cannot only read books. I would get bored by the format. 
Blog posts are great for communicating recent and out-of-scope ideas. 
Video lectures are great if the topic requires lots of visuals or if you need to build a solid foundation first."
4171,@rasbt,2022-07-17 18:48:15+00:00,https://twitter.com/rasbt/status/1548741385897054208,"I consume all types of content. Can‚Äôt really say I have a favorite format, but there is something about reading books ‚Äî keeps me more focused and I feel like it lets me think about certain things more deeply."
4172,@rasbt,2022-07-17 15:41:11+00:00,https://twitter.com/rasbt/status/1548694310299787264,"It's also very impressive how far GANs have come in a relatively short amount of time!
 I still remember the (now crummy) DCGAN images from 2017. 
Actually, it doesn't feel like that was so long ago. https://t.co/ROBDjC0oyI"
4173,@rasbt,2022-07-17 15:30:26+00:00,https://twitter.com/rasbt/status/1548691604881432576,"Have you seen the StudioGAN paper?  ü§©

Probably THE reference that concludes the GAN chapter (before the world moves on to Diffusion Models).

Paper: https://t.co/nFnGuCqmua
Code: https://t.co/AzwNCctIVP https://t.co/KNK01S7L4F"
4174,@rasbt,2022-07-17 15:00:51+00:00,https://twitter.com/rasbt/status/1548684160797184001,"@ph_singer @marktenenholtz I am a bit skeptical. Yes, certain AutoML tools solve certain types of user errors. But a) even if everyone was using AutoML tools, you would trust a Kaggle Leaderboard where everyone had access to the complete test dataset? And b) AutoML only really covers some tabular problems"
4175,@rasbt,2022-07-17 14:05:45+00:00,https://twitter.com/rasbt/status/1548670294923042816,"@JFPuget @kaggle üíØ agree. That‚Äôs my favorite example to highlight why the current system is flawed. 

Imagine you would give people on Kaggle access to test set data and let them upload their own test set scores. Chaos. Academic research is kind of like that."
4176,@rasbt,2022-07-17 14:00:15+00:00,https://twitter.com/rasbt/status/1548668910500732928,"üíØ

Giving researchers direct access to test set data is just asking for trouble. 

If we want to fix this, we need to rethink who has access to the test data / who does the model evaluation."
4177,@rasbt,2022-07-17 00:44:11+00:00,https://twitter.com/rasbt/status/1548468574502539264,@made_in_cosmos https://t.co/WX6ea2eHLT
4178,@rasbt,2022-07-17 00:27:58+00:00,https://twitter.com/rasbt/status/1548464489426608128,@MathProfPeter I remember an Udacity course on Differential Equations from like 10 years ago. That one was actually pretty well done. Afaik the prof really nailed the short 20min-ish format already back then and had good &amp; many useful exercises
4179,@rasbt,2022-07-17 00:25:45+00:00,https://twitter.com/rasbt/status/1548463931538100224,"@SciencePaige @rabernat Yes, this was great. Such an awesome week. Thanks everyone organizing &amp; attending &amp; making it so worthwhile!"
4180,@rasbt,2022-07-17 00:23:29+00:00,https://twitter.com/rasbt/status/1548463364052963328,"@MotamedSam @AlexGDimakis That‚Äôs true but in a university setting, you often have to be kinda both"
4181,@rasbt,2022-07-17 00:22:25+00:00,https://twitter.com/rasbt/status/1548463092975017984,"@AlexGDimakis I guess it depends on the type of research. Certain types of experiments require a good understanding of software engineering to be productive. You can probably get by if you focus more on theoretical research, sure. Or if you have staff that can assist you with certain things"
4182,@rasbt,2022-07-17 00:16:37+00:00,https://twitter.com/rasbt/status/1548461634116407296,@therriaultphd Haha looks like you got luckier with the @AmericanAir plane. Ours had mechanical issues of course so I will be here for the weekend I guess. Anyways was good seeing you &amp; safe travels
4183,@rasbt,2022-07-17 00:14:03+00:00,https://twitter.com/rasbt/status/1548460987388350464,@scikit_learn @StefanieMolin @theBodlina @RichardKlima Looks well organized!! üëå
4184,@rasbt,2022-07-16 22:45:56+00:00,https://twitter.com/rasbt/status/1548438812543528965,"@KyleLiang5 *ok if you are a student, some programs require papers for graduation, so you have a point there."
4185,@rasbt,2022-07-16 22:43:30+00:00,https://twitter.com/rasbt/status/1548438202335109124,@KyleLiang5 Disagree. Afaik the system is set up to maximize citations.
4186,@rasbt,2022-07-16 21:07:16+00:00,https://twitter.com/rasbt/status/1548413984780341250,"@SeanG1911 not only NLP but also vision. Together, that's maybe 80% of deep learning &amp; AI research."
4187,@rasbt,2022-07-16 21:06:29+00:00,https://twitter.com/rasbt/status/1548413787111231488,"@SeanG1911 well, most individuals and academic labs who would like to do cutting edge deep learning research but can't because their compute budgets and resources are nowhere near what's currently required for staying competitive. 

https://t.co/M16fBltLr0 https://t.co/GymZYH7w3H"
4188,@rasbt,2022-07-16 20:27:12+00:00,https://twitter.com/rasbt/status/1548403900658552834,"@random_walker This is a big problem indeed. However, this is impossible to fix as long as you allow researchers to evaluate their own methods. Predictive performance need to be either evaluated by a third party, or we have to adopt a model similar to Kaggle where the test data is hidden"
4189,@rasbt,2022-07-16 19:18:37+00:00,https://twitter.com/rasbt/status/1548386641005256704,"@nathanbarry Not if you are into gaming, and definitely not if you are into deep learning &amp; AI"
4190,@rasbt,2022-07-16 19:15:53+00:00,https://twitter.com/rasbt/status/1548385951876911111,"@invictusqed @ylecun I don‚Äôt think that‚Äôs how it works in practice. Imagine you gave everyone on Kaggle all the test set labels üòÜ. To answer the question: You provide the predictions, and someone else who has the labels evaluates these for you."
4191,@rasbt,2022-07-16 18:53:36+00:00,https://twitter.com/rasbt/status/1548380343379451909,"@sugatoray @chenghlee As far as I understand it brings the mamba solver to conda. So yeah if you are already using mamba you probably don‚Äôt need this. But if you prefer typing/using conda, this is for you ;)"
4192,@rasbt,2022-07-16 18:04:25+00:00,https://twitter.com/rasbt/status/1548367968223916033,"This is probably well-known in some circles but probably not addressed anywhere:

Software engineering should be part of the curriculum!

Software engineering knowledge is at least as important &amp; useful as mathematical foundations when it comes to modern machine learning &amp; AI."
4193,@rasbt,2022-07-16 15:47:22+00:00,https://twitter.com/rasbt/status/1548333478571171840,"@mariotelfig Yeah rejected a couple of times in general, not specifically neurips"
4194,@rasbt,2022-07-16 15:38:12+00:00,https://twitter.com/rasbt/status/1548331170349211649,"@MunichNlp Huh wow, had no idea"
4195,@rasbt,2022-07-16 15:37:32+00:00,https://twitter.com/rasbt/status/1548331003571187715,"@Luppoloo Haha the list is not specific to o neurips, rejected papers in general"
4196,@rasbt,2022-07-16 15:14:29+00:00,https://twitter.com/rasbt/status/1548325202114662404,@RWJE_BA Rejected from the rejected-list. Ooops. Should have definitely put it on the top of this list! üòÖ
4197,@rasbt,2022-07-16 15:00:42+00:00,https://twitter.com/rasbt/status/1548321735367241732,@RWJE_BA Hah yes wanted to include it but wasn't sure about it (https://t.co/r9nW21rXSm)
4198,@rasbt,2022-07-16 14:58:01+00:00,https://twitter.com/rasbt/status/1548321060201803776,"Feeling a bit anxious about the NeurIPS reviews being released in about a week ...

A list of rejected papers that ended up having a significant impact:
- PageRank
- Word2Vec (poster)
- YOLO
- Transformer-XL
- Dropout
- Kalman Filters
- RoBERTa
- GELU

via https://t.co/HfeiGi9C8J"
4199,@rasbt,2022-07-16 14:47:14+00:00,https://twitter.com/rasbt/status/1548318343064473603,@amt_shrma Nice work! Want to dig into this topic more. Do you have the code somewhere?
4200,@rasbt,2022-07-16 14:01:49+00:00,https://twitter.com/rasbt/status/1548306916614422528,"@ylecun And having separate training, validation, and test sets is just the bare minimum. As a colleague once put it: ""If you have access to the labels of the test dataset, then it is a validation dataset and the methodology isn‚Äôt done properly."""
4201,@rasbt,2022-07-16 13:54:48+00:00,https://twitter.com/rasbt/status/1548305150191644674,"Great, thanks for making research &amp; science more welcoming üò© https://t.co/pV9ld2LHoo"
4202,@rasbt,2022-07-16 13:34:40+00:00,https://twitter.com/rasbt/status/1548300085099782144,@sGx_tweets @PyTorchLightnin @PyTorch @deliprao @rctatman @predict_addict @joshuastarmer Thanks üòä
4203,@rasbt,2022-07-16 03:20:27+00:00,https://twitter.com/rasbt/status/1548145511953117184,"@xinbinjian @chenghlee Wait, tell me more! Actually, I am a big conda fan (vs virtualenv etc.) because this way you can take care of both the Python version and package versions. How/why would you combine pyenv with it?"
4204,@rasbt,2022-07-16 00:55:06+00:00,https://twitter.com/rasbt/status/1548108931423420417,"@HEPfeickert @Kaszanas Cleaning up slides? Haha, that‚Äôs cheating üòÜ"
4205,@rasbt,2022-07-15 22:11:45+00:00,https://twitter.com/rasbt/status/1548067824928636930,"Conda is awesome, but yeah, it's a snail üêå  not a snake üêç!
So, here's one last little surprise from #SciPy2022 you will love! 
Conda now supports the mamba solver for a 5x-10x speedup üöÄ! 
Thanks @chenghlee!!! https://t.co/rY575iPhFE"
4206,@rasbt,2022-07-15 22:04:00+00:00,https://twitter.com/rasbt/status/1548065872807243778,"""Consider your data analysis as an application."" @HEPfeickert giving compelling reasons to consider using lockfiles at #SciPy2022
Also, TIL about secure installs via pip. More info here: https://t.co/FNIpkLEVJY https://t.co/v6YpiWWk3i"
4207,@rasbt,2022-07-15 21:58:49+00:00,https://twitter.com/rasbt/status/1548064570488397824,"@squevedo8524 @python_engineer haha, noted!"
4208,@rasbt,2022-07-15 21:58:30+00:00,https://twitter.com/rasbt/status/1548064490440179713,"@McDonald_Ibekwe Thanks for the suggestion! I hope I can get to that one day! In the meantime, I do have 2 courses that are loosely based on the book
1. Machine learning: https://t.co/tJU9cJ7xPK
2. Deep learning: https://t.co/8FhMfLo5Vl

Hope that's helpful!!"
4209,@rasbt,2022-07-15 13:57:43+00:00,https://twitter.com/rasbt/status/1547943495951794176,"@paul_rietschka @thomasjpfan Just scrolling through the doc‚Äôs TOC, and wow, it looks like they have a lot of cool stuff in there. Why haven‚Äôt I hear about this before!? Just dropping the link here for others: https://t.co/HihhPQjHLA"
4210,@rasbt,2022-07-14 22:57:51+00:00,https://twitter.com/rasbt/status/1547717036947619842,"Tired of spinning Jupyter notebooks on GitHub üòµ‚Äçüí´, check out @yuvipanda‚Äôs faster way of sharing notebooks at  https://t.co/eSvZe3Xvx9 üëåüëåüëå #SciPy2022"
4211,@rasbt,2022-07-14 20:40:56+00:00,https://twitter.com/rasbt/status/1547682581268742145,"@therriaultphd Ah c'mon, it's like Stranger Things, a little bit of nostalgia won't hurt anyone üòÜ"
4212,@rasbt,2022-07-14 20:20:27+00:00,https://twitter.com/rasbt/status/1547677424246091776,@therriaultphd back to the roots üòÇüòÇüòÇ
4213,@rasbt,2022-07-14 20:16:34+00:00,https://twitter.com/rasbt/status/1547676447489216513,@AllesistKode @PyTorchLightnin @PyTorch @numpy_team @pandas_dev @neuromatch @fastdotai @MLStreetTalk @AndrewYNg @alfcnz @theaisummer @distillpub @HochreiterSepp @jcjohnss @paperswithcode ü´∂ü´∂ü´∂
4214,@rasbt,2022-07-14 20:15:34+00:00,https://twitter.com/rasbt/status/1547676198473330689,"ICYMI: Code examples, slides, and an interactive demo here  https://t.co/1XqkXZMYd7"
4215,@rasbt,2022-07-14 17:49:18+00:00,https://twitter.com/rasbt/status/1547639388678414336,@fchollet Which is actually a good thing imho üòÜ
4216,@rasbt,2022-07-14 17:48:56+00:00,https://twitter.com/rasbt/status/1547639295141285890,@10x_er @fchollet Homebrew &amp; conda ftw! üôå
4217,@rasbt,2022-07-14 17:28:48+00:00,https://twitter.com/rasbt/status/1547634229747388416,@Jeande_d Hope you'll like it! And wishing you all the best on your grad school journey! Enjoy &amp; have fun üòä
4218,@rasbt,2022-07-14 16:43:49+00:00,https://twitter.com/rasbt/status/1547622908700213248,@def_void_main @lilianweng @chipro @AndrewYNg haha thanks! üôåüòä
4219,@rasbt,2022-07-14 16:37:21+00:00,https://twitter.com/rasbt/status/1547621279980613632,"@PyTorchLightnin @joshuastarmer @vboykis Or, want your mind go ü§Ø with some technical detail you probably haven't thought about, yet? Check out @ThomasViehmann's LernApparat: https://t.co/Ea2QYDVa1e"
4220,@rasbt,2022-07-14 16:36:01+00:00,https://twitter.com/rasbt/status/1547620946051092488,"@PyTorchLightnin Haha, 280 characters are not nearly enough.

Because we could all use a little bit more humor ... there's StatQuest (https://t.co/s64Yxn1vEn) by @joshuastarmer of course! 

Also, check out @vboykis's Tech Blog: https://t.co/NneZttMl68.

https://t.co/ZXuSRRk0js"
4221,@rasbt,2022-07-14 16:19:55+00:00,https://twitter.com/rasbt/status/1547616895850795015,"If I had to pick:

1) @lilianweng's blog: https://t.co/0czFwcsyo5

2) @chipro's blog: https://t.co/f8ygrU4QYJ

3) Standford CS229 (https://t.co/N44IIJ25EL) and everything @AndrewYNg does. Big inspiration for me and one of the reasons I got into ML many years ago (and stayed)"
4222,@rasbt,2022-07-14 15:44:35+00:00,https://twitter.com/rasbt/status/1547608000575074310,"@WalterReade @thomasjpfan Yeah, that's why the make_column_selector + pandas DataFrames approach is so cool!"
4223,@rasbt,2022-07-14 15:34:43+00:00,https://twitter.com/rasbt/status/1547605517584855046,"Was nice catching up with @thomasjpfan at #SciPy2022.
Learned lots of cool (not totally obvious) sklearn functions üöÄ

üí°make_column_transformer &amp; pandasüí°are a powerful combo when working with categorical features. 

A permutation importance example üëá
 https://t.co/VGZPYy15ex https://t.co/kMg5STkSie"
4224,@rasbt,2022-07-14 14:57:53+00:00,https://twitter.com/rasbt/status/1547596249439735808,@xamat Also have font memories of chemistry classes in college -- 38C/100F without AC can be quite brutal when you have to wear a thick cotton lab coat üòÜ
4225,@rasbt,2022-07-14 14:56:15+00:00,https://twitter.com/rasbt/status/1547595837286387713,"@xamat Same. And yeah, Germany can get quite hot in summer, too. Remember visiting my parents when it was like 38C/100F for a week. First, I thought it's impossible without AC, but you actually get used to it and then felt super spoiled when I returned back to the US."
4226,@rasbt,2022-07-14 00:06:49+00:00,https://twitter.com/rasbt/status/1547372005313445888,"@karpathy Hah, yes, all good things come in threes: technical work in AI, open source and education! üöÄ
If I can convince you to do all these things in a start-up world while having fun, let me know, happy to chat!!"
4227,@rasbt,2022-07-13 23:59:55+00:00,https://twitter.com/rasbt/status/1547370267885928448,"Love #SciPy2022 Lightning Talks! @nicholdav &amp; Madicken did a great job moderating! Also, so many amazing talks! 
One of my favs was on Generalization &amp; Deep Learning by @DJCordhose. 
Yes, he literally collected training data on the way to the conference!üëá
https://t.co/SWhexedW03 https://t.co/98n1FLtlvX"
4228,@rasbt,2022-07-13 21:19:48+00:00,https://twitter.com/rasbt/status/1547329974880935937,"I love the trading cards at #SciPy2022 this year. 
Haha, and I also think they are totally not randomized. https://t.co/3VbrhvAULx"
4229,@rasbt,2022-07-13 13:28:30+00:00,https://twitter.com/rasbt/status/1547211369270886400,"@joshuastarmer Wow ü§Ø!! Congrats, this is awesome! Bam! ü•Åüçæ"
4230,@rasbt,2022-07-13 13:04:20+00:00,https://twitter.com/rasbt/status/1547205285894393856,"@ducha_aiki Hah yeah, I don‚Äôt mind it because it is efficient and gets the point across. Maybe it‚Äôs a fad but I try to minimize the use of passive voice these days though. Like ‚ÄúSo and so proposed to use deep learning for predicting motion types in the three-body problem [1]‚Äù"
4231,@rasbt,2022-07-13 02:35:55+00:00,https://twitter.com/rasbt/status/1547047140496654336,@JonathanSumDL @python_engineer Haha that‚Äôs quite the todo list üôÑ
4232,@rasbt,2022-07-12 23:56:54+00:00,https://twitter.com/rasbt/status/1547007123506208770,"@python_engineer I guess that would be the https://t.co/mWfOa7CaJG repo üòÅ! 
A (rather random) collection of various deep learning architectures, models, and tips. 
The emphasis is on ""random."""
4233,@rasbt,2022-07-12 19:08:29+00:00,https://twitter.com/rasbt/status/1546934541306273795,"@marktenenholtz Arg! Haha but I guess I have to make this trip a regular, yearly thing then ;). Love Austin, and it feels good to be back. So many amazing folks here doing amazing things"
4234,@rasbt,2022-07-12 14:50:20+00:00,https://twitter.com/rasbt/status/1546869573026304001,@roydanroy @y0b1byte üíØ
4235,@rasbt,2022-07-12 13:58:40+00:00,https://twitter.com/rasbt/status/1546856573368246274,@Suleymanzade Not on Linux/macOS? You can delete it from your home directory (default location). Tbh I can't live without Miniconda. Tried the virtualenv lifestyle but it was too much hassle with pyenv. Tried the procedure below but honestly Miniconda is way smoother https://t.co/t8Wr5Lt6XO
4236,@rasbt,2022-07-12 13:54:38+00:00,https://twitter.com/rasbt/status/1546855555175776258,"Excited to be back in Austin for the week &amp; looking forward to a amazing week with the awesome open source community! ü´∂
Will be at Anaconda's 10 year birthday party &amp; #SciPy2022 and am looking forward to meet and catch up with everyone!"
4237,@rasbt,2022-07-12 01:36:05+00:00,https://twitter.com/rasbt/status/1546669692571598848,"@evohackr @fchollet Oh wow, thanks so much for digging up this reference! Didn‚Äôt know this term originated from a statistical analysis (assumed it was a biological term adopted in stats contexts)"
4238,@rasbt,2022-07-12 01:25:22+00:00,https://twitter.com/rasbt/status/1546666997672443910,"@fbartolic @DynamicWebPaige That‚Äôs Numba on the CPU, right? Curious if you had a chance to try the GPU supported Numba?"
4239,@rasbt,2022-07-11 17:48:32+00:00,https://twitter.com/rasbt/status/1546552030449238018,"@fchollet Well, at least the world will end on a warm, funny note"
4240,@rasbt,2022-07-11 17:26:36+00:00,https://twitter.com/rasbt/status/1546546513723154434,"I got started with GitHub because of version control &amp; stayed because of the awesome open source community! ü´∂ 
If you are not on GH yet, what are your reasons / alternatives?

PS: rumors have it that a GH profile is also one of the most important things on a resume these days! https://t.co/WpWGN5Rmiw"
4241,@rasbt,2022-07-11 15:56:19+00:00,https://twitter.com/rasbt/status/1546523789160235009,"@kchonyc Wait, isn't the deadline today üò≤? Haha, I suppose some people really like living on the edge (that probably goes for both reviewers and ACs üòÖ)"
4242,@rasbt,2022-07-11 15:52:00+00:00,https://twitter.com/rasbt/status/1546522704337145866,"@Chronotope @CompsciDiscu Yes, I did it maybe 3 or 4 months back, and I am 99% sure it must have been this one. Should be fixed now. Sorry for the trouble!! üòÖ. And thanks so much for the blog post! üôå"
4243,@rasbt,2022-07-11 15:45:52+00:00,https://twitter.com/rasbt/status/1546521163312111617,"Wow, what a nice way to start the week! 
""A very honest opinion, this is a great book for everyone who wants to get into machine learning as well as s.o. who is planning to change careers [...]. The book is extremely extremely comprehensive!""
Thx for the kind words @_bhaveshbhatt"
4244,@rasbt,2022-07-11 15:40:41+00:00,https://twitter.com/rasbt/status/1546519855289040897,"@Chronotope @CompsciDiscu Haha, have you written a blog post on Twitter Meta tags for Jekyll by chance? I think I may have adopted it a while back and forgot to change the twitter handle. My only explanation haha."
4245,@rasbt,2022-07-11 15:31:01+00:00,https://twitter.com/rasbt/status/1546517423339233281,"@_bhaveshbhatt Wow, thanks so much for the kind review! ü´∂ 
Really glad to hear you like the book and found the contents useful! Haha, I am particularly happy to hear that the vast scope is a Pro, not a Con! üôå"
4246,@rasbt,2022-07-11 13:28:03+00:00,https://twitter.com/rasbt/status/1546486479802753025,"@JRAnaraki Ah yes, good catch! Thanks!"
4247,@rasbt,2022-07-11 12:48:24+00:00,https://twitter.com/rasbt/status/1546476498542120960,@MolasAlex Yeah it‚Äôs actually very interesting. I remember toying around with it and if you make the network too large it will just memorize. It‚Äôs actually not as trivial as it seems.
4248,@rasbt,2022-07-11 12:38:29+00:00,https://twitter.com/rasbt/status/1546474006605340673,@MolasAlex Neural networks üôÉ
4249,@rasbt,2022-07-11 12:30:54+00:00,https://twitter.com/rasbt/status/1546472098125733888,@mmattamala It looks like something DALL-E would generate
4250,@rasbt,2022-07-11 12:23:37+00:00,https://twitter.com/rasbt/status/1546470265525248001,"@code_star Nice, this means that I‚Äôll see you at Anaconda Conf and SciPy this week?"
4251,@rasbt,2022-07-11 12:21:39+00:00,https://twitter.com/rasbt/status/1546469770161168386,A fun phenomenon indeed. Want to test how well a machine learning algorithm can deal with such epistatic effects? I have a multiplexer function here (https://t.co/34NxvvFTOh) for benchmarking
4252,@rasbt,2022-07-11 12:18:06+00:00,https://twitter.com/rasbt/status/1546468874710835201,@fchollet Btw is there a word for that? I heard ‚ÄúEpistasis‚Äù or ‚ÄúEpistatic effect‚Äù which is kind of related yet slightly different (‚ÄúWhenever two or more loci interact to create new phenotypes.‚Äù)
4253,@rasbt,2022-07-11 01:33:15+00:00,https://twitter.com/rasbt/status/1546306594794766336,"@MitchellAGordon I think the alternative attention forms don't really make a big difference in practice to make it worthwhile. Other parts of the architecture probably dwarf the cost of self-attention vs alternatives. 
(Also some additional comments in the thread below https://t.co/JxaiNDt2h5)"
4254,@rasbt,2022-07-10 16:21:18+00:00,https://twitter.com/rasbt/status/1546167690498293760,"@leonpalafox @hardmaru Yes exactly. And not only design cost. Referenced the Google article on reducing latency and file size above, but I couldn't find the one were they referenced the reduction in server costs. I remember &amp; am 99% sure that it was a big discussion for the redesign back then."
4255,@rasbt,2022-07-10 16:18:53+00:00,https://twitter.com/rasbt/status/1546167083930624000,"@hardmaru E.g., from the Google article on their logo redesign: 
""it allows us to optimize these assets for size and latency, including building a special variant of our full-color logo that is only 305 bytes, compared to our existing logo at ~14,000 bytes."" https://t.co/kMPXusZrvv"
4256,@rasbt,2022-07-10 16:03:57+00:00,https://twitter.com/rasbt/status/1546163324018122752,"@hardmaru Indeed. 
I think the OP (suggesting it's about ""trying to quantify beauty"") got it wrong. 
I think it's more of a Bitmap Vs Vector Graphics kind of thing."
4257,@rasbt,2022-07-10 14:55:06+00:00,https://twitter.com/rasbt/status/1546145998396858368,@apachaves https://t.co/3CHnT1K2EZ
4258,@rasbt,2022-07-10 14:13:35+00:00,https://twitter.com/rasbt/status/1546135551606247425,"Glad you liked y deep learning videos I shared last weekend. 
Yes, DL is fun! 
But it's also important to learn about the core concepts of machine learning incl. bias/variance trade-offs, cross-validation, and model evaluation! üìàüéØ
I got you covered here: https://t.co/tJU9cJp9ek"
4259,@rasbt,2022-07-10 13:44:26+00:00,https://twitter.com/rasbt/status/1546128212526354436,"@david_perell ‚Äúit allows us to optimize these assets for size and latency, including building a special variant of our full-color logo that is only 305 bytes, compared to our existing logo at ~14,000 bytes.‚Äù"
4260,@rasbt,2022-07-10 13:43:43+00:00,https://twitter.com/rasbt/status/1546128035195273220,"@david_perell Not sure about the others, but re Google, it was also largely motivated by computational efficiency. I remember articles quoting millions of dollars in server cost savings. Might have been this article: https://t.co/kMPXusZrvv"
4261,@rasbt,2022-07-10 03:13:08+00:00,https://twitter.com/rasbt/status/1545969340863889409,"@tunguz @PyTorch MPU, meat processing unit"
4262,@rasbt,2022-07-10 02:40:30+00:00,https://twitter.com/rasbt/status/1545961130161496065,"@rahuldave @think___y @__mharrison__ @fchollet @danintheory @ml4trading Yes, I think watermarking could help somewhat. Probably not perfect because someone could either remove the watermark or buy it with a throw-away email, but it's at least making it a bit harder. Tbh I don't know why @leanpub doesn't have a watermarking feature."
4263,@rasbt,2022-07-10 02:03:30+00:00,https://twitter.com/rasbt/status/1545951816965406720,"@nlpnyc @PyTorch Hah, yeah, the temperature ranges are pretty much the same so that's not too far off"
4264,@rasbt,2022-07-10 02:01:23+00:00,https://twitter.com/rasbt/status/1545951287069626371,"@vineettiruvadi @rationalcypher @Sid____ @yudapearl 2/2 It's usually less about replacing physicians but adding some additional functionality (mostly something monitoring-related, or some early detection)"
4265,@rasbt,2022-07-10 02:00:01+00:00,https://twitter.com/rasbt/status/1545950939999354888,"@vineettiruvadi @rationalcypher @Sid____ @yudapearl Yes, I am honestly only hearing about it from the sidelines. It's mostly people showing me / talking about systems they've developed and asking for some ML modeling advice. I was thinking that these systems were adding value 1/2"
4266,@rasbt,2022-07-10 00:39:17+00:00,https://twitter.com/rasbt/status/1545930625978343428,"Accelerated grilling brought to you by PyTorch 2.0. 

""Well done"" @PyTorch team! https://t.co/R6jwmD0MaR"
4267,@rasbt,2022-07-09 23:54:16+00:00,https://twitter.com/rasbt/status/1545919294147526657,@GossiTheDog @jorgex135 @eIonmusk @elonmusk Wait what is this sorcery? Which one is the magic char? On iOS I can‚Äôt even tell in that font.
4268,@rasbt,2022-07-09 23:47:46+00:00,https://twitter.com/rasbt/status/1545917659010703361,"@vineettiruvadi @rationalcypher @Sid____ E.g., the healthcare system currently deployed by Mars (and used by thousands of clinics) that I referenced earlier is so that an early diagnosis can be made the same day so that a treatment can start earlier rather than having to come back next day."
4269,@rasbt,2022-07-09 23:45:57+00:00,https://twitter.com/rasbt/status/1545917202909495296,"@vineettiruvadi @rationalcypher @Sid____ Different discussion but just to make sure we are on the same page just in case there was an ambiguity: In general, I didn't mean to claim anything along the lines of any AI being better than a physician. The healthcare apps I know about are to get (pre-)decisions faster"
4270,@rasbt,2022-07-09 18:20:57+00:00,https://twitter.com/rasbt/status/1545835413796900864,@AlisonBLowndes And that‚Äôs just the subset of papers with code üôÉ
4271,@rasbt,2022-07-09 18:20:09+00:00,https://twitter.com/rasbt/status/1545835213283946496,"@jukujala Yeah good question. Wondered the same. I am not storing them in the GitHub repo but attached them to a release tag. Alternatively, you can upload it elsewhere ‚Äî you just have the specify the URL in the hubconf file"
4272,@rasbt,2022-07-09 16:51:50+00:00,https://twitter.com/rasbt/status/1545812988095070208,"@vineettiruvadi @Sid____ Fair, I am not working in healthcare and thus I am not using any of these systems. I can only tell you what I heard other people telling me. Based on that info, it appears that ML is used in healthcare settings though. How widespread it is, dunno, it could be selection bias"
4273,@rasbt,2022-07-09 16:26:31+00:00,https://twitter.com/rasbt/status/1545806613495382018,@vineettiruvadi @PWGTennant @Sid____ There are countless examples where ML is used in a healthcare setting. Just recently talked to a doctor who helped developing a patient monitoring system at ICUs.
4274,@rasbt,2022-07-09 16:24:19+00:00,https://twitter.com/rasbt/status/1545806061239681025,@vineettiruvadi @PWGTennant @Sid____ It was one example
4275,@rasbt,2022-07-09 16:17:01+00:00,https://twitter.com/rasbt/status/1545804225703301120,"@vineettiruvadi @Sid____ Lots of examples here:
https://t.co/2WU1K6SWCv
https://t.co/pYFj70rWzc
https://t.co/MGf3dsBskg"
4276,@rasbt,2022-07-09 16:02:15+00:00,https://twitter.com/rasbt/status/1545800508207775745,@PWGTennant @vineettiruvadi @Sid____ Here would be an example from a recent talk (minute 30:54) on how ML / AI is used for veterinary health care at Mars: https://t.co/uy4f6FBCUB
4277,@rasbt,2022-07-09 14:46:21+00:00,https://twitter.com/rasbt/status/1545781406462353409,@Sid____ Just a quick Twitter search and randomly picking one of the first results that came up: https://t.co/0h2vrBguuo
4278,@rasbt,2022-07-09 14:45:41+00:00,https://twitter.com/rasbt/status/1545781242083393536,"@Sid____ Let me ask you the other way around. If you say anything about data centric AI, people will tell you that this is nothing new and that they have been using data-centric AI all along. So by that definition, it works successfully because ML is used pretty much anywhere these days."
4279,@rasbt,2022-07-09 14:31:25+00:00,https://twitter.com/rasbt/status/1545777651771637762,"A check-in at the 1-3 year mark before this prediction expires. With 
(1) data-centric AI building successful ML systems across health care, government tech, and manufacturing;
(2) large language models enabling breakthroughs in language modeling,
are we still on track with this?"
4280,@rasbt,2022-07-08 20:51:35+00:00,https://twitter.com/rasbt/status/1545510934432595968,*This feature has been around for a while. And I have been a frequent Torch Hub user for torchvision models. But today was the day I created my own hubconf. py for the first time üòä
4281,@rasbt,2022-07-08 20:49:44+00:00,https://twitter.com/rasbt/status/1545510466360942594,"Finally got to play around with Torch Hub today. It's pretty neat and lets you load models directly from GitHub:
model = torch.hub.load(
    ""rasbt/ord-torchhub"",
    model=""resnet34_corn_afad"",
    source='github',
    pretrained=True
)
Full example here: https://t.co/0vXZc7yrmJ"
4282,@rasbt,2022-07-08 18:27:54+00:00,https://twitter.com/rasbt/status/1545474774209634305,@valentyn_bez nope (not yet üòÜ)
4283,@rasbt,2022-07-08 18:22:39+00:00,https://twitter.com/rasbt/status/1545473451837820928,Achievement unlocked! https://t.co/ymTYAAc6Rk
4284,@rasbt,2022-07-08 18:10:55+00:00,https://twitter.com/rasbt/status/1545470499051954176,"@think___y @__mharrison__ @fchollet @danintheory @ml4trading Thanks for the suggestion, but I don't think this would solve the issue. I.e., in the context of the problem described in the article: someone buys the book from the online store, swaps out the cover and author name, and sells it as their own on Amazon."
4285,@rasbt,2022-07-08 16:40:16+00:00,https://twitter.com/rasbt/status/1545447686039638017,@behzadshomali 2/2 I don't think the second point you made is an issue if we have a date cut-off and make the fair point that only previous work needs to be discussed (the article does not need to be updated each time there is some new related article coming out)
4286,@rasbt,2022-07-08 16:39:00+00:00,https://twitter.com/rasbt/status/1545447367612239872,@behzadshomali Yeah but even for experts it is easy to miss or overlook things (like in this case). There should be a mechanism to adopt such feedback post-pub (similar to how you can revise articles on arxiv). 1/2
4287,@rasbt,2022-07-08 15:32:29+00:00,https://twitter.com/rasbt/status/1545430630430871555,"@pararths @goodfellow_ian Yeah. I haven't followed this closely, but it seems that no one takes it seriously? I mean even if it's not exactly stealing his ideas, if there is some related aspect to it, why not acknowledging it in the related work?

https://t.co/sjiYo1R3rE

(Plot twist: he is rich now üòÜ)"
4288,@rasbt,2022-07-08 15:28:18+00:00,https://twitter.com/rasbt/status/1545429575655735298,"@NoisyFrequency it could use some refactoring, but the relevant part is basically this:
(link to the full code: https://t.co/lZ2lf9eXmY) https://t.co/BHB2GMByLE"
4289,@rasbt,2022-07-08 15:21:24+00:00,https://twitter.com/rasbt/status/1545427840996450304,@moksenenko https://t.co/mqvNy9BYOg (Courtesy of @karpathy)
4290,@rasbt,2022-07-08 14:37:38+00:00,https://twitter.com/rasbt/status/1545416827982995462,"The ML field has become so big that comprehensive reviews have maybe become infeasible, and important original works can be missed by accident. 
Nonetheless, constructive feedback like this should be addressed &amp; ideally incorporated. We should allow paper edits after publication."
4291,@rasbt,2022-07-08 14:16:41+00:00,https://twitter.com/rasbt/status/1545411552500670466,"Yes, actually doing things is the only way to get things done. Changing &amp; fiddling with productivity tools is often just another flavor of procrastination.
I prefer simple tools: https://t.co/3HtDAgjkis -- only thing that's changed is that I now do the daily sheet on an e-reader."
4292,@rasbt,2022-07-08 13:18:38+00:00,https://twitter.com/rasbt/status/1545396944880762883,"@marktenenholtz Nothing wrong with it imho. It‚Äôs just missing step 
4. Do EDA"
4293,@rasbt,2022-07-08 13:16:26+00:00,https://twitter.com/rasbt/status/1545396393208156161,@jeremyphoward FFP2 = N95?
4294,@rasbt,2022-07-08 13:13:32+00:00,https://twitter.com/rasbt/status/1545395660874301440,"@leonpalafox @tadaspetra Personal manager? I wish I had one! Other than that, I keep it simple and stick to what I‚Äôve been doing for years so that it becomes routine and doesn‚Äôt get too much in the way of doing: https://t.co/3HtDAgjkis"
4295,@rasbt,2022-07-08 12:36:26+00:00,https://twitter.com/rasbt/status/1545386326559789058,@QuantifiedJest That‚Äôs why I think it‚Äôs important to upload your papers on a platform like arxiv and have reviews public there. No need to have an accept/reject for papers that are not obviously fake or broken. Expert comments are enough and people can make up their own mind.
4296,@rasbt,2022-07-08 12:33:19+00:00,https://twitter.com/rasbt/status/1545385539918069766,"@tadaspetra Yup, wise decision. That‚Äôs why I stopped chasing the latest fad regarding productivity tools a few years back."
4297,@rasbt,2022-07-08 12:26:05+00:00,https://twitter.com/rasbt/status/1545383719627784193,"@QuantifiedJest Yeah, this is sad, academic publishing in ML has become kind of a mess."
4298,@rasbt,2022-07-08 12:17:27+00:00,https://twitter.com/rasbt/status/1545381546999353345,"Arg, here we go again üò©. I wonder how much of this goes unseen."
4299,@rasbt,2022-07-08 01:46:38+00:00,https://twitter.com/rasbt/status/1545222795889713152,"@NoisyFrequency No it shouldn't. Both approaches are O(n): just permuting one feature at the time. For the one on the right, you permute all features in the feature group at the same time."
4300,@rasbt,2022-07-08 01:38:33+00:00,https://twitter.com/rasbt/status/1545220762398871552,"@karpathy Also recommend checking out Ursula LeGuin, maybe starting with The Left Hand of Darkness and The Dispossessed"
4301,@rasbt,2022-07-08 01:36:06+00:00,https://twitter.com/rasbt/status/1545220147593576449,"@karpathy Oh, and you might like The Sparrow by Mary Doria Russell. (There is heavy use of GOFAI &amp; expert systems in that book.)"
4302,@rasbt,2022-07-08 01:32:25+00:00,https://twitter.com/rasbt/status/1545219221268955136,@karpathy Surprised that Leviathan Wakes isn‚Äôt on the list. And one of THE AI books: Ancillary Justice.
4303,@rasbt,2022-07-07 20:51:39+00:00,https://twitter.com/rasbt/status/1545148561830166528,@zacharylipton @OpenAI OpenSigh üòÆ‚Äçüí®
4304,@rasbt,2022-07-07 20:32:48+00:00,https://twitter.com/rasbt/status/1545143817342517248,"@Pimp_Fada Same now! Have been traveling a lot this year and it‚Äôs so much better than lugging around notebooks, articles. and books!"
4305,@rasbt,2022-07-07 20:29:32+00:00,https://twitter.com/rasbt/status/1545142995120525312,@Pimp_Fada Yup!
4306,@rasbt,2022-07-07 20:29:03+00:00,https://twitter.com/rasbt/status/1545142877235585024,@Schots üíØ!! That‚Äôs exactly what I needed for a recent research project and I thought why not adding it to mlxtend for everyone ‚ò∫Ô∏è
4307,@rasbt,2022-07-07 20:27:28+00:00,https://twitter.com/rasbt/status/1545142474913480704,"This year #NeurIPS2022 reviewing is happening at my remote office!

I've never understood the mathematical proofs better. I have more mental clarity. My skin is clearer. My focus has improved. https://t.co/FIRiZ1Ydwk"
4308,@rasbt,2022-07-07 17:44:33+00:00,https://twitter.com/rasbt/status/1545101479001919489,"* that is, if you install the current dev version via 
pip install git+git://github.com/rasbt/mlxtend.git

Documentation example here: https://t.co/QBDvztuZrm (Example 3 at the bottom)"
4309,@rasbt,2022-07-07 17:44:33+00:00,https://twitter.com/rasbt/status/1545101477064179718,"Finally added feature group support to the ""feature importance via permutation"" analysis in MLxtend. You can now specify certain feature sets to be treated as a single feature -- very useful when dealing with large one-hot encodings.
#30DaysOfMachineLearningAndCode Day 1 https://t.co/7D4m4o3yB8"
4310,@rasbt,2022-07-07 15:39:17+00:00,https://twitter.com/rasbt/status/1545069951345741825,"@svpino @BertPluymers Hah, yes, I don't disagree. I am just being lazy sometimes üôÑ"
4311,@rasbt,2022-07-07 15:38:16+00:00,https://twitter.com/rasbt/status/1545069696487231488,@PyTorchLightnin MusicMood üé∂ https://t.co/wCCXLjhw2T https://t.co/JUfiMDZtrS
4312,@rasbt,2022-07-07 15:31:58+00:00,https://twitter.com/rasbt/status/1545068110536908804,"Ever wondered what the Ops in MLOps stands for? 
(Not to be confused with ""Oops, I forgot to normalize the input data, again."")

Ops -&gt; operationalize -&gt; bringing sth into production = deploying, monitoring, and maintaining 
(Courtesy of @chipro and her excellent ML Systems book)"
4313,@rasbt,2022-07-07 15:22:32+00:00,https://twitter.com/rasbt/status/1545065736028229632,@svpino That's fair. Using them always may help with getting used to the additional overhead.
4314,@rasbt,2022-07-07 15:18:32+00:00,https://twitter.com/rasbt/status/1545064730200530944,"So, making &amp; keeping them optional (for Python) might just be the perfect choice. Let the individual projects decide whether to require them or not."
4315,@rasbt,2022-07-07 15:15:39+00:00,https://twitter.com/rasbt/status/1545064004057550849,"personally, I fall in the camp of ""I am okay using them when contributing to bigger code bases; but sorry, can't be bothered to use them for my private projects. Also, please don't ask me to set them up in the first place üòÜ"""
4316,@rasbt,2022-07-07 15:13:15+00:00,https://twitter.com/rasbt/status/1545063402665644033,Just having a discussion about Type Hints (in Python). Are you using them?
4317,@rasbt,2022-07-07 14:16:49+00:00,https://twitter.com/rasbt/status/1545049200802508806,@StepaRusskov Yes and no. I thought about that in a general label uncertainty context but in a more general sense and not specifically for ordinal regression. You have any idea how it connects to ordinal regression?
4318,@rasbt,2022-07-07 12:56:20+00:00,https://twitter.com/rasbt/status/1545028943551643649,@tunguz @roydanroy But that‚Äôs meta-learning?!
4319,@rasbt,2022-07-07 02:00:18+00:00,https://twitter.com/rasbt/status/1544863848913637377,@TheZachMueller haha hilarious! I was commenting while reading ... just finished and came back here to say this. Nicely done üëå
4320,@rasbt,2022-07-07 01:51:14+00:00,https://twitter.com/rasbt/status/1544861567228968961,"@TheZachMueller Actually, that's a super cool example. I never thought of writing a decorator that calls a function repeatedly, and this kind of makes a lot of sense. I can think of fun DL application of this, e.g., a ""max batchsize"" finder.

@ maximize_batchsize
def training_code(...):
    ..."
4321,@rasbt,2022-07-07 01:45:33+00:00,https://twitter.com/rasbt/status/1544860135683661825,"@TheZachMueller It's probably not a whole article by itself, but `partial(...)` is yet another thing that I bet most people never used! Personally, I just picked it up about a month ago -- and I have been coding in Python for a looong time!"
4322,@rasbt,2022-07-07 01:42:53+00:00,https://twitter.com/rasbt/status/1544859467707195392,"Zach and I just chatted about Python decorators, that they are cool, under-appreciated, and should be used more often! 
6 hours later, the same @TheZachMueller hammered out this awesome article on decorators! 
This is the awesome, passionate open source community for you ü´∂"
4323,@rasbt,2022-07-07 01:40:16+00:00,https://twitter.com/rasbt/status/1544858807414755328,"@TheZachMueller @__mharrison__ Two things:
1) ohh, haha, I actually meant the @ torch.jit.script decorator wrt to when to use it or not, oops üòÖ
2) Anyways, this is an awesome article, thanks for writing üëè. And yes, we should use decorators more often in general!! üôå"
4324,@rasbt,2022-07-06 19:06:50+00:00,https://twitter.com/rasbt/status/1544759794946478084,"@3scorciav Absolutely not. Of course, that‚Äôs when I get project and topic ideas, but yeah, the actual writing happens at the computer ;)"
4325,@rasbt,2022-07-06 19:02:52+00:00,https://twitter.com/rasbt/status/1544758797524164609,@osanseviero @xamat üòÖüôÑ
4326,@rasbt,2022-07-06 18:55:18+00:00,https://twitter.com/rasbt/status/1544756895025664001,"@AiBeginners Wow, this looks like a very thorough article üëè. Just bookmarked it, sent it to my e-reader, and look forward to reading it! ‚ò∫Ô∏è"
4327,@rasbt,2022-07-06 18:53:45+00:00,https://twitter.com/rasbt/status/1544756503021850627,@AiBeginners Very nice results. Looks like a 20% improvement here. And yeah I want to clarify that I totally believe that it makes a difference in theory. It‚Äôs more like that I don‚Äôt think it really matters that much in practice (for me at least) :)
4328,@rasbt,2022-07-06 18:50:18+00:00,https://twitter.com/rasbt/status/1544755635371347978,"@xamat I first thought you were talking about HF üòÜ. On Twitter, I haven‚Äôt used either ü§∑‚Äç‚ôÇÔ∏è and totally agree with you"
4329,@rasbt,2022-07-06 16:27:14+00:00,https://twitter.com/rasbt/status/1544719632413741057,@TheZachMueller @__mharrison__ Yes please!! üòÅ
4330,@rasbt,2022-07-06 16:20:20+00:00,https://twitter.com/rasbt/status/1544717896995176448,@TheZachMueller @__mharrison__ Yes this! I does feel like people somehow don‚Äôt like using decorators. I.e. I rarely see them being used and feel guilty of this myself (thinking of @ torch.jit.script ü•π)
4331,@rasbt,2022-07-06 16:06:28+00:00,https://twitter.com/rasbt/status/1544714406067568640,@python_engineer -r requirements.txt üòÜ
4332,@rasbt,2022-07-06 16:05:32+00:00,https://twitter.com/rasbt/status/1544714171518001154,"@mmitchell_ai I was thinking about this a lot recently ‚Äî primarily as a way to support open source. So far, I have never given a paid talk, but I was toying around with the idea to request speaking fees that are then donated to the open source libraries my talks are usually centered around."
4333,@rasbt,2022-07-06 15:33:28+00:00,https://twitter.com/rasbt/status/1544706100645269504,"@seanmylaw @github If you are the maintainer of the repo that this PR is for, you can clone the forked project, switch to the respective branch, and push your commit."
4334,@rasbt,2022-07-06 15:23:53+00:00,https://twitter.com/rasbt/status/1544703689436299264,@Zergylord Probably because the AI-assisted peer review matching systems fails to find suitable reviewers
4335,@rasbt,2022-07-06 13:47:49+00:00,https://twitter.com/rasbt/status/1544679513216454659,@davisblalock Haha I first read this as ‚Äúbeat backpropagation‚Äù and you got me interested. Nicely done üòÜ
4336,@rasbt,2022-07-06 13:41:48+00:00,https://twitter.com/rasbt/status/1544677998011580416,@rwhitcomb Do the following not work reliably? I usually go back and forth between three computers (all Unix/Linux based) and this usually isn‚Äôt a problem; but with vastly different architectures it is probably a different story
4337,@rasbt,2022-07-06 13:39:35+00:00,https://twitter.com/rasbt/status/1544677440898875393,@ducha_aiki Ok fair there could be a counter for unanswered discussions
4338,@rasbt,2022-07-06 13:30:22+00:00,https://twitter.com/rasbt/status/1544675122702860289,@roydanroy @vmansinghka I don‚Äôt belief it
4339,@rasbt,2022-07-06 13:15:41+00:00,https://twitter.com/rasbt/status/1544671426736685058,"@rezar Oh, I thought we were talking about CNNs and transformers for tabular data. Otherwise, of course!"
4340,@rasbt,2022-07-06 13:13:39+00:00,https://twitter.com/rasbt/status/1544670917124562944,Great overview! One thing to add is answering questions. I think that GitHub Discussions are a really nice way of facilitating Q &amp; A‚Äôs (wish they were more actively used compared to GH issues)
4341,@rasbt,2022-07-06 13:08:55+00:00,https://twitter.com/rasbt/status/1544669724180635648,"Maybe I am just too used to working around the quirks, but yeah, I‚Äôd consider pip/conda as being in reasonable shape, too. (I mean, have you ever tried to set up Ruby &amp; Jekyll on a new computer?)"
4342,@rasbt,2022-07-06 13:04:05+00:00,https://twitter.com/rasbt/status/1544668506054082565,"@rezar Both CNNs &amp; transformers are also not really used in the real world. The papers were interesting &amp; promising, but when someone compared them to XGboost on various tabular datasets there was no real benefit (yet). Can find the paper later when I am back at my computer"
4343,@rasbt,2022-07-06 12:59:53+00:00,https://twitter.com/rasbt/status/1544667452969304065,@tunguz And here I thought this was a new paper to bookmark and check out. Haha forgot that holpular was only a month ago; feels like we discussed this ages ago üòÖ
4344,@rasbt,2022-07-06 12:56:25+00:00,https://twitter.com/rasbt/status/1544666579069243392,"@Abebab The best advice I got was to learn to say ‚Äúno‚Äù. It‚Äôs really hard and I constantly have to remind myself that this may be the only way. Saw sth like this on another professor‚Äôs desk once, to remember it and make it more rewarding https://t.co/VG6Nu0O2sd"
4345,@rasbt,2022-07-06 12:49:24+00:00,https://twitter.com/rasbt/status/1544664813699203074,Nice! Another entry to check out for my Deep Learning for Tabular Datasets collection!
4346,@rasbt,2022-07-05 23:04:11+00:00,https://twitter.com/rasbt/status/1544457140391247876,"@cHHillee Perfect, thanks!"
4347,@rasbt,2022-07-05 22:56:07+00:00,https://twitter.com/rasbt/status/1544455109433753601,"@Katie78651182 *I should clarify, the bottleneck would be for the dataloaders. So back in the day I could never really get 100% GPU utilization. Maybe it's different now."
4348,@rasbt,2022-07-05 22:55:01+00:00,https://twitter.com/rasbt/status/1544454831385055234,"@Katie78651182 I am not sure if Google Colab can have multiprocessing. Maybe they changed it but back in the day they only supported one main process, which would create bottlenecks. I should maybe check out Google Colab some time again, but I also don't like running .py files in a notebook env"
4349,@rasbt,2022-07-05 22:52:58+00:00,https://twitter.com/rasbt/status/1544454318526545922,@leonpalafox good call
4350,@rasbt,2022-07-05 21:24:12+00:00,https://twitter.com/rasbt/status/1544431980548444163,"@paul_rietschka Yeah, that's my guess, too. For research btw I think it's probably personal taste. Personally I am coming from TensorFlow &amp; Keras, and PyTorch just fits my workflows and coding style better."
4351,@rasbt,2022-07-05 21:14:13+00:00,https://twitter.com/rasbt/status/1544429468185497602,"Any ideas what the ""Other languages and frameworks"" of the https://t.co/DcWadBnqE3 chart could be composed of? 
My best guesses are scikit-learn, C++, some Theano, and primarily R libraries. (Or, maybe it is really just A LOT of really small, exotic libraries and languages) https://t.co/TvfNrHOqDf"
4352,@rasbt,2022-07-05 20:01:20+00:00,https://twitter.com/rasbt/status/1544411123721666567,"@datenzauberai üíØ
I think the multiples of 8 argument makes kind of sense but yeah, maybe only if you care more about small computational performance percentages (versus predictive performance percentages) üòÜ"
4353,@rasbt,2022-07-05 18:19:55+00:00,https://twitter.com/rasbt/status/1544385603231514624,"@Remi_Coulom Nice, thanks a lot for sharing! Actually, just wanted to add this as additional reference to the article, but it seems that the Nividia documentation has changed? For some reason, I can't find this plot (and corresponding experiments) in the document you linked"
4354,@rasbt,2022-07-05 17:10:43+00:00,https://twitter.com/rasbt/status/1544368188695236609,"@lukas_mut @roydanroy @lorisdanto Either just a nice markdown editor (like Typora) for the first draft or Google Docs (has a nice ""suggestion"" and ""comment"" feature for collaborative brainstorming and initial drafts)"
4355,@rasbt,2022-07-05 16:18:32+00:00,https://twitter.com/rasbt/status/1544355057071685632,Controversial opinion: we don't have to choose batch sizes as powers of 2. Here are my thoughts and experiments:  https://t.co/U92xL32uxH
4356,@rasbt,2022-07-05 16:04:31+00:00,https://twitter.com/rasbt/status/1544351528600879104,"@roydanroy @lorisdanto I think it's great for the collaborative final editing (fine-tuning) of your paper. But yeah, drafting a paper in overleaf (or LaTeX in general) sounds painful."
4357,@rasbt,2022-07-05 13:48:52+00:00,https://twitter.com/rasbt/status/1544317390795800576,"@hectorandradel @thegautamkamath Well, he is rich üòÜ (https://t.co/lQ0AUBDQxq)"
4358,@rasbt,2022-07-05 11:42:10+00:00,https://twitter.com/rasbt/status/1544285506502115329,@giffmana @PreetumNakkiran The method exhibits unexpectedly poor behavior. However extensive experiments on diverse datasets demonstrate the efficacy of the proposed approach.
4359,@rasbt,2022-07-05 00:53:43+00:00,https://twitter.com/rasbt/status/1544122317739114497,"@sp_monte_carlo That's why I personally have a ""!RemindMe in 5 years"" on causal inference topics üòÖ"
4360,@rasbt,2022-07-05 00:50:16+00:00,https://twitter.com/rasbt/status/1544121447232245762,"@bhutanisanyam1 @weights_biases Wow, that's big news! Wishing you all the best on your journey and next step in your productive and impressive career!"
4361,@rasbt,2022-07-05 00:47:48+00:00,https://twitter.com/rasbt/status/1544120826387103746,"@themintsv Oh, I always thought memory was was not included in ""compute"" because we often speak of compute-bound and memory-bound algorithms"
4362,@rasbt,2022-07-05 00:37:45+00:00,https://twitter.com/rasbt/status/1544118297553240069,"@themintsv Fair, maybe ""processing power"" would be a better (grammatically correct) term for compute nowadays?"
4363,@rasbt,2022-07-05 00:08:48+00:00,https://twitter.com/rasbt/status/1544111014303735809,@miclugo üíØ
4364,@rasbt,2022-07-05 00:02:24+00:00,https://twitter.com/rasbt/status/1544109404341116928,"When &amp; why did the machine learning community invent terms like
‚Ä¢ compute resources = CPU resources
‚Ä¢ matrix multiplies = matrix multiplications
I think it was around 2016ish? Any quotes pinpointing it? Asking for a friend."
4365,@rasbt,2022-07-04 18:55:50+00:00,https://twitter.com/rasbt/status/1544032251079495682,@pragmaticml @thegautamkamath Semi adversarial network. The idea was a bit different from GANs. I.e instead of a true/fake discriminator it had a reconstruction loss plus target class classification loss to optimize. Ie generate images that optimize some target outcome with making minimal cha he‚Äôs to an input
4366,@rasbt,2022-07-04 17:36:14+00:00,https://twitter.com/rasbt/status/1544012222489399297,"@SAKSHAM111 @thegautamkamath Thanks, glad to hear you like it!"
4367,@rasbt,2022-07-04 16:12:54+00:00,https://twitter.com/rasbt/status/1543991248570253315,@VittoMartinelli @thegautamkamath Interesting viewpoint üôÉ
4368,@rasbt,2022-07-04 15:33:31+00:00,https://twitter.com/rasbt/status/1543981338109394946,"@thegautamkamath Hah like me for GANs (or SANs which we called them. Had the idea 2013ish but didn‚Äôt work on them until 3 years later). But to be honest, unless you do science for the credits, it doesn‚Äôt really matter who did what first."
4369,@rasbt,2022-07-03 15:07:34+00:00,https://twitter.com/rasbt/status/1543612417888108544,"@cfsaracho Haha, for spelling, I usually reference the crab from the Disney Mermaid movie. But yeah, Blade Runner being one of my favorite movies of all time, that's a much better reference üòÜ"
4370,@rasbt,2022-07-03 13:05:33+00:00,https://twitter.com/rasbt/status/1543581712113963010,"@NeuroTaha Wow, thanks so much for the kind compliment üòäüôå"
4371,@rasbt,2022-07-03 13:05:19+00:00,https://twitter.com/rasbt/status/1543581656128360448,"@hackathorn @guysnovelutumba Good question! Actually, there is no direct 1:1 correspondence between the two. The one exception is that the Transformer chapter is based on the lectures."
4372,@rasbt,2022-07-03 12:21:50+00:00,https://twitter.com/rasbt/status/1543570713797345289,"@colinraffel It‚Äôs something people don‚Äôt talk about often (enough), thanks for sharing!"
4373,@rasbt,2022-07-03 01:43:07+00:00,https://twitter.com/rasbt/status/1543409971962019843,"@CSkrishna whoa, thanks! üôå"
4374,@rasbt,2022-07-03 01:42:29+00:00,https://twitter.com/rasbt/status/1543409816080732161,"@jay40768744 Yeah, it's always challenging to find the balance between detail and scope. See, because some of the lectures were already too detailed, we ran out of time wrt to dim reduction &amp; feature extraction methods like T-SNE and UMAP üòÖ"
4375,@rasbt,2022-07-02 23:03:32+00:00,https://twitter.com/rasbt/status/1543369813141094406,@AMULETAnalytics Glad to hear that the from-scratch implementation was not too bothersome and on the contrary quite helpful :)
4376,@rasbt,2022-07-02 14:25:07+00:00,https://twitter.com/rasbt/status/1543239348681834496,"@guysnovelutumba Wow glad to hear you are liking it! Haha, and thanks for the kind words!"
4377,@rasbt,2022-07-02 14:17:46+00:00,https://twitter.com/rasbt/status/1543237499945902082,PS: this is for the series here https://t.co/8FhMfL6v3N
4378,@rasbt,2022-07-02 14:17:46+00:00,https://twitter.com/rasbt/status/1543237497915842562,"Feeling thankful that I can kick off this weekend with a motivational message üòä. 
""This series is actually 100 times better than the paid courses. These lectures are gems. Thanks for these lectures Sebastian!"""
4379,@rasbt,2022-07-02 03:19:24+00:00,https://twitter.com/rasbt/status/1543071815446265856,"@ptrblck_de 2/2 Or in other words, I should absolutely toy around with the settings you suggested! However, in practice, I do think that most researchers do take the pow(2) batch size to seriously and can relax about that a little -- no, things won't fall apart and take twice as long üòÖ"
4380,@rasbt,2022-07-02 03:17:12+00:00,https://twitter.com/rasbt/status/1543071262267826176,@ptrblck_de wow thanks for the pointers. Totally agree that this may not be the super scientific benchmark here. I do think though that the kind of simple benchmark may be closer to the real workflow -- something you would actually encounter as a typical researcher. 1/2
4381,@rasbt,2022-07-01 23:10:15+00:00,https://twitter.com/rasbt/status/1543009114586075137,"@JFPuget Yes! I know there are more fun things to do, but in case you want to run it for reference, here's the code: https://t.co/lG7QRPxsR9
Run it as 
python main. py --num_epochs 10 --batch_size ... --mixed_precision true"
4382,@rasbt,2022-07-01 22:37:31+00:00,https://twitter.com/rasbt/status/1543000877597851655,"@JFPuget Good point. Looking into it again, it was around 70-80%. Here is another run with ~99% utilization (couldn't go larger than 513 really due to memory limitations). https://t.co/oRoa6oq3U1"
4383,@rasbt,2022-07-01 22:02:28+00:00,https://twitter.com/rasbt/status/1542992056477417473,"@crashdaddy4 haha, that's indeed hilariousüòÜ"
4384,@rasbt,2022-07-01 21:58:40+00:00,https://twitter.com/rasbt/status/1542991102558470146,"@datasith @svpino @JFPuget Omg I am so sorry üôà. There was a formatting error and the 0.10 was for the validation set. Just reran it to get the test set value, and it's also 0.15 min similar to the other ones. Ahhh, sorry for all the confusion üòûüòî"
4385,@rasbt,2022-07-01 21:47:16+00:00,https://twitter.com/rasbt/status/1542988230353686531,"@francoisfleuret Kind of in the same vein as convolutions, or fully-connected output layers."
4386,@rasbt,2022-07-01 21:41:38+00:00,https://twitter.com/rasbt/status/1542986816374161408,"Worth highlighting that FlashAttention does not use any approximation, and just focuses on optimizing  memory reads/writes. Results in 3.5x faster GPT-2 training, for example."
4387,@rasbt,2022-07-01 21:36:56+00:00,https://twitter.com/rasbt/status/1542985633009991683,"@francoisfleuret Nice one! Yeah, here it's really worth emphasizing the ""no approximations"" part of FlashAttention!"
4388,@rasbt,2022-07-01 21:09:44+00:00,https://twitter.com/rasbt/status/1542978785242382339,@DrGroftehauge It's a tad slower but not that much. Maybe 10-20% slower. But I didn't run all the experiments w/o mixed precision because I think that might be less interesting nowadays
4389,@rasbt,2022-07-01 21:07:52+00:00,https://twitter.com/rasbt/status/1542978314792468480,"@svpino @JFPuget Yes, everything was done with the same batch size here."
4390,@rasbt,2022-07-01 21:07:06+00:00,https://twitter.com/rasbt/status/1542978121913212929,"@JFPuget @datasith @svpino Yeah, I am actually only interested in training performance. For my applications of deep learning (mostly research) inference essentially just means running the model on a test set, which is kind of negligible compared to the training time."
4391,@rasbt,2022-07-01 21:05:19+00:00,https://twitter.com/rasbt/status/1542977675651944449,@datasith @svpino @JFPuget actually it's also a very small test set (Cifar 10). I think that would have to be investigated more to see if the 33% would hold
4392,@rasbt,2022-07-01 19:59:23+00:00,https://twitter.com/rasbt/status/1542961082754547712,"@AiBeginners @127 Good point. Actually, it matches the results here: https://t.co/gUW19eb9mw"
4393,@rasbt,2022-07-01 19:49:37+00:00,https://twitter.com/rasbt/status/1542958625848696835,"@datasith @svpino @JFPuget Honest question: do you care about batch sizes in production? I don't have enough industry experience for that, but I would assume you process queries as they come versus batching them into multiples of 8?"
4394,@rasbt,2022-07-01 19:47:44+00:00,https://twitter.com/rasbt/status/1542958152227905536,"@svpino @JFPuget Yes! Honestly, I am not sure how practical this is though. In production, before servers process a query, do they really wait until they have batch sizes as multiples of 8? üòÜ"
4395,@rasbt,2022-07-01 19:44:45+00:00,https://twitter.com/rasbt/status/1542957398645784579,"@WaltonStevenj @wightmanr Yeah, probably also more noticeable for non-convolutional models."
4396,@rasbt,2022-07-01 19:43:58+00:00,https://twitter.com/rasbt/status/1542957203258228738,"@themintsv üíØYes, that was what I was thinking."
4397,@rasbt,2022-07-01 18:06:22+00:00,https://twitter.com/rasbt/status/1542932639857999873,"@svpino @JFPuget I ran it a second time and yes, I got the same results"
4398,@rasbt,2022-07-01 18:01:00+00:00,https://twitter.com/rasbt/status/1542931288444780544,CC @JFPuget @svpino
4399,@rasbt,2022-07-01 18:00:21+00:00,https://twitter.com/rasbt/status/1542931127509438464,"Ok, I did a quick benchmark with mixed precision on a V100 here (https://t.co/QEgrVNQ2xC). 
Honestly, I think that it's okay not to worry about forcing it to be powers of 2 or multiples of 8. https://t.co/isLbALuAqi"
4400,@rasbt,2022-07-01 17:22:54+00:00,https://twitter.com/rasbt/status/1542921702115627008,@wightmanr Interesting. I am still 99.9% in GPU land and never really had access to / used a TPU.
4401,@rasbt,2022-07-01 16:12:15+00:00,https://twitter.com/rasbt/status/1542903923580731393,@JFPuget Let me test it again later on a V100. Will keep you posted
4402,@rasbt,2022-07-01 16:10:50+00:00,https://twitter.com/rasbt/status/1542903565127237643,@JFPuget I did some a few years ago and couldn‚Äôt see a difference. Maybe incorrect use. Also I didn‚Äôt try a V100
4403,@rasbt,2022-07-01 16:05:51+00:00,https://twitter.com/rasbt/status/1542902311781113856,"@JFPuget Yeah, it makes sense. I would like to see a practical example though."
4404,@rasbt,2022-07-01 16:03:52+00:00,https://twitter.com/rasbt/status/1542901813447360518,@nachimak28 Just clicking through it. There don't seem to be any solutions to the exercises though? ü§î
4405,@rasbt,2022-07-01 16:01:12+00:00,https://twitter.com/rasbt/status/1542901142056828930,"@JFPuget It would be interesting to have that in the context of some control experiment. Say
132 -&gt; 128 versus 133 -&gt; 129"
4406,@rasbt,2022-07-01 15:52:14+00:00,https://twitter.com/rasbt/status/1542898884766203908,@DrGroftehauge üíØ
4407,@rasbt,2022-07-01 15:51:41+00:00,https://twitter.com/rasbt/status/1542898745762877441,@JFPuget Practical benchmark pls! I mean I get the theory behind it but I would really like to see a practical example where it makes a noticeable difference using some standard architecture like ResNet.
4408,@rasbt,2022-07-01 15:49:02+00:00,https://twitter.com/rasbt/status/1542898080315576320,"""Pen &amp; Paper Exercises in Machine Learning"" -- probably the most interesting arXiv article I've seen in a while ‚ò∫Ô∏è
üìù  https://t.co/JQWhJadxzo 
Love it when exercises come with solutions. üëå
(Textbooks with exercises but w/o solutions are truly evil üòÜ). https://t.co/bULUF1UclK"
4409,@rasbt,2022-07-01 15:04:52+00:00,https://twitter.com/rasbt/status/1542886963090526211,"@ThFriedrich1 Good point. Dunno, but I remember running some experiments back then when I used TensorFlow 1 and also didn't notice any differences really."
4410,@rasbt,2022-07-01 14:48:41+00:00,https://twitter.com/rasbt/status/1542882893181108227,"""Do Batch Sizes Actually Need to be Powers of 2?"" The answer is no, there is no noticeable training speed diff. Thank you. In class, I usually mention that it's 
1. mostly done for historical reasons
2. makes it look less like cherry-picking
3. constraints the number of hypeparam"
4411,@rasbt,2022-07-01 14:21:06+00:00,https://twitter.com/rasbt/status/1542875950198702081,"@overlordayn Fair. But also only ""some"" üòÖ"
4412,@rasbt,2022-07-01 14:18:36+00:00,https://twitter.com/rasbt/status/1542875323209027586,"@adamcifu @beenwrekt You got my attention when I had to check ""1 - Specificity = FPR"""
4413,@rasbt,2022-07-01 14:08:27+00:00,https://twitter.com/rasbt/status/1542872768378724352,"In recent years, we have seen a whole bunch of ""efficient"" self-attention alternatives w. linear complexity (Longformer, Linformer, Nystr√∂mformer, Performer etc). In practice, they don't matter? Recent language transformers don't use them (eg see LaMDA https://t.co/qxhrAZeM7C) ü§î"
4414,@rasbt,2022-07-01 12:07:28+00:00,https://twitter.com/rasbt/status/1542842320810393600,"@svpino @e_kazakos @giffmana Yeah, I agree with that"
4415,@rasbt,2022-06-30 21:52:11+00:00,https://twitter.com/rasbt/status/1542627079832870912,"If you are like me and not really into all the recent digital image art stuff, this is a really good summary:"
4416,@rasbt,2022-06-30 21:43:11+00:00,https://twitter.com/rasbt/status/1542624818503319554,@JFPuget @giffmana @renegadesilicon That's a pretty plausible hunch.  Would indeed love to see a paper on this üòä
4417,@rasbt,2022-06-30 21:21:05+00:00,https://twitter.com/rasbt/status/1542619256550002688,"@renegadesilicon @giffmana Yeah, they are often highly correlated. But I find accuracy really much easier to read. I have a better idea of overfitting if I see 95% training accuracy vs 70% validation accuracy compared to a loss of 0.223 vs 0.181"
4418,@rasbt,2022-06-30 21:17:26+00:00,https://twitter.com/rasbt/status/1542618336072171522,"@giffmana @JFPuget Sadly, there is no incentive for proper evaluation in the current academic research landscape"
4419,@rasbt,2022-06-30 21:15:45+00:00,https://twitter.com/rasbt/status/1542617911080230912,"@paul_rietschka @__mharrison__ @alfcnz @ammaryh92 @svpino Ah yes, good point. If you forget to shutdown your notebook, that can be costly üòÜ. In a Lightning App you can set a time_out to shutdown the expensive GPU instances automatically after training. You can also attach a Jupyter Notebook component to it."
4420,@rasbt,2022-06-30 21:07:34+00:00,https://twitter.com/rasbt/status/1542615851270111232,"@paul_rietschka @__mharrison__ @alfcnz @ammaryh92 @svpino Yeah, I honestly just want a place where I can run my scripts on a multi-GPU machine, or sometimes I just want a simple GPU JupyterLab notebook. It should be as easy as running it locally, but I don't need extra fluff on top. Btw here is an example of the JupyterLab interface https://t.co/j0WY5vB6UQ"
4421,@rasbt,2022-06-30 20:36:11+00:00,https://twitter.com/rasbt/status/1542607954427396098,@paul_rietschka @__mharrison__ @alfcnz @ammaryh92 @svpino For remote notebooks I just use Grid: I can just spin up a notebook with whatever number of GPUs I need for however long I like. And it's easy to pause &amp; resume to not waste credits. (Although I usually run multi-GPUs run as scripts coz generally notebooks don't do well with DDP)
4422,@rasbt,2022-06-30 20:33:51+00:00,https://twitter.com/rasbt/status/1542607366616764418,"@paul_rietschka @__mharrison__ @alfcnz @ammaryh92 @svpino Yeah, I find AWS way too complicated. I find it so clunky that I had to write a book chapter for myself to remember all that steps üòÜ (https://t.co/MSwdy7xdMq). Honestly, I had the same impression with GCP."
4423,@rasbt,2022-06-30 20:22:19+00:00,https://twitter.com/rasbt/status/1542604464242171904,@paul_rietschka @__mharrison__ @alfcnz @ammaryh92 @svpino GCP has always been too much hassle for me. Same with EC2 instances. Even had education grants for both but students also found it too much work to set it up.
4424,@rasbt,2022-06-30 19:46:57+00:00,https://twitter.com/rasbt/status/1542595563723661312,"@e_kazakos @giffmana Hm, to me everything where training &gt; validation performance indicates overfitting. That's the canonical definition of overfitting afaik. But sure, I would use that model with peak validation performance as my final model. That's usually built into my training scripts."
4425,@rasbt,2022-06-30 19:35:15+00:00,https://twitter.com/rasbt/status/1542592619037048832,"@giffmana @JFPuget To quote a colleague, who made a good point: ""If you have access to the labels of the test dataset, then it is a validation dataset and the methodology isn‚Äôt done properly."""
4426,@rasbt,2022-06-30 19:33:43+00:00,https://twitter.com/rasbt/status/1542592233328852993,"@giffmana Actually, I look at the spread between training accuracy*  and validation accuracy during training. I do look at the validation loss also, but never really at the training-validation loss spread.

(*or alternative eval metric)"
4427,@rasbt,2022-06-30 19:09:00+00:00,https://twitter.com/rasbt/status/1542586015730352128,"@ThomasViehmann I'd say it depends on the context: for academic papers, people prefer easy accuracy estimates (esp. if they are positively biased). And my guess is that people whose money depends on it (like some ML purchasing system) will probably go the extra mile"
4428,@rasbt,2022-06-30 18:46:22+00:00,https://twitter.com/rasbt/status/1542580319496409089,"@Teach37932576 Wow, thanks so much for the kind words üòä. Also, I wish all the best on your journey -- you will see, machine learning is a lot of fun! üôå"
4429,@rasbt,2022-06-30 15:20:48+00:00,https://twitter.com/rasbt/status/1542528588263706624,"How do we make our research models available for practical use? And how can we tap into extra GPU hardware and servers? 
Check out my new blog post on Leveraging the Cloud: https://t.co/Qbh5Qd0aCZ"
4430,@rasbt,2022-06-30 14:51:19+00:00,https://twitter.com/rasbt/status/1542521168271290368,"@roydanroy Also, in my opinion, ditching Beamer is already half the battle."
4431,@rasbt,2022-06-30 14:49:14+00:00,https://twitter.com/rasbt/status/1542520643387658241,"@roydanroy ""slide:ology: The Art and Science of Creating Great Presentations"" by Nancy Duarte is a good starter."
4432,@rasbt,2022-06-30 14:38:24+00:00,https://twitter.com/rasbt/status/1542517914334507009,"@paul_rietschka @__mharrison__ @alfcnz @ammaryh92 @svpino ahh, I see"
4433,@rasbt,2022-06-30 14:24:24+00:00,https://twitter.com/rasbt/status/1542514391316238337,@paul_rietschka @__mharrison__ @alfcnz @ammaryh92 @svpino Why? What's the problem with TensorFlow on Grid? You mean you would like TPU support?
4434,@rasbt,2022-06-30 13:59:02+00:00,https://twitter.com/rasbt/status/1542508007845597184,"@__mharrison__ @alfcnz @ammaryh92 @svpino I mean, if I want a notebook with one or more GPUs, I typically just spin up a Session on https://t.co/ufnsjwpbAF, which come with plain JupyterLab interfaces https://t.co/agRF9AzBgN"
4435,@rasbt,2022-06-30 13:50:23+00:00,https://twitter.com/rasbt/status/1542505834013306882,"@paul_rietschka @__mharrison__ @samsja19 @ammaryh92 @jeremyphoward @svpino I use it occasionally for data loading and some light preprocessing, but it's literally just a few lines at most. I usually work mostly with array data these days."
4436,@rasbt,2022-06-30 13:24:41+00:00,https://twitter.com/rasbt/status/1542499366828662784,"@__mharrison__ @samsja19 @ammaryh92 @jeremyphoward @svpino I just realize that I haven't really used Pandas much in the last couple of years. I wonder if this is a problem that can be addressed by increasing the black line-length so that it doesn't attempt to break up the lines (but yeah, if you prefer shorter lines that doesn't help)"
4437,@rasbt,2022-06-30 02:12:17+00:00,https://twitter.com/rasbt/status/1542330148560699394,"@PhDemetri Yes, agree üíØif you take it literally. In the same sense, evaluating on an independent test dataset does not improve the model"
4438,@rasbt,2022-06-30 01:43:48+00:00,https://twitter.com/rasbt/status/1542322982621782017,@__mharrison__ @alfcnz @ammaryh92 @svpino I actually don't use Colab because of the UI. There is something about it (probably visually) that makes me want to use JupyterLab (or even Jupyter Notebook would be fine).
4439,@rasbt,2022-06-30 00:55:16+00:00,https://twitter.com/rasbt/status/1542310767780839427,@alfcnz @__mharrison__ @ammaryh92 @svpino Can you elaborate on the environments part? Do you mean UI-wise?
4440,@rasbt,2022-06-30 00:54:15+00:00,https://twitter.com/rasbt/status/1542310510686863365,"@samsja19 @ammaryh92 @jeremyphoward @__mharrison__ @svpino Yes, that's another really nice one I use regularly for important things."
4441,@rasbt,2022-06-29 19:22:34+00:00,https://twitter.com/rasbt/status/1542227041424113664,@ammaryh92 @__mharrison__ @svpino JupyterLab. I mainly like the tab UI and the visual debugger
4442,@rasbt,2022-06-29 19:14:42+00:00,https://twitter.com/rasbt/status/1542225059577741313,"@JermaFan8517 No, I don‚Äôt have an M2 ü•πüòÖ"
4443,@rasbt,2022-06-29 15:48:16+00:00,https://twitter.com/rasbt/status/1542173108940988416,@maosbot @ZoubinGhahrama1 @PhilippHennig5 Wow that looks awesome! Just added it to my reading list ‚ò∫Ô∏è
4444,@rasbt,2022-06-29 15:45:33+00:00,https://twitter.com/rasbt/status/1542172427563720707,@simonkmtse Could be due to thermal throttling on laptops
4445,@rasbt,2022-06-29 14:34:58+00:00,https://twitter.com/rasbt/status/1542154663876780036,@Kaszanas They provide alternative data frame APIs üòä
4446,@rasbt,2022-06-29 12:45:50+00:00,https://twitter.com/rasbt/status/1542127200023068674,"@wiebe74117332 @PyTorchLightnin Good one! In that case, I'd probably pick a random forest or logistic regression model, forgo tuning, and use LOOCV or the 0.632+ bootstrap for evaluation üòä"
4447,@rasbt,2022-06-29 12:43:55+00:00,https://twitter.com/rasbt/status/1542126719670394880,@simonkmtse The RTX is better in this case as well. Or do you mean the laptop cards? https://t.co/JIcFCNdHha
4448,@rasbt,2022-06-29 11:50:20+00:00,https://twitter.com/rasbt/status/1542113231094833153,@simonkmtse You mean the 2nd row from the bottom? That‚Äôs an RTX 2080Ti
4449,@rasbt,2022-06-29 01:05:18+00:00,https://twitter.com/rasbt/status/1541950904366256129,[3/3] The new TorchArrow library looks fun! It's basically a pandas DataFrame for PyTorch tensors. (There's a nice hands-on tutorial here: https://t.co/1wcS3AGt9s)
4450,@rasbt,2022-06-29 01:05:18+00:00,https://twitter.com/rasbt/status/1541950903074316288,[2/3] Integrated support for ARM GPUs (M1 &amp; M2) on macOS. No more installation of nightly releases necessary. (What's the performance of running DNNs on a Mac you ask? Also got you covered here: https://t.co/6f0HX8yYwp)
4451,@rasbt,2022-06-29 01:05:17+00:00,https://twitter.com/rasbt/status/1541950901564342272,"Wohoo, PyTorch 1.12 is out! Detailed release notes here: https://t.co/btpSpjsfCf.
Interesting (personal top 3) highlights
1) Updated DataPipes -- now with fully working shuffling and sharding (what are DataPipes? See my recent blogpost here: https://t.co/wnHQM2Itz8)
[1/3]"
4452,@rasbt,2022-06-28 21:55:35+00:00,https://twitter.com/rasbt/status/1541903160956141568,"@Ne_oL @PyTorchLightnin Good q! The short tweet-compatible answer: If you tuned your model using k-fold cross-validation, then the performance estimate is likely optimistically biased (the prediction performance will look better than it really is) due to overfitting/-tuning to the validation folds."
4453,@rasbt,2022-06-28 20:45:24+00:00,https://twitter.com/rasbt/status/1541885499924774914,@JFPuget @ph_singer @PyTorchLightnin ü§£
4454,@rasbt,2022-06-28 20:36:59+00:00,https://twitter.com/rasbt/status/1541883380513521664,@ph_singer @JFPuget @PyTorchLightnin Little known fact (and preceding attention by 2 years): https://t.co/5t5P8bs1TM
4455,@rasbt,2022-06-28 20:33:24+00:00,https://twitter.com/rasbt/status/1541882477710557185,"@david_macedo @GaryMarcus @hardmaru @EthanJPerez @MelMitchell1 Ok fair, it would be too easy otherwise üòÜ"
4456,@rasbt,2022-06-28 20:02:04+00:00,https://twitter.com/rasbt/status/1541874594868510722,@hardmaru @GaryMarcus @EthanJPerez @MelMitchell1 Fun exam question I usually do is to sketch the boundary of an unpruned decision tree on a dataset like this üôÑ
4457,@rasbt,2022-06-28 20:01:14+00:00,https://twitter.com/rasbt/status/1541874382649249792,"@GaryMarcus @hardmaru @EthanJPerez @MelMitchell1 Wait, isn't it about bigger models (not bigger datasets)? Or am I missing a subtle point here?"
4458,@rasbt,2022-06-28 19:48:06+00:00,https://twitter.com/rasbt/status/1541871079194599427,@red__eyed @PyTorchLightnin Best ML satire ever: https://t.co/BPqzWkSFqj
4459,@rasbt,2022-06-28 19:47:07+00:00,https://twitter.com/rasbt/status/1541870830300299266,@ph_singer @PyTorchLightnin CC @tunguz üòÜ
4460,@rasbt,2022-06-28 19:28:03+00:00,https://twitter.com/rasbt/status/1541866033824292867,"@PyTorchLightnin Oh, here's another one: Calibration methods such as Platt scaling and Isotonic regression can be used improve the ROC AUC performance on Kaggle."
4461,@rasbt,2022-06-28 19:14:38+00:00,https://twitter.com/rasbt/status/1541862657258569728,"@var_tec @seldo @kchonyc Haha, and that was A/B testing or just trolling?"
4462,@rasbt,2022-06-28 19:12:45+00:00,https://twitter.com/rasbt/status/1541862182278791168,"@PyTorchLightnin Hah, that's a good question ü§î. I can maybe think of worse ones, but for starters, a professor once told me that since I used k-fold cross-validation, I didn't have to use a independent test set üôÑ"
4463,@rasbt,2022-06-28 14:26:57+00:00,https://twitter.com/rasbt/status/1541790258433560580,"@nezubn @seldo @kchonyc Probably üòÜ. Also, I forgot Duo!"
4464,@rasbt,2022-06-28 14:20:37+00:00,https://twitter.com/rasbt/status/1541788663277027328,"@seldo @kchonyc And then there's Google Meet and Allo ü§Ø. Haha, this is ridiculous. All this to avoid semantic versioning!?"
4465,@rasbt,2022-06-28 14:12:32+00:00,https://twitter.com/rasbt/status/1541786633091031043,@MikeKimel @ilyasut üî•
4466,@rasbt,2022-06-28 13:45:40+00:00,https://twitter.com/rasbt/status/1541779868504956929,Amazingly thorough article by @reshamas. Lot's of useful lessons and take-aways if you are planning sprints for your open source library.
4467,@rasbt,2022-06-28 13:36:07+00:00,https://twitter.com/rasbt/status/1541777465655410688,"@TheZachMueller @svpino Haha ok, I thought I missed something. I think git checkout will still stick around for backward compat, but yeah, it's mainly a refactoring into ""switch"" and ""restore"""
4468,@rasbt,2022-06-28 13:32:05+00:00,https://twitter.com/rasbt/status/1541776449404911616,"@TheZachMueller @svpino Also, the most upvoted comment: ""Helpful note: for those used to git checkout -b &lt;branch name&gt; you can use git switch -c &lt;branch name&gt; to get the same effect"" ü§î"
4469,@rasbt,2022-06-28 13:31:32+00:00,https://twitter.com/rasbt/status/1541776310959210498,@TheZachMueller @svpino How's that's explaining the differences though üòÜ https://t.co/H6EnWERpkQ
4470,@rasbt,2022-06-28 13:28:44+00:00,https://twitter.com/rasbt/status/1541775610246316034,"@twitganglion Oh yeah, that's a good one!"
4471,@rasbt,2022-06-28 13:20:35+00:00,https://twitter.com/rasbt/status/1541773555691560962,"@ph_singer Ok fair üòÜ ""Based on our calculations, we expect the free credits provided by OpenAI to be enough to evaluate most tasks at least once across all model sizes."""
4472,@rasbt,2022-06-28 13:12:20+00:00,https://twitter.com/rasbt/status/1541771479720812544,"This sounds like a fun challenge! If you are smart about keeping the training costs down, you could maybe even make a few bucksüòÖ"
4473,@rasbt,2022-06-28 13:07:06+00:00,https://twitter.com/rasbt/status/1541770163682508805,@TheZachMueller @svpino Oh I thought they were equivalent üòÜ. What's the main diff between the two?
4474,@rasbt,2022-06-28 13:02:58+00:00,https://twitter.com/rasbt/status/1541769124447195136,"@zzdjb_desu Nice, should give it a try! @adrianwaelchli is a big fan and probably one of the most productive people I ever met. Enough reason to check it out :)"
4475,@rasbt,2022-06-28 13:02:18+00:00,https://twitter.com/rasbt/status/1541768956444348417,World models and large language models. Did I get this right? ü§î https://t.co/ImbtsDZv0C
4476,@rasbt,2022-06-28 12:30:07+00:00,https://twitter.com/rasbt/status/1541760859025842177,@MikeKimel @ilyasut PR actually üòÜ
4477,@rasbt,2022-06-28 12:29:38+00:00,https://twitter.com/rasbt/status/1541760735939805184,"@SchuelerMo Thanks! Yeah, pip is also what I use as the default in tutorials because it works pretty universally. I wonder if there is an elegant way to exclude sub-dependencies (I usually manually grep the main libraries to make it more human readable)"
4478,@rasbt,2022-06-28 00:46:08+00:00,https://twitter.com/rasbt/status/1541583692174327809,@dcseifert My guess is it only exist to empty their touchbars from their inventory
4479,@rasbt,2022-06-28 00:13:38+00:00,https://twitter.com/rasbt/status/1541575516163084288,"@hasibzunair @PyTorchLightnin Nice! Btw if you feel like the email component is in a way too limited, you don‚Äôt need to use it as is! It‚Äôs easy to customize and we also welcome suggestions and contributions :)  https://t.co/KCWmAnOyHc"
4480,@rasbt,2022-06-28 00:12:46+00:00,https://twitter.com/rasbt/status/1541575296574447616,"@YuraFiftyTwo Haha, I complained about the naming of ""checkout"" in the video and just realized in the post-editing that there is indeed a ""switch"" now. Nice!"
4481,@rasbt,2022-06-28 00:10:14+00:00,https://twitter.com/rasbt/status/1541574660592226306,@EthanJPerez @hardmaru Sounds like a fun weekend project üòÜ. CC @GaryMarcus
4482,@rasbt,2022-06-28 00:08:03+00:00,https://twitter.com/rasbt/status/1541574108374253569,"@haltakov @terrible_coder Hah same, was setting up a new computer recently and it was a good reason to give omz a try"
4483,@rasbt,2022-06-27 23:40:27+00:00,https://twitter.com/rasbt/status/1541567164829896706,@andrewgwils Wohoo! Big congrats üçæüéä
4484,@rasbt,2022-06-27 21:12:14+00:00,https://twitter.com/rasbt/status/1541529863588397057,"@ccanonne_ Of course. It‚Äôs 2022, these things usually work smoothly nowadays üòá."
4485,@rasbt,2022-06-27 21:11:14+00:00,https://twitter.com/rasbt/status/1541529612458594307,"@terrible_coder @haltakov Ahh, thanks."
4486,@rasbt,2022-06-27 20:49:04+00:00,https://twitter.com/rasbt/status/1541524032515866625,"@haltakov Haha, I can finally clean up my .zshrc then üòÜ"
4487,@rasbt,2022-06-27 20:45:59+00:00,https://twitter.com/rasbt/status/1541523256808816644,"@haltakov Whoa, did not know these came out of the box, thanks for sharing!"
4488,@rasbt,2022-06-27 20:00:13+00:00,https://twitter.com/rasbt/status/1541511739006750721,@svpino üëç. Did not know you can use `-d` to delete branches now. My muscle memory defaults to `-D` (capital D) for for some reason.
4489,@rasbt,2022-06-27 19:17:23+00:00,https://twitter.com/rasbt/status/1541500961990090753,"@jeethu Haha, yip, agreed!"
4490,@rasbt,2022-06-27 19:10:34+00:00,https://twitter.com/rasbt/status/1541499246947565579,"@jeethu fair. but it's a drop-in replacement though and all the commands are identical, right?"
4491,@rasbt,2022-06-27 18:46:49+00:00,https://twitter.com/rasbt/status/1541493268285952002,"I found branching super intriguing when I started using Git. But as a fresh grad student, I really appreciated that it encouraged experimentation.
Pro Tip: You can create &amp; checkout branches with a single command:
`git checkout -b my-new-branch`
What are your favorite shortcuts?"
4492,@rasbt,2022-06-27 18:26:25+00:00,https://twitter.com/rasbt/status/1541488135380541440,"@BeebsMemes @erikrtn @igor_chubin wow, very nice! thanks for sharing!"
4493,@rasbt,2022-06-27 18:19:53+00:00,https://twitter.com/rasbt/status/1541486489640509442,"@LGthnk4yourself @ilyasut Yup, one was inspired by the other, and they are based on a similar concept. Ultimately, they are relatively different things though. Basically the same relationship as the one between the first mathematical neuron model and the biological neuron."
4494,@rasbt,2022-06-27 16:36:08+00:00,https://twitter.com/rasbt/status/1541460380899086337,@ilyasut 2022 is an interesting year for ML &amp; AI ü§î https://t.co/wypef5mj1s
4495,@rasbt,2022-06-27 16:25:12+00:00,https://twitter.com/rasbt/status/1541457631390404608,"@YassineAlouini Hah, no, that was just a relatively quick copy &amp; paste and formatting in keynote. Notion would have taken me at least 2x as long."
4496,@rasbt,2022-06-27 16:24:33+00:00,https://twitter.com/rasbt/status/1541457464280944640,"@anuragsaharoy Good call regarding the --no-builds flag. Updated it in the https://t.co/iLxUSVqe6G file. Yeah, agree with the --from-history. Unless you want the latest packages, maybe less useful from a reproducibility standpoint."
4497,@rasbt,2022-06-27 14:21:21+00:00,https://twitter.com/rasbt/status/1541426463634751492,PDF version: https://t.co/gnf2EoPkRH
4498,@rasbt,2022-06-27 14:18:32+00:00,https://twitter.com/rasbt/status/1541425752750579713,Made a little conda environment export cheatsheet ... because I still have to look it up every time https://t.co/3Xr6igMeeQ
4499,@rasbt,2022-06-27 12:41:42+00:00,https://twitter.com/rasbt/status/1541401385203552256,Python 4.0 is out
4500,@rasbt,2022-06-27 12:24:33+00:00,https://twitter.com/rasbt/status/1541397066731094016,"@akshay_pachaar @roydanroy Afaik all citations go into the H-index on Google Scholar. So if you have papers in JOSS and impactful blog articles or preprints cited in academic work, then yes, that would be used in the H-index calculation afaik"
4501,@rasbt,2022-06-27 12:21:20+00:00,https://twitter.com/rasbt/status/1541396259252101120,"@roydanroy Citation counts are harmful. If citation counts must be used, Google Scholar at least also tracks blog posts and open source work (e.g., JOSS) when it is cited in academic papers -- those impactful things that are usually considered ""invisible labor"" in other citation databases."
4502,@rasbt,2022-06-26 20:11:26+00:00,https://twitter.com/rasbt/status/1541152177108013060,@therriaultphd *priced of course üòÇ
4503,@rasbt,2022-06-26 18:42:24+00:00,https://twitter.com/rasbt/status/1541129767881170944,"@taocds Oh, I don't know how these details work üòÖ. Thanks for the suggestion though. I think the cost is due to the Amazon print pricing (afaik the publ doesn't have a warehouse etc. and everything in print-on-demand). The silver lining is maybe that it's not as bad for the environment"
4504,@rasbt,2022-06-26 18:16:45+00:00,https://twitter.com/rasbt/status/1541123313891770374,"@therriaultphd Haha, thanks. And yes, definitely! I am not sure if I would go with a textbook publisher though -- many textbooks are also often ridiculously prized üôÉ. Also for the sake of making things more manageable for both author &amp; reader, I though &lt; 400 pages should be the goal."
4505,@rasbt,2022-06-26 18:14:19+00:00,https://twitter.com/rasbt/status/1541122702735511552,@therriaultphd That's the Amazon print service. Regarding books in general: totally. I think I have seen 800+ textbooks.
4506,@rasbt,2022-06-26 15:34:47+00:00,https://twitter.com/rasbt/status/1541082553905463299,"@moo_hax Thanks, yeah that‚Äôs a good suggestion! But yeah, that‚Äôs what the  publisher already did to be able to fit the book into the page limit for the current print version. I think we were able to cut more than 100 pages with the smaller margins and smaller font size"
4507,@rasbt,2022-06-26 15:00:12+00:00,https://twitter.com/rasbt/status/1541073852096282630,"@MiguelCRomao There are still some differences in the font size though. So, I would say that the PDF is maybe the best version. In any case, this time all digital versions have at least syntax color :)"
4508,@rasbt,2022-06-26 14:56:04+00:00,https://twitter.com/rasbt/status/1541072809895624705,"@MiguelCRomao For many books, I prefer reading them in traditional paperback form on a comfy chair far away from my computer (so I am more focused), but then for a second pass where I toy around with the code, I actually do prefer digital versions so I can have them side-by-side on my computer"
4509,@rasbt,2022-06-26 14:54:29+00:00,https://twitter.com/rasbt/status/1541072411394703360,"@MiguelCRomao Can totally understand. Tbh the ebook versions are actually great. We used a new layout, and the math formulas look exceptionally good in the Kindle versions as well in my opinion (compared to typical Kindle books)."
4510,@rasbt,2022-06-26 14:47:56+00:00,https://twitter.com/rasbt/status/1541070765650583555,@tdietterich @thegautamkamath Absolutely!
4511,@rasbt,2022-06-26 14:47:05+00:00,https://twitter.com/rasbt/status/1541070549941633026,The only option would be to maybe cut it into 2 volumes of 400 pages each. With selected pgs in color (~70 each). Might come down to $50 per book -- but still too expensive coz now readers would have to buy it as 2 volumes. Memo to myself that my futures books shall be shorter üòá
4512,@rasbt,2022-06-26 14:47:05+00:00,https://twitter.com/rasbt/status/1541070548767326211,"Personally, I would love to have a color print version for myself, too. Even for the 600 pages it's $118! üòµ. The reason why it's so expensive is that it's a print-on-demand title. It's basically what Amazon charges for printing (no profit margin for the publisher included)"
4513,@rasbt,2022-06-26 14:47:04+00:00,https://twitter.com/rasbt/status/1541070547479666688,"There were lots of queries asking for a color print option of my book! Talked to the publisher &amp; turns out that's unfortunately not feasible :(. Actually, the page limit printers can handle for color is 600 -- would have to trim 150+ pages. Will write a shorter book next time! üòÖ"
4514,@rasbt,2022-06-26 14:36:10+00:00,https://twitter.com/rasbt/status/1541067804522192897,"@TaliaRinger @UlrichJunker Yeah, if you want to game the system, you could just write a paper with a controversial take on a popular problem, or maybe try to get some weird, wrong result published. You can prob argue that lots of negative cites mean high ""impact"" but that doesn't imply it's good research"
4515,@rasbt,2022-06-26 14:29:48+00:00,https://twitter.com/rasbt/status/1541066201002086402,"@thegautamkamath However, academic reviews aside, I do think that Google Scholar would be equally useful if it didn't have individual researcher profiles."
4516,@rasbt,2022-06-26 14:28:01+00:00,https://twitter.com/rasbt/status/1541065752765239296,"@thegautamkamath I do like Google Scholar as a service though, i.e., it's pretty easy to find relevant papers &amp; related works that way. But yeah, citation counts in research profiles is probably only relevant for annual academic reviews (I usually listed mine there -- committee found it useful)"
4517,@rasbt,2022-06-26 14:25:22+00:00,https://twitter.com/rasbt/status/1541065083354316800,"@thegautamkamath Many years ago, I mentioned to my PhD advisor that she doesn't have a Google Scholar profile. I don't remember her exact response but it was something along the lines of what value does it add and that you really don't need it for anything."
4518,@rasbt,2022-06-25 12:05:36+00:00,https://twitter.com/rasbt/status/1540667525519683585,"@marcoseduardoek We are a remote-first company, and there isn‚Äôt a geographic restriction afaik. :)"
4519,@rasbt,2022-06-24 21:34:31+00:00,https://twitter.com/rasbt/status/1540448306492473346,"@__mharrison__ Whoa, the video compression is strong with this one. Btw to make it a bit more easy to see: the way you activate the visual debugger is by clicking the ""bug"" symbol (should come by default in recent JupyterLab versions) https://t.co/qjjAgP4L6d"
4520,@rasbt,2022-06-24 19:54:05+00:00,https://twitter.com/rasbt/status/1540423032027611143,@xamat @NetflixResearch So Netflix shows their movies in theaters after all
4521,@rasbt,2022-06-24 19:38:38+00:00,https://twitter.com/rasbt/status/1540419143727562752,@_curious_human @__mharrison__ that was a quick&amp;dirty QuickTime screen recording üòÖ
4522,@rasbt,2022-06-24 19:33:24+00:00,https://twitter.com/rasbt/status/1540417828133785606,Looking for clean and organized code implementations of various variational autoencoders in PyTorch? This is THE repo: https://t.co/NnPFMKDi7u
4523,@rasbt,2022-06-24 19:18:42+00:00,https://twitter.com/rasbt/status/1540414128229064704,@JirkaBorovec @github Wow! Achievement unlocked! Congrats!
4524,@rasbt,2022-06-24 19:17:00+00:00,https://twitter.com/rasbt/status/1540413702410731520,@__mharrison__ Using the visual debugger! https://t.co/RzoM2cwJMw
4525,@rasbt,2022-06-24 17:02:26+00:00,https://twitter.com/rasbt/status/1540379837571145728,"@LechMazur Curious how the train/test gap looks like. Could be that SAM is say 85/83 percent ACC, and ERM is like 95/85. I mean, technically ERM would have a better generalization accuracy, but yeah, it's still interesting to think about this in terms of overfitting though"
4526,@rasbt,2022-06-24 15:48:06+00:00,https://twitter.com/rasbt/status/1540361130245341185,"So, it turns out that we have to take the suggestion that ""flatter solutions generalize better than sharper solutions to unseen data"" with a grain of salt. 
At least when it comes to using the Œª_max sharpness measure (based on the largest eigenvalue of the loss Hessian)"
4527,@rasbt,2022-06-24 15:36:16+00:00,https://twitter.com/rasbt/status/1540358150167076865,"Yes, we are hiring! Nearing my 6-month anniversary, joining the Lightning team was one of my best decisions so far. It feels really awesome to be part of a smart, motivated, and fun team!"
4528,@rasbt,2022-06-24 14:26:30+00:00,https://twitter.com/rasbt/status/1540340593657774080,"""Why do a lot of researchers like to submit the paper just at the deadline of the conferences?"" (https://t.co/3fhslQ6s8E). Haha, yeah, ""like"" is not the right word. More like ""Have to."" (""Could use another 2 weeks but we have to submit now because we are running out of time"") üòÜ"
4529,@rasbt,2022-06-24 11:52:59+00:00,https://twitter.com/rasbt/status/1540301959357407232,@stevejpurves @kacodes @ph_singer Yeah where it actually really helps is when you write a conference paper with a strict page limit. I still try to resist that and try to eyeball it before pasting my draft into the latest template for the final editing and trimming.
4530,@rasbt,2022-06-23 21:36:39+00:00,https://twitter.com/rasbt/status/1540086455321649155,"@ph_singer @ZefsGuides No, I don't think so, unless that's a new feature or so. Usually, you write in a Markdown flavor. It used to be ""Leanpub Flavoured Markdown"" and is ""Markua"" now. They then have scripts converting that internally to the layouted version."
4531,@rasbt,2022-06-23 13:58:02+00:00,https://twitter.com/rasbt/status/1539971041555951617,"@ph_singer Oh I see. Yeah, for me I'd easily get distracted and would fix formatting issues as they occur and then probably wouldn't get anything else done üòÖ. Honestly, I also even sometimes just write in TextEdit (I have it set to plaintext by default) so that I get less distracted"
4532,@rasbt,2022-06-23 12:54:41+00:00,https://twitter.com/rasbt/status/1539955099010797574,"@ph_singer Yes, it really is. Latex is of course more powerful, but markdown is perfect for drafting. It‚Äôs better at letting you focus on the content, not formatting."
4533,@rasbt,2022-06-22 22:01:31+00:00,https://twitter.com/rasbt/status/1539730327127695362,"@ChristophR1996 @PyTorchLightnin @_willfalcon Wohoo! Thanks for joining us! It was nice meeting you, and I am glad to hear you had a great time! ‚ö°Ô∏è"
4534,@rasbt,2022-06-22 18:08:53+00:00,https://twitter.com/rasbt/status/1539671783779012608,"@wightmanr @huggingface Wow! congrats, Ross! üçæ All the best in your new role, and happy to hear timm is going to be continued! üéâ Sounds like a win-win!"
4535,@rasbt,2022-06-22 15:42:58+00:00,https://twitter.com/rasbt/status/1539635063230545920,"@CSkrishna @ctitusbrown Yes, we are ü§ê! And thanks for the kind words!!"
4536,@rasbt,2022-06-22 15:41:51+00:00,https://twitter.com/rasbt/status/1539634783080402944,"@ctitusbrown @CSkrishna Yes, please!!

Thanks to your inspiration there is one from 2013: https://t.co/gQF8I6dNHq But omg, I really can't look at my old blog posts üôà"
4537,@rasbt,2022-06-22 12:08:44+00:00,https://twitter.com/rasbt/status/1539581147499401217,"@jvrlrnzdz @tunguz Actually, that does look very interesting. Thanks for mentioning!"
4538,@rasbt,2022-06-22 02:44:14+00:00,https://twitter.com/rasbt/status/1539439085617655808,@sean_abreau @shelbyh_ai @marktenenholtz Yeah should probably make a agh action for that. But these tools are pretty stable these days and probably don‚Äôt change that much?
4539,@rasbt,2022-06-22 00:17:06+00:00,https://twitter.com/rasbt/status/1539402061053304832,"@tunguz @paul_rietschka I do think that the Notebook issue could probably be resolved with the right extension or plugin. For now there is nbdev of course, but I think sth like that could also be integrated in the future."
4540,@rasbt,2022-06-22 00:16:06+00:00,https://twitter.com/rasbt/status/1539401807746695169,"@tunguz @paul_rietschka Ok fair, there's the quirky syntax, and it's not great for versioning binary files and Nbs to some extend. Tbh  I do appreciate it though that I can use the same tool and platform for both coding and my ML/DS projects, because I often work at the intersection of both."
4541,@rasbt,2022-06-22 00:13:10+00:00,https://twitter.com/rasbt/status/1539401071398879234,@uberalex @gibranerl ü§£ that's probably true too
4542,@rasbt,2022-06-21 23:33:44+00:00,https://twitter.com/rasbt/status/1539391145423273984,@PatrickKidger @Theteamatx Wow! Congrats! üçæ
4543,@rasbt,2022-06-21 20:26:38+00:00,https://twitter.com/rasbt/status/1539344063207460864,@DoltHub @ctitusbrown You got me at free and open source üòÖ -- might make me overlook the fact that it has an SQL interface üòÜ
4544,@rasbt,2022-06-21 20:17:52+00:00,https://twitter.com/rasbt/status/1539341854021500929,"Credit for this goes to @ctitusbrown, who was very adamant about best practices. Blogging, version control, unit testing, reproducible research ... I was so lucky to have had him on my committee!"
4545,@rasbt,2022-06-21 19:59:41+00:00,https://twitter.com/rasbt/status/1539337280783011842,"Using Git was one of the Pro Tips I got when I started my Ph.D. -- adopting version control was a life- and code-changing experience!
(Yes, there is an initially steep learning curve, but we hope to get you started in no more than 10 min!) https://t.co/iPThhMY1uC"
4546,@rasbt,2022-06-21 18:13:31+00:00,https://twitter.com/rasbt/status/1539310559748689925,"@BlackHC @overleaf Haha, looking at some arxiv papers that would explain a lot üòÜ"
4547,@rasbt,2022-06-21 17:54:29+00:00,https://twitter.com/rasbt/status/1539305771086790660,"@jessehman @marktenenholtz Sure, depends on your hooks. E.g., if you use something like isort and black, this shouldn't break pushes -- it just clean things up automatically."
4548,@rasbt,2022-06-21 17:50:33+00:00,https://twitter.com/rasbt/status/1539304782644510722,"@shelbyh_ai @marktenenholtz Yes! After a bit of tinkering, I came up with isort-black-flake8 (in that order).  
Here's an example: https://t.co/BYODDA4GXw

Flake8 is nice for checking for unused variables or imports in addition the Pep8 formatting."
4549,@rasbt,2022-06-21 17:11:45+00:00,https://twitter.com/rasbt/status/1539295018237706240,"@marktenenholtz Another nice addition:
.pre-commit-config.yaml"
4550,@rasbt,2022-06-21 01:47:48+00:00,https://twitter.com/rasbt/status/1539062499298922498,@roydanroy @DeepMind @demishassabis Hah yeah just looked at your screenshots and thought that was the main result. Should have checked the paper of course before complaining üòá
4551,@rasbt,2022-06-21 01:46:37+00:00,https://twitter.com/rasbt/status/1539062197984411650,"@Gerald7440 @driscollis I use it for some sort of demo purpose 90% of the time. But another good one is fetching datasets periodically, syncing things etc."
4552,@rasbt,2022-06-20 23:46:25+00:00,https://twitter.com/rasbt/status/1539031948957519872,"@GuvercinGoktug @AllesistKode @math_dandy Wow awesome! Ping me when they are out, would love to read those!"
4553,@rasbt,2022-06-20 23:41:58+00:00,https://twitter.com/rasbt/status/1539030829409701898,"@gibranerl @fchollet arg sorry, industry jargon. HPO = hyperparameter optimization."
4554,@rasbt,2022-06-20 23:03:18+00:00,https://twitter.com/rasbt/status/1539021100906070017,"@fchollet üíØ. Every ML class should start with explaining the ""garbage in, garbage out"" concept. So many countless hours of HPO could be saved!"
4555,@rasbt,2022-06-20 20:08:32+00:00,https://twitter.com/rasbt/status/1538977119275044866,"@roydanroy @DeepMind @demishassabis Hm I get that this is about the relative comparison, but showing 85% accuracy on CIFAR-10 is almost like showing 85% accuracy on MNIST at this point. I mean SOTA is in the 95+ range https://t.co/bxan92yrec. Why not more interesting datasets?"
4556,@rasbt,2022-06-20 16:24:23+00:00,https://twitter.com/rasbt/status/1538920708197302272,@ammaryh92 I think for most researchers this shift has already happened a long time ago üòÖ https://t.co/DcWadBnqE3 https://t.co/avgP7ce3dG
4557,@rasbt,2022-06-20 16:21:43+00:00,https://twitter.com/rasbt/status/1538920039927238656,"@JFPuget @MaxEpstein5 Yeah, otherwise for people asking whether they should switch from PyTorch to JAX it‚Äôs like asking whether they should switch from PyTorch to functorch. I mean there are awesome use cases but it really is an üçé to üçä comparison."
4558,@rasbt,2022-06-20 16:10:31+00:00,https://twitter.com/rasbt/status/1538917220679573504,@nafiz_h Let‚Äôs not forget about Jax + Elegy üòâ
4559,@rasbt,2022-06-20 15:48:53+00:00,https://twitter.com/rasbt/status/1538911775902646272,"@MaxEpstein5 @JFPuget I would say Flax is more similar to PyTorch. PyTorch Lightning is really on another level when it comes to utilities and making things like multi-GPU, fault-tolerant, mixed-precision training etc. convenient."
4560,@rasbt,2022-06-20 15:41:51+00:00,https://twitter.com/rasbt/status/1538910004438343681,"@math_dandy Hm, in my opinion not quite. JAX doesn't really have DL utilities whereas TensorFlow is really super focused on DL. 

I would rather say, ‚ÄúFlax is to JAX as Keras is to NumPy+autograd+cupy‚Äù. Also, I think Flax looks more similar to PyTorch than to Keras to me"
4561,@rasbt,2022-06-20 15:22:30+00:00,https://twitter.com/rasbt/status/1538905137527369729,"When people say JAX vs PyTorch, do they really mean ""JAX+Flax vs PyTorch""?
Otherwise, I think we should be comparing ""JAX vs torch.tensor"". And I think that's also how JAX and PyTorch compare in typical use cases."
4562,@rasbt,2022-06-20 15:16:20+00:00,https://twitter.com/rasbt/status/1538903583365681152,"@JFPuget The comparison is also a bit tricky, since JAX is more like NumPy with Autograd, Jit, and TPU/GPU support. 
Sure, there are many APIs on top JAX to make it more convenient for DL, but ""JAX vs PyTorch"" is almost like ""NumPy vs scikit-learn""."
4563,@rasbt,2022-06-20 01:22:10+00:00,https://twitter.com/rasbt/status/1538693660606443520,@peng_illinois @HelixonBio CASP15 is going to get really interesting this year üò≤
4564,@rasbt,2022-06-19 21:37:08+00:00,https://twitter.com/rasbt/status/1538637028060975107,@TobiasSchraink A very weird version of latex math though. It kinda feels half-broken from a user‚Äôs perspective
4565,@rasbt,2022-06-19 21:09:22+00:00,https://twitter.com/rasbt/status/1538630038089781258,"OneNote for macOS now supports local backups, can you believe it? What‚Äôs next, LaTeX-Math support? https://t.co/nEwqbVguPI"
4566,@rasbt,2022-06-19 17:48:08+00:00,https://twitter.com/rasbt/status/1538579398227640327,"@chriswolfvision Haha, I remember @CSProfKGD saying something along the lines that ""CVPR policy is that arXiv doesn't exist."" I guess they take that quite literally üòÑ"
4567,@rasbt,2022-06-19 14:28:07+00:00,https://twitter.com/rasbt/status/1538529062024536064,"@Kaszanas @dustinvtran If you want to replicate the classic PDF layout, I agree. But why does it have to be PDF? In 2022 i think it should be web-first. If someone wants a PDF, just export the web page as PDF"
4568,@rasbt,2022-06-19 14:22:16+00:00,https://twitter.com/rasbt/status/1538527589920391168,@Kaszanas @dustinvtran Shouldn‚Äôt be too hard to add a feature that recognizes citation tags. I put something like that together in a few hours once https://t.co/AzDysqo1yP
4569,@rasbt,2022-06-19 13:40:17+00:00,https://twitter.com/rasbt/status/1538517022904041472,@Aayush_ander @PyTorchLightnin Thanks! Currently out of town but I am hoping some time this week!
4570,@rasbt,2022-06-19 12:42:48+00:00,https://twitter.com/rasbt/status/1538502558615994369,"@ylecun We can maybe start with ‚ÄúHaiku, Flax, or Elegy, which Jax API to use?‚Äù üòÜ"
4571,@rasbt,2022-06-19 12:41:20+00:00,https://twitter.com/rasbt/status/1538502188430917633,"@ylecun Oh no. I felt like 2021/22-ish, we finally moved beyond the language and library wars in favor of focusing more on the big picture. Are the ‚ÄúX vs. Y, which one should you use‚Äù debates all coming back? ü•≤"
4572,@rasbt,2022-06-19 01:26:12+00:00,https://twitter.com/rasbt/status/1538332287535751169,@TaliaRinger Academic seminar talks basically üòÖ
4573,@rasbt,2022-06-19 01:23:52+00:00,https://twitter.com/rasbt/status/1538331696931622912,@venuv62 500 is crazy. I can do 5x40 on a good day üòÖ
4574,@rasbt,2022-06-18 13:27:03+00:00,https://twitter.com/rasbt/status/1538151306241933314,"Had an awesome time hanging out with my friend and colleague @joshuastarmer. And yes, I am holding THE StatQuest Illustrated Guide to Machine Learning, the best travel companion one can hope for! Seriously, the illustrations are just üëå. Triple BAM üí• https://t.co/xnXmAhGhTC"
4575,@rasbt,2022-06-18 13:09:52+00:00,https://twitter.com/rasbt/status/1538146982245580800,"@AiBeginners @PyTorchLightnin The times they are a-changin üòä. The best part: it‚Äôs all open source and everyone can create their own components! Oh, and if someone wants to make a Signal component, we‚Äôd be happy to feature it in the Gallery."
4576,@rasbt,2022-06-18 12:26:48+00:00,https://twitter.com/rasbt/status/1538136144973549573,"Haha for this reason, we have messaging components for @PyTorchLightnin in the component gallery (https://t.co/HaaD38kDm8), that can ping you (Slack, email, telegram, text) once the model finished training."
4577,@rasbt,2022-06-18 12:23:48+00:00,https://twitter.com/rasbt/status/1538135387842953217,"I usually don‚Äôt wait for my ML models, my ML models usually wait for me üòÜ."
4578,@rasbt,2022-06-18 12:12:12+00:00,https://twitter.com/rasbt/status/1538132469517541376,@ykilcher Didn‚Äôt know you were up for tenure!
4579,@rasbt,2022-06-18 11:46:24+00:00,https://twitter.com/rasbt/status/1538125977896853505,"@ellisvalentiner @beeonaposy Great idea, love this!"
4580,@rasbt,2022-06-18 03:59:05+00:00,https://twitter.com/rasbt/status/1538008371101519872,@savvyRL That‚Äôs a good suggestion. Also I find a combined Results &amp; Discussion often more readable ‚Äî ie a discussion following the results directly rather than putting it into a separate section and cross reference.
4581,@rasbt,2022-06-18 03:53:24+00:00,https://twitter.com/rasbt/status/1538006940449574915,"@unsorsodicorda @MilesCranmer Well, maybe you want 1_234_567"
4582,@rasbt,2022-06-18 03:47:53+00:00,https://twitter.com/rasbt/status/1538005553753911296,@dustinvtran Just keep the math part (via MathJax or equivalent) and let researchers write in Markdown. It‚Äôs already pretty established. There are also dozens of good templates out there for rendering (even the default GitHub template is pretty readable).
4583,@rasbt,2022-06-17 18:11:16+00:00,https://twitter.com/rasbt/status/1537860445687660544,"""Sharing Deep Learning Research Models with Lightning Part 1: Building A Super Resolution App""! 
Interested in a bottom-up approach to Lightning Apps &amp; are looking for sth to play with over the weekend? Check out my post &amp; have fun with @PyTorchLightnin! 
https://t.co/LKeu5ELrVW"
4584,@rasbt,2022-06-17 04:23:49+00:00,https://twitter.com/rasbt/status/1537652210074624000,@LesGuessing Thanks for the feedback! I am more of a bottom-up person as well and will try to explain how to build a Lightning App from scratch. Stay tuned for a blog post tomorrow!
4585,@rasbt,2022-06-16 19:11:19+00:00,https://twitter.com/rasbt/status/1537513169899376641,@_joaogui1 And https://t.co/vFcSjsQpW0 :)
4586,@rasbt,2022-06-16 18:48:45+00:00,https://twitter.com/rasbt/status/1537507487032680456,"@_joaogui1 https://t.co/IbyBlVhWmE, your OS for AI üòä"
4587,@rasbt,2022-06-16 18:22:18+00:00,https://twitter.com/rasbt/status/1537500833331527680,Tldr; https://t.co/Op8y37Rrlt
4588,@rasbt,2022-06-16 18:21:22+00:00,https://twitter.com/rasbt/status/1537500596206444544,"Lightning Apps are really meant to be easy to use. And they are for everyone, to build everything from production-ready, multi-cloud ML systems to simple research demos. Actually, the best way to learn more is head over https://t.co/U1SRtf9RgJ and give it a try!"
4589,@rasbt,2022-06-16 18:20:28+00:00,https://twitter.com/rasbt/status/1537500370888540160,"Really excited about our big Lightning AI reveal!
If you didn't catch the keynote live, we have a recording up here on YouTube: https://t.co/OWQVyO4KWj"
4590,@rasbt,2022-06-16 13:51:46+00:00,https://twitter.com/rasbt/status/1537432752240201732,Starting soon!
4591,@rasbt,2022-06-16 11:15:01+00:00,https://twitter.com/rasbt/status/1537393303200710656,@Zaker237 Good question! Yes! It will be free for everyone!
4592,@rasbt,2022-06-16 11:11:33+00:00,https://twitter.com/rasbt/status/1537392429011243011,@TheFucking22 üòÖ https://t.co/CzFPzHNuCa
4593,@rasbt,2022-06-16 11:11:09+00:00,https://twitter.com/rasbt/status/1537392328943579137,"After so many months of hard work, today is the day! ‚ö°Ô∏èWe have something truly awesome to announce! If you are into ML and AI, I can promise you that this will be worth your while! 
They keynote will be starting in about 2 hours at 9 am ET!"
4594,@rasbt,2022-06-16 10:48:02+00:00,https://twitter.com/rasbt/status/1537386513801138177,"@TheFucking22 Actually, while I love VSCode, I still use JupyterLab for notebooks. I can't explain why, but I kind of prefer it for that."
4595,@rasbt,2022-06-15 15:37:27+00:00,https://twitter.com/rasbt/status/1537096957868613632,@MagouilleMan @TaliaRinger Yeah it could be due to translation. Maybe a good rule of thumb is whether the scientific method can be applied.
4596,@rasbt,2022-06-15 15:26:55+00:00,https://twitter.com/rasbt/status/1537094306779086848,@liuyao12 @jefrankle I haven‚Äôt heard. This is sad news üò¢. May he RIP.
4597,@rasbt,2022-06-15 15:13:40+00:00,https://twitter.com/rasbt/status/1537090972961722375,@_sam_sinha_ ‚õΩÔ∏èü´ó
4598,@rasbt,2022-06-15 14:23:15+00:00,https://twitter.com/rasbt/status/1537078285850628098,"There's something really cool coming in the next couple of days ü§ê -- In preparation, and upon popular request, I updated the code styling on my blog after 9 years üòÖ https://t.co/wnHQM2Itz8"
4599,@rasbt,2022-06-15 14:16:12+00:00,https://twitter.com/rasbt/status/1537076510871498754,"@thegautamkamath @roydanroy Just have a low fee, encourage as many virtual attendees as possible to sign up, and use the registration fees to cover the travel cost for in-person attendees."
4600,@rasbt,2022-06-15 14:13:44+00:00,https://twitter.com/rasbt/status/1537075890097733632,"@willwolf_ @hardmaru Curious to hear what the issue is, the button doesn‚Äôt show?"
4601,@rasbt,2022-06-15 11:31:27+00:00,https://twitter.com/rasbt/status/1537035051732434944,"@jefrankle As a bonus, it would be interesting to see how/if the recipes affect robustness, and there might be an opportunity for a Mosaic-Robust ResNet by adding ideas from here:
https://t.co/R2WissH5W4 (Patchifying, reducing activation layers, increasing kernel size)"
4602,@rasbt,2022-06-15 11:23:23+00:00,https://twitter.com/rasbt/status/1537033021181894658,"Long live ResNet. My favorite DL architecture for image classification just got a nice tune-up: 
https://t.co/f2OJOgvCma https://t.co/9t3Xx1l6oV"
4603,@rasbt,2022-06-15 11:02:29+00:00,https://twitter.com/rasbt/status/1537027759188459521,"@LonesPhoebe @_willfalcon Personally, I use VSCode when I debug on remote machines. The interface is relatively similar to PyCharm. However, you can actually use PyCharm for remote debugging as well now üòä: https://t.co/aLPjWymQQW https://t.co/G0JUNMIBJI"
4604,@rasbt,2022-06-15 01:26:22+00:00,https://twitter.com/rasbt/status/1536882776670097412,"@sarahookr @forai_ml Whoa, big congrats! This is exciting!!! üçæ"
4605,@rasbt,2022-06-15 00:58:21+00:00,https://twitter.com/rasbt/status/1536875727211180034,@Antisimplistic @michelkokk @jeremyphoward And StitchFix: https://t.co/2Wk84UhHld
4606,@rasbt,2022-06-15 00:57:32+00:00,https://twitter.com/rasbt/status/1536875522319433729,@Antisimplistic @michelkokk @jeremyphoward Also Netflix: https://t.co/GJh14HPC6R
4607,@rasbt,2022-06-15 00:47:37+00:00,https://twitter.com/rasbt/status/1536873026515619840,@fchollet Looks like it's converging üòÅ
4608,@rasbt,2022-06-15 00:32:08+00:00,https://twitter.com/rasbt/status/1536869127624736771,@michaelwaskom üíØ. Why waste time on implementing bugs when you can implement new features üòÜ
4609,@rasbt,2022-06-15 00:28:41+00:00,https://twitter.com/rasbt/status/1536868261693992960,"Achievement unlocked, I guess. But please don't tell anyone ü§£ https://t.co/dsxnCbVqIG"
4610,@rasbt,2022-06-14 20:34:11+00:00,https://twitter.com/rasbt/status/1536809246188351489,@michelkokk üôÑüòÖ https://t.co/8h3eY2ZVYz
4611,@rasbt,2022-06-14 20:32:52+00:00,https://twitter.com/rasbt/status/1536808913085124615,"@teethcode Yes, ipdb is nice! However, nowadays I go with the visual debugger 99% of the time üòÅ"
4612,@rasbt,2022-06-14 20:26:05+00:00,https://twitter.com/rasbt/status/1536807208318648320,"Pro tip: even if you prefer coding in JupyterLab, I recommend taking advantage of the debugger! The UI is actually very similar to PyCharm, and it's quite powerful.

What is your go to tool for debugging? Any favorites or personal insider tips people should know about? https://t.co/uCU9Jp40G5"
4613,@rasbt,2022-06-14 15:08:38+00:00,https://twitter.com/rasbt/status/1536727318424698882,@GaryMarcus @nypost Of course not
4614,@rasbt,2022-06-14 14:49:57+00:00,https://twitter.com/rasbt/status/1536722617222275072,"@GaryMarcus @nypost Headline: Prominent AI researcher says ""machines would have feelings""

Prof. Marcus, a senior AI researcher who has been testing recent artificial intelligence tools says ""machines would have feelings."" He did not rule out that this breakthrough could happen within this decade."
4615,@rasbt,2022-06-14 14:30:22+00:00,https://twitter.com/rasbt/status/1536717688071938048,"@SaravananStat @PyTorchLightnin @_willfalcon @pycharm If you are open to experimenting a bit, there is a PR here https://t.co/7YdfjK1d0Q -- otherwise, I'd say stay tuned, it's almost ready to be merged ‚ò∫Ô∏è"
4616,@rasbt,2022-06-14 14:19:52+00:00,https://twitter.com/rasbt/status/1536715048076328960,@Kaszanas @_willfalcon .exe files? ü§î
4617,@rasbt,2022-06-14 14:00:13+00:00,https://twitter.com/rasbt/status/1536710099611402240,"@Kaszanas @_willfalcon You could add mypy as a pre-commit hook? But yeah, you may have non-typed dependencies ... especially if you use any of my code üòÜ"
4618,@rasbt,2022-06-14 13:50:09+00:00,https://twitter.com/rasbt/status/1536707569871425541,"@Kaszanas @_willfalcon Fair, but one might say that instead of learning a whole new language someone could just add type hints üôÉ. And for misspelled variable names, flake8 should take care of that."
4619,@rasbt,2022-06-14 13:01:33+00:00,https://twitter.com/rasbt/status/1536695335459905538,"Just added a small but important ""Known Caveats"" section (https://t.co/2HlKQwfeFj). Thanks to @hug_nicolas for pointing these out!"
4620,@rasbt,2022-06-14 10:52:12+00:00,https://twitter.com/rasbt/status/1536662787015024640,"@svpino I am more of a visual person and prefer my measurements in cups, stones, and feet"
4621,@rasbt,2022-06-13 15:57:49+00:00,https://twitter.com/rasbt/status/1536377309715910658,"@JosiahLaivins @hug_nicolas @PyTorch Yes, thanks! @hug_nicolas was so kind to send me some additional notes, and I am planning to add a ""Caveats"" sections tonight/tomorrow morning. Btw do you know what happens if you use the ShardingFilter and then use Fully Sharded Data Parallel (usually by go to for multi-gpu)?"
4622,@rasbt,2022-06-13 13:42:25+00:00,https://twitter.com/rasbt/status/1536343235752251393,@hug_nicolas @PyTorch Thanks! I am planning to add a limitation section with some examples + referencing your https://t.co/Hd7gjxQNEp section.
4623,@rasbt,2022-06-13 13:37:29+00:00,https://twitter.com/rasbt/status/1536341993697181696,"@hug_nicolas @PyTorch Ahh, I see now!"
4624,@rasbt,2022-06-13 13:31:31+00:00,https://twitter.com/rasbt/status/1536340488881577985,@hug_nicolas @PyTorch Good call. Actually I had the shuffle=True in the original code I used but then for some reason forgot and dropped it in the article. Let me fix that.
4625,@rasbt,2022-06-13 12:52:20+00:00,https://twitter.com/rasbt/status/1536330628207190021,"@RexDouglass @CookieSci @wwbrannon @marktenenholtz Wait what? You mean because of the random weight init? Also, technically a fully-connected is a affine transformation, not a linear transformation."
4626,@rasbt,2022-06-13 12:28:13+00:00,https://twitter.com/rasbt/status/1536324560001327105,@blattnerma @tunguz The irony is also that people complain about these articles but at the same time they amplify it in order to make their point ü§î.
4627,@rasbt,2022-06-13 12:25:46+00:00,https://twitter.com/rasbt/status/1536323944961216513,@shravankumar147 @PyTorch @PyTorchLightnin @adrianwaelchli gave a nice talk on that at @DataUmbrella recently: https://t.co/J623r5615I
4628,@rasbt,2022-06-13 12:24:07+00:00,https://twitter.com/rasbt/status/1536323530522079232,"@shravankumar147 @PyTorch I use @PyTorchLightnin for that :). E.g., Trainer(accelerator='gpu', devices=4, strategy='ddp_sharded', ...)
If you don't want to convert to PyTorch Lightning, checkout LightningLite: https://t.co/md74ppxBAu"
4629,@rasbt,2022-06-13 02:08:27+00:00,https://twitter.com/rasbt/status/1536168591799746560,"@tunguz Ha, yes. I can‚Äôt be bothered to read the article or interview that is the topic of the day because yeah, it sounds like it probably is just a new flavor of the same old, and/or a marketing stunt. I don‚Äôt know why people are so eager to jump on this. Especially AI folks."
4630,@rasbt,2022-06-13 01:18:45+00:00,https://twitter.com/rasbt/status/1536156084800524288,"@RexDouglass @wwbrannon @marktenenholtz Yeah, I vaguely recall that there was a heated discussion on the mailing list or so. On the other hand, I think it's totally fine. If you are a purist, just set penalty='none'. And if you don't know what the penalty is, the default is probably not a bad choice."
4631,@rasbt,2022-06-13 00:39:33+00:00,https://twitter.com/rasbt/status/1536146218987945987,@marktenenholtz You might be happy to hear that scikit-learn's LogisticRegression uses a L2 (Ridge) penalty as the default setting üôÉ
4632,@rasbt,2022-06-13 00:29:57+00:00,https://twitter.com/rasbt/status/1536143802917847040,@themintsv @PyTorch Just saying that nested parallelism is somewhat dangerous because it is easy to shoot yourself in the foot with that.
4633,@rasbt,2022-06-13 00:27:54+00:00,https://twitter.com/rasbt/status/1536143288868163584,"@themintsv @PyTorch Fair, but if you have enough processes so that this doesn't become a bottle-neck, it shouldn't be a problem. If you need more images, e.g., to find suitable triplets, you could also just increase the batch size and then only use a subset of those."
4634,@rasbt,2022-06-12 23:59:29+00:00,https://twitter.com/rasbt/status/1536136138045509632,"@terrible_coder @PyTorch Thanks! And that's awesome, I would be interested to read about your experiences! Haha, I can totally understand if you don't want to spoil the surprise, but did you notice any substantial speed differences?"
4635,@rasbt,2022-06-12 23:57:45+00:00,https://twitter.com/rasbt/status/1536135699358965762,"@j0hnparkhill @PyTorch Not yet, I think, but I think this is totally possible and probably already in the works."
4636,@rasbt,2022-06-12 23:54:25+00:00,https://twitter.com/rasbt/status/1536134861764939777,"@SchuelerMo @PyTorch 2/2 Optionally (but recommended), you can also use DataModules in PyTorch Lightning (https://t.co/zTIpeQx1EN). But DataModules are essentially composed of PyTorch Datasets &amp; DataLoaders. In other words, DataPipes will be something will be able to use with PyTorch Lightning."
4637,@rasbt,2022-06-12 23:51:58+00:00,https://twitter.com/rasbt/status/1536134246066274308,"@SchuelerMo @PyTorch Good questions: DataPipes are just a new way to form the input dataset for a PyTorch DataLoader. And you can use PyTorch DataLoaders in PyTorch Lightning. Like
trainer = Trainer(...)
trainer. fit(model, train_dataloader, ...)
So, PyTorch Lightning will of course also benefit 1/2"
4638,@rasbt,2022-06-12 23:48:48+00:00,https://twitter.com/rasbt/status/1536133448976502785,"@terrible_coder @PyTorch Awesome, thanks for sharing. Added this tidbit to the article :)"
4639,@rasbt,2022-06-12 17:38:28+00:00,https://twitter.com/rasbt/status/1536040249150914561,@themintsv @PyTorch Good question. I‚Äôd say that‚Äôs not recommended because then you end up with inner and outer parallelism. It‚Äôs ok if a dataset is slow because you have the outer parallelism via the dataloader.
4640,@rasbt,2022-06-12 15:11:43+00:00,https://twitter.com/rasbt/status/1536003318320857090,@david_macedo @PatrickMcCarter @PyTorch Curious to hear what you two think :)
4641,@rasbt,2022-06-12 14:53:34+00:00,https://twitter.com/rasbt/status/1535998753114669057,"Have you tried @PyTorch's new DataPipes, yet? I just put together an article illustrating how they work: 
""Taking Datasets, DataLoaders, PyTorch‚Äôs New DataPipes for a Spin:""
https://t.co/wnHQM2Itz8"
4642,@rasbt,2022-06-11 21:31:36+00:00,https://twitter.com/rasbt/status/1535736532019159042,"@phillip_lippe @cgarciae88 @jejjohnson @shoyer @DynamicWebPaige @PyTorch @PyTorchLightnin @GoogleColab Thanks, but omg, these are really massive and hard to read  üôàüòÜ"
4643,@rasbt,2022-06-11 20:20:08+00:00,https://twitter.com/rasbt/status/1535718547023925248,"@phillip_lippe @cgarciae88 @jejjohnson @shoyer @DynamicWebPaige @PyTorch @PyTorchLightnin @GoogleColab Thanks for the update. That looks more realistic, but I am still curious how that can be üòÖ. Btw. out of curiosity, do you have the benchmark scripts on GitHub somewhere?"
4644,@rasbt,2022-06-11 16:19:07+00:00,https://twitter.com/rasbt/status/1535657893038546945,@marktenenholtz @tunguz @LeopolisDream I may be wrong but I don‚Äôt think that FIL recasts the decision trees into matrix multiplications that you can run in PyTorch. Don‚Äôt know what the speed differences are though.
4645,@rasbt,2022-06-11 16:04:09+00:00,https://twitter.com/rasbt/status/1535654127551844353,"@TheFucking22 Well, M2 wasn‚Äôt out then yet ;)"
4646,@rasbt,2022-06-11 14:30:02+00:00,https://twitter.com/rasbt/status/1535630442702983169,@tunguz @LeopolisDream that's for inference. training is a different beast though.
4647,@rasbt,2022-06-11 14:29:23+00:00,https://twitter.com/rasbt/status/1535630279695642624,"@tunguz @LeopolisDream You can actually express the decision trees incl. tree traversal as matrix multiplications. Based on that idea, there's a library that can export all sorts of sklearn decision tree models &amp; XGBoost to PyTorch and run it as tensor computations: https://t.co/cmDYE1pbER"
4648,@rasbt,2022-06-11 13:29:20+00:00,https://twitter.com/rasbt/status/1535615166771040256,"@phillip_lippe @cgarciae88 @jejjohnson @shoyer @DynamicWebPaige @PyTorch @PyTorchLightnin @GoogleColab Good call regarding GPU utilization. Very interesting overall. If you ever have a chance to try the jitted PyTorch code, let us know (I rarely do this and am just curious how much it would make a difference here)."
4649,@rasbt,2022-06-11 13:26:32+00:00,https://twitter.com/rasbt/status/1535614461125480449,"@phillip_lippe @cgarciae88 @jejjohnson @shoyer @DynamicWebPaige @PyTorch @PyTorchLightnin @GoogleColab Yeah, to be honest, I remember that for CIFAR 3-4 is usually the sweet spot on my computers. Beyond that, there is really no benefit of using more workers (but depends on the CPU and disk of course üòÖ)"
4650,@rasbt,2022-06-11 13:23:26+00:00,https://twitter.com/rasbt/status/1535613682763321344,@phillip_lippe @cgarciae88 @jejjohnson @shoyer @DynamicWebPaige @PyTorch @PyTorchLightnin @GoogleColab Have you considered jitting PyTorch as well?
4651,@rasbt,2022-06-11 13:08:57+00:00,https://twitter.com/rasbt/status/1535610037296680960,"@cgarciae88 @jejjohnson @shoyer @DynamicWebPaige @PyTorch @PyTorchLightnin @GoogleColab Just skimming through the code. The Jax version uses 8 workers, the PyTorch version 4 workers. I would use the same data loaders for a fair comparison. https://t.co/mJIXICaQol"
4652,@rasbt,2022-06-11 13:02:45+00:00,https://twitter.com/rasbt/status/1535608475706961921,"@cgarciae88 @jejjohnson @shoyer @DynamicWebPaige @PyTorch @PyTorchLightnin @GoogleColab Also, to me, it doesn't matter that DataLoaders run in Python. As long as you have enough workers so that the GPU doesn't need to wait for the next batch, it's all good."
4653,@rasbt,2022-06-11 13:01:32+00:00,https://twitter.com/rasbt/status/1535608171212963840,"@cgarciae88 @jejjohnson @shoyer @DynamicWebPaige @PyTorch @PyTorchLightnin @GoogleColab Haha, but sorry, it is not published yet. Need to do some final polishing sometime. Maybe this weekend. Anyways, I think there is no performance difference between Dataset and DataPipes. It's just that the latter are more composable."
4654,@rasbt,2022-06-11 12:39:55+00:00,https://twitter.com/rasbt/status/1535602730626056192,*robustness here in terms of out-of-distribution examples.
4655,@rasbt,2022-06-11 12:39:13+00:00,https://twitter.com/rasbt/status/1535602552527630336,"Robust-ResNet. 3 Key ideas to make CNNs more robust: 
1) patchifying input images similar to ViTs; 
2) increasing kernel size; 
3) reducing activation layers &amp; norm layers similar to ConvNext.
Paper: https://t.co/R2WissH5W4
Code: https://t.co/9K2Pz50SjQ https://t.co/OuQLk3P0fQ"
4656,@rasbt,2022-06-11 11:58:02+00:00,https://twitter.com/rasbt/status/1535592190977638400,"@AlejandroPiad Haha, out of context, this looks bad indeed. But I actually do something like this 

train_acc = model.score(X_train, y_train)
test_acc = model.score(X_test, y_test)
return train_acc, test_acc

to get a rough idea of how much the final model overfits."
4657,@rasbt,2022-06-11 11:53:17+00:00,https://twitter.com/rasbt/status/1535590993873014784,"@EdogawaKogoro *By that, I meant Python, the terminal, etc. Of course, you can check it from the macOS UI https://t.co/WdJjFrvqTZ"
4658,@rasbt,2022-06-11 11:51:46+00:00,https://twitter.com/rasbt/status/1535590613617463297,"@EdogawaKogoro I don't think there is a good way of checking how many GPU cores the chip has. The best I could find was the brand. I.e., ""M1"", ""M1 Pro"" etc. via ""cpuinfo"". But btw when you run PyTorch on the Mac ARM GPU, it always uses all cores atm."
4659,@rasbt,2022-06-11 02:11:07+00:00,https://twitter.com/rasbt/status/1535444486368681985,"@Giba1 Thanks! Yeah my guess is it depends on the type of input model? If your first level models are eg neural networks, then that‚Äôs probably totally redundant"
4660,@rasbt,2022-06-10 15:36:50+00:00,https://twitter.com/rasbt/status/1535284864966082560,@AhmadMustafaAn1 @xamat The code is all on GitHub though. I think that was what he was referring to üòä
4661,@rasbt,2022-06-10 14:23:33+00:00,https://twitter.com/rasbt/status/1535266421135093760,@MolasAlex @drussellmrichie Of course. But at least they don‚Äôt paywall you yet unlike those private companies where people publish their academic papers.
4662,@rasbt,2022-06-10 14:17:26+00:00,https://twitter.com/rasbt/status/1535264881817141250,"@xamat True! Haha, but I was more joking about the scenario where the book author was maybe a bit lazy ... you know ... üòá"
4663,@rasbt,2022-06-10 14:14:29+00:00,https://twitter.com/rasbt/status/1535264141765758977,"@xamat If you mean my recent book, it was published after the Copilot release. Just saying ... üòÜü§£"
4664,@rasbt,2022-06-10 14:10:25+00:00,https://twitter.com/rasbt/status/1535263115234910208,"@drussellmrichie @MolasAlex So, just put your preprint on GitHub then. Problem solved üôÑ. Would also make it easier to track changes, collect suggestions, and encourage fixes."
4665,@rasbt,2022-06-10 12:17:19+00:00,https://twitter.com/rasbt/status/1535234654399250432,"@JFPuget @Giba1 Wow, nice find, thank you!"
4666,@rasbt,2022-06-10 00:51:13+00:00,https://twitter.com/rasbt/status/1535061992347557890,@Kirti69895678 @PyTorchLightnin Almost! It's getting very close! https://t.co/7YdfjJJBCg
4667,@rasbt,2022-06-10 00:38:27+00:00,https://twitter.com/rasbt/status/1535058779687231488,"@andrewheiss It's the ""helpful"" index of course. How many students you have mentored, how many students you helped with recommendation letters, how many open source contributions you made."
4668,@rasbt,2022-06-09 21:45:47+00:00,https://twitter.com/rasbt/status/1535015326244560896,"@__mharrison__ I'd say the trick is to practice the learned knowledge by applying it in a project. Then, put that project on GitHub. You can then always go back and reuse that code üòä"
4669,@rasbt,2022-06-09 21:24:15+00:00,https://twitter.com/rasbt/status/1535009905849032712,@renegadesilicon @giffmana @hardmaru Yeah. Like for some people it is still Beige-ian statistics.
4670,@rasbt,2022-06-09 21:20:49+00:00,https://twitter.com/rasbt/status/1535009043512713228,"@giffmana @renegadesilicon @hardmaru wow that must be ages ago. The cool kids pronounce it ""loss"" nowadays."
4671,@rasbt,2022-06-09 21:13:17+00:00,https://twitter.com/rasbt/status/1535007147410481166,@giffmana @renegadesilicon @hardmaru right next to the new crossentroPy package
4672,@rasbt,2022-06-09 21:00:51+00:00,https://twitter.com/rasbt/status/1535004019067871263,"@tiredofmoi @savvyRL @giffmana @hardmaru Good point, need to try that next time I have to fit a paper within a 8-page conference paper constraint ü§î"
4673,@rasbt,2022-06-09 20:38:57+00:00,https://twitter.com/rasbt/status/1534998505227444246,"@haltakov @code Actually, in addition to the CLI, I am relying a lot on the excellent GitHub web UI nowadays."
4674,@rasbt,2022-06-09 20:32:39+00:00,https://twitter.com/rasbt/status/1534996923010146313,"@savvyRL @giffmana @hardmaru Thanks, finally!

Also
open-source or open source code
cross-validation or cross validation
cross-entropy or cross entropy
---
on-line learning or online learning
mini-batch or minibatch
hyper-parameter or hyperparameter"
4675,@rasbt,2022-06-09 18:44:38+00:00,https://twitter.com/rasbt/status/1534969739470065665,"@armandjoulin @giffmana @hardmaru Sure, pretrained as an adjective, and pre-trained as a verb. ""First, we pre-trained a model on the boring dataset. Then, we fine(-)tuned the pretrained model on the something-task dataset"""
4676,@rasbt,2022-06-09 18:22:27+00:00,https://twitter.com/rasbt/status/1534964153143676933,"@djwdata @giffmana @hardmaru haha, this is concerning"
4677,@rasbt,2022-06-09 14:30:22+00:00,https://twitter.com/rasbt/status/1534905750354640898,@paul_rietschka @giffmana @hardmaru O.K.
4678,@rasbt,2022-06-09 14:21:50+00:00,https://twitter.com/rasbt/status/1534903602342420481,"@paul_rietschka @giffmana @hardmaru Haha, was gonna say that as well. As in mini-batch and super-vised?! üòú"
4679,@rasbt,2022-06-09 14:10:58+00:00,https://twitter.com/rasbt/status/1534900866481897472,@alfarabyab I think it's a custom design. https://t.co/Idll7IILSr
4680,@rasbt,2022-06-09 14:07:25+00:00,https://twitter.com/rasbt/status/1534899972772085763,"@aadriasola You can train it, but I think it's more for the experimental purposes. I think the end goal might be to have the trained model on a chip. https://t.co/4XJqNpgnGB"
4681,@rasbt,2022-06-09 13:57:05+00:00,https://twitter.com/rasbt/status/1534897372119109632,"Whoa, TIL about photonic‚Äìelectronic deep neural networks. The on-chip photonic deep neural network can classify an image in 570 pico seconds. Or in other words, the DNN can classify 1.7 billion images per second. https://t.co/ofQvWfBdmf https://t.co/9NknYzzacK"
4682,@rasbt,2022-06-09 13:34:24+00:00,https://twitter.com/rasbt/status/1534891666699603968,"@giffmana @hardmaru Agreed. Now, the bigger question is"
4683,@rasbt,2022-06-09 12:29:57+00:00,https://twitter.com/rasbt/status/1534875445304385538,"*PS: In scikit-learn, the ""use_feature_in_secondary"" then became the aptly named ""passthrough"". But the same concept applies. Does anyone know any studies comparing this on a set of representative datasets. (Or Kaggle competitions?)"
4684,@rasbt,2022-06-09 12:29:57+00:00,https://twitter.com/rasbt/status/1534875443819646977,"When we implemented the stacking classifier in mlxtend back then, we added a use_features_in_secondary option to also have the orig features provided to the meta classifier. I think we did that because it was a common thing to try as a hparam. Does anyone know of any studies? https://t.co/uVLeQxXlkR"
4685,@rasbt,2022-06-09 02:23:21+00:00,https://twitter.com/rasbt/status/1534722788564602881,"@themintsv @giannis_daras @AlexGDimakis Remains unknown. Was just probing some hypotheses this evening and couldn't find anything conclusive. Suffice it to say, the authors suggest it could be misspelling (but based on my trials, maybe not) or just adversarial examples due to similarity in the embedding space"
4686,@rasbt,2022-06-09 01:22:19+00:00,https://twitter.com/rasbt/status/1534707429015007232,"@xamat Oh, one of the first things I do on a new Mac is disabling Siri &amp; Siri suggestions in spotlight. That should fix it. https://t.co/wO77lEnJN0"
4687,@rasbt,2022-06-09 01:17:45+00:00,https://twitter.com/rasbt/status/1534706279523962880,"@rioderaca Thinking the same thing. Maybe using your custom keybindings. In VSCode you do have also small goodies like runtime per cell. The debugger is nice, but I don't mind the JupyterLab debugger, it's actually quite powerful. https://t.co/TsjikW2DcH"
4688,@rasbt,2022-06-09 01:00:16+00:00,https://twitter.com/rasbt/status/1534701879405424645,"""Discovering the Hidden Vocabulary of DALLE-2"" (https://t.co/BPVkQN0ghF) -- Really interesting experiment and ""out-of-the-box"" thinking by @giannis_daras &amp; @AlexGDimakis (I will make this is my very first post on anything related to DALL¬∑E or DALL¬∑E2) https://t.co/JqxPJoYncY"
4689,@rasbt,2022-06-08 18:38:37+00:00,https://twitter.com/rasbt/status/1534605836164669440,@sebadzia @code Nice! Sounds like I am missing out!
4690,@rasbt,2022-06-08 17:42:00+00:00,https://twitter.com/rasbt/status/1534591588118183942,"@guiwitz @_willfalcon Oh yeah, what I like about notebooks is incremental exploration ‚Äî basically a modern take on the interpreter. However it‚Äôs definitely not something for managing bigger Python projects or package development. Glad to hear you are liking the series!"
4691,@rasbt,2022-06-08 17:39:16+00:00,https://twitter.com/rasbt/status/1534590897974804486,"@JordiClive Yeah, that sounds about right. I have a massive list of notes for git workflows but maybe it‚Äôs a out time to Stich the CLI"
4692,@rasbt,2022-06-08 17:26:21+00:00,https://twitter.com/rasbt/status/1534587649503240195,"Anyone using Git / version control integration? For some reason, that's one thing I am still old-school with: maybe due to muscle memory, but I still use the git CLI from the terminal"
4693,@rasbt,2022-06-08 17:17:21+00:00,https://twitter.com/rasbt/status/1534585382825869312,"If you had to pick, what is your favorite IDE productivity feature?
Because in this week's ‚ö°Ô∏èLightning Bits‚ö°Ô∏èepisode, @_willfalcon &amp; I are just getting started https://t.co/oopb11dMLL ... ‚ò∫Ô∏è"
4694,@rasbt,2022-06-08 15:18:48+00:00,https://twitter.com/rasbt/status/1534555548598902785,Sounds like a well-trained GAN at equilibrium to me
4695,@rasbt,2022-06-08 02:26:44+00:00,https://twitter.com/rasbt/status/1534361254583848960,"Whoa ‚ò∫Ô∏è. Nine Days, Nine Hours, Nine Persons, Nine Doors, such a nice round number! https://t.co/NnlR2S4eqa"
4696,@rasbt,2022-06-08 01:34:14+00:00,https://twitter.com/rasbt/status/1534348040592580608,"4) Task difficulty. Here, task difficulty is investigated via ""granularity"" (size of the class hierarchy). We can see that predictive performance goes down with the granularity -- not a big surprise in itself, but compared to supervised learning, it goes downhill more quickly https://t.co/kJOdU7bXWe"
4697,@rasbt,2022-06-08 01:34:14+00:00,https://twitter.com/rasbt/status/1534348039581745152,"3) Data quality. It seems like that self-supervised learning suffers way more from low-res/-quality data than supervised learning. (Again, a similar figure for fine-tuning would have been nice)"
4698,@rasbt,2022-06-08 01:34:13+00:00,https://twitter.com/rasbt/status/1534348038403137536,2) Domain transfer. There is a really big benefit from pretraining on the same domain as the target task. Classification performance is best when the target dataset matches the dataset used for pretraining. (Would have liked to see a similar table for fine-tuning.) https://t.co/AjJ7F2qvbS
4699,@rasbt,2022-06-08 01:34:13+00:00,https://twitter.com/rasbt/status/1534348037153234946,"1) Data quantity. Similar to the regular supervised learning reference (black curves), self-supervised learning benefits from more data. However, on some datasets, there seem to be diminishing returns for going beyond 500k images. https://t.co/33NfqdV5PS"
4700,@rasbt,2022-06-08 01:34:13+00:00,https://twitter.com/rasbt/status/1534348035916017665,"""When Does Contrastive Visual Representation Learning Work?"" (https://t.co/eocpz9BELN) -- nice paper answering key questions on self-supervised learning for vision tasks. The q's are on (1) data quantity (2) domain transfer (3) data quality (4) task difficulty. Spoilers below üëá https://t.co/ftUMfkYQiC"
4701,@rasbt,2022-06-08 00:31:55+00:00,https://twitter.com/rasbt/status/1534332356819132416,"@roydanroy @boazbaraktcs üòÇYes, of course. Hence all the typos."
4702,@rasbt,2022-06-08 00:30:47+00:00,https://twitter.com/rasbt/status/1534332072722059264,"@roydanroy @boazbaraktcs *haha, get it now. Had no idea that Apple brought back the touchbar ü§¶‚Äç‚ôÇÔ∏è"
4703,@rasbt,2022-06-07 21:49:56+00:00,https://twitter.com/rasbt/status/1534291595570429952,"@thecapeador same, but I guess I can blame my 2080Ti's üòÜ"
4704,@rasbt,2022-06-07 20:14:22+00:00,https://twitter.com/rasbt/status/1534267545175433216,@roydanroy @boazbaraktcs This is so 2015
4705,@rasbt,2022-06-07 20:10:56+00:00,https://twitter.com/rasbt/status/1534266682079948807,@rioderaca Actually I prefer JupyterLab for notebooks for some reason. Tried it in VSCode and PyCharm and for some reason I still prefer JupyterLab
4706,@rasbt,2022-06-07 12:07:43+00:00,https://twitter.com/rasbt/status/1534145076292636673,"@thomascygn I have mixed feelings about Copilot üôÑ
https://t.co/aoh7jS7sF4"
4707,@rasbt,2022-06-07 12:06:19+00:00,https://twitter.com/rasbt/status/1534144723014889472,"@kskrygan @EmreSevinc Yes, I can see how my tweet was confusing: I meant I thought it was not possible, but apparently it is possible now (i.e., I linked the beta GA you mentioned above)"
4708,@rasbt,2022-06-07 11:36:33+00:00,https://twitter.com/rasbt/status/1534137231576801282,@AllesistKode haha I don't read VSCode notifications or What's New announcements ... there are too many üòÜ
4709,@rasbt,2022-06-07 11:31:57+00:00,https://twitter.com/rasbt/status/1534136071830872065,"Thanks everyone for debunking those!
1) VSCode is hard to set up on a new computer since you have to install plugins individually. Not anymore: https://t.co/74pdUoAdDW
2) PyCharm doesn't support remote development. Apparently, also a thing from the past: https://t.co/pmKozDxBQd"
4710,@rasbt,2022-06-07 11:26:37+00:00,https://twitter.com/rasbt/status/1534134731431985154,@amitness @sinash93 Nice! Thanks for sharing!
4711,@rasbt,2022-06-07 01:28:58+00:00,https://twitter.com/rasbt/status/1533984328463654912,"@sudomaze @Kaszanas Bookmarked! That's so nice, I wish I knew about it a few months earlier! Thanks!"
4712,@rasbt,2022-06-07 01:14:30+00:00,https://twitter.com/rasbt/status/1533980686209654784,"@Kaszanas Nice, thanks, I didn't know that! Have to try it out when I am back from my trip and have access to my personal machine. Maybe I can finally get VSCode feature parity between personal and work computer this way, haha"
4713,@rasbt,2022-06-07 00:57:08+00:00,https://twitter.com/rasbt/status/1533976318127267840,"@Kaszanas Yeah, that might be an option. But you still need to install the plugins, right? I was hoping for something like this
https://t.co/UxyPZQj9Ck"
4714,@rasbt,2022-06-07 00:48:12+00:00,https://twitter.com/rasbt/status/1533974068155793409,"*I feel like VSCode really needs a
```
conda env export &gt; environment. yml
conda env create --file environment.yml
```
equivalent that you can share across machines üòÜ"
4715,@rasbt,2022-06-07 00:43:06+00:00,https://twitter.com/rasbt/status/1533972783981633540,"4/4 PyCharm on the other hand comes with a lot of stuff included, which is nice. Now, in recent weeks I adopted this workflow of using PyCharm for bigger code projects and VSCode for editing single files here and there, and it feels like that's the best of both worlds now."
4716,@rasbt,2022-06-07 00:43:05+00:00,https://twitter.com/rasbt/status/1533972782853328898,"3/4 Not too long ago, I was cursing A LOT when setting up VSCode on my work computer. VSCode plugins are really awesome, but it was a lot of work to set it up the way I have it on my personal machine."
4717,@rasbt,2022-06-07 00:43:05+00:00,https://twitter.com/rasbt/status/1533972781767041024,"2/4 I tried PyCharm couple of times throughout the last decade. My main problem with it was that it always felt bloated and slow. Making this episode, @_willfalcon  urged me to give it another try -- lo and behold, it's not slow at all on a modern laptop."
4718,@rasbt,2022-06-07 00:43:05+00:00,https://twitter.com/rasbt/status/1533972779883708417,"Ha, I have t admit that I am actually a big VSCode fan üòÜ. But I also have to admit that this episode made me reconsider PyCharm, and I am really liking it this time around ‚ò∫Ô∏è.
What are your pros and cons using one over the other? 
1/4"
4719,@rasbt,2022-06-07 00:32:55+00:00,https://twitter.com/rasbt/status/1533970223384170496,"@KLdivergence Sure, you can also write those things down in a text file. But those have the tendency to more easily get lost. Also, think about when you are traveling and you want to quickly check something from your phone (given you have internet connection) :P"
4720,@rasbt,2022-06-07 00:30:55+00:00,https://twitter.com/rasbt/status/1533969720747167745,"@KLdivergence To me, personal websites are also public repositories where you can organize your content free form, making it easy for you and others to find. Even a list of papers is a nice, organized way of writing everything down in your preferred sort order. For others and your future self."
4721,@rasbt,2022-06-06 23:49:32+00:00,https://twitter.com/rasbt/status/1533959302934847488,@hackathorn Thanks üôè
4722,@rasbt,2022-06-06 02:09:09+00:00,https://twitter.com/rasbt/status/1533632053090066435,"@AhmadMustafaAn1 maybe, but that would be super inefficient üòÜ"
4723,@rasbt,2022-06-06 02:07:42+00:00,https://twitter.com/rasbt/status/1533631685975232514,"They propose the alternative 'neural gradient representation by activity differences' algorithm, but I am not sure if that one has been ""debunked"" yet. The paper is 2 years after all. https://t.co/bBAhPs43dm"
4724,@rasbt,2022-06-06 02:07:41+00:00,https://twitter.com/rasbt/status/1533631684553342976,"Indeed! Backprop is awesome, but it's probably not how the biological brain works, and that's ok. 
For reference, I really like the excellent (but paywalled) article ""Backpropagation and the Brain"" by Lillicrap, Santoro, Marris, Akerman, and Hinton.
https://t.co/16tquUXRw2"
4725,@rasbt,2022-06-06 01:25:48+00:00,https://twitter.com/rasbt/status/1533621143785160704,"@octonion Thanks, Christopher!"
4726,@rasbt,2022-06-06 01:24:17+00:00,https://twitter.com/rasbt/status/1533620760392216577,@napoperez1998 Wow thanks so much for sharing üôè. Glad to hear you liked it!
4727,@rasbt,2022-06-06 01:21:38+00:00,https://twitter.com/rasbt/status/1533620096169541633,"Was just checking in... and wow, thanks everyone!! I am really happy to see that you like the new book overall! Haha, given that the saying goes ""all good things come in threes"" and 100 is such a nice round number ... I am already very humbled and appreciative, but just saying üòÖ https://t.co/cRdpGzRV3R"
4728,@rasbt,2022-06-06 00:41:47+00:00,https://twitter.com/rasbt/status/1533610067102257153,"@killpueino_goni @chrisalbon Haha, I wish. But you still need to know the basics so you can tweak it when trimming your paper down to the mandatory 8-page conference requirements"
4729,@rasbt,2022-06-06 00:29:06+00:00,https://twitter.com/rasbt/status/1533606876042211328,"Speaking of useful ML apps ... apparently, there is also a top 10 of plant disease apps, but I haven't had a chance to evaluate their generalization performance yet (https://t.co/voZGbM7A0m)"
4730,@rasbt,2022-06-06 00:26:17+00:00,https://twitter.com/rasbt/status/1533606163417284608,"@Jake_Color ""Free"" *asterisk*"
4731,@rasbt,2022-06-06 00:25:40+00:00,https://twitter.com/rasbt/status/1533606010417467393,"*next, I need a pre-commit hook to fix my tweet typos, pleaseüò¨"
4732,@rasbt,2022-06-06 00:22:28+00:00,https://twitter.com/rasbt/status/1533605205438242816,"@paul_rietschka @xamat But, but, ... 1-based indexing?ü•π"
4733,@rasbt,2022-06-06 00:20:29+00:00,https://twitter.com/rasbt/status/1533604706400055299,"Yes, machine learning is everywhere. But this one application where it really delivers, my ugly handwriting and all. (Fun fact: my students implemented and live-demoed sth similar as their class project). https://t.co/6VU8BsGcFX"
4734,@rasbt,2022-06-05 22:11:41+00:00,https://twitter.com/rasbt/status/1533572290469933056,"@manaskar @arkatPDA @fchollet Plot twist: in academia you have to *pay* to publish a paper, not the other way around."
4735,@rasbt,2022-06-05 20:48:07+00:00,https://twitter.com/rasbt/status/1533551261986996224,"@arkatPDA @fchollet Haha sure, but I thought the metric was number of citations not number of papers."
4736,@rasbt,2022-06-05 20:16:56+00:00,https://twitter.com/rasbt/status/1533543413244739584,@kneupane @fchollet Probably. But even after tenure it‚Äôs like this.
4737,@rasbt,2022-06-05 20:12:19+00:00,https://twitter.com/rasbt/status/1533542253096062977,@fchollet Yeah exactly. Often people are just focused on how to get a/the next paper published. And that‚Äôs it. I met so many people who literally have this focus.
4738,@rasbt,2022-06-05 14:22:26+00:00,https://twitter.com/rasbt/status/1533454201543696384,"@ylecun Nows 2 decades later it's all the rage
""On the origin of implicit regularization in stochastic gradient descent""
""The inverse variance‚Äìflatness relation in stochastic gradient descent is critical for finding flat minima""
""Generalization Bounds of SGD for Wide &amp; Deep Neural Nets"""
4739,@rasbt,2022-06-05 14:16:45+00:00,https://twitter.com/rasbt/status/1533452772829429761,@JFPuget @BlindDou @tunguz agreed!
4740,@rasbt,2022-06-05 14:15:18+00:00,https://twitter.com/rasbt/status/1533452405127397378,@thegautamkamath +1
4741,@rasbt,2022-06-05 14:15:05+00:00,https://twitter.com/rasbt/status/1533452351184437248,@vovahimself Isn't that the Supercharger network? üòú
4742,@rasbt,2022-06-05 14:12:17+00:00,https://twitter.com/rasbt/status/1533451645295681536,@Parisa__Rashidi @xamat On the other hand if Statisticians can learn Julia they could also learn Python. üòÖ
4743,@rasbt,2022-06-05 14:10:42+00:00,https://twitter.com/rasbt/status/1533451247222673409,"@JFPuget @BlindDou @tunguz Sure, but tbh the paper could have done a better job with providing a link to the GitHub folder to the exact experiments and datasets they used to reproduce the results. Otherwise we get the issue with self-reported benchmarks and made-up numbers."
4744,@rasbt,2022-06-05 14:07:37+00:00,https://twitter.com/rasbt/status/1533450471452643331,How peer-review comments are going to look like in 2024 üò©
4745,@rasbt,2022-06-05 14:04:20+00:00,https://twitter.com/rasbt/status/1533449645531312129,"@BlindDou @JFPuget @tunguz Agreed, but I think that's what peer-reviewers could help with. Not the typical ""asking authors to run other methods for comparison"" but asking authors to run their methods on reasonable benchmark datasets."
4746,@rasbt,2022-06-05 14:02:12+00:00,https://twitter.com/rasbt/status/1533449110841446404,"@GaryMarcus Chicken-robot problem. I think GIFs are mostly only cool if they come from movies, so we'd have to do the Dall-E movie generator first."
4747,@rasbt,2022-06-05 13:24:54+00:00,https://twitter.com/rasbt/status/1533439720784527360,"@xamat Was at a seminar where the speaker talked about a deep learning project presented at an RStudio conference. I was like: ""wait, how does DL fit into an R conf""? Speaker: ""I ran TensorFlow in R -- it's actually Python under hood, but psst, don't tell anyone"" https://t.co/7evV59WSRI"
4748,@rasbt,2022-06-05 02:18:13+00:00,https://twitter.com/rasbt/status/1533271945722077184,"@ChrSzegedy latent dirichlet allocation, siamese networks"
4749,@rasbt,2022-06-05 00:40:29+00:00,https://twitter.com/rasbt/status/1533247352118575104,"@mpsampat @roydanroy Thanks a lot, it's really nice to hear that this was helpful! üôå"
4750,@rasbt,2022-06-04 22:11:28+00:00,https://twitter.com/rasbt/status/1533209851639304193,@zacharylipton You mean foundation models? Definitely not in my vocabulary.
4751,@rasbt,2022-06-04 18:11:20+00:00,https://twitter.com/rasbt/status/1533149417540288513,"@JFPuget @tunguz Maybe we shouldn‚Äôt require papers to run other methods. Maybe it would be better for the authors to just focus on their method, pick a common benchmark, and compare to existing results on that benchmark."
4752,@rasbt,2022-06-04 17:34:59+00:00,https://twitter.com/rasbt/status/1533140270891638792,@JFPuget @tunguz I wish more peer reviewers were actually hands-on like this.
4753,@rasbt,2022-06-04 14:47:23+00:00,https://twitter.com/rasbt/status/1533098092031053825,"@Kaszanas @LRaes2 @tunguz 2/2
- ConvXGB: A new deep learning model for classification problems based on CNN &amp; XGBoost
https://t.co/AxhE3a9Fii
- Deep Neural Networks and Tabular Data: A Survey
https://t.co/Qpvpdiv0xt
- Tabular Data: Deep Learning is Not All You Need
https://t.co/GOeH3XxqV4
&amp; there is more"
4754,@rasbt,2022-06-04 14:46:30+00:00,https://twitter.com/rasbt/status/1533097871825854465,"@Kaszanas @LRaes2 @tunguz DL methods for tabular data? Of course!
- Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning https://t.co/Ann9eIZXUL
- On Embeddings for Numerical Features in Tabular Deep Learning https://t.co/0Byepm74FD
1/2"
4755,@rasbt,2022-06-04 12:07:55+00:00,https://twitter.com/rasbt/status/1533057960397750274,"PS: if you are interested in a high level overview before diving into the nitty gritty details and build transformers from scratch, I have a series of short lecture videos on transformers here (covering RNN+attention, BERT, GPT, BART, etc.): https://t.co/JhY0KBGs1D"
4756,@rasbt,2022-06-04 12:05:42+00:00,https://twitter.com/rasbt/status/1533057404576866307,"There are good tutorials on the concepts behind transformers out there. Also, there tons of tutorials on using the HF transformers lib. 
But how about a step-by-step guide on coding BERT, GPT, BART from the ground up? Here's @DanielPressel's amazing repo: https://t.co/jJjWor8D92"
4757,@rasbt,2022-06-04 01:30:52+00:00,https://twitter.com/rasbt/status/1532897641234833409,@karpathy Chasing AGI is a lifestyle. The journey matters more than the goal.
4758,@rasbt,2022-06-04 00:44:12+00:00,https://twitter.com/rasbt/status/1532885897984745474,"@kruggle @DavidFenyo @TobiasSchraink Whoa, this looks üëå! Also totally missed that you had your PhD defense @TobiasSchraink! Huge!! Big congrats!! ü•≥üéâ"
4759,@rasbt,2022-06-03 19:18:50+00:00,https://twitter.com/rasbt/status/1532804015406424066,"@LRaes2 @tunguz @EddieTitus2 @bot_biotech Honestly, I wouldn't trust papers on this because the reported numbers are usually wrong and crucial implementation details are often missing. I would probably check for examples on Kaggle, e.g., https://t.co/DTdyqEkbNR"
4760,@rasbt,2022-06-03 17:53:36+00:00,https://twitter.com/rasbt/status/1532782566981480450,@karlrohe I hope it's reciprocal!
4761,@rasbt,2022-06-03 17:48:06+00:00,https://twitter.com/rasbt/status/1532781185109303298,"@ChurchillMic Yeah, basically what you said. Deep learning is great if you have large datasets and unstructured data. Tabular data is already structured so you kind of miss on the greatest strengths of deep learning (the automatic feature extraction). Especially when features are independent."
4762,@rasbt,2022-06-03 16:32:14+00:00,https://twitter.com/rasbt/status/1532762090074738694,"@rupertpekni Oh yeah sure, basically data organized like a spreadsheet with independent columns as features. Like Iris basically. Sometimes also called ""structured"" data. (Or in statistics jargon we call that ""design matrix""; and also throwing in the i.i.d. assumption here). https://t.co/zDT9KvJTia"
4763,@rasbt,2022-06-03 16:17:48+00:00,https://twitter.com/rasbt/status/1532758457396473857,"@yoga_mat_ @_willfalcon @PyTorchLightnin Sorry, that's currently due to a default setting that is a bit unfortunate, but it is on the roadmap (https://t.co/E8GCR6oyOp). For the time-being, can you try average='macro' in Precision, Recall, etc?"
4764,@rasbt,2022-06-03 15:29:29+00:00,https://twitter.com/rasbt/status/1532746299455545344,"@ChurchillMic I don't think it is ""just use"" -- still takes experience to get good results. But yeah, I think there has been no evidence so far that anything outperforms XGBoost on tabular data in terms or predictive performance (or ensembles &amp; hybrids that involve XGBoost)."
4765,@rasbt,2022-06-03 14:18:38+00:00,https://twitter.com/rasbt/status/1532728469322452994,"@roydanroy There's also a written version (~50 page chapter) in my recent book, which people found helpful."
4766,@rasbt,2022-06-03 14:17:16+00:00,https://twitter.com/rasbt/status/1532728123933999104,"@roydanroy ""L19: Self-attention and transformer networks"" here: https://t.co/JhY0KBGs1D. I start with the original attention mechanism for RNNs, explain self-attention and the original transformer, and then cover the popular architectures (GPT v1-3, BERT, BART). There's also a code demo."
4767,@rasbt,2022-06-03 13:33:14+00:00,https://twitter.com/rasbt/status/1532717046181552130,"@tunguz @EddieTitus2 @bot_biotech Yeah, I usually ignore &amp; skip papers if they don't have code."
4768,@rasbt,2022-06-03 13:17:44+00:00,https://twitter.com/rasbt/status/1532713145453662208,"@overlordayn @_willfalcon wow, very nice and organized!"
4769,@rasbt,2022-06-03 13:16:47+00:00,https://twitter.com/rasbt/status/1532712903828197377,"@Pavdom @yoyololicon Yes, the babysitting and fiddling to stabilize the training. I find that working with GANs is very very frustrating üòÖ"
4770,@rasbt,2022-06-03 13:15:39+00:00,https://twitter.com/rasbt/status/1532712617873133570,@JFPuget Nice! Curious to hear your opinion on this!
4771,@rasbt,2022-06-03 13:15:36+00:00,https://twitter.com/rasbt/status/1532712605848158208,"@EddieTitus2 @bot_biotech Thanks for sharing! I do wonder though how did they get this published, isn't the CNN-feature extraction for XGBoost a standard technique on Kaggle, @tunguz? Also, they don't share any code?? ü´§"
4772,@rasbt,2022-06-03 13:09:54+00:00,https://twitter.com/rasbt/status/1532711170200698880,"@FzzyB Ok, but that's a time series dataset?"
4773,@rasbt,2022-06-03 02:50:07+00:00,https://twitter.com/rasbt/status/1532555198006272014,"@bot_biotech 2/2 even those don't outcompete XGBoost. There are papers that claim they do, but common wisdom is that XGBoost wasn't used very well (hparam tuning and all). Btw., MLPs &amp; Co,  are not bad for tabular data per se. They actually make fine embedding methods for XGBoost."
4774,@rasbt,2022-06-03 02:47:48+00:00,https://twitter.com/rasbt/status/1532554613634867207,"@bot_biotech You can sometimes get fine results with a regular MLP on tabular data. But the common wisdom is that you probably won't beat XGBoost with that if you know how to use XGBoost well. Then there are all these recent, special purpose deep learning architectures for tabular data ...1/2"
4775,@rasbt,2022-06-03 00:16:20+00:00,https://twitter.com/rasbt/status/1532516499553910797,"Machine learners on Twitter don't let their friends use deep learning architectures on tabular datasets. It's still an interesting fresh approach that is worth a look, but yeah of course it doesn't seem to pass the ""beats XGBoost test"". 
(PS: PyTorch code https://t.co/MoExBGY8p6)"
4776,@rasbt,2022-06-03 00:07:24+00:00,https://twitter.com/rasbt/status/1532514248248655881,"@tunguz Maybe still worth checking out to see whether the method is a create new take that may inspire new methods. But yeah, thanks for running that quick check, saves me the time spending time on it atm!"
4777,@rasbt,2022-06-02 23:52:26+00:00,https://twitter.com/rasbt/status/1532510481210015751,"@HeyIamGianluca @_willfalcon Yes, this. It's pretty big in computational bio. Usually where you have a lot of compiler, header, and driver dependencies. But yeah, for my scientific computing tasks, everything has ""wheels"" or conda binaries, so a requirements.txt or environment.yml is usually sufficient."
4778,@rasbt,2022-06-02 23:48:29+00:00,https://twitter.com/rasbt/status/1532509489483612175,"@TaliaRinger Is this a reference to Piper? üòÜ If so, I wonder too, because they do use git for open source work it seems."
4779,@rasbt,2022-06-02 23:46:51+00:00,https://twitter.com/rasbt/status/1532509078873858048,"@zacharylipton And importantly, explaining that anonymity policies are not an excuse for not sharing your code!"
4780,@rasbt,2022-06-02 22:03:59+00:00,https://twitter.com/rasbt/status/1532483191495446549,"@HeyIamGianluca @_willfalcon Haha wow, I successfully dodged docker my whole scientific computing life (thus far ...)"
4781,@rasbt,2022-06-02 15:53:22+00:00,https://twitter.com/rasbt/status/1532389922321190919,@PrasoonPratham Glad to hear üôå
4782,@rasbt,2022-06-02 15:34:57+00:00,https://twitter.com/rasbt/status/1532385288277868544,"@PrasoonPratham Wohoo awesome! This just popped up in the timeline and I was like: wait, I know this cover üòÜ. Hope you'll like it!! ‚ò∫Ô∏è"
4783,@rasbt,2022-06-02 15:27:51+00:00,https://twitter.com/rasbt/status/1532383498509631489,"@lorecarnevale @_willfalcon That is a good approach for many projects. But the one little caveat might be, how do you manage multiple Python versions then?"
4784,@rasbt,2022-06-02 13:38:14+00:00,https://twitter.com/rasbt/status/1532355915730534400,"@ylecun @AnsDome @alfcnz @alfcnz gave a brilliant talk about the VAE approach at UW-Madison ~2 years ago. For those who are interested, here is a nice 20 minute version: https://t.co/r16tWMXlvX"
4785,@rasbt,2022-06-02 13:19:09+00:00,https://twitter.com/rasbt/status/1532351110819758080,"@alfcnz Btw happy birthday, Alf!!! üç∞üéÇü•≥üéâ"
4786,@rasbt,2022-06-02 13:17:28+00:00,https://twitter.com/rasbt/status/1532350687996268544,"@alfcnz I am really glad that you get to do what you love to do and are really excellent at that! That's one of the coolest things in life!üôå And don't tell me you are not smart, the content you are producing is in the top 1 percentile. Not people would understand let alone create it!‚ô•Ô∏è"
4787,@rasbt,2022-06-02 12:40:10+00:00,https://twitter.com/rasbt/status/1532341301651324930,"@pquadri @_willfalcon Yeah, I heard very compelling arguments in favor of poetry. Maybe I should revisit this once things for M1 got more mature. But btw. coincidentally someone introduced me to conda-lock yesterday (https://t.co/5c21HvCwcD) üòá"
4788,@rasbt,2022-06-02 12:34:29+00:00,https://twitter.com/rasbt/status/1532339872953925636,"@_willfalcon @pquadri I gave it a serious try some time ago and it's really neat! For me, why I eventually returned to miniforge/conda is as usual the M1 Arm Mac üòÜhttps://t.co/MQ7DwbaJtw"
4789,@rasbt,2022-06-02 12:32:24+00:00,https://twitter.com/rasbt/status/1532339347126734848,"@Kaszanas @_willfalcon haha yeah, good luck having TensorFlow and PyTorch in the same environment. There is always something that clashes."
4790,@rasbt,2022-06-02 12:15:52+00:00,https://twitter.com/rasbt/status/1532335187731824640,"@AJ_Acevedo @_willfalcon @PyTorchLightnin That's a very nice option as well! Personally, I do use a lot of packages from conda-forge (vs pip + PyPI) which makes conda a tad more attractive to me. It's mainly because it was one of the first that had native M1 support back then. But pyenv is a nice option!"
4791,@rasbt,2022-06-02 01:10:58+00:00,https://twitter.com/rasbt/status/1532167857026617346,"@TheZachMueller I think a --check_latest flag would go nicely with the existing --packages flag. üî•

%watermark --packages numpy
numpy: 1.22.1 (version 1.22.4 is available)"
4792,@rasbt,2022-06-02 00:57:41+00:00,https://twitter.com/rasbt/status/1532164517551128578,@TheZachMueller I actually really like your is_latest_version. Would be really handy in my OSS projects when I develop locally and where I run CI's with latest packages on PRs
4793,@rasbt,2022-06-02 00:55:34+00:00,https://twitter.com/rasbt/status/1532163983700119552,@TheZachMueller Nice! I created something like this for my book (https://t.co/r0honNUe2p) but probably not nearly as sophisticated as yours. Probably should have adopted yours :) https://t.co/JnYNEL7eU6
4794,@rasbt,2022-06-02 00:07:22+00:00,https://twitter.com/rasbt/status/1532151851998760960,"@jessehman Wow, nice, haven't heard of conda-lock yet! Btw. for projects that only use conda-forge packages, ""conda env export --from-history"" is awesome. But I found it doesn't include pip packages (sometimes?). Do you have a workaround for this?"
4795,@rasbt,2022-06-01 23:20:45+00:00,https://twitter.com/rasbt/status/1532140120698241025,"@AndrewLRhyne @pycharm Haha, if you like PyCharm, all I can say is ""stay tuned"" :P"
4796,@rasbt,2022-06-01 22:06:32+00:00,https://twitter.com/rasbt/status/1532121442791432193,* https://t.co/mcWXveqldQ
4797,@rasbt,2022-06-01 22:05:36+00:00,https://twitter.com/rasbt/status/1532121210946994177,"Forgot to mention, watermark doesn't require Jupyter notebooks or IPython at all üòâ. You can import it as a regular Python package. It's actually super handy to include it in your deep learning training scripts, esp when you use remote machines https://t.co/rC5aWYCjJ9"
4798,@rasbt,2022-06-01 22:01:29+00:00,https://twitter.com/rasbt/status/1532120174194720768,@MolasAlex You can use watermark as a regular Python package if that helps https://t.co/54IfJgxv5S
4799,@rasbt,2022-06-01 19:57:13+00:00,https://twitter.com/rasbt/status/1532088900704927748,"@paul_rietschka haha, sorry, that doesn't sound right to me"
4800,@rasbt,2022-06-01 19:44:13+00:00,https://twitter.com/rasbt/status/1532085627533000705,"@paul_rietschka Well yeah, but you still need to activate it, no? And if you forget to activate it, then you end up using the ""wrong"" packages."
4801,@rasbt,2022-06-01 14:41:43+00:00,https://twitter.com/rasbt/status/1532009504249872385,"@gvarnu @_willfalcon Sure thing! Actually, if you use conda, this shouldn't be a problem per se though. I think it is only a problem in cases such as when you install conda and then install Python from https://t.co/3p1HYTavit lets say and it overrides the `pip` link in the base environment."
4802,@rasbt,2022-06-01 14:36:29+00:00,https://twitter.com/rasbt/status/1532008185992732697,"@gvarnu @_willfalcon You can check that by running `which pip` on the terminal (I think `where pip` on Windows). If that's the wrong one, you can always use pip as a module, like `python -m pip install ...` instead of `pip install` (assuming ""python"" is associated with the right env of course :P)"
4803,@rasbt,2022-06-01 14:34:33+00:00,https://twitter.com/rasbt/status/1532007697704443909,"@gvarnu @_willfalcon I have seen this issue happen sometimes when the user had the ""pip"" command in their terminal referring to a pre-installed system environment. I think this sometimes also happens when people hard code their `pip` path e.g., via aliases in the .zshrc."
4804,@rasbt,2022-06-01 13:57:17+00:00,https://twitter.com/rasbt/status/1531998319215525894,@nathangs20 üíØ
4805,@rasbt,2022-06-01 12:33:53+00:00,https://twitter.com/rasbt/status/1531977330905821184,"[5/5] PS: Often, installing a fresh `jupyterlab` fixes the issue. 

If you are interested in learning more about best practices and using virtual envs, @_willfalcon &amp; I put together video tutorials (https://t.co/9hxhQkMg2a) with comprehensive show notes (https://t.co/TQXTUQ2FtH)"
4806,@rasbt,2022-06-01 12:33:52+00:00,https://twitter.com/rasbt/status/1531977329064419329,"[4/5] So, how would you know which environment you are in and what package versions are installed? I developed `watermark` (https://t.co/mcWXveqldQ) back then that can help a bit with these diagnostic issues. It can conveniently show you package versions and environment names https://t.co/DItjj1R4TB"
4807,@rasbt,2022-06-01 12:33:52+00:00,https://twitter.com/rasbt/status/1531977327940444161,"[3/5] How do you fix that? Overall, version and environment issues are almost the culprits when students and readers reach out to me. And sometimes, even after so many years, I experience these problems myself! Key to debugging this is recognizing these issues easily."
4808,@rasbt,2022-06-01 12:33:52+00:00,https://twitter.com/rasbt/status/1531977326505910275,"[2/5] Arg, still doesn't work! Why is the package version wrong? You installed everything correctly!?
After some poking around, it turns out that your Jupyter Lab instance launches a Jupyter notebook using a different conda environment where different packages are installed. https://t.co/xoZE0bF6Ch"
4809,@rasbt,2022-06-01 12:33:51+00:00,https://twitter.com/rasbt/status/1531977325117595650,"Ever had this problem? You open a Jupyter Nb, and code doesn't work as intended? After some back &amp; forth with the author/repo maintainer, you find that it's because you have the wrong package version installed. So, you head back to the terminal and type `conda update...` [1/5] https://t.co/hMiDqW9SaN"
4810,@rasbt,2022-06-01 02:55:50+00:00,https://twitter.com/rasbt/status/1531831861894316033,"@lvwerra @bigdata Ok, I remembered the logo design being cooler, but I still think it was a pretty catchy name. Should probably add my existing codes some time, maybe it's still useful as it was more based on statistical tests. https://t.co/5tgYIVPxwr"
4811,@rasbt,2022-06-01 02:29:46+00:00,https://twitter.com/rasbt/status/1531825302619492354,@lvwerra @bigdata I am still very proud of my creative library name &amp; logo though. Maybe I will just use it for a contrib project or plugin one day üôÉ
4812,@rasbt,2022-06-01 02:27:05+00:00,https://twitter.com/rasbt/status/1531824627751784448,"@lvwerra Haha, @bigdata nudged me again about building a model evaluation tool in our podcast recently. I guess I can now finally relax üòÜ"
4813,@rasbt,2022-06-01 02:25:48+00:00,https://twitter.com/rasbt/status/1531824304207323136,"@lvwerra Wow, nice! Am a big fan of best practices for model evaluation (https://t.co/aYvW168wLF) and talked about sth like this at my faculty interview many years ago! Anyways, glad it was finally built!"
4814,@rasbt,2022-05-31 23:16:35+00:00,https://twitter.com/rasbt/status/1531776683505864705,"Oh, and if you are wondering about the difference between .update and .forward, I got you covered here üòÅhttps://t.co/RtxIPRvHTv"
4815,@rasbt,2022-05-31 23:14:51+00:00,https://twitter.com/rasbt/status/1531776248854286336,"TorchMetrics 0.9 is out with a refactored forward method. As a user, there are no API changes necessary! But a single forward call is now 2x as fast! (via @JirkaBorovec, Nicki Skafte &amp; team!) https://t.co/L6HupqeEtm"
4816,@rasbt,2022-05-31 20:41:36+00:00,https://twitter.com/rasbt/status/1531737680572194816,"Wohoo. Looking forward to attending my fav open source conference once again! Happy to hang out and chat! üôå
Oh, and if you are there, I'll be talking about 
""Using Deep Learning When Class Labels Have A Natural Order -- Predicting Ratings and Rankings using @PyTorchLightnin"" ‚ò∫Ô∏è"
4817,@rasbt,2022-05-31 14:06:31+00:00,https://twitter.com/rasbt/status/1531638257360027650,"@jerofad Thanks for sharing. Looks like they ran experiments on 32x32 images. I can image that for real-world applications with reasonable image sizes, there is probably no way around linear attention!?"
4818,@rasbt,2022-05-31 13:39:10+00:00,https://twitter.com/rasbt/status/1531631374796480512,"Just 2 things for my wishlist: (1) confidence intervals (also for all the tables in the paper) and (2) including the most popular ResNet, ResNet-50, in the paper."
4819,@rasbt,2022-05-31 13:39:10+00:00,https://twitter.com/rasbt/status/1531631373286625282,"How do popular linear attention mechanisms perform in convolution-ViTs?  According to ""Convolutional Xformers for Vision"" (https://t.co/ZyOZkCMaR3), replacing expensive, quadratic self-attention with e.g., Performer, Nystr√∂mformer, Linear Transformer seems really worthwhile: https://t.co/9w1yA8Wh3U"
4820,@rasbt,2022-05-31 13:03:30+00:00,https://twitter.com/rasbt/status/1531622398209957889,"@aliarshad_m @DeepMind @JayAlammar @TensorFlow @seb_ruder Thanks for the kind mention! (PS: 2nd row to the right, I think you got Andrej Karpathy's pic)"
4821,@rasbt,2022-05-30 20:26:19+00:00,https://twitter.com/rasbt/status/1531371448404692993,@kchonyc The internet archive is going to be busy today.
4822,@rasbt,2022-05-30 13:27:26+00:00,https://twitter.com/rasbt/status/1531266033671077888,"PS: A list of all the ""Lightning Bits: Engineering for Researchers"" episodes so far can be found here: https://t.co/9hxhQkMg2a"
4823,@rasbt,2022-05-30 13:27:26+00:00,https://twitter.com/rasbt/status/1531266032345792517,"In this week's Lightning Bits: Engineering for Researchers episode, @_willfalcon and I talk about virtual environments. A super important topic for keeping organized, making code reproducible, and collaborating with others!
https://t.co/ipZAJlVMoN"
4824,@rasbt,2022-05-30 12:55:59+00:00,https://twitter.com/rasbt/status/1531258116750311425,"@guillaume_boni @skepteis @_Ricardo_Simoes @abdnahid_ Indeed. But I also don't think anyone complained about training expensive models per se. It's more about fair comparisons. Right now: ""We can only propose to build a new passenger airplane for transportation if it flies higher &amp; faster than the recent the Virgin Galactic shuttle"""
4825,@rasbt,2022-05-29 23:19:27+00:00,https://twitter.com/rasbt/status/1531052631359209472,"@JFPuget @ylecun @francoisfleuret Sure, but they still allowed him to publish. They just preferred he used a pen name to draw less attention among competitors."
4826,@rasbt,2022-05-29 23:06:27+00:00,https://twitter.com/rasbt/status/1531049361018343424,"@Kaszanas @TDataScience a) incomplete requirements (missing gendoc, for example)
b) lack of wheels for ARM Macs"
4827,@rasbt,2022-05-29 21:39:02+00:00,https://twitter.com/rasbt/status/1531027359914242049,"@fchollet Yes! Will probably cost extra, but I am sure there will be a demand for human-anything. Can't count the number of times I call customer support and say ""talk to representative"" 3x as a default so their system reroutes me and someone can actually solve the issue I am calling about"
4828,@rasbt,2022-05-29 21:08:20+00:00,https://twitter.com/rasbt/status/1531019633058365442,@ylecun @JFPuget @francoisfleuret student's t-distribution &amp; t-tests üòâ
4829,@rasbt,2022-05-29 20:44:13+00:00,https://twitter.com/rasbt/status/1531013566580547596,@cgarciae88 # and please update all the model parameters
4830,@rasbt,2022-05-29 18:44:23+00:00,https://twitter.com/rasbt/status/1530983406363987968,"@TDataScience Except for 99% of *my* use cases pd. read_csv() is just fine because my data frame loads in less than a second anyway. Also, it's easier to install üòÖ https://t.co/PP8sIg9SZw"
4831,@rasbt,2022-05-29 16:56:03+00:00,https://twitter.com/rasbt/status/1530956145631932417,"@iamcuriosity @ylecun @francoisfleuret Yeah, there are scenarios where it also can easily stifle innovation and progress. E.g., think of a creative, innovative new idea but the paper gets rejected because you don't have the compute resources to scale it to trillion parameters in order to claim better benchmark scores."
4832,@rasbt,2022-05-29 14:46:03+00:00,https://twitter.com/rasbt/status/1530923431470018560,"@Pranjal_d_vyas If prompt engineering becomes the dominant way to use ML in the future, that'd be a sad day. Reminds me too much of ‚ÄúYou‚Äôre holding it wrong‚Äù"
4833,@rasbt,2022-05-29 14:43:14+00:00,https://twitter.com/rasbt/status/1530922720669704193,@bruno_constanzo @mashrur_morshed @_manofletters First think in my ML courses is usually to show that you can replace this for loop with a NumPy/PyTorch dot product :)
4834,@rasbt,2022-05-29 14:41:54+00:00,https://twitter.com/rasbt/status/1530922386270330882,"@nin_ran_jan I agree, but alternatively you could get these templates from a curated list of GitHub repos or SO discussions you trust? Maybe spending 3-5 min searching for a Gh repo or SO thread is more efficient than having CoPilot create a template that you have to spend 20 min on debugging"
4835,@rasbt,2022-05-29 14:36:39+00:00,https://twitter.com/rasbt/status/1530921065584766976,@ylecun @francoisfleuret I don't see having different categories/tracks as *slowing down progress*. The same way developing a formula one car is not slowing down progress for car makers wrt to developing better affordable and efficient cars for everyday use.
4836,@rasbt,2022-05-29 00:50:04+00:00,https://twitter.com/rasbt/status/1530713049732087808,"@pbaylies I don't think that's how it works. More like ""..., and I was the first to make the mistake"""
4837,@rasbt,2022-05-29 00:07:49+00:00,https://twitter.com/rasbt/status/1530702413568557057,"@bruno_constanzo haha wow, good catch!"
4838,@rasbt,2022-05-29 00:07:36+00:00,https://twitter.com/rasbt/status/1530702359709601792,@bruno_constanzo The bug I am referring to is probably due to mashing things together. But it could also be due to omission.
4839,@rasbt,2022-05-29 00:06:20+00:00,https://twitter.com/rasbt/status/1530702043542847488,@bruno_constanzo Fair! Not a bug but not very pythonic.
4840,@rasbt,2022-05-28 23:12:51+00:00,https://twitter.com/rasbt/status/1530688581521625089,"Hah, yes, on a 3rd glance there are lots of issues! Also, cosmetically, I think it's really clunky to have a set_inputs methods for the dataset. And has Copilot never heard of @property?"
4841,@rasbt,2022-05-28 23:11:44+00:00,https://twitter.com/rasbt/status/1530688300117381121,"@vykthur To be honest, I think this particular bug may occur because Copilot is mashing different implementations/approaches e.g., if you would combine the implementation in my PyML books and ML with the one in my ML with Python book you would get something like that"
4842,@rasbt,2022-05-28 23:08:44+00:00,https://twitter.com/rasbt/status/1530687547923472386,"@vykthur Ok that's fair. I think a) is relatively low if you know how the perceptron works and b) but on average, I would suspect that someone on stackoverflow would point that out."
4843,@rasbt,2022-05-28 23:07:49+00:00,https://twitter.com/rasbt/status/1530687314506223616,"@ammaryh92 Yeah, the implementation is just wrong :)"
4844,@rasbt,2022-05-28 23:02:51+00:00,https://twitter.com/rasbt/status/1530686066059091970,"@Taylor_Series As usual, I also got you covered üòÜ. What do you prefer, NumPy (https://t.co/r0honNUe2p), PyTorch (https://t.co/X3SNqqjLAA)?"
4845,@rasbt,2022-05-28 22:57:40+00:00,https://twitter.com/rasbt/status/1530684760913285120,"Hate to say this but Copilot is only impressive at 1st glance. Take a 2nd glance and you'll notice these silent bugs. Do you see the issue? Hint: the perceptron below may work ok on standardized data (or generally features centered at 0), but otherwise it will fail spectacularly."
4846,@rasbt,2022-05-28 22:49:14+00:00,https://twitter.com/rasbt/status/1530682641036492801,"@andrewgwils I think it was implied &amp; sarcastic, i.e., 'Top Labs' in quotes. But yeah in general I agree with you :P"
4847,@rasbt,2022-05-28 21:49:01+00:00,https://twitter.com/rasbt/status/1530667485854408704,"@OfficialLoganK @DynamicWebPaige @SlackHQ @JuliaLanguage @discord Maybe I have been using Slack for too long, but to me Discord turns into chaos with that many people because the way they do threaded answers/responses usually turns into a mess for me and I totally lose track of conversations."
4848,@rasbt,2022-05-28 19:04:27+00:00,https://twitter.com/rasbt/status/1530626071749599232,@roydanroy Seems like things shifted from focusing on one thing well to doing just a little on a lot of committees. I (*rhetorical question*) wonder why that is.
4849,@rasbt,2022-05-28 19:04:00+00:00,https://twitter.com/rasbt/status/1530625956351774721,"@benergetic @doorisajar If I want to improve either the predictive and the computational performance, I nowadays often look first at how I can modify or augment the dataset üôÉ"
4850,@rasbt,2022-05-28 18:59:01+00:00,https://twitter.com/rasbt/status/1530624704842715139,"@benergetic @doorisajar Haha, yeah. I have probably read more than 100 papers that propose a new method that is better than ResNet on their benchmarks. So what I do I do? I still happily use ResNet because I don't see a compelling reason not to ü§∑‚Äç‚ôÇÔ∏èüôÉ"
4851,@rasbt,2022-05-28 16:33:50+00:00,https://twitter.com/rasbt/status/1530588164942966784,Also this! Oh my üòë https://t.co/N2ZyyeCkHi
4852,@rasbt,2022-05-28 16:23:23+00:00,https://twitter.com/rasbt/status/1530585536469078016,"@francoisfleuret Yeah, instead of organizing conference tracks based on research topic (NLP, vision, etc.) we could have different tracks based on compute resources:
Laptop, workstation, server, and cluster track üòÜ"
4853,@rasbt,2022-05-28 15:30:44+00:00,https://twitter.com/rasbt/status/1530572287681888256,"""I don't really trust papers out of 'Top Labs' anymore"" (https://t.co/Bcks13TAIb) -- interesting commentary on the current direction of DL research. Remember when we could actually try &amp; run latest models?
Maybe we need a subfield and/or conference on Practical Machine Learning."
4854,@rasbt,2022-05-28 02:27:48+00:00,https://twitter.com/rasbt/status/1530375254492827648,"@python_ds @gyleodhis And we will totally have a @PyTorchLightnin Bits episode on that (https://t.co/9hxhQkMg2a). For now, I have a short write-up here in the Episode 1 shownotes. Hope that helps : https://t.co/sK1V30hkEw"
4855,@rasbt,2022-05-28 02:26:03+00:00,https://twitter.com/rasbt/status/1530374815651069952,"@python_ds @gyleodhis For that to work, you really don't need much. Just a rudimentary setup .py file and an empty __init__. py file. There is an example of that here: https://t.co/11IzzyfsCz."
4856,@rasbt,2022-05-28 02:22:45+00:00,https://twitter.com/rasbt/status/1530373985321500675,"@python_ds @gyleodhis Oh thanks for bringing this up! Totally missed the above tweet! So, traditionally I used ""python https://t.co/WpPFKcVsyR develop"" but now you can use ""pip install -e ."" (assuming you are in the packages dir) as @python_ds mentioned."
4857,@rasbt,2022-05-28 01:34:25+00:00,https://twitter.com/rasbt/status/1530361822473244672,@xamat Wow thanks for the kind words üôå. Glad you are liking it! Coming from someone with your expertise that means a lot to me!
4858,@rasbt,2022-05-27 02:24:56+00:00,https://twitter.com/rasbt/status/1530012145676591107,"Also, the plot_confusion_matrix now supports colormap normalization in the plot_confusion_matrix (as suggested by @michaelwaskom). It's really handy when working with relatively accurate deep learning classifiers on large datasets: https://t.co/X9wwSNvHcG https://t.co/MuYVwW4FP4"
4859,@rasbt,2022-05-27 02:24:55+00:00,https://twitter.com/rasbt/status/1530012143814381568,"It's been more than 8 months since the last mlxtend release. Happy to share that 0.20.0 is live now. 
The highlight is the Group time series split via a kind contribution by Dmitry Labazkin: https://t.co/2DW6ugIlie https://t.co/S5OoLLGcqC"
4860,@rasbt,2022-05-27 01:52:34+00:00,https://twitter.com/rasbt/status/1530004001105772545,"@3scorciav @BlindDou @ylecun Not every paper has a reddit page. And some have multiple ones. I think reddit is better suited for what's hot and popular. Similarly, you could say: why does Amazon need a product review system, why not use reddit?"
4861,@rasbt,2022-05-27 01:31:39+00:00,https://twitter.com/rasbt/status/1529998737547923456,"@3scorciav @BlindDou @ylecun RE ""Why do you say so?"": I do think that it can be useful to have more people contribute. Sometimes people find potential issues or interesting tidbits that others overlook. On the other hand, I think there is also value in having well-matched reviewers for expert opinions."
4862,@rasbt,2022-05-27 00:46:31+00:00,https://twitter.com/rasbt/status/1529987380031246347,"@3scorciav @BlindDou I think they both have value. I see @BlindDou as a take that is more like Amazon reviews. It lowers the barrier to entry and lets all people easily contribute. In contrast, PeerXiv seems closer to the traditional model with a 
 handful of matched reviewers."
4863,@rasbt,2022-05-27 00:22:18+00:00,https://twitter.com/rasbt/status/1529981282251427845,"As always, the concern is the reviewer matching &amp; workload. But sth interesting I will keep on my radar."
4864,@rasbt,2022-05-27 00:22:17+00:00,https://twitter.com/rasbt/status/1529981280707923987,"PeerXiv -- not sure how to pronounce it, but it looks like another interesting take on peer-reviewing (https://t.co/BtIU5DrKfW). I like the idea of not using an accept/reject score but rather using categories (Presentation, Novelty, Significance, Reproducibility, and Validation)"
4865,@rasbt,2022-05-26 23:34:51+00:00,https://twitter.com/rasbt/status/1529969341000781824,"@BenTheEgg Awesome, thanks! This is not pre-trained, right?"
4866,@rasbt,2022-05-26 19:23:44+00:00,https://twitter.com/rasbt/status/1529906147091746817,"@EddieTitus2 I think a promising technique is ŒºP, but I haven't had a chance to try it out yet https://t.co/vNo2vXXMa2"
4867,@rasbt,2022-05-26 19:20:39+00:00,https://twitter.com/rasbt/status/1529905373053870087,"@EddieTitus2 Yeah. Was just working on a paper revision last weekend, and even with small models, trying out these hyperparameter ranges on 4 datasets is already ~$1200 using cloud resources https://t.co/f8ZTn9o0n0"
4868,@rasbt,2022-05-26 19:07:21+00:00,https://twitter.com/rasbt/status/1529902026070581248,"@EddieTitus2 I would say that's really not feasible in most contexts unless you have an infinite budget. With modern platforms, it is easy¬†to set up hyperparameter sweeps, but resources and computational cost is usually the bottleneck"
4869,@rasbt,2022-05-26 19:05:12+00:00,https://twitter.com/rasbt/status/1529901481750581252,"Our first Lightning DevCon is only few weeks away! I don't say this lightly but we'll have some really exciting stuff to announce! Haha, I really wish I could share it already üòÖ!
Also looking forward to @AnimaAnandkumar's &amp; @kchonyc's talks! More info at https://t.co/bAxws0wPo5"
4870,@rasbt,2022-05-26 18:53:49+00:00,https://twitter.com/rasbt/status/1529898619452764171,3/3 Btw. the key ideas of the paper are 1) creating overlap between neighboring patches and 2) masking the diagonal in the attention matrix (and rescaling the matrix). I am generally curious about ViT usage though :)
4871,@rasbt,2022-05-26 18:53:49+00:00,https://twitter.com/rasbt/status/1529898617963786279,2/3 I am mainly curious about how much fiddling ViTs require in practice to get the hyperparameter settings right. What are the memory requirements on small datasets such as CIFAR-10/100 for demo purposes?  And how long the training takes compared to ResNets üòÖ
4872,@rasbt,2022-05-26 18:53:48+00:00,https://twitter.com/rasbt/status/1529898616575467521,"""Vision Transformer for Small-Size Datasets"" (https://t.co/OTlEt8axQ3). I am curious, has someone tried this, yet? ViT seems to have the same predictive performance as ResNet56 but 2x the image throughput (during inference?). Curious what the hassles &amp; training times are. 1/3"
4873,@rasbt,2022-05-26 13:50:13+00:00,https://twitter.com/rasbt/status/1529822214807121922,"@NoorJihad2 Yeah, good question. In my older books I used 0.0 as the threshold. It's because I changed the class labels from -1 / 1 to the more modern 0 / 1. And then 0.5 is in the center between the two labels."
4874,@rasbt,2022-05-26 13:49:03+00:00,https://twitter.com/rasbt/status/1529821920908017667,"@BlackHC @francoisfleuret @PyImageSearch Hm, fair, but then you can also say that about transposing before multiplying :)"
4875,@rasbt,2022-05-26 13:25:22+00:00,https://twitter.com/rasbt/status/1529815959669813251,"@francoisfleuret @PyImageSearch Nice idea adding the colors for the dimensions. Looks very elegant: just enough information but not more. Would not add anything to it, it's perfect as it is."
4876,@rasbt,2022-05-25 22:48:52+00:00,https://twitter.com/rasbt/status/1529595381172027394,"@LostInTangent Eg
grid run \
--name ""..."" \
--dependency_file ... \
--instance_type g4dn.2xlarge \
--datastore_name ... \
 -- \
model-code/refactored-version/cnn-image/....py \
--learningrate ""[0.00005, 0.0001]"" \
--batchsize ""[16, 32, 64]"" \
...
and it would run all 6 experiments in parallel"
4877,@rasbt,2022-05-25 22:47:42+00:00,https://twitter.com/rasbt/status/1529595091110748160,"@LostInTangent So, this is where it becomes important to package everything up in a way that it can run on independent machines."
4878,@rasbt,2022-05-25 22:44:29+00:00,https://twitter.com/rasbt/status/1529594280414674944,"@LostInTangent E.g., for a recent research project, I just ran ~300 training scripts. It would have been tedious (and impossible in the available time) to do all of that on the same machine one after the other."
4879,@rasbt,2022-05-25 22:43:19+00:00,https://twitter.com/rasbt/status/1529593985601241088,"@LostInTangent Good question. Sometimes yes, sometimes no. For small projects, I run them on my workstation or a Grid session. But for bigger projects, I use multiple machines &amp; Grid runs where I submit the training scripts."
4880,@rasbt,2022-05-25 17:34:08+00:00,https://twitter.com/rasbt/status/1529516176333754368,@abose550 @RisingSayak Thanks for the kind words. Glad to hear you liked it!
4881,@rasbt,2022-05-25 17:24:03+00:00,https://twitter.com/rasbt/status/1529513642387034119,"@tennis_dr @subhobrata1 It depends. If I were to talk about energy-efficient ML, I would have to compare studies comparing RNNs and distilled transformers in terms of their energy consumption. Given a same predictive performance level, I can't say off the top of my head which one is more efficient"
4882,@rasbt,2022-05-25 14:48:10+00:00,https://twitter.com/rasbt/status/1529474411522301954,"@mlpermabull Haha, fair! I must say though that I never had any PyTorch-CUDA issues since their installer bring their own binaries and I usually don't compile from scratch :P"
4883,@rasbt,2022-05-25 14:20:00+00:00,https://twitter.com/rasbt/status/1529467323911905282,"@kchonyc ""SGD distributional dynamics of multi-head attention"" has a nice ring to it ü§î"
4884,@rasbt,2022-05-25 14:15:30+00:00,https://twitter.com/rasbt/status/1529466189046505474,@kchonyc This! üî•
4885,@rasbt,2022-05-25 13:50:34+00:00,https://twitter.com/rasbt/status/1529459916255133701,"@PRONOjits Yeah, I think this is the way!"
4886,@rasbt,2022-05-25 13:49:30+00:00,https://twitter.com/rasbt/status/1529459646838317062,"@martingoodson It is pretty much settled :). In my exp, LSTMs are really the worst on small datasets. For that, usually even BoW works better. Predictive performance-wise transformers are best on small datasets, but most BoW-based approaches are more efficient. LSTM is neither on small data."
4887,@rasbt,2022-05-25 13:44:33+00:00,https://twitter.com/rasbt/status/1529458402568675330,"@moro065 In my book I cover RNNs, LSTMs, RNNs + attention, and various Transformers. I also have some videos (L15 and L19) here: https://t.co/JhY0KBGs1D"
4888,@rasbt,2022-05-25 13:42:53+00:00,https://twitter.com/rasbt/status/1529457980038688768,"@cybertiger16 @jerome_massot For NLP yes. I think for time series, LSTMs are still relevant. But for NLP, I think a conceptual overview of RNNs is sufficient. The 5 hours on backprop through time, code examples, and LSTMs could be spend on additional transformer contents."
4889,@rasbt,2022-05-25 13:40:59+00:00,https://twitter.com/rasbt/status/1529457502747770880,"@Jacoed Just waiting for the PyTorch Lightning support for ""mps""  (it's getting close) and then it's coming (already set up the template here: https://t.co/JTeyOshUEq)"
4890,@rasbt,2022-05-25 13:40:01+00:00,https://twitter.com/rasbt/status/1529457262233899010,"@rolisz Thanks for the feedback. That was what I was thinking: a broad conceptual overview, but skipping the details like backpropagation through time, code examples, LSTM"
4891,@rasbt,2022-05-25 13:38:33+00:00,https://twitter.com/rasbt/status/1529456891889434624,@Ajay400 One in the making. üòá
4892,@rasbt,2022-05-25 01:24:56+00:00,https://twitter.com/rasbt/status/1529272269167632384,@JoseMPortilla Haha sad but true ü•π
4893,@rasbt,2022-05-25 01:15:21+00:00,https://twitter.com/rasbt/status/1529269859539886083,@Kaszanas @ZENODO_ORG haha yeah for sure! Was just focused on the code here. Gotta submit a paper revision on Sunday checking off those things except for 10 I have it on GitHub (part of the Gh archive program). That being said: 12 - archive your paper on arXiv
4894,@rasbt,2022-05-25 01:11:44+00:00,https://twitter.com/rasbt/status/1529268948881088512,"@chrisalbon I first read this as ""I once applied for a visa with a cover letter that started with me being a strong fit for that AirBnB"""
4895,@rasbt,2022-05-25 01:04:46+00:00,https://twitter.com/rasbt/status/1529267195867500544,"+1! Here is a template of how a typical research workflow often looks like for me
1 - Set up fresh env
2 - Install project reqs
3 - Install code as Python pkg
4 - Inspect the dset
5 - Run training scripts
6 - Inspect results
7 - Iterate
8 - Export model
https://t.co/11IzzyfsCz"
4896,@rasbt,2022-05-24 23:54:16+00:00,https://twitter.com/rasbt/status/1529249452447481860,"@AllesistKode Yeah, I am just debating: if there is only time for one, RNN+LSTM or Transformers, which should it be? Could be a short mention of RNNs and jumping to transformers, or it could be RNNs and a short mention of transformers ü§î"
4897,@rasbt,2022-05-24 23:50:58+00:00,https://twitter.com/rasbt/status/1529248624248606722,"@paul_rietschka Fair! when it comes to CV, I would probably skip the boilerplate and start the introduction to convolutional nets with VGG nowadays."
4898,@rasbt,2022-05-24 23:48:05+00:00,https://twitter.com/rasbt/status/1529247895559577600,@jmsykes15 Very nice! That's also very surprising to me as I thought that the M1 chips were currently the top performers when it comes to laptops!
4899,@rasbt,2022-05-24 22:56:54+00:00,https://twitter.com/rasbt/status/1529235015262949377,"@joelgrus I agree! I did that in my previous class (and book), but this is quite a lot of RNN hours that students have to put in for this tidbit, which comes at the expense of other relevant concepts. It's always a trade-off since you can't cover it all üò≠"
4900,@rasbt,2022-05-24 22:54:52+00:00,https://twitter.com/rasbt/status/1529234503637532673,@paul_rietschka Devil's advocate would say it is useful to understand the limitations of RNNs to understand why researchers added the attention mechanism to them in the first place? https://t.co/bXuzIOcBBJ
4901,@rasbt,2022-05-24 22:45:52+00:00,https://twitter.com/rasbt/status/1529232241414524928,"@paul_rietschka Only thing is if you go in historical/chronological order, RNNs are a good for motivating the development of attention mechanisms, which led to the transformer. But yeah, agreed, RNNs are more relevant for time series nowadays."
4902,@rasbt,2022-05-24 22:40:59+00:00,https://twitter.com/rasbt/status/1529231013129371649,"@kgec_soham Yeah, in my previous class &amp; book I go from the RNNs to transformers, and I introduce it gradually (and chronologically how it was developed) RNN -&gt; RNN+attention -&gt; Transformers. But I think it is too much üòÖ"
4903,@rasbt,2022-05-24 22:30:53+00:00,https://twitter.com/rasbt/status/1529228471343501314,"For the intro to NLP portion of my class, I am currently debating whether I should jump from bag-of-words directly to transformers, skipping RNNs &amp; LSTM. 
Now, here's the plot twist: seems like LSTMs are becoming relevant for computer vision research now!? https://t.co/OOCYE2GwJz https://t.co/7DHxRRweCS"
4904,@rasbt,2022-05-24 15:54:20+00:00,https://twitter.com/rasbt/status/1529128673495883777,@Kaszanas @PyTorchLightnin @_willfalcon @pyscript_dev üíØ
4905,@rasbt,2022-05-24 13:29:28+00:00,https://twitter.com/rasbt/status/1529092217545052161,"@Ihor_Bobak sure, you can find the code here: https://t.co/W7tSSUN8pR. Let me know what you find!"
4906,@rasbt,2022-05-24 13:23:04+00:00,https://twitter.com/rasbt/status/1529090606315741185,"@jmsykes15 No I haven't. Don't have access to one. Regarding AMD, that's interesting. Is this for laptop or server CPUs?"
4907,@rasbt,2022-05-23 23:34:58+00:00,https://twitter.com/rasbt/status/1528882209314185216,"In Ep 1 (https://t.co/7IzCdaQf6P), @_willfalcon &amp; I chat about Notebooks vs Python Projects. We mix and ‚ô•Ô∏è both! You can see this in action here: https://t.co/aixqcu1qyj. 
And if you can't wait to learn about the setup, check out the show notes ‚ò∫Ô∏è: https://t.co/t9b8xsncuN"
4908,@rasbt,2022-05-23 22:59:50+00:00,https://twitter.com/rasbt/status/1528873367058939904,@JFPuget @ph_singer *What's worse there were even infs during training for the M1 GPU. But that got fixed in the recent nightly release https://t.co/BDXZT5cIP7
4909,@rasbt,2022-05-23 21:48:37+00:00,https://twitter.com/rasbt/status/1528855444613124097,"@JFPuget @ph_singer No they aren't. Could be because due to lack of determinism or other reasons. But for that, I'd say 1 epoch really isn't enough and one would really have to train until convergence."
4910,@rasbt,2022-05-23 20:50:54+00:00,https://twitter.com/rasbt/status/1528840919755243526,"@JFPuget @ph_singer For mixed precision training, I agree. But batch size is also a hyperparameter, I don't want to max that out all the time depending on the GPU. https://t.co/QHoYhc2JEu"
4911,@rasbt,2022-05-23 18:07:32+00:00,https://twitter.com/rasbt/status/1528799807879380994,@srvmshr @_willfalcon üòá no spoilers üòá
4912,@rasbt,2022-05-23 17:46:05+00:00,https://twitter.com/rasbt/status/1528794410800013312,"IDEs, the terminal, Git+GitHub,... what do these have in common? They make us more productive &amp; they are things I wish I had known when I started out in #MachineLearning.
@_willfalcon &amp; I are excited to cover these tools in our Lightning Bits video series: https://t.co/9hxhQkMg2a https://t.co/ZpgIDQdDI0"
4913,@rasbt,2022-05-23 16:15:19+00:00,https://twitter.com/rasbt/status/1528771567274057731,"@ph_singer @JFPuget I think you can do that with the 2080Ti too. I will wait for ""mps"" support in PyTorch Lightning so I can then repeat the training with mixed precision training: https://t.co/7YdfjK1d0Q"
4914,@rasbt,2022-05-23 15:46:27+00:00,https://twitter.com/rasbt/status/1528764304278831107,"@mrdbourke @alperahmetoglu Yeah, can confirm, on the M1 Pro I saw about 20% improvement when doubling the batch size. That was for both the May 18 version in the initial benchmark a couple of days ago and the new nightly"
4915,@rasbt,2022-05-23 15:44:43+00:00,https://twitter.com/rasbt/status/1528763867932794884,@JFPuget Don't the 1080Ti (11 Gb) and 3080 (10 Gb) have the same memory anyways? So if you can't run 64 batch sizes on the 1080Ti how would you do it on the 3080?
4916,@rasbt,2022-05-23 15:40:00+00:00,https://twitter.com/rasbt/status/1528762680798068736,"@datametrician @JFPuget Yes, I think so, too! The laptop has 130W, I need to double-check, but I think the 1080Ti workstation has a 1600W power supply. Suffice it to say, much better cooling."
4917,@rasbt,2022-05-23 15:33:15+00:00,https://twitter.com/rasbt/status/1528760981232537601,@thecapeador I feel like comparing across different batch sizes is a bit unfair though
4918,@rasbt,2022-05-23 15:29:20+00:00,https://twitter.com/rasbt/status/1528759995512377347,"@Tinker_1081 For debugging it, you could run 
conda install watermark -c conda-forge
python -c ""import watermark; print(watermark.watermark())"" https://t.co/sgrseQMWqt"
4919,@rasbt,2022-05-23 15:25:57+00:00,https://twitter.com/rasbt/status/1528759143921860608,"@EmmanuelOvma I looked at the RAM usage during training. Before, it kept growing to crazy numbers like 30+ Gb"
4920,@rasbt,2022-05-23 15:25:02+00:00,https://twitter.com/rasbt/status/1528758913461526530,@Daniel_J_Im which code looks old?
4921,@rasbt,2022-05-23 01:43:02+00:00,https://twitter.com/rasbt/status/1528552051835289600,"@metaxis_eth As far as I understand only the GPU not the ANE, but maybe @PyTorch can give a more precise answer here :)"
4922,@rasbt,2022-05-23 00:54:36+00:00,https://twitter.com/rasbt/status/1528539859354255362,@sdztudhsh Nice! Cool to hear that it worked well in practice!
4923,@rasbt,2022-05-23 00:52:49+00:00,https://twitter.com/rasbt/status/1528539414531645445,@JFPuget @BenTheEgg On the M1 Pro I tried both and 64 was ~20% faster.
4924,@rasbt,2022-05-22 23:54:00+00:00,https://twitter.com/rasbt/status/1528524612149166080,"@Tom14985282 @sebastiandadal Yes, probably better to compare to the M1 Pro, which is also a laptop. For the Ultra, it would be more fair to compare it to the 1080Ti (also a desktop)"
4925,@rasbt,2022-05-22 23:52:47+00:00,https://twitter.com/rasbt/status/1528524305025404928,"@CaroliFrederico * Actually, I didn't know there was a 64 Core GPU version of the Ultra. Will annotate that in the figure later! Thanks!"
4926,@rasbt,2022-05-22 23:50:25+00:00,https://twitter.com/rasbt/status/1528523709077766146,@CaroliFrederico it was a M1 Ultra with 128GB RAM and 48core GPU (not mine unfortunately üòÜ) https://t.co/ISdTAtx2cW
4927,@rasbt,2022-05-22 23:46:48+00:00,https://twitter.com/rasbt/status/1528522798104207362,"@JFPuget No, the batch size is 32 on all machines (except the 3060 as noted)"
4928,@rasbt,2022-05-22 21:29:09+00:00,https://twitter.com/rasbt/status/1528488158521970688,Ready for some M1 Ultra results!? https://t.co/XKgO6yu8wW
4929,@rasbt,2022-05-22 18:46:10+00:00,https://twitter.com/rasbt/status/1528447143190618117,"@codinggeorgi I find it more intuitive. It's something I usually care about the most when training neural networks since I usually use a ""num epochs"" parameter (versus ""num images"" parameter)"
4930,@rasbt,2022-05-22 18:13:04+00:00,https://twitter.com/rasbt/status/1528438812812029952,@thecapeador @TensorFlow Yeah. Btw. is PyTorch 20/05 and 22/05 flipped?
4931,@rasbt,2022-05-22 18:11:07+00:00,https://twitter.com/rasbt/status/1528438321973989376,"@ATornede I see what you mean. Yeah, I could maybe add an example including a test set. I was usually focused on keeping the examples minimal but I can see your point."
4932,@rasbt,2022-05-22 16:20:12+00:00,https://twitter.com/rasbt/status/1528410408238862342,"@karpathy Yeah, I am 100% bored of human-like intelligence &amp; AGI-discussions. Let's just focus on wether the methods deliver better results than previous ones. If the real-world problem is text classification, I care more about better generalization &amp; acc rather than how close it is to AGI"
4933,@rasbt,2022-05-22 16:13:59+00:00,https://twitter.com/rasbt/status/1528408844136767488,"Turns out the first PyTorch release with M1 GPU had a memory leak that is now fixed in the current nightly release. So, I gave it another try. Training performance looks (up to 50%) better! ‚ò∫Ô∏è
https://t.co/6f0HX8yYwp https://t.co/ty3ioNF5VQ"
4934,@rasbt,2022-05-22 13:57:22+00:00,https://twitter.com/rasbt/status/1528374461363273728,"@RDub2 Oh I can see why it may be misleading! For more context: It's a majority vote classifier that combines different models with uniform weights. Here ""weights"" refers to the weights for combining the models, not the model parameter weights."
4935,@rasbt,2022-05-22 13:39:25+00:00,https://twitter.com/rasbt/status/1528369947776278529,"@ATornede Validation sets are commonly for tuning. In reality, you have an independent test set I'd hope."
4936,@rasbt,2022-05-22 13:38:17+00:00,https://twitter.com/rasbt/status/1528369661179482112,@alperahmetoglu @mrdbourke Reran the experiments and it was indeed a tad faster. Will update later and share the results
4937,@rasbt,2022-05-21 17:16:56+00:00,https://twitter.com/rasbt/status/1528062297486376961,"@JC_Pouplard @julesgm4 Oh, I misread! I was looking at the inference plot!"
4938,@rasbt,2022-05-21 17:03:34+00:00,https://twitter.com/rasbt/status/1528058932178173952,@CyrusMaher In many cases probably not :) https://t.co/pQ1VeQ0wfV
4939,@rasbt,2022-05-21 16:42:01+00:00,https://twitter.com/rasbt/status/1528053510612340736,"@CyrusMaher Kind of different things. NM is an optimization algorithm, logistic regression is a  predictive model. You can use logistic regression of course, but then it would become a stacking classifier. Slightly different."
4940,@rasbt,2022-05-21 16:08:59+00:00,https://twitter.com/rasbt/status/1528045197111840769,"@JC_Pouplard @julesgm4 Would you mind posting the complete training contents here: https://t.co/Wq8mm6eUZq. E.g, like this: https://t.co/kn4dOLvfLi"
4941,@rasbt,2022-05-21 16:07:40+00:00,https://twitter.com/rasbt/status/1528044868165148675,@JC_Pouplard @julesgm4 Nice! So that's basically even a tad slower than the M1 GPU! Let me add this later!
4942,@rasbt,2022-05-21 13:44:25+00:00,https://twitter.com/rasbt/status/1528008817514102784,"@bkbrd I don't think that's something that can be easily computed. If you want, you can probably approximate it by assuming ~90% or so average GPU utilization and then considering the runtime and the wattage of each GPU (the info is probably available online somewhere)"
4943,@rasbt,2022-05-21 13:40:54+00:00,https://twitter.com/rasbt/status/1528007930083155968,@alperahmetoglu @mrdbourke Thanks. Sounds like a memory leak. Subscribed and will rerun the benchmarks once that's fixed.
4944,@rasbt,2022-05-21 13:38:26+00:00,https://twitter.com/rasbt/status/1528007309787648001,"@adamlowlife @AlexandreKateb You can build a workstation yourself, but yeah, if you want something performant that is guaranteed to work, I recommend checking out https://t.co/3nafvk4SYJ. I got one in 2018 for work, and it's still running smoothly (that's what the 1080Ti benchmark was based on)"
4945,@rasbt,2022-05-21 13:35:47+00:00,https://twitter.com/rasbt/status/1528006641727283201,"@adamlowlife @AlexandreKateb Yeah, I use my workstation most of the time for small experiments, but when there is need for scaling things up I use cloud resources (i.e., https://t.co/ufnsjwGMZf)"
4946,@rasbt,2022-05-21 13:34:32+00:00,https://twitter.com/rasbt/status/1528006327053713408,"@Tom14985282 Yeah, that would be an interesting comparison since 3060 are laptop cards and it would be more of an apples-to-apples comparison (no pun intended)"
4947,@rasbt,2022-05-21 13:32:45+00:00,https://twitter.com/rasbt/status/1528005880750415872,@FlorianWThamm You might be happy to hear that there is actually support for AMD cards since PyTorch 1.8 ‚ò∫Ô∏è https://t.co/Ax3vk0Xu3H
4948,@rasbt,2022-05-21 03:44:08+00:00,https://twitter.com/rasbt/status/1527857749291323392,"@mrdbourke Could be the same I am seeing with smaller networks. LeNet and small MLPs. Btw, can you crank up the image size to like 224x224 and see what happens?"
4949,@rasbt,2022-05-20 20:57:02+00:00,https://twitter.com/rasbt/status/1527755301084094468,"@julesgm4 Yeah, I would be curious, too. In case someone has a laptop with these card equivalents, I'd be happy about some numbers ‚ò∫Ô∏è"
4950,@rasbt,2022-05-20 15:59:36+00:00,https://twitter.com/rasbt/status/1527680447639130112,"@akbirthko yes totally agree. MacBooks are great productivity machines for everything else though. (haha, and I am kind of glad that they are bad for gaming, otherwise, that'd be too distracting :D)"
4951,@rasbt,2022-05-20 15:46:38+00:00,https://twitter.com/rasbt/status/1527677186966159361,"@srvmshr Yup. But on the bright side, this is much much faster than the beefy server-grade Intel CPU. And thus much much better than any previous-gen Intel MacBook :)"
4952,@rasbt,2022-05-20 15:45:32+00:00,https://twitter.com/rasbt/status/1527676909039108096,"@akbirthko Haha, true. But one is a $50 chip that fits into a laptop, the other is a &gt;$500 card that doesn't üôÉ https://t.co/UklJjTARub"
4953,@rasbt,2022-05-20 15:40:10+00:00,https://twitter.com/rasbt/status/1527675556241846274,@mrdbourke I ran the VGG-16 M1 Pro GPU with batch size 64 too. It took 48.71 min. Slightly faster than the 59.74 min
4954,@rasbt,2022-05-20 15:36:22+00:00,https://twitter.com/rasbt/status/1527674601597243395,"@giffmana @soumithchintala It's not such an early release? I've been using PyTorch on M1 CPUs since early 2021. It's always been quite fast on M1 (compared to Intel CPUs). It blew my 15 inch Intel MacBook Pro out of the water. I don't have it anymore, otherwise I would have included those numbers too"
4955,@rasbt,2022-05-20 15:34:31+00:00,https://twitter.com/rasbt/status/1527674137644244992,"@giffmana Yes, the Intel CPU benchmark uses MKL. I always use the MKL compiled version on my Intel computers."
4956,@rasbt,2022-05-20 15:31:51+00:00,https://twitter.com/rasbt/status/1527673464924033025,"A little update on the M1 PyTorch Benchmarks! Upon popular request, I added the VGG16 inference performance. And someone was so kind to provide M1 Max results as well! https://t.co/6f0HX8yYwp https://t.co/K1ZZaM1fHN"
4957,@rasbt,2022-05-19 23:43:57+00:00,https://twitter.com/rasbt/status/1527434916039901184,@NNightsNNoons Same. But that's also true for regular CPU &amp; GPUs. It's probably because things are so small that the transfer overhead outweighs the benefits of using GPU cores.
4958,@rasbt,2022-05-19 18:44:08+00:00,https://twitter.com/rasbt/status/1527359467243065346,"@AiBeginners Yeah, that could be true. I mean, it's still amazing that this little chip in a laptop outperforms a 12 core Intel Xeon that is huge and costs like $1.5k alone."
4959,@rasbt,2022-05-19 18:41:50+00:00,https://twitter.com/rasbt/status/1527358887816417312,"What a week for open source &amp; scientific computing! We got Intel extensions to accelerate PyTorch, M1 GPU support for PyTorch, and now this just dropped: ""Math support in Markdown"" https://t.co/qDECvj2ur0"
4960,@rasbt,2022-05-19 14:24:01+00:00,https://twitter.com/rasbt/status/1527294006413078535,@paul_rietschka Example of rolling my own layer: https://t.co/mlAlllRejq
4961,@rasbt,2022-05-19 14:23:22+00:00,https://twitter.com/rasbt/status/1527293842839552000,"@paul_rietschka I don't disagree with your layers comment but it 100% depends on the content. Sure, rolling your own layers when it's just reinventing the wheel doesn't make sense except for learning. But you sometimes need to roll your own layers in research. Else how do you develop new things?"
4962,@rasbt,2022-05-19 14:21:47+00:00,https://twitter.com/rasbt/status/1527293443315212289,"@paul_rietschka In my view, the Jax APIs I have seen make Jax more like PyTorch. PT Lightning is actually different, it's on top of PyTorch to take PyTorch as a research &amp; tinkering framework and add best practices to scale your code."
4963,@rasbt,2022-05-19 14:01:18+00:00,https://twitter.com/rasbt/status/1527288289643749378,"@AiBeginners Update: I repeated the M1 Pro GPU run with a batch size of 64, and it took 48.71 min. Slightly faster than the 59.74 min shown in the plot above with batch size 32."
4964,@rasbt,2022-05-19 14:00:38+00:00,https://twitter.com/rasbt/status/1527288121036918785,@kay_saer Yeah. I have been using miniforge since 2021 due to the arm support. I actually love conda-forge as my default channel for conda packages :)
4965,@rasbt,2022-05-19 13:52:39+00:00,https://twitter.com/rasbt/status/1527286114653855751,"@ducnh279 Thanks üôè! Haha, I will, actually! üôå"
4966,@rasbt,2022-05-19 13:51:13+00:00,https://twitter.com/rasbt/status/1527285751011999744,"@paul_rietschka I actually do roll my own layers in PyTorch sometimes üòÇ. As to Jax, it looks like a cool library, but there are like a gazillion APIs for it, ... choice paralysis, you know üòâ"
4967,@rasbt,2022-05-19 12:58:57+00:00,https://twitter.com/rasbt/status/1527272597725057024,"If someone want's to check it out, it would be this video series here: https://t.co/9RIzs6NGfj"
4968,@rasbt,2022-05-19 12:55:07+00:00,https://twitter.com/rasbt/status/1527271635174281216,"A nice start into the day ‚ò∫Ô∏è ""this lecture series is incredible Sebastian‚Äîthanks for putting it on YouTube, sharing the code, and making it modern &amp; 
practical with Pytorch. I went to UW 15 yrs ago, it would have been so nice if my math, cs, &amp; stats professors would've done this"""
4969,@rasbt,2022-05-19 12:49:22+00:00,https://twitter.com/rasbt/status/1527270185157132288,@jplasser My guess is they maybe they don't fully support it yet? It was just realized yesterday so they'll probably need some time.
4970,@rasbt,2022-05-19 12:49:00+00:00,https://twitter.com/rasbt/status/1527270093348012033,"@thecapeador Yeah, it doesn't cause any problems for me. The only issue is if I go higher than 2 on MNIST I get issues (but that's on all computers) because MNIST is so small and you end up with too many open files."
4971,@rasbt,2022-05-19 12:48:06+00:00,https://twitter.com/rasbt/status/1527269869200281600,@cc_parku thanks for sharing! I remember seeing it last year but I should give it another read for hints!
4972,@rasbt,2022-05-19 12:47:10+00:00,https://twitter.com/rasbt/status/1527269631374905344,@MubasharSharif I would maybe recommend eyeballing how many hours you run per year and then compute the cost based on 1) the prices in a cloud service (https://t.co/ufnsjwGMZf has a handy list) and a GPU workstation (I can recommend Lambda machines https://t.co/UOi2CaDrts) https://t.co/BNfJJIm2BQ
4973,@rasbt,2022-05-19 12:43:07+00:00,https://twitter.com/rasbt/status/1527268615543717888,"@MubasharSharif If you run experiments 24/7, then if makes sense to invest in your own hardware. But if you run a few experiments a week (maybe couple of hours each week), then it's probably cheaper just to use cloud resources."
4974,@rasbt,2022-05-19 12:42:10+00:00,https://twitter.com/rasbt/status/1527268372848816129,"@MubasharSharif Depending on your usage, it might also make sense to just use a cloud -- that's what I do at https://t.co/ufnsjwGMZf at the moment. What's nice is you don't have to worry about keeping yet another machine up to date, fixing hardware, etc."
4975,@rasbt,2022-05-19 12:40:52+00:00,https://twitter.com/rasbt/status/1527268045852487681,"@MubasharSharif Personally, my machines are quite dated. I have a Lambda workstation from 2018, and a deep learning server from 2019. They are from my work funding at the university though; not sure if I would spend that money privately üòÖ. I can post the specs but not sure if that's useful?"
4976,@rasbt,2022-05-19 03:02:30+00:00,https://twitter.com/rasbt/status/1527122497958715392,@AiBeginners I don't use Rosetta. Never did. Back then I compiled PyTorch myself to avoid it. Now I use the native M1 version of conda-forge. Different batch sizes could be something worthwhile trying. Only worry is that RAM is already at 80% with 32 images per batch. I can try 64 perhaps
4977,@rasbt,2022-05-19 02:54:29+00:00,https://twitter.com/rasbt/status/1527120480087441409,"@DrCMcMaster Yeah good point. After all, it all needs to be practical if we are curious whether running DNN training on our MacBooks can make our life easier. So far, the bottom line is training DNNs on a laptop is still not feasible (but I was curious to give it a try :))"
4978,@rasbt,2022-05-19 02:42:48+00:00,https://twitter.com/rasbt/status/1527117540249436160,@DrCMcMaster I see. I didn't do it for fairness here because the GPUs couldn't handle more than 32 images per batch (they are resized to 224x224 to imitate typical imagenet sizes)
4979,@rasbt,2022-05-19 02:41:48+00:00,https://twitter.com/rasbt/status/1527117287102337024,"@AiBeginners That being said, do you know if there are any special Metal upgrades/installations required? It should come out of the box on (latest) macOS, right? üòÖ"
4980,@rasbt,2022-05-19 02:34:11+00:00,https://twitter.com/rasbt/status/1527115372108955652,"@kay_saer Ok, results are not super exciting: https://t.co/3QAeQElNny. 
Hoping someone has some tips for speeding it up."
4981,@rasbt,2022-05-19 02:32:52+00:00,https://twitter.com/rasbt/status/1527115038720512000,"@AiBeginners Just took another look, yes, it uses tons of RAM, but utilization cycles between 58% and 80% so that shouldn't be an issue https://t.co/Tv1CjoEUCw"
4982,@rasbt,2022-05-19 02:30:28+00:00,https://twitter.com/rasbt/status/1527114436418453504,@AlexGDimakis CIFAR-10 rescaled to 224x224 ImageNet-size that is üòÖ
4983,@rasbt,2022-05-19 02:24:00+00:00,https://twitter.com/rasbt/status/1527112809267482627,"@AiBeginners But yeah, good call, maybe the M1's don't have memory efficient convolution implementations yet (I remember this being an issue in the early days for the CPU implementations)"
4984,@rasbt,2022-05-19 02:22:18+00:00,https://twitter.com/rasbt/status/1527112379926032385,"@AiBeginners 32 Gb. True, this might be an issue! But then, the Nvidia cards I tested also only have 10 Gb VRAM"
4985,@rasbt,2022-05-19 01:43:29+00:00,https://twitter.com/rasbt/status/1527102613749125120,Was really excited to take the PyTorch nightly release with the new M1 GPU for a spin tonight ü•≥! Here are some early thoughts (that I can hopefully update later): https://t.co/6f0HX8yYwp
4986,@rasbt,2022-05-19 00:22:25+00:00,https://twitter.com/rasbt/status/1527082209659723778,"@guy_nakli @kay_saer you can print out the device name for the model and tensors via .device. 
For the M1 GPU, you want to put things on ""mps"" (as opposed to ""cuda"" for example)"
4987,@rasbt,2022-05-18 18:41:34+00:00,https://twitter.com/rasbt/status/1526996431239647232,@roydanroy @NandoDF Monitor stand ü§∑‚Äç‚ôÇÔ∏è? (What I've been doing since grad school)
4988,@rasbt,2022-05-18 18:38:52+00:00,https://twitter.com/rasbt/status/1526995752890904576,@kay_saer running it now
4989,@rasbt,2022-05-18 18:15:06+00:00,https://twitter.com/rasbt/status/1526989770404003840,"@unsorsodicorda @Apple Fair, but I don't think the M2 Pro will be that much faster than the M1 Pro. Not like the Intel -&gt; M1 / M1 Pro / M1 Max jump. I think we can consider their phone chips as a baseline. They are faster each year, but not magnitudes faster."
4990,@rasbt,2022-05-18 16:37:46+00:00,https://twitter.com/rasbt/status/1526965279066099713,@unsorsodicorda @Apple M2's?
4991,@rasbt,2022-05-18 15:41:04+00:00,https://twitter.com/rasbt/status/1526951006952726528,Official M1 GPU support for PyTorch is here. Wohooo. I have been waiting for this!! ü•≥
4992,@rasbt,2022-05-18 15:21:42+00:00,https://twitter.com/rasbt/status/1526946133603454977,@JFPuget @ph_singer Indeed. Wished I had one / had access to one
4993,@rasbt,2022-05-18 15:07:14+00:00,https://twitter.com/rasbt/status/1526942496047104003,"@JFPuget @ph_singer hah, no, not yet. But I guess this supports the point that yeah transformer fine-tuning can get you good predictive performance but it no where as fast as LogReg + BoW or an RNN ... out of the box ü§™"
4994,@rasbt,2022-05-18 14:34:07+00:00,https://twitter.com/rasbt/status/1526934158802575361,"@ph_singer @JFPuget Ok here we go:
 1) fp16=True: 14.94 min/ep -&gt; 14.89 min (probably because it's a 1080Ti)
2) Using 4 workers in the data loaders instead of tokenizer parallelism: 0 difference
3) Cutting the tokenizer max_length from 512 to 256: 14.94 -&gt; 7.32 min/ep"
4995,@rasbt,2022-05-18 14:16:53+00:00,https://twitter.com/rasbt/status/1526929824161349633,@unsorsodicorda that's fair!
4996,@rasbt,2022-05-18 13:34:18+00:00,https://twitter.com/rasbt/status/1526919106754187264,@ph_singer @JFPuget Thanks!!! I will test this and get back to you with some actual numbers :)
4997,@rasbt,2022-05-18 13:23:59+00:00,https://twitter.com/rasbt/status/1526916512153538562,@yoavgo Pixelmator Pro ftw
4998,@rasbt,2022-05-18 12:42:53+00:00,https://twitter.com/rasbt/status/1526906169188569089,"@Michael86050726 @JFPuget @ph_singer Haha yeah, it's usually a challenge when teaching. When students have certain types of bugs, my first go to is asking whether they use Windows and recommend trying their code with 0 workers."
4999,@rasbt,2022-05-18 12:40:44+00:00,https://twitter.com/rasbt/status/1526905624423956481,@JFPuget @ph_singer 2) It's already the largest batch size that runs on this machine w/o out of memory errors. DistilBert is smaller than BERT but still takes up a lot of GPU memory
5000,@rasbt,2022-05-18 12:39:08+00:00,https://twitter.com/rasbt/status/1526905221871460357,"@JFPuget @ph_singer Thanks for taking a look! 1) Usually use multiple workers, but in this case it makes go twice as slow. It would then complain:
""huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks..."""
5001,@rasbt,2022-05-18 12:34:25+00:00,https://twitter.com/rasbt/status/1526904035571290114,"@unsorsodicorda Oh thanks, that would sound fun! But I don't think I will get a chance in the next coming months. There are also some other hobby projects that I have lying around half-finished. Really need to finish things I started üòÖ. A collab on that some time would be fun though."
5002,@rasbt,2022-05-18 02:43:50+00:00,https://twitter.com/rasbt/status/1526755412573310978,@khademinori @tdietterich @ylecun By this definition you would exclude a lot of real humans though and perhaps include GPT-3 &amp; Co ü§î
5003,@rasbt,2022-05-18 02:41:34+00:00,https://twitter.com/rasbt/status/1526754842420686849,"@khademinori @tdietterich @ylecun Yeah and at the same time most humans would not pass most of these tests. Some people don't read, cook, code, drive, do math, compose music, etc. How do you even define human-level intelligence, and how do you measure it?"
5004,@rasbt,2022-05-18 02:30:27+00:00,https://twitter.com/rasbt/status/1526752045226655744,"@khademinori @tdietterich @ylecun Vice versa, if people fail at the interview tasks you mentioned it doesn't mean they are not intelligent üòâ"
5005,@rasbt,2022-05-18 02:29:50+00:00,https://twitter.com/rasbt/status/1526751888334540802,"@khademinori @tdietterich @ylecun Ok, so we would have to define a set of tasks as you do below and somehow formalize it. There are still infinitely many tasks though. E.g., AIs can succeed at the tasks you list below, but is it AGI if it can't drive and/or can't get groceries?"
5006,@rasbt,2022-05-18 02:18:46+00:00,https://twitter.com/rasbt/status/1526749103245369344,"Notes from ""The 2022 Python Language Summit: Python without the GIL"": https://t.co/pHT6C0EAsR
Nogil #Python be a huge feature &amp; in terms of code changes ""no impact at all to a library like scikit-learn, and perhaps only 15 lines of code for numpy"" sounds like exciting news to me!"
5007,@rasbt,2022-05-17 21:53:41+00:00,https://twitter.com/rasbt/status/1526682391598841858,"Solid collection! Here is my suggested reading order from left to right to 
(1) get started with ML 
(2) Refine your data processing skills 
(3) Apply your knowledge to challenging problems! 
(And (4), excel in an interview, of course, but I don't have a copy at hand, sorry!) https://t.co/epJmBr4Bax"
5008,@rasbt,2022-05-17 21:38:29+00:00,https://twitter.com/rasbt/status/1526678566179688448,"@khademinori @tdietterich @ylecun So, the suggestion is to compare different AIs based on how many tasks they can do? Is that scalable? I mean, I don't even know how many tasks I can do!? How can I then compare myself to others if I can't even quantify how many more/fewer tasks I can do than an AGI / person x?"
5009,@rasbt,2022-05-17 21:26:43+00:00,https://twitter.com/rasbt/status/1526675604426326017,They even computed the average performance over multiple runs with standard deviations back then üëå https://t.co/JaB0V6L7qL
5010,@rasbt,2022-05-17 21:20:19+00:00,https://twitter.com/rasbt/status/1526673994937782272,@Koronomoa @SchmidhuberAI This is from https://t.co/Lb5Vp5YV13
5011,@rasbt,2022-05-17 21:19:33+00:00,https://twitter.com/rasbt/status/1526673801735557122,"@Koronomoa @SchmidhuberAI I see they apparently used DanNet also in 2010 already: ""Already in 2010, we introduced our deep and fast GPU-based NNs to Arcelor Mittal, the world's largest steel maker, and were able to greatly improve steel defect detection through CNNs[ST] (before ImageNet 2012)."""
5012,@rasbt,2022-05-17 21:12:28+00:00,https://twitter.com/rasbt/status/1526672022167773184,@Koronomoa @SchmidhuberAI Thanks! The internet never forgets! üòÅ
5013,@rasbt,2022-05-17 19:22:44+00:00,https://twitter.com/rasbt/status/1526644406547361792,It's been ages since I used @SymPy for my math homework back in college and totally forgot about it! The plotting functionality is super convenient indeed ü•∞! https://t.co/fkO08fRnMI
5014,@rasbt,2022-05-17 18:51:51+00:00,https://twitter.com/rasbt/status/1526636632149041153,"@lavanyaai @weights_biases @l2k Wow, awesome news. Big congrats ü•≥"
5015,@rasbt,2022-05-17 18:12:51+00:00,https://twitter.com/rasbt/status/1526626816525484038,"@adad8m @beenwrekt oh no, so it'll basically be like academia üôÉ"
5016,@rasbt,2022-05-17 17:44:30+00:00,https://twitter.com/rasbt/status/1526619682584858624,"@karpathy 4.0: neural net designs the prompt, output is the ""mind state"" (activations) of a new foundation model neural net"
5017,@rasbt,2022-05-17 16:59:43+00:00,https://twitter.com/rasbt/status/1526608414943719424,@adad8m @beenwrekt Best (and probably worst) case scenario: the # will just go up üòÖ
5018,@rasbt,2022-05-17 15:25:34+00:00,https://twitter.com/rasbt/status/1526584718782869504,"@bruno_constanzo @SchmidhuberAI haha wow, that sounds wild. Ye goode olde fun times!"
5019,@rasbt,2022-05-17 15:24:34+00:00,https://twitter.com/rasbt/status/1526584466818453504,"@marc_claesen @amazingguo @allonsygamma On that note, I have an .edu email but use my private email for arxiv (didn't know it would make a difference) and was always wondering why I was the only one who had to get referrals before uploading my first papers back then."
5020,@rasbt,2022-05-17 13:42:13+00:00,https://twitter.com/rasbt/status/1526558710243500038,"@SchmidhuberAI Going down that rabbit hole, according to that paper, CNN GPU training goes all back even 1/2 decade earlier
Chellapilla et al., 2006; 
Uetz and Behnke, 2009; 
Strigl et al., 2010
But those were special-purpose, hardcoded variants."
5021,@rasbt,2022-05-17 13:37:27+00:00,https://twitter.com/rasbt/status/1526557509766479879,"Currently looking into the origins of training neural nets (CNNs in particular) on GPUs. Usually, AlexNet is my go-to example for successful CNNs thx to GPUs. But I just saw that there was (of course) a paper from the @SchmidhuberAI lab that preceded that: https://t.co/4VWuBMqZqj"
5022,@rasbt,2022-05-17 13:12:32+00:00,https://twitter.com/rasbt/status/1526551241156878337,"@DrGroftehauge Haha sure, I agree with you for a practical use-case scenario. But otherwise it's a chicken-egg problem: one of these networks (e.g., the ones used for training they hypernets or the self-supervised ones) have probably been trained with Glorot/He üôÉ"
5023,@rasbt,2022-05-17 11:51:17+00:00,https://twitter.com/rasbt/status/1526530795065819136,"Hypernetworks predict the weight params of another network. GHN-2 (https://t.co/IgCxNgZcrB) is a hypernet predicting params for ResNet-50, ViT etc. Cool stuff on its own, but maybe interesting research idea: Combine/compare it w self-supervised learning, as pre-training approach?"
5024,@rasbt,2022-05-17 02:02:56+00:00,https://twitter.com/rasbt/status/1526382732527517697,"Just noticed I somehow amassed quite the list on OOD over the last few months üòÖ. If I had some more time, this would be a fun review article/blog article right there. https://t.co/Tm3krZbUfT"
5025,@rasbt,2022-05-17 01:53:43+00:00,https://twitter.com/rasbt/status/1526380412385300480,"Fantastic thread on deep learning and OOD detection (identifying examples outside the training set) by @unsorsodicorda: 
https://t.co/OyDwr72akO
+1 more method by @david_macedo that just landed on Arxiv a few days ago:  https://t.co/9MBViGUhYF"
5026,@rasbt,2022-05-17 01:39:57+00:00,https://twitter.com/rasbt/status/1526376945130299393,@sandstep1 I think DL is often worth a try. But it usually shouldn't be the first thing you try; try it only after establishing simpler baseline first :)
5027,@rasbt,2022-05-16 20:35:31+00:00,https://twitter.com/rasbt/status/1526300332623544320,"@ph_singer @JFPuget huh, not sure what the bottleneck was. Old Huggingface version perhaps?"
5028,@rasbt,2022-05-16 18:24:59+00:00,https://twitter.com/rasbt/status/1526267482461417472,"@therriaultphd @roycoding Yeah, that sounds about right. For translation, that's another story though üòÖ"
5029,@rasbt,2022-05-16 17:57:07+00:00,https://twitter.com/rasbt/status/1526260472420483072,"@JFPuget If you compute training and validation accuracy after each epoch, as you normally would, make that ~1h https://t.co/Oxwjt5moJx"
5030,@rasbt,2022-05-16 17:55:20+00:00,https://twitter.com/rasbt/status/1526260024317714433,@JFPuget I think that was not even a Google Colab default GPU but a 2080Ti.
5031,@rasbt,2022-05-16 17:54:15+00:00,https://twitter.com/rasbt/status/1526259749435604994,@JFPuget Fine-tuning DistilBert for 3 epochs on IMDb took 45 min on Google Colab: https://t.co/DGqkUjGv9Z
5032,@rasbt,2022-05-16 17:51:21+00:00,https://twitter.com/rasbt/status/1526259019085664258,"@JFPuget While the right branch is maybe obsolete, I would still recommend the left branch as a baseline prior to finetuning a transformer"
5033,@rasbt,2022-05-16 17:50:27+00:00,https://twitter.com/rasbt/status/1526258792614268930,"@JFPuget That's fair. You probably don't care about CNNs and LSTMs if you only care about predictive performance. Training a BoW logistic regression model takes seconds though, an LSTM from scratch is 5 min. DistilBert takes an hour. And that's on a small dataset."
5034,@rasbt,2022-05-16 17:33:33+00:00,https://twitter.com/rasbt/status/1526254539854200845,@johnnync13 @PyTorch @fanzhao_intel Oh it does? That's a nice surprise! Thanks!
5035,@rasbt,2022-05-16 17:30:25+00:00,https://twitter.com/rasbt/status/1526253752923086849,@PyTorch @fanzhao_intel I almost asked whether this has support for M1 yet ü§¶‚Äç‚ôÇÔ∏èüòë
5036,@rasbt,2022-05-16 17:26:35+00:00,https://twitter.com/rasbt/status/1526252787356532738,"**** Ahh, for some reason the last link was broken. Should be https://t.co/DGqkUjGv9Z. Btw. this is also just accuracy. Finetuning DistilBert took like 10x as long as training the LSTM. And the BoW logistic regression model in sklearn took just a few seconds."
5037,@rasbt,2022-05-16 17:18:16+00:00,https://twitter.com/rasbt/status/1526250695497859072,"@therriaultphd Haha, yes, this. That's also the typical conversation with colleagues :)"
5038,@rasbt,2022-05-16 16:58:32+00:00,https://twitter.com/rasbt/status/1526245726916853760,"*** All on the same IMDb movie review dataset:

1) BoW + logistic regression: 89.9%, https://t.co/2rVPp5cjT7

2) RNN (LSTM): 85.67%, https://t.co/u98WkPyO2v

3) DistilBert: 93.27%, https://t.co/SdFIp9mPVt"
5039,@rasbt,2022-05-16 16:58:31+00:00,https://twitter.com/rasbt/status/1526245724702265344,"** The IMDb movie dataset has a ration of ~144. This would suggest a bag-of-words model. Indeed, I found that a BoW model performs better than an RNN. But a transformer is even better! (Actual code examples from my book below):"
5040,@rasbt,2022-05-16 16:58:31+00:00,https://twitter.com/rasbt/status/1526245722949050369,* I assume this is based on some experimental data. Would be nice if someone knows the reference? And the icing on the cake would be extending this to transformer models :)
5041,@rasbt,2022-05-16 16:58:30+00:00,https://twitter.com/rasbt/status/1526245720625491973,"Stumbled upon this neat flowchart for choosing text classification methods. I usually eye-balled it, but using a samples/number ratio cut-off seems reasonable. I.e., with a samples/number &lt; 1500 use a bag-of-words model, with a &gt;= 1500, use a seq. model (https://t.co/gbLJEGBOJA) https://t.co/2BmxTTx9Z4"
5042,@rasbt,2022-05-16 14:49:33+00:00,https://twitter.com/rasbt/status/1526213270356365312,"@chipro @lmoroney @josh_wills @sh_reya @jacopotagliabue @GokuMohandas Wow, so awesome! Really excited to get a copy!"
5043,@rasbt,2022-05-14 17:32:06+00:00,https://twitter.com/rasbt/status/1525529398522302469,"@srchvrs @fchollet It would also be interesting if they would be thinking about spending some resources to build a system that involves hiring professional reviewers, who are really good at reviewing papers, to improve the peer review system üôÉ"
5044,@rasbt,2022-05-14 17:01:42+00:00,https://twitter.com/rasbt/status/1525521751081463809,"@fchollet 3/3 I.e., isn't it also kind of up to the investors to do their research and find out which stuff is legit and worth investing in? And maybe it will turn out press releases are not sufficient to judge, so it will all cycle back to legit research articles?"
5045,@rasbt,2022-05-14 17:01:00+00:00,https://twitter.com/rasbt/status/1525521572068478977,"@fchollet 2/3 It's maybe just the nature of business, and if you let it run its course, the good stuff will probably stick around whereas the crappy stuff won't?"
5046,@rasbt,2022-05-14 17:00:43+00:00,https://twitter.com/rasbt/status/1525521501507698693,@fchollet That's a good point and valid concern. Not sure if there is anything for us to do about that though. I'd say there was also the Make-believe phase for software and the web in general (and probably still is) ...  1/3
5047,@rasbt,2022-05-14 14:35:43+00:00,https://twitter.com/rasbt/status/1525485012434436100,"@marktenenholtz Oh I see. I thought that was only for testing in Inception 3. My bad. 
Another classic one would be VGG16. Random crops, color shift, and horizontal flipping."
5048,@rasbt,2022-05-14 14:31:03+00:00,https://twitter.com/rasbt/status/1525483835001012225,"@Suleymanzade And based on the dataset. Sounds like AutoML, so yes, it sounds like a headache üòÜ"
5049,@rasbt,2022-05-14 14:27:32+00:00,https://twitter.com/rasbt/status/1525482951982596098,@marktenenholtz Inception v3? I thought they didn't use image augmentation (at least they didn't describe it in the paper afaik) @ChrSzegedy
5050,@rasbt,2022-05-14 14:14:58+00:00,https://twitter.com/rasbt/status/1525479791432015872,"""A Comprehensive Survey of Image Augmentation Techniques for Deep Learning"" https://t.co/AJ89b0Ggka --Overviews like this are actually super helpful. 
Would be a nice future project to build sth like ""model tables"" where in addition to image aug. we also list hyperparam settings https://t.co/uyNzv9cgD3"
5051,@rasbt,2022-05-14 13:55:21+00:00,https://twitter.com/rasbt/status/1525474850755723265,@xamat 100k. That sounds like beyond next level. Even quite the distance on a bike! Good luck!
5052,@rasbt,2022-05-13 23:21:39+00:00,https://twitter.com/rasbt/status/1525254976867647489,"@cHHillee Ahhh, that makes sense üëå"
5053,@rasbt,2022-05-13 23:17:02+00:00,https://twitter.com/rasbt/status/1525253818463690753,@hythloday @Hrant25 @zacharylipton @helenz1235 I remember when we had to make a judgement call whether to install 64-bit Windows if your PC had &gt;= 4 GB RAM. The N64 had 4 Mb of RAM. 4 Mb!!!
5054,@rasbt,2022-05-13 22:49:18+00:00,https://twitter.com/rasbt/status/1525246838277914624,"Dunno why, but I never used the PyTorch profiler before. It's actually cool stuff, even if you don't use all the extra fluff in TensorBoard. But what's the negative memory? ü§î https://t.co/YxXW8bgpks"
5055,@rasbt,2022-05-13 21:26:07+00:00,https://twitter.com/rasbt/status/1525225905626423298,"@xamat @tunguz @StackOverflow wait what, is this a recursion joke? üòÜ"
5056,@rasbt,2022-05-13 20:45:47+00:00,https://twitter.com/rasbt/status/1525215753628266496,"@zacharylipton I think you missed the train üòÜ. This was cool in like Jan 2022, until Feb 2022 üôÉ."
5057,@rasbt,2022-05-13 19:35:04+00:00,https://twitter.com/rasbt/status/1525197956126760962,"@xamat @tunguz @StackOverflow Haha, no. But also yes. I usually explain the concept of a stack overflow. And then of course I mention that this is also what the @StackOverflow name is based on üôÉ"
5058,@rasbt,2022-05-13 18:49:00+00:00,https://twitter.com/rasbt/status/1525186364748222465,"@tunguz I usually introduce it in decision tree contexts
(1) I mention it's a common interview question thus useful in interviews (not the real world) and 
(2) it's actually a nice segue to explaining what a stack overflow is üòÜ"
5059,@rasbt,2022-05-13 17:44:01+00:00,https://twitter.com/rasbt/status/1525170012431982592,"@arian_jamasb @leocastorina @DeepMind Yeah, I never had time to work on it üòÖ"
5060,@rasbt,2022-05-13 12:15:57+00:00,https://twitter.com/rasbt/status/1525087450166611969,@MauroJimenezM That‚Äôs true for any type of encoding though. Ie you have to know contexts like whether it‚Äôs an nominal or ordinal categorical variable to decide whether to use one hot encoding etc. what do you mean by validating clusters?
5061,@rasbt,2022-05-13 01:42:14+00:00,https://twitter.com/rasbt/status/1524927971076743185,"@MGuasch999 @svpino Got tired of it üòÖ. Originally, setting it up was a fun challenge &amp; exercise to keep up with tech and get familiar with all that stuff. But yeah that was pretty much it. I don't have any other NFTs or crypto and am not really interested in that so I changed it back üôÉ"
5062,@rasbt,2022-05-13 00:43:25+00:00,https://twitter.com/rasbt/status/1524913169403195393,"Biopandas v0.4.0 is out (https://t.co/MoLGWoh4Ko)! Tired of what the protein data bank has to offer? Thanks to a kind contribution by @arian_jamasb, you can now fetch structures directly from @DeepMind's Alphafold DB: https://t.co/iOgyF5gRWC"
5063,@rasbt,2022-05-12 23:49:37+00:00,https://twitter.com/rasbt/status/1524899627547480071,"@BlindDou @tunguz Yeah, that sounds reasonable, and then distribute that all over the Ethereum blockchain."
5064,@rasbt,2022-05-12 22:48:44+00:00,https://twitter.com/rasbt/status/1524884307466149892,"@_rxavier_ @tunguz Same, because it kind of bothers me on a conceptual level (""it just doesn't feel right""). However, I think it's quite common on Kaggle and can you get pretty good predictive performance sometimes."
5065,@rasbt,2022-05-12 22:23:34+00:00,https://twitter.com/rasbt/status/1524877972636848128,"@_rxavier_ @tunguz Just curious: When you use label / ordinal encoding for categorical features, do you treat the alphabetical order of the features as a hyperparameter? I.e., do you do multiple runs with different alphabetical orders like prepending random letters?"
5066,@rasbt,2022-05-12 20:25:57+00:00,https://twitter.com/rasbt/status/1524848375581093888,"@tunguz Hah, probably not if each bot runs one of these 30B language models that were open sourced last week üòÜ"
5067,@rasbt,2022-05-12 19:15:51+00:00,https://twitter.com/rasbt/status/1524830734107693056,"@_kenny_joseph @joshuastarmer @HunterSchafer @RabirajBandyop1 Nice, glad you found the lecture notes helpful! In case it's even more convenient, here is a page with links to all videos, notes, and code examples from this class: https://t.co/tJU9cJp9ek"
5068,@rasbt,2022-05-12 16:13:54+00:00,https://twitter.com/rasbt/status/1524784945717190658,"@rather__aarif I agree, I would have loved to have it in color, too! I hope you'll like the rest of the contents though üòä"
5069,@rasbt,2022-05-12 15:31:43+00:00,https://twitter.com/rasbt/status/1524774326783836166,"Had a fun chat with Ben Lorica @bigdata on The Data Exchange Podcast! We covered lots of topics, from the state of deep learning for developers to keeping up with arXiv -- there are so many papers! https://t.co/QD0ZrQaOUu"
5070,@rasbt,2022-05-11 23:30:36+00:00,https://twitter.com/rasbt/status/1524532456728276994,"It's fascinating how far you get and what you can do with just 3 basic ingredients: 
(1) embedding layers + 
(2) attention heads + 
(3) cross entropy loss. (And Adam!).
""End-to-end symbolic regression with transformers""  https://t.co/BP0ovywZ3J https://t.co/SB1xxFB6b4"
5071,@rasbt,2022-05-11 21:17:36+00:00,https://twitter.com/rasbt/status/1524498985641291776,"@apachaves @jeremyphoward @ProjectJupyter No no, I have the default IPython kernel https://t.co/iK6XlBJO2T"
5072,@rasbt,2022-05-11 18:59:28+00:00,https://twitter.com/rasbt/status/1524464223178440704,"@jeremyphoward @ProjectJupyter *I just see what you mean by ""switch"". Actually, I can't recall it looking like they show in the docs. It's just this ""bug"" symbol itself that you can click to turn it on and off."
5073,@rasbt,2022-05-11 18:56:03+00:00,https://twitter.com/rasbt/status/1524463360670109698,"@jeremyphoward @ProjectJupyter Once you have it activated, you can then set the breakpoints by clicking on the respective line https://t.co/NSn92xFWzf"
5074,@rasbt,2022-05-11 18:54:34+00:00,https://twitter.com/rasbt/status/1524462988366917638,"@jeremyphoward @ProjectJupyter Yeah, I actually use it quite often. It's pretty nice. https://t.co/8yUN2q5SzB"
5075,@rasbt,2022-05-11 18:23:58+00:00,https://twitter.com/rasbt/status/1524455287066923009,"@Suleymanzade @DataUmbrella Yes, if you use tf.nn.sparse_softmax_cross_entropy_with_logits then it should be the same."
5076,@rasbt,2022-05-11 18:12:22+00:00,https://twitter.com/rasbt/status/1524452371505586176,"@Suleymanzade @DataUmbrella 2/2 That's because the cross_entropy function computes the LogSoftmax internally. The log is for numerical stability here. So, basically, the cross_entropy does the softmax already for you, but sometimes you might be interested in looking at the probability scores of the model."
5077,@rasbt,2022-05-11 18:10:52+00:00,https://twitter.com/rasbt/status/1524451991090511877,"@Suleymanzade @DataUmbrella Good question. I sometimes do this because I am sometimes interested in looking at the class-membership probabilities (=the softmax values). But you are right, for cross_entropy loss in PyTorch, the logits should be used 1/2"
5078,@rasbt,2022-05-11 17:49:52+00:00,https://twitter.com/rasbt/status/1524446708821864455,"ICYMI: Here are the recordings of our @DataUmbrella seminar yesterday! This was fun!

Part 1: PyTorch (https://t.co/XqarMI4SJU)

Part 2: Scaling PyTorch code with LightningLite (https://t.co/8sMdTSNEaz)

Part 3: Q&amp;A: https://t.co/BzX3vdCVpo"
5079,@rasbt,2022-05-11 04:06:18+00:00,https://twitter.com/rasbt/status/1524239450611625986,@xamat Oops. I was thinking in one it‚Äôs encouraged in the other it‚Äôs discouraged. Looks like some candidates didn‚Äôt read the handbook üòÖ
5080,@rasbt,2022-05-11 03:53:56+00:00,https://twitter.com/rasbt/status/1524236339612471297,@xamat The difference between an academic and an industry resume? üòÜ
5081,@rasbt,2022-05-11 03:06:58+00:00,https://twitter.com/rasbt/status/1524224518587355136,"@gdb @hardmaru And then there are paper revisions where you have a few weeks to run some additional experiments on some remotely related methods. Of course, the methods don't share their code so you have to scramble to get it coded up asap so that experiments finish running in time."
5082,@rasbt,2022-05-10 22:57:12+00:00,https://twitter.com/rasbt/status/1524161662030331910,@harasimowiczm Wow nice! I hope you will like it!! üòä
5083,@rasbt,2022-05-10 22:56:28+00:00,https://twitter.com/rasbt/status/1524161479171358721,"@david_macedo wohoo, thanks for the teaser!"
5084,@rasbt,2022-05-10 14:37:08+00:00,https://twitter.com/rasbt/status/1524035818267942914,"@fjuengermann Yeah, looks like it's the same method (and the same authors)"
5085,@rasbt,2022-05-10 14:36:40+00:00,https://twitter.com/rasbt/status/1524035700328472577,@jmaronasm I think  you are right! https://t.co/0ylZEnYaGz
5086,@rasbt,2022-05-10 14:33:40+00:00,https://twitter.com/rasbt/status/1524034942019190785,@kh_notodiputro https://t.co/B5ljB4nCIY
5087,@rasbt,2022-05-09 22:08:41+00:00,https://twitter.com/rasbt/status/1523787064709320704,"@adbreind @svpino @PyTorchLightnin @onnxai @ApacheTVM Hm, but ONNX is just a representation/protocol, not a tool for efficient hot-swapping of models etc. It all depends on your needs &amp; how you define ""deployment process"" but in either case there needs to be an adjustment I'd say."
5088,@rasbt,2022-05-09 19:44:15+00:00,https://twitter.com/rasbt/status/1523750718737317889,"@marktenenholtz @svpino @PyTorchLightnin This was a feel-good, fun one üòä https://t.co/0LjEHAXcvw"
5089,@rasbt,2022-05-09 18:23:52+00:00,https://twitter.com/rasbt/status/1523730485834223617,@heartsalve @CinaGiovanni 2/2 Unknown entries would all default to &lt;unk&gt; but then don't you already know it's OOD data and can probably infer that it should be high uncertainty?
5090,@rasbt,2022-05-09 18:22:18+00:00,https://twitter.com/rasbt/status/1523730093930999812,"@heartsalve @CinaGiovanni Categorical data ... looking into that sound interesting &amp; tricky at the same time. Given that you encode categorical data using an embedding layer before inputting, how would you deal with OOD data? 1/2"
5091,@rasbt,2022-05-09 18:20:48+00:00,https://twitter.com/rasbt/status/1523729715755773952,@jmschreiber91 üíØ
5092,@rasbt,2022-05-09 16:43:49+00:00,https://twitter.com/rasbt/status/1523705309394792448,Putting on the final touches for our talk on PyTorch @DataUmbrella tomorrow! @adrianwaelchli &amp; I will be giving you an intro to PyTorch &amp; scaling PyTorch via optimized accelerators to hundreds of GPUs or TPUs for modern DL at scale. You can join us here: https://t.co/D91iXnvQUE https://t.co/ro9IIw4NJQ
5093,@rasbt,2022-05-09 15:48:43+00:00,https://twitter.com/rasbt/status/1523691441067012096,"@csaybar @joost_v_amersf Thanks, bookmarked!"
5094,@rasbt,2022-05-09 14:23:53+00:00,https://twitter.com/rasbt/status/1523670092826902529,"@EivindHTo yes yes üòì
https://t.co/sHYIwRcPx3"
5095,@rasbt,2022-05-09 14:20:23+00:00,https://twitter.com/rasbt/status/1523669211914342400,"Oops, had multiple tabs open and was sharing a different, related paper. The one I meant to share was ""A Simple Approach to Improve Single-Model Deep Uncertainty via Distance-Awareness"" of course üòÖ https://t.co/WCc1lM8Bie"
5096,@rasbt,2022-05-09 14:11:42+00:00,https://twitter.com/rasbt/status/1523667027344650240,@jmschreiber91 *Uncertain on OOD data
5097,@rasbt,2022-05-09 14:04:03+00:00,https://twitter.com/rasbt/status/1523665101710000133,"New method for estimating the predictive uncertainty of deep neural networks with just 2 little changes: (1) spectral norm of the weights and (2) replacing the output layer with a Gaussian process layer. No Bayesian neural nets &amp; ensembles required, yay! https://t.co/FBY3Hur1dS https://t.co/ns5JmtV6Bh"
5098,@rasbt,2022-05-09 12:08:10+00:00,https://twitter.com/rasbt/status/1523635939519590400,"Wohoo, I am really excited about @joshuastarmer‚Äôs new book! Have seen a draft version a few months back and can guarantee you that if you like StatQuest you will love this! Quadruple Bam!"
5099,@rasbt,2022-05-08 20:42:25+00:00,https://twitter.com/rasbt/status/1523402967423983616,@fchollet Totally agree. I feel like for those who understand DL and are naturally aware of the limitations it is probably also more productive to skip these as they usually go in circles
5100,@rasbt,2022-05-06 02:06:53+00:00,https://twitter.com/rasbt/status/1522397460013932544,"@DynamicWebPaige *in a good way, right!? üòä"
5101,@rasbt,2022-05-06 01:50:57+00:00,https://twitter.com/rasbt/status/1522393448107679745,"@harsha_musunuri @marktenenholtz Have fun! And in case you have a long weekend, I have some hands-on follow-up material here üòä: https://t.co/CWcHmjqg0w"
5102,@rasbt,2022-05-05 22:28:18+00:00,https://twitter.com/rasbt/status/1522342449133273089,@roydanroy Well you made it sound so confusing that I actually looked üòÜ. Has been a while since I clicked a 1/n thread tweet ...
5103,@rasbt,2022-05-05 22:25:02+00:00,https://twitter.com/rasbt/status/1522341627586650113,@rikvanderkant Want me to fill in the blanks? üòÜü§£
5104,@rasbt,2022-05-05 13:47:51+00:00,https://twitter.com/rasbt/status/1522211475460444160,"@marktenenholtz Wohoo, thanks for the kind words!"
5105,@rasbt,2022-05-05 13:33:22+00:00,https://twitter.com/rasbt/status/1522207828877971456,"@roydanroy @kchonyc @dwf @tyrell_turing Kind of. $3500 per day and $10,000 per week. It should be sufficient for most rent payments though ü§î"
5106,@rasbt,2022-05-04 20:48:40+00:00,https://twitter.com/rasbt/status/1521954988624420871,Great advice on best practices that also extend to DL research üëå! Stuff I wish I knew when I was a student ... or maybe even just a year ago üòÖ
5107,@rasbt,2022-05-04 17:36:49+00:00,https://twitter.com/rasbt/status/1521906705898037248,"Was trying to implement k-fold cross-validation for deep neural nets ... 
Phew, I was almost about to reinvent the wheel before I discovered the pl_cross library! Just put together a quick demo here: https://t.co/YQXPvFto2b"
5108,@rasbt,2022-05-04 16:47:25+00:00,https://twitter.com/rasbt/status/1521894275545448448,@unrahu1 Sure! It's available here: https://t.co/NgBKsfIHJs
5109,@rasbt,2022-05-04 15:30:35+00:00,https://twitter.com/rasbt/status/1521874940236025856,@therohanpandey1 @karpathy The process of capturing is still very useful though as it also gives you piece of mind that you are on top of things
5110,@rasbt,2022-05-04 15:29:49+00:00,https://twitter.com/rasbt/status/1521874747767857155,"@therohanpandey1 @karpathy It depends. Often, when I work on a project regularly I actually don't look at the logs very often if at all. It gets useful though when you are juggling multiple projects and want to come back to one after a few weeks or months (e.g., working on paper revisions üòÜ)"
5111,@rasbt,2022-05-04 15:21:08+00:00,https://twitter.com/rasbt/status/1521872562447396867,"@therohanpandey1 @karpathy It's kind of weird as I usually prefer open source tools and markdown formats etc., but for project-logging, I actually really like MS OneNote since it makes drag &amp; drop of figures plus drawing on them super fast and seamless."
5112,@rasbt,2022-05-04 15:19:41+00:00,https://twitter.com/rasbt/status/1521872197631066113,"@therohanpandey1 @karpathy Personally, I just try to write down and log as much as I can. The best setup is the one that makes copy &amp; pasting text, code, and figures/plots most seamless. Otherwise, you will get lazy and omit things. Capturing is key, and then you can always go back and edit &amp; refine."
5113,@rasbt,2022-05-04 14:58:46+00:00,https://twitter.com/rasbt/status/1521866931392987143,"@karpathy Very cool! It's also that sort of thing where future self will thank you, too."
5114,@rasbt,2022-05-04 14:49:53+00:00,https://twitter.com/rasbt/status/1521864696432898053,"Susan, Mikel, Sam, Daniel, Punit, Moya, Stephen, Myle, Kurt, ... Takes a lot of people to make it all work. Should share this with a collaborator who recently asked me if we (/I) could train an LLM from scratch on their dataset in an academic setting."
5115,@rasbt,2022-05-04 14:38:44+00:00,https://twitter.com/rasbt/status/1521861892322607104,"@sdztudhsh @Jeande_d Oh nice, thanks for sharing! Looks super interesting, but  I guess I'd really lack the Physics domain knowledge for this. Looking at the paper, I remember some of the stuff from my time dabbling with molecular dynamics simulations, but yeah, I'd be super rusty in this context"
5116,@rasbt,2022-05-04 14:09:33+00:00,https://twitter.com/rasbt/status/1521854547240656897,"@sdztudhsh @Jeande_d You mean energy-based models? Hmm, not sure if they are my cup of tea ü§îüòÜ"
5117,@rasbt,2022-05-04 00:27:36+00:00,https://twitter.com/rasbt/status/1521647696989368327,"This was really a super nice &amp; productive collaboration! And I learned A LOT about computational communication research!
(PS: You can find our paper on ""Integrating Machine Learning with Communication Theories to Study the Use of Color &amp; Brightness"" here: https://t.co/tXJnGHJ083)"
5118,@rasbt,2022-05-02 17:35:02+00:00,https://twitter.com/rasbt/status/1521181482471116801,@kjbird15 Super interesting! I actually didn't know about the zero-initializing of the last batchnorm layer in each of the residual branches: https://t.co/aMVPfqZw60
5119,@rasbt,2022-05-02 13:35:11+00:00,https://twitter.com/rasbt/status/1521121125203333122,@nicholasglazer I'd say since most web hosts don't give you admin access to the servers or it's at least tricky to do for many people?
5120,@rasbt,2022-05-01 21:56:30+00:00,https://twitter.com/rasbt/status/1520884894309789698,"@gdsttian Yeah exactly, not sure if I‚Äôd call it a big lie üòâ"
5121,@rasbt,2022-05-01 21:20:26+00:00,https://twitter.com/rasbt/status/1520875819266158595,"@Suleymanzade Sure! In the meantime, not sure if that's helpful, but there is a short section on that in my new book: https://t.co/xwmTD2jyV9"
5122,@rasbt,2022-05-01 20:57:02+00:00,https://twitter.com/rasbt/status/1520869929834192899,@Suleymanzade Actually funny that you ask because it is on my ‚Äúsomeday‚Äù list. Glad to hear people would be interested in that! Maybe in a few weekends.
5123,@rasbt,2022-05-01 19:50:10+00:00,https://twitter.com/rasbt/status/1520853102966054914,"@DuaneJRich Hah, yeah, I was also very surprised about this, which is why I posted this üòÜ"
5124,@rasbt,2022-05-01 19:47:25+00:00,https://twitter.com/rasbt/status/1520852410759061507,"I finally got around updating my DL repo and adding some ordinal regression models for deep learning. More will follow some time ... (Among other things, there were also updates to mlxtend and biopands, yay, #OpenSourceSunday) 

https://t.co/4jZVqEYcmp https://t.co/5kPvEsahPK"
5125,@rasbt,2022-05-01 18:45:54+00:00,https://twitter.com/rasbt/status/1520836929134239747,"Ok ok, they are probably all lies. But let me post the solution üôÉ 

(Haha, I think that was my first twitter survey ... not sure why I set it to 24h, and didn't know you can't quit it early) https://t.co/o1i59nKiwB"
5126,@rasbt,2022-05-01 18:43:50+00:00,https://twitter.com/rasbt/status/1520836410210664454,"This is huge ü•∞. And the best part is: No installation! Just add two lines to your HTML file 
&lt;link rel=""stylesheet"" href=""path/to/pyscript.css"" /&gt;
&lt;script defer src=""path/to/pyscript.js""&gt;&lt;/script&gt;
and off you go!"
5127,@rasbt,2022-05-01 18:33:42+00:00,https://twitter.com/rasbt/status/1520833859901870085,"@JesperDramsch @burkov @scikit_learn @TensorFlow @aureliengeron Thanks! Just wanted to mention that there is a PyTorch edition now, along with some extra contents :). https://t.co/wI7Mdcq6rE"
5128,@rasbt,2022-05-01 16:31:40+00:00,https://twitter.com/rasbt/status/1520803148570505216,"@Do_Widzeni_a Can't remember where I read it, but there was this example of Japan and South Korea being two of the technologically most advanced countries. And they have unemployment rates of only 2.8 and 3.1 percent."
5129,@rasbt,2022-05-01 15:10:30+00:00,https://twitter.com/rasbt/status/1520782723681562624,"@TheRandomMtrix 2/2 Imho, I think calling it ""statistical data science"" emphasizes that there is a stronger focus on the statistical underpinnings vs the programming aspects. Otherwise, why bother using ""statistical"". Same here with probabilistic."
5130,@rasbt,2022-05-01 15:09:04+00:00,https://twitter.com/rasbt/status/1520782360421228544,"@TheRandomMtrix Yeah I also know what you mean when you point out that the term is vague. But to be honest, imho it's fine. I remember colleagues criticizing the term ""Statistical data science"" because all data science involves statistics. 1/2"
5131,@rasbt,2022-05-01 15:06:59+00:00,https://twitter.com/rasbt/status/1520781835567042560,@MarcosCarreira @Sharpe_Actuary @chrisalbon @jeremyphoward Reprogramming of course also doesn't hurt. It's basically a money vs time issue :P
5132,@rasbt,2022-05-01 15:06:03+00:00,https://twitter.com/rasbt/status/1520781602623836165,"@MarcosCarreira @Sharpe_Actuary @chrisalbon @jeremyphoward You could rent a cloud instance for this specific computation. E.g., on Grid you can fire up a Jupyter Notebook is a few sec. It doesn't have to be a GPU machine but could be a massive CPU node with lots of RAM. https://t.co/9XqQ4jt1wQ"
5133,@rasbt,2022-05-01 15:02:55+00:00,https://twitter.com/rasbt/status/1520780813285085184,"@NetaShoham @TheRandomMtrix Yeah, Bayesian can be one case. But you can also consider frequentist probabilistic models. E.g., consider a regression example where you learn the mean and standard deviation of a gaussian via maximum likelihood."
5134,@rasbt,2022-05-01 14:58:45+00:00,https://twitter.com/rasbt/status/1520779764247707649,@TheRandomMtrix My model can output a probability distribution and still be deterministic. And my model could output a different class label each time due to dropout but still be non-probabilistic.
5135,@rasbt,2022-05-01 14:55:40+00:00,https://twitter.com/rasbt/status/1520778989845069824,"@TheRandomMtrix Hm yeah, but I think deterministic/stochastic is different from probabilistic/non-probabilistic"
5136,@rasbt,2022-05-01 14:08:12+00:00,https://twitter.com/rasbt/status/1520767045826224128,"@TheRandomMtrix Here probabilistic deep learning in the sense that it combines probabilistic models with deep learning. Like in variational inference, normalizing flows, etc."
5137,@rasbt,2022-05-01 11:59:08+00:00,https://twitter.com/rasbt/status/1520734562426499072,"@venksaiyan @burkov I‚Äôm order to interpret the scores, there are papers that explain it on a conceptual level; you don‚Äôt need to be an expert in PAC learning or computing VC dimensions in order to understand them."
5138,@rasbt,2022-05-01 11:55:42+00:00,https://twitter.com/rasbt/status/1520733700811546624,@venksaiyan @burkov I don‚Äôt think you need much/any math to choose say MCC over accuracy for imbalanced class problems. What I was trying to get at is exactly that: you need the math to come up with MCC but not to use it.
5139,@rasbt,2022-05-01 03:19:36+00:00,https://twitter.com/rasbt/status/1520603820119961600,"@RidNai Depends on the research, but for most people I don‚Äôt think so unless it evolves. It‚Äôs great for small budgets and small example codes, but it lacks eg multi-GPU support which is kind of essential for modern experiments. There are other platforms that are better in that area."
5140,@rasbt,2022-05-01 02:36:57+00:00,https://twitter.com/rasbt/status/1520593084366610432,@RidNai Maybe it‚Äôs intentional so that people don‚Äôt run notebooks 24/7 for multiple days in a row which would probably cost too much.
5141,@rasbt,2022-04-30 23:34:02+00:00,https://twitter.com/rasbt/status/1520547054430347264,@jeremyphoward @chrisalbon @HelloPaperspace So the persistent storage was not just for the datasets but also for code and everything? Ok then that's fair and useful enough!
5142,@rasbt,2022-04-30 23:15:35+00:00,https://twitter.com/rasbt/status/1520542411528810496,"@jeremyphoward @chrisalbon @HelloPaperspace Nice! Hah, the last feature to ask about: can you change the accelerators (GPUs) of the instance? E.g., if you run something on 1 GPU and then decide to temporarily scale it up to 4 GPUs but want to scale back later to save costs (it's one of the nice features I like about Grid)."
5143,@rasbt,2022-04-30 23:12:35+00:00,https://twitter.com/rasbt/status/1520541656222781440,@randal_olson There's probably a near perfect rank correlation with the popularity of those cars though.
5144,@rasbt,2022-04-30 23:06:49+00:00,https://twitter.com/rasbt/status/1520540204150501377,"@jeremyphoward @chrisalbon @HelloPaperspace Is the storage tied to that instance though? Like if you want to switch instances (different GPUs), do you still have access to your datasets or do you have to reupload?"
5145,@rasbt,2022-04-30 22:22:36+00:00,https://twitter.com/rasbt/status/1520529075298873347,"@chrisalbon @jeremyphoward @HelloPaperspace You can train small PyTorch models pretty fast on an M1, but right, it doesn't natively support the M1 GPU(s) yet. But even if it starts supporting it, I am not sure if the cooling will be good enough to train neural nets on it. Mine can actually get pretty hot under load."
5146,@rasbt,2022-04-30 22:10:27+00:00,https://twitter.com/rasbt/status/1520526020310405121,"@chrisalbon @jeremyphoward @HelloPaperspace Another one: if you work with Google Colab, you have to either get data from a mounted Google Drive (painfully slow) or it gets deleted with the instance after so-and-so many hours. Kind of impossible to work on real problems with real datasets this way? (But maybe it changed)"
5147,@rasbt,2022-04-30 22:06:47+00:00,https://twitter.com/rasbt/status/1520525097932664832,"@chrisalbon @jeremyphoward @HelloPaperspace Google Colab doesn't support multi-GPU? (Compared to e.g., Grid or Paperspace.)"
5148,@rasbt,2022-04-30 19:49:10+00:00,https://twitter.com/rasbt/status/1520490464981495810,"@cmarschner Well, this book also includes the sentences like ""If you want to analyze data that has no structure, like tabular data in Excel sheets, then you should consider fully connected networks"" among others üôà"
5149,@rasbt,2022-04-30 19:41:05+00:00,https://twitter.com/rasbt/status/1520488428323889152,"@isskoro Haha, this is funny but also true and sad and does not really motivate me to write anything for that deadline üòÜ"
5150,@rasbt,2022-04-30 19:18:03+00:00,https://twitter.com/rasbt/status/1520482631518982145,"@tunguz @roydanroy Yeah, I really liked the style. The visuals and the soundtrack. I liked the books back then, but I mainly went to see it because it was a Villeneuve (I really liked Bladerunner 2049; not as good as the first one but they did a great job)"
5151,@rasbt,2022-04-30 19:15:01+00:00,https://twitter.com/rasbt/status/1520481869510369280,"Was just reading a book on probabilistic deep learning that had an interesting explanation of ""The big lie of deep learning."" 
Can you guess what it is?"
5152,@rasbt,2022-04-30 18:59:36+00:00,https://twitter.com/rasbt/status/1520477991586914305,@soumithchintala @anacondainc Wow nice! And the best part is that it looks like it's really easy to set up. Almost too easy to not give it a try! https://t.co/3mGxYfh6gY
5153,@rasbt,2022-04-30 18:56:26+00:00,https://twitter.com/rasbt/status/1520477193792593923,"@tunguz @roydanroy Yap, have almost given up on movie theaters because most Hollywood movies are meh these days, but I made exceptions for Dune and Batman, and they were really worth it üëå"
5154,@rasbt,2022-04-30 18:52:38+00:00,https://twitter.com/rasbt/status/1520476236048482307,"@volokuleshov Yeah, it certainly has very interesting elements!"
5155,@rasbt,2022-04-30 17:43:22+00:00,https://twitter.com/rasbt/status/1520458804982435841,"@volokuleshov Ok, it's not too bad, but it's also not too far off from existing lineart pictures plus of course the picasso blend. Something you could potentially achieve with neural style transfer. https://t.co/QwNIjNt5qp"
5156,@rasbt,2022-04-30 12:05:38+00:00,https://twitter.com/rasbt/status/1520373810305941504,@LucaAmb Nice! üëå Welcome to the dark side!
5157,@rasbt,2022-04-30 12:03:44+00:00,https://twitter.com/rasbt/status/1520373335204454402,@xamat Red flag that the related work section might be missing a lot of relevant stuff.
5158,@rasbt,2022-04-29 22:36:40+00:00,https://twitter.com/rasbt/status/1520170228432392194,"@burkov Yes, this! I think math is important for developing new techniques, but I don‚Äôt think math should get in the way when it comes to applications and everyday use cases"
5159,@rasbt,2022-04-29 22:33:28+00:00,https://twitter.com/rasbt/status/1520169422631145477,@TomQbk @bernhardsson Time would have been better spent on adding math support so that people don‚Äôt have to upload pixelated screenshots of math formulas
5160,@rasbt,2022-04-29 14:02:09+00:00,https://twitter.com/rasbt/status/1520040747193573376,@joshuastarmer Awesome! Looking forward to it! Double BAM!!
5161,@rasbt,2022-04-29 13:38:11+00:00,https://twitter.com/rasbt/status/1520034715859836929,"@rcsaxe In your case you could probably do this with hooks (https://t.co/sRuWj6HF4O); here, a backward hook though. But you are right, that's additional work."
5162,@rasbt,2022-04-29 13:35:58+00:00,https://twitter.com/rasbt/status/1520034154913619968,"@rcsaxe Ok, fair that would require a few extra steps in PyTorch since intermediate gradient values are not automatically kept."
5163,@rasbt,2022-04-29 13:18:09+00:00,https://twitter.com/rasbt/status/1520029673970884609,"@rcsaxe It's been some time, but you mean ye goode olde sessions were more convenient? ü§≠
with tf.Session(graph=g) as sess:
    https://t.co/d7bOQ7WjQd(https://t.co/7qlWeqPlfv_variables_initializer())
    ...
    ??? = https://t.co/d7bOQ7WjQd([???], 
        feed_dict={...}"
5164,@rasbt,2022-04-29 12:13:55+00:00,https://twitter.com/rasbt/status/1520013506422231041,@marktenenholtz @JFPuget @kaggle üòÜ
5165,@rasbt,2022-04-29 12:12:54+00:00,https://twitter.com/rasbt/status/1520013251068796928,@JFPuget @kaggle *That is only if you want to claim SOTA. For everything else outperforming other methods should not be a requirement for good research and publication.
5166,@rasbt,2022-04-29 12:11:02+00:00,https://twitter.com/rasbt/status/1520012782783143936,@JFPuget @kaggle Part of the publication requirement should be to compare the method across at least 3 different Kaggle competitions. Doesn‚Äôt have to win but should at least perform as well as the methods that are directly related.
5167,@rasbt,2022-04-29 12:07:04+00:00,https://twitter.com/rasbt/status/1520011782965891072,"@svpino *Autocorrect, I meant ‚Äúback‚Äù of course but ‚Äúbest‚Äù has obviously also a nice ring to it üòÇ"
5168,@rasbt,2022-04-29 11:47:55+00:00,https://twitter.com/rasbt/status/1520006963542773761,"@fgewrgd @roydanroy @tomgoldsteincs @shortstein Didn‚Äôt know, thanks! üëå Concerns for citing blogposts are solved then?"
5169,@rasbt,2022-04-29 03:23:43+00:00,https://twitter.com/rasbt/status/1519880077852479488,@yoshitomo_cs Nice I will have a look!
5170,@rasbt,2022-04-29 02:08:47+00:00,https://twitter.com/rasbt/status/1519861221121474561,@xamat I was going to make a joke that you were lucky that they didn‚Äôt charge you for writing a book for them üòÜ. but this whole thing sounds just too frustrating üòû
5171,@rasbt,2022-04-29 01:40:07+00:00,https://twitter.com/rasbt/status/1519854005471649792,"@svpino I had a bumpy start, but looks like I am best in business ü¶æ https://t.co/OoSTJJfNx3"
5172,@rasbt,2022-04-28 23:15:38+00:00,https://twitter.com/rasbt/status/1519817648183418880,@roydanroy @tomgoldsteincs @shortstein That's fair. It would be nice to manually trigger it somehow when you cite an article.
5173,@rasbt,2022-04-28 23:09:03+00:00,https://twitter.com/rasbt/status/1519815988354691073,@tomgoldsteincs Many of my cited articles are also blog posts. I am very proud of those üòÖ. Item 3 &amp; 5 are also blog posts that I later submitted to arxiv. https://t.co/GvwZPR3w33
5174,@rasbt,2022-04-28 23:07:25+00:00,https://twitter.com/rasbt/status/1519815577530994691,"@shortstein @tomgoldsteincs Many arxiv papers are also not peer reviewed at the point in time when they are cited. If you as the author can make a judgement call that they look good to you, it's fine."
5175,@rasbt,2022-04-28 23:04:53+00:00,https://twitter.com/rasbt/status/1519814942337216512,"@roydanroy @tomgoldsteincs @shortstein If they disappear, there is the Internet Archive https://t.co/Bb2f3zxhJp?"
5176,@rasbt,2022-04-28 18:24:40+00:00,https://twitter.com/rasbt/status/1519744424716251137,"@deliprao @jcg9129 Yeah, I was thinking exactly the same thing! üòÜ"
5177,@rasbt,2022-04-28 16:02:32+00:00,https://twitter.com/rasbt/status/1519708652818644993,"@__mharrison__ I love VS Code, but I should probably give Effective PyCharm a read!"
5178,@rasbt,2022-04-28 15:44:26+00:00,https://twitter.com/rasbt/status/1519704096890044418,"@AllenDowney Wow, that's a big accomplishment üôåü•≥! Excited to hear what you are up to next!"
5179,@rasbt,2022-04-28 15:30:54+00:00,https://twitter.com/rasbt/status/1519700692490989569,"@PyTorchLightnin The docs are now a guided tour of 27 levels, ranging from ""Training a model"" to advanced topics like 
""Scaling to 1 trillion parameters on GPUs"" or 
""Adding a new custom hardware accelerator"" https://t.co/DbGuSLvhV8"
5180,@rasbt,2022-04-28 15:22:31+00:00,https://twitter.com/rasbt/status/1519698581850050560,"Very excited about our big doc update at @PyTorchLightnin that just went live: https://t.co/O2WPwRypKM!
Our new Level-Up guide disentangles the docs and provides a clear path for your learning journey, teaching you the main concepts one step, ehm, ""level"" at a time!"
5181,@rasbt,2022-04-28 15:11:38+00:00,https://twitter.com/rasbt/status/1519695845083525120,"@jcg9129 Ok, I just see one disadvantage of surgeon-pytyorch. It can't run if the network itself doesn't work due to dimension incompatibilities. It makes it less attractive for debugging. https://t.co/Mzl5Fr3yTX"
5182,@rasbt,2022-04-28 14:15:24+00:00,https://twitter.com/rasbt/status/1519681693686415361,"@jcg9129 Huh, nice! I didn't know about this one. Looks like it allows you to achieve the same thing! https://t.co/7M4MAzmxQt"
5183,@rasbt,2022-04-28 13:52:44+00:00,https://twitter.com/rasbt/status/1519675989198057472,"@ZainulA40877140 @peterhoffmann That being said, I think Julia is a great language. Just not for deep learning. A lot of my colleagues use Julia for statistical modeling, and it's great."
5184,@rasbt,2022-04-28 13:51:16+00:00,https://twitter.com/rasbt/status/1519675618568327168,"@ZainulA40877140 @peterhoffmann 2/2 Python also doesn't have performance issues for deep learning. If you compare the PyTorch Python API to the equivalent C++ API, the overhead from Python is just 10%. That's good enough for research, and you can always export to C++ for deployment."
5185,@rasbt,2022-04-28 13:50:12+00:00,https://twitter.com/rasbt/status/1519675349516361728,@ZainulA40877140 @peterhoffmann For deep learning Python is here to stay in the foreseeable future though. It's kind of near impossible to  work on state-of-the-art deep learning with Julia right now. 1/2
5186,@rasbt,2022-04-28 13:44:50+00:00,https://twitter.com/rasbt/status/1519673999818690561,Tired of adding forward hooks or print statements to look into intermediate layer outputs of your PyTorch models? Surgeon-pytorch (https://t.co/fPRZqloQLs) allows you to inspect the intermediate output layers of PyTorch models without changing the original implementation. https://t.co/RG5FVlcwU2
5187,@rasbt,2022-04-27 20:26:48+00:00,https://twitter.com/rasbt/status/1519412770919309314,Write a fully-fledged Python library using Jupyter Notebook with this one weird trick. MLOps engineers hate him. üòÜ
5188,@rasbt,2022-04-27 18:23:13+00:00,https://twitter.com/rasbt/status/1519381668620087298,@peterhoffmann Wohoo! Hope you have fun! üëê
5189,@rasbt,2022-04-27 14:06:16+00:00,https://twitter.com/rasbt/status/1519317004242542595,"Interesting work on making the stride parameter of convolutional layers learnable. No, it doesn't require discrete optimization as in conventional NAS but is based on gradient descent. Code curently only for TF, but should be portable to PyTorch. https://t.co/QtRrY4KpSZ https://t.co/5wFOtTPpn9"
5190,@rasbt,2022-04-27 13:54:40+00:00,https://twitter.com/rasbt/status/1519314087812947970,@Centropy3 The first one would be more of a confidence interval of the average k-fold performance. The second would be kind of like the confidence interval of the average average k-fold performance.
5191,@rasbt,2022-04-27 13:53:27+00:00,https://twitter.com/rasbt/status/1519313780622118914,@Centropy3 There are 2 different ways you can do that. Let's say you have r repetitions for k-fold cv. You could apply the quantile (/percentiles) to the r*k pooled runs for the average k-fold performance. Or you could average over the k folds and collect the r averages for the quantiles
5192,@rasbt,2022-04-27 13:30:47+00:00,https://twitter.com/rasbt/status/1519308077379502081,@vandotorres @unrahu1 That's a good question. We can look into the possibility of live streaming some portions of the event. Stay tuned!
5193,@rasbt,2022-04-26 21:53:19+00:00,https://twitter.com/rasbt/status/1519072156415672321,"@adnancagri @PyTorch @PyTorchLightnin 4/4 Really want to emphasize the first point again, you can feed in your original PyTorch models, and you can also get them out of PyTorch Lightning later if you want. I have some examples in my https://t.co/armA3X7hOt repo, e.g., https://t.co/6vqyEVXu3g to illustrate that better"
5194,@rasbt,2022-04-26 21:53:00+00:00,https://twitter.com/rasbt/status/1519072076493168641,"@adnancagri @PyTorch @PyTorchLightnin 3/4 ... there are nice goodies that come with it. For example, it is super easy to add things like ""save the model from the epoch with the highest validation performance"" or ""scale this code to x (or all) GPUs on that machine"""
5195,@rasbt,2022-04-26 21:52:42+00:00,https://twitter.com/rasbt/status/1519071999863275526,"@adnancagri @PyTorch @PyTorchLightnin 2/4 Have been using @PyTorchLightnin since January &amp; can highly recommend it. Previously, I was reinventing the wheel myself for each project, and that was very confusing for people I collaborated with. PT Lighting makes things a) more consistent &amp; organized, and b)  ..."
5196,@rasbt,2022-04-26 21:52:07+00:00,https://twitter.com/rasbt/status/1519071854484406273,"@adnancagri @PyTorch @PyTorchLightnin Good question! Not sure if we should call it ""switching"" as it sits on top of PyTorch. It's more like ""would you recommend to *adopt* PyTorch Lightning"" instead of hacking together everything from scratch every time you use PyTorch üòÖ. 1/4"
5197,@rasbt,2022-04-26 21:24:45+00:00,https://twitter.com/rasbt/status/1519064964681670656,"We are very excited to host our very first Lightning Developer Conference on June 16th! Hope you can join us!!
It's going to be jam-packed with lots of interesting things including some (very) exciting announcements and workshops around deep learning and AI!"
5198,@rasbt,2022-04-26 15:25:29+00:00,https://twitter.com/rasbt/status/1518974551941595137,"@pietro_lesci You could create e.g., 200 bootstrap samples from each random seed model and then construct the confidence intervals from the 1000 - 2000 bootstrap samples. Not sure how well it works (how accurate it is) in practice though."
5199,@rasbt,2022-04-26 15:12:27+00:00,https://twitter.com/rasbt/status/1518971273338142720,"@GaelVaroquaux Oh yeah, that sounds tricky. Haven't tried that in simulation studies, but a spontaneous thought: e.g., to incorporate random seeds, run 500 bootstrap rounds, 100 with a different random seed each? Same for hyperparams. (But that's probably getting computationally intractable.)"
5200,@rasbt,2022-04-26 14:39:49+00:00,https://twitter.com/rasbt/status/1518963059955544069,"@vandotorres Sounds reasonable, you can give it a try."
5201,@rasbt,2022-04-26 14:39:08+00:00,https://twitter.com/rasbt/status/1518962889872314369,@Centropy3 How do you construct the CI from that though? With a t interval and n=number of repititions? Yeah that might work for getting a CI of the average k-fold performance. But is it what you want?
5202,@rasbt,2022-04-26 14:34:12+00:00,https://twitter.com/rasbt/status/1518961648651935744,"@GaelVaroquaux The original sentence: ""For instance, in the aforementioned *Accounting for variance in machine learning benchmarks study*, the researchers found that randomizing as many sources of variation as possible can help reduce the estimation error."""
5203,@rasbt,2022-04-26 14:24:31+00:00,https://twitter.com/rasbt/status/1518959212159713280,@sharma_abhishek I think all methods except maybe method 1 don't really depend on accuracy specifically. But even method 1 might work ok. You could give it a try running the simulation study here: https://t.co/TzImfhy1cB  I would maybe change repetitions from 1000 to 100 to make it go faster ;).
5204,@rasbt,2022-04-26 14:23:06+00:00,https://twitter.com/rasbt/status/1518958856503808001,@barisak100 I would maybe just give it a try. You could run the simulation study here: https://t.co/TzImfhy1cB with F1 and an unbalanced dataset. I would maybe change repetitions from 1000 to 100 otherwise it might take half a day.
5205,@rasbt,2022-04-26 14:20:54+00:00,https://twitter.com/rasbt/status/1518958299252731908,@barisak100 Hm yeah tricky. I would say that F1 is also based on the 0/1 loss and also a proportion (similar to Accuracy) but method 1 is probably not technically sound then. The other methods should still apply though.
5206,@rasbt,2022-04-26 14:15:31+00:00,https://twitter.com/rasbt/status/1518956945520173056,"@GaelVaroquaux Ah yes, I had mentioned that in the conclusion and referenced your article! (Btw. regarding random seed, that's basically method 4 in that article, but since it is not a deep learning method, it's not very interesting.)"
5207,@rasbt,2022-04-26 13:11:59+00:00,https://twitter.com/rasbt/status/1518940957722427399,"@sina96nv @Haz09714143 Interesting question. I don't think I would write a book about confidence intervals in the near future because I now already covered it in the blog post, so if you are interested in reading about it, I wouldn't wait for a book about it üòÖ"
5208,@rasbt,2022-04-26 03:17:24+00:00,https://twitter.com/rasbt/status/1518791327026143232,"@radekosmulski @NVIDIAAI @fastdotai @kaggle Wow so awesome! Big congrats! üéâ. I remember part of your journey from your book, and this is so well deserved! üëè"
5209,@rasbt,2022-04-26 00:02:59+00:00,https://twitter.com/rasbt/status/1518742398733590530,"I forgot to mention for those interested in confidence intervals around the model weights, that's a bit trickier in general -- some models don't have weights, and some have too many üôÉ. But I wrote about how to do it for linear and logistic regression here https://t.co/uKgb66tbmX"
5210,@rasbt,2022-04-25 21:54:27+00:00,https://twitter.com/rasbt/status/1518710051669778432,@yoavgo @togelius Yeah of course not. But just for the sake of improving transparency
5211,@rasbt,2022-04-25 21:29:05+00:00,https://twitter.com/rasbt/status/1518703670640234496,@yoavgo @togelius On the flip side there are proposed plans regarding open sourcing the timeline algo etc which doesn‚Äôt sound too bad ü§î
5212,@rasbt,2022-04-25 18:32:19+00:00,https://twitter.com/rasbt/status/1518659182903369728,"@Haz09714143 Ah no, this was out of scope for the book üòÖ"
5213,@rasbt,2022-04-25 16:17:38+00:00,https://twitter.com/rasbt/status/1518625290632761344,"@vandotorres 2/2 (1) for interpretability, you can describe which original features the model uses, and (2) if you want to reduce the number of features further after PCA, you could do that based on an eigenvalue cut-off."
5214,@rasbt,2022-04-25 16:17:31+00:00,https://twitter.com/rasbt/status/1518625260886704129,"@vandotorres I don't think there is any formal way to you can say one is better than the other. However, I would say that in most practical scenarios, doing feature selection before PCA makes more sense, because 1/2"
5215,@rasbt,2022-04-25 15:53:09+00:00,https://twitter.com/rasbt/status/1518619128713687040,@KyleCranmer 2/2 then let the recommended practices evolve in upcoming years via workshops.
5216,@rasbt,2022-04-25 15:52:55+00:00,https://twitter.com/rasbt/status/1518619070572244993,"@KyleCranmer I agree, these could be decoupled. In general, I think it is really hard to establish standards (unless mandated by the publisher or conference organizers). I would start with a recommendation to include a detailed description of how failure cases were handled, and 1/2"
5217,@rasbt,2022-04-25 15:36:03+00:00,https://twitter.com/rasbt/status/1518614825353555973,"@KyleCranmer Also reminds me of one of my very very first blog posts on ""Dixon's Q test for outlier identification"" üòÖ  https://t.co/dOsw898YoU"
5218,@rasbt,2022-04-25 15:27:09+00:00,https://twitter.com/rasbt/status/1518612584479477764,@KyleCranmer Yeah great point! I mentioned the failed runs in the conclusion somewhere. How to deal with it? It's kind of subjective. Include all of them to highlight how brittle the method is? Remove all failures? Pick top 5 out of 10 runs? I think it depends on what you want to show.
5219,@rasbt,2022-04-25 15:16:42+00:00,https://twitter.com/rasbt/status/1518609957729546240,"Ever wondered how to add confidence intervals to quantify the uncertainty of your machine learning models' performance estimates? 
I just put together a hands-on comparison here: https://t.co/CWcHmjqg0w"
5220,@rasbt,2022-04-25 15:16:11+00:00,https://twitter.com/rasbt/status/1518609824224878593,"@jovoguzvic Good question! Personally, I used TensorFlow and Keras many years ago and switched to PyTorch in ~2018. I wrote down some of my thoughts here https://t.co/F4cHj7qJeJ. Also chatted about it recently on the How AI happens podcast (around min 24:20) https://t.co/q0xYPeebx9"
5221,@rasbt,2022-04-25 14:59:04+00:00,https://twitter.com/rasbt/status/1518605519229009920,"Wohoo, my fav YouTube channel meets my favorite DL library! ü•∞"
5222,@rasbt,2022-04-24 21:21:07+00:00,https://twitter.com/rasbt/status/1518339275242229760,"@irfnali1 @psteinb_ Yap, big fan of bootstrapping, and this paper is mentioned in the article I am currently putting together ‚ò∫Ô∏è. Near finished, will probably post tomorrow morning."
5223,@rasbt,2022-04-24 17:19:43+00:00,https://twitter.com/rasbt/status/1518278527522643974,"@emurrelldev Imho, people are trying very hard to turn Web3 into a self-fulfilling prophecy."
5224,@rasbt,2022-04-24 17:09:58+00:00,https://twitter.com/rasbt/status/1518276072932098049,"@ehudkar @unsorsodicorda @psteinb_ yes, the more precise definition is that the distributions of the residuals are normal"
5225,@rasbt,2022-04-24 16:50:02+00:00,https://twitter.com/rasbt/status/1518271055105769472,@GaryMarcus https://t.co/hdqX3iD9a9
5226,@rasbt,2022-04-24 16:36:30+00:00,https://twitter.com/rasbt/status/1518267649742024705,"@tpsmith @basedvoid @karpathy @SahilBloom Yeah, honestly if there is a üßµsymbol in a tweet or an ""1/n"" thread with n &gt; 5, I won't read it."
5227,@rasbt,2022-04-24 16:21:28+00:00,https://twitter.com/rasbt/status/1518263867717074944,@tpsmith @basedvoid @karpathy Like Twitter threads replaced blog posts üòú
5228,@rasbt,2022-04-24 14:00:31+00:00,https://twitter.com/rasbt/status/1518228394537803776,"@ajboateng @karpathy Ah, right, I am learning this now! Have spent too much time on alternative search engines and have to up my Google game. (PS: would still be nice to integrate this into YouTube directly)"
5229,@rasbt,2022-04-24 13:54:11+00:00,https://twitter.com/rasbt/status/1518226801222422530,"@anthonygitter @Bekry_md @IAkhil3 @karpathy Huh, that works! üëå"
5230,@rasbt,2022-04-24 13:51:49+00:00,https://twitter.com/rasbt/status/1518226205639684097,"@chrisoffner3d @IAkhil3 @karpathy Ok fair! Now, it would be nice if there was a search function in YouTube that would do this more effectively and show me a page just with these clip results :)"
5231,@rasbt,2022-04-24 13:38:25+00:00,https://twitter.com/rasbt/status/1518222833503158273,@Bekry_md @IAkhil3 @karpathy How do I do this though? In my case it just shows the full videos? https://t.co/bJeOHqRLz8
5232,@rasbt,2022-04-24 13:37:00+00:00,https://twitter.com/rasbt/status/1518222475703853057,"@IAkhil3 @karpathy I think it just finds the full videos, not clips within a video? Unless I am doing it wrong."
5233,@rasbt,2022-04-24 13:24:23+00:00,https://twitter.com/rasbt/status/1518219300854718464,"@karpathy YouTube really needs to add better search capabilities to display clips based on relevant search results. Searching for ""how to do a double iteration with a list comprehension in Python""? Show me the relevant 30 sec clip, not a whole Python programming lecture."
5234,@rasbt,2022-04-24 13:21:48+00:00,https://twitter.com/rasbt/status/1518218650934730756,"@kiruba_selvi6 @psteinb_ 3) How to manage: For me, I only write if I like the topic and I am in the mood mostly. Blogging is mostly a hobby so I don't want to overthink it to make it become (too much) work. I do like staying organized though, which is why I always start with an outline."
5235,@rasbt,2022-04-24 13:19:18+00:00,https://twitter.com/rasbt/status/1518218024913973248,"@kiruba_selvi6 @psteinb_ 2) Research: I usually don't do any upfront research. Usually, there is something I write about because I find it interesting, so I come up with the topic first and start outlining. But then I often find things here and there that I want to look up to go in deeper."
5236,@rasbt,2022-04-24 13:17:16+00:00,https://twitter.com/rasbt/status/1518217509551456258,"@kiruba_selvi6 @psteinb_ Oh very good question, but hard to answer! 1) Time: I usually don't track the time, but it is mostly 1 or 2 weekends. Maybe 5-10 hours. Really depends on the topic though üòÖ"
5237,@rasbt,2022-04-24 13:14:58+00:00,https://twitter.com/rasbt/status/1518216931253407744,"@elece___ @unsorsodicorda @psteinb_ Unfortunately, no. When I tried to learn about all these things back then, I had to pull it together from various articles scattered all over the place. Wanted to write a book about that but then I opted for a series of blog posts."
5238,@rasbt,2022-04-24 13:13:29+00:00,https://twitter.com/rasbt/status/1518216558342025218,"@amazingguo @akshay_iyerr Hah, sounds all too familiar. Need to save this as a template :P"
5239,@rasbt,2022-04-24 13:06:40+00:00,https://twitter.com/rasbt/status/1518214844398325760,"@jeremyphoward @xkcd Hah, that's hilarious! I was just putting together some slides for teaching the other day and was thinking about exactly this! ü§ó https://t.co/vmGiK0ZhBm"
5240,@rasbt,2022-04-24 12:27:46+00:00,https://twitter.com/rasbt/status/1518205053965897730,@RDub2 @psteinb_ Right that is not the case.
5241,@rasbt,2022-04-23 19:27:16+00:00,https://twitter.com/rasbt/status/1517948235242950659,"@BlindDou @psteinb_ Haha ok, I have to check later ... I kind of abandoned email lately in order to get things done üòÖ"
5242,@rasbt,2022-04-23 19:26:28+00:00,https://twitter.com/rasbt/status/1517948037653581825,@nagaraj_arvind @jeremyphoward @fastdotai @GuggerSylvain @MDPIOpenAccess I think there is a subtle distinction between pre-training on labeled data in the sense of classic transfer learning and the more modern paradigms where you pre-train with self-supervised learning. I think the latter is also relatively recent in CV (~max 5-7 years ago?).
5243,@rasbt,2022-04-23 19:22:46+00:00,https://twitter.com/rasbt/status/1517947102772486146,"@unsorsodicorda @psteinb_ @iclr_conf Thanks for the invite! I am quite busy next week and not attending. But happy to chat some time in general (maybe later this year). I would need to get into instance segmentation again though, currently I would really lack the recent domain knowledge in that areaüòÖ"
5244,@rasbt,2022-04-23 19:20:37+00:00,https://twitter.com/rasbt/status/1517946562499989511,@RDub2 @psteinb_ Then add variances or standard deviations?
5245,@rasbt,2022-04-23 19:18:10+00:00,https://twitter.com/rasbt/status/1517945947229147136,@amazingguo @moreisdifferent That's a very good point. There is only a very small incentive: putting it on your CV for the annual departmental review in academia. A very small incentive though.
5246,@rasbt,2022-04-23 18:27:29+00:00,https://twitter.com/rasbt/status/1517933193114136579,"@sudharsankp @vandotorres @psteinb_ ""Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning"" ü§ó https://t.co/aYvW168wLF"
5247,@rasbt,2022-04-23 18:26:27+00:00,https://twitter.com/rasbt/status/1517932930282180608,"@unsorsodicorda @psteinb_ ""testing whether models have the same performance are different kinds is relevant to the topic of the workshop "" --&gt; absolutely! 100% agree. Was just saying that this is much more tricky. We want to work towards it, but yeah I think we should slowly start with UQ which is simpler"
5248,@rasbt,2022-04-23 18:24:56+00:00,https://twitter.com/rasbt/status/1517932549921808385,"@unsorsodicorda @psteinb_ You are right, this is somewhat similar to ANOVA. Cochran's Q is a non-parametric test, ANOVA assumes that the data is normally distributed"
5249,@rasbt,2022-04-23 18:23:19+00:00,https://twitter.com/rasbt/status/1517932142109540355,"@unsorsodicorda @psteinb_ Sure, I implemented it here: 
Cochran's Q test -- https://t.co/oU827NkJhr
McNemar's test: https://t.co/2GvTHlKh1i

Disclaimer: this is for classification. Haven't thought about comparing instance segmentation methods."
5250,@rasbt,2022-04-23 17:11:38+00:00,https://twitter.com/rasbt/status/1517914104853315585,@sina96nv @psteinb_ Wow thanks for the kind words ü•∞
5251,@rasbt,2022-04-23 17:09:57+00:00,https://twitter.com/rasbt/status/1517913679156719617,"@unsorsodicorda @psteinb_ To answer the question, we can use an omnibus test like Cochran's Q followed by corrected post-hoc (e.g. McNemar's) tests. But to be honest, I think that adding uncertainty estimates to the results vs testing whether models have the same performance are different kinds of beasts"
5252,@rasbt,2022-04-23 17:07:44+00:00,https://twitter.com/rasbt/status/1517913123914715141,"@unsorsodicorda @psteinb_ Yeah, we can't really use individual CI's for a pairwise comparisons. We can say that the diff of two measurements is statistically significant if CI's don't overlap. However we cannot say that results are not statistically significant if CI's do overlap. https://t.co/8N64lD7za9"
5253,@rasbt,2022-04-23 16:09:35+00:00,https://twitter.com/rasbt/status/1517898488381677568,"Currently writing the blog article I always wanted to write ‚úçÔ∏è! Stay tuned for Monday (assuming experiments  finish in time!). In the meantime, check out @psteinb_  et al's excellent article on confidence intervals as min standard for presenting ML results https://t.co/pgW6ILD7JW https://t.co/k9HAGTemt5"
5254,@rasbt,2022-04-23 13:55:05+00:00,https://twitter.com/rasbt/status/1517864642311303169,"@TaliaRinger Whohoo, awesome! Congrats üéäüéàüéâ"
5255,@rasbt,2022-04-23 13:50:40+00:00,https://twitter.com/rasbt/status/1517863528622956557,@mathsppblog I really feel the urge to write this cool blog article if have in my head this weekend ‚úçÔ∏è. It involves lots of Python code üêç‚ù§Ô∏è
5256,@rasbt,2022-04-23 01:10:36+00:00,https://twitter.com/rasbt/status/1517672250228494336,@HEPfeickert @WKCosmo Wohoo! This looks like a fun weekend ahead üòä
5257,@rasbt,2022-04-23 00:03:44+00:00,https://twitter.com/rasbt/status/1517655424622895104,@randal_olson Nice! I recently got a copy as well! Have fun!
5258,@rasbt,2022-04-22 23:42:37+00:00,https://twitter.com/rasbt/status/1517650109814747137,@xamat 10 papers!? This is insane! üòü Good luck! üòÖ
5259,@rasbt,2022-04-22 21:48:40+00:00,https://twitter.com/rasbt/status/1517621433593180160,"@jeremyphoward @fastdotai @GuggerSylvain @MDPIOpenAccess Wow, really awesome news ü•≥! I am really glad to hear that it was so well received! And it was my pleasure, I am always happy to support open source efforts!"
5260,@rasbt,2022-04-22 19:54:47+00:00,https://twitter.com/rasbt/status/1517592773381312514,@__jeremylane__ @BlackHC @Gillesvdwiele 100% on four!!! datasets
5261,@rasbt,2022-04-22 19:52:27+00:00,https://twitter.com/rasbt/status/1517592188674351106,"@m_usmanrafique Btw fwiw my response was ""This does not really answer my question."" ü§∑‚Äç‚ôÇÔ∏è Haha, all very strange."
5262,@rasbt,2022-04-22 19:39:43+00:00,https://twitter.com/rasbt/status/1517588980354666498,"I should maybe add a disclaimer that this is fake research. If you flip the labels in the test set and still get 100% test accuracy, it tells you there's something very fishy going on (since training labels don't correspond to test labels anymore)."
5263,@rasbt,2022-04-22 19:25:48+00:00,https://twitter.com/rasbt/status/1517585481105555457,"@m_usmanrafique Honestly, I think the authors are just trolling. No way they are serious. It all looks like a belated April Fool's joke. https://t.co/e7x3MCuNsR"
5264,@rasbt,2022-04-22 15:43:35+00:00,https://twitter.com/rasbt/status/1517529556118380544,@paul_rietschka @tunguz I thought we already have at least a handful of those ü§îü§∑‚Äç‚ôÇÔ∏è
5265,@rasbt,2022-04-22 15:31:18+00:00,https://twitter.com/rasbt/status/1517526466803679234,"@__mharrison__ @tunguz 2/2 Each time, I trained the model on the training data (using the originally best config) and evaluated it on the test set. It was a small real-world dataset that was very noisy, and I think the HGB overfit to the training set (despite k-fold cv)"
5266,@rasbt,2022-04-22 15:29:39+00:00,https://twitter.com/rasbt/status/1517526051395706880,"@__mharrison__ @tunguz Haha fair, I was way too brief. I tuned an HGB model via 5-fold cross-validation on the training set and then evaluated it on the test set (repetition 0). Then, I saved the best hyperparam configuration, pooled the train+test sets, and created new train/test splits. 1/2"
5267,@rasbt,2022-04-22 15:21:08+00:00,https://twitter.com/rasbt/status/1517523909637201920,"@tunguz Left-hand side HGB, right-hand side RF: https://t.co/S3he3ScmxS"
5268,@rasbt,2022-04-22 15:17:05+00:00,https://twitter.com/rasbt/status/1517522887170789376,@tunguz @vamsikrrish https://t.co/Im7mM1tEtL
5269,@rasbt,2022-04-22 15:15:54+00:00,https://twitter.com/rasbt/status/1517522589777805315,"@tunguz Maybe at the expense of LightGBM or HistGradientBoosting (because they are relatively similar), I would add Random Forest to the list. Good out-of-the-box performance, even it if is just as a baseline for tuning 1, 2, 4, 5, 6"
5270,@rasbt,2022-04-22 14:15:34+00:00,https://twitter.com/rasbt/status/1517507406665850880,"Had a fun time chatting with @robstertweets on ""How AI Happens""! ML in academia vs industry, when to use ML vs DL, and yes, TensorFlow vs PyTorch ... we got it all covered üôÉ 
üçèhttps://t.co/STCBcPGgmK
üéôÔ∏èhttps://t.co/UxkbLBDVX1"
5271,@rasbt,2022-04-22 01:33:04+00:00,https://twitter.com/rasbt/status/1517315516783857664,@BlackHC @Gillesvdwiele There does seem to be a deep rabbit hole that one can go down to (https://t.co/RYp237UWom): https://t.co/ebx4PiDTDW
5272,@rasbt,2022-04-22 01:30:21+00:00,https://twitter.com/rasbt/status/1517314832852262914,"@BlackHC @Gillesvdwiele Take this with the responses on Gh &amp; reddit, it seems that the authors are just trolling. I think it's okay for April 1st joke but I honestly think it's not cool just to publish papers like this and waste everyone's time."
5273,@rasbt,2022-04-22 01:29:43+00:00,https://twitter.com/rasbt/status/1517314675737870338,@BlackHC @Gillesvdwiele It is a bit negligent though. One could have ran a simple test like shuffling the labels or just simply swapping out two categories in the test set. I did the latter (1 -&gt; 6; 6 -&gt; 1) and still got 100% test accuracy. I feel like there are 1000 ways the authors could have checked.
5274,@rasbt,2022-04-21 18:19:33+00:00,https://twitter.com/rasbt/status/1517206421548457984,"@Gillesvdwiele haha, imho this sort of behavior should only be allowed on April 1st üôÑ"
5275,@rasbt,2022-04-21 18:16:10+00:00,https://twitter.com/rasbt/status/1517205566686384130,"@unsorsodicorda @tdietterich @stanislavfort @stats_stephen @lihua_lei_stat Thanks, bookmarked! Wow, there is so much cool literature out there on that topic, and it makes me feel totally ignorant üòÖ. Have to catch up with it some time!"
5276,@rasbt,2022-04-21 18:14:05+00:00,https://twitter.com/rasbt/status/1517205043535302656,"@Gillesvdwiele I am baffled that the authors don't realize the problem. It is simple to check with a control experiment. Actually ran their code flipping labels in the test set (leaving the training set as it) &amp; still got 100% test acc, which is impossible unless you have bug or data leakage"
5277,@rasbt,2022-04-21 18:10:33+00:00,https://twitter.com/rasbt/status/1517204153587712000,@Gillesvdwiele DL Researchers Hate Him! How He Got 100% Test Accuracy With This One Weird Trick
5278,@rasbt,2022-04-21 15:12:02+00:00,https://twitter.com/rasbt/status/1517159228854652929,@unsorsodicorda @tdietterich Thanks for the pointer (ah but somehow the link doesn't work for me)! Btw it was this one: https://t.co/E5siNhwiVH
5279,@rasbt,2022-04-21 15:10:11+00:00,https://twitter.com/rasbt/status/1517158763853144064,"I am actually really enjoying @svpino's daily ML challenges. Hah, finally an easy one to boost my percentage. 
(Btw as someone who dreads making exams, I can ensure you that making questions is harder than taking them, and @svpino does a really great job making them educational.)"
5280,@rasbt,2022-04-21 15:03:36+00:00,https://twitter.com/rasbt/status/1517157105777758209,@svpino Wohoo! ü•≥ https://t.co/JtWWqTwFf9
5281,@rasbt,2022-04-21 14:24:41+00:00,https://twitter.com/rasbt/status/1517147313264685056,"Since we had this really good discussion on out-of-distribution (OOD) detection here on twitter last week, there is a really timely &amp; good thread (and approach) on the related task of open set recognition üëá"
5282,@rasbt,2022-04-21 14:19:54+00:00,https://twitter.com/rasbt/status/1517146110699065344,"@richardtomsett @osprangers This should be impossible. If you only flip test set labels, not the training set labels, and then still get 100% test accuracy, you know that there's something that's not right. I.e., possibly a data leak."
5283,@rasbt,2022-04-21 14:17:41+00:00,https://twitter.com/rasbt/status/1517145552055533571,"@richardtomsett @osprangers Huh, that's very fishy behavior on their part then. Actually, I am very sure there is a data leak. I just downloaded their notebook and ran it on MNIST (using https://t.co/HuhWX17eDR) and got 100% accuracy. Then, in the test set I relabeled 1-&gt;6 &amp; 6-&gt;1. Still 100% test accuracy https://t.co/J4IdPmdLFl"
5284,@rasbt,2022-04-21 01:43:14+00:00,https://twitter.com/rasbt/status/1516955689486327808,"Part of my daily routine is to learn sth new every day! Thx @PatrickKidger for making this inevitable today by explaining ""signatures"" to me -- those little pathwise solutions to SDEs that you might encounter when toying around with Jax &amp; those Haskell-like type signatures üëá"
5285,@rasbt,2022-04-21 00:34:26+00:00,https://twitter.com/rasbt/status/1516938375059709954,"@jfmontgar Let me delegate this question to @PatrickKidger, who can probably put it very nicely &amp; precisely within 240 chars üòÖ"
5286,@rasbt,2022-04-20 19:27:53+00:00,https://twitter.com/rasbt/status/1516861228404068356,@Wraf2003 there is a good explanation at the bottom of the linked thread :)
5287,@rasbt,2022-04-20 18:38:28+00:00,https://twitter.com/rasbt/status/1516848791441358852,Apparently they have some data leakage that could explain this: https://t.co/cvDzMtaaLc https://t.co/gKu75E8xXa
5288,@rasbt,2022-04-20 17:40:08+00:00,https://twitter.com/rasbt/status/1516834110987448323,@jmschreiber91 @NumFOCUS @PyTorch I am open to using anything that doesn't involve Bayesian stats
5289,@rasbt,2022-04-20 17:37:03+00:00,https://twitter.com/rasbt/status/1516833338316963840,"""Learning with Signatures"" (https://t.co/VsE3q37TWf) 
Whoa, they achieve 100% test accuracy on MNIST and CIFAR-10 ü§Ø. 
Impressive or rather suspicious given that MNIST has mislabeled examples (https://t.co/ofWFXRcZip) -- and the same is probably true for CIFAR-10 ü§î? https://t.co/6jqybzYvXu"
5290,@rasbt,2022-04-20 16:53:34+00:00,https://twitter.com/rasbt/status/1516822394735931399,"@tryolabs @gridai_ @_willfalcon @PyTorchLightnin @maiabrenner @dekked_ Wohoo, that was fun! Always a pleasure hanging out with the @tryolabs team! üòä"
5291,@rasbt,2022-04-20 14:08:52+00:00,https://twitter.com/rasbt/status/1516780944237252617,"@y0b1byte Another really good one is RL for designing molecules (e.g., in a drug discovery context). Here is one randomly picked, recent paper on this: https://t.co/FRG3evP8py https://t.co/GIFTkZEFOi"
5292,@rasbt,2022-04-20 03:59:22+00:00,https://twitter.com/rasbt/status/1516627560892973058,@jmschreiber91 @NumFOCUS @PyTorch For real? That‚Äôs super exciting actually! Wohoo üéâ
5293,@rasbt,2022-04-20 03:56:34+00:00,https://twitter.com/rasbt/status/1516626856749019146,"@svpino You do a great job actually. And yes, it‚Äôs hard. Especially if you want to create learning experiences and not ‚Äúgotcha‚Äù questions. (For me, making exams is one of the hardest things about teaching; I always tell my students that making the exam is harder than taking it.)"
5294,@rasbt,2022-04-20 00:17:20+00:00,https://twitter.com/rasbt/status/1516571682068213766,"@bhutanisanyam1 @kaggle Wow, that's super cool! Haha, one more reason making me want to become more active on Kaggle! Btw. I still wear a jacket Quora sent me years ago. It's basically my favorite running jacket now! https://t.co/pyA2FKURIJ"
5295,@rasbt,2022-04-19 21:31:11+00:00,https://twitter.com/rasbt/status/1516529868686696458,"8/8 The dataset pruning reminds me of a couple of papers I saw on cleaning up ImageNet last year. E.g., this can be automated as shown in ""Automated Cleanup of the ImageNet Dataset by Model Consensus, Explainability and Confident Learning"" (https://t.co/gOQf2RLLKn) https://t.co/pvJ0umKrb8"
5296,@rasbt,2022-04-19 21:31:10+00:00,https://twitter.com/rasbt/status/1516529865838710792,"6/ Here is a ranking of different methods (without confidence intervals üòñ). Looks like next to meta-learning, ye goode olde data set pruning (removing noisy examples) is the way? https://t.co/8lSIjf5kRg"
5297,@rasbt,2022-04-19 21:31:10+00:00,https://twitter.com/rasbt/status/1516529864412704775,"5/ Noise model-free methods design models that are robust to noise (e.g., via loss functions, regularization, meta-learning, model ensembles etc.)"
5298,@rasbt,2022-04-19 21:31:09+00:00,https://twitter.com/rasbt/status/1516529863133442062,"4/ Regarding noise model-based methods: they estimate the noise structure and use this info in some sense. E.g., omitting or de-emphasize noisy examples, correcting noisy labels, etc. An advantage here is that it decouples the classification algo and noise method"
5299,@rasbt,2022-04-19 21:31:09+00:00,https://twitter.com/rasbt/status/1516529861665464321,3/ The survey I linked above groups the existing methodologies into 2 broad categories: noise model-based and noise model-free methods. It's a pretty comprehensive list! https://t.co/AkfroLWsEU
5300,@rasbt,2022-04-19 21:31:09+00:00,https://twitter.com/rasbt/status/1516529860277067780,"2/ Label noise is a particularly big issue in deep learning. I guess one reason why we usually glance over it is we think it averages out as we collect more data. But then, DL models are still extremely good at memorization, especially in real-world settings with limited data."
5301,@rasbt,2022-04-19 21:31:08+00:00,https://twitter.com/rasbt/status/1516529858825830408,How do we deal with noisy labels in deep learning? Label noise is a common issue that we usually glance over when working with benchmark datasets. But it's super relevant in real world problems. This is a super comprehensive survey right here:  https://t.co/VjckUgoIwS 1/
5302,@rasbt,2022-04-19 14:09:19+00:00,https://twitter.com/rasbt/status/1516418669328404497,@Circadiancap @__mharrison__ Glad to hear! I hope it will you help you .to_excel when you .apply pandas do your project .stack!
5303,@rasbt,2022-04-18 20:40:48+00:00,https://twitter.com/rasbt/status/1516154804522913793,@giffmana @pabbeel @therobotbrains @geoffreyhinton üî•
5304,@rasbt,2022-04-18 20:16:10+00:00,https://twitter.com/rasbt/status/1516148602732752906,"@svpino wohoo, have to make sure I get that one right then üòÖ. No pressure üëÄ"
5305,@rasbt,2022-04-18 19:57:39+00:00,https://twitter.com/rasbt/status/1516143943662153734,"@svpino I really liked this one because I usually I don't think too hard about the beta and just use it as F1. As a side-note, I really got to like MCC; there was a convincing article on that (https://t.co/JcKdC4ejRd) that I ~recently read https://t.co/vGOalhUllO"
5306,@rasbt,2022-04-18 19:06:53+00:00,https://twitter.com/rasbt/status/1516131168986533888,"@YassineAlouini @AndrewYNg @StanfordOnline @DeepLearningAI_ Now that you say it, it may have been 2012! Anyways, Happy 10 Year Anniversary @coursera ! And Happy Birthday @AndrewYNg!"
5307,@rasbt,2022-04-18 16:46:14+00:00,https://twitter.com/rasbt/status/1516095771090771975,"@AndrewYNg @StanfordOnline @DeepLearningAI_ I took your class back then in 2011, and it kickstarted my career! I am super excited to hear about this new specialization!"
5308,@rasbt,2022-04-18 02:58:10+00:00,https://twitter.com/rasbt/status/1515887381978701827,"@svpino Hah, same. To get going, almost every project I start builds upon something I have worked on before, so I can use it as a stepping stone template. I guess the key is not to keep it all in your head but work on things and to keep organized üòÖ"
5309,@rasbt,2022-04-17 13:07:36+00:00,https://twitter.com/rasbt/status/1515678363670781955,"@difficultyang Ok but this was 20 years ago, what were good, viable alternatives back then besides C?"
5310,@rasbt,2022-04-17 13:02:07+00:00,https://twitter.com/rasbt/status/1515676985250525191,"@togelius Hm tricky, but I‚Äôd say don‚Äôt have LLMs too much attention (no pun intended) and have decent portions on symbolic AI"
5311,@rasbt,2022-04-17 00:19:22+00:00,https://twitter.com/rasbt/status/1515485031434706953,"@svpino Yeah, my guess is they called it copilot for a reason. Similar Jupyter Notebook."
5312,@rasbt,2022-04-16 14:47:45+00:00,https://twitter.com/rasbt/status/1515341181353349128,"@xamat Yeah, same. Turns out 3 most useful works (judging by citation) have not been peer reviewed https://t.co/HpOHA2opp8"
5313,@rasbt,2022-04-16 14:31:39+00:00,https://twitter.com/rasbt/status/1515337127336292358,Training Compute-Optimal Large Language Models ‚Äî ‚ÄúWe find that current large language models are significantly undertrained‚Äù üëÄ https://t.co/UEjVWhBFyq
5314,@rasbt,2022-04-16 13:02:13+00:00,https://twitter.com/rasbt/status/1515314621577633793,@__mharrison__ @tunguz Whoa that looks pretty cool actually. Probably the nicest chair I have ever seen. It‚Äôs probably also not too uncomfy with a little cushion or so
5315,@rasbt,2022-04-16 01:16:12+00:00,https://twitter.com/rasbt/status/1515136946573615108,"@chrisalbon I don‚Äôt know what it is, but I really can‚Äôt watch TED talks. It‚Äôs a weird format that gets your somewhat interested but then also leaves you hanging in a very unsatisfying way."
5316,@rasbt,2022-04-16 01:14:07+00:00,https://twitter.com/rasbt/status/1515136420595314689,"@Rajath_DB @julien_c @huggingface Recently got a copy too. Have only just started but looks great. Only thing is it‚Äôs for NLP not CV, but otherwise great"
5317,@rasbt,2022-04-15 14:07:02+00:00,https://twitter.com/rasbt/status/1514968545570000901,@DrGroftehauge @anthonygitter Wow!! Super intriguing!! I guess the problem is in higher dims &amp; with unstructured data: where do you put the points?
5318,@rasbt,2022-04-15 04:50:33+00:00,https://twitter.com/rasbt/status/1514828501911842817,"@daniela_witten Or better yet, check up on all these LinkedIn notifications, connection requests, and messages"
5319,@rasbt,2022-04-15 03:08:57+00:00,https://twitter.com/rasbt/status/1514802933631660038,"@tdietterich Afaik they also didn't modify the validation set. I don't know about the data cleaning-specific best practices, but I would say that in this case you can look at it as a hyperparameter tuning pipeline where you make changes based on validation performance. 1/2"
5320,@rasbt,2022-04-15 03:01:38+00:00,https://twitter.com/rasbt/status/1514801090813779979,"@tdietterich Yes, there is a high risk of overfitting to the validation set. Here, they didn't have access to the test set though, and my guess is that even though they overfit to the validation set, the relative model performance ranking was probably ok (like in https://t.co/joAN2AAE59)."
5321,@rasbt,2022-04-15 02:53:54+00:00,https://twitter.com/rasbt/status/1514799144321228800,"@WillingCarol @DynamicWebPaige @anyscalecompute @raydistributed @spacy_io @huggingface @dask_dev @weights_biases @FastAPI @SciPyConf Yay! Looking forward to meet in person! Hah, and I am happy to sign ... hope it's not too heavy &amp; bulky for the suitcase (this really should have been split into two separate books) üòÖ"
5322,@rasbt,2022-04-15 01:33:30+00:00,https://twitter.com/rasbt/status/1514778912802320396,"*Ok, in ideal world we would have confidence intervals ... (I am tempted ... but let me finish writing the cross-entropy part 2 article first üòÖ, and then stay tuned for an article on this!)"
5323,@rasbt,2022-04-15 01:30:10+00:00,https://twitter.com/rasbt/status/1514778071462600706,"4/4
Last step:
4) augment &amp; clean edge cases (retrain model with the previously cleaned &amp; augmented dataset; then use t-SNE to project the data into a 2D space and find outliers). 
Results look good! Not sure if they shared the code, but  might not be too hard to replicate :) https://t.co/zeptWbDbfy"
5324,@rasbt,2022-04-15 01:27:52+00:00,https://twitter.com/rasbt/status/1514777494494212101,"Their approach was as follows: 
1) delete training data that negatively influence the validation loss
2) augment the data (Faster AutoAugment, Hataya et al. 2020)
3) train model with contrastive learning &amp; remove data points again
3/ https://t.co/XONmtNvNFi"
5325,@rasbt,2022-04-15 01:27:52+00:00,https://twitter.com/rasbt/status/1514777492606763011,"The authors were working with a fixed ResNet-50 model. The focus was on tinkering with the dataset to boost model performance. Meanwhile, the training &amp; validation data was plagued by all-too-familiar real world probs: 
(1) noisy labels 
(2) data scarcity 
(3) class imbalance
2/"
5326,@rasbt,2022-04-15 01:27:51+00:00,https://twitter.com/rasbt/status/1514777491067473927,"Was just chatting about data-centric AI on a podcast with @jaygshah22 &amp; just remember this informative  ""Augment &amp; Valuate: A Data Enhancement Pipeline for Data-Centric AI"" paper: https://t.co/6MHaqaTLQy 
Before spending days on hyperparam tuning it might be worth a try 1/"
5327,@rasbt,2022-04-15 01:17:40+00:00,https://twitter.com/rasbt/status/1514774927567560710,@nicholdav Ahhh why do days only come in 24h chunks. I need  ... want to dig into this more! Thanks for the pointers!
5328,@rasbt,2022-04-15 01:16:09+00:00,https://twitter.com/rasbt/status/1514774543809740803,@e_leandr_o @tunguz @svpino @JFPuget In case it is out-of-scope for scikit-learn ... üôÑüòÖ https://t.co/U6MtRrRIaF
5329,@rasbt,2022-04-15 00:45:28+00:00,https://twitter.com/rasbt/status/1514766825120157701,"@nicholdav Thanks, bookmarked! (Or alternatively not using Softmax üòÜ: https://t.co/xVep05ZmSE)"
5330,@rasbt,2022-04-15 00:35:01+00:00,https://twitter.com/rasbt/status/1514764193299279884,"Remember when we implemented our first multi-class neural nets using sigmoid activations in the output layer because it was a tad simpler than deriving the softmax gradients? Maybe it wasn't such a bad idea after all ... 
https://t.co/aEOTE1Tlv4 https://t.co/gEXsqVJDIx"
5331,@rasbt,2022-04-15 00:29:21+00:00,https://twitter.com/rasbt/status/1514762767605018636,"@Ryan_G_Lambert Thanks! Without having read the paper, intuition-wise this makes a lot of sense. Unless you have an ""Other/OOD"" category, forcing the class-membership probabilities sum up to 1 sounds like asking for trouble üôÉ"
5332,@rasbt,2022-04-14 18:33:48+00:00,https://twitter.com/rasbt/status/1514673292929482763,"@david_picard Yeah some conferences do that with OpenReview. But imho most people prefer their preprint to be on arXiv. 
(Not saying you should not use OpenReview, but you probably want both, the preprint up on arXiv and then a version of it on OpenReview for peer-reviewing.)"
5333,@rasbt,2022-04-14 16:23:42+00:00,https://twitter.com/rasbt/status/1514640549147549696,@ducnh279 haha glad it's useful!
5334,@rasbt,2022-04-14 16:06:37+00:00,https://twitter.com/rasbt/status/1514636251676217350,"@ducnh279 Ah yes, reading it really made my day :)"
5335,@rasbt,2022-04-14 14:57:15+00:00,https://twitter.com/rasbt/status/1514618796019007490,@hardmaru @elonmusk Maybe they should just rent it out for a few months to see if it's a good fit.
5336,@rasbt,2022-04-14 14:53:08+00:00,https://twitter.com/rasbt/status/1514617760348737538,"""Everything really clearly explained, I came because I didn't know if the convolutional layer used the same kernel for all the receptive fields, but stayed because the explanation was really good, I think I'll watch the other lectures too, you deserve way more views, thanks!!"" ü§ó"
5337,@rasbt,2022-04-14 14:31:16+00:00,https://twitter.com/rasbt/status/1514612254427152397,"2/3 The double-blind process is advantageous for reducing bias in peer-reviewing. On the other hand, uploading preprints is advantageous for advancing science. Sadly, some venues like ACL took a step backwards prohibiting preprint uploads a month prior to the review period."
5338,@rasbt,2022-04-14 14:31:15+00:00,https://twitter.com/rasbt/status/1514612251826655249,"""To ArXiv or not to ArXiv"" (https://t.co/sQnvQMDzgp) -- interesting paper trying to debate this with quantitative measurements. Apparently more than one-third (and, in reality, probably closer to half) of the reviewers break the double-blind process by searching for papers. 1/3"
5339,@rasbt,2022-04-14 13:14:36+00:00,https://twitter.com/rasbt/status/1514592959894892546,@dan_abramov Python 3 vs Python 2.7
5340,@rasbt,2022-04-14 12:43:33+00:00,https://twitter.com/rasbt/status/1514585148506968066,"@cdisalvo Well, academics use PowerPoint for a lot of things üòÖ"
5341,@rasbt,2022-04-14 04:03:00+00:00,https://twitter.com/rasbt/status/1514454148921663489,"@zacharylipton Wow, how sad that this is even a question üò¶. Don‚Äôt know if I want to know the answer üò¨"
5342,@rasbt,2022-04-14 03:40:45+00:00,https://twitter.com/rasbt/status/1514448547990716416,"@CSProfKGD I hear you. But I also still remember this moment 1st year in grad school where a seminar speaker said: ""Fortunately, the other group hasn't solved the crystal structure for this protein yet."" Still remember it 10 years later, and it is really kind of sad"
5343,@rasbt,2022-04-14 01:54:13+00:00,https://twitter.com/rasbt/status/1514421737756188680,"@DynamicWebPaige @anyscalecompute @raydistributed @spacy_io @huggingface @dask_dev @weights_biases @FastAPI @SciPyConf That'd be awesome! Hope it'll work out!
Haha, I am actually really bad at this üòÖ, but I will happily sign your copy of my book. Actually, I am really flattered that you got one! üòä"
5344,@rasbt,2022-04-14 01:48:35+00:00,https://twitter.com/rasbt/status/1514420319511093254,"""Know Your Limits: Uncertainty Estimation with ReLU Classifiers Fails at Reliable OOD Detection"" -- an interesting paper on this subject where the authors have a theoretical explanation that ReLU and Softmax are (partly) to blame: https://t.co/STbOjj9YJx https://t.co/pEoztyQRHw"
5345,@rasbt,2022-04-14 01:48:35+00:00,https://twitter.com/rasbt/status/1514420318424686594,"Re calibrated probabilities &amp; deep learning. One of the remaining challenges is how to deal with out-of-distribution (OOD) data. We could filter out OOD data using uncertainty estimation, right? But the prob is that neural nets are overconfident on OOD data. Chicken-egg problem?"
5346,@rasbt,2022-04-14 01:31:01+00:00,https://twitter.com/rasbt/status/1514415899113136131,"@therriaultphd @irfnali1 @tunguz @svpino @JFPuget But yeah, opening this can of worms, what other methods for calibration are there besides Platt's method and isotonic calibration? Thanks for the super insightful discussion btw., really enjoyed reading through all the comments!"
5347,@rasbt,2022-04-14 01:28:12+00:00,https://twitter.com/rasbt/status/1514415190489640963,"@glemaitre58 @martingoodson @tunguz @svpino @JFPuget Ah yes, thanks! (Btw. a reviewer recently brought this up üëÄ)"
5348,@rasbt,2022-04-14 01:24:04+00:00,https://twitter.com/rasbt/status/1514414148163186693,"@ykilcher Also to be fair, it's pretty challenging to be moonshotting  all by yourself or in a small team (like the average PhD research group setting) üåö"
5349,@rasbt,2022-04-14 01:20:57+00:00,https://twitter.com/rasbt/status/1514413363962556419,"@DynamicWebPaige @anyscalecompute @raydistributed @spacy_io @huggingface @dask_dev @weights_biases @FastAPI Nice! Have watched the virtual SciPy talk last year and the ecosystem is indeed super impressive! Speaking of which, any chance to meet you at SciPy in Austin this summer?"
5350,@rasbt,2022-04-13 20:43:52+00:00,https://twitter.com/rasbt/status/1514343635940171779,"@JFPuget @tunguz @svpino Oh yes, very good points, thanks for sharing!"
5351,@rasbt,2022-04-13 19:30:22+00:00,https://twitter.com/rasbt/status/1514325137931317266,"@martingoodson @tunguz @svpino @JFPuget Yes you are right. Unless it introduces ties, but I wouldn't consider this as an improvement but coincidental side-effect. I've seen people use it on Kaggle and am somewhat skeptical. We had a discussion here that the improvement might be due to the CV and averaging"
5352,@rasbt,2022-04-13 17:43:17+00:00,https://twitter.com/rasbt/status/1514298191696564230,"@therriaultphd @tunguz @svpino @JFPuget Yeah, that was just a really quick and dirty example. In practice, you probably would also have a test set"
5353,@rasbt,2022-04-13 17:25:55+00:00,https://twitter.com/rasbt/status/1514293817968676868,"@therriaultphd @tunguz @svpino @JFPuget Sure, that's fair! My guess is that you won't be getting it to match exactly because I am not sure if the training set partitioning is the same -- would be easier if you could pass the folds manually into the bagging classifier https://t.co/ntNvdcF0BJ"
5354,@rasbt,2022-04-13 16:46:33+00:00,https://twitter.com/rasbt/status/1514283913870516224,@therriaultphd @tunguz @svpino @JFPuget Ooops üòÖ. I guess I owe you a drink. https://t.co/D4XWAQlNh2
5355,@rasbt,2022-04-13 16:44:10+00:00,https://twitter.com/rasbt/status/1514283314005299205,@therriaultphd @tunguz @svpino @JFPuget You can replicate this with other classifiers. But nonetheless I think you are on to something! Good point. Should have thought of this üòÖ https://t.co/B8CBpLFpmU
5356,@rasbt,2022-04-13 16:36:57+00:00,https://twitter.com/rasbt/status/1514281496533741572,"@therriaultphd @tunguz @svpino @JFPuget Have to think about it more deeply, but I think it is due to cross-validation. Minimal example: https://t.co/oiZgVwZEA9 https://t.co/7XA6ZpWSkm"
5357,@rasbt,2022-04-13 16:19:07+00:00,https://twitter.com/rasbt/status/1514277010163523593,"People who are competing on Kaggle. Are you calibrating your classifiers / proba scores at all? (E.g., using CalibratedClassifierCV, https://t.co/cS7zI5CFTX.) Do you find that it noticeably improves your ROC AUC? (cc @tunguz @svpino @JFPuget)"
5358,@rasbt,2022-04-13 01:26:25+00:00,https://twitter.com/rasbt/status/1514052353778933770,@noahsark769 @CSProfKGD Btw. they also have a fitness spin-off! https://t.co/X6GtOhwMwB
5359,@rasbt,2022-04-13 00:53:55+00:00,https://twitter.com/rasbt/status/1514044173120327682,TIL you can add images and logos for dark mode on GitHub via # gh-light-mode-only and # gh-dark-mode-only tags. So cool. https://t.co/F7Tu2xB7nw https://t.co/XOwdmvM0I2
5360,@rasbt,2022-04-12 23:52:49+00:00,https://twitter.com/rasbt/status/1514028799087755266,"@KristinHenry To be fair, the article does mention that: ""behind the scenes all the heavy lifting is done by C/C++ or Fortran compiled routines. In essence, Python is used to point a fast routine in the right direction (i.e. to the right memory address), and no more."""
5361,@rasbt,2022-04-12 23:46:50+00:00,https://twitter.com/rasbt/status/1514027292762292228,"*Sure, nothing prevents you from using a KDtree data structure in Fortran. But the point is that if you are not an expert programmer, you are probably less likely to stumble upon it and use it."
5362,@rasbt,2022-04-12 23:46:50+00:00,https://twitter.com/rasbt/status/1514027291621351427,"2/2  E.g., using a KDtree (https://t.co/TPsouBYYDn) data structure to query from instead of implementing a vanilla search can speed things up tremendously. The article has an interesting anecdote where Fortran finished in 6:30h vs SciPy KDtree-based code finished in 4 minutes"
5363,@rasbt,2022-04-12 23:46:49+00:00,https://twitter.com/rasbt/status/1514027290400854021,"""The counter-intuitive rise of Python in scientific computing."" Sure, a nearest neighbor search in Python is slower than Fortran. But using e.g. Python's sci tools lowers the barrier to using even more efficient ways, like discovering KD-trees 1/2
 https://t.co/wEkoC2xb5R"
5364,@rasbt,2022-04-12 19:11:56+00:00,https://twitter.com/rasbt/status/1513958110888706052,"3/3 For the mid-semester project proposal there is no penalty, just a warning when I find copied passages. And they have to fix those and resubmit. For the end-of-semester reports, there is a bigger penalty for this, but luckily students are really good at citing by then :)"
5365,@rasbt,2022-04-12 19:11:55+00:00,https://twitter.com/rasbt/status/1513958109533908998,"2/ I don't think that students plagiarize intentionally since it is easy to detect thanks to having plagiarism checkers build into the submission platform. But yeah, I guess it is a concept that takes students some time getting used to."
5366,@rasbt,2022-04-12 19:11:55+00:00,https://twitter.com/rasbt/status/1513958108271370252,"From my teaching experience, many students genuinely don't know the quotation-mark rule when using sentences verbatim. I go over citation best-practices in class, but I still often find issues in the project proposals that are due mid-semester.  1/"
5367,@rasbt,2022-04-12 19:04:04+00:00,https://twitter.com/rasbt/status/1513956132171173888,"Arg, this is really unacceptable :("
5368,@rasbt,2022-04-12 18:11:32+00:00,https://twitter.com/rasbt/status/1513942913272762372,@lmoroney @verified Maybe we should write Wikipedia articles for each other üòÜ
5369,@rasbt,2022-04-12 18:05:44+00:00,https://twitter.com/rasbt/status/1513941450127556608,"@lmoroney @verified 2/2 I think I tried ""Other"" which has a Content Creator category that educators could fall into. But I don't think the ""notability"" methods are necessarily good ways to prove that you are creating content. Why not Coursera or university pages, or Amazon trends &amp; author pages? https://t.co/1AOKyMLdVR"
5370,@rasbt,2022-04-12 18:03:22+00:00,https://twitter.com/rasbt/status/1513940857635938306,"@lmoroney @verified I wouIdn't worry about Twitter verification too much. It's just a digital badge at the end of the day. Fwiw, also tried that a few months back and got rejected. I think the problem is that there is no Educator category. The closest one is maybe Entertainment but not really üòÖ 1/2 https://t.co/VGtfZzksOE"
5371,@rasbt,2022-04-12 15:04:51+00:00,https://twitter.com/rasbt/status/1513895932382924813,"""Machine Learning State-of-the-Art with Uncertainties"" -- great paper by @psteinb_ &amp; @helmholtz_ai
making a case for confidence intervals in ML benchmarks, or really any ML work. And no, adding CI's (e.g. via normal approx.) doesn't have to be expensive :) https://t.co/pgW6ILD7JW"
5372,@rasbt,2022-04-12 02:27:31+00:00,https://twitter.com/rasbt/status/1513705343427223559,"@GaryMarcus Set a reminder to check back &amp; am kind of bummed that there won't be (?) a debate. Also don't get the hostility thing people are talking about. Maybe I've been in academia for too long, but why are people annoyed if s.o. asks tricky questions for the sake of advancing science?"
5373,@rasbt,2022-04-12 00:24:41+00:00,https://twitter.com/rasbt/status/1513674429217316868,"@hugobowne Haven't been at SciPy for 5 years! Really looking forward to it!
""Gettin' the band back together"" as @amuellerml put it today ü§óüé∏!"
5374,@rasbt,2022-04-11 23:12:53+00:00,https://twitter.com/rasbt/status/1513656360529018881,@Inspiredlearne2 Wow! Love it üòç! Mine really pales in comparison. https://t.co/BEZoBjXbS4
5375,@rasbt,2022-04-11 21:25:31+00:00,https://twitter.com/rasbt/status/1513629341615276034,"@thedataprof @PacktPub @PacktAuthors Wow nice, this is cool stuff! I hope you had fun!"
5376,@rasbt,2022-04-11 16:24:25+00:00,https://twitter.com/rasbt/status/1513553565419196416,"@Inspiredlearne2 Wow cool pic! That looks like an impressive library right there! Have fun, and I hope you will like my book!"
5377,@rasbt,2022-04-11 14:09:01+00:00,https://twitter.com/rasbt/status/1513519491220754438,"@TaliaRinger And a UI that feels like we are still stuck in the 1990s. I often think twice or thrice before submitting a job vs just trying to run it on my workstation because of how much hassle it is. For our academic cluster, it even expects us to submit the dataset every time"
5378,@rasbt,2022-04-11 13:54:24+00:00,https://twitter.com/rasbt/status/1513515812098875401,"@irinarish @GaryMarcus Sure, that‚Äôd be nice to have. But until then I wouldn‚Äôt mind a debate."
5379,@rasbt,2022-04-11 13:52:03+00:00,https://twitter.com/rasbt/status/1513515222656499719,@KristinHenry Yeah it feels like a scam targeting people who were *not* into art before. It‚Äôs an easy sell because of how subjective art is
5380,@rasbt,2022-04-11 13:45:15+00:00,https://twitter.com/rasbt/status/1513513509623152641,@tymwol @bernhardsson Have you ever compiled PyTorch?
5381,@rasbt,2022-04-11 13:37:06+00:00,https://twitter.com/rasbt/status/1513511459564707845,@AhmadMustafaAn1 @ChristophMolnar This is academic publishers for you. I think they expect us to be grateful that we don‚Äôt have to pay the 1000 bucks publication fee on top of it.
5382,@rasbt,2022-04-11 10:52:01+00:00,https://twitter.com/rasbt/status/1513469917516947466,@AhmadMustafaAn1 @AlejandroPiad @svpino Agreed. But even 2D vision models. I don‚Äôt think it is possible to implement or even tinker with current ViTs without having coding expertise
5383,@rasbt,2022-04-11 10:50:10+00:00,https://twitter.com/rasbt/status/1513469448690229249,@tunguz Same. I might think about it again next year
5384,@rasbt,2022-04-11 10:39:08+00:00,https://twitter.com/rasbt/status/1513466674401398786,"@ChristophMolnar If that is not exploiting profs and students then I don‚Äôt know what is. As an academic, you are grateful not to pay publication fees &amp; someone making millions of your content and not sharing anything ‚Ä¶ that‚Äôs sad given that it‚Äôs often even hard to afford groceries as a student"
5385,@rasbt,2022-04-11 10:35:45+00:00,https://twitter.com/rasbt/status/1513465823943446532,"@ChristophMolnar wrote a book chapter for Springer for free when I was a grad student. They sold it for $49.99. They recently emailed mentioning that it was downloaded 70,000 times. They cashed in ~3.5 million bucks with my chapter and their generous offer is that I can update it free of charge."
5386,@rasbt,2022-04-11 10:29:47+00:00,https://twitter.com/rasbt/status/1513464322554568706,"@ChristophMolnar *99% of the time they are asked to write chapters for free, and the publisher makes it sound like it‚Äôs a generous offer using phrases like ‚Äúfree of charge‚Äù"
5387,@rasbt,2022-04-11 10:23:59+00:00,https://twitter.com/rasbt/status/1513462862039105540,@AlejandroPiad @svpino Yeah but it looks like the landscape is slowly shifting towards requiring more ML engineering knowledge. Even for academic research not knowing anything about ML engineering will hold you back if you want to stay up to date and implement/use current methods
5388,@rasbt,2022-04-11 08:56:47+00:00,https://twitter.com/rasbt/status/1513440918275244039,"@CSProfKGD Be prepared, the first trip is going to be weird, but it becomes easier and almost normal again afterwards."
5389,@rasbt,2022-04-11 00:39:35+00:00,https://twitter.com/rasbt/status/1513315790744961027,@DynamicWebPaige @clauren42 @eamodio Wow cool! Congrats on the new role üçæü•≥. Exciting times ahead!
5390,@rasbt,2022-04-11 00:13:40+00:00,https://twitter.com/rasbt/status/1513309269516558341,"@lindsey @TaliaRinger Yeah, that's a good call and an interesting case. I think it won the test of time award at NeurIPS last year, however, everyone is using synchronous SGD nowadays!?"
5391,@rasbt,2022-04-11 00:09:30+00:00,https://twitter.com/rasbt/status/1513308220437245956,@TaliaRinger Pretty much everything from DeepSpeed: https://t.co/4IcGuPZSoX. MosaicML is currently working on ways to speed up training in a less hardware-related fashion (https://t.co/u8obirCJz8) that is worth looking into. Maybe @jefrankle can list some papers to include.
5392,@rasbt,2022-04-10 14:59:23+00:00,https://twitter.com/rasbt/status/1513169780290822153,@hugobowne See you in Austin!
5393,@rasbt,2022-04-10 12:28:53+00:00,https://twitter.com/rasbt/status/1513131906442973184,"@JirkaBorovec @aniketmaurya @PyTorch Yes, I heard that the DataPipes class will be a replacement for Dataset."
5394,@rasbt,2022-04-09 11:26:25+00:00,https://twitter.com/rasbt/status/1512753798384652290,@TweetySanthosh Wow nice. Have fun!
5395,@rasbt,2022-04-08 14:32:47+00:00,https://twitter.com/rasbt/status/1512438308990824448,"@ChristophMolnar Doesn't have to be -ists though. I mean, even though we have Biologists &amp; and Physicists, it doesn't mean we have to call people Mathematicists &amp; Statisticists üòú"
5396,@rasbt,2022-04-08 14:20:34+00:00,https://twitter.com/rasbt/status/1512435236411478016,"@Inspiredlearne2 I hope you'll like it! It's a big book, so I recommend taking it one small step at a time :)"
5397,@rasbt,2022-04-08 14:19:43+00:00,https://twitter.com/rasbt/status/1512435023605121025,@hsuyab @PacktPub @durgaamma2005 It's black &amp; white for price reasons. I think color prints for such a big book would cost at least twice as much. The kindle version is in color though.
5398,@rasbt,2022-04-08 14:08:45+00:00,https://twitter.com/rasbt/status/1512432262683447301,"Recently mentioned that incorporating explicit rules (during inference, not just modding the loss during training) could make DL really more attractive in certain areas. Just saw how people approach this from a data representation perspective. Cool stuff!
https://t.co/DfGJ0Xx2FY https://t.co/YGIQZZptYI"
5399,@rasbt,2022-04-08 13:19:05+00:00,https://twitter.com/rasbt/status/1512419761560473603,"@techruralist @karpathy @alfcnz *and just to clarify, in both cases this is how it looked before I took the first sip üòÜ. @alfcnz would probably say: ""this looks about right"""
5400,@rasbt,2022-04-08 13:02:14+00:00,https://twitter.com/rasbt/status/1512415520615768067,"'[Machine Learning] is no longer solo work, but teamwork. The corollary is this: discipline enables better collaborative work.'
Great post by @ericmjl: https://t.co/sOzazojsfF
- conda envs
- git repos (for every project)
- cookiecutters
All the things I recommend &amp; use!"
5401,@rasbt,2022-04-08 11:52:25+00:00,https://twitter.com/rasbt/status/1512397950835695618,@tmlabonte @ccanonne_ This! It happens to me all the time.
5402,@rasbt,2022-04-08 11:49:06+00:00,https://twitter.com/rasbt/status/1512397119046443008,"@ChristophMolnar What‚Äôs wrong with 
Machine Learning-&gt; Machine Learners
Deep Learning      -&gt; Deep Learners
Causal inference  -&gt; Causal Inferencers 
Supervised ML      -&gt; Supervised Machine Learners?"
5403,@rasbt,2022-04-08 11:43:11+00:00,https://twitter.com/rasbt/status/1512395627807846404,"@techruralist @karpathy Haha so true. Just had my first Italian coffees a few months ago. The coffee is so delicious (CC @alfcnz) but it takes time to get used to. My first order was a ‚Äúcoffee to go,‚Äù and this is what I got. The second one was an Americano üòÖ. https://t.co/bXrjffqe2I"
5404,@rasbt,2022-04-08 11:35:41+00:00,https://twitter.com/rasbt/status/1512393742526951434,"@Richard_thaler1 @karpathy Same in Germany. My parents would never go there. There, it‚Äôs considered more like a luxury thing where you go if you have too much money."
5405,@rasbt,2022-04-08 11:25:07+00:00,https://twitter.com/rasbt/status/1512391083224875013,"@Inspiredlearne2 3/3 it does contain all the fundamental topics for beginners though, and I think it‚Äôs a good way to start into ML where you also will see the connection between regular machine learning and deep learning, and both are useful for different types of problems"
5406,@rasbt,2022-04-08 11:22:26+00:00,https://twitter.com/rasbt/status/1512390408084635651,"@Inspiredlearne2 2/ it might be just the right level of detail for you. But if it is too much, don‚Äôt be afraid of skipping sections. You can still get a lot out of it. It‚Äôs maybe 3x as much content as the typical book, and you can decide how much you want to read in the first pass"
5407,@rasbt,2022-04-08 11:19:37+00:00,https://twitter.com/rasbt/status/1512389698303451139,"@Inspiredlearne2 I think it is well suited for beginners. It would say Python knowledge is required to get the most out of it. And since there are some mathematical notations in there, it would also be good if you don‚Äôt totally hate math üòä 1/n"
5408,@rasbt,2022-04-07 20:37:58+00:00,https://twitter.com/rasbt/status/1512167825502318594,@giffmana It‚Äôs based on ‚Äúa‚Äù ViT and people don‚Äôt know which one to cite üòÖ. Oh and thanks for not using the deep learning f-word üòÜ
5409,@rasbt,2022-04-07 20:08:19+00:00,https://twitter.com/rasbt/status/1512160363059556358,"@CSProfKGD Haha. I am super torn between: 
""wow this looks cool / makes cool-looking things"" 
and 
""how could this be useful to me?"""
5410,@rasbt,2022-04-07 16:42:43+00:00,https://twitter.com/rasbt/status/1512108620573560844,"@alexjc Ok but to be fair, I think this is actual research, it's just only a small snapshot that is shared."
5411,@rasbt,2022-04-07 16:32:03+00:00,https://twitter.com/rasbt/status/1512105935845707781,"@alexjc Haha, maybe we just need to go with the times and invent a new term for that. Like there is a Review Paper format, so this could be a research *Preview* Paper"
5412,@rasbt,2022-04-07 16:22:49+00:00,https://twitter.com/rasbt/status/1512103613086281745,"@distribution_fu @satellitegalaxy But it is kind of inconsistent in R? 
Like 
bla &lt;- function(a = 1, b = 2) {
   result &lt;- a * b
   print(result)
}
bla()"
5413,@rasbt,2022-04-07 03:25:10+00:00,https://twitter.com/rasbt/status/1511907910313521154,"@DynamicWebPaige @PyTorch @raydistributed @scikit_learn This looks amazing! 

(Ah, sorry, but a little nitpick, I don't think there should be a softmax in the output layer if you use CrossEntropyLoss; sorry, can't help it due to https://t.co/NqBL3dItB7 üòÖüòÖüòÖ)"
5414,@rasbt,2022-04-07 03:17:38+00:00,https://twitter.com/rasbt/status/1511906015234637831,"Oh, and in case you don't know how to toy around with data in pandas DataFrames or just want to take it up to the next level, I can highly recommend Effective Pandas by my favorite Python teacher @__mharrison__ . I thought I knew it all, but this book taught me otherwise. https://t.co/twqBPVHNHZ"
5415,@rasbt,2022-04-07 03:12:46+00:00,https://twitter.com/rasbt/status/1511904788304248833,"BioPandas v0.3.0 is out! Thx to a kind contrib by Arian Jamasb (https://t.co/srtuGpDqjl), you can now read mmCIF files (large protein structures) into pandas DataFrames, and then you can toy around with those proteins using your favorite data analysis lib: https://t.co/cksMUrbF1M"
5416,@rasbt,2022-04-06 19:05:31+00:00,https://twitter.com/rasbt/status/1511782170704109568,"@bskkarthik Yeah, it looks like I mistyped this."
5417,@rasbt,2022-04-06 18:53:56+00:00,https://twitter.com/rasbt/status/1511779252756172804,"@bskkarthik Oh do you mean this one here? Good point, looks like I made a typo here https://t.co/eD8GBrJnP2"
5418,@rasbt,2022-04-06 16:05:21+00:00,https://twitter.com/rasbt/status/1511736829254512640,@wightmanr Wow that was quick ‚ò∫Ô∏è! Do you have a rough estimate how it compares to GELU?
5419,@rasbt,2022-04-06 16:02:37+00:00,https://twitter.com/rasbt/status/1511736143347339275,@ZefsGuides That's really nice! What is the specific beta for this illustration?
5420,@rasbt,2022-04-06 15:49:33+00:00,https://twitter.com/rasbt/status/1511732854451015680,"Finally got our new activation function. While Cyclemoid came with code but no paper, SmeLU comes with a paper but no code (?)
Sounds interesting though. Main point is that it is a) easier to implement than other smooth activation functions like GELU &amp; Swish + it's also monotonic"
5421,@rasbt,2022-04-06 03:39:39+00:00,https://twitter.com/rasbt/status/1511549167067410435,"@FFanciest yes, the test set is not guaranteed to have zero mean and unit variance for each feature. I mean, these properties are also really just beneficial for training. On the contrary, it is not desirable to force the test set to have zero mean and unit variance, as shown in the example"
5422,@rasbt,2022-04-06 03:32:45+00:00,https://twitter.com/rasbt/status/1511547431095345161,"@FFanciest I know it can appear a bit weird, but this is intentional and correct. We don't want to use the testset info in standardization, because we want to treat it as new, independent data. I have an example here that might help illustrate the problem &amp; rationale https://t.co/FSZ1IDi9xV"
5423,@rasbt,2022-04-06 02:08:32+00:00,https://twitter.com/rasbt/status/1511526235603673088,@tunguz Reminds me of the typo in the GAN article on arxiv. https://t.co/CHqTeA4xeV
5424,@rasbt,2022-04-06 02:02:07+00:00,https://twitter.com/rasbt/status/1511524620817608709,@michalwols Typora! Have been using it for many years. Not free anymore but worth the price imho. https://t.co/FgkXHaq5UB
5425,@rasbt,2022-04-06 01:57:09+00:00,https://twitter.com/rasbt/status/1511523372307521546,"@tunguz Yeah, like on arxiv. You can still point to a specific version but it doesn't default to it. Not a Facebook user but it sounds like Facebook has this already: https://t.co/fpSDJXmkWS"
5426,@rasbt,2022-04-05 17:57:17+00:00,https://twitter.com/rasbt/status/1511402609957089301,"@srchvrs That's a good point. I think it might be due to vanishing gradients. Because I think when I accidentally left the Softmax in a smallish network, it kind of trained somewhat.  But when you try it with sth like VGG-16 it doesn't really work"
5427,@rasbt,2022-04-05 17:51:32+00:00,https://twitter.com/rasbt/status/1511401163849179143,@srchvrs Afaik Softmax doesn't work well most of the time when you use CrossEntropyLoss. Was mentioning log-softmax because that's what NLLLoss accepts. And if you include a LogSoftmax layer but then use CrossEntropyLoss instead of NLLLoss it should also work due to the idempotency :P
5428,@rasbt,2022-04-05 17:32:37+00:00,https://twitter.com/rasbt/status/1511396404706557959,"@srchvrs I actually tried double-log softmax and it kind of works. It's probably not ideas because you have this extra step in the derivative and then maybe vanishing gradients like you said. But it kind of works pretty well, which is why I would consider it as a silent bug"
5429,@rasbt,2022-04-05 17:23:08+00:00,https://twitter.com/rasbt/status/1511394018000785409,"@unsorsodicorda It's a bit tricky because cross-entropy doesn't accept probas. But if you use BCELoss and and NLLLoss (CrossEntropyLoss is basically LogSoftmax + NLLLoss), then yes. Maybe I have some blocker, but I can't see how we'd find the logits for CrossEntropyLoss to make that work https://t.co/m8P85vwLjc"
5430,@rasbt,2022-04-05 17:14:33+00:00,https://twitter.com/rasbt/status/1511391855551909890,@joshuastarmer Wow that's awesome to hear!!! ‚ò∫Ô∏è
5431,@rasbt,2022-04-05 17:14:03+00:00,https://twitter.com/rasbt/status/1511391728548388865,"@srchvrs Well said. Haha, but if you pass log-softmaxified inputs, that's okay again (because (torch.log(F.softmax(log_softmax, dim=1)) == log_softmax).all() is true) ü§Ø https://t.co/GyicapUSK4"
5432,@rasbt,2022-04-05 17:09:30+00:00,https://twitter.com/rasbt/status/1511390585248178179,"@unsorsodicorda ""logsigmoid(logits) as input, so that basically means that you should instead use BCEWithLogitsLoss (with logits as input"" Also just to clarify, this convergence issue for  log(sigmoid(...)) vs of logsigmoid was for some custom code, not BCELoss :)"
5433,@rasbt,2022-04-05 17:06:28+00:00,https://twitter.com/rasbt/status/1511389822388166656,"@unsorsodicorda ""and you shouldn't use BCELoss with logsigmoid(logits) as input, "" -&gt; you are right, it's one of the little tricky things in PyTorch. NLLLoss wants you to use log-probas, but BCELoss wants you to use regular probas. Was more referring to the internal logsigmoid though: https://t.co/FGMEfMPTq3"
5434,@rasbt,2022-04-05 17:01:58+00:00,https://twitter.com/rasbt/status/1511388690135883786,"@unsorsodicorda ""Ok, but CrossEntropyLoss and BCELoss are the same if K=2 (number of classes)"" -- discussing that in part 2 :). It's is a bit different though because you have 2 output nodes. It's not quite the same network."
5435,@rasbt,2022-04-05 16:46:27+00:00,https://twitter.com/rasbt/status/1511384783703654408,@unsorsodicorda things would first train fine but then fail after 20-50 epochs or so. Either resulting in NaN or inf
5436,@rasbt,2022-04-05 16:45:51+00:00,https://twitter.com/rasbt/status/1511384634675937281,"@unsorsodicorda don't have extensive experience using BCELoss (vs CrossEntropy and BCEWithLogitsLoss), so I don't know if that's just an extreme / outlier case here. However, I know that esp for deep networks, I had big convergence issues when using log(sigmoid(...)) instead of logsigmoid losses"
5437,@rasbt,2022-04-05 16:13:13+00:00,https://twitter.com/rasbt/status/1511376422752903173,@alfcnz Haha those are fun but time is probably better spent learning a new music instrument üéª
5438,@rasbt,2022-04-05 14:43:04+00:00,https://twitter.com/rasbt/status/1511353735037034499,"@bskkarthik Actually, I don't know why the .long() needs to be added in your case -- it works fine on my laptop and my GPU workstation. A possible explanation and my best guess: are you using Windows and have a 32bit Python version installed?"
5439,@rasbt,2022-04-05 14:01:36+00:00,https://twitter.com/rasbt/status/1511343300137074706,"@bskkarthik Nice! I think you are getting a 
""RuntimeError: expected scalar type Long but found Int""
in the ""loss = loss_fn(pred, y_batch)"" otherwise. Essentially, the reason is that from_numpy gives you a 32 bit integer (Int) rather than 64bit integer (Long) here."
5440,@rasbt,2022-04-05 13:59:08+00:00,https://twitter.com/rasbt/status/1511342679145254922,"@tobalko_ Glad to hear! It's really hard to cut out sections after putting a lot of effort into it. But sometimes too much is too much üòÖ. Glad that putting this at the end with links to the relevant topics was useful; in this case, having had to remove those sections now hurts a bit less"
5441,@rasbt,2022-04-05 13:55:50+00:00,https://twitter.com/rasbt/status/1511341849641951244,"@bskkarthik Are you referring to the line 
y_train = torch.from_numpy(y_train) 
And does changing it to
y_train = torch.from_numpy(y_train).long()
help?"
5442,@rasbt,2022-04-05 13:44:54+00:00,https://twitter.com/rasbt/status/1511339095854882818,@tfkeras Thanks!!
5443,@rasbt,2022-04-05 13:43:15+00:00,https://twitter.com/rasbt/status/1511338681331814412,"@liftingcovered Thanks! And wow, after all these years using Keynote, I never stumbled upon the in Window option. This will come in so handy in other contexts as well!"
5444,@rasbt,2022-04-05 02:17:49+00:00,https://twitter.com/rasbt/status/1511166186691702789,"@thomasjpfan Oh no, what a dumb copy &amp; paste error in such an important location ü§¶‚Äç‚ôÇÔ∏è. Thanks for pointing it out. Just fixed it."
5445,@rasbt,2022-04-05 00:58:52+00:00,https://twitter.com/rasbt/status/1511146318391087111,@TaliaRinger @jmschreiber91 @adrianwaelchli Keep us updated! It's an extremely interesting and annoying issue.
5446,@rasbt,2022-04-05 00:08:32+00:00,https://twitter.com/rasbt/status/1511133651618127873,@TaliaRinger @adrianwaelchli That sounds frustrating. It could be a PyTorch bug but also a CUDA or cuDNN bug. If you have time it might be worthwhile trying to upgrade or downgrade. Actually one time I even had a faulty GPU that produced inaccurate results (was an issue with some early 2080‚Äôs back then)
5447,@rasbt,2022-04-04 23:57:44+00:00,https://twitter.com/rasbt/status/1511130932098519041,@ryanlei_psych Or when undergrads are expected to have papers to get admitted to grad school
5448,@rasbt,2022-04-04 23:06:24+00:00,https://twitter.com/rasbt/status/1511118015429029893,@OkbaLeftHanded Sounds reasonable üëå
5449,@rasbt,2022-04-04 23:01:20+00:00,https://twitter.com/rasbt/status/1511116740041846793,"@OkbaLeftHanded Hah, yes, this! I am getting to that in part 2. The sneaky think about it is also that LogSoftmax is numerically more stable, so you should use that one instead in general. But when you use LogSoftmax() + CrossEntropyLoss, it works too (basically a silent bug) ü§Ø https://t.co/tQzq6eYXSP"
5450,@rasbt,2022-04-04 22:36:27+00:00,https://twitter.com/rasbt/status/1511110475576221698,"@TaliaRinger import pytorch_lightning as pl
trainer = pl.Trainer(
    ...
    deterministic=True
    ...
)
üòÜ"
5451,@rasbt,2022-04-04 21:54:35+00:00,https://twitter.com/rasbt/status/1511099941480972292,"Well, of course you should probably never implement a binary cross-entropy loss from scratch in pure PyTorch for a real-world application. However, sometimes you want to develop custom losses where you need that type of manual coding."
5452,@rasbt,2022-04-04 21:54:35+00:00,https://twitter.com/rasbt/status/1511099939161522181,"A useful tidbit is to look for log(proba) calls &amp; replace them by logsigmoid(logits) when you can. to improve numerical stability. In two research projects, this was literally a difference from having a loss that's converging and a loss that turned into ""inf"" after many epochs https://t.co/sW0YF3fqhM"
5453,@rasbt,2022-04-04 21:19:54+00:00,https://twitter.com/rasbt/status/1511091212303974400,"Are the negative log-likelihood loss, binary cross-entropy, and logistic loss the same? A common &amp; legit question. Also, if we implement a binary classifier in PyTorch, should we use BCELoss or BCEWithLogitsLoss? Answering this turned into a fun wknd proj:
https://t.co/NqBL3dItB7 https://t.co/JXKDG6wGdx"
5454,@rasbt,2022-04-04 16:01:12+00:00,https://twitter.com/rasbt/status/1511011007698714624,@andrewgwils Awesome! Huge congrats!! üéä
5455,@rasbt,2022-04-04 03:52:03+00:00,https://twitter.com/rasbt/status/1510827511734800385,@mbilalai @CSProfKGD No pressure üôÇ
5456,@rasbt,2022-04-04 03:50:17+00:00,https://twitter.com/rasbt/status/1510827069407698950,"@CSProfKGD Oh yeah, the field exploded recently. But it‚Äôs exciting times I guess üòä. (Btw, speaking of staying up to date ‚Ä¶ sorry, but I can‚Äôt help but noticing ‚Ä¶ what OS version is this? This looks ancient üòÖ)"
5457,@rasbt,2022-04-03 22:29:40+00:00,https://twitter.com/rasbt/status/1510746382713372672,"@dan_s_becker @tunguz Yeah makes no sense. Also, the only way to avoid the kiosk seems to be paying extra and bringing a carry-on. No carry-on is actually more hassle since: ""you may need to finish checking in at the airport so we can verify that you don't have a carry-on."""
5458,@rasbt,2022-04-03 21:10:42+00:00,https://twitter.com/rasbt/status/1510726508150722566,"@dan_s_becker @tunguz Oh, you were referring to online check-in? I was responding while thinking were are talking about the check-in counters at the airport üòÖ"
5459,@rasbt,2022-04-03 21:09:09+00:00,https://twitter.com/rasbt/status/1510726117824643077,@dan_s_becker @tunguz https://t.co/MSV89MYbWU
5460,@rasbt,2022-04-03 21:07:27+00:00,https://twitter.com/rasbt/status/1510725692845178891,"@dan_s_becker @tunguz Maybe that's a ""basic economy"" vs ""economy thing"". Or maybe that was because of the chaos &amp; staff shortages in the recent months."
5461,@rasbt,2022-04-03 21:04:03+00:00,https://twitter.com/rasbt/status/1510724837014220801,"@WalterReade @tunguz Yes, I am curious, too."
5462,@rasbt,2022-04-03 20:58:56+00:00,https://twitter.com/rasbt/status/1510723548771500036,"@WalterReade @tunguz For cars, we now have electric ones. Or for trains something like the Maglev (https://t.co/0YmfCFZkEb). What's the equivalent of that in terms or airplanes? The Concorde? (Oh wait, that was 5 decades ago and they got rid of that.)"
5463,@rasbt,2022-04-03 20:56:19+00:00,https://twitter.com/rasbt/status/1510722889665990668,"@dan_s_becker @tunguz bag drop üòÖ (btw regarding seat assignment, that's not true anymore. Unless you pay extra, you can't select your seats online anymore. On all my recent flights via United, Frontier, and American)"
5464,@rasbt,2022-04-03 20:51:41+00:00,https://twitter.com/rasbt/status/1510721723028676611,"@WalterReade @tunguz Sure, compared to 150 years ago, it's still a big achievement, but 100 years later, I feel like there's some lack of innovation when it comes to transportation:
1825 first steam locomotive
1886 first automobile
1912 first motor ship
1914 first passenger airline"
5465,@rasbt,2022-04-03 20:38:24+00:00,https://twitter.com/rasbt/status/1510718380986310656,"@roycoding @tunguz That's true. On the other hand, that's also true for cars and computers. Whether you should be driving a 30 year old car (emissions) or use a 30 year old computer (wattage and speed) is another question ..."
5466,@rasbt,2022-04-03 20:24:36+00:00,https://twitter.com/rasbt/status/1510714906164842499,"@SambbhavGarg @tunguz *Oops, meant ""hurt"". But yeah, ""not being heard"" is probably also not wrong."
5467,@rasbt,2022-04-03 20:18:33+00:00,https://twitter.com/rasbt/status/1510713385352105991,@SambbhavGarg @tunguz Afaik luckily no one got heard. I agree with you on the classic classroom model. This also needs a massive overhaul.
5468,@rasbt,2022-04-03 20:01:58+00:00,https://twitter.com/rasbt/status/1510709213739290638,@SambbhavGarg @tunguz I was teaching in that building Fall 2021. I am not kidding. https://t.co/pGtPptAziG
5469,@rasbt,2022-04-03 19:51:27+00:00,https://twitter.com/rasbt/status/1510706564562407433,@tunguz The fact that the only way you can tell whether you are flying in a new or a 30 year old airplane is the color of the seats is a sign that they have a massive issue with innovation. And not even checkin got easier. It‚Äôs still all the same as it was decades ago
5470,@rasbt,2022-04-03 19:48:35+00:00,https://twitter.com/rasbt/status/1510705844761116678,"@tunguz Yeah, I am really curious about this. While computers and even cars made leaps in recent years, I feel like air travel is not only stagnating but regressing. Air travel is still expensive, loud, inefficient, uncomfortable, and stressful. This industry needs a massive overhaul"
5471,@rasbt,2022-04-03 18:32:13+00:00,https://twitter.com/rasbt/status/1510686627387035661,@DigThatData @scikit_learn that's *all we want*!
5472,@rasbt,2022-04-03 03:13:05+00:00,https://twitter.com/rasbt/status/1510455318815334400,@shoyer Great point!
5473,@rasbt,2022-04-02 21:28:25+00:00,https://twitter.com/rasbt/status/1510368578570182662,"@giffmana Scikit-learn, git, scipy"
5474,@rasbt,2022-04-02 19:35:01+00:00,https://twitter.com/rasbt/status/1510340042274844673,"@Smerity @pcdopc_ Or, in the ConvNext paper: ""We find that ReLU can be substituted with GELU in our ConvNet too, although the accuracy stays unchanged (80.6%)."""
5475,@rasbt,2022-04-02 19:33:56+00:00,https://twitter.com/rasbt/status/1510339768768417798,"@Smerity @pcdopc_ True. But I feel like I actually did spend too much time on activation functions though, and I also found that GELU doesn‚Äôt really make a difference in my case. But it might just be me and my suboptimal hyperparameter tuning"
5476,@rasbt,2022-04-02 17:27:53+00:00,https://twitter.com/rasbt/status/1510308047893274629,"@overlordayn Also, see AlphaFold2, which is also a transformer, and it's applied to huge protein structures (which are graphs that are infeasible for message passing)"
5477,@rasbt,2022-04-02 17:26:46+00:00,https://twitter.com/rasbt/status/1510307768552595470,"@overlordayn Sure, but I'd say it's sufficient for molecule disocvery contexts. Especially for drug discovery etc. you have like ~5-15 heavy atoms per molecule."
5478,@rasbt,2022-04-02 17:21:19+00:00,https://twitter.com/rasbt/status/1510306395014537219,"@bose_joey üòÜ. Oh, and technically speaking, AlphaFold 2 is also a transformer, and proteins are huge graphs ... üôÑ"
5479,@rasbt,2022-04-02 17:17:39+00:00,https://twitter.com/rasbt/status/1510305470787076108,"@bose_joey Ah yes, that's an unfortunate wording. It's not datasets of large graphs but a graph datasets that are large üòÖ. I think it's clear from the molecule dataset context, but I agree that it is confusing w/o that context"
5480,@rasbt,2022-04-02 16:58:07+00:00,https://twitter.com/rasbt/status/1510300558598590467,"@kchonyc Published on April 1st ... but not an April Fool's joke, is it?"
5481,@rasbt,2022-04-02 16:24:35+00:00,https://twitter.com/rasbt/status/1510292120233562114,Graph neural networks are still the first choice for graph data ... But graphormers are coming for you. Graphormer -- transformers for large graph datasets https://t.co/x6dc9I5hAQ https://t.co/AowhZ1LCYX
5482,@rasbt,2022-04-02 16:13:50+00:00,https://twitter.com/rasbt/status/1510289414320271363,"""Small Scope and Fast Review The secret to happy devs"" via @mrocklin  -- A fast article on the benefits of fast PRs to avoid scope creep in open source. 
""Fast PRs also feel great, we should do more of those"" 
https://t.co/86jQGvxfcU"
5483,@rasbt,2022-04-02 15:47:43+00:00,https://twitter.com/rasbt/status/1510282842135306252,"@pcdopc_ Where the improved version has ""-pi &amp; pi"" in the clamp section than just the arbitrary -3 &amp; 3 

    term1 = torch.tanh(torch.pi*x)
    term2 = torch.tanh(torch.pi*torch.square(x)-0.95)**2
    term3 = torch.cos(torch.clamp(x, min=-torch.pi, max=torch.pi))**2"
5484,@rasbt,2022-04-02 15:46:26+00:00,https://twitter.com/rasbt/status/1510282516451704839,"@pcdopc_ Well, joking aside, it's not that it does not work, but it's about whether you want to use it. Cyclemoid does perform better than Relu actually. E.g., test accuracies of a simple AlexNet on Cifar-10:
0.724 ReLU
0.727 Cyclemoid orig
0.733 Cyclemoid improved"
5485,@rasbt,2022-04-02 14:43:39+00:00,https://twitter.com/rasbt/status/1510266718236643331,"@pcdopc_ Ok, so what about GELU, ELU, PrELU ABReLU, SoftPlus ... üôÑ? There is a lesson learned here: stick with ReLU, and think twice before adopting a new activation function üòâ"
5486,@rasbt,2022-04-02 14:24:48+00:00,https://twitter.com/rasbt/status/1510261974957015050,"Oh, I also just added Keras functionality via 
from cyclemoid_pytorch.easteregg import CycleMoid. The code is thanks to a kind contribution by Achint -- don't know whether he is in on the joke or not, maybe I should let him know üòÜ https://t.co/8LruYq2glh"
5487,@rasbt,2022-04-02 14:24:06+00:00,https://twitter.com/rasbt/status/1510261797302984708,"Credits to @giffmana for almost running some ImageNet experiments, and @wightmanr for actually running some experiments. @TheZachMueller was thinking about integrating it into a popular DL library, and @code_star was thinking about it real hard all day!"
5488,@rasbt,2022-04-02 14:23:13+00:00,https://twitter.com/rasbt/status/1510261575445364741,"Ok, I think I should let you all know that this was an April Fool's joke of course ü§ó. Moral of the story: if you are a student looking for thesis topics, there seems to be a huge interest in new activation functions üòÜ"
5489,@rasbt,2022-04-01 23:24:26+00:00,https://twitter.com/rasbt/status/1510035390664781832,@tiredofm3 @wightmanr @giffmana @PyTorch @PyTorchLightnin It got 95% accuracy out of the box on MNIST with a simple MLP and no tuning in 5 min on my laptop: https://t.co/9ynYyi8eE6
5490,@rasbt,2022-04-01 23:03:45+00:00,https://twitter.com/rasbt/status/1510030184325562374,"@wightmanr @giffmana @PyTorch @PyTorchLightnin Haha, lol. The figures and tables were from here btw.: https://t.co/CRpvlfKvV1 (with some slight edits). The points you brought up re Cifar10(0) and ImageNet, and SiLU vs ReLU still hold though üòâ"
5491,@rasbt,2022-04-01 22:56:44+00:00,https://twitter.com/rasbt/status/1510028418502508546,"@wightmanr @giffmana @PyTorch @PyTorchLightnin Ok okay sorry, enough fun for today üòä. Before this gets totally out of hand, this whole thing was an April Fool's joke üòÅ. Sorry üòÖ"
5492,@rasbt,2022-04-01 22:36:52+00:00,https://twitter.com/rasbt/status/1510023419655503881,"@wightmanr @giffmana @PyTorch @PyTorchLightnin Wow that's a huge difference. But wouldn't it be more fair to compare it to a relu-from-scratch version like
def relu(x):
    return torch.max(torch.tensor([0.]), x)
rather than F.relu() / nn.ReLU?"
5493,@rasbt,2022-04-01 22:28:35+00:00,https://twitter.com/rasbt/status/1510021335199756295,"@wightmanr @giffmana @PyTorch @PyTorchLightnin 1/3 of the total training speed, or speed relative to ReLU activation during training?"
5494,@rasbt,2022-04-01 22:27:14+00:00,https://twitter.com/rasbt/status/1510020995171729416,"@wightmanr @giffmana @PyTorch @PyTorchLightnin Hm, yeah, in terms of training loss, swish/SiLU looked indeed better but this didn't generalize to test accuracy. In general, maybe our hyperparam settings were also not ideal. If you have time, I would of course appreciate it if you can could put it through your benchmark suite"
5495,@rasbt,2022-04-01 22:14:34+00:00,https://twitter.com/rasbt/status/1510017806431051787,"@_lychrel @tszzl @spenceraviav @aniiyengar Yeah, bad naming in my part, and I wish I could take it back but the paper is already submitted üòÖ. Coiledmoid would have definitely been the better name."
5496,@rasbt,2022-04-01 20:11:27+00:00,https://twitter.com/rasbt/status/1509986821907881984,"@giffmana @PyTorch @PyTorchLightnin If you have ImageNet setups ready to go and are interested in that, I‚Äôd be happy to collaborate. Pretty sure it‚Äôs still possible to add you as a co-author if that‚Äôs sounds interesting to you"
5497,@rasbt,2022-04-01 19:32:33+00:00,https://twitter.com/rasbt/status/1509977034637856772,@giffmana @PyTorch @PyTorchLightnin Only CIFAR-10/100 but we can add ImageNet to the appendix. The wiggly thing: we have a theoretical analysis in the paper but conceptually it enables gradient sign flipping in the most active regions such that you can wiggle the loss free in case it gets trapped on saddle points. https://t.co/WWpGoGjgHJ
5498,@rasbt,2022-04-01 19:17:16+00:00,https://twitter.com/rasbt/status/1509973186548584448,"@giffmana @PyTorch @PyTorchLightnin First things first, lol. But I am glad I got you interested. And let me know if you have any questions in the meantime."
5499,@rasbt,2022-04-01 18:54:20+00:00,https://twitter.com/rasbt/status/1509967416264175620,"@hllo_wrld haha fun fact: a couple years prior, I developed pyprind but it never took off: https://t.co/Xnp4uRgOH8"
5500,@rasbt,2022-04-01 18:44:24+00:00,https://twitter.com/rasbt/status/1509964917125832708,@PyTorchLightnin Lightning Storm üòÄ
5501,@rasbt,2022-04-01 17:40:39+00:00,https://twitter.com/rasbt/status/1509948873929904133,"@GaryMarcus Too good to be true: April Fool's.
Too bad to be true ..."
5502,@rasbt,2022-04-01 17:38:39+00:00,https://twitter.com/rasbt/status/1509948369661276161,"It's my favorite day to publish new research!
Fun fact: EfficientNetV2 was published exactly 1 year ago! https://t.co/k1DsW8v1kM"
5503,@rasbt,2022-04-01 14:28:33+00:00,https://twitter.com/rasbt/status/1509900528830066708,"@Abdel_Bentorcha @seanjtaylor Yeah, totally. Btw I first did all my data processing &amp; plotting in R. However, I found certain things clumsy and needed to write custom scripts for data processing, which is why I learned Python ~12 years ago. Today, I find it more convenient to do everything in Python :P"
5504,@rasbt,2022-04-01 13:44:21+00:00,https://twitter.com/rasbt/status/1509889404294381569,"@BEBischof In the ConvNext paper: ""We find that ReLU can be substituted with GELU in our ConvNet too, although the accuracy stays unchanged (80.6%)."" ü§∑‚Äç‚ôÇÔ∏è"
5505,@rasbt,2022-04-01 13:35:54+00:00,https://twitter.com/rasbt/status/1509887281494208515,"@BEBischof Monotonicity is not a requirement. I.e., see GELU &amp; Co. https://t.co/f6aYbEbXya"
5506,@rasbt,2022-04-01 13:09:01+00:00,https://twitter.com/rasbt/status/1509880512315277317,"@hugocunha @PyTorch @PyTorchLightnin Yeah, that's an odd one. We noticed that this can sometimes happen due to gradient sign switching. However, this pretty much isn't an issue in practice if you train to convergence."
5507,@rasbt,2022-04-01 12:16:54+00:00,https://twitter.com/rasbt/status/1509867397464956936,Excited to share our latest research! The Cyclemoid function is inspired by cyclical learning rates and has nice mathematical properties to stabilize gradients. We achieved SOTA on several benchmarks! A @PyTorch impl &amp; @PyTorchLightnin demo are on GitHub: https://t.co/oAYm6rm2dl
5508,@rasbt,2022-04-01 03:33:45+00:00,https://twitter.com/rasbt/status/1509735742783819776,"@seanjtaylor Gnuplot, Java, Perl, maybe R"
5509,@rasbt,2022-04-01 01:20:22+00:00,https://twitter.com/rasbt/status/1509702175567527936,@Ferdous_nayan Hm yeah but Kaiming He has a good track record of uploading the code
5510,@rasbt,2022-04-01 01:16:29+00:00,https://twitter.com/rasbt/status/1509701198273826819,"*Code is unfortunately not available, yet, but the authors promised that it will follow."
5511,@rasbt,2022-04-01 01:16:28+00:00,https://twitter.com/rasbt/status/1509701196864446470,"""Exploring Plain Vision Transformer Backbones for Object Detection:"" Nice, competitive results with decoupled pre-training and fine-tuning stages. I.e, a plain ViT can be pre-trained in a general-purpose fashion before fine-tuning for object-detection https://t.co/urdSrpJh1E https://t.co/UKTgKu3lrh"
5512,@rasbt,2022-03-31 21:58:46+00:00,https://twitter.com/rasbt/status/1509651441576824841,"@unfoldds @marktenenholtz @Richard_thaler1 Yeah, I agree. Having been there, it is actually really hard to create and update a syllabus ... I mean from a bureaucracy perspective."
5513,@rasbt,2022-03-31 20:57:04+00:00,https://twitter.com/rasbt/status/1509635914137579521,"Finally some numbers: ""In tests, a 395 billion-parameter MoE model took 20 hours to train running on 8,000 H100s, while it took 7 days running on the same number of A100s."" (via @DeepLearningAI_'s recent newsletter)"
5514,@rasbt,2022-03-31 15:35:31+00:00,https://twitter.com/rasbt/status/1509554994659434507,"@kchonyc @samscub This worked, thanks!"
5515,@rasbt,2022-03-31 15:31:31+00:00,https://twitter.com/rasbt/status/1509553989653778441,"Thanks so much for these, everyone! Hearing from you that this is something useful is one of the highlights of my day! Also just saw that there were 50(!) reviews on Amazon already, thanks so much for the support ‚ò∫Ô∏è https://t.co/Jo98IASEkN"
5516,@rasbt,2022-03-31 04:04:47+00:00,https://twitter.com/rasbt/status/1509381167132327937,@tunguz @scikit_learn That is true. The good performance is maybe not despite but because of the fewer hyperparameter options: less tuning and hence less chance to overfit to the validation folds üôÑ
5517,@rasbt,2022-03-30 23:57:11+00:00,https://twitter.com/rasbt/status/1509318855264546816,@jsut_monkey @__mharrison__ @ducha_aiki Only the old pro afaik
5518,@rasbt,2022-03-30 23:46:42+00:00,https://twitter.com/rasbt/status/1509316216741154826,@TaliaRinger *The book needs to be really good so I look forward to going to bed and read.
5519,@rasbt,2022-03-30 23:46:08+00:00,https://twitter.com/rasbt/status/1509316076286402565,"@TaliaRinger make it ritual to read a really good book (usually a novel) until I get sleepy (like 30 min lol), and then I switch to an audiobook with a 10 min timer. Without that I keep thinking and planning, which is not very conducive to falling asleep."
5520,@rasbt,2022-03-30 22:16:15+00:00,https://twitter.com/rasbt/status/1509293455679397888,@johnny_83 @GreeneScientist @localee_compact @FertigLab @siminaboca @biodataguy @evan_cofer @1AlexanderTitus @Benjamin_D_Lee @alxndrkalinin but that would be so boring &amp; last decade üòÖ
5521,@rasbt,2022-03-30 22:00:00+00:00,https://twitter.com/rasbt/status/1509289362852392967,@dmarthal @ogrisel or just cupy
5522,@rasbt,2022-03-30 21:55:07+00:00,https://twitter.com/rasbt/status/1509288134252580865,"@katsiferis Hm, maybe for the appendix. I don't think Brier score is super meaningful for models with uncalibrated probabilities like kNN, decision trees, etc."
5523,@rasbt,2022-03-30 20:58:43+00:00,https://twitter.com/rasbt/status/1509273942246273026,"Actually, @scikit_learn is all we need! 
In my experience, the HistGradientBoostingClassifier (a reimplementation of LightGBM) sometimes even slightly outperforms the others in my applications :)"
5524,@rasbt,2022-03-30 20:17:43+00:00,https://twitter.com/rasbt/status/1509263622685528064,@Jeande_d üíØ And that decision tree is almost on par with the random forest!
5525,@rasbt,2022-03-30 20:15:14+00:00,https://twitter.com/rasbt/status/1509263000791826442,"If your monitor is too low, I recommend getting two copies üòÜ"
5526,@rasbt,2022-03-30 18:21:03+00:00,https://twitter.com/rasbt/status/1509234262423355393,@Kaszanas @Michael_J_Black üíØ
5527,@rasbt,2022-03-30 18:20:22+00:00,https://twitter.com/rasbt/status/1509234092663058432,*quite literally. My most cited paper on Google Scholar is an arxiv preprint :)
5528,@rasbt,2022-03-30 18:17:04+00:00,https://twitter.com/rasbt/status/1509233263533084675,"If you want to maximize impact, upload a preprint to @arxiv  üôÉ"
5529,@rasbt,2022-03-30 17:41:35+00:00,https://twitter.com/rasbt/status/1509224331754233865,"@twimlai Haha, it's turtles, ehm, Python all the way down üôÉ"
5530,@rasbt,2022-03-30 16:46:25+00:00,https://twitter.com/rasbt/status/1509210449535021065,"@Kaszanas @Michael_J_Black the first two were creative, but yeah, it's too much, it's not creative anymore"
5531,@rasbt,2022-03-30 16:05:56+00:00,https://twitter.com/rasbt/status/1509200260949753863,@anuragsaharoy 3) Regarding the MLP + embedding paper you mentioned. I read it but haven't tried it yet. But thanks for reminding me. The author just shared the relevant code portions with me and I wanted to follow-up on that when I have time. https://t.co/LFWSr3HOcG
5532,@rasbt,2022-03-30 16:04:04+00:00,https://twitter.com/rasbt/status/1509199790256664578,@anuragsaharoy Number 2 :) https://t.co/mRaHuPWari
5533,@rasbt,2022-03-30 16:03:34+00:00,https://twitter.com/rasbt/status/1509199663496318976,@anuragsaharoy Sure. There are multiple things to this answer. 1) There is typically no single method that is always best (even on tabular datasets) https://t.co/Wq73BWDpnJ
5534,@rasbt,2022-03-30 15:46:18+00:00,https://twitter.com/rasbt/status/1509195319795400709,"Hah, coincidentally also on that note: https://t.co/hHaBZRcR1Q"
5535,@rasbt,2022-03-30 15:21:51+00:00,https://twitter.com/rasbt/status/1509189168412438533,"@micahjsmith E.g., I have one project with real-world data right now where an MLP + embeddings outperforms XGBoost, LightGBM, and CatBoost on a tabular dataset with a mix of categorical and numerical data."
5536,@rasbt,2022-03-30 15:20:22+00:00,https://twitter.com/rasbt/status/1509188794574159876,"@micahjsmith Yeah, it's the classic ""no free lunch"" in ML. Saying that there is no best model across all datasets was very popular back then (which is why we needed to at least try a handful of models). I feel like today people sometimes forget that :)"
5537,@rasbt,2022-03-30 15:19:01+00:00,https://twitter.com/rasbt/status/1509188454676111366,Another interesting tidbit is that the KNN has a non-zero training time :). But it's probably from using a KD- or Ball-tree data structure to partition the dataset for faster querying.
5538,@rasbt,2022-03-30 15:14:50+00:00,https://twitter.com/rasbt/status/1509187400962129924,"* correction: ""The circle size reflects the *accuracy* standard deviation"". This probably explains why the circles are not elliptical. Maybe a bit misleading to use circles here then."
5539,@rasbt,2022-03-30 15:11:47+00:00,https://twitter.com/rasbt/status/1509186635119960073,@KMarwatov Yeah that's odd.
5540,@rasbt,2022-03-30 15:11:10+00:00,https://twitter.com/rasbt/status/1509186479414784012,@danilotat @ducha_aiki Haven't tried it yet since I mostly use PyTorch. I'll probably wait until they add native support for the M1 GPU.
5541,@rasbt,2022-03-30 15:07:10+00:00,https://twitter.com/rasbt/status/1509185470525280260,"This is a nice paper, but in my experience, your mileage may vary (a lot) depending on the dataset. 
On a different note, I really like this visual (compared to the standard accuracy tables) since it also includes training time. The bubble size represents the standard deviation."
5542,@rasbt,2022-03-30 13:43:45+00:00,https://twitter.com/rasbt/status/1509164480395157509,"@ducha_aiki Torn on the size for traveling: I love the 16 inch of the MBP for traveling if I use the computer a lot (working on 13 inch screen is just too small and I am too hunched over). On the flipside, I like the smaller weight and size of the MBAir while carrying it around."
5543,@rasbt,2022-03-30 13:41:48+00:00,https://twitter.com/rasbt/status/1509163990471127047,"@ducha_aiki Have both the MBAir (personal) and the MBP (work), so here comes my list. MBP: more RAM (32 &amp; 64 Gb), faster GPU (e.g., if you do stuff in Final Cut Pro), 3 instead of 2 USB-C ports, HDMI port. MBAir: love the portability, also great value for the money. Probably my fav computer."
5544,@rasbt,2022-03-30 13:28:54+00:00,https://twitter.com/rasbt/status/1509160743677186062,"@tunguz @marktenenholtz Devil‚Äôs advocate: ‚ÄúI skate to where the puck is going, not where it has been.‚Äù üôÉ"
5545,@rasbt,2022-03-30 01:13:09+00:00,https://twitter.com/rasbt/status/1508975584071884803,@GreeneScientist @bffo @localee_compact @FertigLab @siminaboca @biodataguy @evan_cofer @1AlexanderTitus @Benjamin_D_Lee @alxndrkalinin The infamous 0-indexing glitch from too much Python coding üôÉ
5546,@rasbt,2022-03-29 20:24:27+00:00,https://twitter.com/rasbt/status/1508902930207883282,"@psteinb_ Thanks! Yeah, it could have been a more general article ü§î -- the computational bio context is really just to set a scope for the cited examples"
5547,@rasbt,2022-03-29 17:22:02+00:00,https://twitter.com/rasbt/status/1508857023588454400,@__mharrison__ They don't have a stable wifi connection and thus using Keynote/Powerpoint/Google Slides in the browser might be flaky ü§î
5548,@rasbt,2022-03-29 16:50:45+00:00,https://twitter.com/rasbt/status/1508849153266401294,"@themintsv @karpathy Yeah, I think for small datasets, doing epochs works better. For larger datasets (say 100k samples and up) I honestly don't really notice a difference. (I usually do epochs though because it is easier for keeping track in an academic research context)"
5549,@rasbt,2022-03-29 16:42:56+00:00,https://twitter.com/rasbt/status/1508847184040665095,"@themintsv @karpathy Yeah, basically like this below on the right, but with minibatches instead of single training examples. https://t.co/nD3mgmKsSC"
5550,@rasbt,2022-03-29 16:30:03+00:00,https://twitter.com/rasbt/status/1508843940803403781,@jacopotagliabue @TDataScience Awesome! Please share a link to the workshop page when it goes online
5551,@rasbt,2022-03-29 13:49:51+00:00,https://twitter.com/rasbt/status/1508803626025824277,"@karpathy And, one step further, drawing *independent* random samples (iterations) makes also helps with studying certain properties mathematically (in statistics, that's also sometimes referred to as ""true"" SGD)"
5552,@rasbt,2022-03-29 12:49:08+00:00,https://twitter.com/rasbt/status/1508788345379467274,"üß¨Ten Quick Tips for Deep Learning in Biologyüß¨ 
from our massive(ly productive) collaboration just got published.
We discuss essential topics such method choice, model baselines, data context, reproducibility, interpretability, research ethics, and more: 
https://t.co/VITEYGXjgB https://t.co/XG33cn4bIL"
5553,@rasbt,2022-03-29 03:50:21+00:00,https://twitter.com/rasbt/status/1508652757074518017,"@TaliaRinger Hah, you are not the only one üòÖüòä"
5554,@rasbt,2022-03-29 03:48:56+00:00,https://twitter.com/rasbt/status/1508652400441233408,"@TragicHero628 I had similar questions, which is maybe why it‚Äôs hard to think about what should or could go into the intersections. (The figure is from the article I linked)"
5555,@rasbt,2022-03-29 03:45:10+00:00,https://twitter.com/rasbt/status/1508651453665185792,"@TaliaRinger I would totally audit classes myself, it‚Äôs just hard to find time for it so I usually stick with online classes I can take whenever, like in the early morning or evening üòÖ"
5556,@rasbt,2022-03-29 03:43:18+00:00,https://twitter.com/rasbt/status/1508650981680160770,"@TaliaRinger Oh yes for sure. I had profs who wanted to learn about ML / DL auditing my classes several times. Usually they would contact me about that beforehand and ask if it‚Äôs ok ‚Äî my guess is that‚Äôs the etiquette to avoid awkward situations, but I think it‚Äôs totally cool"
5557,@rasbt,2022-03-29 03:23:39+00:00,https://twitter.com/rasbt/status/1508646040169291777,@neuralvis @TheZachMueller @1Password Same. It‚Äôs so good that changing didn‚Äôt even cross my mind
5558,@rasbt,2022-03-29 02:04:51+00:00,https://twitter.com/rasbt/status/1508626209273491461,"Has it already been 12 years? My data science journey started with the now all-too-familiar Venn diagram. Regarding MLOps, not being able to fill in the blanks tells me that I am not quite there yet. Any fav suggestions? 
This is a great article btw: https://t.co/rfI8wogs3G https://t.co/LVaTO3jqFA"
5559,@rasbt,2022-03-28 23:30:17+00:00,https://twitter.com/rasbt/status/1508587309595246597,"@Thom_Wolf @huggingface @_lewtun @lvwerra Congrats on the book, that's an awesome achievement! Just got a copy as well and will be looking forward to reading! https://t.co/XvJlBRDiGn"
5560,@rasbt,2022-03-28 19:47:11+00:00,https://twitter.com/rasbt/status/1508531165766074371,"This was fun! Had a great time chatting with 
@samcharrington on @twimlai. We had lots of interesting stuff to talk about, including machine learning education, deep ordinal regression, modern deep learning frameworks, and some fun anecdotes!
https://t.co/bnyHmVefYJ"
5561,@rasbt,2022-03-28 14:15:58+00:00,https://twitter.com/rasbt/status/1508447811771109379,@prthgo @AniTho2910 Just remembered that I also put up some resources up here if useful: https://t.co/R3B1AHnGfE. Would really check for some more comprehensive courses on Coursera or Udacity though
5562,@rasbt,2022-03-28 14:14:02+00:00,https://twitter.com/rasbt/status/1508447326922473474,"@prthgo @AniTho2910 Browsed the early drafts and it looked good indeed. I think it is more for people who already have some math background and need some review. For beginners, I would maybe recommend looking for algebra, calculus, stats, and linear algebra intro courses on Coursera prior to this."
5563,@rasbt,2022-03-28 01:49:31+00:00,https://twitter.com/rasbt/status/1508259960064552971,"@xamat I may be totally misunderstanding what @therriaultphd‚Äôs company is about ‚Ä¶ if not, it think @civin_co is maybe sth like that?"
5564,@rasbt,2022-03-28 01:46:50+00:00,https://twitter.com/rasbt/status/1508259283955159041,"@prthgo If you are like me, you‚Äôd probably find it tedious and boring. I‚Äôd probably also not recommend this route and rather say: mix it up with applications and implementations to keep you motivated. But I am not sure I‚Äôd call that time ‚Äúwasted‚Äù üôÉ"
5565,@rasbt,2022-03-27 22:54:01+00:00,https://twitter.com/rasbt/status/1508215794043301892,"@karpathy Enjoy the well-deserved sabbatical. And happy learning üöÄ! There are so many interesting things to you around with, from academic research to production. I am sure you won‚Äôt be bored üòä"
5566,@rasbt,2022-03-27 17:27:19+00:00,https://twitter.com/rasbt/status/1508133577887608833,@liftingcovered Sure please feel free to post if it‚Äôs not too complicated. Or maybe a blog post format would work better for it?  It might be useful for others. Also happy to bookmark it and give it a try when I am back home. It might be useful for in seminar contexts in the future.
5567,@rasbt,2022-03-27 17:11:59+00:00,https://twitter.com/rasbt/status/1508129721418059778,@liftingcovered Good question! We only had asynchronous online or in-person teaching formats so I never got to try this setup.
5568,@rasbt,2022-03-27 15:33:57+00:00,https://twitter.com/rasbt/status/1508105047300661252,@tashay_g Happy birthday! üéÇ
5569,@rasbt,2022-03-27 15:32:01+00:00,https://twitter.com/rasbt/status/1508104560937635843,"@liuzhuang1234 @ylecun Awesome, congrats! üéâ It‚Äôs an amazing paper!"
5570,@rasbt,2022-03-26 22:09:08+00:00,https://twitter.com/rasbt/status/1507842114004176900,"@xamat if this was a rage post, I am no particularly excited about what's coming next üòÜ"
5571,@rasbt,2022-03-26 22:08:29+00:00,https://twitter.com/rasbt/status/1507841950321287169,"@xamat On that note, maybe the title could reflect the text focus, but maybe that's overkill"
5572,@rasbt,2022-03-26 22:08:05+00:00,https://twitter.com/rasbt/status/1507841847707664388,"@xamat I had some but then did a cmd+F search, and it looks like you pretty much covered all the relevant ones üòä (but yeah, I am probably also not the domain expert in this area as I usually work more with vision models)"
5573,@rasbt,2022-03-26 21:55:24+00:00,https://twitter.com/rasbt/status/1507838657754935296,@xamat Haha sure. This blog post is really well done. That‚Äôs (medium-)rare these days! Love it.
5574,@rasbt,2022-03-26 20:24:40+00:00,https://twitter.com/rasbt/status/1507815824022671360,"@q_hibernator @burkov I do think that it could also be the shared work among collaborators. Everyone chimes in a bit. I don‚Äôt have the link handy, but there was a recent study showing that outsourcing data labeling usually results in lower quality labelings"
5575,@rasbt,2022-03-26 20:19:19+00:00,https://twitter.com/rasbt/status/1507814475260260352,"@q_hibernator @burkov I get that, but rerunning hyperparameter sweeps is also not that intellectually stimulating :P"
5576,@rasbt,2022-03-26 20:11:08+00:00,https://twitter.com/rasbt/status/1507812418021326848,@burkov This! How many researcher &amp; engineering days (comparing and fine tuning models) could be saved by just spending a few more hours on labeling more data
5577,@rasbt,2022-03-26 16:35:55+00:00,https://twitter.com/rasbt/status/1507758254146809861,@xamat That looks like a really nice and succinct overview!
5578,@rasbt,2022-03-26 15:35:45+00:00,https://twitter.com/rasbt/status/1507743112021479426,@kchonyc and an e-reader if you really want to show off üòâ
5579,@rasbt,2022-03-25 17:37:41+00:00,https://twitter.com/rasbt/status/1507411412469039112,@porestar @rahuldave @marktenenholtz Good idea. And scaffold splits@for comp bio contexts
5580,@rasbt,2022-03-25 15:34:06+00:00,https://twitter.com/rasbt/status/1507380311281356810,"@rahuldave @marktenenholtz Of course! There's always more to add :). The one section I really want to add some time is on calibration. Btw. permutation importance is in the feature selection lecture, but yeah, model evaluation and interpretation are closely connected."
5581,@rasbt,2022-03-25 13:40:46+00:00,https://twitter.com/rasbt/status/1507351787963101194,"@ChurchillMic E.g. here is a minimal context: https://t.co/YNpE8XfTYq In `trainer = pl.Trainer(...)`, you can set `strategy='ddp'` for distributed data parallel or `strategy='fsdp'` for the fully sharded version etc. TorchMetrics works with all of that out of the box w/o changes required."
5582,@rasbt,2022-03-25 13:33:22+00:00,https://twitter.com/rasbt/status/1507349928590385155,"@ChurchillMic Yes, it does, and I have! In fact, it was specifically designed for this purpose :)."
5583,@rasbt,2022-03-25 12:48:24+00:00,https://twitter.com/rasbt/status/1507338609606774829,@zacharylipton @fhuszar @niljanaakpinar @natrokh @samcharrington @ykilcher @risteski_a @tlbtlbtlb @jonkhler @ProfvLilienfeld @TerencePlizga @tom_suhr @steverab Seufz üò©
5584,@rasbt,2022-03-25 12:36:22+00:00,https://twitter.com/rasbt/status/1507335583579967492,"@marktenenholtz Yes, this! I am usually overdoing it and go through the whole list of topics from https://t.co/aYvW168wLF üòÖ. The ideal coverage is maybe somewhere in between üôÑ"
5585,@rasbt,2022-03-25 12:31:37+00:00,https://twitter.com/rasbt/status/1507334387817500699,"@Durbangash Wow! Enjoy Spring, Paris ‚Ä¶ and the book!"
5586,@rasbt,2022-03-24 20:22:05+00:00,https://twitter.com/rasbt/status/1507090398258290689,"Since it's a super helpful library for computing metrics in deep learning, and since there are a few common questions about it, I just wrote a short post on 
""TorchMetrics -- How do we use it, and what's the difference between .update() and .forward()?"" https://t.co/RtxIPRvHTv"
5587,@rasbt,2022-03-24 15:12:31+00:00,https://twitter.com/rasbt/status/1507012491682799620,"@arnabbiswas1 @tunguz Yeah, actually many of my books are digital. And I also donate most of my books every few years, so the ones I showed are by no means an exhaustive less."
5588,@rasbt,2022-03-24 03:50:07+00:00,https://twitter.com/rasbt/status/1506840759743434755,@kakrafoon2 @tunguz *here ‚Äúit‚Äù refers to the 3rd edition on the shelf
5589,@rasbt,2022-03-24 03:48:59+00:00,https://twitter.com/rasbt/status/1506840472752627713,"@kakrafoon2 @tunguz I got it because I was teaching an stats class last year, and the plan was to use portions as additional resources to the mandatory textbook. You can actually check the PDF here https://t.co/yKubTAHuOx"
5590,@rasbt,2022-03-24 03:48:31+00:00,https://twitter.com/rasbt/status/1506840358679977988,@kakrafoon2 @tunguz Read the first edition in 2010ish when it was new (back then it was super awesome because the online version was free compared to buying overpriced stats textbooks for my classes). Haven‚Äôt really read the 3rd edition though but it is probably still sth it‚Äôd recommend
5591,@rasbt,2022-03-24 03:15:04+00:00,https://twitter.com/rasbt/status/1506831937570283521,"@themintsv @Jeande_d ""remember effnet authors replying to the regnet authors' tweet, and criticizing the comparison to v1 and not v2, which they claimed to be better than regnets.""  But hold on a sec. If the EffNet v2 (2021) paper came after RegNets (2020), how could the RegNet authors have known? ü§î"
5592,@rasbt,2022-03-24 03:12:03+00:00,https://twitter.com/rasbt/status/1506831179521138694,"@themintsv @Jeande_d ""Our EfficientNetV2 models also significantly outperform all re- cent RegNet and ResNeSt, in both accuracy and inference speed. Figure 1 further visualizes the comparison on train- ing speed and parameter efficiency."" Totally forgot that RegNet was older that EfficientNet v2! üòÖ https://t.co/4lnYEaAJIn"
5593,@rasbt,2022-03-24 03:09:37+00:00,https://twitter.com/rasbt/status/1506830567542829058,"@themintsv @Jeande_d Oh, thanks for clarifying."
5594,@rasbt,2022-03-24 03:01:43+00:00,https://twitter.com/rasbt/status/1506828577727209472,@hiydavid @tunguz üëå
5595,@rasbt,2022-03-24 00:35:34+00:00,https://twitter.com/rasbt/status/1506791798928297986,@MDavidHansen @tunguz @__mharrison__ No worries lol üòÜ. You have permission to continue using my book as a course text üòÜ
5596,@rasbt,2022-03-24 00:25:22+00:00,https://twitter.com/rasbt/status/1506789232559509504,"@MDavidHansen @tunguz Sry but you got that wrong, I am not the pandas guy (CC @__mharrison__ ). I do sometimes work with pandas, though üòÖ https://t.co/kfDyyVEzrj https://t.co/tdPgXW5zby"
5597,@rasbt,2022-03-24 00:16:56+00:00,https://twitter.com/rasbt/status/1506787111776698371,@Jeande_d Really nice! Btw do you know if it‚Äôs EfficientNet v2?
5598,@rasbt,2022-03-24 00:14:14+00:00,https://twitter.com/rasbt/status/1506786430303064071,@giffmana The prohibitive cost of learning about a few new tools and techniques that help you accomplish that for free üòú
5599,@rasbt,2022-03-23 23:25:49+00:00,https://twitter.com/rasbt/status/1506774247024340994,"@paul_rietschka @tunguz speaking of which, are you mainly rolling your own via the xformers library or are you mainly fine-tuning huggingface transformers? Not advertising or judging, just curious."
5600,@rasbt,2022-03-23 23:16:48+00:00,https://twitter.com/rasbt/status/1506771976228069388,"@tunguz @paul_rietschka Yeah. Even if they are not SOTA, they are still a good baseline. E.g., consider something small like the classic IMDB dataset. Logistic regression 85% acc in 5 min if you only have a CPU, RNNs 89% acc in like 5 min if you have a GPU, fine-tuning BERT 92% acc on a GPU in 1/2 a day"
5601,@rasbt,2022-03-23 23:08:36+00:00,https://twitter.com/rasbt/status/1506769911812603904,"@tunguz @paul_rietschka Can second that. I learned it mostly by doing. When I was a grad student, I had a fantasy soccer prediction with ML side project where I was using pandas for the data munging. Basically, I automated everything, including querying the latest line-ups and injuries from websites"
5602,@rasbt,2022-03-23 22:38:29+00:00,https://twitter.com/rasbt/status/1506762332801802243,"@ZechinD @tunguz Most of the bottom-shelf ones involve tools, but I would say that all of them stood the test of time. They are all still very relevant. Ok, the generative DL one is maybe the one that is least timeless, but it is still a good intro I'd recommend for a quick read."
5603,@rasbt,2022-03-23 20:48:36+00:00,https://twitter.com/rasbt/status/1506734679705149440,@tunguz I categorized mine by fun and not so fun (but still super informative). Guess which row is which üôÉ https://t.co/zY2vMoyUBX
5604,@rasbt,2022-03-23 20:42:49+00:00,https://twitter.com/rasbt/status/1506733226961874958,@Jeande_d @tunguz üòÇ thanks üòä
5605,@rasbt,2022-03-23 20:40:19+00:00,https://twitter.com/rasbt/status/1506732596201410560,@TheZachMueller @BecomingDataSci Sometimes I wonder how much better students would be prepared for the job market if instructors just used GitHub Classroom instead of Canvas.
5606,@rasbt,2022-03-23 19:35:37+00:00,https://twitter.com/rasbt/status/1506716313150005259,"@alfcnz Sometimes I feel like you are too multi-headed! Pay more *attention* to the details, Alf! üòú"
5607,@rasbt,2022-03-23 18:44:44+00:00,https://twitter.com/rasbt/status/1506703507637813257,"@NatTrask I mean it's kind of like with books. Are eg Amazon ratings necessary? Probably not. But yeah, it smtms helps with identifying really bad stuff you probably don't want to buy. In the case of papers, it could help filtering out the really bad stuff (plagiarism, wrong results, etc)"
5608,@rasbt,2022-03-23 18:41:57+00:00,https://twitter.com/rasbt/status/1506702807059021828,"@NatTrask Sure, there are risks and problems with that. But a scoring system could potentially help with pushing people towards better practices, such sharing code, creating legible figures, clear organization &amp; writing, technical sound experiments, (confidence intervals!) etc."
5609,@rasbt,2022-03-23 17:31:34+00:00,https://twitter.com/rasbt/status/1506685095746453511,@josegalaz_ @JOSS_TheOJ TIL my most cited peer-reviewed paper is actually a @JOSS_TheOJ  paper ü•≥ (https://t.co/8W2Wo1k0jw)
5610,@rasbt,2022-03-23 17:28:51+00:00,https://twitter.com/rasbt/status/1506684411684741121,"@josegalaz_ @JOSS_TheOJ It's a bit different because it's still for invited reviewers. But generally yes, I like it a lot! :)"
5611,@rasbt,2022-03-23 14:44:52+00:00,https://twitter.com/rasbt/status/1506643143319597063,"@roydanroy Yeah, there is room for improvement. It could be made more similar to Rotten Tomatoes with a separate  professional peer-reviewer Tomatometer and an Audience score."
5612,@rasbt,2022-03-23 13:45:56+00:00,https://twitter.com/rasbt/status/1506628313527291913,"@moreisdifferent Yeah, there needs to be a gamification like stackoverflow. Also it doesn‚Äôt need to be a replacement for the traditional peer review but just a place to add comments and have discussions (similar to Reddit). But re the original point: how do you incentivize traditional reviews?"
5613,@rasbt,2022-03-23 12:37:28+00:00,https://twitter.com/rasbt/status/1506611081778716675,"@samoalfred @roydanroy There was a hint of sarcasm in there üòÖ. But to be honest, when I submitted to conferences, I sometimes had the impression that reviewers were totally unfamiliar with the topic."
5614,@rasbt,2022-03-23 12:31:44+00:00,https://twitter.com/rasbt/status/1506609639529529350,@roydanroy The fact that everyone can leave a review and rating rather than a somewhat randomly chosen group of 3 people?
5615,@rasbt,2022-03-23 04:14:51+00:00,https://twitter.com/rasbt/status/1506484595105189892,"@Suleymanzade Oh no üôà. I wanted to imply that if there is no universal GPU for AI and bitcoin mining, it would probably be a good thing (coz less Bitcoin mining and more GPUs in stock for AI) üòÖ"
5616,@rasbt,2022-03-23 04:02:45+00:00,https://twitter.com/rasbt/status/1506481552846434304,@Suleymanzade *bitcoin mining
5617,@rasbt,2022-03-23 03:08:10+00:00,https://twitter.com/rasbt/status/1506467816089833477,@iamtrask üò¨ I see what you did there
5618,@rasbt,2022-03-23 02:56:24+00:00,https://twitter.com/rasbt/status/1506464854982418436,"@BenTheEgg yeah, I guess 6x transformer performance is probably more intuitive than throwing 4000 TFLOPS into the room üòÜ"
5619,@rasbt,2022-03-23 02:41:12+00:00,https://twitter.com/rasbt/status/1506461029361930240,From transformers is all we need to transformers is all we care about üôÉ https://t.co/sgHDDI3YFi
5620,@rasbt,2022-03-23 02:31:49+00:00,https://twitter.com/rasbt/status/1506458666215559173,@wjarek @jefrankle @nader_ghaffari @VentureScanner Double +1! This is a beautiful way to put it.
5621,@rasbt,2022-03-23 02:30:11+00:00,https://twitter.com/rasbt/status/1506458255911964676,"@wjarek @jefrankle @nader_ghaffari @VentureScanner I usually have a slide on specialized chips as alternatives to GPUs for deep learning. I am actually not sure what the actual landscape looks like right now (except TPUs and IPUs), but I remember Chris Lattner talking about SiFive and that got me interested to watch this space :)"
5622,@rasbt,2022-03-23 02:22:40+00:00,https://twitter.com/rasbt/status/1506456364750675973,"@jefrankle @wjarek @nader_ghaffari @VentureScanner What's nice is that these are all synergistic, and I think we should pursue them all: new efficient chip architectures, more env friendly sources of electricity, more efficient algorithms, better tooling to take advantage of existing and idle hardware"
5623,@rasbt,2022-03-23 02:18:39+00:00,https://twitter.com/rasbt/status/1506455352719679495,"2/2 So, here the authors propose the so-called VOS framework to synthesize outliers for regularizing the decision boundary. They model the in-distribution data as class-conditional Gaussians and then sample from the low-likelihood regions. https://t.co/oCid7K7xjU"
5624,@rasbt,2022-03-23 02:18:38+00:00,https://twitter.com/rasbt/status/1506455351314591748,"Last year, I attended a seminar on issues with deep neural network classifiers &amp; overconfident predictions on out-of-distribution data. Haven't dug too deeply into all the literature, yet, but this seems like an interesting recent paper: 
https://t.co/8VcMerw4Ni
1/2"
5625,@rasbt,2022-03-23 00:52:51+00:00,https://twitter.com/rasbt/status/1506433761449484288,"@jefrankle The way I see it, sadly, 2x more efficient algorithms will just make people run twice the number or hyperparameter configurations üòú"
5626,@rasbt,2022-03-23 00:43:44+00:00,https://twitter.com/rasbt/status/1506431468276523011,@jefrankle You maybe haven‚Äôt upgraded to an M1 Mac yet üòÖ
5627,@rasbt,2022-03-23 00:37:50+00:00,https://twitter.com/rasbt/status/1506429982754721800,@jefrankle Why not both? Better and more efficient hardware paired with more efficient algorithms?
5628,@rasbt,2022-03-22 22:52:05+00:00,https://twitter.com/rasbt/status/1506403367286980617,@yoavgo @roydanroy @erishabh I don‚Äôt have any answers to your questions because I see it exactly the same way üòÖ
5629,@rasbt,2022-03-22 22:39:23+00:00,https://twitter.com/rasbt/status/1506400171478892549,"@roydanroy @erishabh @yoavgo There is obviously a sweet-spot somewhere in-between, but I feel like these days there is too much emphasis on hiring to maximize number of papers and grants vs actually wanting to teach &amp; train people."
5630,@rasbt,2022-03-22 22:31:41+00:00,https://twitter.com/rasbt/status/1506398235224690695,"@tmarzagao Nice, I didn't know about ResearchHub!"
5631,@rasbt,2022-03-22 22:23:18+00:00,https://twitter.com/rasbt/status/1506396127167401984,"Looking at some papers I recently read ... My guess the challenge really is how to handle the overall the star rating üòµ. Maybe thumbs up (well written, convincing results) or thumbs down (missing code, no confidence intervals, etc.) for individual categories would be easier üòÖ"
5632,@rasbt,2022-03-22 22:17:47+00:00,https://twitter.com/rasbt/status/1506394735526785031,"Finally! After all these years dreaming this up, someone put together a social peer review platform that lets you upvote papers and leave comments. This + arxiv üëå. (Ok, the challenge will be to detect fake comments and votes, but at least it's a start.) https://t.co/Kw3kJOMQ04 https://t.co/d6dxnSr0LC"
5633,@rasbt,2022-03-22 21:46:32+00:00,https://twitter.com/rasbt/status/1506386872259461127,"@tdietterich @mark_riedl 2/2 But for the end user, I think this is still not the solution to the problem? Maybe instead of focusing on classifiers, we really want more like VQA systems with multiple levels of hierarchies for predetermined concepts that people can query?"
5634,@rasbt,2022-03-22 21:46:08+00:00,https://twitter.com/rasbt/status/1506386774406438915,"@tdietterich @mark_riedl Thanks. Yeah, I can see something like that as super useful for auditing e.g., medical image classifiers. Here, you modify latent spaces/images according to some predetermined concepts and check whether the classifier picks up on that. 1/2"
5635,@rasbt,2022-03-22 21:25:09+00:00,https://twitter.com/rasbt/status/1506381489902166026,"@mark_riedl @tdietterich E.g., in an image context, how would you solve this problem as long as models are susceptible to changing individual pixels? You would need to change the nature of the models such that they create intermediate, human-readable/interpr concepts that the classifications are based on"
5636,@rasbt,2022-03-22 19:57:56+00:00,https://twitter.com/rasbt/status/1506359543571304449,@mattvanh83 @PyTorch @huggingface The transformer chapter was one of my favorites to work on! Have fun!!
5637,@rasbt,2022-03-22 19:28:47+00:00,https://twitter.com/rasbt/status/1506352208064958466,"@themintsv Yes it's skyrocketing indeed‚ò∫Ô∏è. (PS: I did submit to journals btw., it was kind of necessary for grants and annual reviews; and I found journals a bit easier to work with since there are no deadlines, no super strict page limits, and often better review comments) https://t.co/dsTkDvpatH"
5638,@rasbt,2022-03-22 19:07:15+00:00,https://twitter.com/rasbt/status/1506346789758283776,"Whoa, that's quite a steep growth at ICML. Do they have a better virtual setup, better timing, more interesting papers, or is it just more fun to attend? https://t.co/8fb26N8jmq"
5639,@rasbt,2022-03-22 19:03:09+00:00,https://twitter.com/rasbt/status/1506345755396739072,"Flipping through the recent AI Index report for 2022 (https://t.co/B5Dk8qQNuZ). Some pretty interesting, almost unexpected trends: There's a downward trend in the number of conference pubs -- people transitioning to journals? Exciting stuff: more papers host code in repositories! https://t.co/89RQiZqag5"
5640,@rasbt,2022-03-22 00:23:31+00:00,https://twitter.com/rasbt/status/1506063993110155266,@TalkPython Happy birthday üéÇ! And thanks so much for all the value you provide to the Python and open source communities ‚ù§Ô∏è
5641,@rasbt,2022-03-21 23:38:47+00:00,https://twitter.com/rasbt/status/1506052734331629573,"@__mharrison__ The submissions were open to everyone, but I think most (all?) submissions came from academia."
5642,@rasbt,2022-03-21 23:00:15+00:00,https://twitter.com/rasbt/status/1506043037121761289,"@soumithchintala 2/2 I am very grateful that grad school usually pays you as a research assistant. This way I could afford having my own apartment. But on the other hand, it was basically like a reg. job (with a learning component). I am curious to hear what potential alternatives look like."
5643,@rasbt,2022-03-21 22:58:48+00:00,https://twitter.com/rasbt/status/1506042671135182850,"@soumithchintala This! Going to grad school (and studying abroad) was the perfect opportunity (/excuse) for me to move out from my parent‚Äôs home, and it taught me how to live independently and take care of all sorts of things you have to deal with as an adult. 1/2"
5644,@rasbt,2022-03-21 21:27:15+00:00,https://twitter.com/rasbt/status/1506019631458238465,"@jasongfleischer Yeah, that‚Äôd be one approach :). It‚Äôs a chicken-egg problem, but I usually like to show them a small curated list of previous-year projects for inspiration. Also, it helps to have them just pitch their early ideas and you provide them with feedback"
5645,@rasbt,2022-03-21 20:29:17+00:00,https://twitter.com/rasbt/status/1506005046198218754,@BjornHolzhauer @YuraFiftyTwo Actually I found that increasing the number of parameters substantially for LightGBM may lead to better k-fold performance but at the same time I found that it usually leads to way lower test set performance due to overfitting to the k-fold cross validation splits
5646,@rasbt,2022-03-21 16:23:22+00:00,https://twitter.com/rasbt/status/1505943159234351106,"Just discovered this RNN gem: 
""LSTM: A Search Space Odyssey""
https://t.co/nCdF2Abch7
Basically it's a large scale study looking into LSTM variants. While things can be simplified, the forget gate and the output activation function are the most critical parts of the LSTM cell"
5647,@rasbt,2022-03-21 15:27:15+00:00,https://twitter.com/rasbt/status/1505929036555563009,"Personally, I think that class projects are really worthwhile.
They are a lot of work but are very rewarding for both the students (practical experience &amp; sth for the CV) and the teacher (it's always sth unique &amp; interesting vs the standard HW assignments)
https://t.co/Q1LJvDXg4Z"
5648,@rasbt,2022-03-21 15:18:32+00:00,https://twitter.com/rasbt/status/1505926843693772800,"The proceedings of the 2nd Teaching Machine Learning and Artificial Intelligence Workshop are now online: https://t.co/6zsEgN3p8e
It was a fun workshop catching up with colleagues and exchanging tips &amp; tricks about teaching ü§ì"
5649,@rasbt,2022-03-21 02:16:52+00:00,https://twitter.com/rasbt/status/1505730127082139654,"@sama Yeah, things like @Austen 's @bloomtech. My partner did the program when it was still called Lambda School. Upon finishing, she got a senior position at a reputable tech company; her college grad colleagues started as juniors because they were less familiar with the tech stack."
5650,@rasbt,2022-03-21 02:06:13+00:00,https://twitter.com/rasbt/status/1505727448595451908,"@datametrician @RAPIDSai Thx for sharing! Hah, yeah, guess the challenge is the simultaneous dataset reading :P. Totally agree, CPU -&gt; GPU is super expensive and you want to minimize that at all costs. On top of that, what I found interesting is the GPU memory bandwidth concern, minimizing ops in general"
5651,@rasbt,2022-03-20 16:02:33+00:00,https://twitter.com/rasbt/status/1505575530162278401,PS: credits go to @cHHillee for this excellent article!
5652,@rasbt,2022-03-20 16:01:03+00:00,https://twitter.com/rasbt/status/1505575155292164106,"@cHHillee Oh yeah, I agree with you. I was trying to see it from a ""profiling"" lens where all you have is the left panel for now. I'd say from the other 2 panels you see it's likely not overhead bound, which is why I didn't refer to overhead-bound below."
5653,@rasbt,2022-03-20 15:14:39+00:00,https://twitter.com/rasbt/status/1505563474742722560,"9/9 Python can perform 32 million additions per sec, however, PyTorch can only do 280 thousand operations per sec. Interesting, but again not an issue in practice, because we usually use few, large array operations when we work in PyTorch"
5654,@rasbt,2022-03-20 15:14:38+00:00,https://twitter.com/rasbt/status/1505563473547350017,"8/ Interesting tidbit about overhead. Python can perform 32 million additions per sec. But in the time Python requires for 1 FLOP, an A100 GPU can perform 9.75 million FLOPS (but in practice Python overhead is  not an issue because the percentage of time spent there is so small)"
5655,@rasbt,2022-03-20 15:14:38+00:00,https://twitter.com/rasbt/status/1505563472159031306,"7/ In the middle panel we can see that the FLOPS ramp up, and in the right panel we see that the memory bandwidth goes down as we reach 128ish repeats. Meaning that the code switches from being memory-bound to being CPU-bound. https://t.co/cipIwoj283"
5656,@rasbt,2022-03-20 15:14:38+00:00,https://twitter.com/rasbt/status/1505563470833631234,6/ For the following plot we can see that the runtime (left panel) doesn't increase until we reach 32 repeats. So the code is probably mostly memory-bandwidth- and overhead-bound. https://t.co/RglKfkNUCv
5657,@rasbt,2022-03-20 15:14:37+00:00,https://twitter.com/rasbt/status/1505563469646548994,"5/ Anyways, in general, one of the main take-aways is to find out whether your (GPU) code is 
(1) compute-,
(2) memory-,
(3) or overhead-bound.
There's an interesting analysis using the following code: 

def f(x: Tensor[N]):
     for _ in range(repeat):
x=x*2 return x"
5658,@rasbt,2022-03-20 15:14:37+00:00,https://twitter.com/rasbt/status/1505563468329590796,"4/ 
There is the concept of operator fusion -- eg via custom CUDA kernels. 
I know many mathematically inclined folks prefer the elegance of composition: things like torch.log(F.softmax(a)). 
But F.log_softmax(a) is not only better for numeric stability but also efficiency."
5659,@rasbt,2022-03-20 15:14:37+00:00,https://twitter.com/rasbt/status/1505563467092312069,"3/  Because of the memory read &amp; writes, running successive operations can be expensive, even if you already have your data transferred to the GPU 
Eg 4 read &amp; writes:
x1 = x.cos() 
x2 = x1.cos()

vs 2:
x2 = x.cos().cos() 
The latter is still inefficient (unless compiled) though."
5660,@rasbt,2022-03-20 15:14:36+00:00,https://twitter.com/rasbt/status/1505563465783685125,"2/ Different things to consider:

1. Compute: Time the GPU spends on floating point operations (FLOPS) 
2. Memory: Time spent transferring tensors within a GPU
3. Overhead: Everything else (like Python, and the PyTorch API) https://t.co/MNQkm61QSI"
5661,@rasbt,2022-03-20 15:14:36+00:00,https://twitter.com/rasbt/status/1505563464479223810,"Ever had a colleague who wants to apply linear regression to  thousands of small datasets and asked you about a PyTorch-GPU implementation to speed things up? This would be a great article to share, illustrating the different performance bottle necks:
https://t.co/r0zNm8dGWl 1/"
5662,@rasbt,2022-03-20 01:17:29+00:00,https://twitter.com/rasbt/status/1505352798740922377,"@ericjdaza @GulInan5 Hah, I think this was the point: it doesn't have to address machine learning applications :P. I think this was satire re Foundations of Data Science üôÉ"
5663,@rasbt,2022-03-19 23:12:29+00:00,https://twitter.com/rasbt/status/1505321337576906761,@najoungkim And people who also include a link to the corresponding code/GitHub repository ‚ù§Ô∏è‚ù§Ô∏è
5664,@rasbt,2022-03-19 18:26:40+00:00,https://twitter.com/rasbt/status/1505249412070756357,@mahdavi_mahyar @protienking @marksaroufim @aureliengeron I summarized the differences between the current (PyTorch) and the previous (TensorFlow) one here: https://t.co/WsT2MvUom4
5665,@rasbt,2022-03-19 16:44:34+00:00,https://twitter.com/rasbt/status/1505223716564873222,"@protienking @mahdavi_mahyar @marksaroufim @aureliengeron I agree. Another consideration is: how often do you want to use the latest models and research code in general? Right now, 58% of DL research papers use PyTorch and only 10% use TensorFlow. https://t.co/DcWadBnqE3"
5666,@rasbt,2022-03-19 16:00:25+00:00,https://twitter.com/rasbt/status/1505212605799010309,"@nuyorkster @marksaroufim I am not quite there, yet, but how about walking through the code examples with your kids üôÉ"
5667,@rasbt,2022-03-19 15:55:10+00:00,https://twitter.com/rasbt/status/1505211285138558978,@marksaroufim @kushashwa either the best or worst way to spend your Saturday then üò¨
5668,@rasbt,2022-03-19 15:19:09+00:00,https://twitter.com/rasbt/status/1505202221448896518,"Is there a better way to spend the weekend üòÜ? Will join the stream to check in on @marksaroufim  around 4 pm CST (2 pm PST). 
Help me to prepare some tricky questions üòÅ (just kidding ... or maybe not? üòá)"
5669,@rasbt,2022-03-19 14:08:32+00:00,https://twitter.com/rasbt/status/1505184448102477828,"@BjornHolzhauer Sure, if you do that for 10 learning rates, then you maybe have a problem overfitting to the validation folds. But I do think that 2 learning rates is not an issue. It's maybe even a good thing considering as a backup in case the max. max-iters were too small."
5670,@rasbt,2022-03-19 14:07:10+00:00,https://twitter.com/rasbt/status/1505184105348087809,"@BjornHolzhauer Sure, I agree that tuning the learning rate is not necessary. But say you do an extensive hyperparameter tuning for learning rate 0.001, and then you also consider learning rate 1. Considering a second learning rate doesn't suddenly turn a well tuned model into a bad one"
5671,@rasbt,2022-03-19 03:15:53+00:00,https://twitter.com/rasbt/status/1505020203457032193,@dmi3k @AlasfarLina @nj_tierney @rstats_tweets Pearson and Fisher argued about default params in R? üòÜ
5672,@rasbt,2022-03-19 03:11:58+00:00,https://twitter.com/rasbt/status/1505019219905323009,"@kearneymw @cbrnr_ @nj_tierney Yeah, you‚Äôll notice that with small sample sizes or example problems. Found out the hard way years ago when I tried to replicate something where the data was now a pandas DataFrame and not a NumPy array, and I called .std(). I first thought it was a floating point precision error"
5673,@rasbt,2022-03-18 22:43:48+00:00,https://twitter.com/rasbt/status/1504951731515441156,@josueortc @tdietterich I would probably use multiple validation sets to track the improvement. The validation set from the original data. A validation set from the new data. (And a combined validation set.)
5674,@rasbt,2022-03-18 22:41:51+00:00,https://twitter.com/rasbt/status/1504951241251688448,"@josueortc @tdietterich To add to that. Make a backup of your model checkpoint for sure and then compare. Honestly, I wouldn't know which approach is definitely preferred. My guess is it depends on so many things (data set size, model size, model type, etc.)"
5675,@rasbt,2022-03-18 22:31:51+00:00,https://twitter.com/rasbt/status/1504948727789858816,"@bwang482 Yeah, if your dataset is large enough, 1D convolutional nets and recurrent neural networks are classic examples of DL that can work well on such data. But re DL, in this article they only looked at MLPs &amp; transformers that do not assume any spatial relationships betw the features"
5676,@rasbt,2022-03-18 22:02:14+00:00,https://twitter.com/rasbt/status/1504941271420395527,"@bwang482 yeah that's probably right 95% of the time. But I don't think the static aspect has anything to do with arguing for GBDT vs DL. It's more about the fact that there is structured data where DL can't shine via its auto feature learning (e.g., when applied to images)."
5677,@rasbt,2022-03-18 21:43:48+00:00,https://twitter.com/rasbt/status/1504936633505832961,"@bwang482 I think the embeddings are created independently from each other on a feature-by-feature basis. So, the general assumption of independent features applies. But it probably also works for time series data with lag features. I can't see why it wouldn't."
5678,@rasbt,2022-03-18 21:25:46+00:00,https://twitter.com/rasbt/status/1504932096430772228,"@tdietterich On the surface, a simple scenario, but off the top of my head, I can't recommend one of the 3 scenarios over another:
1) Transfer: continue training on new data for a given number of epochs
2) Train on combined dataset from scratch
3) Continue training on the combined dataset"
5679,@rasbt,2022-03-18 21:16:40+00:00,https://twitter.com/rasbt/status/1504929805573230597,"@__mharrison__ *How would you know that you don't have a scenario like EY. I.e., it's worthwhile just trying both. Training MLPs on tabular datasets is super fast (esp on the M1 :P)"
5680,@rasbt,2022-03-18 21:14:06+00:00,https://twitter.com/rasbt/status/1504929158652125191,"@__mharrison__ But in a new real-world application how would you know that? I think the take-away is a) that we don't necessarily require one of the recently proposed fancy architectures for tabular DL and b) the DL can be competitive to GB, and sometimes it's better."
5681,@rasbt,2022-03-18 20:56:09+00:00,https://twitter.com/rasbt/status/1504924640388554759,"@__mharrison__ You mean why gradient boosting doesn't really work well here? PS: For context, EY= Eye movement dataset, and PLR = ReLU - Linear - Periodic activation"
5682,@rasbt,2022-03-18 20:06:41+00:00,https://twitter.com/rasbt/status/1504912191706775570,Kudos to the authors for providing all the code to reproduce the results on GitHub: https://t.co/CEYaR2Etih https://t.co/qVTsgX2W3S
5683,@rasbt,2022-03-18 19:49:28+00:00,https://twitter.com/rasbt/status/1504907858982453251,"3/3 The second one is based on periodic activation functions (inspired by positional encodings). Besides having competitive performance to gradient boosting, it is also interesting to note that with these embeddings, the MLPs are also competitive to transformer-architectures."
5684,@rasbt,2022-03-18 19:49:27+00:00,https://twitter.com/rasbt/status/1504907857719930881,"2/ The authors employ two embedding schemes that are competitive with gradient boosting and apparently result in SOTA performance.

The first embedding scheme is a piecewise-linear encoding involving feature binning. red by positional encodings) https://t.co/z80lB2bDqB"
5685,@rasbt,2022-03-18 19:46:42+00:00,https://twitter.com/rasbt/status/1504907164753739778,"Let the ""Deep Learning for Tabular Data"" saga continue -- it's been a while!
""On Embeddings for Numerical Features in Tabular Deep Learning"" (https://t.co/0Byepm74FD)
This time, the focus is on the embeddings for numerical features rather than proposing a new architecture.* https://t.co/2NcpYvnYlS"
5686,@rasbt,2022-03-18 19:12:20+00:00,https://twitter.com/rasbt/status/1504898516975505411,@VeredShwartz It's everywhere üò≠ https://t.co/oSkimb1r2f
5687,@rasbt,2022-03-18 18:48:01+00:00,https://twitter.com/rasbt/status/1504892396680658946,"7/7 Best of all, the authors provide a PyTorch-compatible package (https://t.co/kw1v2R3HKz) that lets us try it via only 3 lines of code:

for param in model.parameters():
      mup.init.uniform_(param, -0.1, 0.1)

optimizer = MuSGD(model.parameters(), lr=0.1) # or MuAdam"
5688,@rasbt,2022-03-18 18:48:01+00:00,https://twitter.com/rasbt/status/1504892395481145345,"6/ This essentially allows us to find optimal hyperparameters (like learning rate, batch size, etc.) for a small model and then transfer them to our big, expensive model."
5689,@rasbt,2022-03-18 18:48:00+00:00,https://twitter.com/rasbt/status/1504892394256453635,"5/ In turn, the stable training dynamics across model sizes have the nice side-effect that optimal hyperparameter settings are also shared across model sizes. Can you guess where this is going?"
5690,@rasbt,2022-03-18 18:48:00+00:00,https://twitter.com/rasbt/status/1504892393048399879,"4/ So, via their proposed ¬µP method, the researchers provide a parameterization that keeps the activations consistent as model width increases (I think it also generalizes to depth); this helps with stabilizing the gradients and convergence properties."
5691,@rasbt,2022-03-18 18:48:00+00:00,https://twitter.com/rasbt/status/1504892391924326408,"3/ But, yeah, using A100s is expensive (even if we rent them via cloud), and I feel model sizes and resource requirements grow even faster than the hardware can keep up with. Tuning large models can cost a fortune (and lets not forget environmental costs)!"
5692,@rasbt,2022-03-18 18:48:00+00:00,https://twitter.com/rasbt/status/1504892390733189126,"2/ Why is that interesting? Hyperparameter tuning is becoming more and more expensive! Sure, hardware has become faster and faster, too (and training a neural network on my goode olde 1080Ti feels like bringing a Toyota Prius to the race track)."
5693,@rasbt,2022-03-18 18:47:59+00:00,https://twitter.com/rasbt/status/1504892389504266247,"""Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer""  (https://t.co/92EjCJtMYI). This is a really interesting and promising research direction! Essentially, they provide a way to transfer hyperparameters from a small model to a large model 1/"
5694,@rasbt,2022-03-18 17:34:16+00:00,https://twitter.com/rasbt/status/1504873836931686400,"@VeredShwartz Ahhhh! Tbh, I thought you were exaggerating üòÜ... https://t.co/5d8vfuMD50 https://t.co/BoXIxce1uq"
5695,@rasbt,2022-03-18 15:32:06+00:00,https://twitter.com/rasbt/status/1504843091773112331,"@andrewwhite01 Haha, yeah, I agree with you. Especially when you have more than 1 for-loop like [entry for tag in tags for entry in entries if tag in entry] üò®.
In your example it's borderline though. I think it would read so much better if you wouldn't have everything in one line üòâ"
5696,@rasbt,2022-03-18 03:22:49+00:00,https://twitter.com/rasbt/status/1504659563886301190,@VeredShwartz People have been coding all day in Python üòÖ
5697,@rasbt,2022-03-17 21:06:27+00:00,https://twitter.com/rasbt/status/1504564845185847304,"@srvmshr Oh, I am really sorry about that. That sucks  :(. Whatever my next book is, I will be happy to send you a personally signed copy!"
5698,@rasbt,2022-03-17 21:03:53+00:00,https://twitter.com/rasbt/status/1504564200450007042,"Hello, my favorite library for general scientific computing. Welcome to Twitter!"
5699,@rasbt,2022-03-17 20:58:38+00:00,https://twitter.com/rasbt/status/1504562878879186982,@srvmshr Wow thanks so much for the support üôè. And I really hope you like the new edition! The Transformer and Graph Neural Network chapters are my favorites and most fun to work on!
5700,@rasbt,2022-03-17 20:51:51+00:00,https://twitter.com/rasbt/status/1504561170199592961,@seanmylaw @marktenenholtz @hardmaru @stumpy_dev Thanks for sharing! I am still waiting for a time series project to pop up so that I can take it to a test drive üòÖ
5701,@rasbt,2022-03-17 20:50:49+00:00,https://twitter.com/rasbt/status/1504560911524282368,"@srvmshr If you are not careful &amp; disciplined, the process of keeping up can turn into a full time job üòÖ"
5702,@rasbt,2022-03-17 20:49:37+00:00,https://twitter.com/rasbt/status/1504560611623149570,"@francoisfleuret @ducha_aiki @PyTorch That's true. It's rare, but sometimes you have these cases where you need to create tensor from scratch inside forward() and have to specify torch.tensor(...device=something). Dummy GPUs would be great btw."
5703,@rasbt,2022-03-17 18:27:30+00:00,https://twitter.com/rasbt/status/1504524843294900236,"@ptrblck_de @ducha_aiki Good point, probably better to use 
`z = y. to(x.device)`
and
`z = y. to(x.dtype)`
to be more precise."
5704,@rasbt,2022-03-17 17:20:15+00:00,https://twitter.com/rasbt/status/1504507921992138752,"@srchvrs @hector_sab @ducha_aiki Yeah, it's probably going to be ""coreml"". Also, there are IPUs"
5705,@rasbt,2022-03-17 17:17:34+00:00,https://twitter.com/rasbt/status/1504507247547895810,"@ducha_aiki I used to do
device = torch.device('cuda' if https://t.co/19QQU3xuRR_available() else 'cpu')
def forward(self, x):
    ... 
    z = y. to(device)
But even try to avoid that now in case people want to run on multi-gpu.
z = y. type_as(x) is better."
5706,@rasbt,2022-03-17 16:47:12+00:00,https://twitter.com/rasbt/status/1504499604326342667,"Really enjoy working on academic research. However, I recently realized that training models on my GPU workstation != using DL in the real-world. There are lots of cool, compounding techniques to scale-up your PyTorch models. A good &amp; succinct overview:  https://t.co/JtfBLvMYXF"
5707,@rasbt,2022-03-17 15:23:46+00:00,https://twitter.com/rasbt/status/1504478608819064835,@marktenenholtz @hardmaru Only Kaggle competitions will tell... PS: @seanmylaw any pointers by chance?
5708,@rasbt,2022-03-17 15:18:40+00:00,https://twitter.com/rasbt/status/1504477323147456512,"@marktenenholtz @hardmaru Have you used StumPy? Based on the SciPy 2021 talk, I am now convinced that this is the way! https://t.co/trlgNQcPh5 (Haven't had a chance to try it in a real project, yet, because I usually don't have time series related problems :P)."
5709,@rasbt,2022-03-17 15:17:23+00:00,https://twitter.com/rasbt/status/1504477001150709771,"@marktenenholtz @hardmaru Reminds me of a few cool ideas I've seen in a DL context. Instead of just predicting on the available data, generate the next time steps and then predict on those. Have seen a couple of papers on that, and it seems to work relatively well for certain data https://t.co/uleSAjYZwH https://t.co/HCPmxn6M5H"
5710,@rasbt,2022-03-17 15:10:36+00:00,https://twitter.com/rasbt/status/1504475295025270794,"@marktenenholtz @hardmaru Actually, now that you say that, when I see time series models in the wild, it is almost always a ""regular"" ML classification or regression model (XGBoost, etc.) with lag features rather than anything designed time series modeling (like matrix profile-based approaches)"
5711,@rasbt,2022-03-17 13:18:59+00:00,https://twitter.com/rasbt/status/1504447205725421575,@megthescientist Arg this sounds frustrating but I am glad to hear that it made it. Hope you like the book and have a good spring break with / despite of it üòÖ
5712,@rasbt,2022-03-17 13:06:10+00:00,https://twitter.com/rasbt/status/1504443977210253316,@IoThobbyist Good question. I am not sure there is one but maybe @PacktPub can help.
5713,@rasbt,2022-03-16 23:44:29+00:00,https://twitter.com/rasbt/status/1504242230441172996,@sekk_isma But there is too much going on in this figure. Here is an example (https://t.co/Djz93fRgxn) https://t.co/T3Nzd2ECrI
5714,@rasbt,2022-03-16 23:41:53+00:00,https://twitter.com/rasbt/status/1504241576209526789,"@sekk_isma Thanks for the pointer, very very interesting. Actually, I am not doing a one-hot encoding, and the binary label extension looks very similar to a thermometer encoding. I kind of skipped the encoding due to time constraints, but it is essentially like this: https://t.co/tBVnL21p6n"
5715,@rasbt,2022-03-16 23:37:25+00:00,https://twitter.com/rasbt/status/1504240451662057479,"@taocds Haha, thanks, I take that as a compliment. I think the only talk I practiced before was my PhD thesis üò¨. But yeah, it was only a 15 minute talk so practicing it didn't sound too dreadful this time üòâ"
5716,@rasbt,2022-03-16 23:07:48+00:00,https://twitter.com/rasbt/status/1504232998291529742,"Yap, the slide view is unfortunately a bit too small üòû. But hey, good news is that I tried something new this time and also recorded my talk to force myself practice it: https://t.co/1WIcMhD96Z"
5717,@rasbt,2022-03-16 23:04:30+00:00,https://twitter.com/rasbt/status/1504232166972182531,"Interested in using deep learning for prediction problems where class labels have an intrinsic order (e.g., mild &lt; moderate &lt; strong)? Here's a recording of my ReWork talk that gets you up to speed in 15 min! Spoiler: You can modify your classifier with just 3 lines of code! üëá"
5718,@rasbt,2022-03-16 18:04:47+00:00,https://twitter.com/rasbt/status/1504156739637321729,@Ashwin_S18 @svpino Thanks! Btw here is a link to the list you mentioned: https://t.co/Xfn2F4pLXD
5719,@rasbt,2022-03-16 18:01:04+00:00,https://twitter.com/rasbt/status/1504155804328415232,"@AllesistKode @marksaroufim @PacktPub No, personally I don't have a problem with that at all. I would be honored and happy to hear that people find it useful and help people getting into ML. I think distributing copies without the publishers permission would be a problem though."
5720,@rasbt,2022-03-16 17:46:35+00:00,https://twitter.com/rasbt/status/1504152158568132615,"@AllesistKode @marksaroufim Honestly, I don't know how it works in general. However, I am happily giving my permission, and @PacktPub is probably on the same page :)"
5721,@rasbt,2022-03-16 16:21:03+00:00,https://twitter.com/rasbt/status/1504130636390572036,"@svpino Wow, thanks so much for the kind recommendation. Coming from you, this means A LOT to me!"
5722,@rasbt,2022-03-16 16:07:15+00:00,https://twitter.com/rasbt/status/1504127160994471945,@onurfailson @marksaroufim Oh oh. You might be rightüò¨
5723,@rasbt,2022-03-16 15:55:10+00:00,https://twitter.com/rasbt/status/1504124123274006532,"Wow! Super flattered that someone (hopefully) likes my book so much to spend a whole Saturday with it.
Haha happy to check in &amp; say hello @marksaroufim. And maybe I will even ask a tricky question to check whether you are really *really* reading it üòÜ."
5724,@rasbt,2022-03-15 23:36:49+00:00,https://twitter.com/rasbt/status/1503877910779813889,"@TaliaRinger Yeah SSBs as MVP or POC, love it"
5725,@rasbt,2022-03-15 23:34:35+00:00,https://twitter.com/rasbt/status/1503877348508188677,"@TaliaRinger Logistic loss, negative log likelihood, cross entropy, ‚Ä¶ you name it üôÉ"
5726,@rasbt,2022-03-15 23:08:54+00:00,https://twitter.com/rasbt/status/1503870885400358917,@mrdbourke I think other fields would not even consider it since the ReLU function is not even ‚Äúsmooth‚Äù at x=0 and thus not differentiable. What‚Äôs awesome about machine learning is that we don‚Äôt care and just make it work.
5727,@rasbt,2022-03-15 20:04:08+00:00,https://twitter.com/rasbt/status/1503824386419306498,@bhutanisanyam1 @kaggle @jeremyphoward @vopani Wow this is huge! Big congrats! üéäüçæ
5728,@rasbt,2022-03-15 20:03:22+00:00,https://twitter.com/rasbt/status/1503824195230347268,"@JFPuget One person probably exported the model to LibTorch and used the C++ API to train the model on an iPhone to speed things up, because the MacBook was still running on Intel chips"
5729,@rasbt,2022-03-15 19:59:21+00:00,https://twitter.com/rasbt/status/1503823184193335299,"@PhilCulliton So, what were the approximate proportions for the winning solutions? :)"
5730,@rasbt,2022-03-15 14:07:11+00:00,https://twitter.com/rasbt/status/1503734557262110727,"@ngaroeqir I think it‚Äôs really better for competitions. For tabular data Python and R are maybe on par. But when it comes to other modalities and deep learning, I don‚Äôt know any other language but Python where you can do it effectively. Python is where all the main libraries are."
5731,@rasbt,2022-03-15 13:20:59+00:00,https://twitter.com/rasbt/status/1503722930995445772,"@valentyn_bez @CAMDA_conf @PyTorch @huggingface Nice, congrats!"
5732,@rasbt,2022-03-15 13:20:05+00:00,https://twitter.com/rasbt/status/1503722707682275328,@BlackHC ‚Äújust happy to keep up with some of the newly published papers‚Äù -&gt; this is already a full time job üôÉ
5733,@rasbt,2022-03-15 13:05:23+00:00,https://twitter.com/rasbt/status/1503719007819644930,"Whoa. 96% of the winning solutions used Python. This is the way. 

Interesting tidbit: all winning NLP solutions used transformers. However, most winning computer vision solutions were still  convolutional nets (mostly EffficientNet)."
5734,@rasbt,2022-03-14 19:57:24+00:00,https://twitter.com/rasbt/status/1503460305099272203,"Wow, this is awesome. Unfortunately, in my ML class, I only got to cover t-SNE (with a big disclaimer re using UMAP in practice) before we ran out of time at the end of the semester. This is the (no-longer) missing tutorial I wish I had for the *Recommended Resources* section!"
5735,@rasbt,2022-03-14 19:01:09+00:00,https://twitter.com/rasbt/status/1503446148840935429,"@iUzairmansuri @fchollet Nice! Have fun! I think they will complement each other nicely: ML, scikit-learn, deep learning, TensorFlow &amp; Keras, PyTorch, time series, transformers, graph neural net, reinforcement learning, and many more. Covers all your bases if you ever have an ML interview coming up ;)"
5736,@rasbt,2022-03-13 23:48:32+00:00,https://twitter.com/rasbt/status/1503156085154369536,"@irinarish @GaryMarcus @NautilusMag Re taking care of forecasting &amp; protein structure predictions. Sure, maybe. But probably no if we focus too hard on comparing it to human-level intelligence üôÉ"
5737,@rasbt,2022-03-13 23:29:57+00:00,https://twitter.com/rasbt/status/1503151408832565250,@irinarish @GaryMarcus @NautilusMag I agree. Predictive performance of DL models improved a lot in recent years. Are we making progress towards AGI? Dunno. But AGI is not everything. There are breakthroughs in applications like weather forecasting &amp; protein structure predictions that I consider (more!?) important
5738,@rasbt,2022-03-13 22:18:40+00:00,https://twitter.com/rasbt/status/1503133468443779077,"After years using AlexNet for demo purposes, I just realized that I never implemented it with grouped convolutions. What took a lot of effort back then is now a simple `torch.nn.Conv2d(..., groups=2)` (but makes me realize how far we've come re DL code): 

https://t.co/6QD59uJEOS https://t.co/zrziFzwI06"
5739,@rasbt,2022-03-13 21:53:10+00:00,https://twitter.com/rasbt/status/1503127052064595975,@_willfalcon @chrisalbon @leonpalafox @gridai_ @PyTorchLightnin And rumors have it that the team who won the final race doesn't have to write unit tests and documentation until the next offsite. https://t.co/mpvIVOXht4
5740,@rasbt,2022-03-13 20:30:01+00:00,https://twitter.com/rasbt/status/1503106126862299139,"@therriaultphd @bwbensonjr Among other things, I added a section explaining gradient boosting for classification (I don't think any other book or even blog article covers that). Nowadays, gradient boosting is THE algorithm for tabular data, so I think it's worthwhile teaching it :)"
5741,@rasbt,2022-03-13 20:27:31+00:00,https://twitter.com/rasbt/status/1503105498807218183,"@therriaultphd @bwbensonjr Oh yeah, I'd consider sklearn &amp; ML still as one of the fundamentals. Even for people who are interested in DL later on, it's a good to be familiar with non-neural-net ML. Btw this part of the book also has some little tweaks and goodies here and there ..."
5742,@rasbt,2022-03-13 18:39:25+00:00,https://twitter.com/rasbt/status/1503078293905494017,"@raghurama123 @vmirly Nice! What a small world! It's an awesome dataset for benchmarking and model development, thanks for creating and sharing it!"
5743,@rasbt,2022-03-13 18:37:06+00:00,https://twitter.com/rasbt/status/1503077707999068161,@JoshBambrick One additional thing that just came to mind is grouped convolutions. Should really do a write-up for this map one day :).
5744,@rasbt,2022-03-13 18:35:31+00:00,https://twitter.com/rasbt/status/1503077311251427338,"@alantucker @python_engineer Haha, having worked with many (maybe 30+) students who choose this topic as their class projects, I am not sure if you really want to go that rabbit hole ... üòÖ"
5745,@rasbt,2022-03-13 18:33:58+00:00,https://twitter.com/rasbt/status/1503076919675428866,"@jasondeanlee Yeah, it's one of these terms to make an (un)intentional restriction sound more fancy than it really is."
5746,@rasbt,2022-03-13 18:29:11+00:00,https://twitter.com/rasbt/status/1503075717126496262,"@richardjnsa @python_engineer For a more big-picture overview, I also recommend @burkov 's awesome Hundred Page Machine Learning Book"
5747,@rasbt,2022-03-13 18:28:09+00:00,https://twitter.com/rasbt/status/1503075456270151687,"@richardjnsa @python_engineer I hope my book is relatively beginner-friendly :). I think as long as you are comfortable in Python and don't mind a mathematical equation here and there (although, these can be skipped), I hope it works great for a beginner."
5748,@rasbt,2022-03-13 18:24:33+00:00,https://twitter.com/rasbt/status/1503074553530097671,"@MaartenvSmeden Spot on üëå, I agree with you on that"
5749,@rasbt,2022-03-13 18:07:29+00:00,https://twitter.com/rasbt/status/1503070255840702470,"@joshuastarmer @gridai_ BAM! This was a fun week! Enjoyed meeting and hanging out! 

PS: If someone is interested in getting a copy without having to join me and my friend &amp; colleague at Grid (although I highly highly recommend üòä), I have one more copy to spare: https://t.co/HwThO4IBEG"
5750,@rasbt,2022-03-13 17:56:58+00:00,https://twitter.com/rasbt/status/1503067610598064136,@therriaultphd @bwbensonjr And nothing more fun than switching from TensorFlow to PyTorch one week before class starts üôÉ
5751,@rasbt,2022-03-13 17:54:29+00:00,https://twitter.com/rasbt/status/1503066983323086850,"@python_engineer Whoa, thanks for this big compliment. Super happy to hear you are having a good time with it!"
5752,@rasbt,2022-03-13 17:42:28+00:00,https://twitter.com/rasbt/status/1503063961515827201,"@philipvollet Nice! You know what, let's make it four! Happy to chime in and add a personally signed copy to the lottery pool. https://t.co/xGLNRLc2Zd"
5753,@rasbt,2022-03-13 17:12:14+00:00,https://twitter.com/rasbt/status/1503056354025431041,@leonpalafox @gridai_ @PyTorchLightnin a week; a tad shorter than the typical coding bootcamp üôÉ
5754,@rasbt,2022-03-13 15:23:06+00:00,https://twitter.com/rasbt/status/1503028887265153030,"Just got back from our offsite: an intense week of fun &amp; work! I don't think I ever experienced sth like this! As someone who often worked on projects alone, it was pretty amazing to experience what you can accomplish if you are part of an awesome team @gridai_ @PyTorchLightnin https://t.co/EZo97Jn0sD"
5755,@rasbt,2022-03-10 17:32:59+00:00,https://twitter.com/rasbt/status/1501974409623523335,@psteinb_ @ThomasViehmann @helmholtz_ai @eric_brachmann There is no standard way afaik. For small CNNs maybe a LeNet-style viz would work best. Here are some tools you could check out:  https://t.co/EgimRyZB9f https://t.co/XlCTizspeT
5756,@rasbt,2022-03-10 14:26:27+00:00,https://twitter.com/rasbt/status/1501927467786727426,"@CSProfKGD @unsorsodicorda @PyTorch @TensorFlow Actually, the M1 CPU version of PyTorch is plenty fast and should be fine for prototyping and teaching. But yeah, tinkering with SHARK might of course be more fun."
5757,@rasbt,2022-03-10 14:03:17+00:00,https://twitter.com/rasbt/status/1501921636685160449,"@unsorsodicorda @CSProfKGD @PyTorch @TensorFlow I don't think there is an official (and/or beta) release of the PyTorch with M1 GPU support. There is SHARK though, but I haven't used it yet: https://t.co/M6X9DaYgvR"
5758,@rasbt,2022-03-09 16:28:30+00:00,https://twitter.com/rasbt/status/1501595793618259975,"@kneupane @ronky_gee @tomgoldsteincs Oh, wasn‚Äôt suggesting or recommending it; was just wondering how early stopping related to random forests üòÖ"
5759,@rasbt,2022-03-09 14:12:01+00:00,https://twitter.com/rasbt/status/1501561447616335875,@kneupane @ronky_gee @tomgoldsteincs You use an incremental random forest algorithm? Like hi-RF?
5760,@rasbt,2022-03-09 13:45:27+00:00,https://twitter.com/rasbt/status/1501554763594350593,"@shengy90 Hah, yeah, it turned out to be bigger than expected, even though I tried to be very selective in terms of which topics to include üòÖ. I wouldn't know how to trim it further, and I hope you have a good time with it! ‚ò∫Ô∏è"
5761,@rasbt,2022-03-09 13:26:46+00:00,https://twitter.com/rasbt/status/1501550062249328645,"@thomasahle @tomgoldsteincs @AdrianoDAlessa3 That‚Äôs true. One could tell based on the training code if it is included and not altered. Btw one time I found this violation based on plots though. I.e., the authors plotted the train/test acc for each epoch and then it was obvious they used test performance for selection."
5762,@rasbt,2022-03-09 05:22:56+00:00,https://twitter.com/rasbt/status/1501428297762316288,"@MaxEpstein5 @tomgoldsteincs Also, we can think of ""validation performance"" as more of a general placeholder term. It doesn't have to be a single, particular validation set. It can be a rotating validation set, or multiple validation sets. It's up to the context (and practitioner) how to calculate it."
5763,@rasbt,2022-03-09 05:21:45+00:00,https://twitter.com/rasbt/status/1501428001296293894,"@MaxEpstein5 @tomgoldsteincs I agree, the more effort and resources you spend on tuning the hyperparameters, the more prone you are to overfitting to the validation set. But it is probably still better than using the last epoch ..."
5764,@rasbt,2022-03-09 05:17:48+00:00,https://twitter.com/rasbt/status/1501427008026390534,"@GeringerAdam @ronky_gee @tomgoldsteincs I.e., how you compare the difference between training and validation accuracy to assess overfitting, you can compare validation and test accuracy. With loss units it's a bit more unituitive. (I find 60% - 70% - 73% accuracy easier to compare than loss values)"
5765,@rasbt,2022-03-09 05:15:35+00:00,https://twitter.com/rasbt/status/1501426450305630208,"@GeringerAdam @ronky_gee @tomgoldsteincs Yeah, I would expect a high (negative) rank correlation between validation loss and validation accuracy, so I think both will give you the same results most of the time. I do think validation accuracy is more useful though because you can compare it to test accuracy later."
5766,@rasbt,2022-03-09 05:13:24+00:00,https://twitter.com/rasbt/status/1501425901879414786,"@FeedCompu Many thanks! Haha, more pages is not possible. Actually, only the new layout with the slimmer margins aloud us to fit it into the page limit such that it can still be offered as a print copy üòÜ"
5767,@rasbt,2022-03-09 05:11:12+00:00,https://twitter.com/rasbt/status/1501425344900907012,"@tejasybhakta @tomgoldsteincs @fchollet Well, it's not optimal, but it is a simple, easy to understand approach that is better than selecting the last epoch and comes for free depending on the deep learning framework you use (and fits into a 280 character response :P)"
5768,@rasbt,2022-03-09 05:07:48+00:00,https://twitter.com/rasbt/status/1501424490894475264,"@AdrianoDAlessa3 @tomgoldsteincs Plus, in deep learning, the datasets are usually large enough that the validation set is negligible."
5769,@rasbt,2022-03-09 05:07:04+00:00,https://twitter.com/rasbt/status/1501424308819791877,"@AdrianoDAlessa3 @tomgoldsteincs In a ""traditional"" (non-neural-network) context, I recommend retraining the model on the bigger dataset after evaluation. E.g., steps 4 &amp; 6 in a holdout context in the screenshot below (from https://t.co/aYvW168wLF). But DL models are too ""flaky"" for that :P. https://t.co/mFxrIc8uhf"
5770,@rasbt,2022-03-09 05:03:09+00:00,https://twitter.com/rasbt/status/1501423319702286337,@AdrianoDAlessa3 @tomgoldsteincs I see what you are saying. I think in most deep learning contexts (2) is the better option because convergence properties are often hard to guess from a previous model or run.
5771,@rasbt,2022-03-09 05:01:21+00:00,https://twitter.com/rasbt/status/1501422866050469888,"@tomgoldsteincs @AdrianoDAlessa3 In other words, it's like hyperparameter tuning on the test set, and I would call that out in a paper review."
5772,@rasbt,2022-03-09 05:00:15+00:00,https://twitter.com/rasbt/status/1501422592258977795,"@tomgoldsteincs @AdrianoDAlessa3 I was going to respond saying that is definitely better than using the training set for selection due to overfitting and didn't even consider using the test set for epoch selection as an option. But yeah, some people do that and it is definitely cheating."
5773,@rasbt,2022-03-08 23:41:48+00:00,https://twitter.com/rasbt/status/1501342449427435528,@ronky_gee @tomgoldsteincs Yes exactly :)
5774,@rasbt,2022-03-08 23:10:11+00:00,https://twitter.com/rasbt/status/1501334495567482882,"@ronky_gee @tomgoldsteincs But how do you measure when the model stops learning -- e.g., in the context of double decent, warm starts, etc. For the second point, isn't that based on hypothesizing that the model with the best validation performance is the one that generalizes best?"
5775,@rasbt,2022-03-08 22:56:15+00:00,https://twitter.com/rasbt/status/1501330988940550148,"@MaxEpstein5 @tomgoldsteincs Sure, that can happen. But it‚Äôs better than selecting the best model by training performance. Also, if you don‚Äôt select the model based on best validation accuracy, what do you use the validation accuracy for?"
5776,@rasbt,2022-03-08 22:49:42+00:00,https://twitter.com/rasbt/status/1501329340633477124,"@tomgoldsteincs Yes and no. Yes, we train as long as possible. But no, we haven‚Äôt abandoned early stopping. I.e., after training, we select the model with the best validation accuracy from that run for testing etc (which is a form of early stopping). Or is it just me (still) doing that? üòÖ"
5777,@rasbt,2022-03-08 22:24:09+00:00,https://twitter.com/rasbt/status/1501322911399002114,@tashay_g @PacktPub Hope you‚Äôll like it &amp; it‚Äôll be fun :)
5778,@rasbt,2022-03-08 18:03:30+00:00,https://twitter.com/rasbt/status/1501257316322070529,@HenggaoCai @driscollis @PacktAuthors @PacktPub @PyTorch Wow thanks ‚ù§Ô∏è
5779,@rasbt,2022-03-08 18:02:47+00:00,https://twitter.com/rasbt/status/1501257134805237764,"@TheCodingProjec Cool, that‚Äôs nice to hear. I spent a lot of time stressing about the order and scope of these, so it‚Äôs good to hear this :)"
5780,@rasbt,2022-03-08 13:15:43+00:00,https://twitter.com/rasbt/status/1501184893514133509,"Thank you, everyone! When you work really hard on something for a long time, all the positive feedback and motivating words really mean a lot! https://t.co/8tMd89hE4F"
5781,@rasbt,2022-03-08 13:09:03+00:00,https://twitter.com/rasbt/status/1501183213456216077,"@__mharrison__ @driscollis @PacktAuthors @PacktPub @PyTorch I am not exactly sure what their plans are, but one of the things on my list was to send you a signed copy when I am back home next week -- to repay the kindness of sending me a signed copy of the Illustrated Guide to Python 3 a few years ago :)"
5782,@rasbt,2022-03-08 03:28:05+00:00,https://twitter.com/rasbt/status/1501037009787367433,@_willfalcon @PyTorchLightnin @us_navyseals @lantiga What an experience! Couldn't possibly get sandier &amp; can still feel every minute of these long six hours. But tough times don‚Äôt last. Tough teams do.
5783,@rasbt,2022-03-07 19:24:59+00:00,https://twitter.com/rasbt/status/1500915434832465920,"@divideconcept @sytelus @CSProfKGD Just wanted to say that I am actually pretty excited that you are working on this. Am planning to give it a try in the context of teaching. Sure, it's an early version, so I totally understand that it's not perfect, but I look forward to see it grow based on community feedback"
5784,@rasbt,2022-03-07 19:21:43+00:00,https://twitter.com/rasbt/status/1500914611482243079,"@frguerre Wow, nice! Wishing you a fun &amp; productive time with it! Hope you'll find it useful!"
5785,@rasbt,2022-03-06 20:41:45+00:00,https://twitter.com/rasbt/status/1500572362433085445,"@a10daze____ @hen_str There‚Äôs still a lot of boilerplate though. In a blog post, you could just link a Wikipedia article for Intro/related work üòú"
5786,@rasbt,2022-03-06 20:37:54+00:00,https://twitter.com/rasbt/status/1500571393133621253,"@TaliaRinger Yeah, but it had a pretty good and active ML community. I‚Äôll give it that."
5787,@rasbt,2022-03-06 20:32:25+00:00,https://twitter.com/rasbt/status/1500570016927916040,"@hen_str Seb‚Äôs law: the more blog posts you read &amp; write, the more difficult it gets to make things look traditional."
5788,@rasbt,2022-03-06 20:25:52+00:00,https://twitter.com/rasbt/status/1500568364753854466,"@3scorciav @eccvconf Wait, I thought the recent rumor on the street is that it‚Äôs the opposite (https://t.co/wxSYxoBoAV), I.e., convs as high pass filters are the ones less robust etc. Or do you mean training convenience wrt hyperparameter settings?"
5789,@rasbt,2022-03-06 19:44:55+00:00,https://twitter.com/rasbt/status/1500558061978673158,Another interesting paper trying to reconcile &amp; combine the advantages of convolutional layers and multi-head self-attention https://t.co/VV3rfSDJl2. The ViT literature is getting really interesting &amp; there's lots of interesting stuff emerging from this exploratory stage üî• https://t.co/hejKO2y9aa
5790,@rasbt,2022-03-06 19:28:41+00:00,https://twitter.com/rasbt/status/1500553976810459137,@kchowdha @stephaniehicks I am actually using a slightly modified version of that that one for the WIP parts üòä https://t.co/h81R1eMfnx
5791,@rasbt,2022-03-06 19:12:43+00:00,https://twitter.com/rasbt/status/1500549957878784002,"""Why it's best to keep software and data analysis repositories separate"" -- nice &amp; concise article by @stephaniehicks. Did this in my recent research projects and can only recommend it if you like to keep things decluttered &amp; user-friendly https://t.co/rHspgowOMb"
5792,@rasbt,2022-03-06 19:05:56+00:00,https://twitter.com/rasbt/status/1500548250566340611,"@CSProfKGD It's super neat. Discussed this with some colleagues last week. The gist was that it works great for simple examples but may not be ideal/ready yet for more serious stuff and real-world use cases. I can see it being useful for teaching though (e.g., as alternatives to notebooks)"
5793,@rasbt,2022-03-06 18:54:13+00:00,https://twitter.com/rasbt/status/1500545301412728843,"@KyleCranmer One the other hand, most students I interacted with in the stats department wished they had taken more computer science or programming classes üòÜ"
5794,@rasbt,2022-03-06 18:43:44+00:00,https://twitter.com/rasbt/status/1500542663115825156,@michael_nielsen You can just drag &amp; drop URLs from the Safari address bar into Finder.
5795,@rasbt,2022-03-06 02:18:18+00:00,https://twitter.com/rasbt/status/1500294671058231296,@gowthami_s Didn‚Äôt know about this. Bookmarked and will check it out! Thanks!
5796,@rasbt,2022-03-05 17:25:58+00:00,https://twitter.com/rasbt/status/1500160706204868613,"@ZainulA40877140 Or take climate research and weather forecasting as an example. State of the art methods are based on a mix of predictive and generative modeling with deep learning. If you filter out all the noise, I think we are well on track with AI/DL making important contributions."
5797,@rasbt,2022-03-05 17:24:14+00:00,https://twitter.com/rasbt/status/1500160270693502983,"@ZainulA40877140 It depends on where &amp; how you look at it. From an AGI perspective, sure I agree. But do we need AGI? I don‚Äôt think so. There have been pretty impressive narrow AI applications like AlphaFold that beat classical approaches and may result/aid in important medical research contexts"
5798,@rasbt,2022-03-05 17:20:58+00:00,https://twitter.com/rasbt/status/1500159448739946503,"@blaine_bateman Nice, glad to hear! I remember tinkering with it quite a bit in hope to find an intuitive way to show/explain"
5799,@rasbt,2022-03-05 17:20:08+00:00,https://twitter.com/rasbt/status/1500159237997182983,@swooooooosh_ml Glad to hear you have a good first impression :). Hope you‚Äôll also like the rest üòä
5800,@rasbt,2022-03-05 17:17:41+00:00,https://twitter.com/rasbt/status/1500158622931816449,@cleavey1985 Hope you‚Äôll like it! üòä
5801,@rasbt,2022-03-05 17:16:15+00:00,https://twitter.com/rasbt/status/1500158259579269120,"4/4 Also, a big shout-out to Letitia and Miss Coffee Bean @AICoffeeBreak for an excellent video on this paper! https://t.co/g1m1rcw7Tr"
5802,@rasbt,2022-03-05 17:15:39+00:00,https://twitter.com/rasbt/status/1500158107296620549,"3/ Also, ""MSAs are low-pass filters, but Convs are high-pass filters"". This means that MSAs better capture shapes and curvature, whereas convolutional layers are more focused on capturing texture."
5803,@rasbt,2022-03-05 17:15:12+00:00,https://twitter.com/rasbt/status/1500157996390834181,"2/ I.e., one of the silver linings of data-hungry ViTs is that they ""are [relatively] robust against data corruptions [...] and adversarial attacks"". This might be due to MSAs flattening the loss landscape!?"
5804,@rasbt,2022-03-05 17:14:53+00:00,https://twitter.com/rasbt/status/1500157917923794945,"""How Do Vision Transformers (ViTs) Work?"" -- Don't be fooled by the title; this is a paper offering a pretty insightful discussion around how &amp; why multi-head attention (MSA) works. (https://t.co/wxSYxoBoAV?) 1/"
5805,@rasbt,2022-03-04 20:14:21+00:00,https://twitter.com/rasbt/status/1499840694713819139,"@CSProfKGD Thanks for your interest in this, and I hope the semester is going well! I don't think your excellent classes need this, but I hope you'll find a few helpful tidbits in there that come in handy :). PS: All the figures are (in somewhat high res) on GitHub: https://t.co/1fFQeWfbgJ"
5806,@rasbt,2022-03-04 16:05:07+00:00,https://twitter.com/rasbt/status/1499777969501261828,"Thanks to a kind invitation, I am currently doing an AMA on reddit in case someone wants to ask something that doesn't quite fit into Twitters 280 chars üòÖhttps://t.co/Zs94JOFvsc"
5807,@rasbt,2022-03-04 16:03:30+00:00,https://twitter.com/rasbt/status/1499777563618652162,"@blaine_bateman Thanks for the kind words, I am glad to hear that given all the content it is still approachable :)"
5808,@rasbt,2022-03-04 16:02:05+00:00,https://twitter.com/rasbt/status/1499777209032130560,@bhutanisanyam1 Thanks for your motivating words @bhutanisanyam1 ! really appreciate the support!
5809,@rasbt,2022-03-04 00:30:12+00:00,https://twitter.com/rasbt/status/1499542693298454531,Someone's author copies of the #MachineLearning book just arrived! https://t.co/uvgj2zwnlt
5810,@rasbt,2022-03-03 19:09:38+00:00,https://twitter.com/rasbt/status/1499462017358471175,"@marksaroufim @marktenenholtz @bhutanisanyam1 @sudomaze @ykilcher @AICoffeeBreak I am actually traveling &amp; out of town next week üòÖ. Depending on date &amp; time I could maybe make it but if we could push it back by one week that'd be more convenient. Anyways, lets make this work somehow! Pls keep me in the loop!"
5811,@rasbt,2022-03-03 17:21:22+00:00,https://twitter.com/rasbt/status/1499434772812242947,"@marksaroufim @sudomaze @bhutanisanyam1 @marktenenholtz @ykilcher @AICoffeeBreak Haha this sounds hilarious, how can I say No!? Happy to join in saying Hi for the motivational support üòâ"
5812,@rasbt,2022-03-03 16:41:58+00:00,https://twitter.com/rasbt/status/1499424856508715008,"@akionet5 @marktenenholtz @ykilcher Nope. However, there are 3 good reasons: you (1) need to satisfy your FOMO so you can sleep better; (2) want to create content around the latest happenings; (3) finished the experiments for your paper and are currently writing the Related Work section."
5813,@rasbt,2022-03-03 16:03:02+00:00,https://twitter.com/rasbt/status/1499415060879491072,"@LucaAmb On the other hand, that‚Äôs exactly what people said about deep learning in general 10 years ago"
5814,@rasbt,2022-03-03 14:55:12+00:00,https://twitter.com/rasbt/status/1499397987851587590,"@marktenenholtz @ykilcher Hah, yeah, keeping up with latest research and developments in the DL space is (almost) a full-time job itself üòÖ. But it's fun, each day you get to learn something new, and there is a never ending stream of new fun stuff to learn about."
5815,@rasbt,2022-03-03 14:52:38+00:00,https://twitter.com/rasbt/status/1499397342788677646,@PacktPub @BFGHDF @vmirly As a little addition to this: I also embedded all the color figures in the Jupyter notebooks for easy access &amp; cross-referencing: https://t.co/1fFQeVXzS9
5816,@rasbt,2022-03-03 14:47:13+00:00,https://twitter.com/rasbt/status/1499395979971158021,"@Kamil43107097 @radekosmulski I will let others answer this, but as an author, you are the target audience I had in mind :)."
5817,@rasbt,2022-03-03 01:31:13+00:00,https://twitter.com/rasbt/status/1499195658883973124,@paul_rietschka Yap. I remember I was moderating arxiv that day and thought the paper (https://t.co/k1DsW8v1kM) was an April fool's joke at first üòÇ (like to good to be true)
5818,@rasbt,2022-03-02 23:50:09+00:00,https://twitter.com/rasbt/status/1499170225983475716,@JirkaBorovec This is perfect üëç . You can pretty much recreate that plot (and more) from the CSVs there!
5819,@rasbt,2022-03-02 20:57:25+00:00,https://twitter.com/rasbt/status/1499126755042512901,@unsorsodicorda @nc_znc That one worked. Super useful! Thanks! https://t.co/Zod3wjznxC
5820,@rasbt,2022-03-02 19:47:53+00:00,https://twitter.com/rasbt/status/1499109255198261252,"@unsorsodicorda @nc_znc Oh no, the link doesn't work. Very curious to check it out, could you send me the correct one? üòÖ"
5821,@rasbt,2022-03-02 19:42:13+00:00,https://twitter.com/rasbt/status/1499107831609540609,"@BFGHDF @PacktPub @vmirly Yeah, that would be nice. I think it's largely due to keeping the price down, but maybe there could be an option (similar to how some books have hardcover and softcover options)"
5822,@rasbt,2022-03-02 19:30:06+00:00,https://twitter.com/rasbt/status/1499104781759045634,@CSProfKGD @samsungresearch Great to hear! Congrats to you and your students!
5823,@rasbt,2022-03-02 19:12:49+00:00,https://twitter.com/rasbt/status/1499100430361632769,@BFGHDF @PacktPub @vmirly Nice! Hope you are liking it so far!? üòä
5824,@rasbt,2022-03-02 19:08:08+00:00,https://twitter.com/rasbt/status/1499099254358487041,@nmvrodrigues Nice! Have fun and let me know how it goes! :)
5825,@rasbt,2022-03-02 18:29:37+00:00,https://twitter.com/rasbt/status/1499089560298573828,"@bhutanisanyam1 @giffmana Nice! Thanks a lot for sharing! (I was looking for CNN-only architectures for a CNN lecture, but you couldn't have known, haha. This will be useful either way though!)"
5826,@rasbt,2022-03-02 18:24:12+00:00,https://twitter.com/rasbt/status/1499088195958579209,"@DrGirishPsych @omarsar0 Weka is a Java app whereas PyTorch and scikit-learn are both Python libraries. I'm sure there are still people using Weka, but I never met anyone who used it and can't say much about it. Just checking usage trends (Papers with code and Kaggle) Weka doesn't seem to make the cut ü§î https://t.co/m7FJJZGLOW"
5827,@rasbt,2022-03-02 18:10:47+00:00,https://twitter.com/rasbt/status/1499084821661990915,"I love this figure for comparing size, predictive performance, and computational performance of CNNs (https://t.co/ghiSUTLw4e). 

Caveat: It's from 2018. Before duplicating efforts üòÖ... Does anyone know of a more recent version that includes EfficientNetV2, RepVGG, HaloNet etc? https://t.co/ar1UoHoaJF"
5828,@rasbt,2022-03-02 16:41:30+00:00,https://twitter.com/rasbt/status/1499062353148755971,"@tunguz You are right, no speech modeling! But there is a chapter on graph neural nets ü§ó"
5829,@rasbt,2022-03-02 16:10:58+00:00,https://twitter.com/rasbt/status/1499054666272940041,@marcorossi20211 @omarsar0 There was a little discussion about that here üòÜ https://t.co/bbDhPywbJC
5830,@rasbt,2022-03-02 15:40:07+00:00,https://twitter.com/rasbt/status/1499046902180024334,"@omarsar0 Have fun! And no pressure at all, but I would be very happy to hear your thoughts once you finished it :)"
5831,@rasbt,2022-03-02 15:14:34+00:00,https://twitter.com/rasbt/status/1499040475201916933,"@tunguz Hope you'll like it! (""Almost all,"" haha, you have to elaborate one day üòâ)"
5832,@rasbt,2022-03-02 05:20:55+00:00,https://twitter.com/rasbt/status/1498891078346461186,@pvolad The paper with the most famous appendix üòÖ https://t.co/mAkPqrK3AN
5833,@rasbt,2022-03-02 02:01:21+00:00,https://twitter.com/rasbt/status/1498840853464457216,@willmcgugan Conda / Miniforge  https://t.co/pEePmXSYMZ
5834,@rasbt,2022-03-02 00:40:40+00:00,https://twitter.com/rasbt/status/1498820551460147200,"Oh, and if you wonder: why don't we just learn the activation function? People already thought of it as well üòÖ. ""Self-Learnable Activation Functions [...] learned during training and are capable of approximating most of the existing activation functions."" https://t.co/6yVxgUll3c"
5835,@rasbt,2022-03-02 00:28:52+00:00,https://twitter.com/rasbt/status/1498817579254792194,"When I got into deep learning, there were essentially three choices for your hidden layer activations: 
(1) logistic sigmoid, 
(2) tanh, 
(3) or ReLU as the hot new thing. 
Things were simpler back then üç® (https://t.co/CRpvlfKvV1) https://t.co/l8fIiBhqmj"
5836,@rasbt,2022-03-01 19:35:30+00:00,https://twitter.com/rasbt/status/1498743751757467651,"@xamat On a side note, to be honest, I am surprised that print is still so popular.  I love print books, but I am always running out of space at home (so I end up donating half my books each year). And for traveling, I got an e-reader now, which is really convenient."
5837,@rasbt,2022-03-01 19:33:48+00:00,https://twitter.com/rasbt/status/1498743322541711368,"@xamat Like a Vol. 1 and Vol.2? Interesting thought ü§î. (My guess is that it would make it more expensive for the reader, but I get your point regarding portability)"
5838,@rasbt,2022-03-01 19:31:30+00:00,https://twitter.com/rasbt/status/1498742746236043264,"@shortstein @zacharylipton Haha, I had to explain ""vanilla"" in my class once. Like, um, it's the base version. No chocolate chips. You know, when you get ice cream and ""just"" get vanilla flavor."
5839,@rasbt,2022-03-01 18:46:51+00:00,https://twitter.com/rasbt/status/1498731507816488965,@dvgodoy @aureliengeron Wow nice! We should trade books some time üòÖ. Happy to check it out :)
5840,@rasbt,2022-03-01 18:41:56+00:00,https://twitter.com/rasbt/status/1498730272665309186,"@PreetumNakkiran @unetloss @databoydg ""Distributional Generalization‚Äî which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error."" -- Thanks for sharing, I like that idea"
5841,@rasbt,2022-03-01 18:38:18+00:00,https://twitter.com/rasbt/status/1498729356788703252,"@code_star @AlexAddison ""it is easily established"""
5842,@rasbt,2022-03-01 18:24:19+00:00,https://twitter.com/rasbt/status/1498725839332159488,"@fredericosantos You could add it to the test step. But for the visualization code, no, there is currently no built-in way to do that. https://t.co/LtLgcZBZTR"
5843,@rasbt,2022-03-01 18:22:41+00:00,https://twitter.com/rasbt/status/1498725428151959557,"@YalmTo Yeah, data cleaning might help, or more data augmentation for those classes. In extreme cases even reweighting the loss for those classes."
5844,@rasbt,2022-03-01 18:00:27+00:00,https://twitter.com/rasbt/status/1498719830584741889,"@code_star Sometimes, when I attend stats seminars and feel humbled, I remember that you can get the same reaction if you show something like the following to a statistician üòÖ https://t.co/qeEBHA3ORi"
5845,@rasbt,2022-03-01 17:36:58+00:00,https://twitter.com/rasbt/status/1498713921489981444,"@TaliaRinger How do people deal with that in practice? For academic research, the common practice is to repeat the training at least 5 times and report the mean (incl. std dev or CI). In applications, you do the same (run it multiple times) and just save the best model."
5846,@rasbt,2022-03-01 17:34:44+00:00,https://twitter.com/rasbt/status/1498713359063076870,"@TaliaRinger You mean in the context of SGD-based optimization? Yeah, depending on the model, you can get noticeably different results based on initial random weights and data order. Usually, the local optima are of similar quality, but sometimes models don't converge at all."
5847,@rasbt,2022-03-01 13:55:19+00:00,https://twitter.com/rasbt/status/1498658143722774528,"@code_star Haha, enjoy (if possible)."
5848,@rasbt,2022-03-01 04:38:07+00:00,https://twitter.com/rasbt/status/1498517920170885122,"@michael_nielsen All the things. But I use it only with authentication apps. So, I assume if you want to log in somewhere you have Wi-Fi on your computer. And that means your phone can also connect to the internet (whether it‚Äôs via cell phone tower or Wi-Fi)"
5849,@rasbt,2022-03-01 02:58:43+00:00,https://twitter.com/rasbt/status/1498492902787502085,@tashay_g Would be happy to! ü§ó
5850,@rasbt,2022-02-28 23:15:50+00:00,https://twitter.com/rasbt/status/1498436814813773824,"Thanks to the kind invitation by @iamreddave I am doing an AMA on r/MachineLearning this Friday https://t.co/dEd9THSgg7. Pls feel free to AMA about my new book üìï, academic research ‚öóÔ∏è, or what I am currently up to at @gridai_ &amp; @PyTorchLightnin ‚ö°Ô∏è"
5851,@rasbt,2022-02-28 21:35:41+00:00,https://twitter.com/rasbt/status/1498411611085840384,"@bhutanisanyam1 @andradaolteanuu Wow, nice one, thanks for sharing üëå"
5852,@rasbt,2022-02-28 21:30:41+00:00,https://twitter.com/rasbt/status/1498410352584892417,"@blaine_bateman I think I have seen mosaic plots, but not in this particular context. Super cool, thanks for sharing!"
5853,@rasbt,2022-02-28 19:28:02+00:00,https://twitter.com/rasbt/status/1498379487133585413,"@CristianLazoQ Good point, we added a show_normed param to the plot_confusion_matrix function, but yeah, I didn't use it here."
5854,@rasbt,2022-02-28 19:18:53+00:00,https://twitter.com/rasbt/status/1498377182732853258,"@swooooooosh_ml Good question, I am actually not sure. I think Amazon usually discounts the ebook version after buying a print copy. I think Packt also has bundle deals."
5855,@rasbt,2022-02-28 19:17:15+00:00,https://twitter.com/rasbt/status/1498376770604703749,@MinhaajR Thanks for the kind words!
5856,@rasbt,2022-02-28 18:23:06+00:00,https://twitter.com/rasbt/status/1498363145978626054,"@michaelwaskom Oh yes, good call! https://t.co/9JRYQ7NRBu"
5857,@rasbt,2022-02-28 15:48:03+00:00,https://twitter.com/rasbt/status/1498324122761416710,There is something to be said about just adding a simple confusion matrix to inspect what pairs of classes a model confuses the most. https://t.co/giWJ6uV7cP
5858,@rasbt,2022-02-26 15:32:24+00:00,https://twitter.com/rasbt/status/1497595411820916736,@iamreddave Thanks for setting this up!
5859,@rasbt,2022-02-26 15:01:16+00:00,https://twitter.com/rasbt/status/1497587576382832647,"@iamreddave Thanks! Never done an AMA on reddit before, let me DM you for more instructions if you don't mind"
5860,@rasbt,2022-02-26 14:55:08+00:00,https://twitter.com/rasbt/status/1497586031557758979,"@iamreddave Yes, https://t.co/Ntv8XAea9e"
5861,@rasbt,2022-02-26 14:30:36+00:00,https://twitter.com/rasbt/status/1497579858485858306,"@thejamestay @Raspberry_Pi Yes! None of the examples requires extensive resources or expensive hardware. The first half of the book can be run on a conventional laptop or Raspberry Pi. For the DL portions, I'd recommend using e.g., Google Colab (the free tier should be sufficient)."
5862,@rasbt,2022-02-26 14:27:26+00:00,https://twitter.com/rasbt/status/1497579060356165634,"@TroyDLoeffler 2/2 W/o any specific ordering, these seem good:
- Interactive tutorial at https://t.co/RPVFwqwjkj
- Think Python by @AllenDowney   https://t.co/85RzB09kbG
- The Treading on Python series by @__mharrison__  https://t.co/5addl15SOP
- Python like you mean it https://t.co/HDUrwkEoUc"
5863,@rasbt,2022-02-26 14:25:03+00:00,https://twitter.com/rasbt/status/1497578460549632000,"@TroyDLoeffler Let me know what you think. Hope this is a useful resource. Maybe, in addition, I would recommend an Introduction to Python to go a long with it 1/n"
5864,@rasbt,2022-02-26 14:08:41+00:00,https://twitter.com/rasbt/status/1497574340467912710,"@bjkvictim Thanks for the note! At first, I was like: wow how can something like that have slipped through. But I think it must be a mistake by the layouter who created the Amazon page. It looks fine in the book itself. I will let them know and have that fixed. https://t.co/XsSlpsL56w"
5865,@rasbt,2022-02-26 14:05:13+00:00,https://twitter.com/rasbt/status/1497573469986467845,@NainaChaturved8 Wow that's a pretty rich resource!
5866,@rasbt,2022-02-26 14:03:24+00:00,https://twitter.com/rasbt/status/1497573013373419522,"@Tinker_1081 @liftingcovered The ebook versions have the charts in color (I embedded all the figures in the Jupyter Notebooks here: https://t.co/1fFQeVXzS9). Personally, I was doing some proof-reading of the ebook on my black&amp;white e-reader and it looks quite ok in grayscale I think https://t.co/lbpyenB5PR"
5867,@rasbt,2022-02-26 14:00:32+00:00,https://twitter.com/rasbt/status/1497572289558335490,"@durgaamma2005 I am not sure about the paperback in India, maybe @PacktPub can help with a more precise answer."
5868,@rasbt,2022-02-26 13:59:25+00:00,https://twitter.com/rasbt/status/1497572012449058817,"@gupta_anik Thanks! And good question. I'd say experience with Python would be good, and maybe some experience with NumPy (but I have a primer for that here: https://t.co/SkStNbFy9u)"
5869,@rasbt,2022-02-26 13:54:54+00:00,https://twitter.com/rasbt/status/1497570875742294018,"@iamreddave Sounds fun, I'd be open to it! :)"
5870,@rasbt,2022-02-26 01:19:07+00:00,https://twitter.com/rasbt/status/1497380672964489216,"@WillingCarol @_MarkConway_ I have a main list of papers organized by topic in my wiki. Other than that, I keep an individual list of papers for each specific project. I don't really store PDFs anymore but just title + (arxiv) URL. For books, I have Calibre, but I mostly access the books from the Finder app"
5871,@rasbt,2022-02-25 23:20:38+00:00,https://twitter.com/rasbt/status/1497350857817477120,"@radekosmulski Wow, thanks so much, Radek. I am really glad to hear that you liked the book. And that's probably one of the kindest compliments I ever got! Big thanks also to my great co-authors without whom this wouldn't have been possible!"
5872,@rasbt,2022-02-25 22:50:34+00:00,https://twitter.com/rasbt/status/1497343291624497167,"@liftingcovered Yeah, personally, I like iBooks, and the Packt version comes with an .epub that you can import into iBooks in case you like it as well (but I think you can also import the .mobi version into the Kindle app) or read the PDF in your favorite PDF reader."
5873,@rasbt,2022-02-25 22:46:16+00:00,https://twitter.com/rasbt/status/1497342207807963138,@liftingcovered That's a good question. I think the difference is that the Amazon Kindle version can be read in their cloud reader. Packt's e-book version can be send to a Kindle though (but not sure if it will be available in the cloud reader)
5874,@rasbt,2022-02-25 22:36:30+00:00,https://twitter.com/rasbt/status/1497339749601845257,"@datadrivenAT @_brohrer_ Hope you'll like it. And oops. Well, maybe the silver lining is that you hopefully had a more relaxed Christmas break üòÖ"
5875,@rasbt,2022-02-25 22:29:49+00:00,https://twitter.com/rasbt/status/1497338067761475584,"@TaliaRinger Professor Mini
Professor Air
Professor
Professor Pro"
5876,@rasbt,2022-02-25 22:08:20+00:00,https://twitter.com/rasbt/status/1497332663207743491,@dabeaz @TaliaRinger And a professor with/at a startup is half or one-and-a-half professor? üòÖ
5877,@rasbt,2022-02-25 22:03:30+00:00,https://twitter.com/rasbt/status/1497331444787654658,@TaliaRinger Ultra professor is if you are still coding and writing yourself ;)
5878,@rasbt,2022-02-25 21:56:17+00:00,https://twitter.com/rasbt/status/1497329629195026432,"@esp_py @chrisalbon @Wikimedia Was just making fun, I learned as much from Chris as he  (probably?) learned from my books :). 
Thanks for the kind words üôè"
5879,@rasbt,2022-02-25 21:47:41+00:00,https://twitter.com/rasbt/status/1497327464447725571,"@esp_py @chrisalbon @Wikimedia More like ""about"" the book üòÖ"
5880,@rasbt,2022-02-25 21:25:52+00:00,https://twitter.com/rasbt/status/1497321976733614080,"@__mharrison__ Thanks, Matt! I'd like to return the favor some time and send you a signed copy, too üòä (once my author copies arrive)"
5881,@rasbt,2022-02-25 21:24:29+00:00,https://twitter.com/rasbt/status/1497321628237275142,@xamat Thanks for the support! I hope you'll like it!
5882,@rasbt,2022-02-25 21:22:59+00:00,https://twitter.com/rasbt/status/1497321248149356556,@therriaultphd Thanks for the kind words and recommendation! üòä
5883,@rasbt,2022-02-25 21:22:12+00:00,https://twitter.com/rasbt/status/1497321052174757894,@Sam_Tracey76 Thanks! I'll be looking forward to hear your feedback (in a few months) :)
5884,@rasbt,2022-02-25 21:21:02+00:00,https://twitter.com/rasbt/status/1497320757847810052,"@_MarkConway_ Hah. Unfortunately, I don't think there is a secret sauce. Just keeping doing things you enjoy :). (Keeping organized though helps a lot https://t.co/3HtDAgjkis)"
5885,@rasbt,2022-02-25 21:19:13+00:00,https://twitter.com/rasbt/status/1497320299863367683,@chrisalbon We didn't get much snow this year ‚õ∑Ô∏è
5886,@rasbt,2022-02-25 21:18:36+00:00,https://twitter.com/rasbt/status/1497320146456694784,@0xhexhex I hope you'll like this one as well! Thanks for your support!
5887,@rasbt,2022-02-25 21:17:48+00:00,https://twitter.com/rasbt/status/1497319943850930176,@chrisalbon Thanks for the kind compliment(?) !
5888,@rasbt,2022-02-25 17:36:47+00:00,https://twitter.com/rasbt/status/1497264322887700870,@tunguz I am pretty sure that this should be possible. I'll reach out to the publisher and will be in touch!
5889,@rasbt,2022-02-25 17:24:41+00:00,https://twitter.com/rasbt/status/1497261280519929864,"@Zia14893121 Thanks, it makes me really glad to hear this"
5890,@rasbt,2022-02-25 15:24:57+00:00,https://twitter.com/rasbt/status/1497231149071929350,"If you are curious what the ""Machine Learning with PyTorch and Scikit-Learn"" book covers and how it is different from ""Python Machine Learning,"" I summarized it in the blog post here: https://t.co/WsT2MwbZdC. Please let me know in case you have any questions."
5891,@rasbt,2022-02-25 15:19:14+00:00,https://twitter.com/rasbt/status/1497229708236369922,"@NikhilJ26842108 This is not how it works, right? üò¨üòÖ https://t.co/zZ00dMU76S"
5892,@rasbt,2022-02-25 15:08:21+00:00,https://twitter.com/rasbt/status/1497226970379206660,"2022 was off to such a good start, and I wish I could make this announcement during better times. A lot of hard work went into this, and I am happy that it is now finally available. At the same time, with the world in disarray, it is hard to be excited about sth at the moment."
5893,@rasbt,2022-02-25 15:08:21+00:00,https://twitter.com/rasbt/status/1497226968894521347,"If you are looking for something for this weekend, my new book *Machine Learning with PyTorch and Scikit-Learn* just came out today: https://t.co/vQv1P30OFR"
5894,@rasbt,2022-02-25 15:02:11+00:00,https://twitter.com/rasbt/status/1497225419208241152,"@jeanmarcalkazzi Hah, yeah. It was only thanks to the new layout with the smaller margins that we could fit everything within the total page limit for print copies üòÖ"
5895,@rasbt,2022-02-25 15:01:11+00:00,https://twitter.com/rasbt/status/1497225165641498639,@FaisalAlsrheed Thanks for the kind words! Glad to hear it could leave a good first impression :)
5896,@rasbt,2022-02-24 14:39:38+00:00,https://twitter.com/rasbt/status/1496857354436063232,"I just saw the horrible news this morning, and it is hard to think about anything else right now. My heart and thoughts are with everyone affected by the war üò¢."
5897,@rasbt,2022-02-24 14:35:49+00:00,https://twitter.com/rasbt/status/1496856393395101697,"@jeanmarcalkazzi wow thanks! I will give you a few weeks, but then I am curious to hear what you think ;)"
5898,@rasbt,2022-02-23 23:23:14+00:00,https://twitter.com/rasbt/status/1496626733960814592,"@CSProfKGD @paintingpeter @tunguz @gusthema What's nice about your own hardware is that it encourages exploration. It completely eliminates questions like ""should I be running this exp. or is it wasteful?"" (Sure, there is electricity cost, but then given that you invested in the machine, idling is also a form of wasteful)"
5899,@rasbt,2022-02-23 23:16:57+00:00,https://twitter.com/rasbt/status/1496625154411184131,@Usman_skhan Thanks for not saying the joy of research is when your paper gets accepted üòÜ
5900,@rasbt,2022-02-23 23:13:20+00:00,https://twitter.com/rasbt/status/1496624243634802693,"@paintingpeter @tunguz @abhi1thakur @fchollet @aureliengeron If you only run ~1 project at the time, you could maybe consider a small desktop with 1 or 2 GPUs. However, it comes with some overhead managing that (and also requires physical space). Besides DL, a good GPU is sth  nice to have if you are also into video games or video editing."
5901,@rasbt,2022-02-23 23:08:20+00:00,https://twitter.com/rasbt/status/1496622986539016196,"@CSProfKGD @paintingpeter @tunguz @gusthema Also, I don't have to worry about software and hardware upgrades, which is nice. Anyways, I think a own server/desktop is great though, and you can also always consider hybrids where you do 90% of the work on your own hardware and 10% in the cloud if you need more or beefier GPUs"
5902,@rasbt,2022-02-23 23:05:36+00:00,https://twitter.com/rasbt/status/1496622296714432513,"@CSProfKGD @paintingpeter @tunguz @gusthema Sure, using the cloud might be more expensive in the long run, but it is more convenient. Esp. for my workflows here I often use Jupyter notebooks. With my own machine, there was a limited number of ports for SSH access, but I can now have infinitely many independent machines."
5903,@rasbt,2022-02-23 23:04:33+00:00,https://twitter.com/rasbt/status/1496622035459616771,"@CSProfKGD @paintingpeter @tunguz @gusthema I swiched to the cloud in January. Much more convenient fore me because my GPUs are pretty old and have limited memory so I had to do workarounds with batch sizes etc. Via cloud, it is super easy to get exactly the type &amp; number of GPUs you need for a given context."
5904,@rasbt,2022-02-23 21:42:18+00:00,https://twitter.com/rasbt/status/1496601334539300867,"@TheRandomMtrix Absolutely. It gets you the dedicated time and space to work away on an interesting problem very intensely, and it can be very productive. I do think that the degrees themselves are overrated and essentially just pieces of paper. It's about the skills and mindset you develop."
5905,@rasbt,2022-02-23 21:40:19+00:00,https://twitter.com/rasbt/status/1496600836335669250,"@themintsv On the other hand, I know so many people who have great positions in industry without a PhD. It's really a wide range of jobs in industry, and most great jobs don't require a PhD."
5906,@rasbt,2022-02-23 21:33:04+00:00,https://twitter.com/rasbt/status/1496599012253831171,"Would I do it again and/or recommend it. Hard to tell. I took this particular path and don't have an alternative path for the comparison. Do I have regrets? No, I think everything turned out well in the end (however, there were periods where I almost quit)."
5907,@rasbt,2022-02-23 21:31:02+00:00,https://twitter.com/rasbt/status/1496598498992656396,"Working on research, that is, creating new insights and knowledge, is a dance between frustration and joy -- depending on how the experiments go. But either way, on this journey, you'll learn how to learn and how to organize projects. Very important life skills."
5908,@rasbt,2022-02-23 21:25:58+00:00,https://twitter.com/rasbt/status/1496597226939981831,"If you have the opportunity to do a PhD, should you take it? It depends. It's one of the big decisions in life, and you'll hear different advice depending on who &amp; when you ask. And it is very useful to pool advice from different sources. Below is an extremely useful thread:"
5909,@rasbt,2022-02-23 19:21:29+00:00,https://twitter.com/rasbt/status/1496565899045871621,@TaliaRinger But for occasional use it's really nothing to worry about. I think you'll enjoy it. It's a really fun toy :)
5910,@rasbt,2022-02-23 19:20:35+00:00,https://twitter.com/rasbt/status/1496565672683442182,"@TaliaRinger The individual GPUs get around 80C each when in use. Can get pretty toasty when you run it for a few hours. Haha, but yeah, in winter I didn't mind because it was a bit cold in my office indeed -- Wisconsin weather and leaky windows. Noise is approx like a table fan on full power"
5911,@rasbt,2022-02-23 18:44:26+00:00,https://twitter.com/rasbt/status/1496556575217131521,@TaliaRinger PS: Happy to share my wiki pages on running Jupyter Lab remotely from your laptop in case it's useful.
5912,@rasbt,2022-02-23 18:42:11+00:00,https://twitter.com/rasbt/status/1496556009023852546,"@TaliaRinger Awesome, congrats! That's really exciting! And it looks particularly pretty in the dark üåÉ. One little caveat is that it does get a bit loud and hot, so I ended up moving it to our server room. But yeah, it's 4 years old and still running smoothly after all this time! https://t.co/sAlgANTLOb"
5913,@rasbt,2022-02-22 22:31:19+00:00,https://twitter.com/rasbt/status/1496251283078004742,@kushashwa @gridai_ @PyTorchLightnin @_willfalcon @lantiga This is exciting ü•≥! Welcome to the team! üéâ
5914,@rasbt,2022-02-22 15:31:56+00:00,https://twitter.com/rasbt/status/1496145742863519757,"@ragasimger Sure, no problem. The TOC is on GitHub https://t.co/1fFQeWfbgJ. There is one chapter overview in the main Readme. And each chapter has its own more detailed TOC in its Readme. Let me know if you have any questions."
5915,@rasbt,2022-02-22 15:24:30+00:00,https://twitter.com/rasbt/status/1496143872724017154,"@ragasimger Sorry, I am not familiar with this book"
5916,@rasbt,2022-02-22 15:14:43+00:00,https://twitter.com/rasbt/status/1496141407622414342,"@ragasimger Sure. So there is Ch 11 where I show how to implement a simple neural network (multilayer perceptron) from scratch in NumPy. Then, from Ch 12 on (pg. 369/768) everything is deep learning: PyTorch, CNNs, RNNs, GANs, transformers, GNNs. (Ok, except the last chapter on RL of course)"
5917,@rasbt,2022-02-22 13:52:20+00:00,https://twitter.com/rasbt/status/1496120675181993997,@ragasimger The book is approximately 50% non-neural network ML and 50% DL. But yeah besides that I don‚Äôt have any other DL book (only a course)
5918,@rasbt,2022-02-21 20:14:22+00:00,https://twitter.com/rasbt/status/1495854430687801351,"@tez_romach Thanks for all your valuable insights, time, and feedback! I really really appreciate that!"
5919,@rasbt,2022-02-21 18:32:15+00:00,https://twitter.com/rasbt/status/1495828731209920516,"@akatzzzzz @DieterCastel @CSProfKGD @JuliaLanguage *But to clarify, with ""what you can do with it"" above I meant more the dynamism parts and language restrictions."
5920,@rasbt,2022-02-21 18:27:53+00:00,https://twitter.com/rasbt/status/1495827631144673286,"@akatzzzzz @DieterCastel @CSProfKGD @JuliaLanguage 2/2 I think the student loves Julia overall, but the feedback I heard was that it was painful to use Julia for deep learning in this context, and the student wished to have chosen PyTorch for this project (because more mature?). But it is maybe anecdotal, I dunno."
5921,@rasbt,2022-02-21 18:25:37+00:00,https://twitter.com/rasbt/status/1495827063835701257,"@akatzzzzz @DieterCastel @CSProfKGD @JuliaLanguage Wow that's an awesome article, thanks for sharing! Yeah, I think people go to extreme pains and workarounds to make things work in Python :). (I wonder if Swift for TensorFlow didn't take off because of Python)."
5922,@rasbt,2022-02-21 17:28:19+00:00,https://twitter.com/rasbt/status/1495812643352985600,"@liftingcovered Yes, I think that's it! (PS: and I am glad to hear my lecture content is useful!)"
5923,@rasbt,2022-02-21 17:08:53+00:00,https://twitter.com/rasbt/status/1495807753075544070,"@liftingcovered Nice! Good luck and I hope you'll have fun! For the iPad approach, I used Keynote (running on my Mac) with the iPad as a remote device. I like that for the pen tablet, I can look directly into the camera and I also have more software-pen options, but hand-coordination is harder"
5924,@rasbt,2022-02-21 15:48:03+00:00,https://twitter.com/rasbt/status/1495787409249812484,"@ammaryh92 Good question. Unless you are planning to use PyTorch, the second half of the book might maybe be too much PyTorch for someone who prefers TensorFlow. However, I think the transformer and graph neural network chapters are pretty agnostic (although they also contain codes)"
5925,@rasbt,2022-02-21 14:05:11+00:00,https://twitter.com/rasbt/status/1495761523188379649,"@John4man Hot take: as someone who didn't grew up in the US, the US power outlets &amp; plugs feel like first drafts to begin with üòÜüòÖ"
5926,@rasbt,2022-02-21 13:58:21+00:00,https://twitter.com/rasbt/status/1495759803733483524,"Only 4 more days until my new book, Machine Learning with PyTorch and Scikit-Learn, is going to be released! Packt invited me on to their Expert Insight series for a live launch event on Wednesday morning. Please feel free to join and AMA about the book üòähttps://t.co/wX6VNOsEI3 https://t.co/nVXewXjao2"
5927,@rasbt,2022-02-21 13:47:35+00:00,https://twitter.com/rasbt/status/1495757093466427396,"@DieterCastel @CSProfKGD @JuliaLanguage Sure, but you can also say this about about operating systems, web browsers, messaging platforms, etc."
5928,@rasbt,2022-02-21 13:33:31+00:00,https://twitter.com/rasbt/status/1495753551473254403,"@DieterCastel @CSProfKGD @JuliaLanguage Yeah, I was thinking the same thing. Because if you just want NumPy on the GPU, there is already CuPy. Or, if you want autograd with it, there is PyTorch. Or, maybe it's really more about the TPUs?"
5929,@rasbt,2022-02-21 13:31:10+00:00,https://twitter.com/rasbt/status/1495752963293384704,"@DieterCastel @CSProfKGD @JuliaLanguage You are right, it is probably not a big deal to pick up Julia, but look at Torch and Lua. People don't want to learn yet another thing while there is already so much other stuff to learn. It could also be the existing code bases. Look at how long it took to migrate Python 2 -&gt; 3"
5930,@rasbt,2022-02-21 13:29:29+00:00,https://twitter.com/rasbt/status/1495752537542172687,"@DieterCastel @CSProfKGD @JuliaLanguage I think the drop-in replacement here is pretty significant though. I remember the early days of PyTorch where the Tensor API was ""only"" 90% like the NumPy syntax, and the community wanted more (which is why they changed it to get it to ~99% NumPy-like syntax)"
5931,@rasbt,2022-02-21 13:26:55+00:00,https://twitter.com/rasbt/status/1495751892919631873,"@DieterCastel @CSProfKGD @JuliaLanguage I think you could just change ""import numpy as np"" to ""import jax.numpy as np"" and are good to go. But you are right though, if you want to get the extra functionality (like autograd), you'd have to learn something more :)"
5932,@rasbt,2022-02-21 13:16:37+00:00,https://twitter.com/rasbt/status/1495749301338886146,@DieterCastel @CSProfKGD @JuliaLanguage And then for Jax there is more mature GPU and TPU support for the deep learning APIs?
5933,@rasbt,2022-02-21 13:14:19+00:00,https://twitter.com/rasbt/status/1495748719479865347,@DieterCastel @CSProfKGD @JuliaLanguage Dunno. Maybe because people love NumPy and Jax is a drop-in replacement for NumPy.
5934,@rasbt,2022-02-21 13:00:55+00:00,https://twitter.com/rasbt/status/1495745348668637190,"@DieterCastel @CSProfKGD @JuliaLanguage Well, one difference is that Jax is a Python library, not a programming language. And that‚Äôs a big one."
5935,@rasbt,2022-02-21 03:28:44+00:00,https://twitter.com/rasbt/status/1495601353808400387,"@DorGoldenberg @yaroslavvb Hah, haven't thought this through. Unfortunately, that's a good point."
5936,@rasbt,2022-02-21 03:26:48+00:00,https://twitter.com/rasbt/status/1495600869437591553,"Great figure illustrating the different types of deep generative models via @lilianweng  (https://t.co/4NJZzr9HKF) &amp;  nice list of cons. GANs: unstable training, low diversity; VAE: surrogate loss; Flow-based: special architecture for reversible transf (Diffusion: slow to sample) https://t.co/zl4RLIW3EB"
5937,@rasbt,2022-02-21 03:00:52+00:00,https://twitter.com/rasbt/status/1495594342169382916,"@CSProfKGD Haha, what's probably holding me back is that I don't do enough mathy stuff to find this useful. Also, I have some decision paralysis here: which deep learning framework/API should I be using for Jax? Flax, Haiku, Elegy, or sth else? And which one will still be around in 2 years?"
5938,@rasbt,2022-02-21 02:53:28+00:00,https://twitter.com/rasbt/status/1495592481328701444,"@CSProfKGD Coincidentally, I just read ""Why You Should (or Shouldn't) Be Using JAX in 2022"" on my way home yesterday: https://t.co/228uB9PnOK. I was always like why would I need this for my workflow? But there are goodies like ""JAX can compute Hessians remarkably faster than PyTorch"""
5939,@rasbt,2022-02-21 02:49:00+00:00,https://twitter.com/rasbt/status/1495591356974223366,"@mmitchell_ai Wow, I wish I kept mine just for this :) (although it was maybe only 10% of it). I usually tend to get rid of it every time I move (although I started collecting again). Same with (text)books, which usually donate before moving (also to make room for new ones üòÖ)"
5940,@rasbt,2022-02-20 19:15:15+00:00,https://twitter.com/rasbt/status/1495477167156875269,"Excellent article on quantization for deep neural networks &amp; how to do it in PyTorch. If you are mainly working with 32-bit tensors and (w/o buying a new GPU)
(a) want to speed up your networks while 
(b) also lowering the memory pressure, 
have a look: https://t.co/cgChzvfmWe"
5941,@rasbt,2022-02-20 18:44:16+00:00,https://twitter.com/rasbt/status/1495469368733581319,"@LayneSadler @PacktPub @KirkDBorne @Datafloq @kdnuggets @SteveNouri @lnxbox @hackernoon @chanin_nanta @KenJee_DS @PacktAuthors Oops. A book on design &amp; layout probably shouldn't be b&amp;w ü§î. But then, I nowadays read books on a b&amp;w e-ink reader üòÖ."
5942,@rasbt,2022-02-20 14:54:26+00:00,https://twitter.com/rasbt/status/1495411528656474122,"@DorGoldenberg @yaroslavvb PT Lightning should work pretty seamlessly with Optuna. Essentially, you can just put the trainer-related code (.fit() and .test()) into the Optuna objective function. Here's an example: https://t.co/x5EbGpJmqx"
5943,@rasbt,2022-02-19 21:03:50+00:00,https://twitter.com/rasbt/status/1495142101994061831,"@tdietterich @yaroslavvb Can totally relate. Now with PT Lightning it is really as easy as setting devices=2, =4, or just devices=‚Äúauto‚Äù to use them all. But yeah, having this build in would probably lower the barrier to entry even more."
5944,@rasbt,2022-02-19 20:45:58+00:00,https://twitter.com/rasbt/status/1495137605612093442,@yaroslavvb But if I had to pick one I‚Äôd say c). I know so many people who (could) have access to at least a couple of GPUs via cloud or university clusters but are still stuck with a 1 model / GPU paradigm because configuring multi-GPU training is sometimes still tricky or extra effort
5945,@rasbt,2022-02-19 20:31:23+00:00,https://twitter.com/rasbt/status/1495133936548253700,@yaroslavvb If you had asked me a few months ago and my answer would have been üíØ in all cases. But since I discovered and started using PyTorch Lightning ‚Ä¶ üòä
5946,@rasbt,2022-02-19 17:41:48+00:00,https://twitter.com/rasbt/status/1495091261107175426,@cabitzaf Was just in Milan earlier this year. Amazing city and definitely would be down for another visit. This overlaps with SciPy 2022 though but thanks for forwarding.
5947,@rasbt,2022-02-19 14:09:43+00:00,https://twitter.com/rasbt/status/1495037888089628675,"@tymwol @fishnets88 Yeah, this. PS: my first thought was what if we talk about self driving cars here. Like I can wait 20 sec until it recognizes the stop sign üôÉ"
5948,@rasbt,2022-02-19 14:03:53+00:00,https://twitter.com/rasbt/status/1495036418854309893,"@ylecun But also doesn‚Äôt mean we shouldn‚Äôt innovate and try :).And even if it is just to provide concepts and ideas, and inspire Python 4 üòä"
5949,@rasbt,2022-02-19 13:55:46+00:00,https://twitter.com/rasbt/status/1495034376882561026,"@ylecun But yeah, at the same time it'd be really hard to switch over to anything that is not Python. Python has an awesome and strong community, and that's something hard to build from the ground up. Julia makes a lot of sense for ML/DL, too, but yeah, it didn't get picked up."
5950,@rasbt,2022-02-19 13:53:54+00:00,https://twitter.com/rasbt/status/1495033906516533248,"@ylecun Very interesting! Thanks for sharing! At first glance, due to the features around side-effects (yeah, for real-world uses cases and convenience, no one wants to rely on a purely functional paradigm) and caching, I think that it could be an excellent language for DL."
5951,@rasbt,2022-02-18 23:54:54+00:00,https://twitter.com/rasbt/status/1494822765114781696,"@bonni208 @katemath @joshua_r_eyler @tihighered I deeply enjoy sharing knowledge and teaching people something cool that's useful to them. But yeah, grading takes a lot of fun out of it. Wish we could skip the grading part &amp; just let students' accomplishments (eg class projects they share on their resumes) speak for themselves"
5952,@rasbt,2022-02-18 23:19:53+00:00,https://twitter.com/rasbt/status/1494813954043899906,"One of my early ML projects was on generating happy music. There was Musicmood üé∂(https://t.co/wCCXLiZUEj) to label songs. And then I tried RNNs to generate happy lyrics (and happy midi melodies). Now, I feel so humbled after trying the SAM neural net at https://t.co/u3gwjdllxm"
5953,@rasbt,2022-02-18 21:57:01+00:00,https://twitter.com/rasbt/status/1494793100362801155,"@amritd8 I do read on it sometimes, but yeah, e-readers generally don't have the best contrast (esp. if you want to read in the evenings). For annotation, it's fine, but then when you want to take extensive notes, you don't have enough space (you would basically need 2 devices, lol)"
5954,@rasbt,2022-02-18 21:54:50+00:00,https://twitter.com/rasbt/status/1494792548329480193,"@amritd8 Based on my reading, I heard it offers the best writing experience, and the sync workflow sounded super smooth (and it is). Also the fact that it had a pretty large community and seems pretty actively supported."
5955,@rasbt,2022-02-18 16:31:22+00:00,https://twitter.com/rasbt/status/1494711147957682178,@ezyang That HDMI plug though. One fewer thing to pack and worry about.
5956,@rasbt,2022-02-18 16:28:52+00:00,https://twitter.com/rasbt/status/1494710518447153155,@CSProfKGD @Michael_J_Black Nice! Thinking about a startup ‚Ä¶? üòá
5957,@rasbt,2022-02-18 16:24:57+00:00,https://twitter.com/rasbt/status/1494709533188374528,@tacaswell @amuellerml Matplotlib is such an essential tool. This is awesome to hear!
5958,@rasbt,2022-02-18 05:34:04+00:00,https://twitter.com/rasbt/status/1494545730362478593,@TaliaRinger @LambdaAPI Nortech is more like a components or parts supplier but you can reach out to them and they‚Äôll put together (the parts for) a machine for you (I actually have both a Lambda workstation and server from Nortech).
5959,@rasbt,2022-02-18 05:30:41+00:00,https://twitter.com/rasbt/status/1494544882328752128,"@TaliaRinger @LambdaAPI Wow, went through exactly the same hassle a few years ago when buying my Lambda machine. Our former department IT guy helped with that but it was lots of back &amp; forth because we couldn‚Äôt find a good comparable product. I think we got a quote from Nortech when I remember correctly"
5960,@rasbt,2022-02-17 15:26:47+00:00,https://twitter.com/rasbt/status/1494332504966270981,@Suleymanzade Oh actually I don‚Äôt use WordPress or any plugins. It‚Äôs pure HTML. Problem was that I am traveling and tried to update my website remotely üòÖ
5961,@rasbt,2022-02-17 15:25:44+00:00,https://twitter.com/rasbt/status/1494332240955785221,@ChristophMolnar @mSchmitz_ Wohooo ü•≥
5962,@rasbt,2022-02-17 15:25:16+00:00,https://twitter.com/rasbt/status/1494332123410432005,"@ChristophMolnar I remember Watson! However, I actually didn‚Äôt know it was still a thing (no pun intended)"
5963,@rasbt,2022-02-17 15:15:03+00:00,https://twitter.com/rasbt/status/1494329553627467785,"@Suleymanzade Thanks for the note! Looks like there was a file permission issue on the webserver. Should be fixed now! (If not, please let me know!)"
5964,@rasbt,2022-02-17 14:56:41+00:00,https://twitter.com/rasbt/status/1494324932217507855,"@ccanonne_ Haha, as someone who prefers starting with examples and plots, I usually end up with the opposite problem: this looks obvious but how do I best proof it üòÖ"
5965,@rasbt,2022-02-17 02:35:49+00:00,https://twitter.com/rasbt/status/1494138487758475264,"@leonpalafox Yeah, ""wiki"" is my go to if I need dates and numbers, and ""reddit"" for discussions, resources, and product reviews."
5966,@rasbt,2022-02-17 02:28:52+00:00,https://twitter.com/rasbt/status/1494136738528186368,"Wow, I was pretty sure I discovered a genius trick but apparently I am not the only one üòÖ... 
""Google search quality is declining because of too many ads, SEO, and 'smart' AI, prompting people to append 'reddit' to queries to get more authentic result"".  https://t.co/IO9yFm6zhZ"
5967,@rasbt,2022-02-16 22:24:53+00:00,https://twitter.com/rasbt/status/1494075337587585025,@introspection @UMontreal @ppsp_team @deepernix Wow huge congrats! üéäüéàüéâ
5968,@rasbt,2022-02-16 22:22:00+00:00,https://twitter.com/rasbt/status/1494074611469668352,@roydanroy FWD:
5969,@rasbt,2022-02-16 22:17:10+00:00,https://twitter.com/rasbt/status/1494073396254052356,"@dabeaz @TaliaRinger It‚Äôs expensive but can be covered from your start up funds. Problem is maintaining it and keeping it up to date. Given how busy things get, one more thing to manage. But yeah it‚Äôs doable"
5970,@rasbt,2022-02-16 21:43:15+00:00,https://twitter.com/rasbt/status/1494064859931049986,"@AllenDowney 2/2 then there is also the issue that service is limited when you are not a resident, and their support staff is usually only available during EU business hours. On top of that also one more hassle to add to your tax return."
5971,@rasbt,2022-02-16 21:41:29+00:00,https://twitter.com/rasbt/status/1494064415246675968,"@AllenDowney I would stay away from it. As former EU bank account owner, their software is a hassle to deal with (eg they roll their own 2-factor auth software that is buggy) and it relies on physical mail to get access which is painful when you get a new device. 1/2"
5972,@rasbt,2022-02-16 21:38:26+00:00,https://twitter.com/rasbt/status/1494063648267898881,"@troythedataguy That is true. Also, if you go with your own hardware, doesn‚Äôt mean you can never use cloud resources when needed. Eg say you are fine with 16 Gb memory per GPU 90% of the time but for that one experiment you really need to to 60+ GB."
5973,@rasbt,2022-02-16 21:29:25+00:00,https://twitter.com/rasbt/status/1494061378453192704,"@troythedataguy Yeah can be cheaper when used extensively. Personally, as I made the move from my own servers and local cluster to cloud computing this year, it really made things so much simpler though. Less stuff to worry about re aging hardware and software and keeping everything up to date."
5974,@rasbt,2022-02-16 18:05:03+00:00,https://twitter.com/rasbt/status/1494009945666338817,@amy_tabb I'd say built-in so that it doesn't throw off my local editor
5975,@rasbt,2022-02-16 14:02:29+00:00,https://twitter.com/rasbt/status/1493948903078735876,Wow really awesome new feature üéâ. (PS: but I still want LaTeX math/mathjax support üòÖ)
5976,@rasbt,2022-02-16 04:33:20+00:00,https://twitter.com/rasbt/status/1493805670373675008,"@michael_nielsen Hah, coincidentally I am reading it right now. Half-way through, and I have a similar feelings so far. I kind of enjoy it though but maybe not as much as I thought (based on the premise and hype). Should maybe also try a second read afterwards :)"
5977,@rasbt,2022-02-16 04:21:21+00:00,https://twitter.com/rasbt/status/1493802655826825222,"@anwarvic_ Yeah! I got the prices from https://t.co/ufnsjwGMZf, which I am currently using. But it's based on AWS instances. These are prices for the regular ones. Spot instances would be cheaper. https://t.co/Yq7i0Bj9GL"
5978,@rasbt,2022-02-16 04:00:53+00:00,https://twitter.com/rasbt/status/1493797505636708354,"@anwarvic_ Sure! It's like 60% of the performance of a V100 at 1/6 of the price. And it's twice as fast as the K80 or M60 while being substantially cheaper

K80 4.113 TFLOPS (FP32), $0.90/h
M60 4.825 TFLOPS (FP32), $0.75/h
T4  8.141 TFLOPS (FP32), $0.53/h 
V100 14.13 TFLOPS (FP32), $3.06/h"
5979,@rasbt,2022-02-16 00:55:11+00:00,https://twitter.com/rasbt/status/1493750772856721413,@marktenenholtz It's awesome! One of the few selected threads that I added to my bookmark list to revisit for years to come üòä
5980,@rasbt,2022-02-16 00:51:41+00:00,https://twitter.com/rasbt/status/1493749893944393737,"Informative thread on using cloud GPUs. My personal favorite is currently the T4. Offers a good bang-for-buck value, and it's still affordable to use instances with 4 of them for multi-GPU training."
5981,@rasbt,2022-02-15 18:32:06+00:00,https://twitter.com/rasbt/status/1493654368343707650,"@alfcnz @efish__ @isalirezag @dxgp_ Oh I see. I think that's what some apps call ""Typewriter Mode"". My favorite markdown editor (Typora) has that :)"
5982,@rasbt,2022-02-15 16:11:29+00:00,https://twitter.com/rasbt/status/1493618981487456256,"@alfcnz @efish__ @isalirezag @dxgp_ Huh, either a bug or we define scrolling differently üòÖ"
5983,@rasbt,2022-02-15 16:10:17+00:00,https://twitter.com/rasbt/status/1493618676494446603,"Just found out about scikit-lego! Wow, lots of cool, useful stuff in here like sklego.preprocessing.RandomAdder (to add randomness in training), sklego.pipeline.DebugPipeline (better debugging) and many more: https://t.co/1oCoYCE2Z2"
5984,@rasbt,2022-02-15 15:21:48+00:00,https://twitter.com/rasbt/status/1493606477650710530,"@alfcnz @isalirezag @dxgp_ Oops, they either added it in the last few years and/or I have been blind. It also has collapsable sections, I like it!"
5985,@rasbt,2022-02-15 14:55:10+00:00,https://twitter.com/rasbt/status/1493599773768785924,"@marktenenholtz I think the T4‚Äôs are great. It‚Äôs around 50 cent per hour, and I usually use 4xT4‚Äôs now. It‚Äôs still cheaper than a single V100."
5986,@rasbt,2022-02-15 14:47:20+00:00,https://twitter.com/rasbt/status/1493597803850960898,"@CSProfKGD @LassondeSchool Hoping in your case they can fix it in a reasonable time, but well, I also like the projector you got üòä."
5987,@rasbt,2022-02-15 14:45:52+00:00,https://twitter.com/rasbt/status/1493597435343613958,"@CSProfKGD @LassondeSchool Reminds me, during our first in-person semester last semester, after 10 min or so the touch screen control panel would activate random buttons and eventually press the off button of the projector. It took at least 3 calls and a month to get it fixed. So annoying."
5988,@rasbt,2022-02-15 14:41:52+00:00,https://twitter.com/rasbt/status/1493596424768040977,"@CSProfKGD @LassondeSchool Wow that‚Äôs some dedication to teaching right there! Also, PyTorch ‚ù§Ô∏è"
5989,@rasbt,2022-02-15 13:09:43+00:00,https://twitter.com/rasbt/status/1493573235996336133,"@cbrnr_ It is just the standard iPad though, not the pro version. And there are probably display foils that add a little friction and improve the writing feeling. I think I‚Äôve seen that among students who use the iPad for note taking in class (basically everyone does nowadays)"
5990,@rasbt,2022-02-15 13:07:13+00:00,https://twitter.com/rasbt/status/1493572607081422852,"@cbrnr_ Interesting! I do read on my iPad quite a lot, incl ebooks in iBooks (the dark background on the lowest brightness level is perfect for me at night) but I never liked it for note taking. Don‚Äôt like the feeling writing on glass, and the palm rejection often fails me"
5991,@rasbt,2022-02-15 03:59:48+00:00,https://twitter.com/rasbt/status/1493434843492982785,@amritd8 Sure! Please let me know if you have any questions. I love chatting about tech gadgets üòÜ
5992,@rasbt,2022-02-15 03:58:26+00:00,https://twitter.com/rasbt/status/1493434500684128258,"@cbrnr_ But for having everything easily available in digital, that's a worthy trade-off. It has a built-in OCR, but I also often transcribe notes manually (it's a useful extra step for reviewing), and having the handwriting on the screen next to your text editor is very convenient"
5993,@rasbt,2022-02-15 03:54:45+00:00,https://twitter.com/rasbt/status/1493433575571603458,"@cbrnr_ Actually one thing that bothers me a bit is the not-so-great contrast. It's fine during the day, but it's not great in the evening. Just noticed that when I pulled out one of my paper notebooks to look sth up. But to be fair, I think all current e-inks have that issue https://t.co/OSH8dN5f8C"
5994,@rasbt,2022-02-15 03:06:34+00:00,https://twitter.com/rasbt/status/1493421450438586372,"""AlterNet outperforms CNNs not only in large data regimes but also in small data regimes"" üëÄ"
5995,@rasbt,2022-02-15 01:34:39+00:00,https://twitter.com/rasbt/status/1493398317849620481,"Another super impressive paper is ""Asymptotic Analysis via Stochastic Differential Equations of Gradient Descent Algorithms in Statistical and Computational Paradigms"" by my colleague Yazhen Wang: https://t.co/snb70RtNC7. Just skimming it is already a very humbling experience."
5996,@rasbt,2022-02-15 01:31:04+00:00,https://twitter.com/rasbt/status/1493397414623031299,This was usually my go-to paper to share with students who were interested in more mathematical deep learning papers üòÖ
5997,@rasbt,2022-02-15 01:31:03+00:00,https://twitter.com/rasbt/status/1493397413062758414,"It's actually a very accessible 9-pager ... but wait until you see the 93 pages of the appendix with more than 320 equations &amp; 47 Lemmas. It's a great paper, but if you include the appendix, you can probably call it a director's cut + release it as a book. https://t.co/fkd9pAZzk0"
5998,@rasbt,2022-02-14 22:37:41+00:00,https://twitter.com/rasbt/status/1493353782876549120,Really looking forward to the ReWork Deep Learning Summit this week! Haven't been to a conference in years &amp; think it's gonna be fun! Will talk about DL for ordered labels (https://t.co/kxhSXjUwDB)! Let me know in case you are there too and want to meet up and chat about DL &amp; AI!
5999,@rasbt,2022-02-14 22:02:13+00:00,https://twitter.com/rasbt/status/1493344856281956353,"@TaliaRinger Over the years, I adapted to treat my inbox like my Twitter timeline; it's realizing that it's impossible to read it all. I am trying very hard to be disciplined and not to spend more than 1 hour per day on email. It's hard."
6000,@rasbt,2022-02-14 19:16:44+00:00,https://twitter.com/rasbt/status/1493303210165116928,"@ducnh279 @GaelVaroquaux Very nice, thanks for sharing! Hah, and as some homework for myself, I have to read up on gap encoding. I don't think I ever used it."
6001,@rasbt,2022-02-14 17:58:41+00:00,https://twitter.com/rasbt/status/1493283571221606412,"@amritd8 Syncing with the computer is super smooth. So I would take notes on that device when reading or having meetings, and then I'd transfer it to the corresponding project folder right after. It's a pretty smooth experience so far."
6002,@rasbt,2022-02-14 17:55:27+00:00,https://twitter.com/rasbt/status/1493282757518233609,"@cbrnr_ I do read on it, too, but it's mostly for writing. I do read blog articles on it sometimes and annotate them. However, I think if you want to read &amp; write effectively, you probably need 2 devices side-by-side for that üòÖ"
6003,@rasbt,2022-02-14 17:53:38+00:00,https://twitter.com/rasbt/status/1493282299378647043,"@cbrnr_ Yes, I do miss color sometimes. Had a Sony Digital Paper for reading before, and yes, the absence of color was why I sold it again. Right now, I am using a Remarkable, but since I mainly use it as a notetaking device (rather than a reading tablet), the absence of color is ok"
6004,@rasbt,2022-02-14 17:51:43+00:00,https://twitter.com/rasbt/status/1493281817608298499,"@guillemch Haha, yes! I needed a leaner solution (esp. when traveling), and I wanted to have a more convenient workflow for digitizing my notes."
6005,@rasbt,2022-02-14 04:09:38+00:00,https://twitter.com/rasbt/status/1493074934230355972,"* Revisiting my blog post, one little amendment is that I finally switched from pen&amp;paper to e-ink. Pls feel free to AMA."
6006,@rasbt,2022-02-14 03:09:52+00:00,https://twitter.com/rasbt/status/1493059889903677443,@Plinz just wait until people start training DL/AI models on philosophical questions and debates
6007,@rasbt,2022-02-14 01:26:36+00:00,https://twitter.com/rasbt/status/1493033902365200384,I felt like I was spread so thin over so many areas of responsibility in the last few years that I totally forgot how much fun it is to focus on 1-2 things deeply! Last time must have been in grad school. Exciting times and lots of exciting contents in the making ...
6008,@rasbt,2022-02-14 01:26:35+00:00,https://twitter.com/rasbt/status/1493033900918067200,"The way I organize my project data is to keep a project folder on my computer (as I described here: https://t.co/3HtDAgjkis‚Ä¶). Recently, I have been focused on focusing! During today's weekly review, I finally reached the point where there is less than a handful of projects left"
6009,@rasbt,2022-02-13 20:47:59+00:00,https://twitter.com/rasbt/status/1492963785623191552,"@DrJohnWagner Thanks, btw. This is way more elegant."
6010,@rasbt,2022-02-13 20:44:07+00:00,https://twitter.com/rasbt/status/1492962813542899717,"@DrJohnWagner Haha, I clearly spent too much time working exclusively with NumPy arrays and PyTorch tensors recentlyüòÖ"
6011,@rasbt,2022-02-13 20:35:02+00:00,https://twitter.com/rasbt/status/1492960528242814978,"@GaelVaroquaux Awesome! And no, not yet. I have had your dirty_cat talk in my YT playlist for months ... should finally get to it! :)"
6012,@rasbt,2022-02-13 20:18:20+00:00,https://twitter.com/rasbt/status/1492956324807811077,@DrJohnWagner haha agreed on both accounts üòÑ
6013,@rasbt,2022-02-13 20:13:58+00:00,https://twitter.com/rasbt/status/1492955226999033866,"@DrJohnWagner Yeah, it was weird that it read the column as type object. Btw. your solution works, but then it doesn't generalize to settings where you use the transformer in e.g., GridSearchCV etc. I would just do 
""df['numerical'] = df['numerical'].astype(float)"" 
after reading in the df."
6014,@rasbt,2022-02-13 19:56:34+00:00,https://twitter.com/rasbt/status/1492950847747207173,@thomasjpfan Oh that makes sense! And I should have checked. I was already wondering why I never needed this hack before üòÖ. Will update! Thanks!
6015,@rasbt,2022-02-13 19:26:24+00:00,https://twitter.com/rasbt/status/1492943256539303941,@DanLewis3264 @JSEllenberg You could take a hybrid approach and annotate slides. And after the lecture you can share those annotated slides so that students don't have to spent most of their mental capacity on trying to copy things from the board.
6016,@rasbt,2022-02-13 19:21:29+00:00,https://twitter.com/rasbt/status/1492942020209528832,"@JSEllenberg [3/3] To be honest, this made math classes were super boring and frustrating for me. Today, I really dislike math and wonder if it's because of this.

*counter example: there are many people who love and are really good at math despite of this"
6017,@rasbt,2022-02-13 19:20:33+00:00,https://twitter.com/rasbt/status/1492941785441705994,"@JSEllenberg [2/3] When I took math classes, I had to be super focused on deciphering handwritings &amp; just copying stuff from the board rather than trying to follow along. Only at home, I would be able to review and think about the material, but then it was usually too late to ask questions."
6018,@rasbt,2022-02-13 19:19:45+00:00,https://twitter.com/rasbt/status/1492941583334924296,"@JSEllenberg ""it might be that showing students we care could mean making nice prepared slides like the professors in all their non-math classes do, instead of just showing up and writing on the blackboard."" -- yes, please! [1/3]"
6019,@rasbt,2022-02-13 19:02:46+00:00,https://twitter.com/rasbt/status/1492937309771153410,"I have ""Learn a useful programming thing"" on my Daily Habits list. I think I am done for today. Thanks, Twitter!"
6020,@rasbt,2022-02-13 18:01:20+00:00,https://twitter.com/rasbt/status/1492921847368888336,@kchowdha Good point. There was no particular reason. Updated it!
6021,@rasbt,2022-02-13 17:17:12+00:00,https://twitter.com/rasbt/status/1492910743943065603,"@pwang Yes üôå. Btw if you have multiple things connected (eg for me the MagSafe cable with the original charger and the USB-C charger through the dock I usually use for my MBAir) it will automatically figure things out and use the one with the higher wattage, which is nice."
6022,@rasbt,2022-02-13 17:09:38+00:00,https://twitter.com/rasbt/status/1492908838693085195,A blog with fun and/or insightful musings
6023,@rasbt,2022-02-13 17:08:38+00:00,https://twitter.com/rasbt/status/1492908587680677893,"You know, one reason for posting this is that I am hoping that someone has a more elegant solution for this üòÖ"
6024,@rasbt,2022-02-13 17:07:27+00:00,https://twitter.com/rasbt/status/1492908290203922433,"@PreetumNakkiran True! Btw I don‚Äôt think I was ever asked for my H-index or citations, so I hope the tides are turning and we learn to assess contributions more qualitatively"
6025,@rasbt,2022-02-13 16:56:09+00:00,https://twitter.com/rasbt/status/1492905445606010884,"@DrGroftehauge E.g., think of a case where you have categories ""a, b, c, d"". The pandas get_dummies() function would fail if your new data example (or validation set) only has examples from categories ""a"" and ""b"" because it is stateless."
6026,@rasbt,2022-02-13 16:50:17+00:00,https://twitter.com/rasbt/status/1492903966702813184,"@DrGroftehauge Good question. The main reason is that it doesn't work well when you use cross-validation etc. Ok, yeah, you an use it on all your data upfront, but with sklearn's its a more general solution so that you can more easily use it on new, incoming data."
6027,@rasbt,2022-02-13 16:35:57+00:00,https://twitter.com/rasbt/status/1492900362768035842,"@ducnh279 yeah! I actually use it some times and like it. I started using sklearn before these existing, so I am sometimes old school and revert to the old way. Haha, I am also sometimes debating whether these functions are overkill."
6028,@rasbt,2022-02-13 16:33:31+00:00,https://twitter.com/rasbt/status/1492899749560827904,"Or, maybe the best demo of scikit-learn's flexibility (and hackability) through composability: When the ColumnTransformer gives you the wrong array type after OneHotEncoding, just roll your own minimal FloatTransformer: https://t.co/fbL9IS9DOj"
6029,@rasbt,2022-02-13 16:04:19+00:00,https://twitter.com/rasbt/status/1492892398455824384,"Small example on working with datasets that have both numerical and categorical columns. Really love how composable scikit-learn is. But when I work on DL projects for a bit &amp; return to ""regular"" ML, I still need these sorts of personal reference snippets
https://t.co/zHV97zaRLp"
6030,@rasbt,2022-02-13 15:36:59+00:00,https://twitter.com/rasbt/status/1492885522225659905,@singhay_mle @CSProfKGD @alfcnz ** I think that's maybe why there is still this tradition that you have to have append the figures at the end of the manuscript file when submitting to most journals.
6031,@rasbt,2022-02-13 15:35:17+00:00,https://twitter.com/rasbt/status/1492885093744009226,"@singhay_mle @CSProfKGD @alfcnz *Btw a little correction, I think the photographs have only been cut and inserted in the draft version she showed me. But for the actual submission, you had to mail the developed photographs along with your manuscript and the publisher merged them."
6032,@rasbt,2022-02-13 15:30:00+00:00,https://twitter.com/rasbt/status/1492883764166467587,"@singhay_mle @CSProfKGD @alfcnz Haha, not sure. Here is an example, and I don't know if pen &amp; paper would have been less hassle https://t.co/CZG0D6QZni"
6033,@rasbt,2022-02-12 21:54:53+00:00,https://twitter.com/rasbt/status/1492618234599727105,"@CSProfKGD @alfcnz My PhD advisor showed me one of her first papers once. For making figures, they had a dark room for the computer so that they could photograph the screen. The photograph was then printed and glued onto the manuscript ü§Ø"
6034,@rasbt,2022-02-12 19:04:08+00:00,https://twitter.com/rasbt/status/1492575264303464454,"[3/3] In fact, there seems to be an interesting sweet spot where  (1) forgetting too much will prevent making progress during training, and (2) *not* forgetting enough will have *no effect* as the info can be too easily relearned in the next step(s)"
6035,@rasbt,2022-02-12 19:04:07+00:00,https://twitter.com/rasbt/status/1492575262634041344,[2/3] Then they looked at re-training strategies like knowledge evolution (KE) and the newly proposed later-layer forgetting (LLF). One observation (lower right) is that relearning the later layers doesn't really help with generalization accuracy. https://t.co/Nr8TTf9V8X
6036,@rasbt,2022-02-12 19:04:07+00:00,https://twitter.com/rasbt/status/1492575259173822472,"Forget-and-relearn. In ""Fortuitous Forgetting in Connectionist Networks"", the authors take a closer look at iterative forgetting and (re)-learning in neural nets. Pretty interesting as we can see some analogy towards of how we humans learn. (https://t.co/gkWX0o9lva) [1/3]"
6037,@rasbt,2022-02-12 17:30:05+00:00,https://twitter.com/rasbt/status/1492551597293023232,"@isalirezag @alfcnz @dxgp_ Haha, well, I don't want to sound like a sales rep, but  it's faster and smoother (because it runs locally is my guess; maybe really not fair to compare them directly). And I like that it has minor goodies like the TOC on the side so you can quickly jump between sections."
6038,@rasbt,2022-02-12 17:04:15+00:00,https://twitter.com/rasbt/status/1492545093332606977,@nycfksh @alfcnz I don't think I ever made an account. You can just use it as a local app and open files locally.
6039,@rasbt,2022-02-12 15:58:00+00:00,https://twitter.com/rasbt/status/1492528422123413506,"@alfcnz @dxgp_ In hindsight, given how much use I got out of it the $20 back then was a good investment for me (I wrote all of the initial versions of my papers there before sharing them on Overleaf for further collaboration)"
6040,@rasbt,2022-02-12 15:56:34+00:00,https://twitter.com/rasbt/status/1492528063011336199,"@alfcnz @dxgp_ Yeah it's not free but it was ~$20 which seemed ok. I got it back then when I wrote my PhD thesis, and it helped a lot because it was much smoother than alternatives. Yeah, I think I tried TexStudio. I tried a lot of things üòÖ. PS: It's an offline app for editing files locally."
6041,@rasbt,2022-02-12 14:26:54+00:00,https://twitter.com/rasbt/status/1492505497534181376,@bernhardsson I wonder if there is a correlation between preferring static typing and having spellcheckers enabled while writing. (Haha I know I should enable it but find it super distracting when I am typing)
6042,@rasbt,2022-02-12 14:15:51+00:00,https://twitter.com/rasbt/status/1492502717352357888,@alfcnz @dxgp_ TexPad is really good! Can highly recommend giving it a try!
6043,@rasbt,2022-02-12 14:14:11+00:00,https://twitter.com/rasbt/status/1492502295938048003,"@alfcnz Haha I first read this as ‚Äúgood night Word‚Äù (vs World) and was like OMG üò±. Anyways that‚Äôs awesome! Writing is a fun process, I hope you are enjoying it!"
6044,@rasbt,2022-02-12 14:11:08+00:00,https://twitter.com/rasbt/status/1492501528602722311,"@python_engineer @thedataprof @lana_caldarevic @andfanilo @BhavaniRavi_ @stefanjblos @gamesbrainiac @guilatrova @aiflavours @giyednap @AssemblyAI @willmcgugan @aaaldehyde @IAyeshaSahar @PythonWithRune Thanks! Haha, and this makes me remember the time when I signed up on Twitter, and it was all about finding the shortest Twitter handle possible due to the character limit! üòÖ"
6045,@rasbt,2022-02-11 22:38:53+00:00,https://twitter.com/rasbt/status/1492266920120397824,"@MMA_mathematics Thanks, just following the breadcrumps, it seems the metrics are computed based on the following Metrics class (https://t.co/4jbLCfzfzI), which takes a similar stateful approach (but implemented differently). Anyways, that looks all interesting, have to dig deeper some time!"
6046,@rasbt,2022-02-11 22:28:06+00:00,https://twitter.com/rasbt/status/1492264206732869632,"If s.o.'s interested, I have a full AlexNet-Cifar10 example here: https://t.co/6vqyEVXu3g"
6047,@rasbt,2022-02-11 22:22:30+00:00,https://twitter.com/rasbt/status/1492262796712681477,"@MMA_mathematics Actually not yet! Thanks for the pointer! Just skimming over the examples, I see how it trains the model in parallel and takes care of the loss, but are there any examples on how it handles metrics on multiple GPUs / nodes (metrics like accuracy, mean absolute error, etc.)?"
6048,@rasbt,2022-02-11 22:02:48+00:00,https://twitter.com/rasbt/status/1492257841394163727,@lmoroney @Twitter Same. I thought it was because I logged in from a new device recently. Might be sth on the Twitter backend then. Wouldn‚Äôt necessarily worry.
6049,@rasbt,2022-02-11 21:52:52+00:00,https://twitter.com/rasbt/status/1492255339470893057,"Prior to that, I was writing my own wrapper functions (https://t.co/gQcU1Z4x2Y, which didn't parallelize well): https://t.co/6ezsD71JzD"
6050,@rasbt,2022-02-11 21:39:49+00:00,https://twitter.com/rasbt/status/1492252057159487488,"Stateful metrics? When I started scaling my experiments from ye goode olde ""1 model/GPU"" setup to multiple devices, I learned to really appreciate this! It still lets you develop code on your CPU, but the cool thing is you can scale it up to multiple GPUs w/o changing your code"
6051,@rasbt,2022-02-11 14:52:43+00:00,https://twitter.com/rasbt/status/1492149607966691340,"@PiotrZelasko @marktenenholtz Not sure if it wouldn't work well, but I think most people use Adam/AdamW for transformers because of the resource requirements of transformers. Imagine spending all these extra resources for fine-tuning the LR and scheduler üòÜ"
6052,@rasbt,2022-02-11 14:49:03+00:00,https://twitter.com/rasbt/status/1492148684313739267,"@KarimiRabeeh Yeah, that's a good question. It's one of these things that is not particularly efficient but is relatively new, compared to training task-specific models on the embeddings, and looks magical when you first try/see it."
6053,@rasbt,2022-02-11 02:21:16+00:00,https://twitter.com/rasbt/status/1491960495733100544,"@TaliaRinger Haha yeah, and I think if I would get upset every time someone ask me to train a deep neural network on a tabular dataset with +/- 50 data points, I don't think there would be any collaboration anymore ..."
6054,@rasbt,2022-02-11 02:15:27+00:00,https://twitter.com/rasbt/status/1491959034710315019,@TaliaRinger That's true! Said domain experts can sometimes get semi-upset though when I don't recognize a specific amino acid from an 3D structure right away and mix up a aldehyde and a ketone group üòÖ
6055,@rasbt,2022-02-11 01:40:13+00:00,https://twitter.com/rasbt/status/1491950165103632409,"@DatenBergwerker @marksaroufim I mentioned that there is ROCm support on PyTorch now -- with the disclaimer that it is probably still (very?) experimental. I think the old MacBooks had AMD cards, but I never used an AMD GPU for DL so I dunno what the current state is, haha."
6056,@rasbt,2022-02-11 00:52:44+00:00,https://twitter.com/rasbt/status/1491938218144677891,"@marktenenholtz I could never bring myself to spend significant time on learning rate schedulers, but one of my PhD students was (voluntarily) obsessed with it üòÖ"
6057,@rasbt,2022-02-11 00:36:50+00:00,https://twitter.com/rasbt/status/1491934216732524562,"@marktenenholtz Yes, but it's significantly more effort as you hint at. Adam has great out of the box performance, and you don't really need to tinker with schedulers (which I find most painful) or even the learning rate in most cases."
6058,@rasbt,2022-02-10 23:58:06+00:00,https://twitter.com/rasbt/status/1491924468834488322,"@marksaroufim Actually, I was recently chatting with someone who asked if he could use the AMD GPUs (from his crypto mining server) for deep learning"
6059,@rasbt,2022-02-10 19:31:26+00:00,https://twitter.com/rasbt/status/1491857358821203973,@tdietterich @sp_monte_carlo Converting a regular deep learning classifier into a ordinal regression model by changing only 3 lines of code üòé https://t.co/SMNGlY3FJa
6060,@rasbt,2022-02-10 19:25:14+00:00,https://twitter.com/rasbt/status/1491855800171741192,"@bernhardsson Just speak at a regular pace. This usually works. Good luck, you got this üëç"
6061,@rasbt,2022-02-10 19:18:19+00:00,https://twitter.com/rasbt/status/1491854059313283076,"@dabeaz Personal preference:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; for x in np.arange(0., 7.1, 0.1):
..."
6062,@rasbt,2022-02-10 19:11:04+00:00,https://twitter.com/rasbt/status/1491852234170187782,Potentially controversial opinion: SGD -&gt; Adam (-&gt; AdamW)
6063,@rasbt,2022-02-10 19:08:34+00:00,https://twitter.com/rasbt/status/1491851605582524426,"@sp_monte_carlo In the hidden layers of a deep neural net, Sigmoid -&gt; ReLU"
6064,@rasbt,2022-02-10 17:02:00+00:00,https://twitter.com/rasbt/status/1491819753459130371,@Jeande_d Thanks üôè (it's from my new book üòä)
6065,@rasbt,2022-02-10 16:50:14+00:00,https://twitter.com/rasbt/status/1491816790254493713,"@alisher_ai Interesting, did you add the noise only 1 time before you started training?"
6066,@rasbt,2022-02-10 16:50:14+00:00,https://twitter.com/rasbt/status/1491816789998813184,"@alisher_ai Interesting, did you add the noise only 1 time before you started training?"
6067,@rasbt,2022-02-10 16:48:08+00:00,https://twitter.com/rasbt/status/1491816263047331841,"@Jeande_d That makes sense! Also, another (more technical) issue is if your upstream network is too bulky, you won't be readily able to fine-tune it for downstream tasks. However in this case you can use a feature-based approach which works almost similarly well as fine-tuning https://t.co/5igUpkDL63"
6068,@rasbt,2022-02-10 15:28:33+00:00,https://twitter.com/rasbt/status/1491796234545156106,"In some cases, higher upstream accuracy (acc of the pre-trained model) yielded worse downstream accuracy (acc of the fine-tuned model). Maybe  because as we minimize the loss too well, models become too specialized and are too inflexible to change? Like us in the real world? üòÖ"
6069,@rasbt,2022-02-10 15:26:08+00:00,https://twitter.com/rasbt/status/1491795628283686922,"NLP &amp; vision transformers are very expensive to train, so we now focus more on fine-tuning. But should we select by model size, data size, upstream accuracy? Turns out that (maybe intuitively) upstream accuracy is the best predictor for downstream acc: https://t.co/mR8Y8HNmAe https://t.co/o3JD20b750"
6070,@rasbt,2022-02-10 02:48:34+00:00,https://twitter.com/rasbt/status/1491604978120675329,"@roydanroy There was no fixed format, and that was fine. I think a free-form paragraph is absolutely fine for conveying who did what. https://t.co/Too8IQjLWX"
6071,@rasbt,2022-02-10 02:43:43+00:00,https://twitter.com/rasbt/status/1491603760577191939,"@roydanroy And advantage of your ordering is that it makes it easier to elaborate. Actually, I had some great examples in my student projects (I made the contrib section a requirement, and it was graded based on completeness)"
6072,@rasbt,2022-02-10 02:41:07+00:00,https://twitter.com/rasbt/status/1491603105376612352,"@roydanroy Yeah, that would work. Another way would be to organize it by contribution. E.g., Contrib1: author1, author2; Contrib2: author1, author 3. Off the top of my head, don't have a preference. Some journals I contributed to had this format. In practice, it can look a bit messy though: https://t.co/lg1jP56Ztf"
6073,@rasbt,2022-02-10 02:33:10+00:00,https://twitter.com/rasbt/status/1491601105318555649,"@aryehazan @roydanroy Yeah, I agree. I think it should be qualitative rather than quantitative. I am thinking of all the silly top 1%, 3%, 5%, 10% etc. questions in recommendation letter questionnaires. Extending this to author contributions sounds painful."
6074,@rasbt,2022-02-10 01:43:06+00:00,https://twitter.com/rasbt/status/1491588504991764484,"@_MarkConway_ @kaggle Hope you liked it! üòä  (Haha, it's just an arxiv article, so I don't these citations would count for tenure review üòÖ. But hey, I appreciate it as a sign that this article is useful to others ü§ó)"
6075,@rasbt,2022-02-10 01:41:07+00:00,https://twitter.com/rasbt/status/1491588004154126337,"@ChrSzegedy Programming in Rust must be deeply satisfying and fun. Recently asked someone who is primarily working in Go about it, and the person made it sound like programming in Rust is like attending a three-course summer dinner party with champagne and caviar."
6076,@rasbt,2022-02-10 01:35:11+00:00,https://twitter.com/rasbt/status/1491586511460052993,"@_MarkConway_ @kaggle Thanks so much for sharing, very insightful!"
6077,@rasbt,2022-02-10 01:33:56+00:00,https://twitter.com/rasbt/status/1491586197919084556,"@mariaKhalusova Wow that's a big move! While I am sad to hear that you are leaving the tech, I am also excited for your new path. Wishing you all the best on this exciting new journey!üéâü•≥!"
6078,@rasbt,2022-02-09 03:50:12+00:00,https://twitter.com/rasbt/status/1491258103308128262,@TaliaRinger @IgorBrigadir It‚Äôs lean and customizable. Choose your own adventure basically.
6079,@rasbt,2022-02-09 01:18:10+00:00,https://twitter.com/rasbt/status/1491219842334035968,"@DrJohnWagner I think of anticorrelation and negative correlation as synonyms. In general, there might be subtleties in how the (negatively correlated) noise is created though. I don't think I am familiar with the NCS paper üòÖ. Maybe @orvieto_antonio can chime in."
6080,@rasbt,2022-02-09 01:09:22+00:00,https://twitter.com/rasbt/status/1491217626575814661,"@_MarkConway_ @kaggle Haha, before you retire and enjoy the well-deserved time off, a few q if you don't mind üòÖ
1) Which was your favorite competition?
2) What was your favorite classification algo?
3) What was your favorite hparam tuning technique?
4) Bonus: what was your favorite evaluation method?"
6081,@rasbt,2022-02-09 01:03:50+00:00,https://twitter.com/rasbt/status/1491216232754065408,"@sunilchandrase3 Oh, good point. Anticorrelation and negative correlation are usually synonymous. So, perfect anticorrelation would be -1 in this case."
6082,@rasbt,2022-02-08 22:59:35+00:00,https://twitter.com/rasbt/status/1491184965497012225,A treasure trove of various variational autoencoders implemented in PyTorch: https://t.co/JoBocYFqpE https://t.co/7fZZ8k4js2
6083,@rasbt,2022-02-08 22:54:06+00:00,https://twitter.com/rasbt/status/1491183586128842754,"@GaelVaroquaux @marktenenholtz @scikit_learn I am a big fan! Also, last semester, several of my students used it in their class projects (and compared it to alternatives like XGBoost &amp; LightGBM), and it worked really well https://t.co/VVfuYzwsQ7"
6084,@rasbt,2022-02-08 16:01:30+00:00,https://twitter.com/rasbt/status/1491079750265491461,@TaliaRinger A weird one is that when people introduce themselves they talk more about their PhD &amp; postdoc advisors and the place they studied at rather than what they do and what they are interested in.
6085,@rasbt,2022-02-08 15:59:20+00:00,https://twitter.com/rasbt/status/1491079207287681028,"@TaliaRinger Yeah, as the first person in my fam who went to college, I was totally unprepared for these, but I don't mind about breaking these rules anymore üòÜ. However, I still have to explain to my fam why I would ""work"" (like read and review papers) in the evening or on a weekend üòÖ"
6086,@rasbt,2022-02-08 15:11:57+00:00,https://twitter.com/rasbt/status/1491067283963203589,"@orvieto_antonio @HansKersting @AurelienLucchi @BachFrancis Nice work! (PS: The y-axis labels are loss, loss, accuracy?)"
6087,@rasbt,2022-02-08 15:11:04+00:00,https://twitter.com/rasbt/status/1491067059769204747,"Very interesting. Basically, adding (anti-)correlated* (vs just uncorrelated) noise moves gradient descent to wider minima, which helps with generalization. 
*anticorrelated = consecutive perturbations are perfectly anticorrelated
https://t.co/QbkK7UDQkm https://t.co/D5lgPNmh3i"
6088,@rasbt,2022-02-08 14:06:20+00:00,https://twitter.com/rasbt/status/1491050768736358406,"@DynamicWebPaige This please, but with a Nespresso machine üòÜ"
6089,@rasbt,2022-02-08 13:58:16+00:00,https://twitter.com/rasbt/status/1491048740446441473,"@Mlbot4 @JFPuget @danofer @marktenenholtz True, that‚Äôs a limitation (hah, I usually have an exam question around that). But gradient boosting has the same problem."
6090,@rasbt,2022-02-07 19:50:45+00:00,https://twitter.com/rasbt/status/1490775056947064838,"Another concept that is cool but tricky is *fancy indexing* (esp. when you work with NumPy and PyTorch). For that one, I have a tutorial section here, but yeah, a @bascodes -style tutorial would be nice üòä https://t.co/iIjIU4bSXk"
6091,@rasbt,2022-02-07 19:50:45+00:00,https://twitter.com/rasbt/status/1490775055760039938,"This would have been an excellent resource to share coz I went over some of the Python basics rather quickly to keep the syllabus ML-focused, but based on grading homeworks, I think there could &amp; should have been more slicing practice problems"
6092,@rasbt,2022-02-07 19:50:44+00:00,https://twitter.com/rasbt/status/1490775054245847046,"""A Comprehensive Guide to Slicing in Python"" via @bascodes  -- I wish this existed when I was teaching my machine learning class last semester. Slicing is everywhere in ML, and it can be quite intriguing for newcomers https://t.co/LST8db5yqv"
6093,@rasbt,2022-02-07 18:38:09+00:00,https://twitter.com/rasbt/status/1490756785728368641,"@hackathorn @gridai_ @UWMadison If you like my previous educational resources that I shared, be assured that there will be more. It will take a bit of time to create high-quality content, but there's a plan and the execution has already begun ... stay tuned :)"
6094,@rasbt,2022-02-07 18:36:14+00:00,https://twitter.com/rasbt/status/1490756303416877056,"@hackathorn @gridai_ @UWMadison Thanks, Richard! The field &amp; communities are moving fast, indeed! One of the many things I am excited about is that I can now fully focus on working with the latest methods &amp; technologies and get to create useful content about and around it :)"
6095,@rasbt,2022-02-07 17:03:37+00:00,https://twitter.com/rasbt/status/1490732997770981380,@__mharrison__ @ torch.jit.script
6096,@rasbt,2022-02-07 15:06:01+00:00,https://twitter.com/rasbt/status/1490703401801469955,"@JFPuget @danofer @marktenenholtz I second that. I would definitely add RF to the list because compared to the other options, it doesn‚Äôt require hyperparameter tuning to work well, which makes it an excellent baseline"
6097,@rasbt,2022-02-07 13:47:24+00:00,https://twitter.com/rasbt/status/1490683618817155075,@ducha_aiki Accept with major revision
6098,@rasbt,2022-02-07 13:32:43+00:00,https://twitter.com/rasbt/status/1490679922402242561,@Jeande_d Big congrats üéâ!! All the best for the next step in your career! Excited to see what you are up to next!
6099,@rasbt,2022-02-07 02:12:26+00:00,https://twitter.com/rasbt/status/1490508724431110146,"@TaliaRinger Hah, yeah, there are also great examples from the reinforcement learning community üòÜ https://t.co/JgPPxDG7Uw"
6100,@rasbt,2022-02-06 23:02:58+00:00,https://twitter.com/rasbt/status/1490461042547245056,"""Useful Algorithms That Are Not Optimized By Jax, PyTorch, or TensorFlow"" -- nice article on quasi-static algorithms, i.e. algorithms where all computations are fixed but the inputs and results may differ. (E.g., what PyTorch's TorchScript JIT etc assume) https://t.co/56Msdmfcqr"
6101,@rasbt,2022-02-06 19:52:59+00:00,https://twitter.com/rasbt/status/1490413229989892096,"@eprosenthal If you ever choose to go that route, a workflow similar to yours is:
https://t.co/iq7eZsonIr"
6102,@rasbt,2022-02-06 19:51:33+00:00,https://twitter.com/rasbt/status/1490412872366759940,"@eprosenthal In case it's because of the non-commercial use issue, I don't think miniforge (conda with conda-forge as default) has that restriction. Afaik conda-forge packages are fully open source, and I have been happily using miniforge for like 1 to 2 years. https://t.co/OKx3RDLEst"
6103,@rasbt,2022-02-06 19:33:32+00:00,https://twitter.com/rasbt/status/1490408338303201284,"@jonyzambrano01 yeah, and conda-forge packages are more up-to-date anyways, have been using it for 1-2 years now ü§ó"
6104,@rasbt,2022-02-06 17:16:55+00:00,https://twitter.com/rasbt/status/1490373957530304516,@mariokostelac @PhilCulliton I just use the one from conda-forge.
6105,@rasbt,2022-02-06 17:13:59+00:00,https://twitter.com/rasbt/status/1490373216073916417,"@mariokostelac @PhilCulliton Those were the ones, so it's better to always install TensorFlow into a separate env (I don't really use it much anyways): https://t.co/4QQoFALXdc"
6106,@rasbt,2022-02-06 16:41:57+00:00,https://twitter.com/rasbt/status/1490365154244145152,"@chrisalbon @PhilCulliton Haha, sorry for the sales pitch, but did I mention that it doesn't get hot and the battery life is amazing? Plus the MB Pro has an HDMI port and SD card slot once again. Bye bye dongle life."
6107,@rasbt,2022-02-06 16:39:04+00:00,https://twitter.com/rasbt/status/1490364428948324353,"@ncclementi Yes! conda-forge actually supports that :). 
conda install mamba -n base -c conda-forge
Very nice!"
6108,@rasbt,2022-02-06 16:37:41+00:00,https://twitter.com/rasbt/status/1490364082494529539,"@chrisalbon @PhilCulliton When I got it back in Jan 2021, I had to compile things like PyTorch myself. Yeah, you can think of it as a hassle, but it was also oddly fun. Most stuff installs smoothly now, and I really appreciate the big speed boost (plus no fan noise!). But yeah I can understand holding off"
6109,@rasbt,2022-02-06 16:19:29+00:00,https://twitter.com/rasbt/status/1490359503157698564,Here's a Gist in case someone finds this useful: https://t.co/Rlpnml6igD
6110,@rasbt,2022-02-06 16:07:00+00:00,https://twitter.com/rasbt/status/1490356361837879300,@PhilCulliton I've been using it since January 2021 and it was generally fine with homebrew and miniforge. I'd say 99% of packages I need are already converted.
6111,@rasbt,2022-02-06 16:05:30+00:00,https://twitter.com/rasbt/status/1490355984145186819,"@SharadShriyan @dataBiryani Yeah, I was also having some issues with PyTorch and torchvision on the M1. Actually, I am sticking with miniforge for now https://t.co/sNeLRd2h5D"
6112,@rasbt,2022-02-06 16:03:54+00:00,https://twitter.com/rasbt/status/1490355578841047051,"@backpropagating Interestingly, docker is the one tool I never used so far üòÖ"
6113,@rasbt,2022-02-06 16:02:21+00:00,https://twitter.com/rasbt/status/1490355188791709696,"Ok, turns out I am sticking with miniforge a bit longer. Somehow, setting up PyTorch and torchvision didn't go smoothly on the M1. Just exported my minimal conda env from my other machine and it worked like a charm. (PyTorch is installed via conda-forge and torchvision via pip)"
6114,@rasbt,2022-02-06 15:56:45+00:00,https://twitter.com/rasbt/status/1490353783116869640,@jonyzambrano01 Good point regarding poetry and virtualenv. I think it was a personal preference by the author regarding command syntax. But I think you are right and virtualenv would not be needed.
6115,@rasbt,2022-02-06 03:10:51+00:00,https://twitter.com/rasbt/status/1490161034258268165,"@TaliaRinger It's a dilemma. In the beginning, I said Yes too many times which was also not good, because I could barely keep up with everyone. But then when saying No you feel like you are putting a damper on someone's career because you also know there are not so many other options for them"
6116,@rasbt,2022-02-06 03:08:00+00:00,https://twitter.com/rasbt/status/1490160318655434752,"@TaliaRinger Yes :(. Also when you have highly motivated students in your class who are super excited about the topic you are teaching &amp; want to do research with you. I can now say No to admin duties like editor roles, and even collaborations, but saying No to students is really hard &amp; sad :("
6117,@rasbt,2022-02-06 01:38:36+00:00,https://twitter.com/rasbt/status/1490137820350013443,@elmanmansimov Maybe slightly less convenient because there are more things involved üòÖ
6118,@rasbt,2022-02-06 01:37:19+00:00,https://twitter.com/rasbt/status/1490137495731941381,"@egecanTe But renv doesn‚Äôt manage multiple R interpreters/versions, right? So it‚Äôs more like venv or virtualenv rather then pyenv + virtualenv or conda?"
6119,@rasbt,2022-02-05 19:53:59+00:00,https://twitter.com/rasbt/status/1490051094579400710,"@cgarciae88 Does poetry also track conda packages &amp; dependencies if you use poetry in a conda env? Like how conda tracks pip packages via ""conda env export &gt; myproj.yml""?(Curious since I haven't used poetry yet and am debating whether I should/need to haha...)"
6120,@rasbt,2022-02-05 16:10:41+00:00,https://twitter.com/rasbt/status/1489994900670226441,"@CSProfKGD @alfcnz Haha yes, this. I think that's where deadlines come to the rescue."
6121,@rasbt,2022-02-05 16:03:03+00:00,https://twitter.com/rasbt/status/1489992978961776648,@shengy90 @eprosenthal Thanks! Btw the answer is probably this: https://t.co/3Pztgo6Rte
6122,@rasbt,2022-02-05 15:59:43+00:00,https://twitter.com/rasbt/status/1489992138800652289,"For ref, my current procedure to achieve the same:
# create &amp; activate
conda create  --prefix ~/code/myproj python=3.8
conda activate ~/code/myproj
# export env
conda env export &gt; myproj.yml
# create new env from yaml
conda env create --file myproj.yml --prefix ~/code/myproj2"
6123,@rasbt,2022-02-05 15:49:35+00:00,https://twitter.com/rasbt/status/1489989590563893254,"@shengy90 Nice, that would probably help making it simpler. Wondering if @eprosenthal just chose virtualenv vs venv because of personal preference or whether there was a downside using venv in this workflow?"
6124,@rasbt,2022-02-05 15:47:29+00:00,https://twitter.com/rasbt/status/1489989060659716097,"@ladidinesh @eprosenthal I see, then it's probably a virtualenv vs venv thing üòÖ"
6125,@rasbt,2022-02-05 15:46:38+00:00,https://twitter.com/rasbt/status/1489988848872570881,@quassy7 I have been using conda for too long so I can't comment over personal preferences re virtualenv vs venv. It's probably a VIM vs. Emacs thing üòÜ
6126,@rasbt,2022-02-05 15:42:40+00:00,https://twitter.com/rasbt/status/1489987850493964293,"@kingmanzhang Good question. I heard mixed things about pipenv. It seems like a love-hate thing, and personally, I never tried it. Might be worthwhile checking."
6127,@rasbt,2022-02-05 15:39:28+00:00,https://twitter.com/rasbt/status/1489987041760792582,"@AliAhmedSaleh The alternative, conda, is slow too üòÖ (ok, I know there is mamba now)"
6128,@rasbt,2022-02-05 15:38:42+00:00,https://twitter.com/rasbt/status/1489986852161560584,"@paul_rietschka Yeah, I am a long-time conda user (10 years now?). I know, don't fix what ain't broke, but I am happy to try &amp; learn something new once in a while."
6129,@rasbt,2022-02-05 15:36:41+00:00,https://twitter.com/rasbt/status/1489986342239064073,@ladidinesh I think here virtualenv comes in so that you don't install/add everything to your global installation when you use poetry. Please correct me if I'm wrong @eprosenthal
6130,@rasbt,2022-02-05 02:53:02+00:00,https://twitter.com/rasbt/status/1489794164447453185,@cleavey1985 Actually never used either docker nor poetry. I think docker might be overkill for my tasks but poetry sounds appealing. Btw. have been using an M1 since Jan 2021 and it's been pretty good with homebrew and miniforge
6131,@rasbt,2022-02-05 02:40:49+00:00,https://twitter.com/rasbt/status/1489791090144288769,"Setting up a new computer, I may give this one a try! Basically, for each project you set up 
- a Python version (via pyenv)
- packages (via virtualenv)
- and track dependencies via poetry
Any experiences with the ""pyenv-virtualenv-poetry"" (and would you recommend it over conda)?"
6132,@rasbt,2022-02-05 01:20:58+00:00,https://twitter.com/rasbt/status/1489770993103032321,"@ykilcher @RichardSocher New product idea: Meta Search. Runs your search query on all major platforms (You, Google, Bing, DuckDuckGo, etc.) and picks out &amp; ranks the most relevant of the relevant ones üòÖüòÜ"
6133,@rasbt,2022-02-05 01:14:26+00:00,https://twitter.com/rasbt/status/1489769351654014977,"@alfcnz It's called ""perfecting"" it üëå‚ô•Ô∏è"
6134,@rasbt,2022-02-05 01:12:03+00:00,https://twitter.com/rasbt/status/1489768751713169410,@LongFormMath CC @alfcnz üòÜ
6135,@rasbt,2022-02-05 01:02:50+00:00,https://twitter.com/rasbt/status/1489766430564405253,"@dai_nlp os.environ[""PL_GLOBAL_SEED""] = str(seed)
torch.cuda.manual_seed_all(seed)
torch.backends.cudnn.benchmark = False
torch.backends.cudnn.deterministic = True
torch.use_deterministic_algorithms(True)
torch.backends.cuda.matmul.allow_tf32 = False
üòÖüôÉ"
6136,@rasbt,2022-02-04 23:16:24+00:00,https://twitter.com/rasbt/status/1489739647181897728,@alfcnz @_jvs Chapter 2 already. Let me know if you need someone for feedback!
6137,@rasbt,2022-02-04 23:07:48+00:00,https://twitter.com/rasbt/status/1489737484162506755,"@tom_gxt @marktenenholtz Unfortunately it was way too long for inclusion in the book (with the new contents, we already maxed out the total page number that can be printed). There is a shorter hands-on chapter (similar to previous editions) with reference to the article though."
6138,@rasbt,2022-02-04 21:36:02+00:00,https://twitter.com/rasbt/status/1489714389112524800,@3scorciav Nice! PS: I think you should have used GPT-3 and not Copilot for the reviews üòÜ
6139,@rasbt,2022-02-04 21:21:14+00:00,https://twitter.com/rasbt/status/1489710665656844289,@3scorciav Please tell us more :)
6140,@rasbt,2022-02-04 21:11:11+00:00,https://twitter.com/rasbt/status/1489708134314782725,"@yaroslavvb 100-page documents. Wow. I think it makes sense to formalize things, but given our modern attention spans, I wonder if we can replace it by something more actionable, like a portfolio of different real-world use cases."
6141,@rasbt,2022-02-04 21:06:48+00:00,https://twitter.com/rasbt/status/1489707032768831496,"@yaroslavvb Oh yeah, and there's also feature creep. Over the course of a research project, I add things here &amp; there to facilitate certain tests, run on certain hardware, to generate some special plots etc. All makes at the time, but try coming back to it after a month ... ü§Ø"
6142,@rasbt,2022-02-04 21:00:56+00:00,https://twitter.com/rasbt/status/1489705555384016905,"I wrote a lot of hacky scripts in my lifetime for logging, hyperparameter sweeps, and submitting my jobs to our SLURM cluster. I may be biased, but using @gridai_ now  is very refreshing. Just select your Gh repo, the hardware you want to use &amp; the hparam ranges, and off you go https://t.co/u4TWrAfl7T"
6143,@rasbt,2022-02-04 19:45:24+00:00,https://twitter.com/rasbt/status/1489686546953478144,"I get the appeal behind it though. Just because I like e.g., chatting with people myself, it doesn't mean there is no need for better chatbots etc. ;)"
6144,@rasbt,2022-02-04 19:27:58+00:00,https://twitter.com/rasbt/status/1489682161074679815,"@suraj520__ Yes yes, I meant GitHub CoPilot"
6145,@rasbt,2022-02-04 19:13:00+00:00,https://twitter.com/rasbt/status/1489678392119103488,"AlphaCode is in a different ballpark as CoPilot and quite intriguing. For me, personally, I don't necessarily want someone taking on my coding tasks (I enjoy them too much!), but if there was something that could teach me to write better code, that'd get me interested üòä"
6146,@rasbt,2022-02-04 17:45:05+00:00,https://twitter.com/rasbt/status/1489656267316551688,"@MuzafferKal_ @ylecun Ooops, yes, thanks ü§¶‚Äç‚ôÇÔ∏è. That clarifies it üòÖ"
6147,@rasbt,2022-02-04 17:34:31+00:00,https://twitter.com/rasbt/status/1489653609293918209,"@ylecun Haven't read the paper, yet, but at first glance, this 3 step summary looks like Barlow Twins?"
6148,@rasbt,2022-02-04 16:44:30+00:00,https://twitter.com/rasbt/status/1489641020497268741,"@marktenenholtz Oh oh. But to be fair, a semester can be so short! I wasn't careful and Model evaluation ended up taking ~40% of my ML class last semester, haha"
6149,@rasbt,2022-02-04 14:55:43+00:00,https://twitter.com/rasbt/status/1489613645504032769,"@andrewrwyatt @marktenenholtz @joelgrus If your train/validation loss look like a dowsing rod, then your network is probably learning and you are all good üòÖ"
6150,@rasbt,2022-02-04 14:50:33+00:00,https://twitter.com/rasbt/status/1489612345227845634,@marktenenholtz PS: here is a browser-friendly ar5iv version üòä https://t.co/e6A8hPj6cu
6151,@rasbt,2022-02-04 13:38:58+00:00,https://twitter.com/rasbt/status/1489594329052155916,@marktenenholtz Glad to hear it was useful! (But not glad to hear that it is still a badly taught skill. Hope that's changing in the future!)
6152,@rasbt,2022-02-03 22:54:50+00:00,https://twitter.com/rasbt/status/1489371831698173952,"@TomasSoucek @TaliaRinger Good point! In case you are using PyTorch, you can set
torch.backends.cuda.matmul.allow_tf32 = False
torch.backends.cudnn.allow_tf32 = False"
6153,@rasbt,2022-02-03 22:37:18+00:00,https://twitter.com/rasbt/status/1489367419600744450,"@roeeaharoni @kchonyc @yoavgo @nlpnoah And I have this neat idea of compressing these count vectors into a lower-dimensional real-space using PCA, let's call it data2vec."
6154,@rasbt,2022-02-03 22:15:57+00:00,https://twitter.com/rasbt/status/1489362046781206534,"@yoavgo @nlpnoah @kchonyc ok, let's coin the term ""AIcounting"" for an AI that memorizes üòÖ. (Reminds me of a class in grad school where a prof asked everyone to name an example of AI, and someone said predicting a city's population from zip codes. The prof was like ""no, that's not AI, that's accounting"")"
6155,@rasbt,2022-02-03 19:28:14+00:00,https://twitter.com/rasbt/status/1489319838979919874,@ipnosimmia @karlrohe Yes. This. Totally agree! https://t.co/tzB4P0K8uY
6156,@rasbt,2022-02-03 19:26:59+00:00,https://twitter.com/rasbt/status/1489319524818206724,"@karlrohe It's maybe not too far off though: In self-supervised learning, we try to find good starting weights -- and e.g. in the context of most DL models, we can think of the model backbone as a feature extractor. In PCA, we try to extract information from the original features as well."
6157,@rasbt,2022-02-03 16:44:38+00:00,https://twitter.com/rasbt/status/1489278667586945035,"@karlrohe Hm, that's a really interesting perspective! I would say it's maybe more like self-supervised learning then."
6158,@rasbt,2022-02-03 16:39:42+00:00,https://twitter.com/rasbt/status/1489277424206499840,@TaliaRinger In case you are using a particular deep learning framework like PyTorch you can try the following: https://t.co/ul1rQk4YdU. Or in PyTorch Lightning there is a Trainer(deterministic=True) flag. https://t.co/uZZPeZH7MB
6159,@rasbt,2022-02-03 16:34:57+00:00,https://twitter.com/rasbt/status/1489276230423789570,"@TaliaRinger Are you also using convolutions per chance? Convolutions and some other ops are not deterministic by default. There is a special flag to set for that. Otherwise, the algorithm will be chosen at runtime, and while the numeric differences are tiny, they can accumulate to a big diff"
6160,@rasbt,2022-02-03 16:32:20+00:00,https://twitter.com/rasbt/status/1489275572031262721,@TaliaRinger Are you using GPUs?
6161,@rasbt,2022-02-03 03:07:32+00:00,https://twitter.com/rasbt/status/1489073037953716231,@leonpalafox @CSProfKGD Now that you say that I am pretty sure I was a member :). But that feels like ages ago now. First I thought y‚Äôall were talking about a TV or storage  subscription service
6162,@rasbt,2022-02-03 03:00:15+00:00,https://twitter.com/rasbt/status/1489071204732481544,"@profheathergray Students worry so much about their grad schools appl (finals‚Äô week pales in comparison). Literally makes my day when I hear from students that they got in at one of their preferred places. Writing recommendations letters can be tedious, but it is so nice knowing that it helps!"
6163,@rasbt,2022-02-03 02:45:52+00:00,https://twitter.com/rasbt/status/1489067583076765702,@CSProfKGD Wow that‚Äôs hilarious. Seriously forgot what Google+ was.
6164,@rasbt,2022-02-03 02:39:48+00:00,https://twitter.com/rasbt/status/1489066059974025216,@mrdbourke 2025 if you are an optimist üôÉ
6165,@rasbt,2022-02-02 21:46:04+00:00,https://twitter.com/rasbt/status/1488992138088042500,"@agoose77 Nice, so basically a lean version of nbdev?"
6166,@rasbt,2022-02-02 21:37:49+00:00,https://twitter.com/rasbt/status/1488990063778226182,@agoose77 GitHub link or it didn't happen üôÉüòä
6167,@rasbt,2022-02-02 20:33:24+00:00,https://twitter.com/rasbt/status/1488973849534287883,"@story645 Yeah, that's actually a nice way to put it (no pun intended üòÜ)"
6168,@rasbt,2022-02-02 20:23:18+00:00,https://twitter.com/rasbt/status/1488971310864678918,"*Today I would probably mostly use @PyTorchLightnin instead of rolling my own utilities, but I think it gets the point across :)"
6169,@rasbt,2022-02-02 20:21:43+00:00,https://twitter.com/rasbt/status/1488970910656872454,"E.g., here is an example from my DL learning class (https://t.co/awGZjC3Mcp) https://t.co/sNjzoTBdT5"
6170,@rasbt,2022-02-02 20:14:49+00:00,https://twitter.com/rasbt/status/1488969176022667264,This! A common question people ask is whether they should work with .py vs .ipynb files. It doesn't have to be exclusive. E.g. want a nb with plots but have a loss function that you keep reusing? Put it into a .py file (doesn't have to be a pgk) and import into your notebooks.
6171,@rasbt,2022-02-02 18:42:13+00:00,https://twitter.com/rasbt/status/1488945869412085762,"@jmschreiber91 Good question, they had fitness scores, but I am not sure if they obtained them directly from Rosetta or had a subsequent tool. Personally, I never used Rosetta."
6172,@rasbt,2022-02-02 18:37:04+00:00,https://twitter.com/rasbt/status/1488944574437408773,"@jmschreiber91 Haha that's probably not helpful but I was working on it using NLP transformers &amp; dropped the project recently. Anyways, I collaborated with biochemists on this, and talking to them, they said they used Rosetta for predicting fitness &amp; function from amino acid sequence data."
6173,@rasbt,2022-02-02 16:41:42+00:00,https://twitter.com/rasbt/status/1488915541310025730,@taocds @tunguz Currently looking into GitHub  Actions paired with Azure Pipelines. I need mainly lots of GPUs for testing.
6174,@rasbt,2022-02-02 14:28:44+00:00,https://twitter.com/rasbt/status/1488882080578744327,@roziscoding @aniqatc @kennygunderman I hear you! üòä
6175,@rasbt,2022-02-02 13:08:42+00:00,https://twitter.com/rasbt/status/1488861936515178497,"Wow that‚Äôs amazing timing! Just a few days ago, we discussed how diffusion models provide awesome results but are slow to sample from (e.g., compared to GANs). Haha, thanks for fixing it in such a timely manner üëá"
6176,@rasbt,2022-02-02 13:01:29+00:00,https://twitter.com/rasbt/status/1488860120813613062,@tunguz Diving deeper into CI setups for efficient tech writing (and code lintering). And maybe some statistics stuff if there‚Äôs time :P
6177,@rasbt,2022-02-02 12:58:45+00:00,https://twitter.com/rasbt/status/1488859434809974788,@tunguz @PradHolla üòé
6178,@rasbt,2022-02-02 12:56:35+00:00,https://twitter.com/rasbt/status/1488858888845803521,@JustinStrharsky @radekosmulski @BecomingDataSci @math_rachel @jeremyphoward @elenasamuylova @sarahcat21 Thanks so much for the kind words and compliment üôè üòä
6179,@rasbt,2022-02-02 02:59:42+00:00,https://twitter.com/rasbt/status/1488708678609997825,"@zacharylipton I feel like this could be an interesting applied study. Since you have access to the training labels, there are all sorts of interesting ways you can embed subtle patterns and check how reliable Grad-CAM is as a diagnostic."
6180,@rasbt,2022-02-02 02:54:08+00:00,https://twitter.com/rasbt/status/1488707277695725568,"@zacharylipton If it doesn't highlight the corner it doesn't mean everything is okay. If it highlights the corner, maybe that's also not an issue coz it can be meaningless like you said. It's just a debugging tool that isn't great. Question is: does it cause more harm than good during dev"
6181,@rasbt,2022-02-02 02:50:12+00:00,https://twitter.com/rasbt/status/1488706287240155140,"@zacharylipton I guess that's true. I haven't used Grad-CAM in any of my projects but anecdotally I remember there was a case where it highlighted some corner in a medical image setting, which prompted the developers to look further into it, and it turned out some images had watermarks there."
6182,@rasbt,2022-02-02 02:42:10+00:00,https://twitter.com/rasbt/status/1488704264616783878,@zacharylipton Grad-CAM etc I see as debugging tools that are somewhat in the same tool bin as gradient checking
6183,@rasbt,2022-02-02 02:39:58+00:00,https://twitter.com/rasbt/status/1488703711409057794,"@zacharylipton Re Shapley values etc., I don't think we should be considering them as alternatives to performance metrics. They are can be useful as complementary filters to see if there's something fishy. Everything looking okay does not imply that everything *is* okay."
6184,@rasbt,2022-02-02 02:38:04+00:00,https://twitter.com/rasbt/status/1488703232964808710,"@zacharylipton Sure, the model doesn't perform well, but why is that? The features are not useful, you forgot to normalize the data, your model overfits a lot, ...?"
6185,@rasbt,2022-02-02 02:20:36+00:00,https://twitter.com/rasbt/status/1488698840274321411,@zacharylipton I am with you on that it's definitely not for the medical staff using these models. Meant that they can be useful for detecting defects during the development stage. Like how a low test accuracy can be useful but if it is good it's also not the answer to all your problems.
6186,@rasbt,2022-02-02 02:02:31+00:00,https://twitter.com/rasbt/status/1488694289823633413,"@zacharylipton Agree with you, but (similar to p-values) they can be useful as internal debugging tools. Like ""wait, why is the SHAP value for this feature so high ... arg, did we really include the ID column!?"" or ""Why is this CNN looking in the upper left corner, is that a camera watermark?"""
6187,@rasbt,2022-02-01 22:46:10+00:00,https://twitter.com/rasbt/status/1488644876849848327,@albertzeyer Depends on the activation. Xavier used to be recommended for tanh activations. Kaiming He init is basically an adjustment to make it work well for ReLU. I am actually now curious what people use for GeLU?
6188,@rasbt,2022-02-01 22:40:47+00:00,https://twitter.com/rasbt/status/1488643520130953218,@saidpertuz @alfcnz @juliankoh @joelgrus @piazza I think Discord might be even better. Piazza because it was provided inside the Canvas course where students have access to the course material and grades.
6189,@rasbt,2022-02-01 22:23:50+00:00,https://twitter.com/rasbt/status/1488639253135384577,"@alfcnz @juliankoh @joelgrus @piazza I love Piazza. Often students can benefit from the Q&amp;A as they may have similar questions or just learn something new about some edge cases in the material. Also, if students prefer, they can ask anonymously. Universities do have requirements for in-person office hours though"
6190,@rasbt,2022-02-01 20:53:58+00:00,https://twitter.com/rasbt/status/1488616636932308993,"@sama Yes, professional &amp; personal projects ftw!"
6191,@rasbt,2022-02-01 20:30:21+00:00,https://twitter.com/rasbt/status/1488610694522183682,@david_picard @CSProfKGD CC @karlrohe
6192,@rasbt,2022-02-01 18:42:25+00:00,https://twitter.com/rasbt/status/1488583532201000962,"@eprosenthal ""It turns out, being forced to make your code portable is the same thing as requiring reproducibility in building and running your code. It‚Äôs nice when constraints incentivize best practices."" Love it!"
6193,@rasbt,2022-02-01 17:16:57+00:00,https://twitter.com/rasbt/status/1488562022937735170,@CSProfKGD I probably didn't even know computer vision was a thing back then. I took a class in Statistical Pattern Recognition and focused on Bayesian methods for text &amp; tabular data back then. Image data only made sense to me if you put it through a PCA.
6194,@rasbt,2022-02-01 16:54:14+00:00,https://twitter.com/rasbt/status/1488556306470420488,@dginev ar5iv -&gt; hi-5iv üôå
6195,@rasbt,2022-02-01 16:50:53+00:00,https://twitter.com/rasbt/status/1488555463411179520,"@dginev Oh I see üòÖ. Haha, thanks for the transparency"
6196,@rasbt,2022-02-01 16:42:25+00:00,https://twitter.com/rasbt/status/1488553335007465475,"This is amazing! Can't believe how fast the conversion from LaTeX source is, and the output is much more pleasant to read than traditional 2-column PDFs. Also, it looks more more e-reader (and print) friendly to me: https://t.co/zSLPJs2PZr"
6197,@rasbt,2022-02-01 13:44:45+00:00,https://twitter.com/rasbt/status/1488508623487655938,"Fun fact: there are not one, but (at least) two ways we convert a fully connected layer into a convolutional layer:

1) making the kernel size similar to the input (left image)
2) stacking 1x1 pixel channels (right image)

(My verbose explanation here: https://t.co/FexZD11uSA) https://t.co/L1Wa5LjsMp"
6198,@rasbt,2022-02-01 13:29:15+00:00,https://twitter.com/rasbt/status/1488504723489579008,"@Jeande_d @RayGButler Yeah, it's super cool. And there are actually two different ways of doing that. I made a short video about it here üòä: https://t.co/FexZD11uSA"
6199,@rasbt,2022-02-01 04:19:48+00:00,https://twitter.com/rasbt/status/1488366449429299201,@MaxUnfried @aureliengeron Reparameterization. Sorry to disappoint üò¨
6200,@rasbt,2022-02-01 03:53:05+00:00,https://twitter.com/rasbt/status/1488359725968375816,"@aureliengeron Came here to recommend HaloNet but then I saw the requirement is CNN-only üòÖ. How about ""RepVGG: Making VGG-style ConvNets Great Again""
https://t.co/Oy7xYaNKRO https://t.co/IhIvfWR7V0"
6201,@rasbt,2022-02-01 02:51:16+00:00,https://twitter.com/rasbt/status/1488344168065908737,"@TaliaRinger Highly recommend joining a Slack workspace around an open source project. Open source communities are generally genuinely friendly and a good place to share excitement with. Chances are there is a off-topic channel as well, and it usually feels less formal than mailing lists"
6202,@rasbt,2022-02-01 02:45:31+00:00,https://twitter.com/rasbt/status/1488342719676174343,"@amy_tabb ""The result is a system in which one-fifth of researchers contribute up to 94% of reviews"" üò¨"
6203,@rasbt,2022-02-01 02:41:09+00:00,https://twitter.com/rasbt/status/1488341624509849600,"@Nature That part I agree with: ‚Äúresearchers should try to set realistic goals of how many manuscripts they can review,‚Äù says Julia Vilstrup Mouatt, head of the Web of Science Academy [...]. As a rule of thumb, some researchers try to review three papers for every one they publish."
6204,@rasbt,2022-02-01 00:08:49+00:00,https://twitter.com/rasbt/status/1488303285316562946,"@zacharylipton Some prior info please: Linux, macOS, Windows?"
6205,@rasbt,2022-01-31 23:28:07+00:00,https://twitter.com/rasbt/status/1488293045233725446,@bhutanisanyam1 @weights_biases @lavanyaai Wow that's so amazing &amp; impressive üéâ! Keep up the good work (after some well-deserved rest of course) üôå
6206,@rasbt,2022-01-31 20:19:01+00:00,https://twitter.com/rasbt/status/1488245455293239297,"@Hinduxpress1 Yeah, as someone who engineered these things (model checkpointing, parallelization, logging) by hand, I really appreciate the flexibility &amp; structure. Before that, each project had a slightly different ""helper-file"" code base which became tedious and messy, and hard to explain."
6207,@rasbt,2022-01-31 20:16:40+00:00,https://twitter.com/rasbt/status/1488244865850818566,@_arijit8 Oh so you are wondering about general purpose methods as alternatives to Shapley values and permutation importance? The only other one that spontaneously comes to mind is LIME
6208,@rasbt,2022-01-31 20:05:10+00:00,https://twitter.com/rasbt/status/1488241970266918914,"@PyTorchLightnin Wow, that's a big milestone! Huge congrats!"
6209,@rasbt,2022-01-31 18:50:31+00:00,https://twitter.com/rasbt/status/1488223183035633668,"@TroyDLoeffler @TaliaRinger Yes, this! I am already happy about these small hills but I wish there were actual mountains! https://t.co/CfmaULsnbH"
6210,@rasbt,2022-01-31 18:47:32+00:00,https://twitter.com/rasbt/status/1488222432414601217,@trathpai Wow that looks stunning!
6211,@rasbt,2022-01-31 18:46:42+00:00,https://twitter.com/rasbt/status/1488222222686867464,@RobertLaurella @gridai_ Exciting news! Welcome to the team! üéâ
6212,@rasbt,2022-01-31 15:25:35+00:00,https://twitter.com/rasbt/status/1488171609579995143,"@DavidPraiseKalu @kayteeflick Having been on several PhD committees myself since then, keeping it succinct and cutting the boilerplate is definitely well appreciated, since committee members are all very busy, and reading a 100+ pages thesis is a lot üòÖ"
6213,@rasbt,2022-01-31 13:37:40+00:00,https://twitter.com/rasbt/status/1488144452644442114,"Just added a CNN for image data example (https://t.co/XQxLNhpbtk) 
as well as an RNN for text (https://t.co/dj6097qPez), which should cover all the bases now.
(Ok ok, maybe I should add an xformer example next, or add a graph neural net some time.)"
6214,@rasbt,2022-01-31 03:41:09+00:00,https://twitter.com/rasbt/status/1487994332258914306,"@yoyololicon @minimario1729 Oh wow that‚Äôs good to know. My frustration with GANs is that they are super intuitive and easy to implement, but then when it comes training, it‚Äôs so tedious to get them to work well."
6215,@rasbt,2022-01-31 03:39:10+00:00,https://twitter.com/rasbt/status/1487993836089622528,"@unixpickle Awesome, thanks for the insights!"
6216,@rasbt,2022-01-31 03:38:27+00:00,https://twitter.com/rasbt/status/1487993655185096704,"@ArashVahdat Hah yeah, it‚Äôs a lot of math to dig through for people like me who try to avoid math üòÖ. Thanks for those papers, that‚Äôs super useful!"
6217,@rasbt,2022-01-31 03:35:19+00:00,https://twitter.com/rasbt/status/1487992866236469249,"@bernhardsson Oh yeah, fond memories, I remember making my first websites (mid 2000s) in Namo WebEditor"
6218,@rasbt,2022-01-31 02:53:46+00:00,https://twitter.com/rasbt/status/1487982410096680961,"@kayteeflick [3/3] The most useful writing tip I got from my advisor was to cut the boilerplate. She said that everyone's read the general intro to the topic at least a 1000 times &amp; I should just keep it short and write about what's new. And as far as I know, the committee really liked that"
6219,@rasbt,2022-01-31 02:52:25+00:00,https://twitter.com/rasbt/status/1487982068894244866,"@kayteeflick [2/3] I worried a lot about the thesis &amp; defense back then. But in hindsight, I think the prelim was the real test. If the committee signs off on the prelim, they really think your project plans are sufficient for the PhD and it's more about wrapping it up than convincing them."
6220,@rasbt,2022-01-31 02:51:06+00:00,https://twitter.com/rasbt/status/1487981737271517184,"@kayteeflick I was procrastinating on my writing until my PhD advisor went on a 3-month safari tour 3-months before my thesis was due -- of course w/o internet. I remember that I was totally freaked out about this, but I think she believed I got this [1/3]"
6221,@rasbt,2022-01-31 00:52:31+00:00,https://twitter.com/rasbt/status/1487951895239049217,"@tallinzen No, except for virtual machines (now that you say that, so weird) and machine learning of course ;)"
6222,@rasbt,2022-01-31 00:51:15+00:00,https://twitter.com/rasbt/status/1487951575276568580,"@knitesh Interesting! I am not too deep into that topic, but I think they are inspired by physics/thermodynamics: https://t.co/w3tHGGorIH"
6223,@rasbt,2022-01-31 00:17:46+00:00,https://twitter.com/rasbt/status/1487943148936605697,"@knitesh In essence, the so-called diffusion steps add Gaussian noise to the data in an iterative fashion. That is, you have x -&gt; x' -&gt; ... -&gt; z (where z is very noisy). Then, you have a reverse mode learning to undo it z -&gt; ... -&gt; x to reconstruct the original data back from the noise."
6224,@rasbt,2022-01-30 23:41:00+00:00,https://twitter.com/rasbt/status/1487933898432688132,@gle_bellier Wow thanks!
6225,@rasbt,2022-01-30 22:20:51+00:00,https://twitter.com/rasbt/status/1487913729073324034,"@minimario1729 @yoyololicon ""After months of trial and error"" üò¨; ""the result is pretty good"" üôå. Hah, seriously can't tell whether this is good or bad. (To me) Training a VQ-GAN is also tons of work. Thanks for the link to the repo though. Super helpful!"
6226,@rasbt,2022-01-30 21:57:02+00:00,https://twitter.com/rasbt/status/1487907732372000775,@TaliaRinger The cold weather is certainly a trade-off. It comes with some goodies though :) https://t.co/eCYzbDGy5x
6227,@rasbt,2022-01-30 21:54:33+00:00,https://twitter.com/rasbt/status/1487907110105006091,"Has anyone tried diffusion-based models, yet? Heard that they produce better results than GAN (e.g,. https://t.co/aSNmE8tyUX is quite convincing) and heard they are easier to train. True? People also say they are pretty slow to sample from. Anyone any experience with these?"
6228,@rasbt,2022-01-30 21:45:40+00:00,https://twitter.com/rasbt/status/1487904873609928706,"@backpropagating Oh, I forgot another neat feature if you are doing research:
 Trainer(..., deterministic=True)"
6229,@rasbt,2022-01-30 20:15:36+00:00,https://twitter.com/rasbt/status/1487882207725297668,"@zacharylipton @yoavgo I actually really like the BibTex [ABC99] default style for readability. Not as verbose as [Author et al. 1999], somewhat more anonymous, but also somewhat more memorable"
6230,@rasbt,2022-01-30 20:13:35+00:00,https://twitter.com/rasbt/status/1487881699467968513,"@zacharylipton @yoavgo That's a good point! In practice, the only downside when I read papers with [number] citations is that I have a really hard time to keep track of things (is [87] the same paper that was referenced earlier in the related work section, or was that [78] or [86]?)"
6231,@rasbt,2022-01-30 16:03:26+00:00,https://twitter.com/rasbt/status/1487818745984733190,"@_dylancastillo @tunguz Not saying that colleges never make sense, but specifically for tech you are nowadays really better off with alternative models these days (cheaper, faster, more up to date) -- at least based on what I heard from people who are hiring / were hired in the last couple of months."
6232,@rasbt,2022-01-30 15:59:39+00:00,https://twitter.com/rasbt/status/1487817797392646152,"@_dylancastillo @tunguz This! I know someone who got a senior role in tech after completing a 9 mo Bootcamp w/o prior background or experience in tech. At the same time, her colleague with a CS degree (not sure if BSc or MSc) only got a junior role (same job, same company, same team)"
6233,@rasbt,2022-01-30 15:07:50+00:00,https://twitter.com/rasbt/status/1487804757783703552,"@YiTayML @stefan_it_ @seb_ruder Nice, thanks! I think it would be be useful to add the link to the paper because others may be wondering about that as well."
6234,@rasbt,2022-01-30 14:49:53+00:00,https://twitter.com/rasbt/status/1487800238983323661,@stefan_it_ @YiTayML @seb_ruder Doesn't look like it üò¢. And that's a bad look. https://t.co/KMfVTHc2cY
6235,@rasbt,2022-01-30 13:54:39+00:00,https://twitter.com/rasbt/status/1487786339508625410,"In https://t.co/bcRiIqGqzN, researchers found that pre-training CNNs the same way as transformers leads to competitive performance on NLP tasks!
Nice insight &amp; paper I totally missed last year (just stumbled upon it thanks to @seb_ruder's excellent review https://t.co/zAtk7tHLFD) https://t.co/wPhJHTbFvU"
6236,@rasbt,2022-01-29 18:30:42+00:00,https://twitter.com/rasbt/status/1487493422944600064,"@nycfksh @huggingface Good question! I am not deep enough into NLP to make a good suggestion here, but it‚Äôd say if you prefer more customizable code from  building blocks (eg for research) go with xformers &amp; for more prepackaged things and contexts where you care more about fine-tuning HF transformers"
6237,@rasbt,2022-01-29 18:26:34+00:00,https://twitter.com/rasbt/status/1487492381041733640,"@amy_tabb @ducha_aiki @CSProfKGD For the majority of papers it‚Äôs not important to me whether they are reviewed or not ‚Äî usefulness matters. However for topics outside my area of expertise (eg medical contexts), knowing whether something passed peer review can be useful"
6238,@rasbt,2022-01-29 18:24:58+00:00,https://twitter.com/rasbt/status/1487491976903733249,"@amy_tabb @ducha_aiki @CSProfKGD Right. I do know that some journals require it but it is not necessary. We can assume that papers on arxiv are preprints, and if they have an DOI added it‚Äôs obvious that it‚Äôs been reviewed."
6239,@rasbt,2022-01-29 16:58:34+00:00,https://twitter.com/rasbt/status/1487470233849901061,"@ducha_aiki @CSProfKGD In other words, I think we should share manuscript drafts/preprints but the disclaimer (not peer-reviewed) should be obvious. To be honest, I think it we should make it a habit to include a ""Currently under peer-review"" in our Arxiv articles until they are accepted."
6240,@rasbt,2022-01-29 16:56:42+00:00,https://twitter.com/rasbt/status/1487469766470213635,"@ducha_aiki @CSProfKGD Agreed. I think that sharing can only benefit the community (get access to info earlier, and invite more people to weigh in) but I also think it's the researchers' duty to be honest about their work (""in your latest manuscript *that is currently being reviewed*, we saw that ..."")"
6241,@rasbt,2022-01-29 16:46:48+00:00,https://twitter.com/rasbt/status/1487467275162685449,"@nycfksh If you are specifically interested in transformers, there's the xformer library by Facebook Research (https://t.co/umqixG71pF) and HuggingFace's transformer library (https://t.co/rvjy1mXIOW)"
6242,@rasbt,2022-01-29 16:43:34+00:00,https://twitter.com/rasbt/status/1487466458087149574,"@nycfksh Yeah, there are lots of great options out there. I think you can't go wrong with either one. Personally, for general deep learning projects, I am using the following now: https://t.co/USN0H1uE7s"
6243,@rasbt,2022-01-29 14:46:48+00:00,https://twitter.com/rasbt/status/1487437074429104132,Imho the answer was yes. And the 324 people who cited it since them probably found it useful as well and probably agree :)
6244,@rasbt,2022-01-29 14:46:47+00:00,https://twitter.com/rasbt/status/1487437072386478085,"The paper in question (""Fastai: A Layered API for Deep Learning"", https://t.co/vwfFCX8zTA) is a pretty good paper! 

Even if the style may differ from a traditional paper, the question editors should be asking themselves is whether it benefits the community or not üòä"
6245,@rasbt,2022-01-29 02:07:05+00:00,https://twitter.com/rasbt/status/1487245887512485891,@TheNerdStation It‚Äôs mostly blog articles now üòÖ
6246,@rasbt,2022-01-28 23:55:21+00:00,https://twitter.com/rasbt/status/1487212733611266056,"@heads0rtai1s Unfortunately, I don't think the presentation was recorded üòû. Glad to hear that the paper looks useful though!"
6247,@rasbt,2022-01-28 23:40:51+00:00,https://twitter.com/rasbt/status/1487209085531525123,"@heads0rtai1s Or more conceptual, I have a slide deck on ""Modern machine learning -- An introduction to the latest techniques"" that may come in useful: https://t.co/x8JXxkFRFP"
6248,@rasbt,2022-01-28 23:39:08+00:00,https://twitter.com/rasbt/status/1487208652159258628,"@heads0rtai1s Not sure if that's what you are looking for, but we had a tech-focused overview (""Machine Learning in Python: Main Developments and Technology Trends in Data Science, Machine Learning, and Artificial Intelligence"") that summarizes a bit of the landscape https://t.co/U99TAutUzy"
6249,@rasbt,2022-01-28 22:54:08+00:00,https://twitter.com/rasbt/status/1487197326427013120,"@rohepe @PyTorchLightnin I think the best and most up-to-date place is the official docs right now: https://t.co/O2WPwRypKM
There are several layers, from a brief intro to best practices to tutorials. There's tons of good material on there"
6250,@rasbt,2022-01-28 20:09:42+00:00,https://twitter.com/rasbt/status/1487155946468126720,"@code_star Yeah, and it is super easy to finally take advantage of multiple GPUs w/o much effort :)
Trainer(..., accelerator='gpu', devices=4, strategy='ddp')"
6251,@rasbt,2022-01-28 19:29:55+00:00,https://twitter.com/rasbt/status/1487145934429560832,"@ashishkr822 @CSProfKGD You can be lucky if they read the rebuttal ü•≤. (Cynicism aside, yes, sometimes, they do change their decision üôÇ)"
6252,@rasbt,2022-01-28 18:50:17+00:00,https://twitter.com/rasbt/status/1487135961305780225,"The last couple of weeks, I took a deep dive into @PyTorchLightnin and am positively surprised how flexible it is for research. Just created a tutorial implementing our recent CORN method for ordinal regression: https://t.co/SMNGlY3FJa"
6253,@rasbt,2022-01-28 15:50:38+00:00,https://twitter.com/rasbt/status/1487090750991089668,This is gold üß™üëë
6254,@rasbt,2022-01-28 15:40:09+00:00,https://twitter.com/rasbt/status/1487088113029627915,"@xamat I haven‚Äôt used Calendly yet but we have a @getclockwise plug-in for Google calendar, and let me tell, you coming from academia where we email meeting times to each other this has been a big wow moment for me ü§Ø.  Big game changer for productivity"
6255,@rasbt,2022-01-28 15:33:54+00:00,https://twitter.com/rasbt/status/1487086541688250370,"@zacharylipton @weights_biases @l2k Haha, that‚Äôs a new one. Usually we just say Wand. I think the B is silent‚Äî @lavanyaai please correct me if I am wrong üòÜüòÖ"
6256,@rasbt,2022-01-28 02:39:05+00:00,https://twitter.com/rasbt/status/1486891549787140097,"@CSProfKGD Wow nice, and thanks so much!"
6257,@rasbt,2022-01-28 02:38:16+00:00,https://twitter.com/rasbt/status/1486891347114082307,"@roydanroy Like I said, much depends on your environment I'd probably get multiple ones and compare them and then keep the one that works best. However, if you are recording/streaming from home, I'd probably stay away from condensers as they pick up too much noise."
6258,@rasbt,2022-01-28 02:35:26+00:00,https://twitter.com/rasbt/status/1486890634107568139,"@roydanroy If you go XLR, I'd look into the Shure microphones and Neumanns. Again, which one depends in your environment (how much room echo and background noise). If you have a noisy environment, maybe a supercardioid is better. If you have good conditions, a dynamic one may be better"
6259,@rasbt,2022-01-28 02:33:18+00:00,https://twitter.com/rasbt/status/1486890093537370116,"@roydanroy So, if you go the XLR route, you'll have many more options. You'll need an audio interface though, which means yet another box on your desk (and additional cable salad). You can easily spend another $1000 on this but here is a review of some budget options https://t.co/KQfVDRju9H"
6260,@rasbt,2022-01-28 02:27:01+00:00,https://twitter.com/rasbt/status/1486888514805452804,"@roydanroy I am also in the process of upgrading to an XLR mic, so let me know if you are interested in additional details ;)"
6261,@rasbt,2022-01-28 02:26:11+00:00,https://twitter.com/rasbt/status/1486888305039970304,@roydanroy I have both and appreciate the ATR's removal (or not-capturing) of background noise and not picking up room echos. It's great for recording. The Blue Yeti X is better for live audio though since it has a built-in gain meter and various software filters for live audio.
6262,@rasbt,2022-01-28 02:23:31+00:00,https://twitter.com/rasbt/status/1486887634769219585,"@roydanroy Do you want a USB mic or is XLR okay? If you go USB, there are not so many options. The decent ones are
- Audio-Technica ATR2100x-USB
- Blue Yeti 
Depends on your environment though. The ATR is great if you have a lot of background noise, but you will have to be way closer"
6263,@rasbt,2022-01-28 01:47:11+00:00,https://twitter.com/rasbt/status/1486878488766386176,"@pcwein @iamtrask @MatDrinksTea yeah, and who would have thunk that streaming exercise classes on internet-connected stationary bicycles would become a thing"
6264,@rasbt,2022-01-28 01:41:19+00:00,https://twitter.com/rasbt/status/1486877015361957894,"@quantadan @TaliaRinger Well fwiw, the 4th data point is that I requested a leave of absence for 2022 üòÖ"
6265,@rasbt,2022-01-27 22:56:33+00:00,https://twitter.com/rasbt/status/1486835547893022721,@CSProfKGD Oh yeah that makes sense. Because of the audience / camera thing I actually never took notes for my slides but yeah I have a habit of going on tangents if I speak freely üòÇ. I may try a setup similar to yours
6266,@rasbt,2022-01-27 22:43:23+00:00,https://twitter.com/rasbt/status/1486832236913729540,@PhDemetri Actually the subject line included sth along the lines of ‚Äúdecision‚Äù and I went from ‚Äúwow that was quick‚Äù to ‚Äúoh now hi hope it was not rejected‚Äù to ‚Äúphew I just forgot some minor info‚Äù
6267,@rasbt,2022-01-27 22:39:08+00:00,https://twitter.com/rasbt/status/1486831163603881984,"@PhDemetri Arg sorry to hear. And no kidding, had the same thing happening to me last week for a paper that was submitted in November ü•≤"
6268,@rasbt,2022-01-27 21:41:33+00:00,https://twitter.com/rasbt/status/1486816675953577989,"@iamtrask @MatDrinksTea I can see it replace Zoom and Slack for certain contexts (like meetings) once headsets become more convenient, and it might become popular in a gaming context but I don‚Äôt see it as a all-day on kind of thing."
6269,@rasbt,2022-01-27 21:34:42+00:00,https://twitter.com/rasbt/status/1486814948806254592,@tunguz Actually I recently got pretty good results with LightGBM üòú
6270,@rasbt,2022-01-27 21:33:38+00:00,https://twitter.com/rasbt/status/1486814681729753092,@zacharylipton @samcharrington @twimlai Nice! Subscribed!
6271,@rasbt,2022-01-27 21:30:19+00:00,https://twitter.com/rasbt/status/1486813849290514433,@CSProfKGD Enjoy! Btw the iPad is used as a teleprompter or auxiliary notes for the slides? (Just curious because I am looking for ways to improve my setup)
6272,@rasbt,2022-01-27 18:49:29+00:00,https://twitter.com/rasbt/status/1486773371664834571,@tom_gxt That‚Äôs a great point!
6273,@rasbt,2022-01-27 18:41:27+00:00,https://twitter.com/rasbt/status/1486771349632819210,"Btw if you want to learn more about Shapley values, this is an amazing write-up by @ChristophMolnar: https://t.co/K97S1AaoLb"
6274,@rasbt,2022-01-27 18:37:45+00:00,https://twitter.com/rasbt/status/1486770419357171722,@IamManuell @amuellerml @ChristophMolnar Precisely. It's turtles all the way down ;)
6275,@rasbt,2022-01-27 18:35:28+00:00,https://twitter.com/rasbt/status/1486769844854923269,"The intuition behind Shapley values is nice (i.e. captures the difference between the actual and average prediction). But I find that the game theoretic foundation makes it really tough to explain, which matters a lot in collaborations &amp; I personally prefer permutation importance"
6276,@rasbt,2022-01-27 18:27:14+00:00,https://twitter.com/rasbt/status/1486767771560075267,@fhuszar Back then I implemented gradient checking for my code. I doubt this is even mentioned in today's deep learning classes üòÖ
6277,@rasbt,2022-01-27 18:19:09+00:00,https://twitter.com/rasbt/status/1486765738119598083,"@amuellerml @ChristophMolnar [2/2] E.g., in a setting with collaborators who are new to ML: sure, you can say Shapley values are computed based on the difference between the actual and the average prediction, but the underlying coalitional game theory stuff is a tough sell when it comes to explaining it."
6278,@rasbt,2022-01-27 18:18:32+00:00,https://twitter.com/rasbt/status/1486765584373227522,"@amuellerml @ChristophMolnar Yeah, I think that's among the best we have right now. But I have a bit of a love-hate relationship with it though. That's because the intuition is quite nice but on the other hand it is much harder to understand &amp; explain than e.g., permutation importance. [1/2]"
6279,@rasbt,2022-01-27 18:05:16+00:00,https://twitter.com/rasbt/status/1486762244864106496,"Haha, hilarious but spot on. On that note, I recently stumbled upon the ""Bayesian Modeling and Computation in Python"" book which looks like a terrific resource: https://t.co/T0pW4QrHHw"
6280,@rasbt,2022-01-27 16:31:51+00:00,https://twitter.com/rasbt/status/1486738735240732673,"@marazul @GaelVaroquaux Yikes, that sounds like a big red flag and (borderline?) unethical"
6281,@rasbt,2022-01-27 16:24:15+00:00,https://twitter.com/rasbt/status/1486736823791534080,"@mrigankanath_ @PyTorchLightnin @aaditks @hardmaru @karpathy @gridai_ Yes! And it was/is also changing so quickly! I don't have a good resource at hand, yet (but we are working on it ... üòä)"
6282,@rasbt,2022-01-27 16:02:40+00:00,https://twitter.com/rasbt/status/1486731392935284741,"@mdank_pl @PatFlynn @mkennedy @__mharrison__ Haven't been asked about that yet, but so far, my online classes are just videos (no exercises or grading components)"
6283,@rasbt,2022-01-27 16:01:11+00:00,https://twitter.com/rasbt/status/1486731019512279048,@ducnh279 @Sauain @justmarkham @GregOnLock Wow glad to hear üôèü§ó
6284,@rasbt,2022-01-27 04:12:16+00:00,https://twitter.com/rasbt/status/1486552614762340354,"@thegautamkamath Generally agree but it also depends on the location :). E.g., in the related work section, an ""in this paper"" sometimes doesn't hurt to make clear that you are referring to the current and not a previous paper."
6285,@rasbt,2022-01-27 03:33:38+00:00,https://twitter.com/rasbt/status/1486542892420288520,"@TaliaRinger Whoa that's really awesome! Sounds like you are more than on track! I think having a grant in the first year is huge. Also, it's a nice buffer that will probably allow you to go easier in the second year if needed"
6286,@rasbt,2022-01-27 03:17:39+00:00,https://twitter.com/rasbt/status/1486538867079536640,"@TaliaRinger My first year was definitely my favorite one. Creating courses was a lot of fun. Also, I really appreciate that people in my department told me that I shouldn't worry about grants in the first year and can just focus on getting settled. But yeah, it felt very very busy"
6287,@rasbt,2022-01-27 03:15:33+00:00,https://twitter.com/rasbt/status/1486538340602204160,"@TaliaRinger Tricky. The first year felt busy coz I was creating 2 new courses from scratch (machine learning and deep learning). However, the 2nd year was also busy due to more committees &amp; grants. Then starting at the 3rd year, it got super busy coz of teaching 3 instead of 2 classes ... üòÖ"
6288,@rasbt,2022-01-27 02:46:00+00:00,https://twitter.com/rasbt/status/1486530904608710660,@zacharylipton *and generalizes well to unseen data
6289,@rasbt,2022-01-26 22:38:20+00:00,https://twitter.com/rasbt/status/1486468577171492869,@aaditks @hardmaru @karpathy Hah I wish it was citable &amp; shareable.  The last couple of days I was in for a treat when meeting and chatting with my brilliant colleagues @gridai_ &amp; @PyTorchLightnin who have so much knowledge around this topic. But there will be resources for sure. Stay tuned :)
6290,@rasbt,2022-01-26 22:18:13+00:00,https://twitter.com/rasbt/status/1486463512436219907,@hardmaru @karpathy I learned so much about DL in production in the last 2 weeks that all the model training for my research projects in the last couple of years now feels like I was just toying around ü§ØüôÉ
6291,@rasbt,2022-01-26 21:59:39+00:00,https://twitter.com/rasbt/status/1486458840371630085,@yoavgo @karpathy you mean the last one? (Because it uses sentence case consistently üôÉ)
6292,@rasbt,2022-01-25 19:29:28+00:00,https://twitter.com/rasbt/status/1486058656747737088,@solislemuslab Awesome! Big big congrats üéâüéäüçæ
6293,@rasbt,2022-01-25 09:52:08+00:00,https://twitter.com/rasbt/status/1485913367629938691,"@CSProfKGD Also given that I get the feeling that many reviewers don't change their scores due to the inconvenience, it might be worthwhile experimenting with a less fine-grained scale for the first round. Like just reject, accept, and borderline."
6294,@rasbt,2022-01-25 09:50:03+00:00,https://twitter.com/rasbt/status/1485912845099413506,"@dimadamen @CSProfKGD That's a valid point. On the other hand, I find that it is sometimes hard to know what to focus on in a rebuttal. Like when reviewer #2 brings up criticism that is in your opinion not worth spending much space on, does the AC see it the same way or want a more elaborate answer?"
6295,@rasbt,2022-01-25 08:39:02+00:00,https://twitter.com/rasbt/status/1485894969692934147,"@roydanroy Haha, well done. Now, to verify your Twitter account, what‚Äôs the answer?"
6296,@rasbt,2022-01-25 07:00:07+00:00,https://twitter.com/rasbt/status/1485870076419059713,"@Miles_Brundage Yeah, I think we already got all we needed."
6297,@rasbt,2022-01-24 23:10:02+00:00,https://twitter.com/rasbt/status/1485751776133488641,"@tom_gxt Yeah,  good point. Maybe because there's always been so many tabular datasets (etc. compared to good &amp; easy-to-use vision sets) that it was hard to find a consensus. On that note, @randal_olson had a comprehensive repo collecting tabular datasets for that https://t.co/kcsoxPUYQG"
6298,@rasbt,2022-01-24 23:01:03+00:00,https://twitter.com/rasbt/status/1485749518666711050,@eigenhector It‚Äôs like in Germany when you order a sparkling water and they bring you the ‚Äòmedium‚Äô option. It falls flat.
6299,@rasbt,2022-01-24 22:45:08+00:00,https://twitter.com/rasbt/status/1485745511185502214,"@TaliaRinger I just switched to 'faculty' at some point because it happened to me twice that people asked who my professor was because they thought I was someone's assistant. In hindsight, maybe going by 'professor' is even clearer &amp; better."
6300,@rasbt,2022-01-24 22:40:55+00:00,https://twitter.com/rasbt/status/1485744451985330186,"@wightmanr @TheZachMueller @NVIDIAAI @PyTorch Oh ok, thanks! Just wanted to make sure this was accounted for :)"
6301,@rasbt,2022-01-24 22:31:52+00:00,https://twitter.com/rasbt/status/1485742171269566465,"@wightmanr @TheZachMueller @NVIDIAAI @PyTorch I wonder also if this can vary widely by hardware. I don't remember the details since it's been a few years when I read about it, but I recall sth along the lines that those cards with tensor cores (like the RTXs) benefit more from NHWC (and other cards worked better with NCHW)"
6302,@rasbt,2022-01-24 22:06:53+00:00,https://twitter.com/rasbt/status/1485735885198999552,"Imho, ML benchmarks are useful internal controls that hint at the hidden potential of a method. The method also needs to be intuitive &amp; easy to use so that the community can take it to a test drive on real-world problems. Great thread on the current state of ML benchmarks üëá"
6303,@rasbt,2022-01-23 11:03:57+00:00,https://twitter.com/rasbt/status/1485206666123616257,"@CSProfKGD I wish I could, but sorry, there are a few papers I have to review this weekend."
6304,@rasbt,2022-01-23 08:21:18+00:00,https://twitter.com/rasbt/status/1485165735185981443,@FlorianGallwitz Btw in case s.o. is interested: I used OpenSea where minting is also free. But I set a bizarrely low gas fee so it took days to transfer at first (actually one still didn‚Äôt arrive yet). Was a good learning experience but yeah it‚Äôs a weird concept that made me feel really old.
6305,@rasbt,2022-01-23 06:35:02+00:00,https://twitter.com/rasbt/status/1485138990789537794,@zacharylipton You mean like Star Trek?
6306,@rasbt,2022-01-22 21:17:35+00:00,https://twitter.com/rasbt/status/1484998705069625348,"@TaliaRinger * to add to that: I met with each of my research students at least 1 hour/week 1:1. And we usually had synchronous and asynchronous discussions on Slack (depends where in the proj). Besides that, also lots of other meetings. ~2-10h per week dep. on the season (e.g, when hiring)."
6307,@rasbt,2022-01-22 21:05:58+00:00,https://twitter.com/rasbt/status/1484995778548576260,"@TaliaRinger 2/2 In Summer, however, it was almost exclusively hands-on research (coding &amp; writing). Spring was somewhere in-between Summer and Fall.  Also, there were even certain weeks where I spent most of my time writing recommendation letters or reviewing papers."
6308,@rasbt,2022-01-22 21:05:25+00:00,https://twitter.com/rasbt/status/1484995640841195522,"@TaliaRinger For me, it was very cyclical. Fall was usually very focused on teaching: Like Mon &amp; Wed mostly creating lectures, and Tue &amp; Thu teaching and answering student question. Then Fri meeting with my research students and coding/writing for our research projects. 1/2"
6309,@rasbt,2022-01-22 20:30:39+00:00,https://twitter.com/rasbt/status/1484986891795673091,"@KyleCranmer @arfon The Journal of Open Source Software  @JOSS_TheOJ is such a milestone for the intersection of academia &amp; open source. Really appreciate it! Also, I love the transparency, and that‚Äôs sth I wish other journals should consider too, to become a more modern medium in 2022 &amp; beyond"
6310,@rasbt,2022-01-22 17:49:08+00:00,https://twitter.com/rasbt/status/1484946246347460611,"This is super cool. Can totally see how that resembles a car. PS: I think there is so much learned from looking at failure cases manually. Feel like this is something we should all do more often (often recommend it to students for the class projects, but it is still rarely done) https://t.co/RF8xsPNU1c"
6311,@rasbt,2022-01-22 17:41:36+00:00,https://twitter.com/rasbt/status/1484944348349358088,"""When Less is More: Simplifying Inputs Aids Neural Network Understanding"" -- a method to compress images into to fewer bits while maintaining prediction accuracy. Neat: allows for post-hoc analysis on what features are most important for prediction. More details in the threadüëá"
6312,@rasbt,2022-01-22 17:27:29+00:00,https://twitter.com/rasbt/status/1484940795333513216,"@iamtrask DL &amp; AI are everywhere, less need to explicitly search for it üôÉ"
6313,@rasbt,2022-01-22 17:22:33+00:00,https://twitter.com/rasbt/status/1484939557288222720,"@xLaszlo I agree. I think that in research, we only learn very rudimentary programming skills (mostly focused on syntax &amp; not so much on how patterns and how to approach a problem). Back in the day it may have been sufficient, but now with code being more involved, we need to fix this :)"
6314,@rasbt,2022-01-22 16:37:46+00:00,https://twitter.com/rasbt/status/1484928284676792326,"@xLaszlo While I mentioned avoiding for-loops in the other thread, I actually write a lot of for-loops. I usually start via the most naive approach (e.g., for-loops), implement some unit tests and runtime benchmarks, and then incrementally rewrite the code."
6315,@rasbt,2022-01-20 22:27:09+00:00,https://twitter.com/rasbt/status/1484291435465740292,"@roydanroy Ha, so assume 4 TPUs ‚âà 1 GPU, then 1 week training on their TPU pod makes 2048/4/52 ‚âà 6 GPU years"
6316,@rasbt,2022-01-20 22:14:18+00:00,https://twitter.com/rasbt/status/1484288200164192256,"@roydanroy Well, this one is on you üòú. You failed to specify which GPU and they probably thought of the GPU in their gaming laptop"
6317,@rasbt,2022-01-20 21:19:26+00:00,https://twitter.com/rasbt/status/1484274392469278728,"@xLaszlo Agreed. Often it can also make things more compact, more readable, and more maintainable though. It all depends on the the context."
6318,@rasbt,2022-01-20 17:40:07+00:00,https://twitter.com/rasbt/status/1484219202223448080,"Back in 1987 (before I was born), Leon Bottou &amp; @ylecun  already wrote their first neural net library for the Amiga ü§Ø"
6319,@rasbt,2022-01-20 17:23:05+00:00,https://twitter.com/rasbt/status/1484214914101260292,"Also, I thought NumPy always supported SIMD (Single Instruction, Multiple Data). TIL that NumPy 1.18 (that's only 2 years ago!) actually didn‚Äôt have ""much"" SIMD support"
6320,@rasbt,2022-01-20 17:19:00+00:00,https://twitter.com/rasbt/status/1484213887666958336,"One of the first things I recommend in my ML class is vectorization &amp; replacing for-loops wherever possible -- e.g., when applying the same op to multiple elements (https://t.co/xRQN8ZsOa6). Just saw this amazing article that goes into way more depth: https://t.co/NeN2nmPOae"
6321,@rasbt,2022-01-20 16:15:17+00:00,https://twitter.com/rasbt/status/1484197852008099845,@crude2refined That's actually pretty neat!
6322,@rasbt,2022-01-20 09:22:47+00:00,https://twitter.com/rasbt/status/1484094044112396288,"@FatihVNurcin @chriswolfvision *PS: I was assuming you were interested in compiling &amp; installing PyTorch yourself. If you just want to install it ""regularly"" you can now get the M1 version from both the PyTorch conda channel and the conda-forge channel."
6323,@rasbt,2022-01-20 08:13:05+00:00,https://twitter.com/rasbt/status/1484076502882861057,"@omarnomad @fchollet Agreed, Notion and Linear may be more powerful tools for project management, but I think that this is really more for advanced use cases. So far, I am impressed how GitHub balances features and complexity. But yeah I can totally picture a ‚Äúsimple‚Äù/‚Äúadvanced‚Äù toggle in the future"
6324,@rasbt,2022-01-19 22:38:43+00:00,https://twitter.com/rasbt/status/1483931958795251722,"@FatihVNurcin @chriswolfvision Not sure if it still works, but I got it to work with the following steps back then: https://t.co/8piBv0jL2w https://t.co/MNZgIW2aYt"
6325,@rasbt,2022-01-19 22:06:18+00:00,https://twitter.com/rasbt/status/1483923801322762243,"@KristinHenry Oh yeah, I think I know what you mean. I have a love-hate relationship with that feeling üòÖ. But usually that means you got something major done. So, congrats, enjoy the success üéâ"
6326,@rasbt,2022-01-19 22:01:29+00:00,https://twitter.com/rasbt/status/1483922587939921924,"@chriswolfvision * in the early days I had to compile certain packages myself, like PyTorch for example. But they (and most others) have added native M1 support in recent months."
6327,@rasbt,2022-01-19 21:58:33+00:00,https://twitter.com/rasbt/status/1483921849323077634,"@chriswolfvision I never ran the terminal through Rosetta. (Have been on an M1 since January 2021.) Maybe I was lucky, but I could go all native M1 thanks to homebrew and miniforge!"
6328,@rasbt,2022-01-19 20:39:16+00:00,https://twitter.com/rasbt/status/1483901896440045571,@soumithchintala it's much appreciated üôè
6329,@rasbt,2022-01-19 20:36:05+00:00,https://twitter.com/rasbt/status/1483901097752383498,"@soumithchintala Oh no, named tensors were big on my radar (https://t.co/m0JQQOEdc8), but yeah, my gut feeling is that adoption would probably remain low (muscle memory of not using it is too strong) so I can totally understand."
6330,@rasbt,2022-01-19 19:54:46+00:00,https://twitter.com/rasbt/status/1483890697757462534,"@TaliaRinger Have *not done* it a lot but *like* it a lot. I'd say it didn't increase my capacity to take on new students, but it can take off the pressure for sure. It gives you the feeling that there is a backup if things get busy or tough, and I can only recommend it if there's a good fit"
6331,@rasbt,2022-01-19 18:15:45+00:00,https://twitter.com/rasbt/status/1483865778633981960,"Wow, it has been FIVE years already!? Happy Birthday üéâüéâüéâ
And thank you for five fun years of tinkering and making üòä"
6332,@rasbt,2022-01-19 18:07:16+00:00,https://twitter.com/rasbt/status/1483863643712274432,"@CSProfKGD @alfcnz @s_scardapane That's definitely a valid concern. I also recorded my in-person lectures and had a professional service add subtitles. My primary intention was that students who didn't feel well didn't have to come to class, and many students said that this was super helpful."
6333,@rasbt,2022-01-19 08:08:21+00:00,https://twitter.com/rasbt/status/1483712920869642240,"@pandeyparul @weights_biases @lavanyaai @bhutanisanyam1 Wow that‚Äôs awesome news! Big congrats, Parul ü•≥ üéâ"
6334,@rasbt,2022-01-19 08:06:13+00:00,https://twitter.com/rasbt/status/1483712384531324928,@CSProfKGD @alfcnz @SapienzaRoma @s_scardapane I gave around 50 x 75 min lectures with a mask in Fall 2021. Felt uncomfortable in the beginning but really got used to it. Number one concern was the muffled sound but it wasn‚Äôt even mentioned once in the students‚Äô course feedback so it probably wasn‚Äôt too bad for them either :)
6335,@rasbt,2022-01-18 18:47:54+00:00,https://twitter.com/rasbt/status/1483511481383755778,@DynamicWebPaige *but that's maybe a personal anecdote üòá
6336,@rasbt,2022-01-18 18:36:35+00:00,https://twitter.com/rasbt/status/1483508636592885761,"@BlackHC I may be wrong, but my advice would be not to spend more time on this since I don't think they will change their opinion. I would just withdraw &amp; submit somewhere else (and maybe incorporate some of the constructive reviewer suggestions)"
6337,@rasbt,2022-01-18 18:25:00+00:00,https://twitter.com/rasbt/status/1483505717961273344,"@DynamicWebPaige The pandemic was/is rough, so I think people want to try something new and have fun along the way (e.g., via closer interaction and an ambitious and impactful mission)."
6338,@rasbt,2022-01-18 12:57:28+00:00,https://twitter.com/rasbt/status/1483423291691999233,@paul_rietschka ResNet-50 ftw https://t.co/mzdeWMP0t2
6339,@rasbt,2022-01-18 11:53:53+00:00,https://twitter.com/rasbt/status/1483407294054510596,@ludwig_stumpp @alisher_ai @__MLT__ @bhutanisanyam1 Nice! Bookmarked!
6340,@rasbt,2022-01-18 10:24:00+00:00,https://twitter.com/rasbt/status/1483384670452699136,"@ChristophMolnar * here, with reviewing I didn't mean peer-reviewing but just checking if papers were acceptable preprints suited for peer-review down the road"
6341,@rasbt,2022-01-18 10:21:34+00:00,https://twitter.com/rasbt/status/1483384060806406146,"@ChristophMolnar Actually, at some point arxiv even had to hire a person dedicated to just reviewing these works ü§™"
6342,@rasbt,2022-01-18 10:19:48+00:00,https://twitter.com/rasbt/status/1483383613290954759,"@ChristophMolnar Essentially, most studies used the same dataset and there was no thorough evaluation (besides showing test accuracies). Like you said, the chest x ray datasets were just used as drop-in replacements for MNIST"
6343,@rasbt,2022-01-18 10:19:02+00:00,https://twitter.com/rasbt/status/1483383420487090179,"@ChristophMolnar I assume and hope most people meant well, but many works also had an opportunistic vibe. I think what most of these works had in common was that they were rushed and limited in scope"
6344,@rasbt,2022-01-18 10:17:25+00:00,https://twitter.com/rasbt/status/1483383014398861314,@ChristophMolnar Agreed. I remember from my time as arxiv moderator that there was a an immense flood of submissions on that topic. Out of the thousand uploaded papers there is a large number of works that we filtered out because it was of questionable value.
6345,@rasbt,2022-01-18 06:55:42+00:00,https://twitter.com/rasbt/status/1483332252432060416,"@alisher_ai @__MLT__ @bhutanisanyam1 Yeah, I can not only recommend one tool but two :). https://t.co/MjRedslvsB (lets you make AlexNet- and LeNet-style figures), and there is the https://t.co/BtNpVWzbDe repo, which looks amazing. Have fun!"
6346,@rasbt,2022-01-17 17:19:13+00:00,https://twitter.com/rasbt/status/1483126775349755906,"@arnabbiswas1 @JFPuget @PranayT17837428 Yes, scikit-learn implements a TimeSeriesSplit that I usually recommend to students. You can plug it into cross_val_score. Also GroupKfold can be useful, e.g., when students were working on projects like predicting the MVP for a given NBA season etc. https://t.co/WTnCb49p7U"
6347,@rasbt,2022-01-17 16:04:34+00:00,https://twitter.com/rasbt/status/1483107990509133836,@kjelljorner @JFPuget @PranayT17837428 Yes in both cases :)
6348,@rasbt,2022-01-17 13:21:45+00:00,https://twitter.com/rasbt/status/1483067014918856705,"@JFPuget @vijayabhaskarj @PranayT17837428 Yes, I think that with larger datasets, you can get away with having a fixed training set and 1 or 2 validation sets.  There is also added complexity when applied to NNs coz it is usually less automatic &amp; you sometimes don't converge for certain folds with a fixed learning rate."
6349,@rasbt,2022-01-17 07:35:32+00:00,https://twitter.com/rasbt/status/1482979887887659010,"@JFPuget @PranayT17837428 [3/3] You can see that XGBoost can perform well, but it also fluctuates wildly (left) compared to a random forest model (right). So my concl. here is that 10-fold CV is not always a guaranteed solution for avoiding ovefitting (but of course better than 1 or no validation set ;)) https://t.co/BxboQ3dczP"
6350,@rasbt,2022-01-17 07:32:44+00:00,https://twitter.com/rasbt/status/1482979184603537414,"@JFPuget @PranayT17837428 [2/3] In a recent research project, I found that the best model is XGBoost -- after tuning (via random search) using 10-fold CV on the training set. For an experiment, I then combined training + test set &amp; resampled it 500 times and used the best parameter config from 10-fold CV."
6351,@rasbt,2022-01-17 07:31:25+00:00,https://twitter.com/rasbt/status/1482978852053913609,"@JFPuget @PranayT17837428 Yeah, there are some best practices, but many important lessons can only be learned by applying them to real-world datasets and carefully looking &amp; thinking about the results. K-fold cross-validation is one of these best practices, but it is not without flaw. [1/3]"
6352,@rasbt,2022-01-16 21:29:34+00:00,https://twitter.com/rasbt/status/1482827392255242241,"@_kenny_joseph @marktenenholtz Thanks, I am glad you liked it! I was always worried that the model evaluation parts were a bit too extensive üòÖ"
6353,@rasbt,2022-01-16 17:54:13+00:00,https://twitter.com/rasbt/status/1482773198504710146,"@pbloemesquire Relaxing the page limits would help, but yeah, maybe not an excuse. There is no page limit that works for everyone -- actually reminds me of a review I saw where the reviewer wrote that the paper was low-quality because it was half a page below the page limit."
6354,@rasbt,2022-01-16 15:46:54+00:00,https://twitter.com/rasbt/status/1482741154986795014,@BatsouElef Paper or ebooks. There was a time when I was into audiobooks but podcasts basically replaced that for me.
6355,@rasbt,2022-01-16 15:07:50+00:00,https://twitter.com/rasbt/status/1482731327120097280,"@yanaiela @yoavgo Hah yeah, meant to hint at the fact that this seems like a complicated topic and a special type of can of worms :). Thanks for the list below. Great resource for me to dig into."
6356,@rasbt,2022-01-16 13:31:17+00:00,https://twitter.com/rasbt/status/1482707026954240000,@yanaiela @yoavgo Wow awesome thread. So the tl;dr is ‚Äúwhere to even begin?‚Äù
6357,@rasbt,2022-01-16 13:20:38+00:00,https://twitter.com/rasbt/status/1482704347104374785,"@Iamfarisology Yeah, I think the hybrid approach is the most common one that many people have adopted in some form over the years"
6358,@rasbt,2022-01-15 19:08:21+00:00,https://twitter.com/rasbt/status/1482429467435876361,"@TaliaRinger I'd go for it! Once heard that the college &amp; dep. prefer if the start-up money is primarily invested into people rather than equipment. In this case, I see this as one of the biggest investments in people/the team as it will be something that will help with communication so much!"
6359,@rasbt,2022-01-15 17:49:57+00:00,https://twitter.com/rasbt/status/1482409735248822275,"@xinformatics It's all related, but I think the idea is more having the focus on an approach/workflow level. Like keeping the model fixed and focusing on individual steps of the data pipeline. Feature engineering and representation learning is certainly part of it."
6360,@rasbt,2022-01-15 17:31:03+00:00,https://twitter.com/rasbt/status/1482404980061577219,"**Also: sure, it's not something completely new. It's more like looking at things with a different perspective &amp; and lots of cool research exists that I would group into that category. E.g., the following recent paper &amp; discussion would fall into this cat: https://t.co/dLJFyprmny"
6361,@rasbt,2022-01-15 17:18:52+00:00,https://twitter.com/rasbt/status/1482401913681416199,"[3/3] but in real-world applications, I think they are complementary."
6362,@rasbt,2022-01-15 17:18:52+00:00,https://twitter.com/rasbt/status/1482401911894642690,"[2/3] I don't think it's necessary to open the can of worms re ""which one is better, model-centric or data-centric"" For investigation &amp; research purposes in method development, it is of course necessary to have a focus on one (ablation-study style),"
6363,@rasbt,2022-01-15 17:18:51+00:00,https://twitter.com/rasbt/status/1482401910309236747,"I think a lot of the question come from thinking about having a ""data driven"" approach and using ""data analytics"" vs the data-centric approach where you keep you model fixed and develop dataset-based methods to improve performance. [1/3]"
6364,@rasbt,2022-01-15 17:18:51+00:00,https://twitter.com/rasbt/status/1482401908597919745,"As data-centric AI has grown into a bigger topic lately, I've seen a lot of discussions where people were wondering ""what's new?"" (A valid q since data is always essential &amp; important.) Had a nice thread discussing the diffs &amp; that's a good article here: https://t.co/2vgjM21aat"
6365,@rasbt,2022-01-15 16:17:03+00:00,https://twitter.com/rasbt/status/1482386355502166018,@sama Here's a good thread with links to relevant articles (and podcasts):  https://t.co/ltKe1Q0RkP
6366,@rasbt,2022-01-15 14:19:41+00:00,https://twitter.com/rasbt/status/1482356822384472075,"@DrGroftehauge Yeah, that make sense. So, from this thread here, I hear that there are mixed feelings but it is super useful in deployment contexts. So, Docker is mostly sitting somewhere between conda + homebrew solutions and Kubernetes, and there are definitely lots of use cases for that."
6367,@rasbt,2022-01-14 22:04:34+00:00,https://twitter.com/rasbt/status/1482111425426477059,"@tom_gxt Haha, yes. I escaped that one so far! Also, I agree with you. I think some academic contexts where it could be useful though is a) reproducibility and b) submitting jobs to a compute cluster if you have complex dependencies (so far I could do these things without docker)"
6368,@rasbt,2022-01-14 15:24:48+00:00,https://twitter.com/rasbt/status/1482010820607451143,@TastanOznur @xamat Oops üò¨ üôä
6369,@rasbt,2022-01-14 14:33:25+00:00,https://twitter.com/rasbt/status/1481997889194835976,"@margrethmpossi I usually create different conda environments for my different projects, but you bring up a good point regarding things outside conda (e.g., compilers that I install via homebrew) -- I guess I was really lucky so far that everything usually worked."
6370,@rasbt,2022-01-14 13:45:57+00:00,https://twitter.com/rasbt/status/1481985944635031552,"@vijayabhaskarj Good question. I think in the science communities, it's a considered as one of the essentials for reproducibility."
6371,@rasbt,2022-01-14 13:45:16+00:00,https://twitter.com/rasbt/status/1481985770151976968,Just stumbled upon the NeurIPS antology viz website. Cool stuff. Maybe as expected: a big growth in distributed optimization. But more impressively: 2020 -&gt; 2021 saw a big growth across all categories (except SVMs of course üòõ) https://t.co/wrEcoyopwI https://t.co/BdyTQflA7a
6372,@rasbt,2022-01-14 13:28:24+00:00,https://twitter.com/rasbt/status/1481981525327548416,"@valentyn_bez Yeah, but I also think that conda got so much better. Specifically, I am thinking about the great conda-forge community. Their packages are always up to date. And trickier things like PyTorch have their own conda channels now."
6373,@rasbt,2022-01-14 13:21:01+00:00,https://twitter.com/rasbt/status/1481979668416901123,"@zacharylipton @jacobeisenstein @yoavgo I think I kind of know where my assumptions are coming from, I think in my head I am equating ""distribution shift"" with ""covariate shift"" where the distribution of inputs *but not the labeling function* changes. And ""different domain"" would also imply a labeling func change"
6374,@rasbt,2022-01-14 13:17:20+00:00,https://twitter.com/rasbt/status/1481978740653625344,"@zacharylipton @jacobeisenstein @yoavgo Tricky. My guess is wherever we go from here, there will probably be a significant portion of people being confused/mislead by the usage of these terms. Haha, maybe a good addition to a ""Troubling Trends in Machine Learning Scholarship"" 2.0"
6375,@rasbt,2022-01-14 02:17:01+00:00,https://twitter.com/rasbt/status/1481812566783533059,@zacharylipton @jacobeisenstein @yoavgo Oh yeah I am with you on that point: doesn't have to be a continuous or organic morphing that takes place. Could really be an abrupt shift (like different deployment environment).
6376,@rasbt,2022-01-14 01:45:11+00:00,https://twitter.com/rasbt/status/1481804555415343108,"@zacharylipton @jacobeisenstein @yoavgo I dunno, but to me ""different domain"" would mean  that we e.g. trained a classifier on movie reviews and now use it to classify book reviews. ""Distribution shift"" would be more like that the movie reviews got longer over time, reviewers use different terminology etc."
6377,@rasbt,2022-01-14 01:40:22+00:00,https://twitter.com/rasbt/status/1481803345304199171,"@zacharylipton @jacobeisenstein @yoavgo Sure, ""differently distributed"" is not wrong then, but it is a much broader term. Why not being less vague and use terms like ""different domain"" like @yoavgo suggested. To me ""distribution shift"" has the connotation that the distributions started out as the same once."
6378,@rasbt,2022-01-13 13:47:18+00:00,https://twitter.com/rasbt/status/1481623894452842499,"@Jeande_d Not sure but I‚Äôd say it‚Äôs not super useful in a Python context. It might make more sense in a pointer-based language like C. Anyways, reminds me of the fun times implementing these things for education purposes ü§ó https://t.co/kt9qSaAxj4"
6379,@rasbt,2022-01-13 13:42:13+00:00,https://twitter.com/rasbt/status/1481622617685639174,@pbaylies @paul_rietschka And it‚Äôs still alive and kicking: https://t.co/3cCMmxKCNr
6380,@rasbt,2022-01-13 13:38:29+00:00,https://twitter.com/rasbt/status/1481621677557567488,"@c3K Ah, thanks!"
6381,@rasbt,2022-01-13 01:12:07+00:00,https://twitter.com/rasbt/status/1481433848718282762,@tdietterich Please someone run this experiment to confirm üôÉ https://t.co/txNm5vXSd4
6382,@rasbt,2022-01-12 22:10:26+00:00,https://twitter.com/rasbt/status/1481388123447771138,"@chriswolfvision It should definitely work, make sure it's connected to power, otherwise it will go to sleep when the display is closed."
6383,@rasbt,2022-01-12 21:23:58+00:00,https://twitter.com/rasbt/status/1481376432236511238,"@paul_rietschka Totally! I am guilty of that myself for all the reasons you mentioned (https://t.co/dJ3jgtBbQv) -- ok, technically speaking resnet-34 to keep it even more compact."
6384,@rasbt,2022-01-12 14:45:04+00:00,https://twitter.com/rasbt/status/1481276045672202244,"""A Light in the Dark: Deep Learning Practices for Industrial Computer Vision:"" Large, pre-trained models for large DNNs with hundreds of millions of params do not always win compared to small, hand-crafted CNNs when in comes to real-world applications https://t.co/BNmr8lYQVN https://t.co/o5xuLRtNDl"
6385,@rasbt,2022-01-12 03:40:26+00:00,https://twitter.com/rasbt/status/1481108785531965440,"@chriswolfvision Enjoy! For installing Python stuff, I recommend miniforge (https://t.co/OKx3RDLEst) ‚Äî most packages have ARM support now."
6386,@rasbt,2022-01-12 03:05:32+00:00,https://twitter.com/rasbt/status/1481100003359797254,@dabeaz No. I occasionally but rarely download a project from there if it is an app or library I know and consider ‚Äútrustworthy‚Äù. But it‚Äôs usually those apps that have been on there for a long time and/or are in archival mode. I wouldn‚Äôt put up anything new there.
6387,@rasbt,2022-01-12 01:12:27+00:00,https://twitter.com/rasbt/status/1481071541152628741,"I feel like there should be a +1 for points on the reviewer scale if your paper (/ supplementary material) includes such a detailed &amp; useful ""Lessons learned"" doc: https://t.co/kyq29wMORU https://t.co/9hLvSFj9ls"
6388,@rasbt,2022-01-12 00:03:25+00:00,https://twitter.com/rasbt/status/1481054171935748098,"* In hindsight, I totally should have annotated that better. Quick &amp; dirty fix: https://t.co/Rt3mfdwTks"
6389,@rasbt,2022-01-11 23:58:30+00:00,https://twitter.com/rasbt/status/1481052932695068674,"@jacobsn @CSProfKGD @rbpless @rsouvenir19 @SattlerTorsten ""All good things come in threes"" as the saying goes üòâ"
6390,@rasbt,2022-01-11 23:55:13+00:00,https://twitter.com/rasbt/status/1481052106345914371,"[3/3] From, a more practical standpoint, I still like the 1SE rule as it can lead to models that simpler which can help with interpretation (but sure, there is always a trade-off; interpretation is not useful if the model is not accurate.)"
6391,@rasbt,2022-01-11 23:55:13+00:00,https://twitter.com/rasbt/status/1481052104865292291,"[2/3] In ""Chen &amp; Yang, The One Standard Error Rule for Model Selection: Does It Work, 2021"" (https://t.co/FsTJzioKEX), the authors compared it to regular CV and said they found no evidence confirming that the 1SE rule can consistently outperform regular CV"
6392,@rasbt,2022-01-11 23:55:12+00:00,https://twitter.com/rasbt/status/1481052102348750848,"In class, I once mentioned the ""one standard error"" method (orig. from ESL, I think) -- picking the most parsimonious model within one standard error of the best one. (also wrote about it here: https://t.co/hOuwSrmRWT). Someone just sent me a follow-up article on that [1/3] https://t.co/QIxdUM9U3x"
6393,@rasbt,2022-01-11 21:33:17+00:00,https://twitter.com/rasbt/status/1481016386143072256,@subratac You are correct. Hoping it will be out in a few weeks!
6394,@rasbt,2022-01-11 20:51:28+00:00,https://twitter.com/rasbt/status/1481005865742348291,@jtleek @fredhutch Amazing news! Congrats! üéâüéä
6395,@rasbt,2022-01-11 20:13:53+00:00,https://twitter.com/rasbt/status/1480996404667506690,"@ezyang I recommend installing the ""stats"" app (https://t.co/IveBiSKars) and put some basic monitors into your status bar. Then, keep an eye on it and to see if there's something hogging your RAM or CPU which might explain it https://t.co/g1lEQzIDLR"
6396,@rasbt,2022-01-11 18:28:40+00:00,https://twitter.com/rasbt/status/1480969926450073603,"@Ricardo_0621 Thanks, glad to hear!"
6397,@rasbt,2022-01-11 13:49:27+00:00,https://twitter.com/rasbt/status/1480899659291836418,@TaliaRinger This is amazing! Love your lecture design. It looks so fun and engaging!
6398,@rasbt,2022-01-11 13:46:26+00:00,https://twitter.com/rasbt/status/1480898901465092105,@douwekiela @huggingface Awesome! Big congrats! üéâ Looking forward to following your research contributions on Twitter! ü§ó
6399,@rasbt,2022-01-11 13:24:40+00:00,https://twitter.com/rasbt/status/1480893423955628032,"@ChristophMolnar Wow, big congrats taking this leap! This is really awesome! Also, I am really looking forward to the 2nd edition of Interpretable Machine Learning. Loved the 1st ed and have been recommending it to all my students -- it was super helpful when working on their class projects!"
6400,@rasbt,2022-01-11 00:50:43+00:00,https://twitter.com/rasbt/status/1480703687747989513,"@tdietterich That's pretty neat. I think most of us have been doing something similar on our lecture slides, so why not doing something similar in papers as well :)."
6401,@rasbt,2022-01-11 00:47:45+00:00,https://twitter.com/rasbt/status/1480702938892886018,"@TaliaRinger As suggested, my first try would be pandoc. If the results look ugly, another one that works quite well is to generate the PDF as usual and then open it in Adobe Acrobat Pro (most universities have a subscription) and then go Export As -&gt; MS Word"
6402,@rasbt,2022-01-10 21:16:15+00:00,https://twitter.com/rasbt/status/1480649715431714818,"@gridai_ @UWMadison Thanks for the warm welcome, these are exciting times!"
6403,@rasbt,2022-01-10 17:18:14+00:00,https://twitter.com/rasbt/status/1480589814881792005,"@burkov Also, the sad lesson here might be that there is this inherent risk of self-publishing where people take your content and sell it on Amazon without any possibility to intervene."
6404,@rasbt,2022-01-10 17:16:52+00:00,https://twitter.com/rasbt/status/1480589471770988553,"@burkov Arg, I am really really sorry to hear this. I get the idea behind automation, but as a customer who has important issues like that, there needs to be a way to get a human in the loop. I am keeping my fingers crossed that it will somehow work out in the end. ü§û"
6405,@rasbt,2022-01-10 13:57:50+00:00,https://twitter.com/rasbt/status/1480539383413493766,@guillemch Wow glad to hear that this was so helpful! Thanks for the kind words!
6406,@rasbt,2022-01-10 13:57:25+00:00,https://twitter.com/rasbt/status/1480539276186107905,@_krr12 Oh yeah :) https://t.co/CCuxYc3Gye
6407,@rasbt,2022-01-10 13:34:06+00:00,https://twitter.com/rasbt/status/1480533408648421379,@guillemch PS: there is also a whole new layout so 50 pages means like 80 pages in the old layout :). Plus there is also syntax coloring in the ebook version now. https://t.co/1YAErhIAaZ
6408,@rasbt,2022-01-10 13:29:49+00:00,https://twitter.com/rasbt/status/1480532330615816193,"@guillemch Several additions, like explaining the math behind gradient boosting for classification, a rewritten backprop chapter etc. Then, there are also a new 50-page chapter on transformers and a 40-page chapter on graph neural nets. And, of course, now all DL chapters are in PyTorch!"
6409,@rasbt,2022-01-10 02:25:31+00:00,https://twitter.com/rasbt/status/1480365156160917505,"@RWerpachowski @TaliaRinger Oh good point. (Didn't think about it, in my car I can flip over the backseats to get to the trunk)"
6410,@rasbt,2022-01-10 00:15:26+00:00,https://twitter.com/rasbt/status/1480332420314447879,@CSProfKGD ‚ÄúWould it kill you to make the code available on GitHub?‚Äù
6411,@rasbt,2022-01-10 00:13:58+00:00,https://twitter.com/rasbt/status/1480332048539787269,@RWerpachowski @TaliaRinger Came here to say this. Unfortunately this may not help you short term (unless maybe ordering an equivalent one with 1-day delivery &amp; getting it next day is ok) but this is a lifesaver. Got one when I lived in Michigan and that‚Äôs one item I always have in the trunk.
6412,@rasbt,2022-01-10 00:06:21+00:00,https://twitter.com/rasbt/status/1480330132879556609,@CSProfKGD Doesn‚Äôt sound too bad. Have fun!
6413,@rasbt,2022-01-09 22:15:02+00:00,https://twitter.com/rasbt/status/1480302118917578757,@CSProfKGD Whoa! Neat trick associating paper reviews with pleasant scenery and creating to a distraction free environment to get it all done. How many papers are left?
6414,@rasbt,2022-01-09 22:09:25+00:00,https://twitter.com/rasbt/status/1480300706624065546,"@_goose_god Good q! I wrote a short section explaining the basics (the code is here: https://t.co/uqTo6WXWJv). However, be assured that I'll be creating a lot more material dedicated to Lightning this year!"
6415,@rasbt,2022-01-09 17:07:14+00:00,https://twitter.com/rasbt/status/1480224660470083588,"Omg so close! Only one final chapter layout to check! Really excited about the release of ""Machine Learning with PyTorch and Scikit-Learn"" (sometime) this month. In the mean time, all the accompanying code materials are already up on GitHub: https://t.co/1fFQeWfbgJ"
6416,@rasbt,2022-01-09 15:51:17+00:00,https://twitter.com/rasbt/status/1480205544724090892,"@peteronyisi1 @WKCosmo I don't doubt that. On the other hand there is also a long-term perspective. Even if students learned a lot, if they disliked the class, they could lose a lot of motivation to pursue this subject further &amp; avoid it in the future, learning less. E.g. this happened to me with math."
6417,@rasbt,2022-01-09 15:19:47+00:00,https://twitter.com/rasbt/status/1480197618529710086,"@BlackHC @SashaMTL This is probably the best approach. But at the same time, it is also sad that this might be the best approach."
6418,@rasbt,2022-01-09 14:52:12+00:00,https://twitter.com/rasbt/status/1480190674490347520,@SashaMTL üòé https://t.co/uxcKMkgahj
6419,@rasbt,2022-01-09 14:43:29+00:00,https://twitter.com/rasbt/status/1480188482526003201,"@SashaMTL * Adding something about the limitations feels definitely more naturally to me because that's how I learned it, and I am generally also a completionist, haha. However, over the years, I was nudged to not do that, and it doesn't feel right üòÖ"
6420,@rasbt,2022-01-09 13:25:03+00:00,https://twitter.com/rasbt/status/1480168745087684611,"@arnabbiswas1 @__mharrison__ @alfcnz One day in the future, I'd love to have a room dedicated to recording. Something without road noise or echo. I guess then the Yeti may be more useful for recordings as well."
6421,@rasbt,2022-01-09 13:10:44+00:00,https://twitter.com/rasbt/status/1480165142646202370,"@arnabbiswas1 @__mharrison__ @alfcnz [2/2] The ATR2100 needs post-processing though because it has a very low gain. Hence, the ATR2100 for recording things, and the Yeti for live things, because the quality is still good and you can adjust the gain better on that one."
6422,@rasbt,2022-01-09 13:09:35+00:00,https://twitter.com/rasbt/status/1480164852874326020,@arnabbiswas1 @__mharrison__ Haha the situation is complicated: The one hanging up there is a very old ATR2100. I upgraded to a Blue Yeti upon popular recommendation (@alfcnz) but it picks up too much noise so I switched back to the ATR2100 for recordings. [1/2]
6423,@rasbt,2022-01-08 22:20:53+00:00,https://twitter.com/rasbt/status/1479941203638554625,"@KyleCranmer Not that it matters for most workloads on the M1, but the 16"" has also slightly better cooling than the 14"""
6424,@rasbt,2022-01-08 22:19:49+00:00,https://twitter.com/rasbt/status/1479940934523670533,"@KyleCranmer Paradoxically, I prefer the larger ones when traveling. Sure, not on the airplane (but I don't use computers on an airplane anyways), but if you don't have an external monitor available (like hotels etc.), I really appreciate the extra screen estate."
6425,@rasbt,2022-01-08 22:10:52+00:00,https://twitter.com/rasbt/status/1479938683268698121,"@KyleCranmer Ok fair :). Still curious though, the new Mac is a MacBook Pro again? 16 inch?"
6426,@rasbt,2022-01-08 21:48:42+00:00,https://twitter.com/rasbt/status/1479933102734692353,"@KyleCranmer Curious, ""This Mac"" is Kyle's MacBook Pro (7)? üòâ"
6427,@rasbt,2022-01-08 20:17:35+00:00,https://twitter.com/rasbt/status/1479910175414923264,"@zikribayraktar @__mharrison__ Oh wow interesting, didn't know that! Thanks for sharing! I had the window to the side in my old room but then intentionally set up my desk differently this time to maximize brightness -- basically the opposite of what this article suggests."
6428,@rasbt,2022-01-08 17:52:31+00:00,https://twitter.com/rasbt/status/1479873666183839751,"@mmencherogarcia @leonpalafox @yoavgo @TaliaRinger Yes, absolutely! And it is fun (for both me and the students). And it gives you something unique to write about in recommendation letters."
6429,@rasbt,2022-01-08 17:24:03+00:00,https://twitter.com/rasbt/status/1479866502832660480,"[7/7] I really like these additions as they are simple and seemingly easy to implement / add to existing ViTs. Quantitively they improve accuracy. And as a qualitatively check, attention scores indeed become more focused https://t.co/2goS2PryRM"
6430,@rasbt,2022-01-08 17:24:02+00:00,https://twitter.com/rasbt/status/1479866497208102917,"[6/6] Locality self-attention looks like simple scaling (basically softmax + temperature scaling) and diagonal masking (to remove self-token relations). As a result, we make the attention scores less smooth in order to get some value (no pun intended) from those: https://t.co/67v06pV12Y"
6431,@rasbt,2022-01-08 17:24:00+00:00,https://twitter.com/rasbt/status/1479866491818463236,"[5/7] The shifted patch attention (SPT) looks pretty straight forward -- doesn't look much different from traditional data augmentations applied in CNNs contexts. In sum, the goal here is to pack more spatial information into visual tokens: https://t.co/E8QLJ3VnDq"
6432,@rasbt,2022-01-08 17:24:00+00:00,https://twitter.com/rasbt/status/1479866488257499142,[4/7] These modifications seem to makes ViTs more data-efficient (and more accurate) across the board https://t.co/RSx9emY1Z7
6433,@rasbt,2022-01-08 17:23:59+00:00,https://twitter.com/rasbt/status/1479866485006909445,"[3/7] There is an interesting paper (""Vision Transformer for Small-Size Datasets"") by Lee, Lee, &amp; Song that address these issues above by 1) shifted patch tokenization and 2) locality self-attention add-ons https://t.co/OTlEt8axQ3"
6434,@rasbt,2022-01-08 17:23:58+00:00,https://twitter.com/rasbt/status/1479866483534610433,[2/7] Why do ViTs usually have a less locality inductive bias? 1) Tokenization: they generate non-overlapping patches to have permutation importance (but this shrinks the receptive field). 2) Attention: the dim is so high that attention scores become smooth.
6435,@rasbt,2022-01-08 17:23:58+00:00,https://twitter.com/rasbt/status/1479866482012180480,Vision Transformers (ViTs) are an interesting development in computer vision. One downside: they are more data hungry than CNN. Presumably because they have less of a spatial / locality inductive bias so they require more data to obtain acceptable visual representations üßµ [1/7]
6436,@rasbt,2022-01-08 17:15:18+00:00,https://twitter.com/rasbt/status/1479864300739117058,"@base2bit @karlrohe For reference, the logistic regression results https://t.co/VrYSGIsqWB"
6437,@rasbt,2022-01-08 17:10:59+00:00,https://twitter.com/rasbt/status/1479863212472479752,@base2bit @karlrohe Fun Saturday experiment: a perceptron also gets an impressive 89%! https://t.co/o6wjRccn5b
6438,@rasbt,2022-01-08 17:04:22+00:00,https://twitter.com/rasbt/status/1479861547363090432,"@base2bit @karlrohe The prediction is still based on the sum of the inputs and model weights though. It's a generalized linear model that learns a linear decision boundary. You can probably still get 93% accuracy without the nonlinearity. I.e., you can run an experiment with Adaline or an perceptron"
6439,@rasbt,2022-01-08 14:57:16+00:00,https://twitter.com/rasbt/status/1479829562469007371,"@karlrohe What I always found fascinating about MNIST is that you can get very high classification accuracy with a linear model (e.g., logistic regression) like 93% (vs 10% for random prediction accuracy). Maybe interesting to think about that in the context PCA as linear transformation"
6440,@rasbt,2022-01-08 14:47:20+00:00,https://twitter.com/rasbt/status/1479827064610082820,"@leonpalafox @__mharrison__ Haha, I am on &amp; off with those. Had one in grad school and loved it, but the last 5 years I had a Apple keyboard and that was fine too. It recently died and I just felt like getting a (cheaper) mechanical one to replace it."
6441,@rasbt,2022-01-08 14:27:39+00:00,https://twitter.com/rasbt/status/1479822111736836102,"@__mharrison__ Ok, here we go: https://t.co/PtiO8XmO0l"
6442,@rasbt,2022-01-08 14:25:56+00:00,https://twitter.com/rasbt/status/1479821677093699585,"@leonpalafox @yoavgo @TaliaRinger Oh btw this reminds me in case someone is interested, I wrote down what I ended up doing here: https://t.co/HLJzYQNS7b https://t.co/LW4nTP2Kmj"
6443,@rasbt,2022-01-08 14:05:52+00:00,https://twitter.com/rasbt/status/1479816628451876867,"@yoavgo @TaliaRinger Yet so many students are overworked and stressed at the end of the semester, and a final exam can be a lot of extra pressure especially if there is also a class project (which I find also super valuable). Ups and downs either way"
6444,@rasbt,2022-01-08 14:04:06+00:00,https://twitter.com/rasbt/status/1479816184837120006,"@yoavgo @TaliaRinger Yeah I agree, like you said exams can be a very strong incentive for students to review the material and get them to ask questions about things that didn‚Äôt make sense, and to give them an opportunity to make it click."
6445,@rasbt,2022-01-08 14:00:20+00:00,https://twitter.com/rasbt/status/1479815234789515264,@yoavgo @TaliaRinger What students liked about it was that it also removed pressure as the end of the semester is always hectic and stressful.
6446,@rasbt,2022-01-08 13:59:52+00:00,https://twitter.com/rasbt/status/1479815117722243072,@yoavgo @TaliaRinger Not sure that this was the perfect solution but I thought this way I can get students to engage with the material on a weekly or lecture-by-lecture basis to make sure that they don‚Äôt fall behind and wait until the end of the semester to cram for a final exam.
6447,@rasbt,2022-01-08 13:58:44+00:00,https://twitter.com/rasbt/status/1479814831796596736,"@yoavgo @TaliaRinger I see your point. This and last semester I removed the exam from my class but then, like you hint at, how do you make sure students follow the material? What I tried was  making weekly untimed online quizzes students could take any time."
6448,@rasbt,2022-01-08 13:55:26+00:00,https://twitter.com/rasbt/status/1479814003916521474,"@yoavgo @TaliaRinger But no matter how you look at it, there is always a flip side. I like teaching a lot, but I really don‚Äôt like grading students. I wish we could just  teach without having to worry about how to assign scores."
6449,@rasbt,2022-01-08 13:53:14+00:00,https://twitter.com/rasbt/status/1479813449001676805,"@yoavgo @TaliaRinger Sounds like a good approach. I am not a fan of exams in general but if you have one, then allotting the max time makes sense. One problem with infinite time is that some students have other commitments (like classes afterwards they have to attend), which can make it unfair"
6450,@rasbt,2022-01-07 22:06:24+00:00,https://twitter.com/rasbt/status/1479575170042019853,"@DimitrisPapail @madiator @FluxML @PyTorch @JuliaLanguage Oh yeah, it's a neat concept especially for research-type of programming. I guess it's more of taking functional approach in Julia vs Python OOP that you prefer then? I remember to have seen decorators for multiple dispatch in Python but these are of course hacks/workarounds"
6451,@rasbt,2022-01-07 21:58:00+00:00,https://twitter.com/rasbt/status/1479573056867741701,"@chriswolfvision @CSProfKGD Wow congrats, and all the best for the next big thing in your career! Also a perfect gift for your time off before the next adventure starts!"
6452,@rasbt,2022-01-07 15:54:58+00:00,https://twitter.com/rasbt/status/1479481694809997313,@TaliaRinger This may have been one of those I watched https://t.co/Xp8B2KecVR and then it was basically trial and error for me from there
6453,@rasbt,2022-01-07 15:51:26+00:00,https://twitter.com/rasbt/status/1479480809094582279,"@TaliaRinger Also check out if the state parks in your area have groomed trails. Here, in Wisconsin it's pretty awesome. You can get a yearly state park permit for like &lt; 30 bucks and pretty much all the trails are groomed (and closed for hikers) during the snow season."
6454,@rasbt,2022-01-07 15:49:38+00:00,https://twitter.com/rasbt/status/1479480353156997120,"@TaliaRinger Just watched a few youtube videos üòÖ. The classic/traditional style is pretty easy to get into. Almost like walking and there is nothing that can wrong really. Skating is maybe a bit trickier, and you would also need different skis for that. I would start with traditional perhaps"
6455,@rasbt,2022-01-07 15:47:12+00:00,https://twitter.com/rasbt/status/1479479741438701579,"@DimitrisPapail @madiator @FluxML @PyTorch @JuliaLanguage ""Also, why would one pick JAX over PT?"" E.g. you want to readily train on TPUs. Or for your research purposes, you find it easier to work with derivative functions rather than tracing the outputs backwards https://t.co/CeMtzkAJUX https://t.co/zRTsdDgJMm"
6456,@rasbt,2022-01-07 15:42:52+00:00,https://twitter.com/rasbt/status/1479478651557228551,"@DimitrisPapail @madiator @FluxML @PyTorch @JuliaLanguage ""can you port PT models to JAX in a relatively straightforward way?"" Just checking: Jax/Flax/Haiku doesn't seem to have stable ONNX support yet (https://t.co/odCyZG2FsP)"
6457,@rasbt,2022-01-07 15:40:36+00:00,https://twitter.com/rasbt/status/1479478079013724161,"@DimitrisPapail @madiator @FluxML @PyTorch @JuliaLanguage If you don't like the PT syntax, my guess is you'll have similar issues with Jax/Flax. E.g., your
stdv = 1. / math.sqrt(self.weight.size(1))
https://t.co/ePrseENWNb.uniform_(-stdv, stdv)

example would be sth like this: https://t.co/dpkpd0tTYR"
6458,@rasbt,2022-01-07 15:15:29+00:00,https://twitter.com/rasbt/status/1479471761704067076,"@TaliaRinger Good q. I usually avoid it and go cross-country skiing in this weather. It's still good exercise but you can bundle up better (scarf, boots, jacket) without it becoming annoying, and you feel like you are getting the most out of this season. https://t.co/hTJXzoM8CO"
6459,@rasbt,2022-01-07 14:53:48+00:00,https://twitter.com/rasbt/status/1479466302637027333,"@Klyetsko I've been using it all my career because it's free, and its features like seeing what papers cited a given paper are really useful. It's also nice that it links to various sources for PDFs in case articles are behind paywalls."
6460,@rasbt,2022-01-07 13:42:11+00:00,https://twitter.com/rasbt/status/1479448282103435267,"@TroyDLoeffler Interesting, thanks for sharing! Don't mean to criticize (and you couldn't have known), but in the context of this thread, the random sampling baseline would have been nice to study how much of the performance is due to the dataset selection vs using active learning üòÖ https://t.co/JXkIKB60pb"
6461,@rasbt,2022-01-07 13:28:38+00:00,https://twitter.com/rasbt/status/1479444870913835008,"@AllesistKode @mariaKhalusova Yeah, that's a great way to put it!"
6462,@rasbt,2022-01-06 23:04:11+00:00,https://twitter.com/rasbt/status/1479227325082394624,"Alright, wrapping up the topic of feature selection with a code example showing how to use sequential feature selection in practice: https://t.co/4wfGyarKQh"
6463,@rasbt,2022-01-06 21:10:19+00:00,https://twitter.com/rasbt/status/1479198669027131392,"@drob Pen &amp; paper is a big part of my ""studying"" workflow. Helps me with staying focused. https://t.co/NLIuFwS57e"
6464,@rasbt,2022-01-06 18:15:22+00:00,https://twitter.com/rasbt/status/1479154642550411267,"@DimitrisPapail @FluxML @PyTorch @JuliaLanguage Depends on your use case I guess. If you routinely want to compare your methods to other ones, and using PyTorch doesn't slow you down to much, it probably make sense to adopt it (considering that 60% of all DL paper implementations are now in PyTorch, https://t.co/DcWadBnqE3). https://t.co/qXWrwV1EEm"
6465,@rasbt,2022-01-06 16:34:12+00:00,https://twitter.com/rasbt/status/1479129179891376128,"@roydanroy @KDziugaite Anyways, will start collecting all the papers shared in this thread now for a potential blog post review in the future. Thanks for sharing, everyone!"
6466,@rasbt,2022-01-06 16:33:08+00:00,https://twitter.com/rasbt/status/1479128915134365699,@roydanroy @KDziugaite Also reminds me of the following paper that took this to the extreme by creating a 65%-accurate CIFAR-10 classifier from just 10 examples (although those were synthetic ones) https://t.co/PgZ3bZt8YY.
6467,@rasbt,2022-01-06 16:32:34+00:00,https://twitter.com/rasbt/status/1479128771672387586,@roydanroy @KDziugaite Nice one. Thanks for sharing. There seems to be a common theme that more data (assuming is correctly labeled) is not always better.
6468,@rasbt,2022-01-06 14:43:00+00:00,https://twitter.com/rasbt/status/1479101198787653634,"@crude2refined @siddkaramcheti @RanjayKrishna @drfeifei @chrmanning One example that comes to mind is Bayesian hyperparameter optimization vs random search. In my project experience, random search usually always performed better"
6469,@rasbt,2022-01-06 14:40:22+00:00,https://twitter.com/rasbt/status/1479100533382299649,"@lucaruzzola Good q and I am not sure. I am usually not too deep into active learning literature. Regarding boosting you raise a good point. We use rel. shallow learners where uncertainty is easier to estimate and since it is additive, it's more difficult to harm the whole model via outliers"
6470,@rasbt,2022-01-06 14:34:05+00:00,https://twitter.com/rasbt/status/1479098953807405056,"@giffmana I remember reading a related paper last year that basically also confirms what you found: ""Re-labeling ImageNet: from Single to Multi-Labels, from Global to Localized Labels"" https://t.co/l6HN9UJNpK https://t.co/nE7Sr03Cow"
6471,@rasbt,2022-01-06 14:32:37+00:00,https://twitter.com/rasbt/status/1479098583605551106,@giffmana Just asking because I think these tasks are slightly different but combining these (cleaning up labels + removing outliers) can probably have a even stronger positive effect on model prediction performance.
6472,@rasbt,2022-01-06 14:32:26+00:00,https://twitter.com/rasbt/status/1479098537153822721,"@giffmana Thanks for sharing. Haven't had a chance yet to read your paper in detail, but from what I understand you relabeled images (where the label was wrong or ambiguous) rather then removing challenging examples?"
6473,@rasbt,2022-01-06 02:01:21+00:00,https://twitter.com/rasbt/status/1478909523188490240,"@mariaKhalusova *What I meant was: If I need to run NumPy code on the GPU, I may opt for JAX now (as it is kind of a drop-in replacement like CuPy). For DL I will probably stick with PyTorch since I like their API and support for production"
6474,@rasbt,2022-01-06 01:59:02+00:00,https://twitter.com/rasbt/status/1478908938225602564,"@mariaKhalusova Good question. There really isn't as much of a learning curve as I feared as it is so similar to NumPy. Right now, I may not pursue it that much further for now as I don't have a use case for that (given that PyTorch exists) but it might take the role of CuPy (w autodiff) for me"
6475,@rasbt,2022-01-06 01:32:52+00:00,https://twitter.com/rasbt/status/1478902355689193473,"4/4 More details in the paper ""Mind Your Outliers! Investigating the Negative Impact of Outliers on Active Learning for Visual Question Answering"" (https://t.co/4XPqh9DsOf ) by @siddkaramcheti @RanjayKrishna @drfeifei @chrmanning"
6476,@rasbt,2022-01-06 01:32:52+00:00,https://twitter.com/rasbt/status/1478902353843691524,"3/4 After removing those hard-to-learn examples (examples that yield low confidence and low variability), the authors found that active learning outperforms random sampling and requires up to 2-3x fewer examples for similar performance https://t.co/SGQwlM724S"
6477,@rasbt,2022-01-06 01:32:51+00:00,https://twitter.com/rasbt/status/1478902349661888514,"2/4 First, the authors saw that active learning strategies rarely outperform random sampling. Probably because active learning methods prefer sampling ‚Äúhard-to-learn‚Äù examples -- these examples might actually lead to poor performance though. https://t.co/spwYyY0LK7"
6478,@rasbt,2022-01-06 01:32:50+00:00,https://twitter.com/rasbt/status/1478902345761234947,Active learning usually focuses on labeling examples with high prediction uncertainty to improve performance. Plot twist: removing the most difficult examples (based on confidence &amp; variability) helped reaching good performance with *fewer* examples https://t.co/4XPqh9DsOf 1/4 https://t.co/Grm9QmP2mz
6479,@rasbt,2022-01-06 00:56:26+00:00,https://twitter.com/rasbt/status/1478893185669681154,@unsorsodicorda @pfau What's interesting about that one is that it is based on Lidar and RL in a federated learning setting.
6480,@rasbt,2022-01-06 00:55:23+00:00,https://twitter.com/rasbt/status/1478892920136777728,"@unsorsodicorda @pfau Another relevant one: https://t.co/y4ZrlgQzNW (not strictly¬†a factory setting but something to watch for). Now, it also reminds me of the food delivery robots that we have cruising on campus since 2019ish"
6481,@rasbt,2022-01-05 22:46:14+00:00,https://twitter.com/rasbt/status/1478860420274397187,@LorenaABarba Patagonia? Wow this looks really awesome! Wish to go there one day!
6482,@rasbt,2022-01-05 22:37:32+00:00,https://twitter.com/rasbt/status/1478858228738011136,"@thegautamkamath I would probably put an asterisk (*) on posting on social media: in case you are planning to submit it to a conference, make sure that this is in line with recent guidelines."
6483,@rasbt,2022-01-05 19:49:30+00:00,https://twitter.com/rasbt/status/1478815943757537280,"@amy_tabb @szintri Won't recommend, haha. I used ""penultimate layer"" in one of my papers once (referring to a neural network's layer that comes before the output layer) and it created  trouble &amp; questions üò∞"
6484,@rasbt,2022-01-05 19:43:30+00:00,https://twitter.com/rasbt/status/1478814433434611715,"@themintsv it's still a prototype, but you can already install &amp; use it via
conda install torchvision -c pytorch-nightly"
6485,@rasbt,2022-01-05 19:39:15+00:00,https://twitter.com/rasbt/status/1478813364054802433,"It's nice to see that alongside the API refresh, the new training recipe they used also resulted in better predictive performances: https://t.co/tnTeErEip9"
6486,@rasbt,2022-01-05 19:35:51+00:00,https://twitter.com/rasbt/status/1478812508102307840,"It's awesome to see that torchvision added a new API to support multiple sets of weights for each model: https://t.co/euVAaLX33G . I am actually really liking this approach, and it's nice that it is also backwards compatible. https://t.co/0xj6vyF29q"
6487,@rasbt,2022-01-05 18:17:42+00:00,https://twitter.com/rasbt/status/1478792841149263876,@DynamicWebPaige @code @gitlens Nice! I love VS Code for regular coding but for some reason I still use Jupyter Lab for most notebook coding. This notebook diff-ing feature could be the final straw to make me want to switch everything to VS Code now.
6488,@rasbt,2022-01-05 17:23:42+00:00,https://twitter.com/rasbt/status/1478779250874327042,"Last week, I talked about my favorite feature importance technique. I guess it's time to follow-up with my favorite feature selection technique: https://t.co/K3EKVxKvaW"
6489,@rasbt,2022-01-05 16:38:15+00:00,https://twitter.com/rasbt/status/1478767812843872261,@BerbaFan That'd be a great topic for an AMA one day :)
6490,@rasbt,2022-01-05 04:05:13+00:00,https://twitter.com/rasbt/status/1478578304680607744,@pooja_LuvIndia Deciding to let go of the old and starting something completely new. There‚Äôs a new book and a new job ü§ó
6491,@rasbt,2022-01-05 00:51:23+00:00,https://twitter.com/rasbt/status/1478529527630417923,@varcharr It was a lucky coincidence that my prof heard that there was this interesting pattern rec class and encouraged me to take it. The rest came naturally as I got really hooked and developed a huge motivation to learn more about machine learning.
6492,@rasbt,2022-01-05 00:22:11+00:00,https://twitter.com/rasbt/status/1478522177343340545,@WangMiaoyan Big congrats Miaoyan! What a great way to start into 2022 üéâ
6493,@rasbt,2022-01-04 16:23:01+00:00,https://twitter.com/rasbt/status/1478401593204695041,"@unsorsodicorda @pfau Oh yeah, I think I remember hearing about Covariant in a podcast some time ago. I am not following the robotics field very closely, but I also remember the Neural Descriptor Fields paper that I found really promising &amp; impressive: https://t.co/TKOwkN1w99"
6494,@rasbt,2022-01-04 14:20:40+00:00,https://twitter.com/rasbt/status/1478370802986893321,"@fishnets88 You mean DL in general? Yeah, totally. Should have discussed that in the first lecture somewhere https://t.co/GsfIkiywrT"
6495,@rasbt,2022-01-04 02:18:52+00:00,https://twitter.com/rasbt/status/1478189153443631110,"Wow, just realized that Watermark (IPython/Jupyter magic) turned 8 years old! Also just released a new version (https://t.co/mcWXveqldQ), and thx to contribs, you can now print your Conda env. Hah, managing notebooks for research, teaching, &amp; book, I wish we added this earlier üòÖ https://t.co/c3XnNJtpfi"
6496,@rasbt,2022-01-04 02:07:14+00:00,https://twitter.com/rasbt/status/1478186226469548037,"@Jeande_d Ah yes, NAS! Reminds me of the brilliant article by Lilian Weng in 2020: https://t.co/ZafRSWEScP. I haven't followed NAS too closely in 2021 and don't know where it has been going since then except this recent one :) https://t.co/kaiaiX7FUl"
6497,@rasbt,2022-01-03 22:22:47+00:00,https://twitter.com/rasbt/status/1478129740569530374,@unsorsodicorda Great list!  ViT for object detection in videos will also be an interesting one. Not sure if it will be 2022 or more like 2023 &amp; 2024 when ViT-CNN hybrid models are a big(ger) thing
6498,@rasbt,2022-01-03 16:39:52+00:00,https://twitter.com/rasbt/status/1478043445235273733,"@paul_rietschka I can totally see that if you are working primarily on text, images, or tabular data, then graph nets are super unexciting. I think the computational bio background with focus on small molecule/drug discovery makes them very intriguing atm"
6499,@rasbt,2022-01-03 16:24:31+00:00,https://twitter.com/rasbt/status/1478039580624535556,"@DrGroftehauge @paul_rietschka *Actually, I already uploaded the code for that chapter here: https://t.co/gfgF8SQ8B1 (not sure if it is useful without text though)"
6500,@rasbt,2022-01-03 16:22:48+00:00,https://twitter.com/rasbt/status/1478039150251102208,"@DrGroftehauge @paul_rietschka Yeah, I think that's usually in social network or protein network contexts. In a molecule context, you usually consider all nodes and edges for classifying the molecule graph (biologically active, toxic, soluble, etc.). There will be a chapter on that in my upcoming book :)"
6501,@rasbt,2022-01-03 16:03:05+00:00,https://twitter.com/rasbt/status/1478034187298955265,"@paul_rietschka With graph nets we will have to see. I think they enable lots cool things more naturally (social network graphs, small molecules, etc.). But yeah, breakthrough models like AlphaFold2 modeled protein structures (graphs) with transformers rather than graph neural nets."
6502,@rasbt,2022-01-03 16:00:18+00:00,https://twitter.com/rasbt/status/1478033485562535939,"@paul_rietschka Let's say trends = things people focus on ;).  I am also skeptical whether vision transformers replace CNNs, but I can see hybrids being a common, well-working thing in the future"
6503,@rasbt,2022-01-03 15:55:17+00:00,https://twitter.com/rasbt/status/1478032225144905735,"@eugenvector Good call. Tried to summarize distributed training into ""platforms"". Regarding federated learning (which I usually see more as a smartphone and IoT device rather than datacenter thing -- correct me if I'm wrong), I don't have a good intuition if it has peaked or is still a trend"
6504,@rasbt,2022-01-03 15:49:01+00:00,https://twitter.com/rasbt/status/1478030646056525825,@nycfksh My little pony is featured in another lecture/video üò¨ https://t.co/VLj8F2fMiX
6505,@rasbt,2022-01-03 15:42:59+00:00,https://twitter.com/rasbt/status/1478029128926482435,@guillaume_salou @huggingface Congrats! What a way to start into 2022! üöÄ
6506,@rasbt,2022-01-03 15:32:23+00:00,https://twitter.com/rasbt/status/1478026462238289920,"@math_dandy Happy new year! Haven't taught time series in a ML context in university, but @seanmylaw is an expert in this area and may have a few tips."
6507,@rasbt,2022-01-03 15:25:32+00:00,https://twitter.com/rasbt/status/1478024736298999811,"@nialloh23 Oh yeah, both (the resurgences of) multi-task models and multi-modal models are good points."
6508,@rasbt,2022-01-03 15:21:29+00:00,https://twitter.com/rasbt/status/1478023717347336193,"@qasim31wani There are cool things you can do with them in the context of synthesizing molecules. My PhD student has been working on that. Still tricky for ""larger"" molecules, but those challenges may be overcome (similar to how we can make GANs work way past MNIST &amp; CIFAR-10 now)"
6509,@rasbt,2022-01-03 15:16:29+00:00,https://twitter.com/rasbt/status/1478022459068719105,"* For reference, those slides I was referring to: https://t.co/WXb2AoX2AU (and a recording: https://t.co/kBgOPL6adS)"
6510,@rasbt,2022-01-03 15:15:25+00:00,https://twitter.com/rasbt/status/1478022192201969667,"Re deep learning trends: was just looking at my slides from almost exactly 1 year ago. They were self-supervised learning, graph neural nets, large language models, vision transformers. Anything changed/to add? I'd add diffusion models, data-centric AI, platforms. Your thoughts?"
6511,@rasbt,2022-01-03 14:36:49+00:00,https://twitter.com/rasbt/status/1478012479095840768,"@guillemch @vandotorres @remarkablepaper @moleskine Thanks for sharing. I had a 13"" Sony Digital Paper but sold it ~1 1/2 years ago as I am no working from home. I am still debating whether I need/should get another gadget. Maybe once I am through my current stash of physical books and notebooks üòÖ"
6512,@rasbt,2022-01-03 13:56:42+00:00,https://twitter.com/rasbt/status/1478002383259119619,"@abhi1thakur As far as I understand the Colab subscriptions, the GPU type is based on availability? So, this implies that too many other people also got Colab Pro+?"
6513,@rasbt,2022-01-03 13:34:08+00:00,https://twitter.com/rasbt/status/1477996702854520837,"@AnnaGHughes This! I tried this many times as a grad student but found that trying to read a paper on an airplane with loud background noise, clumsy note-taking, and other disruptions was probably among the most unproductive things I ever tried."
6514,@rasbt,2022-01-03 13:22:39+00:00,https://twitter.com/rasbt/status/1477993812265947139,@unsorsodicorda Thanks so much for the interest in my books and all the helpful discussions!
6515,@rasbt,2022-01-03 00:12:40+00:00,https://twitter.com/rasbt/status/1477795007113355267,"@vandotorres @remarkablepaper @moleskine Interesting! I was actually thinking about the Remarkable 2 a few months ago. But since I am not traveling much these days, as a note-taking device,I thought it might be unnecessary. I can see though how it might be useful for reading + annotating books. What are your thoughts?"
6516,@rasbt,2022-01-02 20:58:23+00:00,https://twitter.com/rasbt/status/1477746114648580108,@vandotorres It really depends on how long and complicated the topic is. Say it‚Äôs a 1 hour lecture then the note taking takes ~1h as well (or longer if you pause). And the digitizing and organizing maybe another hour. It‚Äôs time we‚Äôll spent though.
6517,@rasbt,2022-01-02 14:45:09+00:00,https://twitter.com/rasbt/status/1477652188252020739,"Happy New Year everyone! As I did my yearly review yesterday, I noticed that I got so many cool things done in 2021. However, I am disappointed as the list of things I wanted to get done is at least twice as long. So, my 2022 goal is focusing on the process rather than outcomes"
6518,@rasbt,2022-01-01 13:57:05+00:00,https://twitter.com/rasbt/status/1477277701937508356,@DhSubhas The company is a remote-first company so I think this may be possible
6519,@rasbt,2021-12-31 20:29:32+00:00,https://twitter.com/rasbt/status/1477014077331419136,@themintsv Yes! I am joining as Lead AI Educatorü§óüöÄ
6520,@rasbt,2021-12-31 19:44:45+00:00,https://twitter.com/rasbt/status/1477002809040113672,More opportunities if you want to try something new in 2022. Join an awesome team focused on developing user-friendly platforms for deep learning &amp; AI at scaleüëá
6521,@rasbt,2021-12-31 19:28:11+00:00,https://twitter.com/rasbt/status/1476998637523775491,"@bezy92 @obsdmd I tried Obsidian a few years back. It's a great app, indeed! It's pretty snappy and markdown all the way :)"
6522,@rasbt,2021-12-31 19:27:25+00:00,https://twitter.com/rasbt/status/1476998445701472261,"@paintingpeter I am really sorry to hear about your brain injuries. I am wishing you all the best, and I am hoping there is a chance you can fully recover."
6523,@rasbt,2021-12-31 19:22:45+00:00,https://twitter.com/rasbt/status/1476997270067367936,"@nycfksh Honestly, each app or approach has some weakness or limitation. Tried migrating everything to OneNote, Notion, Obsidian. Ultimately, I found that the wiki is just fine. It's a long-term knowledgebase for me, whereas I use OneNote/Notion too for more temporary notes / collaboation"
6524,@rasbt,2021-12-31 19:19:52+00:00,https://twitter.com/rasbt/status/1476996546520662018,"@willem_ropke Yeah, I use Notion for team-based notetaking and tasks lists, too, and it's a great tool"
6525,@rasbt,2021-12-31 16:37:28+00:00,https://twitter.com/rasbt/status/1476955676492578821,@muralijnu1 I've been using MindNode https://t.co/xZTIfGzEZN
6526,@rasbt,2021-12-31 16:25:01+00:00,https://twitter.com/rasbt/status/1476952545188892673,"5) For super helpful information that I want to access most conveniently long into the future, I also make entries in my personal Wiki (I use DokuWiki: https://t.co/PvkYfot3xd). Sometimes, I just link the markdown files from step 3, but sometimes I make direct entries if helpful. https://t.co/MOk5Grr5nZ"
6527,@rasbt,2021-12-31 16:25:00+00:00,https://twitter.com/rasbt/status/1476952540742926337,"4) Depending on what I am learning I also try to put it into context, for example using a mind map. This, again, helps me to think about the material more deeply, and playing around with the hierarchy has a great learning effect. https://t.co/CSbdMm73tk"
6528,@rasbt,2021-12-31 16:24:59+00:00,https://twitter.com/rasbt/status/1476952536460451843,"3) When transcribing my notes, I also think about which pieces of information are the most valuable &amp; that I want to retain long-term. I add these to Anki (https://t.co/qNkSYhJnp7) for spaced repetition. Just formulating the questions has a great learning effect already. https://t.co/PQcgD3f7Th"
6529,@rasbt,2021-12-31 16:24:58+00:00,https://twitter.com/rasbt/status/1476952531968348160,"2) Then, I am usually transcribe my notes from paper to digital (often markdown). Sounds like a waste of time? Yeah, but I think this steps helps with thinking about the material again. It also helps me think about how to organize the material, which has a learning effect for me https://t.co/5Y62DYwapH"
6530,@rasbt,2021-12-31 16:24:57+00:00,https://twitter.com/rasbt/status/1476952525869879299,"1) I tried taking notes in many ways (text editors, tablets, etc.). However, a few years ago, I found that I can focus best by starting the tradition way using pen &amp; paper. I usually don't capture everything, but the main points I want to retain or want to think about. https://t.co/AeimwBGNDv"
6531,@rasbt,2021-12-31 16:24:55+00:00,https://twitter.com/rasbt/status/1476952516973707270,"Wishing you all a Hayppy New Year and a great start into 2022! A new year is a great time to pick up some new skills! Everyone has their own favorite study skills, but since I am often asked about mine, today is maybe a good day to share üßµ"
6532,@rasbt,2021-12-31 14:12:38+00:00,https://twitter.com/rasbt/status/1476919229542772740,@valentyn_bez @pypi Thanks for the note. I just see they have a scikit-contrib package here (https://t.co/Vqaxx8xZqu). Should compare it to sequential feature selection some time.
6533,@rasbt,2021-12-31 14:08:13+00:00,https://twitter.com/rasbt/status/1476918116034781192,@denzil_correa Noted!
6534,@rasbt,2021-12-31 01:11:39+00:00,https://twitter.com/rasbt/status/1476722686290243584,"Machine learning is not complete without code examples. So here they come, permutation importance part 2, the missing code examples üëá
https://t.co/nzG1skUT7b"
6535,@rasbt,2021-12-31 00:07:17+00:00,https://twitter.com/rasbt/status/1476706489796632577,"@_joaogui1 @iamtrask yeah that could explain it. I think @iamtrask is UK-based whereas I am US-based. However, I still feel like they should partially reimburse you if that's the case."
6536,@rasbt,2021-12-31 00:05:59+00:00,https://twitter.com/rasbt/status/1476706160053043209,"@iamtrask No, I definitely don't have one."
6537,@rasbt,2021-12-30 23:58:45+00:00,https://twitter.com/rasbt/status/1476704340308078598,@iamtrask Whoa. I feel like if they remove these from your library they should at least reimburse you. Btw I just double checked and I still seem to have it in my library so it could also be a technical glitch in your case? Would definitely contact their customer support though. https://t.co/VroKMZuueO
6538,@rasbt,2021-12-30 23:53:33+00:00,https://twitter.com/rasbt/status/1476703033987899392,"@andrejerkelens Tbh it's really hard to tell. In a recurrent method like DeepAR, I can imagine that each feature may bear a lot of importance. Maybe here the ""drop column"" approach would be more reasonable (but then the problem is you have to pay attention that each model trains to convergence)"
6539,@rasbt,2021-12-30 23:51:17+00:00,https://twitter.com/rasbt/status/1476702463155654665,"@BexTuychiev Shapley values are a neat concept. But to be honest, they are way more difficult to understand and explain."
6540,@rasbt,2021-12-30 20:42:37+00:00,https://twitter.com/rasbt/status/1476654982006980612,@Jeande_d @mdurazob Thanks for the kind words üôè
6541,@rasbt,2021-12-30 20:10:52+00:00,https://twitter.com/rasbt/status/1476646993116246019,@vinnuvinay008 Thanks! Approx 70% of the chapters are already layouted. Can't be too long  I hope by mid/late-January.
6542,@rasbt,2021-12-30 19:55:09+00:00,https://twitter.com/rasbt/status/1476643038021799939,"@vovahimself Ikr! There was a time when people at least tried, like Restricted Boltzmann Machines and such."
6543,@rasbt,2021-12-30 19:48:30+00:00,https://twitter.com/rasbt/status/1476641365962461189,"@vovahimself Hah, yeah, and in hindsight Graph Neural Networks is maybe an unfortunate term. It's like calling RNNs ""Sequence Neural Networks"""
6544,@rasbt,2021-12-30 19:41:02+00:00,https://twitter.com/rasbt/status/1476639484452216836,"PS: there will be a chapter on Graph Neural Nets in ""Machine Learning with PyTorch and Scikit-Learn"" üòä https://t.co/p2AWXoSDzV"
6545,@rasbt,2021-12-30 19:36:39+00:00,https://twitter.com/rasbt/status/1476638379873873931,Graph neural nets are one of the coolest architectures that picked up steam in recent years. Especially if you are into comp bio.
6546,@rasbt,2021-12-30 19:23:50+00:00,https://twitter.com/rasbt/status/1476635155792109568,"@RohitK_Singh @bhutanisanyam1 @nischay_twt Meanwhile, the first 15 km of the season https://t.co/vbR798Q7cS"
6547,@rasbt,2021-12-30 19:21:43+00:00,https://twitter.com/rasbt/status/1476634625376194561,@RohitK_Singh @bhutanisanyam1 @nischay_twt Oh I see. For some reason I was thinking of an e-mountain bike üòÖ
6548,@rasbt,2021-12-30 14:22:50+00:00,https://twitter.com/rasbt/status/1476559408201146376,@bhutanisanyam1 @nischay_twt Wow this looks stunning! And 230 km on a bike? Double wow!
6549,@rasbt,2021-12-30 14:17:00+00:00,https://twitter.com/rasbt/status/1476557941184643073,"@jha01roshan Yeah, there is no silver bullet other than looking at correlation maps and considering removing features if they are highly correlated."
6550,@rasbt,2021-12-30 14:15:59+00:00,https://twitter.com/rasbt/status/1476557682182180867,"@BharatR123 Yes, however, the importance will be split among those two then. In the upcoming video, I have a code example on that."
6551,@rasbt,2021-12-30 00:08:19+00:00,https://twitter.com/rasbt/status/1476344362204340229,"@lantiga @gridai_ Having read &amp; really enjoyed your book almost exactly 1 year ago, it's so awesome that we get to work together soon! Small world and exciting times!"
6552,@rasbt,2021-12-30 00:00:11+00:00,https://twitter.com/rasbt/status/1476342313735577602,"""Video Lectures Tree-based Methods, Model Eval &amp; Feature Selection"" Just put together a list of my 2020 &amp; 2021 ML (not DL) videos, coz the end of the year is a great time to get organized! And maybe some of you might find them useful for kickstarting 2022! https://t.co/tJU9cJp9ek"
6553,@rasbt,2021-12-29 23:56:28+00:00,https://twitter.com/rasbt/status/1476341379341205505,@tom_gxt Yes! I almost never use univariate methods for that reason. PI for feature importance and sequential feature selection for feature selection.
6554,@rasbt,2021-12-29 21:19:16+00:00,https://twitter.com/rasbt/status/1476301817386516481,"@nycfksh Do you mean sth like that permutation importance represents sth like leave-one-out on feature columns, and you are thinking about including more features at a time (ala k-fold)? I can see how that can be useful in certain contexts, e.g., pixel groups, or groups of one-hot columns"
6555,@rasbt,2021-12-29 18:32:12+00:00,https://twitter.com/rasbt/status/1476259773733560322,"Permutation importance, one of my favorite machine learning methods. It's an intuitive and model-agnostic way to find out which features your ML model relies on the most: https://t.co/jypMJUUOEH"
6556,@rasbt,2021-12-29 18:13:51+00:00,https://twitter.com/rasbt/status/1476255154706034692,"@itsBexli Yeah, the feeling that you put something really useful out into the world is the best feeling ü§ó"
6557,@rasbt,2021-12-29 14:07:08+00:00,https://twitter.com/rasbt/status/1476193069485674509,@breezybadgerr @RisingSayak Thanks for the recommendation!
6558,@rasbt,2021-12-29 14:06:37+00:00,https://twitter.com/rasbt/status/1476192937889476614,"@RisingSayak No, I haven't! Just about to create a wishlist ... (for 2023!?)"
6559,@rasbt,2021-12-29 14:03:26+00:00,https://twitter.com/rasbt/status/1476192136156622849,"@paulsqapp Hah, on that note, many of my blog posts have more citations than my papers"
6560,@rasbt,2021-12-29 14:01:42+00:00,https://twitter.com/rasbt/status/1476191700682821638,"@BlackHC I can see how these are related, but no, not in this paper. To be fair, this is a NeurIPS paper, but I'd maybe expect this to be done as separate future work, or maybe in an extended JMLR version."
6561,@rasbt,2021-12-29 13:57:53+00:00,https://twitter.com/rasbt/status/1476190741693181960,@badbit_0 Yes!
6562,@rasbt,2021-12-29 01:14:30+00:00,https://twitter.com/rasbt/status/1475998628728782848,"@DrGroftehauge You mean whether the dataset generalizes to other architectures? If I understood the paper correctly, they used the same dataset to train finite-width ConvNet and got 50% (as opposed to 64%), which is still very impressive. https://t.co/Chxevo0yY5"
6563,@rasbt,2021-12-29 01:04:41+00:00,https://twitter.com/rasbt/status/1475996158661124098,"Come work with us and help making AI &amp; deep learning at scale easier, cheaper, and faster"
6564,@rasbt,2021-12-29 00:58:03+00:00,https://twitter.com/rasbt/status/1475994490175475717,"Here is the original Data Distillation paper from 2018 for reference (https://t.co/6oqxYOpxJ9), which got an impressive 54% accuracy at the time using 100 CIFAR-10 images. Moreover, it has a nice figure illustrating this: https://t.co/oCToTVwzAT"
6565,@rasbt,2021-12-29 00:58:02+00:00,https://twitter.com/rasbt/status/1475994485817585668,"Impressive results via data distillation (aka reducing a large dataset to a synthetic, smaller one). Here, the researchers represent the 50k images in CIFAR-10 via just 10 images. A model trained on these 10 img achieves 64% accuracy on the orig test set https://t.co/MZHHSaDcK5 https://t.co/3LRn4xAOse"
6566,@rasbt,2021-12-29 00:38:29+00:00,https://twitter.com/rasbt/status/1475989566414860289,"@vandotorres @elonmusk @heydave7 @karpathy There are parts in my course where I link an article or a book chapter for additional detail. Vice versa, there are sections in my book where I recommend a video tutorial for additional detail. I don't think we have to always only rely on one medium for content delivery."
6567,@rasbt,2021-12-29 00:34:08+00:00,https://twitter.com/rasbt/status/1475988470799740931,"@vandotorres @elonmusk @heydave7 @karpathy I think the trick is to recognize which medium is the best suited for the given topic depth. Not a book, but consider the sklearn RF documentation as an example (https://t.co/K9V2WBv54W). I don't think you want/need a video course on that."
6568,@rasbt,2021-12-29 00:32:53+00:00,https://twitter.com/rasbt/status/1475988154209427464,"@vandotorres @elonmusk @heydave7 @karpathy As always, your mileage will vary. There are many parts where my machine learning course is more thorough than my book, and vice versa, there are many parts where my book is more thorough than my ML course."
6569,@rasbt,2021-12-28 23:40:20+00:00,https://twitter.com/rasbt/status/1475974930789457922,"@nevgeniev @vandotorres @elonmusk @heydave7 @karpathy That‚Äôs often true. But for complicated topics it can be harder to learn from books, and it is easier to lose motivation if you struggle too much. Overall, my ratio is maybe 70:30 books vs online lectures"
6570,@rasbt,2021-12-28 20:55:49+00:00,https://twitter.com/rasbt/status/1475933528030334976,"@rustyrazorblade @tomgoldsteincs If I hear &gt; 3 more people agreeing with you, I may actually give the 4th one a chance after all"
6571,@rasbt,2021-12-28 20:51:46+00:00,https://twitter.com/rasbt/status/1475932508541923328,"@unsorsodicorda @_willfalcon @gridai_ @PyTorchLightnin @huggingface Besides the official Lightning tutorials, you might like @_willfalcon &amp; @alfcnz  PyTorch Lightning MasterClass playlist: https://t.co/MWdQl52nl1 . I also have a section in my upcoming book, but it's only going over the basics. Stay tuned for much more material in 2022 :)"
6572,@rasbt,2021-12-28 20:44:14+00:00,https://twitter.com/rasbt/status/1475930613521817609,"@vandotorres @elonmusk @heydave7 @karpathy Books are usually more comprehensive and easier to search. Courses are usually more accessible, and it's easier to show and visualize things this way. Actually, I recommend both: A course to get introduced to a topic, and a book as a in-depth follow-up."
6573,@rasbt,2021-12-28 20:37:05+00:00,https://twitter.com/rasbt/status/1475928816069533697,"""Should You Use Upper Bound Version Constraints?"" I was recently thinking very hard about this as I am putting together the GitHub repo of my book. Now, this is a very thoughtful article on why upper bound constraints are causing real world problems:
https://t.co/nlQIjqvzGr"
6574,@rasbt,2021-12-28 20:28:45+00:00,https://twitter.com/rasbt/status/1475926718816870406,"@tomgoldsteincs If you finish these prereqs, I am not really sure whether you‚Äôll have any desire left to watch the 4th one. And based on what I‚Äôve heard your probably won‚Äôt be missing out. If I were you, I‚Äôd probably just watch the 1st one and leave it at that"
6575,@rasbt,2021-12-28 19:49:15+00:00,https://twitter.com/rasbt/status/1475916777544638472,@themintsv @_willfalcon @gridai_ @PyTorchLightnin https://t.co/ieeQ2LmCzb
6576,@rasbt,2021-12-28 19:22:59+00:00,https://twitter.com/rasbt/status/1475910167631966211,"Let me bump this to 11 üòä. Was just checking my mailbox downstairs, and what  thoughtful gift by @_willfalcon and  the @gridai_ &amp; @PyTorchLightnin team! What an awesome selection to kickstart 2022 üöÄ. Thanks so much! https://t.co/Rn0broV5Bl"
6577,@rasbt,2021-12-28 15:59:22+00:00,https://twitter.com/rasbt/status/1475858923848704003,"@BharatR123 Agreed :). They also recently added this ""Public access"" bar below your citations. It turns red if you don't have all your paper adhering to the open access standards, which is actually pretty good for motivating people to do the right thing üòä https://t.co/4faPkQPQav"
6578,@rasbt,2021-12-28 14:09:36+00:00,https://twitter.com/rasbt/status/1475831301483675651,"Whoops, achievement unlocked. Looks like Google Scholar got into gamification recently. But I must say a little motivational tidbit like that is not a bad way to start the day with üòä https://t.co/MganuuCkAL"
6579,@rasbt,2021-12-27 20:23:02+00:00,https://twitter.com/rasbt/status/1475562890102980620,"@gupta_anik Oh, thanks a lot for your interest! This was my last semester at the university, though. However, the good news is that I will be fully focused on creating educational content around deep learning and AI @gridai_ next year! And I'll make sure to share it ü§ó"
6580,@rasbt,2021-12-27 17:09:40+00:00,https://twitter.com/rasbt/status/1475514230648487938,"After watching a bunch of professionals do it, this is my current setup of options: https://t.co/EwmQ7hVdSx"
6581,@rasbt,2021-12-27 17:09:40+00:00,https://twitter.com/rasbt/status/1475514226999533570,"Have been 1upping my audio editing skills. Learning entirely new skills, and it's actually really fun. (And I am definitely going collect before-and-after examples so that I can automate this with a DL model -- probably U-Net? -- in the future üòâ) https://t.co/TP5HUiK8m2"
6582,@rasbt,2021-12-27 14:06:05+00:00,https://twitter.com/rasbt/status/1475468027714056207,"Oh, a belated Xmas gift just came in: course evaluations! Being back in person had its challenges. But overall, I think it was a great semester, and it was really motivating to teach so many students who where so excited about ML. And their class projects were really impressive! https://t.co/HGpaFdDvtg"
6583,@rasbt,2021-12-27 13:42:09+00:00,https://twitter.com/rasbt/status/1475462004894842880,"Ok ok, I should have shared the titles. But no endorsement here though since I know nothing about these books. Each one is from a different person who thinks this is a book I should read this year. It's really a wild mix, and I am pretty curious :) https://t.co/k1jjFlc1TK"
6584,@rasbt,2021-12-27 03:02:35+00:00,https://twitter.com/rasbt/status/1475301053054824449,"Being grateful that Xmas has been very kind to me this year. All I wanted was being surprised by a good book. And I got 6 ü§ó. (And an ""ugly"" Xmas sweater that will be featured on upcoming recordings.) https://t.co/nh2cp1BJR4"
6585,@rasbt,2021-12-26 23:52:11+00:00,https://twitter.com/rasbt/status/1475253136658944001,"Thanks to @cHHillee I learned the author is on twitter as well, and you can find the following 4 parts in the thread below: https://t.co/4m0MqrHyxo"
6586,@rasbt,2021-12-26 23:25:45+00:00,https://twitter.com/rasbt/status/1475246487282016257,"@cHHillee @IAmAdiFuchs had no idea, thanks for sharing!"
6587,@rasbt,2021-12-26 23:08:00+00:00,https://twitter.com/rasbt/status/1475242019966660614,"@TaliaRinger Yeah, one problem is that many people don't consider non-ML baselines anymore. A first question should be whether this problem ""should"" (not ""can"") be automated via AI at all. But even if the answer is yes, it also doesn't always have to be ML."
6588,@rasbt,2021-12-26 22:12:12+00:00,https://twitter.com/rasbt/status/1475227977654886402,"When it comes to DL research, I think that model efficiency (runtime, size, energy) will be one of the big themes in 2022 and beyond. Just found Adi Fuchs' 5-part series on AI accelerators as a good end-of-the-year read: AI Accelerators ‚Äî Part I: Intro https://t.co/1A504TXCxs"
6589,@rasbt,2021-12-25 23:04:28+00:00,https://twitter.com/rasbt/status/1474878740022894605,@ezyang @bhutanisanyam1 PS: link to the AMA https://t.co/g6Kpbc4G3w
6590,@rasbt,2021-12-25 23:04:04+00:00,https://twitter.com/rasbt/status/1474878641779757070,"@ezyang It‚Äôll be interesting! @bhutanisanyam1 &amp; I recently discussed this during an AMA. I think universities may try to keep in-person lectures, but ultimately it‚Äôll be similar to theatre plays went: you go on special occasions but the default will be watching movies at home"
6591,@rasbt,2021-12-25 22:30:25+00:00,https://twitter.com/rasbt/status/1474870171676332037,"@ilyaraz2 Nice, I am going for 3-4 days a week now, &amp; it feels good. Other things I am proud of are: getting up at 6 am every day, consistently getting outside for at least 1 hour every day, completing an in-person semester successfully, a new book, and taking a leap and starting a new job"
6592,@rasbt,2021-12-25 20:43:57+00:00,https://twitter.com/rasbt/status/1474843381025103880,@PacktPub @vmirly @PacktAuthors Just see it is #1 in neural nets. That‚Äôs super exciting ü§ó https://t.co/47Ced5f8Zp
6593,@rasbt,2021-12-25 13:44:07+00:00,https://twitter.com/rasbt/status/1474737724053725184,@sarveshnikumbh @shoyer And maybe there is also too much of ‚Äúlet‚Äôs just keep it as traditional and rudimentary as possible because these leaves the least room for misinterpretation by the reviewers.‚Äù
6594,@rasbt,2021-12-25 13:42:26+00:00,https://twitter.com/rasbt/status/1474737302735892480,"@sarveshnikumbh @shoyer Yes, I agree. Sometimes, I feel like there is a bit too much of an ‚Äúit has to be done this way because it‚Äôs always been done this way‚Äù."
6595,@rasbt,2021-12-25 13:12:20+00:00,https://twitter.com/rasbt/status/1474729725822124042,"@shoyer Given conference paper deadlines, it‚Äôs maybe easier to add last minute results that way in overleaf directly, and to append a few more row with the reviewers‚Äô favorite methods after the rebuttal."
6596,@rasbt,2021-12-24 23:02:51+00:00,https://twitter.com/rasbt/status/1474515948581359620,@m_pulkit @omarsar0 @KilianQW Thanks! I am actually planning to add more bonus contents over the winter break :)
6597,@rasbt,2021-12-23 19:07:50+00:00,https://twitter.com/rasbt/status/1474094413710336008,"@thegautamkamath @tetraduzione Yeah. It's been incredibly strange and intense year. Also with the many added responsibilities around academic duties and changes wrt to teaching modalities, I can totally sympathize and can totally recommend everyone to take a break, get some rest, and pick it up again next year"
6598,@rasbt,2021-12-23 18:41:23+00:00,https://twitter.com/rasbt/status/1474087759648329734,@tetraduzione @thegautamkamath or there were simply no innovations in theoretical CS this year üò¨
6599,@rasbt,2021-12-23 17:27:41+00:00,https://twitter.com/rasbt/status/1474069211408441344,"Btw, here is the Table of Contents (and I am adding the code files one by one here https://t.co/1fFQeWfbgJ as I am going through the prefinals) https://t.co/1h9taXIJbt"
6600,@rasbt,2021-12-23 17:24:22+00:00,https://twitter.com/rasbt/status/1474068376641318916,@AdrianEisenmei2 Thanks for the kinds words and support!
6601,@rasbt,2021-12-23 17:08:28+00:00,https://twitter.com/rasbt/status/1474064373140406277,"Just heard that it is available on Amazon (for pre-order) now too https://t.co/vQv1P30OFR. I am currently checking the prefinals, and I am super excited about the new layout. The syntax coloring is really neat, and the math formatting is so much cleaner this time https://t.co/2oiU8uRowz"
6602,@rasbt,2021-12-23 16:54:50+00:00,https://twitter.com/rasbt/status/1474060945064349701,"Now that all the grading is done (yay), I just realize that the holidays are already upon us. It's been quite year. Hope you can take some time off &amp; relax too! Happy holidays!"
6603,@rasbt,2021-12-23 15:38:57+00:00,https://twitter.com/rasbt/status/1474041846678667272,"@vovahimself However, the silver lining or nice side-effect of trying to develop AGI may be that you develop lots of useful training mechanisms and architectures along the way, which, in turn, can also improve predictive models ü§ó"
6604,@rasbt,2021-12-23 15:31:10+00:00,https://twitter.com/rasbt/status/1474039890660757511,"@vovahimself Because maybe the world is not worse off without AGI. But there are so many applications that can have positive impacts, from better climate models, discovering cheaper and better pharmaceuticals (https://t.co/V2XdyWCyvl), predicting earthquakes (https://t.co/MlkYMrEQNc) etc."
6605,@rasbt,2021-12-23 15:25:17+00:00,https://twitter.com/rasbt/status/1474038407781310469,"Very true. But as s.o. who is more interested in predictive modeling than developing AGI, I feel like we've made lots of progress in recent years. Transformers may or may not bring us nearer to AGI, but they enable remarkable progress (e.g. think of AlphaFold2 for drug discovery)"
6606,@rasbt,2021-12-23 14:38:31+00:00,https://twitter.com/rasbt/status/1474026639772327940,"All the assignments in an Intro to Statistical Pattern Rec class that introduced me to ML. All HW and assignment templates were in MATLAB, which I didn‚Äôt like. So I was reimplementing algorithms (PCA, naive Bayes, LDA) from scratch in Python &amp; learned so much during this process"
6607,@rasbt,2021-12-23 14:31:26+00:00,https://twitter.com/rasbt/status/1474024854638805000,"@FPyLPython Here this basically means deep neural networks that need a relatively large time to learn. I.e., if you think of a Loss vs. epoch plot, Hyperband etc eliminate the worst runs, which can be bad if the learning hasn't picked up speed in the early epochs. https://t.co/cuXFjBZu3X"
6608,@rasbt,2021-12-23 00:09:00+00:00,https://twitter.com/rasbt/status/1473807817324834822,"@denzil_correa @vovahimself I tried it many times in recent years, but I found the screen is a bit too small, and I don't like writing on glass. I like that it gives you the flexibility with colors and erasing (over conventional pen &amp; paper)"
6609,@rasbt,2021-12-22 22:12:32+00:00,https://twitter.com/rasbt/status/1473778509550166018,"@iamtrask *supersidenote: nice attention to detail when they say ""fewer parameters"" not ""less parameters"" in the title"
6610,@rasbt,2021-12-22 20:40:11+00:00,https://twitter.com/rasbt/status/1473755269075283974,"In practice, couldn't quite figure out the Python API (I think it is more geared towards the CLI). Problems (1) no idea where the experiments are stored / how to clear the cache; (2) plotly plots don't show up in the Nb (3) how to display the best setting? https://t.co/xNQ5XJmJPt"
6611,@rasbt,2021-12-22 20:40:11+00:00,https://twitter.com/rasbt/status/1473755268051881984,"I like Orion as a tool, too. In particular, the fact that it supports so many algos and that it has experiment tracking/version control that allows you to expand or adjust the hyperparameter grid without rerunning previous experiments."
6612,@rasbt,2021-12-22 20:34:20+00:00,https://twitter.com/rasbt/status/1473753796517978122,"One thing to check off before the year ends: caught up with all talks from the SciPy 2021 ML track. Just watched a nice tutorial on Orion for hyperparam tuning here (https://t.co/09uiTxhuRw). In particular, I liked the practical recommendations on choosing a tuning strategy/algo: https://t.co/03HgbYiy1I"
6613,@rasbt,2021-12-22 19:52:13+00:00,https://twitter.com/rasbt/status/1473743195020406794,"@karpathy Regarding colors, there was a good example in the article linked here: https://t.co/omlTUvm7YA https://t.co/B5h9D474zU"
6614,@rasbt,2021-12-22 19:16:32+00:00,https://twitter.com/rasbt/status/1473734218459099147,"@mhajabri Mostly the Apple Ecosystem. Plus, back then (2017ish) I liked that I could have the Apple Keynote presentation on the macbook (hooked up to a projector; also for screen recording) and use the iPad as a remote input device. There are maybe better ways now with PowerPoint. Dunno"
6615,@rasbt,2021-12-22 19:05:16+00:00,https://twitter.com/rasbt/status/1473731382744698881,"@vovahimself Haha this is hilarious, and i actually like it"
6616,@rasbt,2021-12-22 18:54:25+00:00,https://twitter.com/rasbt/status/1473728650478592017,"@vovahimself Haha, I can't do typewriters. I make too many mistakes and like the delete button to clean things up as I write."
6617,@rasbt,2021-12-22 18:45:16+00:00,https://twitter.com/rasbt/status/1473726345876230146,"@vovahimself Whoa. I actually tried that back then for blogging. I like that it helps with focus, but then the ergonomics etc. are a bit suboptimal. I think for me the ideal setup would be just an old, second computer that isn't connected to the internet."
6618,@rasbt,2021-12-22 18:43:01+00:00,https://twitter.com/rasbt/status/1473725781100670982,"@DemandHacker For me, scikit-learn mostly gets the job done. Even the new gradient boosting implementation (HistGradientBoostingClassifier) is very competitive compared to LightGBM etc."
6619,@rasbt,2021-12-22 18:40:48+00:00,https://twitter.com/rasbt/status/1473725222989746185,"@vovahimself Yes, for sure. But then, most workflows really require multiple windows in my case. The only case I can see is maybe certain writing tasks, or image editing tasks, but then I think it wouldn't be great from an ergonomics perspective"
6620,@rasbt,2021-12-22 18:38:08+00:00,https://twitter.com/rasbt/status/1473724554283565067,"@vovahimself Sometimes, I read a paper via LiquidText or make a sketch in Notes, but that's very rare. iPads usually don't work for my workflows since I find switching between apps (and storage management) very frustrating and limiting."
6621,@rasbt,2021-12-22 18:36:50+00:00,https://twitter.com/rasbt/status/1473724226037297153,"@vovahimself I used the tablet mostly for only two things: (1) annotating slides in Keynote in in-person lectures and for my video recordings and (2) reading ebooks in dark mode before going to bed. For other things, I prefer macOS/a computer."
6622,@rasbt,2021-12-22 18:33:51+00:00,https://twitter.com/rasbt/status/1473723476481650696,"After 3 years, my trusty iPad pen stopped working, which made for a good incentive to give pen tablets a try. So, far, I am really liking that setup (can look straight at my larger monitor when annotating slides). But the learning curve is steep, indeed üòÖ https://t.co/CGHlnMsxe8"
6623,@rasbt,2021-12-22 14:55:05+00:00,https://twitter.com/rasbt/status/1473668419060916225,"@chrisoffner3d @karpathy Interesting, didn't know the catalog was so limited. Yeah, maybe it's the settings that people have on their TVs. Would explain why watching movies at home on my monitor looks so much better (to me) than on s.o.'s TV. TV settings these days are so weird."
6624,@rasbt,2021-12-22 13:47:38+00:00,https://twitter.com/rasbt/status/1473651446835027971,"@karpathy Yeah, I don't know how/why people like high frame rates in movies. Makes it look fake. Same with motion smoothing that my family &amp; friends seem to like. Don't have a TV &amp; am most happy watching stuff on my computer monitor because it has a high res but none of the other fluff"
6625,@rasbt,2021-12-22 13:41:23+00:00,https://twitter.com/rasbt/status/1473649874910552070,"@karpathy Arg, but thanks. Saves me some time, money, and disappointment then. Going to wind down by reading good book over the holidays instead"
6626,@rasbt,2021-12-21 21:13:59+00:00,https://twitter.com/rasbt/status/1473401386633150468,@hels The First Law books by Joe Abercrombie were pretty good
6627,@rasbt,2021-12-21 20:13:13+00:00,https://twitter.com/rasbt/status/1473386094595125260,"@RayBell_DTN @lak_gcp Thanks, and I hope you like it :)! Also wishing you nice Christmas holidays ‚Äî sounds like they are definitely not going to be boring"
6628,@rasbt,2021-12-21 14:17:17+00:00,https://twitter.com/rasbt/status/1473296520955011075,"@togelius Wouldn't you say it depends? If the preprint is closely related, was uploaded well ahead of your submission deadline, &amp; there are no obvious flaws, then sure. But there is a reason why arxiv papers ""do not exist"" for CVPR &amp; ICCV during review, for example."
6629,@rasbt,2021-12-21 13:40:35+00:00,https://twitter.com/rasbt/status/1473287284279676931,"@aertherks @DavidPraiseKalu @PyTorch Yes. It is somewhat similar to NumPy and using a row-major (np.array([...], order='C') or column-major (np.array([...], order='F') format there."
6630,@rasbt,2021-12-21 02:16:41+00:00,https://twitter.com/rasbt/status/1473115173825228803,"@zacharylipton I actually love helping people with putting up their Ikea stuff. It's very therapeutic, and it is maybe related to my obsession with Lego as a kid"
6631,@rasbt,2021-12-20 21:26:58+00:00,https://twitter.com/rasbt/status/1473042264092037127,"@fchollet ‚ÄúSome remembered that joysticks, without computer chips, were used to control these features until electronics became affordable and commonplace.
‚ÄòLet‚Äôs go back to the old design,‚Äô said Rick Rodier, a Toro executive. ‚ÄúIt still does the job.‚Äù https://t.co/kRYy38j2es"
6632,@rasbt,2021-12-20 20:11:01+00:00,https://twitter.com/rasbt/status/1473023153676955653,"Interesting way of looking at PCA as a ""featureless"" least-squares model. Here, the black parts are given and the red ones are computed"
6633,@rasbt,2021-12-20 15:44:59+00:00,https://twitter.com/rasbt/status/1472956204112621569,"@DavidPraiseKalu @PyTorch Arg sorry about the variable name above. I tried to rename it to make it more readable but forgot that one line. In any case, the output is correct because memory format doesn't affect the tensor shape in PyTorch: https://t.co/n89bqqE9L7"
6634,@rasbt,2021-12-20 15:42:54+00:00,https://twitter.com/rasbt/status/1472955679250001926,"@docmilanfar Existing experiences might be super valuable for the team, but I can see how trying to be two things at once is suboptimal. Personally, I find the feeling of being split/spread too thin across diff responsibilities and projects unfulfilling &amp; prefer focusing on a few things well."
6635,@rasbt,2021-12-20 15:40:53+00:00,https://twitter.com/rasbt/status/1472955172037013504,"@docmilanfar Very insightful thread. Thanks so much for sharing. I can see the switch also as a means to spark creativity and escape routines. There are other perks of course, but it can also be just about trying something new."
6636,@rasbt,2021-12-20 15:17:10+00:00,https://twitter.com/rasbt/status/1472949200774180871,"@DavidPraiseKalu @PyTorch Yeah, I think this is true for training on most GPUs. Just trying on optimized code, NHWC seems to win. https://t.co/Uxh41WM4Kx"
6637,@rasbt,2021-12-20 15:15:06+00:00,https://twitter.com/rasbt/status/1472948680332353542,"Note that this is about the memory format, which isn't coupled to the input shape. E.g., we have NCHW as input shape for Conv2d, yet you can still have NHWC as memory format: https://t.co/tR3ucoyjO0"
6638,@rasbt,2021-12-20 14:21:25+00:00,https://twitter.com/rasbt/status/1472935172924399617,"@jbhuang0604 I think the boilerplate question could be more like ""I am really sorry, I zoned out / wasn't able to prepare, could you give me a ELI5 summary again?"" before asking any further questions"
6639,@rasbt,2021-12-20 14:14:50+00:00,https://twitter.com/rasbt/status/1472933514513375238,"@mrigankanath_ I am not sure if the publisher offers that, but I can ask!"
6640,@rasbt,2021-12-20 02:25:26+00:00,https://twitter.com/rasbt/status/1472754991089819659,@AllenDowney Congrats! This is really exciting. I have so many students asking me how to prepare for job &amp; internship interviews. I believe this could be a super valuable resource to them!
6641,@rasbt,2021-12-20 02:23:06+00:00,https://twitter.com/rasbt/status/1472754401123127303,"Allen is a great educator, and I love his practical takes on complicated topics that usually only get a very dry, theoretical treatment. So, I am really excited about this one :)"
6642,@rasbt,2021-12-20 02:23:05+00:00,https://twitter.com/rasbt/status/1472754399617368070,Excited to learn that @AllenDowney just released a Python companion for his Think Data Structures book. It probably goes without saying that data structures is a fundamental topic for computer science and also machine learning -- because you probably want to implement things!
6643,@rasbt,2021-12-20 01:49:00+00:00,https://twitter.com/rasbt/status/1472745821821153282,"@willblanzeisky Yes, that's right. But the the Amazon page(s) should be up shortly. Will tweet about it once I know more!"
6644,@rasbt,2021-12-20 01:48:28+00:00,https://twitter.com/rasbt/status/1472745687393710083,"@hiydavid @Julio_A_Soto I have been doing all my research and teaching in PyTorch over the last 2-3 years and prefer it personally. Also, given the PyTorch is used for the majority of DL papers (with code), I thought it'd be useful to teach people who want to get into the field how to use PyTorch"
6645,@rasbt,2021-12-20 01:45:51+00:00,https://twitter.com/rasbt/status/1472745025557696518,@willblanzeisky I don't think it is up on Amazon in general yet. But that will change next week üôÇ
6646,@rasbt,2021-12-20 00:09:14+00:00,https://twitter.com/rasbt/status/1472720712368541701,"@Julio_A_Soto Thanks! Yes, it's essentially a new edition, but there are so many changes and additions that we changed the title. I.e., in particular the second half of the book is now based on PyTorch rather than TensorFlow, and there are new chapters on transformers and graph neural nets."
6647,@rasbt,2021-12-19 22:55:39+00:00,https://twitter.com/rasbt/status/1472702196911378435,"@nycfksh I see what you are saying. Basically more like a structure where there is a chapter per algorithm. This book was originally more of a practitioner‚Äôs guide. But yeah, I thought about writing a different book that is more structured like that, but it would be a very different book"
6648,@rasbt,2021-12-19 21:43:13+00:00,https://twitter.com/rasbt/status/1472683966582951941,"@TheZachMueller Oh yeah, reminds me of the old days of Twitter. Rarely see someone @ ing someone in the beginning of the tweet anymore. I presume because we can now have threads and since it goes to your timeline nowadays anyways (even though in a narrower scope) if I am not mistaken."
6649,@rasbt,2021-12-19 20:39:55+00:00,https://twitter.com/rasbt/status/1472668037794963462,"@nycfksh Could have expanded Ch 13 into several subchapters, but then we actually already reached the max page limit of how big the book can be (otherwise, a print copy would not be possible anymore) :P"
6650,@rasbt,2021-12-19 20:38:46+00:00,https://twitter.com/rasbt/status/1472667746274095110,"@nycfksh But yeah, I was thinking a lot about this in recent years, and there are pros and cons either way. For the ML class, it might be weird to put so many algos into Ch13. But in real life, I'd say that with exception of random forests (&amp; maybe logreg) most of them are less important"
6651,@rasbt,2021-12-19 20:37:04+00:00,https://twitter.com/rasbt/status/1472667320740888578,"@nycfksh I tried a different organization for teaching in the last few years, and it works well (left). For the book, I do think though that the current structure (right) works better. https://t.co/2xXiidgoHS"
6652,@rasbt,2021-12-19 20:31:36+00:00,https://twitter.com/rasbt/status/1472665943767760904,"@nycfksh Re organization, it's probably Ch03 that covers several ML algos that could/should be organized differently?"
6653,@rasbt,2021-12-19 20:28:46+00:00,https://twitter.com/rasbt/status/1472665232942194695,@marktenenholtz @omarsar0 Thanks for the kind words!
6654,@rasbt,2021-12-19 20:00:38+00:00,https://twitter.com/rasbt/status/1472658152856465408,"Just checking the prefinals ... and I am happy to share that we'll finally have syntax coloring this time around :). Overall, I am really liking the cleaner layout and design. https://t.co/T9zDrF9NhC"
6655,@rasbt,2021-12-19 17:16:19+00:00,https://twitter.com/rasbt/status/1472616797870432268,@krismicinski @TaliaRinger @andrewthesmart @story645 unless they are people who didn't write recommendation letters for their students but were able to write dozens of pages for their own award.
6656,@rasbt,2021-12-19 17:09:26+00:00,https://twitter.com/rasbt/status/1472615066457542656,"@TaliaRinger @andrewthesmart @story645 yes, this. it would make me extremely uncomfortable asking for this. it would probably outweigh the positive feeling of getting an award"
6657,@rasbt,2021-12-19 16:53:14+00:00,https://twitter.com/rasbt/status/1472610989652721672,"@roydanroy like i mentioned, i haven't really used VR headsets personally (only tried it once) but my partner does. I think it's a love-hate type of thing"
6658,@rasbt,2021-12-19 16:23:34+00:00,https://twitter.com/rasbt/status/1472603523355398145,"@roydanroy About the faces, I think there is currently no good way around avatars though due to physical (and computational?) limitations. I.e., since you are wearing a headset that is covering half of your face, it'd be hard to capture that real time"
6659,@rasbt,2021-12-19 16:22:05+00:00,https://twitter.com/rasbt/status/1472603150012096514,"@roydanroy Yeah, you can. I don't have experience with it personally, but they use VR headsets at my partner's company. There is Horizon Workrooms for Oculus Quest 2 for example. I think it's free and gives you space for presenting, sketching etc.  (Not sure about grand canyons though)"
6660,@rasbt,2021-12-19 15:52:43+00:00,https://twitter.com/rasbt/status/1472595762055942144,"@TaliaRinger I got a outstanding graduate student award once, and I deeply appreciated it. It was actually a huge surprise and a huge motivation! I feel like there need to be more awards for students, because I think it can have a very positive effect. Also monetary support can be important"
6661,@rasbt,2021-12-19 15:47:55+00:00,https://twitter.com/rasbt/status/1472594552997482497,"@TaliaRinger Oh wait, so there are two different kinds, one where you apply and one where you get nominated?"
6662,@rasbt,2021-12-19 15:46:12+00:00,https://twitter.com/rasbt/status/1472594120183062530,"@agrover112 EfficientNetv2 uses swish, I think. And HaloNet uses attention blocks"
6663,@rasbt,2021-12-19 15:41:36+00:00,https://twitter.com/rasbt/status/1472592962106408960,"@TaliaRinger The fact that one needed to apply (or maybe it was just this particular one) appeared weird to me. Sounded more like a grant application. But that being said, if someone ever wants to give me an award with no strings attached, I would gladly accept ü§ó"
6664,@rasbt,2021-12-19 15:36:55+00:00,https://twitter.com/rasbt/status/1472591784077369350,"@TaliaRinger Must admit that I never figured out how academic awards work: you get tenure because of them, or you get them because of tenure? Not even being sarcastic, I literally never looked into it or applied for one üòì"
6665,@rasbt,2021-12-19 14:39:36+00:00,https://twitter.com/rasbt/status/1472577361262661632,@innerproduct Thanks for sharing your honest opinion!
6666,@rasbt,2021-12-19 14:38:48+00:00,https://twitter.com/rasbt/status/1472577158296088580,@delai50 of course :)
6667,@rasbt,2021-12-19 14:38:08+00:00,https://twitter.com/rasbt/status/1472576989127188487,"@WillingCarol @seanmylaw @stumpy_dev Yes, this sounds like a good way to handle it!"
6668,@rasbt,2021-12-19 03:11:43+00:00,https://twitter.com/rasbt/status/1472404249204117505,"@alfcnz @leonpalafox True, there is definitely a synergistic effect. And the other way, batchnorm and skip connections also help with exploding gradients in a way. Like preventing that they occur in the first place, and if they do mess things up, skipping over that useless part of the architecture"
6669,@rasbt,2021-12-19 02:58:41+00:00,https://twitter.com/rasbt/status/1472400968256049156,"@seanmylaw @stumpy_dev May look like a minor thing, but I would go with ""x += 1"". Looks more Pythonic and, I am assuming you use NumPy arrays, you get in-place operations."
6670,@rasbt,2021-12-18 22:58:27+00:00,https://twitter.com/rasbt/status/1472340514003464194,@timgill924 The fact that it had to read it twice before I recognized it as satire says a lot about the current state and expectations ü•≤
6671,@rasbt,2021-12-18 22:05:50+00:00,https://twitter.com/rasbt/status/1472327269280538624,@SeguraAndres7 PCA + naive Bayes. These were also the first I ever learned about and implemented from scratch. (That was back then when I took a statistical pattern recognition class. And it got me hooked and kindled my fascination for ML)
6672,@rasbt,2021-12-18 20:39:47+00:00,https://twitter.com/rasbt/status/1472305616282656775,"@3scorciav @_LXAI @jeremyphoward Oh yeah, totally. I am also more thinking along the lines of: how can I get more life out of my 4x 1080Ti cards :P. Or, instead of renting an expensive A100's what about 8x the amount of RTX2080Tis for the same per hour price."
6673,@rasbt,2021-12-18 19:54:26+00:00,https://twitter.com/rasbt/status/1472294203438870529,"@3scorciav @_LXAI Recent research and modern tools make multi-GPU and multi-device more efficient and easier. Also, there are tons of old GPUs that are considered too slow as standalone cards. They could be repurposed under multi-GPU/device setups."
6674,@rasbt,2021-12-18 19:53:03+00:00,https://twitter.com/rasbt/status/1472293854296616966,"@3scorciav @_LXAI I think hardware access is the current bottleneck. Personally, we also used a 1 gpu / model paradigm in our latest research (https://t.co/dJ3jgtBbQv) and it was totally sufficient. At the same time, recognizing trends, I don't see why we shouldn't utilize multi-GPU /device setups"
6675,@rasbt,2021-12-18 19:51:25+00:00,https://twitter.com/rasbt/status/1472293443628109828,"@vandotorres It's currently still in a temporary, private repo shared with reviewers and editors. I will try to put up the official repo in the upcoming weeks."
6676,@rasbt,2021-12-18 19:50:25+00:00,https://twitter.com/rasbt/status/1472293193857355783,"@vandotorres Thanks! Yeah, there've been several updates. Top off my head, there were only minor updates due to deprecations. I added lots of new things though, e.g., sections on gradient boosting, successive halving, t-SNE, etc."
6677,@rasbt,2021-12-18 17:24:16+00:00,https://twitter.com/rasbt/status/1472256412743000071,"I would also say that the days of BatchNorm are counted, at least when it comes to trends re transformers and scaling training to multi-GPU and multi-device setups"
6678,@rasbt,2021-12-18 17:22:37+00:00,https://twitter.com/rasbt/status/1472255997448278018,"""EfficientNetV2: Smaller Models and Faster Training"" https://t.co/k1DsW8v1kM"
6679,@rasbt,2021-12-18 17:22:37+00:00,https://twitter.com/rasbt/status/1472255995695013891,"For reference, HaloNet: ""Scaling Local Self-Attention for Parameter Efficient Visual Backbones"" https://t.co/UHnH2Dcpqp"
6680,@rasbt,2021-12-18 17:18:36+00:00,https://twitter.com/rasbt/status/1472254985283026955,"Interesting question. Top off my head, state-of-the-art architectures (for computer vision) like HaloNet and EfficientNetv2 both use dropout, batchnorm and skip connections, but  neither uses ReLU. Yet, I would probably vote for ReLU :)"
6681,@rasbt,2021-12-18 14:37:46+00:00,https://twitter.com/rasbt/status/1472214511365103617,"@muktabh @thegautamkamath Thanks for sharing. Yeah, I can see how semi-supervised learning, self-supervised learning, and weakly supervised learning can complement data-centric AI efforts."
6682,@rasbt,2021-12-17 22:02:05+00:00,https://twitter.com/rasbt/status/1471963937616896000,"@thegautamkamath More NLP-centric, but the DataCLUE paper outlines some of the broad categories of approaches here: https://t.co/9h5uDeuVIA"
6683,@rasbt,2021-12-17 21:54:26+00:00,https://twitter.com/rasbt/status/1471962015262552064,"@thegautamkamath Not necessarily ""traditional"" data-centric AI, but this one is also tangentially relevant https://t.co/3SybU3vaHG"
6684,@rasbt,2021-12-17 21:51:55+00:00,https://twitter.com/rasbt/status/1471961381033418754,"@thegautamkamath The thing is that this is probably mostly done in industry applications, so I'd say the majority may not be available as papers. That being said, I remember these two write-ups from the recent data centric AI competition: https://t.co/6MHaqaCaZ0 &amp; https://t.co/Mfkqk91XLY"
6685,@rasbt,2021-12-17 18:42:32+00:00,https://twitter.com/rasbt/status/1471913719705780228,"@NoorJihad2 Yeah. Having both frameworks in the book would have been a bit weird. (Also, there was literally no space left as we scratched the total max page limit.)"
6686,@rasbt,2021-12-17 16:22:02+00:00,https://twitter.com/rasbt/status/1471878363191128064,"Last week, I shared an ""implementing a CART decision tree from scratch"" exercise for those who wanted to add a bit of an ML flavor to their advent of code. Now, here are the solutions: https://t.co/TodqPbwS85"
6687,@rasbt,2021-12-17 16:18:35+00:00,https://twitter.com/rasbt/status/1471877492663279621,"@TimKietzmann haha, used to drive me nuts when people pronounce it ""beyond tech"""
6688,@rasbt,2021-12-17 15:02:15+00:00,https://twitter.com/rasbt/status/1471858285020123142,"@TheZachMueller Same. I originally switched to it because of tab management (i.e., tabs within, so it doesn't clutter my browser) but learned to like &amp; prefer it over the years. Btw. Colab is great for a different use case though: collaborations. I.e., leaving comments in the notebook."
6689,@rasbt,2021-12-17 14:49:30+00:00,https://twitter.com/rasbt/status/1471855076356640769,@abhi1thakur Earlier this year! I help with that in almost every collaboration if I can üòÖ. It‚Äôs actually a great way to learn about &amp; explore parts of the data and to understand its limitations better.
6690,@rasbt,2021-12-17 00:06:02+00:00,https://twitter.com/rasbt/status/1471632745965174801,@alfcnz @haltakov @ykilcher https://t.co/EuRztsUVA0
6691,@rasbt,2021-12-17 00:04:47+00:00,https://twitter.com/rasbt/status/1471632430742355978,"@alfcnz @haltakov @ykilcher That being said, I definitely want to try to record something in German one day. People say I sound quite different when I speak German, and apparently I talk super fast."
6692,@rasbt,2021-12-17 00:03:41+00:00,https://twitter.com/rasbt/status/1471632150999015424,"@alfcnz @haltakov It's like when @ykilcher had the German version of his ML news video one time. It's kind of cool but there's also something about it that is either uncanny or just doesn't feel quite right, haha."
6693,@rasbt,2021-12-17 00:00:42+00:00,https://twitter.com/rasbt/status/1471631401502093312,"@alfcnz @haltakov Maybe it's because I learned ML outside Germany, but I find that reading German ML texts is a bit awkward as the translations sound a bit uncanny. And a decent chunk of technical terms is not translated, which makes for an awkward mix."
6694,@rasbt,2021-12-16 23:59:18+00:00,https://twitter.com/rasbt/status/1471631047968399360,"@alfcnz @haltakov Maybe I am wrong, but I think if the primary language of the source material is German most would prefer the German version. But if there's a German translation, most people would probably just watch/read the English original."
6695,@rasbt,2021-12-16 23:26:47+00:00,https://twitter.com/rasbt/status/1471622866064007173,"@ssshukla26 Oh, not sure. On a side note: you can report the change of address at USPS after moving, and they usually reroute everything for 1 year. But to be on the safe side, I would maybe not pre-order and wait until after the move."
6696,@rasbt,2021-12-16 22:56:43+00:00,https://twitter.com/rasbt/status/1471615300537835526,"@ssshukla26 Wohoo, congrats on the job offer! I hope it's the offer you wanted and are going to accept :)"
6697,@rasbt,2021-12-16 22:22:11+00:00,https://twitter.com/rasbt/status/1471606608308412425,"@TaliaRinger * but worry no more, my C skills atrophied a lot and I don't know when I used R the last time (ok, maybe for teaching a stats class last year). Python to the moonüöÄ"
6698,@rasbt,2021-12-16 22:19:24+00:00,https://twitter.com/rasbt/status/1471605909084377091,@TaliaRinger Guilty of producing such Frankensteins üôÉ. Especially during the first few years in grad school. Also throw in R scripts for plotting.
6699,@rasbt,2021-12-16 21:10:50+00:00,https://twitter.com/rasbt/status/1471588655626166278,"@abhishek27297 @TaliaRinger Also, a cool tool I learned about recently: https://t.co/qKbzP9x5mJ"
6700,@rasbt,2021-12-16 19:50:25+00:00,https://twitter.com/rasbt/status/1471568417081765892,"@TaliaRinger Whoa! As a non-native speaker, I will remember this as the new textbook definition of a silver lining"
6701,@rasbt,2021-12-16 19:48:10+00:00,https://twitter.com/rasbt/status/1471567851098152966,@TaliaRinger This was a ~200 Gb dataset with many subfolders. I didn't make tarballs for some of the image folders and just uploaded it via web browser. The upload took overnight and I must have been interrupted so that a number of images went missing. So yeah +1 for file size &amp; counts checks
6702,@rasbt,2021-12-16 19:45:09+00:00,https://twitter.com/rasbt/status/1471567089819344909,"@TaliaRinger Oh yeah, makes total sense. I was too focused on the data contents rather than what can go wrong during the technical processing/loading/extracting. Good point though, I actually just had something like that with my collaborators today -- I uploaded an incomplete image folderüò¨"
6703,@rasbt,2021-12-16 19:30:30+00:00,https://twitter.com/rasbt/status/1471563403990814737,"@TaliaRinger Unless it is text or image data, I usually also plot histograms or scatterplots to visually check data for weird patterns, extreme values, or outliers. Made Python function for that: https://t.co/GxePol85e0 https://t.co/Wx1TL7GMoJ"
6704,@rasbt,2021-12-16 19:28:33+00:00,https://twitter.com/rasbt/status/1471562912955346949,"@TaliaRinger Some general ones that are not specific to a given dataset: Missing data checks. Pulling out unique labels, looking at the label distribution. Also, for each categorical variable, checking unique values prior to encoding."
6705,@rasbt,2021-12-16 17:35:20+00:00,https://twitter.com/rasbt/status/1471534421228634122,@nmvrodrigues Thanks! I think it should become available in the EU ones as well
6706,@rasbt,2021-12-16 15:50:52+00:00,https://twitter.com/rasbt/status/1471508132727713802,"@paintingpeter Thanks so much for the support and the kind, motivating words, Peter!"
6707,@rasbt,2021-12-16 15:12:22+00:00,https://twitter.com/rasbt/status/1471498444330004496,"@vovahimself Right now, it's the best we have, so I am pretty sure that it will stay. (Unless, of course, someone comes up with something different that gives better results üòâ)"
6708,@rasbt,2021-12-16 14:44:39+00:00,https://twitter.com/rasbt/status/1471491467747086343,*I was told the Amazon page should also be up by this weekend.
6709,@rasbt,2021-12-16 14:43:35+00:00,https://twitter.com/rasbt/status/1471491200020586505,"@vovahimself Yes, it was a lot of work and took us a large chunk of time this summer. But I am pretty glad how it turned out!  It will be loosely based on the lecture I taught on transformers (https://t.co/JhY0KBGs1D), but it will be more organized and have much nicer figure"
6710,@rasbt,2021-12-16 14:40:40+00:00,https://twitter.com/rasbt/status/1471490466021613568,"@BEBischof Unfortunately, I don't have anything pre-made at this point. But I will share all figures &amp; code notebooks on GitHub to make it easier to adopt them from making slides!"
6711,@rasbt,2021-12-16 14:35:26+00:00,https://twitter.com/rasbt/status/1471489148762525714,"Many new contents, like graph neural nets, transformers, gradient boosting, and yes, everything is now in PyTorch :). If you are interested in more details, I chatted about it with @bhutanisanyam1 last weekend :) https://t.co/nrLlKcmVL1"
6712,@rasbt,2021-12-15 23:36:14+00:00,https://twitter.com/rasbt/status/1471262855739678730,"@TaliaRinger I can see though how it could be useful towards developing neural nets that have certain properties. It would still require coming up with a bunch of novel ideas, but once we have those, we could apply proof assistants to filter for those that have verifiable properties."
6713,@rasbt,2021-12-15 23:33:33+00:00,https://twitter.com/rasbt/status/1471262181266239490,"@TaliaRinger 2/2 There's lots of interest in adversarial robustness, but we know NNs are prone to adversarial attacks, so what are the sorts of proofs we are interested in and are looking for?"
6714,@rasbt,2021-12-15 23:32:44+00:00,https://twitter.com/rasbt/status/1471261977234313221,"@TaliaRinger Another challenge is to formulate a theorem or property of neural nets someone wants to proof. Let's assume proof assistants guarantee that we find a proof for sth, what would people be interested in finding proofs for related to neural nets? 1/2"
6715,@rasbt,2021-12-15 22:53:22+00:00,https://twitter.com/rasbt/status/1471252070921654272,"@mervenoyann Hah yeah! I know there are a thousand apps for that, but I repurposed my G shock for this and love it. https://t.co/nzhVdX11aC"
6716,@rasbt,2021-12-15 20:07:02+00:00,https://twitter.com/rasbt/status/1471210210656149509,@xamat @michaelaye Yes exactly. It‚Äôs not just a simple look-up. There is a lot of learning that goes into this compared to kNN
6717,@rasbt,2021-12-15 19:23:37+00:00,https://twitter.com/rasbt/status/1471199281973538823,"@xamat @michaelaye I.e., for AI models, it is not obvious to see that there was an effort involved in this memorization, that it is not simply accessing something from the storage device."
6718,@rasbt,2021-12-15 19:22:33+00:00,https://twitter.com/rasbt/status/1471199016981467138,"@xamat @michaelaye For AI models, it is not so obvious to see this difference. I.e., an AI model memorizing something appears more like opening a file on a computer (which a computer can already do w/o AI) -- the analogy to a human opening a book instead of memorizing it via the brain"
6719,@rasbt,2021-12-15 19:21:06+00:00,https://twitter.com/rasbt/status/1471198649275359235,"@xamat @michaelaye I see what you are saying. What I wanted to say is that human memorization is not a look-up per se. A look-up is to me opening a book/webpage and reading from it. Instead, human memorization is a process of converting sth into a different (electrical/chemical) representation."
6720,@rasbt,2021-12-15 19:18:26+00:00,https://twitter.com/rasbt/status/1471197980019548161,"@_brohrer_ Of course, this doesn't work, so you have to email them about it. The letter they will then send you takes like 10 business days, and you have to do it each time you get a new phone, because the app doesn't work if you restore the phone from a backup like any other app."
6721,@rasbt,2021-12-15 19:16:05+00:00,https://twitter.com/rasbt/status/1471197388937338889,"@_brohrer_ Oh, and any software related to German banks (or maybe just DKB). It's so bad that it's not even funny. Like if you want to set up the mandatory TAN app, you have to use the TAN app to be able log in and let them send you a temporary code to your physical address."
6722,@rasbt,2021-12-15 19:11:31+00:00,https://twitter.com/rasbt/status/1471196237768675333,"@_brohrer_ (probably not used at companies) but the jankiest pieces of tech I've seen are these MS Word plugins that come with reference/paper managing software (Mendeley, Endnote, Zotero, you name it)"
6723,@rasbt,2021-12-15 15:29:56+00:00,https://twitter.com/rasbt/status/1471140477298778112,"@michaelaye @xamat Sure, that would probably make it even closer to what we call learning. But we can also call it learning w/o forgetting techniques. I think the key here is that is is not simply a look up. E.g., KNN to me is not learning, it is more like someone copying a sentence from Wikipedia"
6724,@rasbt,2021-12-15 13:55:25+00:00,https://twitter.com/rasbt/status/1471116691304329221,"@CSProfKGD Hah, I only wish I had a separate desk and room for recording before trying more things. My desk is getting so messy üòÖ. And that cable situation üò±"
6725,@rasbt,2021-12-15 13:51:45+00:00,https://twitter.com/rasbt/status/1471115766598676488,@CSProfKGD *Nvm. It just learned it‚Äôs a stream deck. Interesting; will go down this rabbit hole later :)
6726,@rasbt,2021-12-15 13:39:50+00:00,https://twitter.com/rasbt/status/1471112766870237186,@xamat Maybe it‚Äôs because it is easy to forget that there is a learning process taking place. Like an AI that memorizes things perfectly may seem more like a 1-nearest neighbor classifier that is not really learning anything but just looking things up.
6727,@rasbt,2021-12-14 20:05:01+00:00,https://twitter.com/rasbt/status/1470847315216904201,"@daniela_witten ""The Matrix Still Has You"" -- spot on Twitter üëå https://t.co/AJXce5CA18"
6728,@rasbt,2021-12-14 15:52:40+00:00,https://twitter.com/rasbt/status/1470783808584749071,"@CSProfKGD Funny enough, back in 2019, I looked for a cooperative board game to play with my partner and this got great reviews, so I got it for her for Xmas. This was Xmas 2019, and we didn‚Äôt play it once."
6729,@rasbt,2021-12-14 15:33:44+00:00,https://twitter.com/rasbt/status/1470779043037515780,"@_brohrer_ Makes me think of the time as a student where I was thinking really hard about choosing Bitbucket (free private repos but limited collaborators) and GitHub (unlimited team members but limited private repos). Oh, there was also a self-hosted GitLab server at MSU that was an option"
6730,@rasbt,2021-12-14 15:15:12+00:00,https://twitter.com/rasbt/status/1470774378250002444,"@Austen Huh, must say I was skeptical of this tweet but the math actually checks out. The federal government spent $6.6 trillion in fiscal year 2020. So, let's assume they spend 18 billion per day. Elon Musk's net worth is $292 billion. 292 billion / 18 billion per day = 16 days."
6731,@rasbt,2021-12-14 15:10:14+00:00,https://twitter.com/rasbt/status/1470773131224694795,@ducha_aiki Best of luck!ü§û
6732,@rasbt,2021-12-13 23:57:02+00:00,https://twitter.com/rasbt/status/1470543315254788101,"@alfcnz Wow that's so cool! Now, I hope you get to enjoy the well-deserved winter break!

PS: Hah, I got this as a little gift (I think / I am hoping it means success &amp; luck ü§ó) https://t.co/v5eqbYnTQv"
6733,@rasbt,2021-12-13 19:11:59+00:00,https://twitter.com/rasbt/status/1470471579410784256,@NVIDIADRIVE @AnimaAnandkumar Nice article! Tangential question: why do (some) self-driving cars use yokes? Does it help with reaction times when humans need to intervene? Is it easier to implement automatic steering since there's less movement? Is it because going for different looks? Or is it sth else?
6734,@rasbt,2021-12-13 19:06:23+00:00,https://twitter.com/rasbt/status/1470470173291425793,"@BritneyMuller @huggingface Wow, that's awesome! Big congrats! üéâü•≥"
6735,@rasbt,2021-12-13 18:18:46+00:00,https://twitter.com/rasbt/status/1470458188982067212,"@shortstein @thomasahle @roydanroy @arxiv Like I mentioned in other threads, I am not a fan of the double-blind process. I prefer open science, too. Right now, conferences prefer double-blind &amp; the anonymity requirements impose sharing restrictions. Temporarily anonymous arxiv papers submissions could help w open science"
6736,@rasbt,2021-12-13 16:57:51+00:00,https://twitter.com/rasbt/status/1470437826445590532,"@gordic_aleksa Beyond learned behaviors, also the parts on electrical and chemical signal transduction via neurons and synapses is super informative"
6737,@rasbt,2021-12-13 16:56:59+00:00,https://twitter.com/rasbt/status/1470437606840315910,@gordic_aleksa Yes! Was lucky that I took neuroscience when I studied bio as an undergrad and it was super informative. I can totally see that being relevant for AI work.
6738,@rasbt,2021-12-13 15:57:55+00:00,https://twitter.com/rasbt/status/1470422743661297667,"@shortstein @thomasahle @roydanroy @arxiv Don't require anonymity: fine. Require anonymity: ok, fine, too. But what I don't like is the current model where anonymity is req. (don't post your paper on social media) but then not all papers are anonymous coz one knows authors from arxiv submissions / paper recommendations"
6739,@rasbt,2021-12-13 15:55:00+00:00,https://twitter.com/rasbt/status/1470422007225405449,"@shortstein @thomasahle @roydanroy @arxiv Agreed. Prob didn't come across in this thread, but I am actually not in favor of anonymity &amp; think a single-blind process like at most journals is okay. In this thread here, I was just trying to make the argument that if you require it, same rules should apply to every submitter"
6740,@rasbt,2021-12-13 12:41:15+00:00,https://twitter.com/rasbt/status/1470373250924433409,"I highly recommend this. Contributing to an open source library is a great way to 
a) give back and 
b) hone your coding skills (since you'll get code reviews and feedback from top developers)"
6741,@rasbt,2021-12-13 12:36:33+00:00,https://twitter.com/rasbt/status/1470372065261899782,"@Thom_Wolf @thegautamkamath Hah, fair point. Or, plot twist, it's an employee anonymously venting that their lab doesn't try to innovate anymore :P"
6742,@rasbt,2021-12-13 12:35:12+00:00,https://twitter.com/rasbt/status/1470371725166714880,"@shortstein @thomasahle @roydanroy @arxiv This would then mean that people self-report that the paper is no longer anonymous to them + they would have to decline reviewing. If that happens, you will lose a lot of qualified reviewers. And again, I think having an anonymous arxiv submission option could help here"
6743,@rasbt,2021-12-13 12:32:46+00:00,https://twitter.com/rasbt/status/1470371113746276354,"@shortstein @thomasahle @roydanroy @arxiv Earlier, we said that we should assume all reviewers act in good faith and don't google paper titles. That's fair. But then we should also assume good faith when people stumble upon arxiv submissions or interesting papers on their mailing lists related to their area of expertise"
6744,@rasbt,2021-12-13 12:29:55+00:00,https://twitter.com/rasbt/status/1470370396264349701,"@shortstein @thomasahle @roydanroy @arxiv Whether it's necessary or not, I feel like if the premise is that paper submissions are anonymous, this should apply to everyone equally, and an temporarily-anonymous arxiv option would help with that"
6745,@rasbt,2021-12-13 12:26:18+00:00,https://twitter.com/rasbt/status/1470369487933345796,"@thegautamkamath Yes, absolutely. I think OP was probably referring to the lack of totally novel architecture paradigms. Where here, this may mean MLP, RNN, CNN, VAE, GAN, GNN,  Transformer etc. There's been a way longer gap after RNNs &amp; CNNs, and there is plenty of stuff happening all the time."
6746,@rasbt,2021-12-13 02:24:58+00:00,https://twitter.com/rasbt/status/1470218156580954118,@taiyasaki @hugo_larochelle Speaking of getting tired in the literal sense: and no need for late-nighters anymore. Yay!
6747,@rasbt,2021-12-13 01:51:54+00:00,https://twitter.com/rasbt/status/1470209833358041089,"@joelgrus @DynamicWebPaige @github @GoogleColab @rstudio Same. And recently miniforge. It's basically miniconda with conda-forge as default channel, which is super well maintained and usually has more up-to-date package versions."
6748,@rasbt,2021-12-13 01:47:02+00:00,https://twitter.com/rasbt/status/1470208609577537540,"@AllenDowney @DynamicWebPaige @github @GoogleColab @rstudio That's true. I'd do the same for workshops. For my class though, I spend a lecture on going through setting up their computers for Python ML (and help them with that during office hours). Maybe out of scope, but I am thinking it will be useful later in their career."
6749,@rasbt,2021-12-13 01:33:04+00:00,https://twitter.com/rasbt/status/1470205093945425920,Excited about what I got in the mail todayüëá! @BecomingDataSci has been such an inspiration for helping people get started in data science &amp; I'm really excited for her book! Thx so much! (Renee has also been the first person inviting me to a podcast back when I was a student!) https://t.co/U3fiMxeTnV
6750,@rasbt,2021-12-13 01:13:18+00:00,https://twitter.com/rasbt/status/1470200120461467649,"3/3 There's also lots of innovation in applying the flood of new architectures to real-world problems, like replacing the CNNs in AlphaFold-1 with transformers in AlphaFold-2 -- and of course there's way way more it than just plugging in GPT-3."
6751,@rasbt,2021-12-13 01:13:18+00:00,https://twitter.com/rasbt/status/1470200119110864900,"2/3 I don't see it as a bad thing &amp; it reminds me of the tick-tock model (https://t.co/djRqeUX0sU) for chip manufacturing: release a new microarchitecture, then shrink the process size. Right now, the focus might be on making things more powerful, and, in parallel, more efficient"
6752,@rasbt,2021-12-13 01:13:17+00:00,https://twitter.com/rasbt/status/1470200117835841539,"""Has the ML community outdone itself?"" (https://t.co/bjBzEgwW4w) referring to the lack of novelty after releasing GPT, CLIP, and DALI last year(s). 1/3"
6753,@rasbt,2021-12-12 23:11:35+00:00,https://twitter.com/rasbt/status/1470169491996909576,"@jhasomesh There is no submission deadline, so, it could help with distributing reviewing tasks more evenly over the year. But sure, the bottleneck is probably having qualified reviewers."
6754,@rasbt,2021-12-12 22:57:57+00:00,https://twitter.com/rasbt/status/1470166059017768960,@CSProfKGD @ankurhandos üëá (I may have several more at my parents' place üòÖ) https://t.co/zzkJNLjcfJ
6755,@rasbt,2021-12-12 22:23:09+00:00,https://twitter.com/rasbt/status/1470157303303319553,"@shortstein @roydanroy @arxiv Yeah, lots of things to think about. It could be a setting in partnership with conferences, similar to how OpenReview handles it. But yeah, that's easier said than done."
6756,@rasbt,2021-12-12 22:15:14+00:00,https://twitter.com/rasbt/status/1470155310723698704,"@shortstein @roydanroy @arxiv 2/2 some people don't submit to arxiv while the paper is still in peer-review. This could maybe encourage more people to share their work-in-progress, which might be good for the advancement of science in general."
6757,@rasbt,2021-12-12 22:13:57+00:00,https://twitter.com/rasbt/status/1470154985170251779,"@shortstein @roydanroy @arxiv That's a good question. Not sure if it is necessary. But I think if we had the option to submit papers to arxiv anonymously, it would at least give the option to experiment with full anonymity if a conference desires. Plus, 1/2"
6758,@rasbt,2021-12-12 22:08:28+00:00,https://twitter.com/rasbt/status/1470153606800232450,"@shortstein @roydanroy @arxiv Also, we don't necessarily need a one-size-fits-all solution. Anonymity requirements should be handled by the conference or journal. But if arxiv supported anonymous submissions, at least some conferences and journal could adopt a double-blind system if they choose to."
6759,@rasbt,2021-12-12 22:05:51+00:00,https://twitter.com/rasbt/status/1470152948424523777,"@shortstein @roydanroy @arxiv I am also not a fan of social media bans at all. Right now, everything is half-baked though. Some papers are anonymous, others are not. Imho, it should be fully anonymous or not anonymous but not ""sometimes anonymous""."
6760,@rasbt,2021-12-12 22:03:36+00:00,https://twitter.com/rasbt/status/1470152379609890826,"@shortstein @roydanroy @arxiv Yes, that's what I am saying. It's not always intentional that people go out and look for papers. For popular topics, it's impossible to avoid arxiv papers if you have recommendations turned on in e.g., Google Scholar or follow social media."
6761,@rasbt,2021-12-12 22:02:12+00:00,https://twitter.com/rasbt/status/1470152029117026313,@shortstein @roydanroy @arxiv That makes sense. But you can also say that the author names don't need to be known during peer review.
6762,@rasbt,2021-12-12 21:59:09+00:00,https://twitter.com/rasbt/status/1470151260049399821,"@shortstein @roydanroy @arxiv I'd say for the same reasons there is the social media ban. For fairness, so that authors don't from non-prestigious labs or institutions don't get disadvantages and vice versa"
6763,@rasbt,2021-12-12 21:56:49+00:00,https://twitter.com/rasbt/status/1470150673798942721,"@shortstein @roydanroy @arxiv I mean, imagine there was a list of who is reviewing which paper, but authors are told: ""okay this list may exist, but please don't look"". How many authors would honestly not look?"
6764,@rasbt,2021-12-12 21:54:43+00:00,https://twitter.com/rasbt/status/1470150147661307907,"@shortstein @roydanroy @arxiv Yeah, but that's the problem @roydanroy proposed to solve via anonymous arxiv? I.e., making a better effort of making it foolproof during the review stage. Right now we have this weird workaround ""pls! don't look for papers on arxiv during review"" because of platform limitations."
6765,@rasbt,2021-12-12 21:45:55+00:00,https://twitter.com/rasbt/status/1470147929516257289,"@shortstein @roydanroy @arxiv How's that anonymous, because you can simply search for the submission number or title and recover the abstract page?"
6766,@rasbt,2021-12-12 20:43:58+00:00,https://twitter.com/rasbt/status/1470132340739514376,"This is an amazing initiative and so important! 
‚úÖa transparent review system
‚úÖanytime submissions and no artificial deadlines
‚úÖallowing shorter submissions (as an improvement over traditional journals)
‚úÖacceptance based on claims, not subjective measures novelty &amp; impact"
6767,@rasbt,2021-12-12 20:35:05+00:00,https://twitter.com/rasbt/status/1470130103606722566,@iamtrask Or these lights on a stick that keep changing colors to tell cars which ones can go and which ones have to wait
6768,@rasbt,2021-12-12 16:52:04+00:00,https://twitter.com/rasbt/status/1470073980300283911,"@fchollet One idea would be to also develop ""good defaults"" with the new method you are introducing. It could be a static default or a dynamic heuristic that depends on the dataset. Then the results could be reported in a table for the different scenarios &amp; tell how specialized a method is https://t.co/2f8njdmgg7"
6769,@rasbt,2021-12-12 16:50:25+00:00,https://twitter.com/rasbt/status/1470073564980252680,"@fchollet Very interesting point! Hm, there may be some middle-ground. Like some things -- for some methods -- sometimes need to be tuned to get reasonable results and convergence (like learning rate and max epochs). Whereas in random forests, you have the other extreme: almost plug &amp; play"
6770,@rasbt,2021-12-12 16:27:29+00:00,https://twitter.com/rasbt/status/1470067795949936642,@bhutanisanyam1 @weights_biases Thanks so much for organizing this and taking the time! Really looking forward to it!
6771,@rasbt,2021-12-11 14:51:01+00:00,https://twitter.com/rasbt/status/1469681129070514180,@roydanroy Critique of ‚ÄúGradients are not all you need‚Äù? https://t.co/gakHsvShSf
6772,@rasbt,2021-12-10 21:34:49+00:00,https://twitter.com/rasbt/status/1469420362106560525,@xamat afaik that's part of the deal
6773,@rasbt,2021-12-10 19:33:44+00:00,https://twitter.com/rasbt/status/1469389890387329032,"@AllenDowney I would, too. Unless, you know what you are doing, I feel like idxmax is just cause for silent bugs due to forgetting about resetting the index (as a primary NumPy user, I am actually really bad at using the index in DataFrames). https://t.co/aXqne1cfLs"
6774,@rasbt,2021-12-10 18:09:52+00:00,https://twitter.com/rasbt/status/1469368785576636423,"Excited about doing a live AMA this Sunday! Deep learning, teaching, machine learning research, academia, my upcoming book, videogaming, cross-country skiing, ... or anything else, I am happy to chat :)"
6775,@rasbt,2021-12-10 17:14:35+00:00,https://twitter.com/rasbt/status/1469354870876647425,"@Netwurc @shortstein I am also thinking that given everything is online, I feel like the poster format seems unnecessarily traditional. It would be interesting to try other formats."
6776,@rasbt,2021-12-10 16:56:15+00:00,https://twitter.com/rasbt/status/1469350257360314380,"@cbrnr_ @DynamicWebPaige @github Just checking out some old notebooks, and yeah, I think it does look prettier now :)"
6777,@rasbt,2021-12-10 16:54:44+00:00,https://twitter.com/rasbt/status/1469349877180428289,"@cbrnr_ @DynamicWebPaige @github I think this always worked, but math(jax) support in markdown was/is missing?"
6778,@rasbt,2021-12-10 13:09:38+00:00,https://twitter.com/rasbt/status/1469293226674827274,@bgn_onatrashcan Haha I wish!
6779,@rasbt,2021-12-09 19:53:49+00:00,https://twitter.com/rasbt/status/1469032556888739848,"@tunguz Oh, I remember the good old times where alternative Python runtimes like IronPython (C#?), Jython (Java) etc were a thing. No idea if they are still around and developed though. Also, never really used them, I just remember that people talked about it a lot"
6780,@rasbt,2021-12-09 18:03:52+00:00,https://twitter.com/rasbt/status/1469004887279255555,"@Jeande_d This is very nice and concise :). Btw., if you ever want to take PyTorch for a spin: https://t.co/awGZjC3Mcp https://t.co/oNtkL2COB0"
6781,@rasbt,2021-12-09 17:59:02+00:00,https://twitter.com/rasbt/status/1469003672638083076,@thomaskipf @NagraniArsha Congrats!
6782,@rasbt,2021-12-09 14:18:03+00:00,https://twitter.com/rasbt/status/1468948058973081605,"Am planning to record bonus lectures for my ML class in the next couple of weeks on feature selection &amp; extraction, clustering, and Bayesian methods. Aiming for 1 vid / day &amp; will be uploading to YT. If you are interested, please feel free to subscribe :). https://t.co/95xIwP28NS"
6783,@rasbt,2021-12-09 13:51:34+00:00,https://twitter.com/rasbt/status/1468941392261136401,"@zacharylipton Ha yeah, the feeling when you realize that writing lecture notes was worthwhile after all; when the target audience is your future self"
6784,@rasbt,2021-12-09 02:49:10+00:00,https://twitter.com/rasbt/status/1468774693889007618,@colinraffel This sounds very exciting! Great idea and initiative!
6785,@rasbt,2021-12-09 00:53:58+00:00,https://twitter.com/rasbt/status/1468745705716162569,"@PranayT17837428 Glad to hear! And yeah, lots of exciting things for the new edition, including the transformer chapter I am currently editing :)"
6786,@rasbt,2021-12-09 00:31:20+00:00,https://twitter.com/rasbt/status/1468740006718103557,"@PranayT17837428 * I must say that I also haven't implemented every algorithm out there üòÖ. However, I challenge myself to implement one every few months or so. It's a good exercise to stay fresh."
6787,@rasbt,2021-12-09 00:30:13+00:00,https://twitter.com/rasbt/status/1468739725238407171,"@PranayT17837428 Actually, I remember that I found kernel PCA quite challenging. I was including it in my book back in 2015 and struggled with it quite a bit. In the end, the code was relatively short and simple, but the math was quite hard."
6788,@rasbt,2021-12-09 00:21:15+00:00,https://twitter.com/rasbt/status/1468737471362093058,@CSProfKGD Good choice üëå
6789,@rasbt,2021-12-09 00:20:07+00:00,https://twitter.com/rasbt/status/1468737185432092674,"How did I learn ML algorithms? I tried implementing them from scratch! So, I put together an optional Coding a CART Decision Tree From Scratch for my students &amp; thought one or the other may want to try it as well! https://t.co/B6NY8DyxNB (Will be sharing the solutions next week!)"
6790,@rasbt,2021-12-08 23:14:58+00:00,https://twitter.com/rasbt/status/1468720788853473291,"@haldaume3 Yeah, agree that tipping the scale entirely towards exploitation is not a good thing for research. On the other hand, tipping the scale a bit can be important for enabling research in adjacent fields. Think of AlphaFold2 and what it potentially means for structural bio &amp; medicine"
6791,@rasbt,2021-12-08 21:21:44+00:00,https://twitter.com/rasbt/status/1468692292257128452,"Also, glad to see the tCO2e reduction  ""380 net tCO2e, compared to 552 net tCO2e for GPT-3"". For reference: ""roughly 300 tCO2e per passenger jet round trip from London to New York."" In other words, in the long run, Gopher is probably more efficient than training a human expert üòÜ"
6792,@rasbt,2021-12-08 21:21:43+00:00,https://twitter.com/rasbt/status/1468692290445225987,"The new 280-billion parameter model is has a pretty decent predictive performance boost over GPT-3 (175 billion parameter, for ref). Also, it gets pretty close to human experts in certain areas. Sure, not perfect, but impressive that it beat the 2022 &amp; 2023 forecasts already! https://t.co/AZk3k8eLHd"
6793,@rasbt,2021-12-08 19:12:05+00:00,https://twitter.com/rasbt/status/1468659664334336010,"@Mniepert Another aspect is that TensorFlow resources can sometimes be out of date since the API changed a lot in recent year. Overall, they do have a good up-to-date documentation on their website now though!"
6794,@rasbt,2021-12-08 19:11:14+00:00,https://twitter.com/rasbt/status/1468659454153482244,"@Mniepert There do seem to be more resources on TensorFlow out there, but I must say that when using PyTorch, I often have to search less. Also, I don't mind that the answers come from the same handful of people -- actually I learned to trust these people because they really are experts"
6795,@rasbt,2021-12-08 14:35:23+00:00,https://twitter.com/rasbt/status/1468590034429300738,"@Michael_J_Black @CSProfKGD Totally agree, as long as the impact of one's students' publications is not measures in number of citations or H-index üòâ"
6796,@rasbt,2021-12-08 14:20:33+00:00,https://twitter.com/rasbt/status/1468586298696941575,Yes! I found reference software surprisingly flaky (screwing up the numbering more than once) last time I used it back in grad school. Actually wrote a bibtex parser so that I can manually insert bibtex refs when drafting &amp; writing in Markdown: https://t.co/e4gzWGaPmD
6797,@rasbt,2021-12-08 02:29:39+00:00,https://twitter.com/rasbt/status/1468407395655241733,"@roydanroy The platform is fine, but it would be more fun if there was a leveling system and you could get XP (no, not citations) from attending conferences, collect equipments from random loot boxes, and have a persistent character."
6798,@rasbt,2021-12-08 02:12:15+00:00,https://twitter.com/rasbt/status/1468403015103172612,"@HEPfeickert @captainsafia Yeah, that's a good summary of how I feel as well."
6799,@rasbt,2021-12-08 00:19:39+00:00,https://twitter.com/rasbt/status/1468374680503472131,@karpathy And even graphs! https://t.co/WYlunoXG1e
6800,@rasbt,2021-12-07 22:57:13+00:00,https://twitter.com/rasbt/status/1468353934708584448,"@PogrebnyakE If you are interested, here's the syllabus! https://t.co/tr5NIuEf4l"
6801,@rasbt,2021-12-07 22:06:51+00:00,https://twitter.com/rasbt/status/1468341259861475332,@PogrebnyakE @UWMadison Yeah
6802,@rasbt,2021-12-07 22:00:59+00:00,https://twitter.com/rasbt/status/1468339781692178432,@PogrebnyakE Intro to Machine Learning
6803,@rasbt,2021-12-07 21:29:08+00:00,https://twitter.com/rasbt/status/1468331767950159873,"I am really flattered by all the positive feedback this semesterü§ó
""To be honest, this course is probably my favorite course in this university, because it does not make students feel stressful, while still letting us to learn lots of interesting¬†things."""
6804,@rasbt,2021-12-07 21:08:02+00:00,https://twitter.com/rasbt/status/1468326459701973001,S.o. asked how we can plot the 2D latent space of a variational autoencoder as a distr in 3D &amp; I just remembered one of my 1st blog posts on kernel density estimation. But reading your own blog post from &gt;7 years ago is such a strangely uncomfy experience https://t.co/bDXJM4iicN https://t.co/85KUJwqwlg
6805,@rasbt,2021-12-07 20:53:31+00:00,https://twitter.com/rasbt/status/1468322805959864373,"@captainsafia Yes, totally worth it. Even though I am not standing every day, what's great about it is that it allows you to easily adjust the height. For example, I need a different height when reading &amp; taking a notes on paper/tablet compared to typing etc."
6806,@rasbt,2021-12-07 18:49:53+00:00,https://twitter.com/rasbt/status/1468291691186696196,"@teemu_roos @CSProfKGD That's great news. I must say that in my department, this is also extremely valued, which I am very thankful for. But I think that in the academic community at large, I sometimes feel like teaching contributions often tend to be a tad undervalued."
6807,@rasbt,2021-12-07 18:36:46+00:00,https://twitter.com/rasbt/status/1468288388965060614,"@teemu_roos @CSProfKGD For sure. It might be sarcasm, but I seriously think that having a online course of this magnitude certainly outweighs a field‚Äôs favorite citation-collecting survey paper. I think it‚Äôs a big accomplishment and service that‚Äôs worth acknowledging."
6808,@rasbt,2021-12-07 18:02:26+00:00,https://twitter.com/rasbt/status/1468279751886450695,"@CSProfKGD Re citation counts and h-index, I don't understand why ""number of students taught"" is not a commonly shared count to brag about. I feel like this is an equally good measure of impact in the sense of how many lives and careers someone positively influenced."
6809,@rasbt,2021-12-07 16:04:46+00:00,https://twitter.com/rasbt/status/1468250137575239683,@mattmayo13 a paper a day keeps FOMO away
6810,@rasbt,2021-12-07 16:04:08+00:00,https://twitter.com/rasbt/status/1468249980855107588,"@nezubn Oh, and blog posts and stackexchange!"
6811,@rasbt,2021-12-07 15:40:58+00:00,https://twitter.com/rasbt/status/1468244149979729928,"@nezubn books, code, online courses"
6812,@rasbt,2021-12-07 15:19:24+00:00,https://twitter.com/rasbt/status/1468238721623502863,"@CSProfKGD Yeah, that makes sense! Thanks!"
6813,@rasbt,2021-12-07 14:59:35+00:00,https://twitter.com/rasbt/status/1468233732830253058,@CSProfKGD Nice! Question from someone with a similar setup (having the desk in front of the window): are the spotlights necessary/making a difference when recording? Wondering if I should invest in some too.
6814,@rasbt,2021-12-07 13:19:42+00:00,https://twitter.com/rasbt/status/1468208599604371464,"@AllenDowney Instead of ""Let me explain this thing that we compute using some blackbox software. Oh, also, the result is not what you think it is, let me reword it.""-approach, why not showing and explaining how it is derived and computed. I think that would go a long way."
6815,@rasbt,2021-12-07 13:16:46+00:00,https://twitter.com/rasbt/status/1468207859913703429,"@AllenDowney Honestly, at this point, instead of trying to explain it by restating it in different words, it may be better to just encourage people to build intuition by looking at the mechanics, i.e., by recommending an intro stats course covering random variables &amp; one-sample inference."
6816,@rasbt,2021-12-07 13:11:56+00:00,https://twitter.com/rasbt/status/1468206643620065285,@AllenDowney I am surprised that people are still writing articles trying to explain p-values. Feels like groundhog day.
6817,@rasbt,2021-12-06 22:11:17+00:00,https://twitter.com/rasbt/status/1467979986921570310,@fchollet SDE as in Software Developer Envelopment
6818,@rasbt,2021-12-06 20:48:04+00:00,https://twitter.com/rasbt/status/1467959046116417541,@maosbot Probably also applies to a PostDoc. Maybe even worse for those on a work visa üò∞
6819,@rasbt,2021-12-06 20:25:29+00:00,https://twitter.com/rasbt/status/1467953362343804933,"""NAS: Green Neural Architecture Search"". I am still unsure if NAS will go anywhere, but being environmentally more friendly &amp; offering 25-50x speed-up compared to traditional NAS is certainly a big plus: https://t.co/HlQEUtUTkz https://t.co/kluXcJ1QCh"
6820,@rasbt,2021-12-06 17:01:24+00:00,https://twitter.com/rasbt/status/1467902002827079684,"@EconAndrew Hah, I think it is more about dreading to read through fine prints as I am fairly sure that your regular car insurance covers rental vehicles (unless I misread). And if not, I think certain credit cards may also cover it."
6821,@rasbt,2021-12-06 13:49:24+00:00,https://twitter.com/rasbt/status/1467853686223351810,"@mariaKhalusova @DynamicWebPaige Never been, actually, and I heard beautiful things about it. How important is it to pick up French?"
6822,@rasbt,2021-12-06 13:48:10+00:00,https://twitter.com/rasbt/status/1467853373592543244,"@Diadochokinetik @DynamicWebPaige Having visited my family this summer, I remembered how much I like Germany. However, I am not sure if I could actually live there. It's more like a country I like to visit."
6823,@rasbt,2021-12-06 13:46:25+00:00,https://twitter.com/rasbt/status/1467852935493267459,"@dmarthal @DynamicWebPaige Hah, have been there this summer. It's a really nice area."
6824,@rasbt,2021-12-06 13:45:53+00:00,https://twitter.com/rasbt/status/1467852799065088005,"@CMastication @DynamicWebPaige I actually like Colorado a lot. Have been there on a road trip this summer. Haha, was only slightly too hot for my partner."
6825,@rasbt,2021-12-06 12:58:44+00:00,https://twitter.com/rasbt/status/1467840932892528641,"@DynamicWebPaige Good one. Have been thinking really hard about this in recent weeks. I don't have the answer, yet, but somewhere where it is warm in summer and snowy in winter -- to get the best of both worlds. Somewhere where there's lots of nature but a vibrant city is in rel. short distance."
6826,@rasbt,2021-12-06 00:18:42+00:00,https://twitter.com/rasbt/status/1467649666347061253,"@yuvalmarton hah, we need more positivity in our lives :)"
6827,@rasbt,2021-12-05 22:28:07+00:00,https://twitter.com/rasbt/status/1467621838066958342,"@Isinlor That's a really nice one, thanks for sharing!"
6828,@rasbt,2021-12-05 19:03:47+00:00,https://twitter.com/rasbt/status/1467570415455326208,"@unsorsodicorda Yes, the CPU gives a decent boost over Intel chips. The M1 GPU support is not official yet afaik (https://t.co/NPJKwMi5yr) but someone put together benchmarks, so I guess it's possible to already compile it with GPU support (https://t.co/O32JBeQakG)"
6829,@rasbt,2021-12-05 18:58:24+00:00,https://twitter.com/rasbt/status/1467569058463817728,@thecapeador @DigantaMisra1 @TheZachMueller That's actually pretty interesting! I bet this is actually a pretty good approximation given that you have good implementations.
6830,@rasbt,2021-12-05 18:54:05+00:00,https://twitter.com/rasbt/status/1467567972374007808,"@DigantaMisra1 @TheZachMueller Phew good question. For traditional methods: VC dimension. For neural nets, cardinal capacity as number of bits that can be stored, which can be estimated by a cubic polynomial in the sizes of the layers https://t.co/DJQ46cglNA ?"
6831,@rasbt,2021-12-05 15:14:36+00:00,https://twitter.com/rasbt/status/1467512736548536322,"@christian_unoxx Ok that's fair! But it sounds like it's more of an implementation issue. Maybe a chicken-egg problem after all: adoption is low because implementation is not good, and implementation is not good because it is not frequently¬†use."
6832,@rasbt,2021-12-05 14:49:37+00:00,https://twitter.com/rasbt/status/1467506450322886657,"@JFPuget It can always get harder. Had to do sth similar over thanksgiving: transfer all data from an old Windows PC to Chromebook. Ok to be fair, it can be solved by moving everything to Google Drive and calling it a day."
6833,@rasbt,2021-12-05 14:31:12+00:00,https://twitter.com/rasbt/status/1467501815059070985,"I can see how it could be super useful in many applications regarding following the computations of batchnorm, layernorm, and attention for 3D and 4D tensors. And if it supported named tensors in PyTorch, that'd be amazing! https://t.co/ZivHfXszKR"
6834,@rasbt,2021-12-05 14:17:26+00:00,https://twitter.com/rasbt/status/1467498350371028996,Following some rabbit holes re Einstein summation/einsum in PyTorch (https://t.co/ZLEHAMjv6f) this morning. People who use it love it &amp; I'm surprised it hasn't caught on more widely. Is it the steep learning curve? Btw. this is an excellent tutorial: https://t.co/kDKLmtLoqL
6835,@rasbt,2021-12-05 03:36:20+00:00,https://twitter.com/rasbt/status/1467337013649158148,"@AdamRossNelson @alfcnz yeah, it also came with tools to completely disassemble it, which could be a meditative exercise one day ;)"
6836,@rasbt,2021-12-05 00:02:21+00:00,https://twitter.com/rasbt/status/1467283162036424705,@AdamRossNelson @alfcnz Haha we shall see
6837,@rasbt,2021-12-04 17:04:57+00:00,https://twitter.com/rasbt/status/1467178122122563589,"I'd say the worst are probably those silent bugs that are hard to debug. Currently helping students with class projects, and there are many cases of perfect test acc (usually due to data leakage) or very low acc (usually issues w preprocessing or sampling) https://t.co/wNIPngrNTp"
6838,@rasbt,2021-12-04 16:45:27+00:00,https://twitter.com/rasbt/status/1467173214015078410,"@__mharrison__ Oh, and this: https://t.co/Ro9209v4dV"
6839,@rasbt,2021-12-04 16:15:30+00:00,https://twitter.com/rasbt/status/1467165674430775296,**hopefully my last batch (for this year) though.
6840,@rasbt,2021-12-04 16:15:00+00:00,https://twitter.com/rasbt/status/1467165549402722306,"Conclusion so far: definitely makes typing up paper reviews more enjoyable (but no, I am still not enjoying reviewing papers on a weekend)"
6841,@rasbt,2021-12-04 14:46:51+00:00,https://twitter.com/rasbt/status/1467143368421650437,"@thesasho That's fair. Specifically for Bayesian networks, neural networks, and many, many others. My guess it depends on context though. Like when we talk about using scikit-learn, when we use the terms KMeans(++) algo and model, everyone knows what is meant. I see your point though."
6842,@rasbt,2021-12-04 14:33:03+00:00,https://twitter.com/rasbt/status/1467139894434750473,"@thesasho I see + agree with both. I'd say that in most contexts, it's just colloquial or shorthand for training algorithm, similar to saying things like ""xxx requires more compute"" vs ""xxx requires more computing resources"". I got used to it üòÖ"
6843,@rasbt,2021-12-04 14:15:07+00:00,https://twitter.com/rasbt/status/1467135382466748428,"@thesasho Curious, are you complaining that DT algorithm is not specific enough (like CART or C4.5) or that you would call that ‚Äòmodel‚Äô?"
6844,@rasbt,2021-12-03 23:17:48+00:00,https://twitter.com/rasbt/status/1466909563760918536,@TaliaRinger *I try to keep it low (I prefer 2-3 to be honest) so that I can spend more time on each project vs becoming spread too thin. But once in a while there is this good idea or interesting collaboration that is hard to say No to üò¨
6845,@rasbt,2021-12-03 23:15:10+00:00,https://twitter.com/rasbt/status/1466908901690028037,"@TaliaRinger Not CS, but ~3-6ish."
6846,@rasbt,2021-12-03 18:08:48+00:00,https://twitter.com/rasbt/status/1466831803226984454,"@ssshukla26 Glad to hear that you got something useful out of it! And thanks so much for the kind words, this means a lot to me!"
6847,@rasbt,2021-12-03 16:52:50+00:00,https://twitter.com/rasbt/status/1466812685694214144,"@fchollet Wow, so cool! Big congrats!"
6848,@rasbt,2021-12-03 15:52:40+00:00,https://twitter.com/rasbt/status/1466797541954105348,@kjbird15 Thanks for the kind words!
6849,@rasbt,2021-12-03 14:50:15+00:00,https://twitter.com/rasbt/status/1466781834780499979,@kjbird15 More like the last conventional in-person lecture. I am going to focus on different contents and media for education next year :)
6850,@rasbt,2021-12-03 14:47:37+00:00,https://twitter.com/rasbt/status/1466781172978130945,"@naman1315 Since Python is the most frequently used language for ML, and is itself a user-friendly programming language to learn, I would probably look into learning a bit of Python alongside learning ML. I have a few resources listed here: https://t.co/cfnxMBRhyo"
6851,@rasbt,2021-12-03 14:44:42+00:00,https://twitter.com/rasbt/status/1466780437725036553,"@naman1315 Good question! It may sound like a distraction from learning ML, but I think you may want to start with a basic programming course. It will really help you in the long run, because ML is/can be very applied. And programming will help you follow tutorials and try ideas."
6852,@rasbt,2021-12-03 14:23:27+00:00,https://twitter.com/rasbt/status/1466775089731579904,"@roydanroy When I was a grad student, I was recommended to join some of these professional societies. But the membership fees and other things about it made me think these were more like pyramid schemes or scams. So, I actually never joined any of these. Sounds like I am not missing out"
6853,@rasbt,2021-12-03 02:09:19+00:00,https://twitter.com/rasbt/status/1466590340744241158,"@GiorgioMantova @alfcnz @Saigarich When my Apple bluetooth keyboard was failing, I connected my old full-size Das Keyboard. Due to the numpad, I couldn't use it. The mouse was way too far away. The tkl feels fine to me, no issues. But you are right, I might like the gmmk layout, too. Haha but I am keeping this now"
6854,@rasbt,2021-12-03 02:00:13+00:00,https://twitter.com/rasbt/status/1466588048804626432,"@GiorgioMantova @alfcnz @Saigarich Yes for sure. I had blue switches back in grad school. I was using them in the shared office. In retrospect, I feel really bad, and thankful about my colleague's patience. I now have brown switches and even they feel too much. So, I also got the O-ring dampers."
6855,@rasbt,2021-12-03 01:58:16+00:00,https://twitter.com/rasbt/status/1466587559958441987,"Actually, I think this is not too far off. Just trying out Nvidia's GauGAN2 (https://t.co/KokW3oZSPo), and I am actually positively surprised how good generative image editing got in recent years https://t.co/4p1mmQ0YvL"
6856,@rasbt,2021-12-03 01:22:54+00:00,https://twitter.com/rasbt/status/1466578659003678720,@ropeharz @thegautamkamath Good point. Based on the previous point (averaging over datasets) I thought we don't have access to the population.
6857,@rasbt,2021-12-02 23:32:11+00:00,https://twitter.com/rasbt/status/1466550796808376320,@alfcnz This week was finally the week I got to replace my 5 year old failing Apple Keyboard. Thanks for the recommendation. Love it so far. (That's the K8 https://t.co/CvB2KMlvVn.) https://t.co/qJbR10dbbC
6858,@rasbt,2021-12-02 20:30:39+00:00,https://twitter.com/rasbt/status/1466505109932847105,"@mervenoyann * ok, big asterisk: sometimes, not always."
6859,@rasbt,2021-12-02 20:16:15+00:00,https://twitter.com/rasbt/status/1466501488327462915,"@mervenoyann üôà. This means you will have very fond memories of grad school one day üòú. In hindsight, it was a fun time!"
6860,@rasbt,2021-12-02 19:58:02+00:00,https://twitter.com/rasbt/status/1466496901306634248,"@mervenoyann Arg yeah, grad school. But it can always be worse ‚Ä¶ at least you are staying fit and healthy üòä. And glad it‚Äôs only a few more weeks ü§ó"
6861,@rasbt,2021-12-02 19:21:39+00:00,https://twitter.com/rasbt/status/1466487747636518912,"@thegautamkamath Regarding 3, consider a decision tree classifier (estimator of some function). A decision tree stump has high bias. It is very consistent though.  A deep decision tree has high variance. It is very inconsistent. https://t.co/tqgCEWvEyU"
6862,@rasbt,2021-12-02 17:54:23+00:00,https://twitter.com/rasbt/status/1466465787288469506,"Today is bittersweet. It's my last (in-person) lecture! Now, I am super excited to see how students put the learned machine learning knowledge into practice in their class projects! (I am also planning to record some bonus contents over winter break, will share them on YT too :))"
6863,@rasbt,2021-12-02 17:33:50+00:00,https://twitter.com/rasbt/status/1466460615376093193,@ManningerTanja @SamuelKaplan13 @monjalexander @freddyrojascama Nope :(
6864,@rasbt,2021-12-02 14:00:20+00:00,https://twitter.com/rasbt/status/1466406883166728192,@JFPuget @Saarques @karpathy agreed
6865,@rasbt,2021-12-02 13:31:43+00:00,https://twitter.com/rasbt/status/1466399683937513481,"@JFPuget @Saarques @karpathy Nonlinear kernel SVM is hard to compare to logistic regression though. Very different things. But yeah, in my experience, a random forest usually wins over nonlinear kernel SVM, scales better, and doesn't require much tuning."
6866,@rasbt,2021-12-02 13:19:24+00:00,https://twitter.com/rasbt/status/1466396584183222279,"@mrsaladfingers2 @karpathy The problem are the memory requirements, since you have the NxN kernel matrix, which is super expensive. It just doesn't scale very well. The standard implementation has O(N^3) time complexity and O(N^2) space complexity."
6867,@rasbt,2021-12-02 12:57:44+00:00,https://twitter.com/rasbt/status/1466391130514333703,"@mrsaladfingers2 @karpathy Only half joking. Because the performance of a linear SVM is usually indistinguishable from logistic regression. And nonlinear SVM is infeasible on large datasets, and more cumbersome to tune whereas a random forest works well out of the box"
6868,@rasbt,2021-12-02 12:55:34+00:00,https://twitter.com/rasbt/status/1466390586840256516,"@JFPuget @Saarques @karpathy Yeah, they can be a tad more accurate sometimes. In my experience, that's very rare and their performance is usually indistinguishable to me. Coz the limitation is more that it's a linear classifier (assuming we are talking about linear SVM when comparing to logistic regression)"
6869,@rasbt,2021-12-02 01:58:01+00:00,https://twitter.com/rasbt/status/1466225108423434245,"4/4 Now, the advantage of the F1-MCC curve is that it doesn't have an inflated performance under strong class imbalance, unlike ROC curves and even PR curves. A little bummer is that we cannot simply compute the AUC, but authors provide a metric score as well (paper for details)"
6870,@rasbt,2021-12-02 01:58:01+00:00,https://twitter.com/rasbt/status/1466225107047796742,"3/4 Instead of looking at a single threshold, curves plotted over variable thresholds (actually the full range of thresholds) allow us to study the classifier performance across different scenarios. And we can still compute the area under the curve if we like a summary metric."
6871,@rasbt,2021-12-02 01:58:01+00:00,https://twitter.com/rasbt/status/1466225105919528963,"2/4 Why use ROC and P(recision)R(ecall) curves? Balanced accuracy, F1, and MCC etc look at performances for a certain prediction threshold. E.g., the default is ""&gt;0.5 -&gt; class 1, and class 0, otherwise"" for logistic regression."
6872,@rasbt,2021-12-02 01:58:00+00:00,https://twitter.com/rasbt/status/1466225103923036180,"Recently, made some Twitter threads discussing F1, balanced accuracy &amp; MCC scores. Now, just putting together a lecture on performance metrics for tomorrow, I read a paper on the logical culmination of these: The F1-MCC curve! (https://t.co/myGGArq06y)  1/4 https://t.co/gf6CBQLjNf"
6873,@rasbt,2021-12-01 19:58:56+00:00,https://twitter.com/rasbt/status/1466134743083274247,"@TheZachMueller @omarsar0 I try to emphasize research/project work in classes, too  https://t.co/HLJzYQNS7b ü§ó. Most students really enjoy it, and it's also good for the CV (and it helps me with writing more unique recommendation letters)"
6874,@rasbt,2021-12-01 19:56:51+00:00,https://twitter.com/rasbt/status/1466134216178114569,"@MSFTResearch @SebastienBubeck @geoishard ""We prove that [...] overparametrization is necessary if one wants to interpolate the data smoothly."" Sounds super intriguing. Haven't read this paper yet, and maybe you mention that :), but that kind of confirms my vague intuition why we can observe double decent"
6875,@rasbt,2021-12-01 19:49:04+00:00,https://twitter.com/rasbt/status/1466132260072083466,"@TheZachMueller Or something along these lines. He was trying to say that you should make sure you take something useful from this class. But to get an A, you have to spend significant time studying, which you could better spend on something more useful like your research project."
6876,@rasbt,2021-12-01 19:48:06+00:00,https://twitter.com/rasbt/status/1466132016215244803,"@TheZachMueller I think GPA only matters for score-based grad school admissions. I don't think GPA is correlated with research success. Or maybe negatively correlated even. I still remember a quote by a prof in my first grad school class: ""Don't waste your time studying for an A in my course."""
6877,@rasbt,2021-12-01 19:15:53+00:00,https://twitter.com/rasbt/status/1466123907048488962,"@TheZachMueller On a related note, I replaced Travis-CI (didn't really work for me anymore) and Appveyor with GitHub Actions for unit testing this week and love it."
6878,@rasbt,2021-12-01 17:40:45+00:00,https://twitter.com/rasbt/status/1466099966414397441,"@karpathy Awesome! Haha, and please replace the SVM with logistic regression or random forests in the future so that I can tell my students that SVMs are really not that relevant anymore :P"
6879,@rasbt,2021-12-01 17:38:26+00:00,https://twitter.com/rasbt/status/1466099383666102272,"@fvsmassa I'd deprecate ""pretrained=True"" in favor of 
""pretrained=None"", 
""pretrained='2017-default'"",
""pretrained='2021-default'"", 
or sth like this."
6880,@rasbt,2021-12-01 15:47:38+00:00,https://twitter.com/rasbt/status/1466071498515435532,@PyTorch Impressive performance compared to torch.script: https://t.co/vkgyCmlNgu
6881,@rasbt,2021-12-01 15:44:29+00:00,https://twitter.com/rasbt/status/1466070705259302915,"@PyTorch Another interesting language to keep on the radar: https://t.co/c9MUJuRdZM 

below, a vector addition example: https://t.co/ougH3c1Ibv"
6882,@rasbt,2021-12-01 15:38:34+00:00,https://twitter.com/rasbt/status/1466069219603275780,"@PyTorch This was an interesting section on the next generation of array programming &amp; processing, and how to outgrow the limitations of the NumPy API and Jax. Will definitely keep an eye on Dex (https://t.co/sh1duW8eAP)."
6883,@rasbt,2021-12-01 15:29:32+00:00,https://twitter.com/rasbt/status/1466066945124491268,Livestream happening now!
6884,@rasbt,2021-12-01 14:04:01+00:00,https://twitter.com/rasbt/status/1466045425392271368,"@iyedBe @aureliengeron Yes, that's another common one. Coincidentally, it happened to some in a class HW ~2 weeks ago https://t.co/xIO4Llcx7B"
6885,@rasbt,2021-12-01 13:37:46+00:00,https://twitter.com/rasbt/status/1466038815756369923,"@aureliengeron Great thread. Based on helping many students with their class projects, another common issue I saw is omitting to apply the same data scaling &amp; processing to the validation set. It‚Äôs sometimes easy to overlook."
6886,@rasbt,2021-12-01 01:49:27+00:00,https://twitter.com/rasbt/status/1465860564610125825,"@guysnovelutumba It's an in-person class this semester, but the link is: https://t.co/tr5NIuDHeN"
6887,@rasbt,2021-12-01 01:49:09+00:00,https://twitter.com/rasbt/status/1465860489473372160,"@MineshJ1291 It was just an excerpt from a nice email I just received, which I found very motivating :)"
6888,@rasbt,2021-12-01 01:08:01+00:00,https://twitter.com/rasbt/status/1465850138501521409,"""Before taking your class, I had very limited knowledge of ML. It's the way you teach, the interesting information you shared in class [...] I participated in the datathon competition you recommended in mid-October and won the first Runner up with my teammates [...]"" So coolü§ó"
6889,@rasbt,2021-12-01 00:17:02+00:00,https://twitter.com/rasbt/status/1465837304560431110,"**In case you are wondering why it says ""Spring"" -- I just added it to an older repo, because it fit nicer into the context of an LSTM I trained on the same dataset, IMDB movie review sentiment"
6890,@rasbt,2021-12-01 00:15:22+00:00,https://twitter.com/rasbt/status/1465836886753165312,*Nice bonus: now I also have a nice example of rule-based AI handy. Something that doesn't require training data.
6891,@rasbt,2021-12-01 00:15:22+00:00,https://twitter.com/rasbt/status/1465836885121589249,"Love the student discussions during office hours, esp. about their near final projects. Today, they showed me VADER, a rule-based method for sentiment analysis. A neat baseline for comparing your more complicated DL models. Just made a quick example here: https://t.co/hGhch3BCbg"
6892,@rasbt,2021-11-30 18:10:17+00:00,https://twitter.com/rasbt/status/1465745012898029581,"@athundt @YassineMrabet21 That's totally true. But I feel like if you are allowing duplicated work at regular conferences, this can easily be abused. I think the duplicated work should probably be presented in a dedicated conference on reproducibility."
6893,@rasbt,2021-11-30 13:03:50+00:00,https://twitter.com/rasbt/status/1465667888350695425,"@roydanroy Arg, sorry to hear. I'll keep an eye out and send future opportunities your way. Also, happy to endorse you on LinkedIn if needed."
6894,@rasbt,2021-11-29 20:47:09+00:00,https://twitter.com/rasbt/status/1465422101783973894,@xtbot @tunguz and adheres to the 140-char limit using a 4-letter twitter handle. classy.
6895,@rasbt,2021-11-29 13:45:30+00:00,https://twitter.com/rasbt/status/1465315988849704969,"@mmbronstein @CompSciOxford @UniofOxford @DeepMind @ExeterCollegeOx Awesome news, big congrats!"
6896,@rasbt,2021-11-28 21:46:44+00:00,https://twitter.com/rasbt/status/1465074706239868933,"@BecomingDataSci Awesome! I wanted to get a copy as a holiday gift to myself, and getting a signed one would be awesome! Getting it plus supporting a fundraiser would be doubly awesome ü§ó"
6897,@rasbt,2021-11-28 18:55:33+00:00,https://twitter.com/rasbt/status/1465031624899317764,@OkbaLeftHanded What makes this even sadder is that it comes from a conference program chair.
6898,@rasbt,2021-11-28 18:51:12+00:00,https://twitter.com/rasbt/status/1465030532568342542,"@CSProfKGD Yeah, I just wish those professors who really know the students well would respond and help out more often."
6899,@rasbt,2021-11-28 18:47:00+00:00,https://twitter.com/rasbt/status/1465029476325208068,"@CSProfKGD Yes, I am very upfront about that and mention that I can only write a few sentences about their performance in class and their individual class project. However, they are unbelievably thankful for that."
6900,@rasbt,2021-11-28 18:45:32+00:00,https://twitter.com/rasbt/status/1465029106127577100,"@CSProfKGD Yes, totally. Also, it always breaks my heart when highly motivated students who want to pursue their studies have thrown such obstacles in their way."
6901,@rasbt,2021-11-28 18:43:46+00:00,https://twitter.com/rasbt/status/1465028662349160453,"@CSProfKGD Personally, I had semester where I wrote letters for 20-30 students. Usually 10-20 applications per student. This could be ~200 to 600 submissions to make. It's time consuming for sure, especially when some admissions forms ask for way too much and unreasonable detail."
6902,@rasbt,2021-11-28 18:41:24+00:00,https://twitter.com/rasbt/status/1465028064363040778,"@CSProfKGD Often, students come to me and ask for a letter even though some of them have only taken 1 class with me &amp; the class is still ongoing when the appl. is due. I ask if there are other professors who know them better, and they say that most a) don't respond b) don't write letters."
6903,@rasbt,2021-11-28 18:40:37+00:00,https://twitter.com/rasbt/status/1465027868946276356,"@CSProfKGD What makes me really sad is that having multiple recommendation letters is a requirement for grad school and at the same time, it appears many professors don't help students with that enough."
6904,@rasbt,2021-11-28 16:20:31+00:00,https://twitter.com/rasbt/status/1464992613308813315,"@BielskiAdam @PyTorchLightnin Anyways, thanks for the very helpful discussion, really appreciate it! Will make sure to add an acknowledgement in the book!"
6905,@rasbt,2021-11-28 15:47:58+00:00,https://twitter.com/rasbt/status/1464984420386017290,@BielskiAdam @PyTorchLightnin *above this should have been validation_epoch_end btw. Was doing some experiments there ...
6906,@rasbt,2021-11-28 15:46:54+00:00,https://twitter.com/rasbt/status/1464984152332279811,"@BielskiAdam @PyTorchLightnin Yes, thanks. Like you suggest, I'd put it into validation_step_end to make it both clearer and to avoid silent bugs here https://t.co/G5wqWtQAf1"
6907,@rasbt,2021-11-28 15:24:34+00:00,https://twitter.com/rasbt/status/1464978531004436483,"@BielskiAdam @PyTorchLightnin Ah you are right, can confirm, a reset() is needed."
6908,@rasbt,2021-11-28 15:16:33+00:00,https://twitter.com/rasbt/status/1464976515175755783,@BielskiAdam @PyTorchLightnin I.e. the original case (left) should be equivalent to using validation_epoch_end as shown on the right. Just ran these two and they give exactly the same numerical values when I ran these two side by side and overlayed the TensorFlow log plots. https://t.co/XdymdGpZyO
6909,@rasbt,2021-11-28 15:15:48+00:00,https://twitter.com/rasbt/status/1464976326062923785,"@BielskiAdam @PyTorchLightnin Ah, I think I see what you are getting at. You are concerned that the validation accuracy would be a running mean if it is logged in validation_step? But given that self.log runs automatically on_epoch=True for validation, this shouldn't happen."
6910,@rasbt,2021-11-28 14:42:56+00:00,https://twitter.com/rasbt/status/1464968055012962316,"@TaliaRinger This sounds like a fun trip! Would definitely do it. Did something similar this summer but started slightly farther north (WI) and stopped slightly farther east (UT). Tip: if you pick a route betw the middle and lower one, you can see the Rocky Mountains and Moab national parks!"
6911,@rasbt,2021-11-28 14:30:40+00:00,https://twitter.com/rasbt/status/1464964965958393864,"@LChoshen @giffmana I am not aware data for this exists and/or this was analyzed though. Retrospectively, it is probably also difficult to analyze in the consistency context as they didn't have the same consistency experiment setup with two groups?"
6912,@rasbt,2021-11-28 14:26:28+00:00,https://twitter.com/rasbt/status/1464963910457610252,"@BielskiAdam @PyTorchLightnin Thanks for the comment! I see what you mean: i.e., it'd be better to be logging the validation accuracy similar to how I logged the training accuracy; that is, accumulating and then calling log on *epoch_end(). Or, maybe using on_epoch=True is even simpler &amp; cleaner: https://t.co/q2ZIah3klC"
6913,@rasbt,2021-11-28 14:25:17+00:00,https://twitter.com/rasbt/status/1464963611416272896,"@LChoshen @giffmana With that, I mean increase the review deadline from 1 to 3 months for a given year and see what happens. If it doesn't help, just change it back."
6914,@rasbt,2021-11-28 14:24:04+00:00,https://twitter.com/rasbt/status/1464963305131421705,"@LChoshen @giffmana Totally agree. It may reduce the variance a bit, but it might not help at all (or even make it worse). This is why I think there needs to be more experiments. (Right now, there seems to be only exploratory data analysis.)"
6915,@rasbt,2021-11-28 14:16:05+00:00,https://twitter.com/rasbt/status/1464961297234239492,"@ducha_aiki @giffmana @LChoshen Sure, the amount of work remains the same. But if I had 3 papers to review, it is easier to make room for / plan in one review every month than one review every week (assuming that a good review takes at least 1/2 a day)"
6916,@rasbt,2021-11-28 14:13:05+00:00,https://twitter.com/rasbt/status/1464960543026995202,"@giffmana @LChoshen Ok, very fair point :)"
6917,@rasbt,2021-11-28 13:55:38+00:00,https://twitter.com/rasbt/status/1464956150265298957,"@giffmana @LChoshen I wonder if people could try harder if they are less overburdened and get more time. Could be achieved by having a more generous review deadline. (And, of course, fewer assignments per reviewer, but that might be harder to accomplish)"
6918,@rasbt,2021-11-28 13:36:36+00:00,https://twitter.com/rasbt/status/1464951360256983042,"Based on the ""Inconsistency in Conference Peer Review: Revisiting the 2014 NeurIPS Experiment"" study https://t.co/a0CbavxCmG, there is no correlation between the impact and the judged quality of a paper. So, it is fortunately safe to ignore rude review comments like this. https://t.co/mxdGqqLgM1"
6919,@rasbt,2021-11-28 13:29:54+00:00,https://twitter.com/rasbt/status/1464949672506806273,"@olgias @GalarnykMichael @PyTorchLightnin I'd say the official ""Lightning in 2 Steps"" doc is a great place to start: https://t.co/AnY1LalzMe. Don't be afraid by the length of the doc: it's super easy to get going with PL. Everything after ""Step 2:""(at 1/4th of the doc) is a bonus for additional customization if needed :)"
6920,@rasbt,2021-11-28 13:25:56+00:00,https://twitter.com/rasbt/status/1464948675050934272,@JJcameron22 This sounds about right :(
6921,@rasbt,2021-11-28 03:57:59+00:00,https://twitter.com/rasbt/status/1464805745879363585,@Reza_Zadeh And spending a whole afternoon learning about unique features of zsh when Catalina was released
6922,@rasbt,2021-11-28 02:34:14+00:00,https://twitter.com/rasbt/status/1464784669556228101,"@Shahrullo1 @PyTorchLightnin I am not exactly sure since the publisher hasn't set an official date, yet. However, I am really hoping we can aim for this year! (And if not, it should be early 2022 for sure!)"
6923,@rasbt,2021-11-28 02:33:01+00:00,https://twitter.com/rasbt/status/1464784365318197249,"@GalarnykMichael @PyTorchLightnin Glad to hear that this is going to be useful! Have been doing research and teaching my DL classes (https://t.co/8FhMfL6v3N) in PyTorch as well, and I think it's makes everything much more organized and intuitive (or at least I hope that students see it the same way :))"
6924,@rasbt,2021-11-28 00:52:49+00:00,https://twitter.com/rasbt/status/1464759146440450050,Super excited about how everything is coming together nicely: @PyTorchLightnin is another neat addition to the upcoming edition of Python Machine Learning. A little sneak peak: https://t.co/G3Lc2lDyEA https://t.co/ZRcONLC7zm
6925,@rasbt,2021-11-28 00:26:08+00:00,https://twitter.com/rasbt/status/1464752432106414084,"@themintsv I think it was ~2000ish for me. We had a dial-up plan  which was free on Sundays. So, we only used the internet on Sundays for a bunch of years :)."
6926,@rasbt,2021-11-28 00:16:05+00:00,https://twitter.com/rasbt/status/1464749902462922756,"I wish! 1995 was way before we got internet. Actually, I think this was when our household got its first PC. Didn't have much money, so it was an old 5 Mhz PC with b&amp;w monitor that my dad got from a friend. On that machine my dad taught himself (and me) about computers :)ü§ó"
6927,@rasbt,2021-11-28 00:05:19+00:00,https://twitter.com/rasbt/status/1464747193877868549,"@ykilcher Agreed. In my experience, having a diverse committee and regular meetings (every 6-12 months) is also a good thing. Even better: having a co-advisor."
6928,@rasbt,2021-11-27 22:03:34+00:00,https://twitter.com/rasbt/status/1464716553258209287,"Whoa, GitHub seems to be down. Haven't seen that in years. But well, it's a weekend, guess it's time to chill :) https://t.co/iMPo4VDxwB"
6929,@rasbt,2021-11-27 20:24:20+00:00,https://twitter.com/rasbt/status/1464691583383748614,"@ykilcher Totally agree with you hereüëçüëå:  ""Stop considering impact factors [... ] Do three really nice, really good arxiv publications; if I am happy with it -&gt; Ph.D."""
6930,@rasbt,2021-11-27 20:16:42+00:00,https://twitter.com/rasbt/status/1464689662707085314,"@giffmana It looks like it's exactly the same and nothing has/was improved over the years. In the 2014 experiment (https://t.co/a0CbavxCmG), we had p(disagreement | accepted) = 43/65 = 2/3 as well."
6931,@rasbt,2021-11-26 21:26:34+00:00,https://twitter.com/rasbt/status/1464344857317675012,"@miguelraz_ Thanks! Hah, I wish I had more time! But one of these days I will certainly make the leap!"
6932,@rasbt,2021-11-26 21:12:20+00:00,https://twitter.com/rasbt/status/1464341273238810628,"@miguelraz_ Oh yeah, as someone who has ""look into and dabble with Julia"" as a yearly New Year's resolution, that would finally give me a a compelling reason to!"
6933,@rasbt,2021-11-26 20:18:18+00:00,https://twitter.com/rasbt/status/1464327677989556234,"@MarlosCMachado the process is maybe ok, but the problem is that it‚Äôs not for one but multiple papers, and the timeline is unrealistic. Given that reviewers have job responsibilities &amp; a social life, the turnaround time should be &gt; 1 month to be able to fit it into your schedule w/o compromising"
6934,@rasbt,2021-11-26 17:44:37+00:00,https://twitter.com/rasbt/status/1464288999258918919,"@Jeande_d Congrats, Jean! Love your tweets about ML! Keep them coming!"
6935,@rasbt,2021-11-26 16:09:45+00:00,https://twitter.com/rasbt/status/1464265124957536262,"@RichmanRonald Sounds good, will DM you!"
6936,@rasbt,2021-11-26 16:04:20+00:00,https://twitter.com/rasbt/status/1464263761720754176,"@RichmanRonald It will hopefully only be a few more weeks for it to come out :) -- that is, the major overhaul of my Python ML book with a new title. The publisher mentioned that they are looking for reviewers of the early access copy though. In case you are interested, I can get you in touch"
6937,@rasbt,2021-11-26 15:58:35+00:00,https://twitter.com/rasbt/status/1464262316933976068,"@BerbaFan Yeah, for CNNs, I recommend looking at https://t.co/EpZpoMKqu6

And for transformers, check out https://t.co/wiNMJn16Ji"
6938,@rasbt,2021-11-26 14:02:18+00:00,https://twitter.com/rasbt/status/1464233052113092615,"2/2 Flipping through the titles of accepted NeurIPS papers, looks like there's now some interesting related work to dig into: ""Counterfactual Explanations Can Be Manipulated"" https://t.co/q5eNwtLUrA https://t.co/cLbiFadJPu"
6939,@rasbt,2021-11-26 14:02:16+00:00,https://twitter.com/rasbt/status/1464233045368524804,"Among the things I recommended students to include in their class projects this year is to include something on model interpretability, e.g., 
- feature importance (https://t.co/5fyL81ClSW)
- or counterfactual analysis (https://t.co/shRpFioPYE)
1/2"
6940,@rasbt,2021-11-25 12:39:47+00:00,https://twitter.com/rasbt/status/1463849900601495559,"In case you are interested in teaming up to work on Kaggle competitions over the long weekend (and beyond), that's a nice opportunity to meet the team and get some hands-on help from the PyTorch Lightning core contributors:"
6941,@rasbt,2021-11-24 16:06:47+00:00,https://twitter.com/rasbt/status/1463539603143548928,"@tunguz Agreed, which is why it was great that arxiv integrated Papers with code"
6942,@rasbt,2021-11-24 15:56:00+00:00,https://twitter.com/rasbt/status/1463536890276204546,"@tunguz I generally find arxiv super useful though. It could use improvements, but I do think it's a very important cornerstone of communicating and sharing progress in ML"
6943,@rasbt,2021-11-24 15:54:56+00:00,https://twitter.com/rasbt/status/1463536621136003077,"@tunguz I think so too, or at least a big overhaul is required. I can see that everyday myself. I usually just read arxiv articles that are interesting/useful to me. Sometimes, I find out later that the articles have been published somewhere, but that is usually not super important to me"
6944,@rasbt,2021-11-24 15:41:56+00:00,https://twitter.com/rasbt/status/1463533350757580802,"@tunguz Arg :(. I think that's maybe not arxiv in general but the physics subcategory. In the machine learning category, we usually accepted master and Ph.D. theses. That being said, my Ph.D. thesis (computational bio) was also rejected from arxiv back then :("
6945,@rasbt,2021-11-24 15:25:28+00:00,https://twitter.com/rasbt/status/1463529208110628866,"@tunguz 3/3 But I think that, today, a better solution would be to auto-hold the first submission of each new submitter for manual checking irregardless of the email address."
6946,@rasbt,2021-11-24 15:24:59+00:00,https://twitter.com/rasbt/status/1463529082713481234,"@tunguz 2/3 As former arxiv moderator, I can understand why it was implemented, though (to reduce ""spam"" that is, submitted texts that are not scientific articles)."
6947,@rasbt,2021-11-24 15:24:29+00:00,https://twitter.com/rasbt/status/1463528960562798604,@tunguz That's a good point. I used my private (non edu) email for arxiv and needing endorsements for submitting was actually quite a hassle. I actually didn't know that this was linked to .edu addresses until recently. 1/3
6948,@rasbt,2021-11-24 13:47:29+00:00,https://twitter.com/rasbt/status/1463504547133992962,"@th_sajal Yeah, it's tricky. You certainly can't use the output of the softmax or sigmoid as probability. However, I think MCDropout for uncertainty estimation works quite well in practice."
6949,@rasbt,2021-11-24 00:16:33+00:00,https://twitter.com/rasbt/status/1463300469418303497,"@grafzhl @ykilcher A carpet will probably help, too? Haven't done any super professional recording, but I noticed that a carpet can make a huge difference. (Can't really tell from the image if you already have one)"
6950,@rasbt,2021-11-23 23:55:35+00:00,https://twitter.com/rasbt/status/1463295193956982787,"@LouferTak I have not based cascades on confidence scores but rather used classifier labels for routing. I haven't read the paper in detail though, but maybe they have calibrated their neural nets. I saw there are techniques for that, e.g., https://t.co/EThfx2WKqu"
6951,@rasbt,2021-11-23 23:48:21+00:00,https://twitter.com/rasbt/status/1463293373524103172,"@jruc96 Nice, thanks for the book tip!"
6952,@rasbt,2021-11-23 23:43:46+00:00,https://twitter.com/rasbt/status/1463292218492563458,"*another flavor of this that came up during office hours of this: for predicting AirBnB prices, have one model that predicts categories based on location, and the categories are then subject to individual regression models. Kind of like 'linear model trees' but not so restricted"
6953,@rasbt,2021-11-23 23:37:58+00:00,https://twitter.com/rasbt/status/1463290758354681857,"Nice blog post on model cascades (~subset of ensembles but executed sequentially). Can confirm that this works well. Recommended it to students for class projects in past years &amp; we usually called it hierarchical models (but I like the term ""cascades"") https://t.co/KfndGB4uyN https://t.co/wQfv22jAjp"
6954,@rasbt,2021-11-23 17:27:46+00:00,https://twitter.com/rasbt/status/1463197596768423951,"@Weigq1234Weigq Thanks for sharing the update! I don't think it's possible to edit the tweet though. However, I can use the new URL in case I share it in the future. Thanks!"
6955,@rasbt,2021-11-23 14:23:04+00:00,https://twitter.com/rasbt/status/1463151114082308096,"@eric_brachmann @ykilcher I agree, but afaik there has been no improvement since the 2014 NeurIPS experiment. Also, how can we say that social media bans and even double-blindness makes a difference for the better/worse if there is no e.g., A/B testing?"
6956,@rasbt,2021-11-23 13:37:17+00:00,https://twitter.com/rasbt/status/1463139591322546181,"@david_picard Yeah. It's tricky. I think the dilemma is just that there is such a large number of submissions now (compared to years ago) that now perfectly fine papers get rejected because of quotas, and I am wondering where all these perfectly fine and useful papers will/should go."
6957,@rasbt,2021-11-23 13:29:59+00:00,https://twitter.com/rasbt/status/1463137754368327680,"@david_picard I wonder if this luck/bad luck situation could be improved by changing the ""number of accepted papers"" threshold. (Although, I hear there is no fixed threshold)"
6958,@rasbt,2021-11-23 13:29:33+00:00,https://twitter.com/rasbt/status/1463137646146895878,"@david_picard I agree. But I feel more for the 13% of papers that didn't get accepted because of bad luck. In absolute numbers, that's a lot of papers."
6959,@rasbt,2021-11-23 13:12:53+00:00,https://twitter.com/rasbt/status/1463133454799937536,@simonkmtse haha i know üòÖüò¨
6960,@rasbt,2021-11-23 13:10:35+00:00,https://twitter.com/rasbt/status/1463132872227926019,@simonkmtse I don't know yet but I am hoping this year.
6961,@rasbt,2021-11-23 13:09:08+00:00,https://twitter.com/rasbt/status/1463132507776421890,@fajaremi Not sure. But you could train graph neural networks (there's a new chapter on those too :)) on the graph data and train a gradient boosting machine in their predictions to make the final prediction (like building a stacking ensemble)
6962,@rasbt,2021-11-23 13:05:41+00:00,https://twitter.com/rasbt/status/1463131642508283916,"@idansc I am in favor of replacing ""good"" with ""correct."" I think it is easier to argue about whether a paper is correct, i.e., reviewers can find errors, authors can fix them, and if no errors can be found or remain, it should be published."
6963,@rasbt,2021-11-23 13:02:38+00:00,https://twitter.com/rasbt/status/1463130871477768192,"@david_picard Ok, fair. But still half of the papers got accepted because they were lucky."
6964,@rasbt,2021-11-23 12:57:53+00:00,https://twitter.com/rasbt/status/1463129678047293447,"@suzan @dai_nlp So, like here, given the 5 papers for which the final decision was ""Oral"", there are 5 cases where decision ""Oral"" and 5 cases where the decision ""Poster"" was made. The order is arbitrary, could have been group 1: oral, poster, oral, poster, oral, and group 2: o, o, p, p, p"
6965,@rasbt,2021-11-23 12:57:15+00:00,https://twitter.com/rasbt/status/1463129516835016707,"@suzan @dai_nlp Sorry, I shouldn't have used the words ""group 1"" and ""group 2"". I think it might make things clearer when we refer to them as ""one group"" and ""another group""."
6966,@rasbt,2021-11-23 03:34:36+00:00,https://twitter.com/rasbt/status/1462987923700293635,@roydanroy Pics or it didn‚Äôt happen
6967,@rasbt,2021-11-23 01:14:57+00:00,https://twitter.com/rasbt/status/1462952778477850625,"@seanmylaw Hah, neither. The final layouts are done in Adobe InDesign or something like that, so the tables are rendered as figures anyway. Which is why I just made this table in PowerPoint here."
6968,@rasbt,2021-11-23 01:13:13+00:00,https://twitter.com/rasbt/status/1462952341146112002,"@Kangwook_Lee Oh, I was looking at P(received one reject | final accepted) = 199 / 298 = 0.67. The disagreement be even slightly worse:
 P(inconsistent | final accepted) = 221/298 = 0.74"
6969,@rasbt,2021-11-23 01:05:44+00:00,https://twitter.com/rasbt/status/1462950459249991680,"@zhong_zhiqiang I think this table is complete as far as accepted papers and consistency experiments go. But yeah, the rejected papers are missing"
6970,@rasbt,2021-11-22 22:46:42+00:00,https://twitter.com/rasbt/status/1462915470135369730,"@gussand @ivn_finaev Actually, we exceeded the page limit of what can actually be printed :)"
6971,@rasbt,2021-11-22 21:55:30+00:00,https://twitter.com/rasbt/status/1462902584079966217,"@YassineMrabet21 It might be worthwhile trying. At this point, I think it's important to be open to trying new concepts because the current systems seems not very good anymore."
6972,@rasbt,2021-11-22 21:40:31+00:00,https://twitter.com/rasbt/status/1462898814285660169,"@YassineMrabet21 I am for accepting all papers that are on topic, technically sound, and have otherwise no issues (like missing related work sec or being duplicated work). Then, editors can curate a subset for oral and poster invites if there are space &amp; time constraints for the physical venues"
6973,@rasbt,2021-11-22 20:56:22+00:00,https://twitter.com/rasbt/status/1462887704492920840,@dai_nlp I think the data was sorted by score across rows to make the analysis easier.
6974,@rasbt,2021-11-22 20:55:24+00:00,https://twitter.com/rasbt/status/1462887460149600258,@roydanroy @HaghifamMahdi Chalkboards ftw! This is how my whiteboard looked like when I got back to my office earlier this semester after 1 1/2 years wfh https://t.co/J0UyyUw9Pw
6975,@rasbt,2021-11-22 20:33:29+00:00,https://twitter.com/rasbt/status/1462881943671001096,@ivn_finaev Oh one other major thing is that I rewrote the code and math for the Neural network / backpropagation chapter almost entirely. I hope it's more accessible now!
6976,@rasbt,2021-11-22 20:31:47+00:00,https://twitter.com/rasbt/status/1462881516606865413,"@ivn_finaev Thanks for your interest &amp; support :). I will write a blog post summarizing the changes later in December. For now, the summaries in a nutshell: https://t.co/fC0hAuMRdF"
6977,@rasbt,2021-11-22 20:29:44+00:00,https://twitter.com/rasbt/status/1462881002649440263,"@EMMC_PhD @allonsygamma @akidTwit @curvenote wow this looks really neat. thanks for sharing, I will keep an eye on it and might actually give it a try in the future (haha, timing is a bit late as I finished or nearly finished all the manuscripts for this season)"
6978,@rasbt,2021-11-22 20:27:02+00:00,https://twitter.com/rasbt/status/1462880322761207811,"@billyG881 It will be a new book based on the 3rd edition, but there will be differences (it's more for people who prefer PyTorch over TensorFlow, for example). I will share more details once it is closer to finishing!"
6979,@rasbt,2021-11-22 20:25:48+00:00,https://twitter.com/rasbt/status/1462880010629525511,"@ivn_finaev Kind of but the name might be different because it will be quite different (e.g., PyTorch instead of TensorFlow etc.), and maybe some contents removed in favor of others. I will share more details when it is closer to finishing."
6980,@rasbt,2021-11-22 20:17:29+00:00,https://twitter.com/rasbt/status/1462877917013319683,"Really thrilled about all the additions to the new edition of my machine learning book! This weekend, I wrote a few sections on gradient boosting for classification. Seems like regression examples are highly abundant on the web, but when it comes to classification, crickets :) https://t.co/F8Ddeq9X4T"
6981,@rasbt,2021-11-22 17:14:54+00:00,https://twitter.com/rasbt/status/1462831971437092868,@__mharrison__ Wow awesome! Congrats! Would make a great holiday gift (*adding it to my wishlist*)
6982,@rasbt,2021-11-22 15:14:56+00:00,https://twitter.com/rasbt/status/1462801779981234178,"""NeurIPS 2021 finally accepted submissions statistics"" from https://t.co/kNcwbAUKUY (summarized via https://t.co/lAfiXiVRj7). Wow, it looks like 199 out of the 298 papers (that is, 2/3!!!) accepted by group 1 would have been rejected by group 2. https://t.co/z5hdaqWb77"
6983,@rasbt,2021-11-22 13:26:22+00:00,https://twitter.com/rasbt/status/1462774459262279687,"@chriswolfvision @openreviewnet Yeah, that‚Äôs not a good look. Can be perceived as shaming the authors for not making the deadline."
6984,@rasbt,2021-11-22 13:08:18+00:00,https://twitter.com/rasbt/status/1462769910833102848,"@MihiretuKebede1 Yeah. For me, the most important feature is collaborative editing of the same document at the same time (no more Dropbox workarounds or emailing each other manuscripts)"
6985,@rasbt,2021-11-22 13:06:16+00:00,https://twitter.com/rasbt/status/1462769401460137986,"@usmanpirzada @iScienceLuvr Huh, maybe not on macOS. I am 100% certain this didn't exist a few months ago. :)"
6986,@rasbt,2021-11-22 13:05:26+00:00,https://twitter.com/rasbt/status/1462769190323036164,"@allonsygamma @akidTwit Sadly, it does matter a lot. It is usually triggers a resubmit if you violate the draft formats -- journals would give you either a LaTeX or a Word template. However, the paper usually still undergoes some final formatting before publication, so it's not all up to the writer"
6987,@rasbt,2021-11-22 03:51:01+00:00,https://twitter.com/rasbt/status/1462629667689672704,"@MeninderP I use both actually. For personal drafting I mostly write in Markdown via Typora, and for collaborative drafts often in Word (but also Google Docs or Overleaf). For (near) final papers, I almost always use LaTeX (collaborative Overleaf, otherwise TexPad)"
6988,@rasbt,2021-11-22 00:39:50+00:00,https://twitter.com/rasbt/status/1462581552173535240,"@allonsygamma Totally true. I would only use it for a first draft where the format doesn't matter, not for the final version."
6989,@rasbt,2021-11-22 00:26:52+00:00,https://twitter.com/rasbt/status/1462578291454455808,"@allonsygamma Ha, maybe. Word is a great tool for collaborative drafting though. It's easier to handle than having your manuscript on Github if people need to edit at the same time. Ok, Overleaf works great for that too, but Word has a better comment and tracked changes function in my opinion."
6990,@rasbt,2021-11-22 00:08:42+00:00,https://twitter.com/rasbt/status/1462573717968629761,@nevgeniev 16.55 https://t.co/2xN2XSYh2B
6991,@rasbt,2021-11-21 23:59:14+00:00,https://twitter.com/rasbt/status/1462571336925159424,"@iScienceLuvr I am pretty sure this didn't work (or only rudimentary) as of last month. At least on Mac. When I typed ""\sum_{i=1}^n"" I got something that looked more like this: https://t.co/OnkDSzYc0p"
6992,@rasbt,2021-11-21 23:48:15+00:00,https://twitter.com/rasbt/status/1462568573738565636,"Holy cow, TIL that MS Word allows me to write math in LaTeX now: https://t.co/DoFjkOxbbh"
6993,@rasbt,2021-11-21 19:17:20+00:00,https://twitter.com/rasbt/status/1462500394869866496,"It's complicatedüòÖ. Have memories using pens and scissors with my left hand, but the kindergarten teacher taught me that this was wrong and I was supposed to use my right hand. Nowadays, I use the computer mouse with my right hand, so I am not a left-handed ML scientist?"
6994,@rasbt,2021-11-21 15:11:50+00:00,https://twitter.com/rasbt/status/1462438613069803532,"@oliverguhr @ykilcher Anyways, thanks for making these videos and calling out this quackery"
6995,@rasbt,2021-11-21 15:09:52+00:00,https://twitter.com/rasbt/status/1462438117646946311,"@oliverguhr @ykilcher Whoa, this just makes me sad. Similar to desk rejects for papers, there needs to be a desk reject for reviews.  
Anyways, ""I recommend to read some [open reviews] to try to make this [review] more clearly"""
6996,@rasbt,2021-11-21 13:48:57+00:00,https://twitter.com/rasbt/status/1462417754225532932,"@OlivierMa2016 On a higher level, when I looked at AlphaFold2, I couldn't find any training code. Nor are there any instructions in the repo. May have overlooked sth, but it is not obvious to me how you take the existing code &amp; train the model. In contrast, there is a clear train_openfold.py :)"
6997,@rasbt,2021-11-20 18:25:25+00:00,https://twitter.com/rasbt/status/1462124940984041476,"@larispardo @mervenoyann Hah, yeah, after this semester is over and i have more time, i was planning to make some additional vids over the break. So, subscribe &amp; stay tuned :)"
6998,@rasbt,2021-11-20 18:24:16+00:00,https://twitter.com/rasbt/status/1462124650901745665,"@mervenoyann Yeah, exactly :). Actually, if I remember correctly, Theano did ""real"" convolution. Not that it matters in DL though :). My guess is PyTorch wanted to save this additional flipping step."
6999,@rasbt,2021-11-20 18:11:50+00:00,https://twitter.com/rasbt/status/1462121523465142272,"@mervenoyann Haha, yeah. One of the two, ""Cross-correlational neural nets doesn't roll off the tongue"" or convolutions can be implemented more conveniently via cross correlation if you rotate the weights. Made a nit-picking video about this some time ago :) https://t.co/QI9uDYUzsL"
7000,@rasbt,2021-11-20 17:58:34+00:00,https://twitter.com/rasbt/status/1462118183880511497,@CSProfKGD I see! Thanks! Let us know what you think and whether you recommend it after you finished it. Looking for things for the holiday gift ideas/wishlist
7001,@rasbt,2021-11-20 17:24:54+00:00,https://twitter.com/rasbt/status/1462109713173291023,@CSProfKGD That looks like an interesting one! Does it have figures or is it purely text based?
7002,@rasbt,2021-11-20 16:24:14+00:00,https://twitter.com/rasbt/status/1462094441976586240,"@TaliaRinger Wow, that's actually pretty cool! It's probably a great feeling to be at the forefront of an emerging important field! Keeping my fingers crossed that your project gets funded! ü§û"
7003,@rasbt,2021-11-20 16:09:20+00:00,https://twitter.com/rasbt/status/1462090693967552529,@ykilcher Whoa! That's an example from the natural adversarial objects dataset? (https://t.co/eLIFeL2zHq)
7004,@rasbt,2021-11-20 16:07:15+00:00,https://twitter.com/rasbt/status/1462090171831177218,"@TaliaRinger Enjoy your vacation! You can be proud to have made the grant deadline. That's actually a big feat. I remember that in my first semester, I didn't even start writing one."
7005,@rasbt,2021-11-20 13:49:09+00:00,https://twitter.com/rasbt/status/1462055416762970112,"@zacharylipton And there are even more exciting times ahead, like ‚Äúcalling quackdom‚Äù on this one"
7006,@rasbt,2021-11-20 13:21:07+00:00,https://twitter.com/rasbt/status/1462048359573774341,"@shashankr27 @ivenzor Based on the issue tracker, often, it can happen if you have multiple environments (not specific to mlxtend but in general). Or are you perhaps using Google Colab? I think they have an older version of mlxtend installed. In any case, please feel free to post on the issue tracker"
7007,@rasbt,2021-11-19 23:46:00+00:00,https://twitter.com/rasbt/status/1461843229737984004,@JFPuget @philipvollet Based on what I heard he blocks lots of people  ü§î
7008,@rasbt,2021-11-19 19:25:11+00:00,https://twitter.com/rasbt/status/1461777595163455500,"Wow, having read the AlphaFold2 paper recently, that's no small feat. In contrast to the official implementation, this OpenFold PyTorch &amp; PyTorch Lightning implementation is also trainable :)"
7009,@rasbt,2021-11-19 19:07:39+00:00,https://twitter.com/rasbt/status/1461773182810177544,"That's what I love about the ML community on Twitter. Was wondering if there's a tool to compute CO2 emissions based on just GPU type, training time, and cloud provider location, and it only took a few seconds for someone to send me a link for exactly that :)"
7010,@rasbt,2021-11-19 19:00:25+00:00,https://twitter.com/rasbt/status/1461771360955473925,"@SashaMTL @julien_c @abhi1thakur @mmitchell_ai @huggingface Perfect, this was exactly what I was looking for. Thanks so much!"
7011,@rasbt,2021-11-19 18:58:47+00:00,https://twitter.com/rasbt/status/1461770948571451398,"@julien_c @SashaMTL @abhi1thakur @mmitchell_ai @huggingface Out of curiosity, if I wanted to add info on that to a research paper, how do I go about that if I only know GPU wattage, training time per model, and the AWS region my instance was located. Is there a tool/resource to calculate carbon/CO2 emissions?"
7012,@rasbt,2021-11-19 15:51:09+00:00,https://twitter.com/rasbt/status/1461723731580051469,"@An_Indian_Otaku @vmirly Hope you like it! Btw the accompanying code can be found here: https://t.co/AvmasMevp3 , and don't hesitate to reach out if you have any questions!"
7013,@rasbt,2021-11-19 15:25:22+00:00,https://twitter.com/rasbt/status/1461717242232643588,"@drugmonkeyblog @Namnezia @Metabo_Dave @alt_dave_smith @IVLRose yes, you are right, but no matter the setting, I personally couldn't get it to taste well. I mean it is drinkable if you are traveling, but it's not something that I particularly enjoy."
7014,@rasbt,2021-11-19 15:11:11+00:00,https://twitter.com/rasbt/status/1461713674008150016,"@Namnezia @drugmonkeyblog @Metabo_Dave @alt_dave_smith @IVLRose Yes, that's what I meant with European style. I can second that Keurig produces weak and watery tasting coffee. It seems like it is going more for quantity (huge volumes) rather than quality. It's basically Starbucks coffee vs small Italian cafe restaurant coffee"
7015,@rasbt,2021-11-19 15:02:04+00:00,https://twitter.com/rasbt/status/1461711379459723277,"@drugmonkeyblog @Namnezia @Metabo_Dave @alt_dave_smith @IVLRose It's about how it's brewed. Based on the Keurig machines I tried, it was basically drip coffee. It tasted horrible."
7016,@rasbt,2021-11-19 14:46:59+00:00,https://twitter.com/rasbt/status/1461707584235266051,"@Namnezia @Metabo_Dave @alt_dave_smith @IVLRose Yes, this. Also, once you tried Nespresso, you probably want to get rid of the Keurig for good."
7017,@rasbt,2021-11-19 14:45:54+00:00,https://twitter.com/rasbt/status/1461707311270047746,"@Metabo_Dave @Namnezia @alt_dave_smith @IVLRose No worries, Keurig and Nespresso are worlds away."
7018,@rasbt,2021-11-19 14:44:25+00:00,https://twitter.com/rasbt/status/1461706938304110601,"@Namnezia @alt_dave_smith @IVLRose @Metabo_Dave Huh, didn't know that, thanks! Haha, but before I get into that I have to work a bit on my backlog ... Have a hard time resisting when traveling and seeing locally roasted coffee (https://t.co/ftZl6EVXZE)"
7019,@rasbt,2021-11-19 14:34:20+00:00,https://twitter.com/rasbt/status/1461704397101146114,"@Namnezia @alt_dave_smith @IVLRose @Metabo_Dave Yes! I actually have nespresso machine and love it. The coffee definitely tastes more European, too. Haha, with my coffee consumption, it's maybe not the smartest choice budget-wise though :)"
7020,@rasbt,2021-11-19 14:16:10+00:00,https://twitter.com/rasbt/status/1461699827339829249,@tunguz @philipvollet Of course. Someone debunking bogus health and fitness claims could be bad for business.
7021,@rasbt,2021-11-19 13:57:38+00:00,https://twitter.com/rasbt/status/1461695164586643457,@alt_dave_smith @IVLRose @Metabo_Dave Aeropress is really good. I used that almost exclusively for a year. (Now using a coffee automat for convenience but I still bring along my aeropress &amp; little grinder on trips)
7022,@rasbt,2021-11-19 13:33:53+00:00,https://twitter.com/rasbt/status/1461689187464318978,"@tunguz @philipvollet I think it was the 4 miles every 4 hours for 48 hours thing. When he was promoting it, I mentioned it sounded dangerous"
7023,@rasbt,2021-11-19 13:20:46+00:00,https://twitter.com/rasbt/status/1461685886719086592,@philipvollet Followed him back then and used to listen to the podcast when I saw that he had interesting guests. Actually some interviews were really good although maybe a tad to esoteric and romantic for me taste. That being said he blocked me a while back so I haven‚Äôt seen his feed lately
7024,@rasbt,2021-11-19 13:13:18+00:00,https://twitter.com/rasbt/status/1461684005967912963,@Metabo_Dave Probably from the personal travel fund
7025,@rasbt,2021-11-19 13:10:53+00:00,https://twitter.com/rasbt/status/1461683399320612868,"@mmbronstein @lawrennd On paper (no pun intended) that sounds nice. But as someone who likes tinkering and coming up with ideas, doesn‚Äôt life get incredibly boring then?"
7026,@rasbt,2021-11-19 13:01:55+00:00,https://twitter.com/rasbt/status/1461681141262475272,@zacharylipton Where you refer to social media as in ‚Äúin public‚Äù or ‚Äúin private‚Äù ?ü§îü§î (kind of works both ways)
7027,@rasbt,2021-11-18 17:59:43+00:00,https://twitter.com/rasbt/status/1461393696675540999,"@SaravananStat I see. PyTorch M1 GPU support is still a few months away based on the recent Gh discussion I saw. However, you can train simple models on the CPU w/o problem. E.g., the examples in this documentation are all created on my M1 laptop because I was too lazy to log into my server :)"
7028,@rasbt,2021-11-18 14:35:33+00:00,https://twitter.com/rasbt/status/1461342319052009473,"@TaliaRinger *general purpose in terms of if you have a large dataset and just need to go through some quick data processing or train a random forest baseline or so, you don't have to find workarounds when things don't fit into memory."
7029,@rasbt,2021-11-18 14:34:17+00:00,https://twitter.com/rasbt/status/1461341997961261060,"@TaliaRinger Regarding regular RAM, you probably don't need much. I'd say it probably only needs to be slightly larger than the combined GPU memory. If you have 2 x 3090, 64 Gb might be enough, but I would probably go with 128 so you can also use it as a general purpose computer as well."
7030,@rasbt,2021-11-18 14:31:31+00:00,https://twitter.com/rasbt/status/1461341303212548096,"@TaliaRinger I see. Yeah, the prices seem way up at the moment :(. Another option is to go with one GPU and add a second one later. I did that with one machine where I got a Titan V via the Nvidia GPU grant program and planned to add a second (similar) GPU later."
7031,@rasbt,2021-11-18 14:01:52+00:00,https://twitter.com/rasbt/status/1461333839150788610,"@TaliaRinger To get a ballpark price idea: https://t.co/UOi2CaDrts. I have one of their machines and it's rocksolid (running for 3 years without issue). I also have a custom build one (is ~30% cheaper), but assembling it and setting that up is much more work (a sysadmin did that for me)"
7032,@rasbt,2021-11-18 13:58:13+00:00,https://twitter.com/rasbt/status/1461332919935549440,"@TaliaRinger I would say $5k-$7k. For that, you can get a decent machine with 4 good GPUs without having to bother about job queues. That's what I did a few years ago. The machine is still great for prototyping and small experiments before scaling up to the more tedious-to-use cluster"
7033,@rasbt,2021-11-18 13:40:11+00:00,https://twitter.com/rasbt/status/1461328383598600203,"@oooctavian Looks like amazing work! Congrats! Just wanted to share it with my drug discovery colleagues, but do you have a link to the code to give it a try? Couldn't find it in the manuscript (wondering if I maybe overlooked it)"
7034,@rasbt,2021-11-18 13:29:13+00:00,https://twitter.com/rasbt/status/1461325623230615555,"@SaravananStat Oh it is! I am using PyTorch on the M1 since January. Back then, I had to compile from scratch, but now you can install it via conda. Here's a short ""how"": https://t.co/K0VIe2qui4"
7035,@rasbt,2021-11-18 13:26:57+00:00,https://twitter.com/rasbt/status/1461325054332047361,"@srchvrs Totally agree. Many real world datasets (especially comp bio, biomedicine, commerce, etc.) have ordinal targets :)"
7036,@rasbt,2021-11-18 01:39:06+00:00,https://twitter.com/rasbt/status/1461146915861577729,"@IvanYashchuk @DynamicWebPaige @quansightai Huge news! TensorFlow and PyTorch were a bit reinventing the wheel in terms of their underlaying array implementation (considering NumPy as a reference) -- ok, it was necessary for GPU support. But this move towards sharing building blocks sounds like a good idea!"
7037,@rasbt,2021-11-18 01:17:21+00:00,https://twitter.com/rasbt/status/1461141444958248962,"Excited to share our new work on ordinal regression w. neural nets. Remember CORAL :)? We got rid of the weight-sharing constraint. And it works better than CORAL! 

A manuscript draft: https://t.co/dJ3jgtBbQv 

And a user-friendly PyTorch code tutorial: https://t.co/ReJLp51Dlu"
7038,@rasbt,2021-11-17 15:53:05+00:00,https://twitter.com/rasbt/status/1460999442622992396,"@maosbot Hah, yeah! Reading resumes of Ph.D. program applicants these days is a very humbling experience :). (That being said, I am forever thankful that my former Ph.D. committee member @ctitusbrown got me into blogging about 1-2 years into my Ph.D. program)"
7039,@rasbt,2021-11-17 15:47:41+00:00,https://twitter.com/rasbt/status/1460998082460590087,"@isabellatromba @mndl_nyc That's an amazing repo, thanks for sharing!"
7040,@rasbt,2021-11-17 15:47:00+00:00,https://twitter.com/rasbt/status/1460997908342390791,@burkov similar to KNN
7041,@rasbt,2021-11-17 13:46:18+00:00,https://twitter.com/rasbt/status/1460967533717164038,"@KateandPie Right, good point. I think it's safe to say that due to the different max_depth restrictions, they will result in different trees. You can also see that based on the training accuracies (in the screenshot above) that they are different."
7042,@rasbt,2021-11-17 13:26:40+00:00,https://twitter.com/rasbt/status/1460962593447845892,"@msaoudallah scaling data was allowed. Btw, one of the top solutions was a BaggingClassifier with RBF-kernel SVM"
7043,@rasbt,2021-11-17 13:24:36+00:00,https://twitter.com/rasbt/status/1460962076214632456,"@GiorgioMantova I have never done this before but could look into it. First, I'd need a new Kaggle account since they blocked mine, haha"
7044,@rasbt,2021-11-17 13:23:48+00:00,https://twitter.com/rasbt/status/1460961871264202752,"@KateandPie Actually, they were very simple, short trees. It was very easy to overfit on that dataset, so keeping them short was probably key: https://t.co/kN4trQrXXv"
7045,@rasbt,2021-11-17 13:20:56+00:00,https://twitter.com/rasbt/status/1460961150334550025,@delai50 All of them use the same features. I looked at the solutions to confirm.
7046,@rasbt,2021-11-17 13:20:18+00:00,https://twitter.com/rasbt/status/1460960993778016257,"@mndl_nyc On a side note, while it's not a categorical dataset, I find CatBoost categorical support easier to use than others. XGBoost is the worst in that respect. https://t.co/4cQwKXjqZP"
7047,@rasbt,2021-11-17 13:19:10+00:00,https://twitter.com/rasbt/status/1460960707856551938,"@mndl_nyc I didn't benchmark it, but when I tried it, I didn't notice it being noticeably slower (but it well might be)."
7048,@rasbt,2021-11-17 13:16:28+00:00,https://twitter.com/rasbt/status/1460960026173005830,"@msaoudallah wow thanks for sharing! Yes, no feature engineering or selection (since those topics weren't covered in class yet; the focus was on cross-validation and hyperparameter tuning)"
7049,@rasbt,2021-11-17 02:06:41+00:00,https://twitter.com/rasbt/status/1460791471301398530,@tunguz I know right!? I almost spent like half a day on it when I made the HW and couldn't crack the 93%. That's why I set 92% as the threshold for full points on the HW. Getting 92% is easy. 92.5% is really hard already.
7050,@rasbt,2021-11-17 01:59:01+00:00,https://twitter.com/rasbt/status/1460789541703409664,@tunguz Really really stoked to see how it turns out https://t.co/MmpThL6YJ7
7051,@rasbt,2021-11-17 00:07:54+00:00,https://twitter.com/rasbt/status/1460761579067162629,"@ghdzjr @SFBART and not ""Bidirectional and Auto-Regressive Transformers"" which combines the ideas behind GPT and BERT :) https://t.co/sU7b6jUSdA"
7052,@rasbt,2021-11-16 22:42:39+00:00,https://twitter.com/rasbt/status/1460740124703141895,"@TheAIDev But according to this benchmark from yesterday, it will run much faster on the GPU :) https://t.co/53holkSk3M"
7053,@rasbt,2021-11-16 22:41:48+00:00,https://twitter.com/rasbt/status/1460739908591656963,"@TheAIDev It's still plenty fast on the M1 CPU though. I wouldn't run CNNs etc on it, but for simple MLPs and a simple CNN like LeNet, I actually got faster training performance compared to a GTX 1080Ti. Or in other words, the CPU version is great for prototyping."
7054,@rasbt,2021-11-16 22:40:20+00:00,https://twitter.com/rasbt/status/1460739542084902918,"@TheAIDev Ah, that one would only allow PyTorch &amp; PL to run on the CPU. The M1 GPU is not officially supported by PyTorch, yet. However, good new is that support is on the way: https://t.co/KP53mMk32r"
7055,@rasbt,2021-11-16 22:33:16+00:00,https://twitter.com/rasbt/status/1460737763846860803,"@tunguz yes, that's right. It's all based on the same test set provided in that notebook."
7056,@rasbt,2021-11-16 22:32:31+00:00,https://twitter.com/rasbt/status/1460737575249924106,"@waydegilliam Yeah, trying a lot of things myself, I found that randomized search randomized search with successive halving usually perform best. Grid search should give you optimal results due to it being an exhaustive search, but in practice, it restricts the parameter space too much"
7057,@rasbt,2021-11-16 20:27:17+00:00,https://twitter.com/rasbt/status/1460706056477282316,"@moo_hax Hard to say, there were 140 students, and we didn't count the number of times each method was used. But anecdotally, I think optuna was slightly more popular. I had provided starter codes for both optuna and hyperopt (https://t.co/9DSTSRF1xj)"
7058,@rasbt,2021-11-16 20:15:37+00:00,https://twitter.com/rasbt/status/1460703121592696839,"@DynamicWebPaige @github Big congrats, this is so exciting! Wishing you all the best in this amazing new role! ü•≥üéâü•Ç"
7059,@rasbt,2021-11-16 18:20:23+00:00,https://twitter.com/rasbt/status/1460674121801555968,"@TheAIDev Oh, good news is that's actually an easy one: (1) Get the latest miniforge from here: https://t.co/OKx3RDLEst. (3) ""conda install"" your typical packages (3) Then ""pip install pytorch_lightning"" https://t.co/PRAYJIDtEa"
7060,@rasbt,2021-11-16 17:56:08+00:00,https://twitter.com/rasbt/status/1460668020150489099,"This was on the recent 13611-example dry bean dataset from 2020 (https://t.co/H7iLW6RKE0). If you want to run your favorite method for comparison, the dataset splits are given in the starter code here: https://t.co/I2ed3CI27r"
7061,@rasbt,2021-11-16 17:56:08+00:00,https://twitter.com/rasbt/status/1460668018674053123,"Also, neither Bayesian optimization implementation  (via Optuna nor Hyperopt) gave better results than say randomized search or grid search (assuming grid search has a sparser grid)"
7062,@rasbt,2021-11-16 17:56:07+00:00,https://twitter.com/rasbt/status/1460668017126395910,"Baseline accuracy via KNN was 80%, via Random forest 91%. Big surprise, 
(1) the ensemble vote classifier from mlxtend (with 3 DTs) came out on top; 
(2) Regular gradient boosting outperformed recent GBM implementations;
(3) Catboost &gt; LightGBM &amp; XGboost on non-categorical data"
7063,@rasbt,2021-11-16 17:56:07+00:00,https://twitter.com/rasbt/status/1460668015213744132,"(Of course) XGBoost does not always win on tabular datasets. Made a HW where students got to tinker w.  hyperparam tuning techniques (grid search, randomized search, Hyperopt, Optuna, successive halving) and algos (GBMs and everything in scikit-learn + mlxtend). Top-10 results: https://t.co/aq88Uw5dkF"
7064,@rasbt,2021-11-15 13:20:09+00:00,https://twitter.com/rasbt/status/1460236179161366539,"@DrGroftehauge @paul_rietschka Yeah, this sounds like how deep learning was usually taught: make the batch size as big as you can given GPU memory constraints. In theory, this makes sense,  though, in practice, I found that this isn't always ideal. Like with so many things, it needs to be experimented with"
7065,@rasbt,2021-11-15 01:44:35+00:00,https://twitter.com/rasbt/status/1460061132044095490,"@jbohnslav yeah, luckily this should only involve changing default params"
7066,@rasbt,2021-11-15 01:21:37+00:00,https://twitter.com/rasbt/status/1460055354713198603,"@paul_rietschka @DrGroftehauge On that note, I remember the paper ""Don't Decay the Learning Rate, Increase the Batch Size"" (https://t.co/CojfzU2ufx). Personally, this never really worked well for me though. Any thoughts?"
7067,@rasbt,2021-11-14 21:17:06+00:00,https://twitter.com/rasbt/status/1459993820196741125,"There was this impressive adversarial attack through simply downscaling an image that worked because of the buggy resizing impl. across deep learning frameworks (https://t.co/L8yv4TZIBA). Thankfully, as someone showed here (https://t.co/VXXHnmAbPn), this can easily be fixed :) https://t.co/RcXljaqUin"
7068,@rasbt,2021-11-14 17:54:47+00:00,https://twitter.com/rasbt/status/1459942902587613186,@b6n This!
7069,@rasbt,2021-11-14 16:37:37+00:00,https://twitter.com/rasbt/status/1459923485803925504,"@J_P_Raymond Oh yeah, sure! The authors also acknowledge that this is a particular case of scenario. (And they do also have a separate analysis on MCC-F1 AUCs.) https://t.co/DRPlwR9tup"
7070,@rasbt,2021-11-14 16:17:28+00:00,https://twitter.com/rasbt/status/1459918414177263624,"@J_P_Raymond It could give you at least the information that, in a perfect world where your model behaves similar on the new data as on the test set, if you apply that particular threshold you selected, you can expect that number of TP, FP, etc. (as summarized by your favorite metric)"
7071,@rasbt,2021-11-14 16:11:40+00:00,https://twitter.com/rasbt/status/1459916955314528260,"@J_P_Raymond Yeah, that is often true. But usually you don't want to over-interpret the scores (e.g., models tend to be overconfident on out-of-distribution data). And often you have to commit to a single threshold in practice."
7072,@rasbt,2021-11-14 16:01:58+00:00,https://twitter.com/rasbt/status/1459914513256439814,"3/3 once you are almost happy with the model, try out some learning rate schedulers to squeeze out some extra performance points. In my experience, learning rate schedulers need a lot of care, and you can cause more harm than good if not careful, so I would create baselines first"
7073,@rasbt,2021-11-14 16:01:58+00:00,https://twitter.com/rasbt/status/1459914512191139841,"2/3 It's a bit easier to find a well-working learning rate with adaptive LR methods such as Adam (compared to SGD). And my strategy is usually to find a good baseline learning rate, do some additional experiments, and then ..."
7074,@rasbt,2021-11-14 16:01:57+00:00,https://twitter.com/rasbt/status/1459914510735659020,"That's a very effective figure. Personally, I find that the learning rate is among the most important hyperparameters 1/3"
7075,@rasbt,2021-11-14 13:54:29+00:00,https://twitter.com/rasbt/status/1459882428860882955,"@vboykis I have a personal wiki based on DokuWiki. Free and can be self hosted if you already have a server. Otherwise, if you prefer a standalone app, I think Obsidian is what the cool kids use these days"
7076,@rasbt,2021-11-14 13:48:28+00:00,https://twitter.com/rasbt/status/1459880917472886787,"@hardmaru ‚ÄúWe propose a simple scheme incorporating servers already available at CERN‚Äù ‚Äî&gt; would be more of a straight reject: ‚ÄúThe method sounds too simple, almost like a trick.‚Äù"
7077,@rasbt,2021-11-13 20:32:09+00:00,https://twitter.com/rasbt/status/1459620117529219074,"@denzil_correa @karpathy Yes, under such circumstances, everything would make more sense. There are arguments pro/con regarding preprint uploading. Leaving the discussion of whether that's good aside. If the article is already publicly available, the current social media ban is some sort of half-measure"
7078,@rasbt,2021-11-13 20:22:40+00:00,https://twitter.com/rasbt/status/1459617733704835073,"@denzil_correa @karpathy Sure, according to the guidelines, people who know the author names should not review then. But then we also have to keep in mind that we remove many of the most qualified reviewers from the pool."
7079,@rasbt,2021-11-13 20:21:37+00:00,https://twitter.com/rasbt/status/1459617467655929858,"@denzil_correa @karpathy I see! If that's the case, that seems reasonable. But like I mentioned, the chance not knowing the author names is really slim these days, because if the paper is related to your area of expertise, chances are you already saw that paper on arxiv, arxiv-sanity, Google Scholar etc."
7080,@rasbt,2021-11-13 19:57:13+00:00,https://twitter.com/rasbt/status/1459611327685668870,"@denzil_correa @karpathy I.e., if the reviewers detect flaws, they would not mention them during peer review because they fear some retribution by the well-known labs? Doesn't the reviewers' anonymity protect against that? And if not, how does not knowing the authors' names help protect the reviewer?"
7081,@rasbt,2021-11-13 19:19:18+00:00,https://twitter.com/rasbt/status/1459601784431857668,@leonpalafox @karpathy So it's basically more like a concert ;)
7082,@rasbt,2021-11-13 18:27:58+00:00,https://twitter.com/rasbt/status/1459588865824591874,@leonpalafox @karpathy Whoa. That's to improve focus so that people attending the conference don't get distracted? Or because sharing the unfiltered information could be dangerous to the public? üôÉ
7083,@rasbt,2021-11-13 18:19:17+00:00,https://twitter.com/rasbt/status/1459586681041035268,"@karpathy Just happened to me last month that Google Scholar notified me about an interesting paper on arxiv that cited ours, and a double-blind conference asked me to review it a week later. So much for double blind. (No worries, I notified the chairs and didn't review)."
7084,@rasbt,2021-11-13 18:18:03+00:00,https://twitter.com/rasbt/status/1459586370415087619,"@karpathy Yeah, it seems a bit weird to put up guidelines or bans that try to undo the internet. Beyond social media, we also use services that recommend related or interesting papers to us, so double-blind doesn't really make that much sense anymore either."
7085,@rasbt,2021-11-13 17:44:29+00:00,https://twitter.com/rasbt/status/1459577924647014407,"And as we have seen in the example above, this is not true for the BA. However, BA gives us a better idea about whether a classifier is better than random guessing."
7086,@rasbt,2021-11-13 17:44:29+00:00,https://twitter.com/rasbt/status/1459577922646327314,"Check out the paper for more examples. To get to the summary, MCC is only high if all 4 rates are high: True positive R, True negative R, Positive predicted value (precision): TP / (TP+FP), and negative predicted value: TN / (TN+FN)."
7087,@rasbt,2021-11-13 17:44:28+00:00,https://twitter.com/rasbt/status/1459577920964419584,11. Here is one extreme example. BA &amp; BM correctly identify that this classifier is much better than random guessing (MCC is not helpful for that here coz an MCC=0.0 indicates random guessing). But MCC tells us that there is a low correlation between predicted and true class https://t.co/3nstia7XA9
7088,@rasbt,2021-11-13 17:44:27+00:00,https://twitter.com/rasbt/status/1459577917911015438,"10. This thread is becoming rather long, so let me cut to the chase. Often, MCC is useful coz it only generates a high score if both classes (in a binary setting) get a lot of correct pred. The BA and BM are more useful for judging if a classifier is better at random guessing."
7089,@rasbt,2021-11-13 17:44:27+00:00,https://twitter.com/rasbt/status/1459577916011040771,"9. The BM and MC have a high correlation (Pearson correlation coefficient &gt; 0.98), and from that we can conclude that BA and MCC are also highly correlated https://t.co/PIzLuOcWRG"
7090,@rasbt,2021-11-13 17:44:26+00:00,https://twitter.com/rasbt/status/1459577911841808398,"8. Actually, the authors focus more on the Biomarker Informedness (BM) instead of BA, which makes the discussion a bit more convoluted. The BM is a rescaled BA:
BA = (BM + 1)  / 2"
7091,@rasbt,2021-11-13 17:44:25+00:00,https://twitter.com/rasbt/status/1459577909346144256,"7. An interesting tidbit is that a BA &gt; 0.5 corresponds to a positive MCC, and a BA &lt; 0.5 corresponds to a negative MCC. https://t.co/DymO7kD5IK"
7092,@rasbt,2021-11-13 17:44:25+00:00,https://twitter.com/rasbt/status/1459577906242408455,"The following is based on the follow-up paper that the authors sent me: ""The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation"" (https://t.co/0gq9vOiizE)"
7093,@rasbt,2021-11-13 17:44:24+00:00,https://twitter.com/rasbt/status/1459577904753520641,"Now, back to comparing Matthews correlation coefficient (MCC) and balanced accuracy (BA). We discussed how MCC works last week. For reference: https://t.co/ketCx7YzL7. In a nutshell, BA and MCC show different things and both can be useful."
7094,@rasbt,2021-11-13 17:44:24+00:00,https://twitter.com/rasbt/status/1459577902635364352,"4. On a side note, the true positive rate (TPR) is also known as ""sensitivity"" or ""recall."" So, in this case, we can think of the balanced accuracy as the macro-averaged recall: https://t.co/g6RT0bcLW0"
7095,@rasbt,2021-11-13 17:44:23+00:00,https://twitter.com/rasbt/status/1459577898533335043,"3. Now, the more common way to compute the balanced accuracy is as the arithmetic mean of the true positive rate (TPR) and true negative rate (TNR). For the multi-class case we average over the TPRs: https://t.co/lpViOY8v6g"
7096,@rasbt,2021-11-13 17:44:22+00:00,https://twitter.com/rasbt/status/1459577894594875392,"3. Then, one way of computing the balanced accuracy is to consider one class as the positive class and the remaining classes as the negative class. I later learned that this is called ""average per-class accuracy"" https://t.co/QdcWfRIdsj"
7097,@rasbt,2021-11-13 17:44:21+00:00,https://twitter.com/rasbt/status/1459577890333466625,"2. We can easily generalize the (regular) accuracy to a multi-class setting by just summing over all the correct predictions in the numerator, that is, summing the diagonal entries in a confusion matrix: https://t.co/0sJLIYNfJC"
7098,@rasbt,2021-11-13 17:44:20+00:00,https://twitter.com/rasbt/status/1459577886978019331,"1. First of all, let's define balanced accuracy, which is useful for imbalanced class problems. There are at least two  definitions that I am aware of. For reference, the regular accuracy is defined as the number of correct predictions (TP + TN) over all n datapoints: https://t.co/fBKwKBysDH"
7099,@rasbt,2021-11-13 17:44:19+00:00,https://twitter.com/rasbt/status/1459577884100767753,"Last week, we compared the Matthews correlation coefficient (MCC) with Precision, Recall, and F1 score when comparing Machine Learning models and saw that the MCC can be much more robust towards edge cases. But how does it fare against balanced accuracy? üßµ"
7100,@rasbt,2021-11-13 15:47:02+00:00,https://twitter.com/rasbt/status/1459548367491579907,"@__mharrison__ Thought of live training, but there could be a perception bias here because ""live training"" is the only one that contains the word ""training"". Maybe calling it ""live workshop"" would be more neutral for the sake of the survey?"
7101,@rasbt,2021-11-13 14:29:19+00:00,https://twitter.com/rasbt/status/1459528810374832134,@ducha_aiki Conventional
7102,@rasbt,2021-11-13 14:20:57+00:00,https://twitter.com/rasbt/status/1459526702107877382,"@amy_tabb This sounds reasonable. And I hope they come up with a better system next year. Also, double-blind doesn‚Äôt really work in the age of the internet, so right now the current system feels like a half-measure"
7103,@rasbt,2021-11-12 21:58:26+00:00,https://twitter.com/rasbt/status/1459279444460326913,"@radekosmulski @vboykis @tunguz @ykilcher @JFPuget @bhutanisanyam1 @ptrblck_de ‚úÖas enthusiastic as @DynamicWebPaige 
‚úÖas philosophical as @fchollet
‚úÖas wise as @hardmaru
‚úÖas motivating as @mervenoyann"
7104,@rasbt,2021-11-12 20:39:04+00:00,https://twitter.com/rasbt/status/1459259472338169861,"@DynamicWebPaige Hah, same boat re NFTs so far. I see them as modern equivalent of the autographed book or baseball card. And I can see the appeal behind it from the perspective of a collector, fan, or investor. But for me personally, the regular copy without signature works just fine :)"
7105,@rasbt,2021-11-12 17:12:59+00:00,https://twitter.com/rasbt/status/1459207607613284359,"@TheZachMueller @huggingface Wow, that's mega exciting! Big congrats!"
7106,@rasbt,2021-11-12 03:21:23+00:00,https://twitter.com/rasbt/status/1458998331179507714,@aureliengeron @fchollet Thanks! For some reason I thought it evolved from it.
7107,@rasbt,2021-11-12 02:46:01+00:00,https://twitter.com/rasbt/status/1458989431172517907,"@Tw1XDy @RichardSocher @ProductHunt Yeah, there is a number of topics that I thought were covered in more depth elsewhere (mostly traditional blogs), but also because it's paywalled more often than not."
7108,@rasbt,2021-11-12 00:25:41+00:00,https://twitter.com/rasbt/status/1458954113929129984,"@fchollet Maybe naive question, but why that name? Is it named after running deep belief systems in a distributed computing setting? If so, why doesn't TensorFlow have any RBM implementations/building blocks (or does it?)"
7109,@rasbt,2021-11-12 00:10:59+00:00,https://twitter.com/rasbt/status/1458950415081480192,"@RichardSocher @ProductHunt Big congrats. Just gave it a try and it works exceptionally well. Didn't expect it that snappy. Overall, I am very impressed. (Little feature request, add Medium to the ""My preferred sources"" so I can deprioritize it when searching for ML contents üòÖ)"
7110,@rasbt,2021-11-12 00:03:36+00:00,https://twitter.com/rasbt/status/1458948557948522502,"@TaliaRinger or ""open-source software"" vs ""open source"" üò¨"
7111,@rasbt,2021-11-11 23:47:59+00:00,https://twitter.com/rasbt/status/1458944628053454850,"@paul_rietschka Oh nice, had no idea!"
7112,@rasbt,2021-11-11 23:42:44+00:00,https://twitter.com/rasbt/status/1458943306793201664,@dvilasuero @rubrixml Oh nice! This looks simple and elegant. Also nice hands-on text classification example. CC @Kaiping_Chen
7113,@rasbt,2021-11-11 23:35:51+00:00,https://twitter.com/rasbt/status/1458941572209328137,"@paul_rietschka Curious to hear what services they actually offer. I know Amazon Turk etc., but it isn't it a diff approach like focusing on labeling scale &amp; consistency rather than labeling based on model performance? I would say they don't have to exclusive. Just curious."
7114,@rasbt,2021-11-11 23:32:24+00:00,https://twitter.com/rasbt/status/1458940704697298944,"@burkov Wouldn't it be more like ""Stick to the notebook"" than ""Start it in a notebook""?"
7115,@rasbt,2021-11-11 19:53:08+00:00,https://twitter.com/rasbt/status/1458885526040293380,"@themintsv Yes, totally. The nice thing is self-supervised learning and increasing your labeled dataset size for fine-tuning are not mutually exclusive :)"
7116,@rasbt,2021-11-11 19:38:04+00:00,https://twitter.com/rasbt/status/1458881733391265803,"@mattturck This is great. Never understood the need for autocropping, and I was always fighting with workarounds (pasting figures into slides and the screenshotting with background) so that the autocropping would display the info I actually wanted to show: https://t.co/HcGKKCz0Rn"
7117,@rasbt,2021-11-11 19:23:56+00:00,https://twitter.com/rasbt/status/1458878176449503235,"@alexpghayes I haven't! And this looks super nice! Thanks for the suggestion, that's actually great timing (with respect to class projects being due soon and students looking for ways to more efficiently inspect their data and improve model performance)"
7118,@rasbt,2021-11-11 19:20:42+00:00,https://twitter.com/rasbt/status/1458877364327358472,"*And no, self-supervised learning &amp; pre-training aren't the answer for everything. Or at least not an efficient answer ;) https://t.co/HcGKKCz0Rn"
7119,@rasbt,2021-11-11 19:17:31+00:00,https://twitter.com/rasbt/status/1458876561629888518,"Active learning is one of these things that I wish was easier to use in practice. Labeling data is always the annoying part, so if you have a dataset and this is necessary, why not doing it more effectively using active learning to suggest examples worthwhile labeling https://t.co/3ktIEW1V5y"
7120,@rasbt,2021-11-11 19:15:06+00:00,https://twitter.com/rasbt/status/1458875951224434709,"@HamelHusain Integrating this feature into GitHub is about time. And in the meantime, a shoutout to the Review Notebook App for GitHub (https://t.co/cNLX5Q79j9). Have been using it for a couple of year and works great."
7121,@rasbt,2021-11-11 18:59:34+00:00,https://twitter.com/rasbt/status/1458872043227783186,"@tymwol @choldgraf Forgot with oss project it was, but there was one that was automatically closing Issues or PRs if they were too old. Not sure why, but probably to tidy up the trackers and maintain focus? So, I can imagine discussing/finding alternatives could be useful"
7122,@rasbt,2021-11-11 18:53:06+00:00,https://twitter.com/rasbt/status/1458870416676687880,"@siminaboca 3G used to be pretty high speed internet. Now, you can't even use Siri, open a website, or search an address on maps when on 3G"
7123,@rasbt,2021-11-11 18:48:31+00:00,https://twitter.com/rasbt/status/1458869264987873285,"@ducha_aiki But in earnest, having moderated/curated comments on arxiv could be super useful. Or even just the orig reviews. It could actually save a lot of time if you read papers and can see potential weaknesses or flaws. The paper can still be useful if flawed but it would be good to know"
7124,@rasbt,2021-11-11 18:45:30+00:00,https://twitter.com/rasbt/status/1458868505114206213,@ducha_aiki üòá
7125,@rasbt,2021-11-11 18:43:38+00:00,https://twitter.com/rasbt/status/1458868035687747593,@ducha_aiki Rhetorical question üòâ. The same things: correct &amp; useful üôÇ
7126,@rasbt,2021-11-11 18:41:06+00:00,https://twitter.com/rasbt/status/1458867395213373444,"To me, as a reader, the two most important things are (1) is the paper correct or not &amp; (2) is the paper useful to me. In that order. One might say the more eyes on the paper the better (finding potential flaws, suggesting improvements)"
7127,@rasbt,2021-11-11 18:26:40+00:00,https://twitter.com/rasbt/status/1458863765924028416,"""Gradients are Not All You Need"" -- Almost missed this paper due to the boring titleüôÉ, but there is actually a quite interesting paper behind it! Highlights issues when computing gradients through dynamic systems and when this is not a good idea (Jacobian has large eigenvalues)"
7128,@rasbt,2021-11-11 17:33:51+00:00,https://twitter.com/rasbt/status/1458850472006193160,"@pacifix001 @TheAIDev @LucaAmb Yeah. You can actually think of a naive Bayes model as a Bayesian network, like the extreme case with total conditional independence. I.e., it would look like that. https://t.co/BgDUWpuaMu"
7129,@rasbt,2021-11-11 15:03:29+00:00,https://twitter.com/rasbt/status/1458812632278966272,"@ludwig_stumpp Yeah, maybe. Actually LDA and naive Bayes were the two first methods I learned about before getting in ML (based on a statistical pattern rec. class and Duda, Hart, and Stork's excellent textbook)."
7130,@rasbt,2021-11-11 13:41:34+00:00,https://twitter.com/rasbt/status/1458792017958359049,"@EIFY Very interesting and I see the connection, but to me they are still totally different. It‚Äôs like random forests and dropout, there are some analogies but these are fundamentally different."
7131,@rasbt,2021-11-11 13:15:36+00:00,https://twitter.com/rasbt/status/1458785480795901959,@tymwol @LucaAmb I don't recall a specific paper re small data. But I remember seeing a paper where naive Bayes performed quite well in a specific comp bio application when the data was very noisy: https://t.co/MeEyaLWNgO https://t.co/GjkYiGCaOT
7132,@rasbt,2021-11-11 00:02:21+00:00,https://twitter.com/rasbt/status/1458585855694671876,"@paul_rietschka 2/2 The ""archaic ones"" are probably very useful for people who want to pursue a more theory-focused academic career. And courses should exist that teach you those. But I don't think this should be the general or intro ML courses."
7133,@rasbt,2021-11-11 00:00:58+00:00,https://twitter.com/rasbt/status/1458585507944964097,"@paul_rietschka Yes. It didn't mean to say that we shouldn't learn about these (SVMs etc.). But maybe they shouldn't be prioritized in the main intro courses. There is always a compromise, because we don't have time to teach everything in a course. 1/2"
7134,@rasbt,2021-11-10 23:59:00+00:00,https://twitter.com/rasbt/status/1458585012555718662,"@markroepke @bradleyboehmke Yap, in my classes, I try to cover all the basic tree-based ones (bagging, random forests, adaboosting, gradient boosting). Also try to analyze why they work in terms of bias-variance decomposition."
7135,@rasbt,2021-11-10 21:18:51+00:00,https://twitter.com/rasbt/status/1458544707626229760,"@BEBischof I have an explanation of gradient boosting, but not a deep theory lecture: https://t.co/v6XzRsp1hw"
7136,@rasbt,2021-11-10 19:47:08+00:00,https://twitter.com/rasbt/status/1458521628405637122,"@aBHInonymous Agree with the general sentiment! But try to google gradient boosting or xgboost. You'll mostly find tutorials on how to use it, or (for some reason) adaptive boosting explanations. SVMs are harder to grasp (esp if Lagrange multipliers are new) but there are many good books on it"
7137,@rasbt,2021-11-10 19:38:08+00:00,https://twitter.com/rasbt/status/1458519362554507269,"@LucaAmb that's true, I implemented the multinomial one back then but it was a rough implementation"
7138,@rasbt,2021-11-10 19:32:48+00:00,https://twitter.com/rasbt/status/1458518020133883906,"@LucaAmb Back then, there were only good of-the-shelf implementations for continuous or discrete features (at least in sklearn) and you couldn't mix them. Pretty sure R has some good implementations though?"
7139,@rasbt,2021-11-10 19:29:50+00:00,https://twitter.com/rasbt/status/1458517274550226945,"@waydegilliam Only taught a high-level intro once (https://t.co/v6XzRsp1hw), and don't have great resources handy. Maybe a good way to start would be Friedman's orig GBM paper, and then read the XGboost &amp; LightGBM papers to learn about the tricks &amp; heuristics that make it work well in practice"
7140,@rasbt,2021-11-10 19:25:24+00:00,https://twitter.com/rasbt/status/1458516156722130945,"@LukasBrausch @BEBischof Oh totally, but I have rarely seen those also outperform logistic regression and Random forests for example. Those I would not cut üôÉ"
7141,@rasbt,2021-11-10 19:24:16+00:00,https://twitter.com/rasbt/status/1458515872914546694,"@LucaAmb Yeah. I heard once (I think via Peter Norvig) that most stuff at Google was based on naive Bayes about 10 yrs ago. Naive Bayes was actually my go-to algo coz it was the first one I ever learned. But in practice, I never really found it perform better than say simple logistic reg"
7142,@rasbt,2021-11-10 19:21:09+00:00,https://twitter.com/rasbt/status/1458515085769519106,"@ph_singer Yes, Bayesian networks maybe. I think with structural EM it can even be feasible now when you don't know the structure. But naive Bayes is not really super useful coz you can't really interpret anything from it because it's such a ""wrong"" model due to the conditional independence"
7143,@rasbt,2021-11-10 19:13:49+00:00,https://twitter.com/rasbt/status/1458513243413041156,"@ph_singer Fair. In my lecture I put Bayesian methods (and naive Bayes) last. Always try to cover it but well stms we run out of time/lecture days. Feels like a pitty, but then I smtms think it's maybe okay. Tree-based methods, ensembles, and model evaluation are maybe more important today"
7144,@rasbt,2021-11-10 19:10:47+00:00,https://twitter.com/rasbt/status/1458512480280383490,@BEBischof My intro to ML has been via Bayesian methods (and naive Bayes) in a statistical Pattern Rec class. I agree that it's been a useful concept for intuition building and why certain things are hard or intractable and we rather use discriminative (vs generative) models for prediction
7145,@rasbt,2021-11-10 19:06:26+00:00,https://twitter.com/rasbt/status/1458511383146999814,Gradient boosting &amp; the XGboost implementation are one of the biggest comebacks and advances in non DNN-based machine learning. I am in favor (and would probably cut naive Bayes and SVMs).
7146,@rasbt,2021-11-10 18:55:16+00:00,https://twitter.com/rasbt/status/1458508572334215170,"@JCornebise hm, now I am wondering what scores we are looking at here. I think these are the unnormalized scores that go into the ""Recommendation: "" field."
7147,@rasbt,2021-11-10 18:50:14+00:00,https://twitter.com/rasbt/status/1458507307734683662,"@skoularidou oh yes, I agree. And another factor is also that they switched from CMT to OpenReview this year. (Afaik as I remember it was CMT last year)"
7148,@rasbt,2021-11-10 18:43:13+00:00,https://twitter.com/rasbt/status/1458505543241408517,"ICLR 2022 submissions and review scores via https://t.co/AKiEtYd1P7. Looks ""normal"" at first glance. And wow, given that the score scale goes up to 10, reviewers seem to be very critical. https://t.co/vQ6TlYH5gN"
7149,@rasbt,2021-11-10 18:03:48+00:00,https://twitter.com/rasbt/status/1458495623393652743,"@TaliaRinger Oh, and emails! When I started using Slack with my students, I found that it reduces the overhead a bit (because there is this unwritten law that emails tend to be more formal and can't be one sentence)"
7150,@rasbt,2021-11-10 13:57:07+00:00,https://twitter.com/rasbt/status/1458433543621726209,"@DynamicWebPaige You are doing everything right! Glad you are having a good time! And we really appreciate all your work, enthusiasm, and resources you share! It's contagious in a very positive sense!"
7151,@rasbt,2021-11-10 13:54:36+00:00,https://twitter.com/rasbt/status/1458432907018637315,"@fchollet Wow, 6 years already! I remember I was in grad school back then, just having learned Theano. And I was super excited going home that evening to check out and learn about TensorFlow. Happy Birthday!"
7152,@rasbt,2021-11-10 02:52:59+00:00,https://twitter.com/rasbt/status/1458266409004380161,"@burkov *Code review could not only help with ensuring reproducibility and accessibility, but it could also be a way of catching bugs that lead to accidentally misleading results, and it could also provide a useful feedback for helping researchers to improve their coding skills."
7153,@rasbt,2021-11-10 02:51:22+00:00,https://twitter.com/rasbt/status/1458266000365862912,"@burkov I do agree. And for those who upload code, it is not always obvious if/how it works -- not blaming though, because I know researchers are notoriously busy, and there is no substantial incentive. But it would perhaps be nice to have both paper and code reviewers for submissions."
7154,@rasbt,2021-11-10 02:47:36+00:00,https://twitter.com/rasbt/status/1458265054760026118,@TheZachMueller Tell us that you are into deep learning and video gaming without telling us that you are into deep learning and video gaming üôÉ
7155,@rasbt,2021-11-10 00:44:46+00:00,https://twitter.com/rasbt/status/1458234142215348225,@gupta_anik I remember from the Kaggle 2021 survey that TensorFlow is slightly ahead of PyTorch still. In the second plot you can see though that PyTorch is slightly growing whereas TensorFlow is slightly declining in use. https://t.co/2xYgZ2aQmA
7156,@rasbt,2021-11-10 00:41:07+00:00,https://twitter.com/rasbt/status/1458233221213298691,@gupta_anik I think this is counting implementations that come with research papers. It's hard to know the exact number of people using either framework across industry sectors because it's difficult to get data about that -- most don't share their code on GitHub
7157,@rasbt,2021-11-09 23:39:02+00:00,https://twitter.com/rasbt/status/1458217600526295047,"@ssshukla26 @gridai_ Thanks! And good question! I don't know the precise answer, but maybe @gridai_ can help. There's also a list of the openings here: https://t.co/FK87PK0FRo"
7158,@rasbt,2021-11-09 22:46:23+00:00,https://twitter.com/rasbt/status/1458204350711574529,@gisilvs Thanks! Must say that I tried really had to get by not using Rosetta 2 so far (since January 2021) üò¨
7159,@rasbt,2021-11-09 20:20:18+00:00,https://twitter.com/rasbt/status/1458167586873614338,"@simeneide Hah yeah, I think that's two unrelated headlines they tried to squeeze into a single slide"
7160,@rasbt,2021-11-09 20:19:43+00:00,https://twitter.com/rasbt/status/1458167439972253697,@gisilvs Unfortunately no. I am already happy about the 2.6 version in conda-forge üòÖ
7161,@rasbt,2021-11-09 14:48:55+00:00,https://twitter.com/rasbt/status/1458084188763086857,"@tunguz There may be exceptions (sensitive data, privacy of patients, etc.) but overall, I agree"
7162,@rasbt,2021-11-09 14:05:35+00:00,https://twitter.com/rasbt/status/1458073285292433415,"@roydanroy Anyways, even on the M1 CPU PyTorch runs super fast. For small networks (MLPs in particular) you can actually get faster training than on consumer grade GPUs such as 2080Ti :)"
7163,@rasbt,2021-11-09 14:03:57+00:00,https://twitter.com/rasbt/status/1458072872023375879,@roydanroy I think the problem it's not trivial is that you would have to explicitly design the backend support for that (like it was designed for cuda and openCL). It's also interesting to think about how/if things like .to(device) remain necessary because of the shared memory.
7164,@rasbt,2021-11-09 14:01:41+00:00,https://twitter.com/rasbt/status/1458072302336331778,"@roydanroy No, not yet (afaik). When I got the M1 Mac earlier this year, I compiled TensorFlow and PyTorch to run on it but this was only for CPU support (PS: you can now more conveniently use it via conda-forge). GPU support would probably take some significant rewrites"
7165,@rasbt,2021-11-09 13:55:40+00:00,https://twitter.com/rasbt/status/1458070788591046660,Glad that Sebastian's NLP newsletter is back! Awesome new edition with a focus on discussing the recent shift from single pre-training objectives to multi-task learning in the large language model space. And many helpful pointers to the relevant research papers.
7166,@rasbt,2021-11-09 12:37:41+00:00,https://twitter.com/rasbt/status/1458051165065605121,"@kaushik_bokka @gridai_ Thanks, looking forward to it!"
7167,@rasbt,2021-11-09 12:25:00+00:00,https://twitter.com/rasbt/status/1458047971208142852,"Great news from the reproducibility front via the State of AI 2021 report (https://t.co/9MMGd7IRNc): ""26% of research papers make their code available and 60% make use of PyTorch."" 26% doesn't sound like much, but it's almost doubled (up by 15%) compared to last year! https://t.co/CVZJqyq4ei"
7168,@rasbt,2021-11-08 23:35:08+00:00,https://twitter.com/rasbt/status/1457854228026769420,"@DavideChicco_it @Giuseppe_Jurman Your article was a great read. Hah, I have approx. one more week before teaching a lecture on evaluation metrics, and this follow-up comes just at the right time. Thanks for sharing (and writing!)"
7169,@rasbt,2021-11-08 23:33:24+00:00,https://twitter.com/rasbt/status/1457853793618604049,@_MarkConway_ @JFPuget @gridai_ @wes_kao @MavenHQ Thanks for the pointer!
7170,@rasbt,2021-11-08 23:27:56+00:00,https://twitter.com/rasbt/status/1457852415319986180,"@cbazodi @gridai_ Thanks, Christina!"
7171,@rasbt,2021-11-08 23:26:52+00:00,https://twitter.com/rasbt/status/1457852150780993540,"@Jeande_d @gridai_ Thanks so much for the kind words, Jean. This is so good to hear and motivates me to continue doing what I love :)"
7172,@rasbt,2021-11-08 23:25:17+00:00,https://twitter.com/rasbt/status/1457851748664676352,@ducnh279 @gridai_ It's really motivating to hear that it's useful :)
7173,@rasbt,2021-11-08 19:00:42+00:00,https://twitter.com/rasbt/status/1457785164570918914,"@JFPuget @gridai_ Oh I will miss the direct interaction with students for sure. On the other hand, we have seen that it is also very important to think beyond the traditional classroom setting and to find alternative ways of teaching. I am very excited about working on evolving that format"
7174,@rasbt,2021-11-08 18:37:41+00:00,https://twitter.com/rasbt/status/1457779372279033859,"@AnanyaHarsh @gridai_ Thanks, Ananya! Excited to be part of it!"
7175,@rasbt,2021-11-08 17:58:40+00:00,https://twitter.com/rasbt/status/1457769556303253504,@omarsar0 @gridai_ Thank you! This means a lot coming from you!
7176,@rasbt,2021-11-08 17:26:54+00:00,https://twitter.com/rasbt/status/1457761561746022403,"@NIkronic @gridai_ Thanks, Nikan! And what a small world :)"
7177,@rasbt,2021-11-08 17:26:05+00:00,https://twitter.com/rasbt/status/1457761355751165960,"@bhutanisanyam1 @gridai_ Thanks, Sanyam!"
7178,@rasbt,2021-11-08 16:33:50+00:00,https://twitter.com/rasbt/status/1457748204208934925,@apreshill @gridai_ Thanks so much for the kind words!
7179,@rasbt,2021-11-08 16:33:16+00:00,https://twitter.com/rasbt/status/1457748064555438087,"Have many ideas for educational AI &amp; deep learning contents that I am super excited about. Our broad goals are to create materials that are really worthwhile &amp; it'd be awesome to hear from you if there's something you are looking forward to re AI, DL, PyTorch &amp; @PyTorchLightnin"
7180,@rasbt,2021-11-08 16:18:05+00:00,https://twitter.com/rasbt/status/1457744241925447690,"Some personal news: I am thrilled to join @gridai_ as Lead AI Educator this coming January! After many incredible years in academia that I spent learning and teaching, I am excited about this opportunity to take my passion for developing educational material to the next level."
7181,@rasbt,2021-11-08 14:09:50+00:00,https://twitter.com/rasbt/status/1457711967666311169,"Q: ""What is something you took the time to learn that benefitted you the most?"" 
A: ""[...] how you evaluate your model""

Can only second that!

https://t.co/CazeZNPUjz https://t.co/U1ackguZFV"
7182,@rasbt,2021-11-08 14:05:56+00:00,https://twitter.com/rasbt/status/1457710987096870918,"@denzil_correa FROC would be testing all thresholds whereas MCC is testing a particular threshold. I think it depends a bit on the conventions, stakeholders, and goals in terms of what's more appropriate. Haven't read it yet, but there's also an MCC curve to consider: https://t.co/NwlgxberS2"
7183,@rasbt,2021-11-08 14:01:16+00:00,https://twitter.com/rasbt/status/1457709812309954563,"@alfcnz Hah, thanks, and glad that this is motivating. We should really collaborate on creating educational material some time :)"
7184,@rasbt,2021-11-08 01:19:56+00:00,https://twitter.com/rasbt/status/1457518214875951106,"@anuragsaharoy @willmcgugan The only one I had issues with was XGBoost, but not anymore ü§ó https://t.co/wGOLPVWiMn"
7185,@rasbt,2021-11-08 01:09:25+00:00,https://twitter.com/rasbt/status/1457515568521678849,@lock_the_clock @AllenDowney There's always trade-off. Never got the concept behind it until I moved into a new place this summer that has lots of windows and not so good shades and now love getting up early and start the work day when the sun comes up.
7186,@rasbt,2021-11-07 23:32:43+00:00,https://twitter.com/rasbt/status/1457491233992060931,"@TaliaRinger I see. Since every dataset is different, I don't think there is a one-size fits all solution that is both efficient &amp; that works all the time :(. I think with dataset related things, it's okay to take a hands-on, manual approach. Still good to use a framework for tracking though"
7187,@rasbt,2021-11-07 23:29:39+00:00,https://twitter.com/rasbt/status/1457490461925560321,"@EugeneVinitsky @TaliaRinger Related to that, the work-life balance. If find the challenge is that there are always so many deadlines and ""fires to put out"" that sometimes it's easy to forget to pause, and it's easy to neglect the social aspects."
7188,@rasbt,2021-11-07 23:21:06+00:00,https://twitter.com/rasbt/status/1457488311237464068,"@TaliaRinger I would highly recommend considering a tracking tool though for more expansive and expensive searches. Weights and Biases is great, for example. Using that, you also avoid running duplicate runs if you restart your jobs."
7189,@rasbt,2021-11-07 23:20:22+00:00,https://twitter.com/rasbt/status/1457488126587412489,"@TaliaRinger 2/2 that is, you start with the subjectively most important hyperparameter while keeping everything else at reasonable values. If you find a good setting for that, you keep that and move on to the next hyperparameter and so on."
7190,@rasbt,2021-11-07 23:19:32+00:00,https://twitter.com/rasbt/status/1457487915450257411,"@TaliaRinger Overall though, in a neural network context, I don't think most hyperparameter optimization paradigms don't give you a big advantage. I think the best bang for the buck is tuning based on experience 1/2"
7191,@rasbt,2021-11-07 23:18:22+00:00,https://twitter.com/rasbt/status/1457487619978366981,"@TaliaRinger Hyperopt and optuna are Baysian optimization-based approaches. You can also try random search with successive halving. It's basically creating a big pool of configurations, and it uses limited resources (to aid efficiency) to weed out the bad ones successively"
7192,@rasbt,2021-11-07 23:16:42+00:00,https://twitter.com/rasbt/status/1457487202984865793,"@TaliaRinger You could use hyperopt or optuna. I just made some examples for class the other week: https://t.co/9DSTSRF1xj. They are in a scikit-learn context but since you define your own objective func, you can extend it to neural nets. I think I actually should have a optuna ex somewhwere"
7193,@rasbt,2021-11-07 17:09:25+00:00,https://twitter.com/rasbt/status/1457394772214226944,"@TaliaRinger Oh that's horrible, I hope it passed and you are feeling better. My partner had a similar reaction from the first shot and fainted, and it was really scary. Luckily the medics were able to help and she recovered after a few hours. Take care and get some rest."
7194,@rasbt,2021-11-07 14:15:53+00:00,https://twitter.com/rasbt/status/1457351103281041412,@_brohrer_ @numba_jit Looks LeJIT
7195,@rasbt,2021-11-07 14:09:47+00:00,https://twitter.com/rasbt/status/1457349565875691529,@TaliaRinger Ted Lasso and Foundation
7196,@rasbt,2021-11-07 13:48:36+00:00,https://twitter.com/rasbt/status/1457344236165246996,"@burhr2 Good q. Would say that PR or ROC AUC serves a slightly different purpose as it is evaluating a model across different thresholds (ie different confusion matrices). Often, you just want to know how well a particular model performs at the threshold you want to use in an application"
7197,@rasbt,2021-11-07 13:45:25+00:00,https://twitter.com/rasbt/status/1457343432784023557,"@RobertERitz *Well, that being said, in an ideal world, I would like to have everything reproducible, but it's also about realizing that days are finite, and making certain aspects fully reproducible can be a time sink."
7198,@rasbt,2021-11-07 13:43:43+00:00,https://twitter.com/rasbt/status/1457343007452274690,"@RobertERitz 2/2 If you don't plan to update and your plot is based on actual data, I agree that having the core parts reproducible would be nice, but if you make modifications that don't affect the data (like adding annotation), I don't think that needs to be reproducible"
7199,@rasbt,2021-11-07 13:42:29+00:00,https://twitter.com/rasbt/status/1457342695840657414,"@RobertERitz It depends on the purpose of the plot. If it's a plot you plan on updating, then having a fully reproducible plot makes sense. Otherwise, I don't think  it's necessary. 1/2"
7200,@rasbt,2021-11-06 17:43:16+00:00,https://twitter.com/rasbt/status/1457040905022722056,"@radamihalcea Looks like a very positive trend. As a reviewer, simpler = better for me as well, but unfortunately, many co-reviewers don't see it this way (yet)"
7201,@rasbt,2021-11-06 17:20:24+00:00,https://twitter.com/rasbt/status/1457035150102089734,"@code @3scorciav consistency &amp; following conventions to aid readability, thorough testing, and ‚òïÔ∏è"
7202,@rasbt,2021-11-06 16:31:00+00:00,https://twitter.com/rasbt/status/1457022714863132681,"@jjc2718 Oh yeah, that sounds very useful if you want to compare  model behavior across different thresholds. Thanks for sharing!"
7203,@rasbt,2021-11-06 16:24:15+00:00,https://twitter.com/rasbt/status/1457021016287420421,"@richardtomsett Hah, yeah, like Jaccard index and Tanimoto coefficient (in bio). Oh this paper has actually a great background section on that. https://t.co/sUDF4Bm7Ns"
7204,@rasbt,2021-11-06 16:13:35+00:00,https://twitter.com/rasbt/status/1457018334025764868,"12. In the other scenarios
B1: only 5 out of 59 healthy individuals recognized
C2: only 2 out of 11 sick patients identified

either ACC or F1 score failed to recognize the poor perf. The bottom line: MCC is relatively robust as it was able to predict the poor perf in all 6 cases https://t.co/xdtfY7xXc6"
7205,@rasbt,2021-11-06 16:13:34+00:00,https://twitter.com/rasbt/status/1457018330498408450,"11. The authors compiled a list of more such ""special"" cases. In the list below, in scenarios

A2: only 5 out of 70 sick patients predicted
B2: only 10 out of 50 sick patients
C1: only 1 healthy out of 90 recognized

ACC and F1 can also detect the low performance. https://t.co/EsQk8SXhSf"
7206,@rasbt,2021-11-06 16:13:33+00:00,https://twitter.com/rasbt/status/1457018326610284544,"10. For example, we have 91 sick patients (positives), and 90 patients were correctly predicted as sick. There are 9 healthy patients but we predicted all of them as sick. Even though such a classifier may not be very good, it gets a high F1 score 0.95, whereas the MCC is -0.03. https://t.co/Tuf8Z1GFBp"
7207,@rasbt,2021-11-06 16:13:32+00:00,https://twitter.com/rasbt/status/1457018322298490884,"9. Now, let's zoom in into the use case highlighted on the previous plot, where the MCC is 0.04 and the F1 score is 0.95. In a 100-examples dataset, it may look as follows: https://t.co/5q0q6bZlxG"
7208,@rasbt,2021-11-06 16:13:31+00:00,https://twitter.com/rasbt/status/1457018318834053121,"8. The researchers did an interesting experiment, where they created a scatterplot of 21,084,251 possible confusion matrices from a dataset of 500 examples. Interestingly, for a given MCC value, the F1 score can vary widely (actually, by its whole range, [0, 1]) https://t.co/bk7nr0Qvz6"
7209,@rasbt,2021-11-06 16:13:31+00:00,https://twitter.com/rasbt/status/1457018315105255427,"7. A little issue appears if a row or column in the confusion matrix consists of zeros. Then, the MCC is not defined. But as a small workaround, you could add a small epsilon to the 0's, and as a consequence MCC will approach 0; makes sense, because the model won't be that useful https://t.co/6cZZ7SeY2z"
7210,@rasbt,2021-11-06 16:13:30+00:00,https://twitter.com/rasbt/status/1457018311842189321,"6. The MCC ranges between -1 and 1, which can be interpreted as follows:

-1: total misclassification
0: random prediction (coin tossing classifier)
+1: perfect classification."
7211,@rasbt,2021-11-06 16:13:29+00:00,https://twitter.com/rasbt/status/1457018310294446092,"5. Matthews correlation coefficient (MCC) is a measure that takes all elements of a confusion matrix into account and doesn't require micro/macro averaging in order to be symmetric. Also, it doesn't suffer from class imbalance like accuracy https://t.co/GM7l994zDf"
7212,@rasbt,2021-11-06 16:13:29+00:00,https://twitter.com/rasbt/status/1457018307438125065,"4. Another aspect worth noting about F1 score is that it is not symmetric, that is, if you swap positive and negative class, results can differ. Although, this can be addressed via micro/macro averaging"
7213,@rasbt,2021-11-06 16:13:28+00:00,https://twitter.com/rasbt/status/1457018305693241345,"3. Neither F1, precision, or recall takes the true negatives into account. Accuracy, (TP+TN) / (TP+TN+FP+FN)  actually does this, but the problem with acc is that it is defunct for imbalanced data. That is, acc may be very close to the no information rate (majority class pred.) https://t.co/8q9fCjrgCK"
7214,@rasbt,2021-11-06 16:13:27+00:00,https://twitter.com/rasbt/status/1457018301389938698,"2. Precision, TP / (TP+FP), tells you something about how many out of the predicted positives are actually positives. Recall, TP / (TP+FN), tells you how many of the actual positives you captured. The F1 score, 2(Pre x Rec) / (Pre + Rec) provides a harmonic mean. https://t.co/ETdOHkPwH0"
7215,@rasbt,2021-11-06 16:13:27+00:00,https://twitter.com/rasbt/status/1457018298672033800,"1. Before getting to the meat of the paper, that is highlighting the advantage of MCC for detecting deficiencies of a classifier in imbalanced problems, let's revisit some general aspects first."
7216,@rasbt,2021-11-06 16:13:26+00:00,https://twitter.com/rasbt/status/1457018296847437824,"Reading ML bio literature, I noticed Matthews correlation coefficient (vs other metrics for assessing ML classifiers) is quite popular. Usually, I stick to precision, recall, and F1 for interpretability reasons, but this article is really convincing: https://t.co/JcKdC4ejRd üßµ"
7217,@rasbt,2021-11-06 14:46:33+00:00,https://twitter.com/rasbt/status/1456996429789020164,"@georgelenton @leonpalafox forgot the name of it, but I recently used a markdown to pdf slide converter and it worked pretty well. maybe something to consider."
7218,@rasbt,2021-11-06 14:26:15+00:00,https://twitter.com/rasbt/status/1456991323311984641,"@georgelenton @leonpalafox I have several years of experience in writing docs in latex. But beamer is an absolute no for me. Tried it a few times, but the results where always meh -- especially wnen considering given the amount of work I put into it. It's a time sink and I will never use again :P"
7219,@rasbt,2021-11-05 22:23:37+00:00,https://twitter.com/rasbt/status/1456749069200764929,"@hllo_wrld @kchonyc @zacharylipton @thegautamkamath Another contrived example: You train a decision tree to predict salary, and the model generalizes perfectly. If you can predict the salary of the richest person on earth (or fail to predict a higher salary) you know that the richest person on earth was in the training data"
7220,@rasbt,2021-11-05 15:29:06+00:00,https://twitter.com/rasbt/status/1456644752108052489,"@AdrianEisenmei2 I like plotly, but for some reason I keep coming back to matplotlib. Either just muscle memory or it has stood the test of time and is relatively good üòä"
7221,@rasbt,2021-11-05 15:27:21+00:00,https://twitter.com/rasbt/status/1456644311651598341,@__mharrison__ @IamManuell My guess is this refers to the annotation
7222,@rasbt,2021-11-05 13:58:31+00:00,https://twitter.com/rasbt/status/1456621954396532741,@barbarikon @GaryMarcus I agree that out-of-distribution generalization may not be the biggest problem. One of the problems is rather that current systems are prone to assigning in-distribution class labels to them with high confidence.
7223,@rasbt,2021-11-05 13:45:35+00:00,https://twitter.com/rasbt/status/1456618700841312271,@__mharrison__ Don't have my old machine anymore to run that comparison but what I can tell you is that it doesn't need to spin up the fans when doing so üòâ
7224,@rasbt,2021-11-05 13:27:26+00:00,https://twitter.com/rasbt/status/1456614133793710082,"@AllenDowney Hm, maybe having trained a deep decision tree in scikit-learn and implementing a function to plot it up to a certain max-depth ü§î"
7225,@rasbt,2021-11-05 13:09:41+00:00,https://twitter.com/rasbt/status/1456609667115851780,"@gerard_sgs @figmadesign Nice, thanks for sharing. That looks like a pretty effective tool for flowcharting"
7226,@rasbt,2021-11-05 13:07:41+00:00,https://twitter.com/rasbt/status/1456609162964647938,"@denzil_correa It's vast. I switch around tools depending on what type of figure I am making because they all have their pros and cons and limitations. The common ones are PowerPoint (yes, simple and effective), OmniGraffle Affinity Designer, Pixelmator, Graphic."
7227,@rasbt,2021-11-05 02:12:18+00:00,https://twitter.com/rasbt/status/1456444227852832771,"I used to make figures totally programmatically (say matplotlib) or in one program only (e.g. PowerPoint, AffinityDesign, etc.). Over the years, I found that using hybrids, using different programs for different layers, is often the way to go (esp. on a limited time budget :)) https://t.co/bCMlswQVWR"
7228,@rasbt,2021-11-05 00:46:22+00:00,https://twitter.com/rasbt/status/1456422604093501443,"@AlejandroPiad CS is a really big field, and no one knows everything. Focus on learning what enables you to work on your topic of passion. Also learn some tangential topics, but don't worry about trying to learn it all."
7229,@rasbt,2021-11-04 17:20:36+00:00,https://twitter.com/rasbt/status/1456310422462771201,"@roydanroy @abhi1thakur Hah, yeah, ok, fair enough. But I think we are talking about deterministic operations like in a multiplexer dataset. You could of course model it by a bayesian network ..."
7230,@rasbt,2021-11-04 12:27:31+00:00,https://twitter.com/rasbt/status/1456236666029584384,@roydanroy @abhi1thakur Figuring out the data generating process that was used to generate the dataset (here the context is those kaggle  competitions that are based on synthetic data)
7231,@rasbt,2021-11-04 12:23:01+00:00,https://twitter.com/rasbt/status/1456235533689135107,"@__mharrison__ @shanselman I must admit when I collaboratively work on something (code or text) and the other person is at the keyboard, it makes me really anxious if the other person doesn‚Äôt hit ctrl+s every 30 seconds or so"
7232,@rasbt,2021-11-04 12:18:09+00:00,https://twitter.com/rasbt/status/1456234307606007809,@Sentdex Flask and Theano. I found it difficult to get into it but then there was also the moment where it clicked and all made sense
7233,@rasbt,2021-11-03 17:04:06+00:00,https://twitter.com/rasbt/status/1455943884836679685,@thomasjpfan Good call! I recently added it to the upcoming ed of my book as one of the new features but then totally forgot about it here üòÖ
7234,@rasbt,2021-11-03 14:19:02+00:00,https://twitter.com/rasbt/status/1455902343782977538,@BEBischof @NotionHQ *does not?
7235,@rasbt,2021-11-03 12:45:39+00:00,https://twitter.com/rasbt/status/1455878842674040840,"@teemu_roos @adhigunamahend1 @LucaAmb I agree, but I would think that the researchers who work on said self-supervised learning did not cause harm on others. Or at least I am not aware."
7236,@rasbt,2021-11-03 02:54:59+00:00,https://twitter.com/rasbt/status/1455730196787699714,"Yes, many colleagues I know do amazing general ML and AI research work moving the field forward and contributing to the open source ecosystem, e.g., React (the JS library), PyTorch among others."
7237,@rasbt,2021-11-03 00:55:13+00:00,https://twitter.com/rasbt/status/1455700055839674369,"@beckerfuffle @abhi1thakur re adding it to auto-sklearn, you are probably right and it's trivial to add."
7238,@rasbt,2021-11-03 00:54:49+00:00,https://twitter.com/rasbt/status/1455699955503480836,"@beckerfuffle @abhi1thakur Only did some minor experiments (not extensive, and nothing on a professional kaggle competition level) and also found xgb performs a tad better than lightgbm and catboost. The latter two have better categorical support though (the one in xgb is still experimental)"
7239,@rasbt,2021-11-03 00:14:38+00:00,https://twitter.com/rasbt/status/1455689840742305794,@jlurzuav @alfcnz üíØ‚ô•Ô∏è
7240,@rasbt,2021-11-03 00:14:08+00:00,https://twitter.com/rasbt/status/1455689715299065856,@beckerfuffle @abhi1thakur  The time budget setting  is maybe something to keep in mind for autoxgb https://t.co/5RDSwudl57
7241,@rasbt,2021-11-03 00:12:45+00:00,https://twitter.com/rasbt/status/1455689368396570630,"@beckerfuffle Yeah, a time budget parameter sounds super super neat. There is a hyperopt-sklearn package https://t.co/ohVK7bFcnK that implements a HyperoptEstimator for algo &amp; model search like auto-sklearn, but it doesn't have the time budget, which really is a killer feature."
7242,@rasbt,2021-11-02 22:38:03+00:00,https://twitter.com/rasbt/status/1455665534440251394,@darkgaro @__mharrison__ and lifesaver during the last 3 hours before a paper submission deadline
7243,@rasbt,2021-11-02 22:16:07+00:00,https://twitter.com/rasbt/status/1455660018443956230,Beyond grid search: considering random search and bayesian optimization via hyperopt &amp; optuna for hyperparameter tuning. Made some starter code (for a HW in class) showing how to use these different search strategies with scikit-learn classifiers: https://t.co/9DSTSRF1xj
7244,@rasbt,2021-11-02 21:36:43+00:00,https://twitter.com/rasbt/status/1455650100668211201,@yayitsamyzhang @kchonyc Congrats!
7245,@rasbt,2021-11-02 21:36:02+00:00,https://twitter.com/rasbt/status/1455649928949243911,"@alfcnz Based on your recordings, your lectures are fantastic! Glad your students see it like that and appreciate it, too!"
7246,@rasbt,2021-11-02 18:00:53+00:00,https://twitter.com/rasbt/status/1455595787187068928,"@CodeKrafter @elnazavr it's true to some extend, but your mileage will vary :)"
7247,@rasbt,2021-11-02 01:13:50+00:00,https://twitter.com/rasbt/status/1455342350721499141,"@RileenSinha @ClausWilke @BecomingDataSci @Datadoses *re tailoring, you could involve students more into tasks like grant writing and administrative duties in case they want that. But I guess that would take out all the fun out of the Ph.D. haha"
7248,@rasbt,2021-11-02 01:12:53+00:00,https://twitter.com/rasbt/status/1455342113470754822,"@RileenSinha @ClausWilke @BecomingDataSci @Datadoses Training as a researcher in general. But I guess you could tailor it if a student expresses a wish to become faculty. In my case, re the two Ph.D. students I worked with who have graduated so far they are both research scientists in industry now"
7249,@rasbt,2021-11-01 23:23:19+00:00,https://twitter.com/rasbt/status/1455314539306786817,And this also applies to coding and open source software!
7250,@rasbt,2021-11-01 23:15:09+00:00,https://twitter.com/rasbt/status/1455312487155474435,"@rjurney I agree. It can sometimes be tedious to find certain papers. Must say though that Google Scholar is great for  discovering PDFs. Via ""all versions"" I usually find some website that uploaded a PDF copy for edu purposes https://t.co/owQcE6C021"
7251,@rasbt,2021-11-01 22:52:25+00:00,https://twitter.com/rasbt/status/1455306763314647045,@RileenSinha @ClausWilke @BecomingDataSci @Datadoses it's usually an on-the-job training as a researcher
7252,@rasbt,2021-11-01 22:49:01+00:00,https://twitter.com/rasbt/status/1455305909123657737,"@rjurney Agreed. I make sure to upload all my published articles to my personal website though, and I usually also put a preprint version on arxiv (most journals don't allow the final version on arxiv). Luckily many others do that, too, But it can be tedious to track down articles stms"
7253,@rasbt,2021-11-01 18:31:40+00:00,https://twitter.com/rasbt/status/1455241144271577091,"@Datadoses @BecomingDataSci Reading a textbook takes more discipline than taking a course that someone prepared for you, and tinkering with problems requires more creativity and skill. so being self-taught is actually something to be really proud of :)"
7254,@rasbt,2021-11-01 18:28:34+00:00,https://twitter.com/rasbt/status/1455240365829656578,"@Datadoses @BecomingDataSci A degree program can be useful as it is a subjectively curated selection of topics and materials to learn and to be tested on. It's basically more of a guided tour or service that someone provides, but the outcome is not necessarily better compared to working through it yourself"
7255,@rasbt,2021-11-01 17:36:39+00:00,https://twitter.com/rasbt/status/1455227299327062024,"""Towards Realistic Market Simulations: a Generative Adversarial Networks Approach"" -- predicting the stock market by simulating it via a GAN: https://t.co/KfFGqFJBdN. Maybe a pipe dream but it might work. Have seen something similar re weather forecasting: https://t.co/NStYi81I6U"
7256,@rasbt,2021-11-01 13:09:56+00:00,https://twitter.com/rasbt/status/1455160175816585219,"Nice work! Allows adding combinatorial black-box solver within a differentiable layer, say Dkijkstra's algo for finding the shortest path on a map. Can also see interesting apps of that in bioinfo, like comparing &amp; scoring protein sequences involving the Needleman-Wunsch algo"
7257,@rasbt,2021-11-01 12:46:52+00:00,https://twitter.com/rasbt/status/1455154372833431552,"@DynamicWebPaige That outlook seems grim, except maybe if you live in Patagonia or Canada"
7258,@rasbt,2021-10-31 23:47:43+00:00,https://twitter.com/rasbt/status/1454958293319921667,"@BlancheMinerva @mmitchell_ai Not publicly traded, but I would add OpenAI to the list"
7259,@rasbt,2021-10-31 22:19:04+00:00,https://twitter.com/rasbt/status/1454935985314217985,"@Richard_D_Riley Spot on. But to be fair, reinventing some of these concepts is sometimes more efficient than spending countless hours sifting through old statistical literature that is hidden by paywalls and/or is written in a way that makes it very inaccessible to people outside the field üòú"
7260,@rasbt,2021-10-31 16:17:04+00:00,https://twitter.com/rasbt/status/1454844882279936004,"@ryandcotterell @yoavgo 2/2 So, in this case, this was a significant flaw, and publishing it in any form wouldn't be ok imho. Ie in this paper the authors claimed to have developed a method sensitive to class ordering, but then the method was based on a dot product, which which is invariant to ordering. https://t.co/Sw2WwT4oF2"
7261,@rasbt,2021-10-31 16:14:02+00:00,https://twitter.com/rasbt/status/1454844119386296322,"@ryandcotterell @yoavgo Reminds me of a paper I read a few years ago and was thinking to include/cite, but I could only find the preprint and not a peer-reviewed version. After careful reading &amp; thinking, I found a serious flaw making the whole claim and premise of the paper wrong. 1/2"
7262,@rasbt,2021-10-31 16:12:51+00:00,https://twitter.com/rasbt/status/1454843823356579844,"@ryandcotterell @yoavgo Good point, and I guess it depends. If a serious flaw is that the ablation studies were not comprehensive enough, that might be ok and can be addressed later. If there is a technical flaw that makes the whole paper misleading and cannot be addressed by more experiments, then np."
7263,@rasbt,2021-10-31 15:09:09+00:00,https://twitter.com/rasbt/status/1454827792193970176,@ykilcher @sirajraval Heard about the plagiarism back then (btw also saw some of my figures in your vids). Nice interview explaining the background &amp; how one thing let to another. Important lesson here to stay away from drugs &amp; keeping in mind that metrics are not everything. Wishing you all the best!
7264,@rasbt,2021-10-31 12:57:13+00:00,https://twitter.com/rasbt/status/1454794587227230209,"@yoavgo 2/2 Rightly so, what people didn't like about it was that it might amplify attention for said mainstream works. Now, it seems like ACL's guidelines could probably also cause that? ü§î"
7265,@rasbt,2021-10-31 12:55:26+00:00,https://twitter.com/rasbt/status/1454794142274539520,"@yoavgo Also, in the past, I was musing about a new conferencing approach where the deadline is smooth, and papers get accepted based on scientific correctness. Where editors and audience can vote for which papers they want to see as talks. 1/2"
7266,@rasbt,2021-10-31 12:54:13+00:00,https://twitter.com/rasbt/status/1454793835037564929,"@yoavgo I don't mind work in progress, but ""significant flaws"" sounds a bit harsh."
7267,@rasbt,2021-10-31 12:50:03+00:00,https://twitter.com/rasbt/status/1454792786348318728,"@yoavgo Yikes indeed. And via ""2 = Borderline: [...] but also significant flaws [...]"" they also imply that some of their workshop papers might have severe issues?"
7268,@rasbt,2021-10-31 12:46:13+00:00,https://twitter.com/rasbt/status/1454791822191075330,"@Nils_Reimers Thanks. Yeah, my guess was that it's either computational performance or preventing overfitting. But since this is based on two BERT models already, I was thinking that a third transformer wouldn't really make a huge difference."
7269,@rasbt,2021-10-30 19:44:19+00:00,https://twitter.com/rasbt/status/1454534651075252231,@aiexplorations @driscollis I am surprised that PySpark is still a popular thing. I thought people use Ray nowadays.
7270,@rasbt,2021-10-30 19:43:07+00:00,https://twitter.com/rasbt/status/1454534347915157509,@fchollet Oh yeah totally agree with you. Was just ranting that nowadays you have to have a subscription for everything üòâ
7271,@rasbt,2021-10-30 19:39:31+00:00,https://twitter.com/rasbt/status/1454533442721521682,@Martinbeyerr Curious how peer reviewers didn‚Äôt raise that question ü§î
7272,@rasbt,2021-10-30 19:37:49+00:00,https://twitter.com/rasbt/status/1454533017578479625,@fchollet And Web 4 is the union of Web 2&amp;3 that is strictly subscription based.
7273,@rasbt,2021-10-30 19:33:33+00:00,https://twitter.com/rasbt/status/1454531943933042696,"@fchollet For Web 3, it is even broader than that if you consider Electron apps like Slack etc and that you can run iPhone apps on M1 desktops :P"
7274,@rasbt,2021-10-30 19:26:07+00:00,https://twitter.com/rasbt/status/1454530069876051975,"@driscollis Hard to pick one, but my top 3 are NumPy, scikit-learn, and PyTorch"
7275,@rasbt,2021-10-30 19:20:35+00:00,https://twitter.com/rasbt/status/1454528680387129348,"@JFPuget @_HannahRitchie Yeah, the chart was very surprising because I thought France was the most CO2 friendly country in Europe (based on per capita CO2 emissions). With the normalization by domestic CO2 that makes sense now ü§î"
7276,@rasbt,2021-10-30 18:29:41+00:00,https://twitter.com/rasbt/status/1454515868914814983,"@mark_riedl @Ted_Underwood StyleGAN1...3, YOLOv1...5, GPT-v1...3, MobileNetV1...3. PathThing is refreshing."
7277,@rasbt,2021-10-30 16:41:26+00:00,https://twitter.com/rasbt/status/1454488628760035339,"@kastnerkyle Very good points, thanks for sharing your thoughts below!"
7278,@rasbt,2021-10-30 16:37:02+00:00,https://twitter.com/rasbt/status/1454487519328968711,"@kastnerkyle Actually, they do use it somehow differently. I feel like the text description also doesn't quite match the flowchart. https://t.co/qT9thK1zC6"
7279,@rasbt,2021-10-30 16:30:38+00:00,https://twitter.com/rasbt/status/1454485907550183424,"@kastnerkyle They do use attention for the LSTM though, i.e., the original attention mechanism when I saw that correctly"
7280,@rasbt,2021-10-30 16:29:26+00:00,https://twitter.com/rasbt/status/1454485605358964736,"@kastnerkyle Yeah, this is probably it üôÇ"
7281,@rasbt,2021-10-30 16:25:34+00:00,https://twitter.com/rasbt/status/1454484634797027330,"@kastnerkyle Good point. Was thinking about that, too. They do have bidirectional transformers for the encoding step though. Or, maybe they are pre-trained on something else. Would need to double-check in the paper."
7282,@rasbt,2021-10-30 13:44:07+00:00,https://twitter.com/rasbt/status/1454444006075682830,"@mrdbourke @DynamicWebPaige Your paper has sota experimental results but doesn't share the corresponding code? Thanks but no thanks. Won't be used, won't be cited, does not exist."
7283,@rasbt,2021-10-30 13:39:19+00:00,https://twitter.com/rasbt/status/1454442795029172227,@fchollet and Colab One. Colab Max
7284,@rasbt,2021-10-30 13:00:51+00:00,https://twitter.com/rasbt/status/1454433113967312898,"@AbrahamStarosta This implementation is probably more vectorized. It's implementing a random forest as a series of matrix multiplications, which in theory should run more efficiently on GPUs due to having better threading and parallelism."
7285,@rasbt,2021-10-30 03:03:23+00:00,https://twitter.com/rasbt/status/1454282758252081153,"@NNovitskiy @GuzaUy @reuvenmlerner Fair enough, but on the other hand, don‚Äôt we want to teach our students something that is useful for their future caterer, outside university!? üòâ"
7286,@rasbt,2021-10-30 03:01:39+00:00,https://twitter.com/rasbt/status/1454282322497490946,"@reuvenmlerner Reminds me of when I learned Python, somewhere saw ‚Äúfrom numpy import *‚Äù, and thought that this was a good thing. There might be cases where overwriting built-ins is useful, but I feel like there should be a safety mechanism, like with the double underscore and private methods"
7287,@rasbt,2021-10-30 01:54:53+00:00,https://twitter.com/rasbt/status/1454265518916046850,"@JALC1829 I don't think there is a direct way to do it. But one of the rationales behind the library is to export the model to PyTorch to make use of tools for serving, including ONNX. I.e., in theory, you could go sklearn -&gt; PyTorch -&gt; ONNX -&gt; TensorFlow https://t.co/ZmK7bKME5M"
7288,@rasbt,2021-10-30 00:55:55+00:00,https://twitter.com/rasbt/status/1454250680512880650,"@zstats @RAPIDSai Oh for sure, I love cuML and it's something I use myself. We have actually written about it last year :) https://t.co/U99TAutUzy. For this particular proj, we had an existing random forest trained in sklearn and need to apply it to a large dataset and wanted to avoid retraining"
7289,@rasbt,2021-10-29 22:01:36+00:00,https://twitter.com/rasbt/status/1454206811003830273,"@itsrainingdata Glad to hear there are positive experiences, too!"
7290,@rasbt,2021-10-29 21:55:40+00:00,https://twitter.com/rasbt/status/1454205320541184002,@AbdulrhmnGhanem Makes me think of how the original perceptrons really worked https://t.co/rUxg9IxvqU
7291,@rasbt,2021-10-29 21:33:42+00:00,https://twitter.com/rasbt/status/1454199788921098240,@Ted_Underwood Yes exactly. That's why I was thinking of it more of an extension or generalization.
7292,@rasbt,2021-10-29 21:32:36+00:00,https://twitter.com/rasbt/status/1454199514579996672,@AbdulrhmnGhanem *hard-attention layers
7293,@rasbt,2021-10-29 21:18:14+00:00,https://twitter.com/rasbt/status/1454195899320651777,"Given recent progress wrt embedded representations and working with multimodal inputs, this sounds like the next logical extension (/generalization) of how they approached language translation (many different lang. are encoded into a shared representation) https://t.co/zwSWe0HU4w https://t.co/xIJWJst0oB"
7294,@rasbt,2021-10-29 20:05:22+00:00,https://twitter.com/rasbt/status/1454177560825409537,"@hillelogram @nicoespeon In this context, it's interesting to muse about how to improve code commenting. E.g., having comment-layer files for a given code files that toggles between different syntax highlighting and code comments for different audiences."
7295,@rasbt,2021-10-29 19:59:12+00:00,https://twitter.com/rasbt/status/1454176011046825985,"@hillelogram @nicoespeon Yes, with that I agree. I think we don't have to do one at the expense of the other though. Modern text editors could surely support a toggle button via plugins. Or we could have the ""background highlight"" in addition to syntax highlighting (not instead of). https://t.co/yuuIVqPFzQ"
7296,@rasbt,2021-10-29 19:56:43+00:00,https://twitter.com/rasbt/status/1454175383872544768,@joelgrus The price is for a single signed copy and dinner with the author or for a box of 10?
7297,@rasbt,2021-10-29 19:13:41+00:00,https://twitter.com/rasbt/status/1454164554401947650,"@nicoespeon 2/2 I.e., when writing code, you can actively debug it when you write. Because syntax highlighting will usually fail when you forget indent, close a parenthesis, mistype a variable, etc. It's actually quite useful for that imho."
7298,@rasbt,2021-10-29 19:11:30+00:00,https://twitter.com/rasbt/status/1454164006869024775,"@nicoespeon To appreciate the value behind syntax highlighting, people can try to read other people's code without by using the ""raw"" links on GitHub. I do get the point though re using syntax highlighting for sth more useful. There is one great use case of syntax highlighting though 1/2 https://t.co/y4taQokqOI"
7299,@rasbt,2021-10-29 18:00:19+00:00,https://twitter.com/rasbt/status/1454146092682170370,"@TheZachMueller @yoavgo * Speaking of which, I do play video games quite frequently, but I don't think a Nintendo Switch would even be remotely capable to drive a VR headset üòÖ"
7300,@rasbt,2021-10-29 17:58:15+00:00,https://twitter.com/rasbt/status/1454145569425928199,"@TheZachMueller @yoavgo Eg I would be totally in for an immersive, realistic driving simulator that helps me teach how to drive in off-road conditions more safely. But an alternative reality, as a realistic simulation of general real-life experiences is probably something I don't need or want."
7301,@rasbt,2021-10-29 17:55:04+00:00,https://twitter.com/rasbt/status/1454144768569655307,"@TheZachMueller @yoavgo Can see why it's appealing. Eg every 5 years or so, I upgrade my computer monitor to improve the experience. A VR headset is basically like that but on another level. One of these technologies that are probably not bad per se if used responsibly, but I think it is easy to abuse"
7302,@rasbt,2021-10-29 17:42:59+00:00,https://twitter.com/rasbt/status/1454141728974331911,"@yoavgo Read Ready Player One like 10 years ago and have never tried a VR headset. I find the technology fascinating, but everytime I was musing about buying a headset, I had to think of the book and was ""nah, I don't need that."" Can see it being useful though, e.g. training surgeos etc"
7303,@rasbt,2021-10-29 14:21:51+00:00,https://twitter.com/rasbt/status/1454091112558256131,@roydanroy CC @zacharylipton https://t.co/CfylzLRV3R
7304,@rasbt,2021-10-29 13:27:21+00:00,https://twitter.com/rasbt/status/1454077396664135702,"@IbraAlshubaily On GPUs, you have better parallelism by having more threads to speed up e.g., matrix multiplications, compared to CPUs. In Hummingbird, decision tree traversal is recast as a series of matrix multiplications."
7305,@rasbt,2021-10-29 13:18:54+00:00,https://twitter.com/rasbt/status/1454075270168780805,"@HamelHusain Haven't run it just yet. Student of mine is working on a project that involves predicting on approx. a billion data points which takes several days. Just remembered the SciPy talk and that this tool exists. How much speed-up it yields remains to be seen. According to docs, ~3-5x"
7306,@rasbt,2021-10-29 13:07:28+00:00,https://twitter.com/rasbt/status/1454072392104488970,"The approach behind it is really elegant, i.e., recasting the algorithm as matrix multiplications in PyTorch. This also allows you tap into all the export &amp; deployment resources as well! Here is 27 minute SciPy 2021 talk from earlier this summer: https://t.co/5uD7bM14XX"
7307,@rasbt,2021-10-29 13:05:07+00:00,https://twitter.com/rasbt/status/1454071802934841346,Just checking out Hummingbird again for a current project (https://t.co/cmDYE1pbER). It combines my two favorite libraries (scikit-learn &amp; PyTorch) and lets you port over existing models (and leverage GPUs) without having to retrain. Amazing stuff! https://t.co/mwl4Pe0Pmn
7308,@rasbt,2021-10-28 22:20:58+00:00,https://twitter.com/rasbt/status/1453849297817067522,"@__mharrison__ I like PiYG, but it is probably not so great re color blindness? https://t.co/ZoxeoYBP9G"
7309,@rasbt,2021-10-28 21:46:08+00:00,https://twitter.com/rasbt/status/1453840532350939141,@chriswolfvision MANGA
7310,@rasbt,2021-10-28 18:42:22+00:00,https://twitter.com/rasbt/status/1453794287196557316,"@WalterReade Hah, at least you didn't get my favorite PyTorch error: ""Buy more RAM!"" https://t.co/pwVaAQPhSW"
7311,@rasbt,2021-10-28 17:24:48+00:00,https://twitter.com/rasbt/status/1453774765953540102,"@Jeande_d @karpathy Ha true, just curious about the amount of sleep people in industry vs academia lose over sth üòâ"
7312,@rasbt,2021-10-28 17:09:14+00:00,https://twitter.com/rasbt/status/1453770849266380811,@Jeande_d @karpathy Would love to see the bar chart of the unnormalized amounts üôÉ
7313,@rasbt,2021-10-28 16:57:39+00:00,https://twitter.com/rasbt/status/1453767932648042504,@RanthonyEdmonds Another good reason: most students absolutely love learning how to use Python and have a fun time when using it for data modeling related things. (At least according to end-of-semester anonymous surveys :))
7314,@rasbt,2021-10-28 16:55:28+00:00,https://twitter.com/rasbt/status/1453767383714312196,@RanthonyEdmonds üíØpercent agree!
7315,@rasbt,2021-10-28 16:49:44+00:00,https://twitter.com/rasbt/status/1453765941536382981,"@RanthonyEdmonds Yes, I would highly recommend that. A large number of students will want  to apply math to a real-world problem so it‚Äôs going to be quite useful."
7316,@rasbt,2021-10-28 16:41:07+00:00,https://twitter.com/rasbt/status/1453763772041007108,"@alfcnz @kchonyc I see it differently. It‚Äôs based on the structure of the data, but still labels are generated from that structure of the data. Like next word prediction or predicting missing tokens in MLM. Or predicting the position on an image patch in a jigsaw puzzle."
7317,@rasbt,2021-10-28 12:08:06+00:00,https://twitter.com/rasbt/status/1453695063729614848,@__mharrison__ Should have clarified of course that this is the original M1 (not M1 Pro/Max). In the MB Air.
7318,@rasbt,2021-10-28 12:07:19+00:00,https://twitter.com/rasbt/status/1453694868354703365,"@Swayson No, luckily not (and I wish I had one üòÖ).  This is from my almost a year-old Mb Air."
7319,@rasbt,2021-10-28 12:05:12+00:00,https://twitter.com/rasbt/status/1453694336403640325,"@alfcnz @kchonyc and also different ways to use unlabeled data in the process
- Semi-supervised: assume the target label by density, similarity, etc.
- Self-supervised: auto-generate labels (usually different from the target labels)
- Weakly supervised: generate the target label with a heuristic"
7320,@rasbt,2021-10-28 12:04:15+00:00,https://twitter.com/rasbt/status/1453694097949134854,"@alfcnz @kchonyc Oh, I meant I was strictly thinking of self-supervised learning how it is used/defined in DL today. (I.e., pretraining a NN with SGD on some auto-generated labels), whereas, like you said, there different ways we can use unlabeled data in the process, and not all need to use SGD"
7321,@rasbt,2021-10-28 02:38:47+00:00,https://twitter.com/rasbt/status/1453551790159433728,"@science_stanley Yes, agreed. It's been an amazing machine so far. And that battery lifeüëå. I am teaching 2x75 min lectures two times a week, and don't even have to think about whether I packed my charger or not."
7322,@rasbt,2021-10-28 02:23:45+00:00,https://twitter.com/rasbt/status/1453548009040584704,"@srvmshr @HelloPaperspace oh yeah, that would be a viable alternative. Actually have another machine that I could use too. Just thought about convenience and the fact that everyone is praising the M1: why not just run it here and see what happens :P"
7323,@rasbt,2021-10-28 02:21:48+00:00,https://twitter.com/rasbt/status/1453547519602987010,"@science_stanley The MB Air, which partly explains that. Have used it for almost a year and this was the first time it crossed the 90 Celsius mark really. But yeah, it's just an office-task machine, and I usually don't run serious code on it."
7324,@rasbt,2021-10-28 02:12:24+00:00,https://twitter.com/rasbt/status/1453545151280914436,"@srvmshr Yeah, basically stopped that run. Need to teach tomorrow morning and don't want to risk anything üò¨"
7325,@rasbt,2021-10-28 02:06:48+00:00,https://twitter.com/rasbt/status/1453543743261401096,"Remote server being down and trying to get some results in, I found Hyperopt + XGboost makes even the M1 a bit toasty https://t.co/Qv0DZSO7sW"
7326,@rasbt,2021-10-27 23:30:23+00:00,https://twitter.com/rasbt/status/1453504377994588166,@chriscoyier TextEdit. Just make sure you have plain text mode enabled. https://t.co/xQBm6KAoSf
7327,@rasbt,2021-10-27 21:49:17+00:00,https://twitter.com/rasbt/status/1453478934897643529,"@alfcnz @kchonyc My bad, didn't check the notes and assumed self-supervised, not semi-supervised learning for pretraining"
7328,@rasbt,2021-10-27 20:49:39+00:00,https://twitter.com/rasbt/status/1453463930018443269,"@alfcnz @kchonyc Pretraining uses SGD too, though, that is, this problem applies recursively?"
7329,@rasbt,2021-10-27 15:10:37+00:00,https://twitter.com/rasbt/status/1453378610253996038,"@TaliaRinger @zacharylipton @Jay5w That sounds fun, except maybe the moving part üòÖ. But given the shift to remote, there are maybe ways around that nowadays"
7330,@rasbt,2021-10-27 14:47:58+00:00,https://twitter.com/rasbt/status/1453372906906472455,"@Jay5w @zacharylipton Oh, I see. Haven't heard about it before. So it's basically a research scientist position but fixed-term (with the prospect of going to academia)?"
7331,@rasbt,2021-10-27 14:42:40+00:00,https://twitter.com/rasbt/status/1453371574778793993,"@Jay5w @zacharylipton then, why not joining a company as 'research scientist' (or perhaps a postdoc in industry means the same thing?)"
7332,@rasbt,2021-10-27 14:36:43+00:00,https://twitter.com/rasbt/status/1453370079127638029,"@zacharylipton Was daydreaming about it during my PhD. Me: a job where I get to focus on research (almost) full time? Amazing, sign me up! Reality (based on hearing from postdocs back then): Have to work 60-80h per week for a minimum salary and very little job security. Thanks, but no thanks."
7333,@rasbt,2021-10-27 12:19:54+00:00,https://twitter.com/rasbt/status/1453335645460615178,"@francoisfleuret I don't mind at all. It's a tweet, not a PhD thesis. Twitter is fun when you get to be spontaneous and don't overthink it. Mulling over your tweets and checking your tweets for typos would take the fun out of it imho. Premature optimization is the root of all evil ;)"
7334,@rasbt,2021-10-26 22:03:35+00:00,https://twitter.com/rasbt/status/1453120147221327874,"@datenzauberai 2/2 Where it is more useful though is in Stacking, where you could train different methods not only on different random subsets but different modalities (e.g., images, text, if available). Not sure if there is a name for that approach though"
7335,@rasbt,2021-10-26 22:02:20+00:00,https://twitter.com/rasbt/status/1453119834200363008,"@datenzauberai Yeah, that's a good point. The ""random subspace method"" by Tin Kam Ho (random forest precursor) for example trained trees on different feature subsets. Random subsets though. There's also an option for that in scikit-learn's BaggingClassifier. 1/2"
7336,@rasbt,2021-10-26 19:21:41+00:00,https://twitter.com/rasbt/status/1453079404221972480,"@BlackHC As someone who had similar thoughts: In hindsight, I think seeing how it is relevant gives you the motivation to study certain topics in more depth. If you started with in-depth studies from the beginning, you could have lost motivation to finish said Ph.D. in the first place."
7337,@rasbt,2021-10-26 02:33:16+00:00,https://twitter.com/rasbt/status/1452825627464187912,"@TheShubhanshu Like 1-2 decades ago, lots of stuff was based on naive Bayes in Google. Search results are now based on Transformers. Not sure if it involves ensembles though. Btw. reminds me of @xamat  great blog post on the Netflix prize: https://t.co/OWb7T1gEjd"
7338,@rasbt,2021-10-26 02:29:59+00:00,https://twitter.com/rasbt/status/1452824800641142788,"@TheShubhanshu No, sorry. I think this is mostly in the loose realm of ""trade-secret."" You may get some anecdotal references here and there by talking to people in industry."
7339,@rasbt,2021-10-26 02:21:19+00:00,https://twitter.com/rasbt/status/1452822619313557515,"@HiramCoriaRodr1 Yes, it's very related. It is essentially bagging with random feature subsets at the nodes."
7340,@rasbt,2021-10-26 01:49:32+00:00,https://twitter.com/rasbt/status/1452814622264860675,"Which is a nice coincidence (or not üòá), as we are finishing up a long lecture on ensemble methods :). In this case, the Kaggle solutions website comes at a nice time in terms of (hopefully) being some sort of motivation for learning about these https://t.co/Fi6xsC3xJc"
7341,@rasbt,2021-10-26 01:49:31+00:00,https://twitter.com/rasbt/status/1452814619018506242,"I like to share latest developments or useful tools &amp; resources in class. For tomorrow, was just browsing through the Kaggle solutions website (https://t.co/G1v5UtlA2T) &amp; there is a nice theme that winning solutions (whether traditional ML or DL) are usually some sort of ensemble https://t.co/00T180kLdV"
7342,@rasbt,2021-10-26 00:10:31+00:00,https://twitter.com/rasbt/status/1452789704047439876,"@fchollet Amazing, congrats! For some reason, I totally missed the first edition. But the more excited I am to check out the second one! ü•≥üéâ"
7343,@rasbt,2021-10-26 00:06:37+00:00,https://twitter.com/rasbt/status/1452788721565188101,"@thomasjpfan Happy to report that the upgrade to Monterey (along with the old Safari, yay) fixed it: https://t.co/zhmKCqJqdO"
7344,@rasbt,2021-10-25 22:26:30+00:00,https://twitter.com/rasbt/status/1452763526158864385,@TimHochberg @randall_balestr @ylecun Not sure. Maybe it was a bug. Maybe it was due to how/that multiprocessing was used for parallelism. Maybe @ThomasViehmann has some insights :)
7345,@rasbt,2021-10-25 19:21:17+00:00,https://twitter.com/rasbt/status/1452716917026873361,@ILaradji What is the baseline and how do you define/evaluate success?
7346,@rasbt,2021-10-25 13:02:43+00:00,https://twitter.com/rasbt/status/1452621645689065481,"@aa_goel Instead of putting together the same building blocks differently, it would be interesting to come up with new building blocks ;)"
7347,@rasbt,2021-10-25 13:02:10+00:00,https://twitter.com/rasbt/status/1452621506249469959,"@aa_goel Totally agree. It's essentially hyperparameter search on steroids. There are some interesting directions of coming up with new architectures, but yeah, it's essentially still the same building blocks put together differently: https://t.co/FPRsVu9Ozo https://t.co/5FJczgW2nF"
7348,@rasbt,2021-10-25 13:00:13+00:00,https://twitter.com/rasbt/status/1452621015348129793,"@PogrebnyakE yes! Defining the problem, the measure of success, collecting the data. Checking and enhancing the data, .... Checking and deploying the model, ...."
7349,@rasbt,2021-10-25 01:07:17+00:00,https://twitter.com/rasbt/status/1452441599447863296,"Suppose you want to build a model for painting artworks via a series of strokes. Sounds like a RL problem? Turns out, you can get better results with a transformer. Yes, those are expensive, but here you get better results in 1/10 of the time (4h vs 40h): https://t.co/YZr655apin https://t.co/Ax0MdCdI1J"
7350,@rasbt,2021-10-24 20:02:26+00:00,https://twitter.com/rasbt/status/1452364884457492492,"Awesome, finally XGBoost support for M1 via conda-forge! No need to compile from source anymore üéâ"
7351,@rasbt,2021-10-24 17:35:02+00:00,https://twitter.com/rasbt/status/1452327790968197126,"@amcrisan @_Alex_Adamov @huggingface Nice article, and yeah, that makes sense. Personally, I also see AutoML as a method to create predictive performance baselines. It would be useful to have intermediate tools between running and evaluating things yourself and having baselines that aim to be fully automatic"
7352,@rasbt,2021-10-24 16:53:20+00:00,https://twitter.com/rasbt/status/1452317292860219398,"@Nils_Reimers Yup, AutoML is essentially a loop of hyperparameter tunings on a benchmark dataset"
7353,@rasbt,2021-10-24 16:12:44+00:00,https://twitter.com/rasbt/status/1452307075904778244,"@DrTBehrens @mervenoyann *and most non Python libraries and software I get from homebrew. Recently, everything works seamlessly (only one that is a bit tricky is xgboost, here you still have to compile yourself)"
7354,@rasbt,2021-10-24 16:11:44+00:00,https://twitter.com/rasbt/status/1452306825546801162,"@DrTBehrens @mervenoyann I have a M1 since February and haven‚Äôt had to use Rosetta 2 at all :). Don‚Äôt have a particular tutorial, but in the beginning I installed Python from homebrew and compiled most libs myself. Now, I just use Miniforge, and most libraries on conda-forge support miniforge."
7355,@rasbt,2021-10-24 15:57:11+00:00,https://twitter.com/rasbt/status/1452303163961315332,"@mervenoyann @DrTBehrens Just as a heads up, tensorflow for M1 installs just fine now via conda-forge. No need to compile from scratch anymore. :)"
7356,@rasbt,2021-10-24 15:55:10+00:00,https://twitter.com/rasbt/status/1452302657109037066,@aadriasola C and C++ ‚Ä¶ good point :).
7357,@rasbt,2021-10-24 15:28:55+00:00,https://twitter.com/rasbt/status/1452296048760795148,"@aadriasola Yes yes, but I can‚Äôt think of anything I still use today. I sometimes use R occasionally, but Perl, gnuplot? No, not really ;)"
7358,@rasbt,2021-10-24 15:18:32+00:00,https://twitter.com/rasbt/status/1452293435742990346,"@_Alex_Adamov @huggingface I think AutoML works for traditional ML. For deep learning contexts I remain a skeptic. Apropos AutoML being dead, the following is from today‚Äôs MLOps newsletter: https://t.co/8VUwlScliR"
7359,@rasbt,2021-10-24 15:03:00+00:00,https://twitter.com/rasbt/status/1452289528627085317,"So, AutoML is just empty promises? üôÉ"
7360,@rasbt,2021-10-24 13:00:25+00:00,https://twitter.com/rasbt/status/1452258679651176450,@ThomasViehmann Very good point! Thanks for the reminder!
7361,@rasbt,2021-10-24 02:48:35+00:00,https://twitter.com/rasbt/status/1452104705547587584,"@fchollet Haven‚Äôt seen Dune yet and that‚Äôs great to hear. I had low expectations for Blade Runner 2049, but it was really awesome. Sounds like he and his crew did a similarly good job with Dune."
7362,@rasbt,2021-10-24 02:30:20+00:00,https://twitter.com/rasbt/status/1452100112449249287,"@leonpalafox @james_r_lucas @jslez @AlbertBuchard @PreetumNakkiran yeah, similar in a sense that you can add a penalty term to the loss function. But here the constraint is that the covariance matrix is similar to the identity matrix, so you can constrain it by adding an I - XX^T term"
7363,@rasbt,2021-10-24 00:36:15+00:00,https://twitter.com/rasbt/status/1452071403692470274,"@jslez @james_r_lucas @leonpalafox @AlbertBuchard @PreetumNakkiran Yeah, an autoencoder with linear activations is essentially identical to PCA, except one little difference: you don't have the orthogonality constraint in the latent space."
7364,@rasbt,2021-10-24 00:34:18+00:00,https://twitter.com/rasbt/status/1452070913994809345,"@AlbertBuchard @PreetumNakkiran Hah, that's actually how I teach it in class :) https://t.co/8fYNqF3IF6"
7365,@rasbt,2021-10-23 22:23:47+00:00,https://twitter.com/rasbt/status/1452038065594245126,@jslez @leonpalafox @AlbertBuchard @PreetumNakkiran It‚Äôs basically because a sum of linear functions is still a linear function.
7366,@rasbt,2021-10-23 18:27:26+00:00,https://twitter.com/rasbt/status/1451978588908048388,"@digiglean I had pretty quirky data (protein structures) to collect, preprocess, and analyze and needed to automate this"
7367,@rasbt,2021-10-23 18:21:44+00:00,https://twitter.com/rasbt/status/1451977154179354632,"@mervenoyann Yeah, it‚Äôs like telling someone what to eat and in what order. Everyone has a different taste, and it it also depends on how hungry you are."
7368,@rasbt,2021-10-22 14:39:03+00:00,https://twitter.com/rasbt/status/1451558726385680406,@AllenDowney Most tab and bottled water is alkaline though as far as I know. My coffee machine came with a pH test to specify the water pH in its settings. I think it was around 8.
7369,@rasbt,2021-10-22 14:15:27+00:00,https://twitter.com/rasbt/status/1451552788333404165,@AdrianEisenmei2 Ok verstehe. Finde auch dass fuer viele Sachen Klassen overkill sind. In diesem context ist es notwendig wegen der komplexen torch.nn.Module Maschinerie fuer automatische Differenzierung in neuralen Netzwerken
7370,@rasbt,2021-10-22 13:46:36+00:00,https://twitter.com/rasbt/status/1451545527489794062,"@AdrianEisenmei2 Ist das bezogen auf das konkrete Beispiel, damit meine ich, dass CustomComputation() keine Klasse sein sollte? Das ist notwendig hier. Damit is im backward() pass erkannt wird, und damit die Gradienten von autodiff getrackt werden koennen etc."
7371,@rasbt,2021-10-22 13:34:23+00:00,https://twitter.com/rasbt/status/1451542451441778714,"Re what can possibly be added and improved, this is really impressive: PyTorch 1.10 --&gt; ""This release is composed of over 3,400 commits since 1.9, made by 426 contributors.""

PS: more detailed parameterize tutorial here: https://t.co/LXJdMGyFfA"
7372,@rasbt,2021-10-22 13:34:22+00:00,https://twitter.com/rasbt/status/1451542449130811399,"I always think that PyTorch is already so feature-rich and polished, what could they change and/or add?  

A neat additions is the ""parameterize"" module. Below, a quick example creating a custom layer. However, the real cool use-cases are applying it to larger modules of course! https://t.co/8CPNedsxMB"
7373,@rasbt,2021-10-22 13:01:21+00:00,https://twitter.com/rasbt/status/1451534140239716367,"@GuggerSylvain @huggingface Wow, 3 years already! Time flew by so fast! Big congrats on both accounts üéâü•≥"
7374,@rasbt,2021-10-22 12:58:58+00:00,https://twitter.com/rasbt/status/1451533540420689962,"@aureliengeron @fchollet Nice tutorial! Particularly looking forward to it in context of the HistGradientBoostingClassifier, which only accepts bool or integers lists as args for categorical_features. This can be a bit error prone (esp. if you have a column-number changing preprocessor in your pipeline)"
7375,@rasbt,2021-10-21 19:50:44+00:00,https://twitter.com/rasbt/status/1451274776572567560,"@HEPfeickert This. We had widespread wifi outages on campus multiple times this semester, and cell reception in my office was not good enough for hotspotting. Finally got around to read some of the papers I printed out before the pandemic üòÖ"
7376,@rasbt,2021-10-21 18:55:46+00:00,https://twitter.com/rasbt/status/1451260944261189637,"@anacondainc @DynamicWebPaige @Microsoft @msPartner Congrats! This is nice and sounds like it's going to be a fruitful collaboration. As someone who wasn't a big fan of Microsoft in the early 2000s, I am excited about that turnaround and focus on the community and open source. (Really appreciate all the work on GitHub and VSCode!)"
7377,@rasbt,2021-10-21 16:44:13+00:00,https://twitter.com/rasbt/status/1451227835738296320,@ducha_aiki the current state and the future of academic publishing certainly seems grim üò¨ https://t.co/A57IaLpmfx
7378,@rasbt,2021-10-21 16:40:18+00:00,https://twitter.com/rasbt/status/1451226851398008833,"@yoavgo Yes. MSc in the EU is courses + (usually research-based) thesis. Basically like a shorter version of the US PhD. The EU PhD, however, is more research focused. Afaik (based on what my sister told me) you don't take courses in the EU when doing a PhD. It's focused only on research"
7379,@rasbt,2021-10-21 16:37:13+00:00,https://twitter.com/rasbt/status/1451226076051542025,@yoavgo I agree. But want to add that it's also possible in the US. Had s.o. in my program who decided after ~2 years not to finish the PhD &amp; opted to leave with a masters instead. I think the masters is usually course-based so after ~2-3 years into the PhD you probably fulfill that req
7380,@rasbt,2021-10-21 12:43:01+00:00,https://twitter.com/rasbt/status/1451167138778079236,"Thanks to @reshamas , I just learned that this feature already exists in scikit-learn today (it was just a bit under-marketed)! No need to install the nightly build, you will already have fun with v1.0 :)"
7381,@rasbt,2021-10-20 23:47:42+00:00,https://twitter.com/rasbt/status/1450972021563826178,"@aureliengeron * Btw., for a time, there was also the recommended ""%matplotlib notebook"". I never really used that one though üò¨"
7382,@rasbt,2021-10-20 23:46:57+00:00,https://twitter.com/rasbt/status/1450971832031531011,"@aureliengeron I don't blame you, because even though you don't need %matplotlib inline  since like 5 years ago, students sometimes have problems with figures not showing up. I think mostly Windows computers are affected? So I still use it just to make sure."
7383,@rasbt,2021-10-20 21:46:47+00:00,https://twitter.com/rasbt/status/1450941593394028544,"@dalmaer Would ask the same questions for fairness. Asking them also gives you a some sort of baseline, whether these questions are potentially more difficult than you might assume if asked on the spot, even for an experienced coder."
7384,@rasbt,2021-10-20 18:08:04+00:00,https://twitter.com/rasbt/status/1450886551647424517,"Kaggle solutions: This website collects a whole bunch of ""solutions"" and tips across different Kaggle competitions. Essentially, a list of deep learning and non-DNN machine models that actually work well on real-world datasets. What a treasure trove. https://t.co/G1v5UtlA2T"
7385,@rasbt,2021-10-20 14:58:58+00:00,https://twitter.com/rasbt/status/1450838963195944962,@leonpalafox @mark_riedl I honestly should just get a touch screen laptop just for presenting as well some time :)
7386,@rasbt,2021-10-20 14:57:48+00:00,https://twitter.com/rasbt/status/1450838666818072584,@skdeshpande91 TIL that BART does not necessarily stand for Bidirectional and Auto-Regressive Transformers üòÖ
7387,@rasbt,2021-10-20 13:08:07+00:00,https://twitter.com/rasbt/status/1450811064413720578,"@leonpalafox @mark_riedl No, it's not that great, but PPT doesn't let me use my iPad for making annotations. Unless they changed something in the last couple of months, I would have to get a laptop with a touch screen or a Wacom pen tablet or equivalent I think."
7388,@rasbt,2021-10-20 12:53:16+00:00,https://twitter.com/rasbt/status/1450807329646067714,@leonpalafox @mark_riedl Prob comes down to the primary use case of the tool. Is it for live presenting or making graphics? I favor PPT for making graphics but I do not like the annotation support during presentations. In Keynote you can work around limitations by importing figures made by other software
7389,@rasbt,2021-10-20 12:50:44+00:00,https://twitter.com/rasbt/status/1450806692049006598,"@amy_tabb @hardmaru Naive question, but given that double-blind is broken, and that it can not be enforced fairly and equally, wouldn‚Äôt be single-blind a better option for now until someone comes up with a better idea one day? Single-blind has its own issues, but there are probably fewer?"
7390,@rasbt,2021-10-20 12:48:17+00:00,https://twitter.com/rasbt/status/1450806072479002628,@amy_tabb @hardmaru Lots of good and important points in your blog article. I agree that this creates more problems than it tries to solve. Thanks for sharing!
7391,@rasbt,2021-10-20 12:13:32+00:00,https://twitter.com/rasbt/status/1450797328198250502,"@hardmaru [2/2] As far as I understand, fortunately, there remain no consequences for authors if others share their preprint on social media. Otherwise, if double-blind standards stand in the way of discovering &amp; sharing knowledge, I feel like double-blind has to go"
7392,@rasbt,2021-10-20 12:12:08+00:00,https://twitter.com/rasbt/status/1450796975155187717,"@hardmaru Oh I thought ML conferences already had this, but I just see that it was merely discouraged. In any case, I think it is rarely the authors themselves but others who discover interesting work on arxiv and share preprints. [1/2] https://t.co/bnHLBgS2DZ"
7393,@rasbt,2021-10-20 12:05:59+00:00,https://twitter.com/rasbt/status/1450795429055053833,"@MJSerraPhD @theFordon @wagsandhowls @moduloone I see, we are on the same page then :)"
7394,@rasbt,2021-10-20 12:05:39+00:00,https://twitter.com/rasbt/status/1450795347052310530,"@leonpalafox @mark_riedl I often use powerpoint as my go to for figure making. But I feel like it is really lacking good annotation capabilities during presentation (e.g., via iPad). Keynote is not great (lacks line widths for the pencil annotations) but much better."
7395,@rasbt,2021-10-20 12:03:30+00:00,https://twitter.com/rasbt/status/1450794804187643909,"@westurner @__mharrison__ I really like this website. This is actually the figure that I use in class to explain Big-O analysis (starting with sorting algorithms, and then KNN &amp; decision trees)"
7396,@rasbt,2021-10-20 01:37:54+00:00,https://twitter.com/rasbt/status/1450637366180339712,@mark_riedl * The trade-off being that Keynote is much more limited for drawing shapes and making figures
7397,@rasbt,2021-10-20 01:37:14+00:00,https://twitter.com/rasbt/status/1450637197485518848,"@mark_riedl Unfortunately, it is pretty rudimentary though. Sums, superscripts, and subscripts usually work, but the rest is frustrating. Keynote actually has almost complete latex math support (press CMD+Option+E on macOS), which is why I opted for Keynote vs PPT for lectures back then."
7398,@rasbt,2021-10-20 00:18:54+00:00,https://twitter.com/rasbt/status/1450617485288476672,"""You should be using at least one of the low precision data types if you are on an V100 or A100 because that's their main claim to fame. If your are just doing your plain FP32 computations you are throwing away a lot of compute power""-- Natalia Gimelshein https://t.co/KOEFEg7Erk"
7399,@rasbt,2021-10-19 21:37:31+00:00,https://twitter.com/rasbt/status/1450576873868697604,@iamtrask Same. I feel like we shouldn't call these photos but portrayals
7400,@rasbt,2021-10-19 19:16:17+00:00,https://twitter.com/rasbt/status/1450541330963308548,@alfcnz I wish my slide design would be at least (h)Alf as good üëç
7401,@rasbt,2021-10-19 17:13:10+00:00,https://twitter.com/rasbt/status/1450510344753930246,TIL that @PyTorch has a developer podcast. This is amazing! https://t.co/Epli5qNHlK https://t.co/9iTatEQKm8
7402,@rasbt,2021-10-19 14:10:39+00:00,https://twitter.com/rasbt/status/1450464416810557452,"@__mharrison__ Big O is definitely an interesting and important topic. I feel like it‚Äôs often overlooked when comparing ML models, but it recently had a small comeback with transformers"
7403,@rasbt,2021-10-19 14:02:10+00:00,https://twitter.com/rasbt/status/1450462280110460935,@__mharrison__ * in this particular case not storage but memory
7404,@rasbt,2021-10-19 14:01:27+00:00,https://twitter.com/rasbt/status/1450462099784732676,"@__mharrison__ Probably less frequently used in classic CS, but in the context of ML, it‚Äôs also useful for analyzing space complexity (like why kernel SVM is bad)"
7405,@rasbt,2021-10-19 01:57:57+00:00,https://twitter.com/rasbt/status/1450280023353659395,"@TechBurnout It's only a quick demo notebook to show how it works (it's applied to more interesting datasets by the students via their class projects). In any case, hope it's useful as a technical reference!"
7406,@rasbt,2021-10-19 01:46:23+00:00,https://twitter.com/rasbt/status/1450277112787709955,"@TechBurnout I would have used Iris, but it doesn't have categorical features. But wait, I could have used it like this ü•≥ https://t.co/X4TXW8O45w"
7407,@rasbt,2021-10-19 01:41:35+00:00,https://twitter.com/rasbt/status/1450275904077406211,"Put together a quick demo nb on how to use the native categorical feature support in HistGradientBoostingClassifier, XGBoost, LightGBM, and CatBoost to finish up the gradient boosting lecture tomrw. Still really like the HistGradientBoostingClassifier :) https://t.co/4cQwKXjqZP"
7408,@rasbt,2021-10-18 22:54:28+00:00,https://twitter.com/rasbt/status/1450233851108896770,"@paul_rietschka @HamelHusain Yeah, it's a hefty price tag. I will stick with my Mb Air. Does everything I need at the moment. (Except having to carry adapters ;))"
7409,@rasbt,2021-10-18 22:38:33+00:00,https://twitter.com/rasbt/status/1450229842272825347,"@paul_rietschka @HamelHusain Regarding the charger, you will still be able to charge via USB-C. But I really think it makes sense to use a separate charging port, because why wasting a precious USB-C thunderbolt port for charging? It's great to have the option to choose either or though."
7410,@rasbt,2021-10-18 22:37:29+00:00,https://twitter.com/rasbt/status/1450229574692900865,@paul_rietschka @HamelHusain I really like USB-C and replacing them would be bad. But adding additional ports for everyday (not speciality) use-cases like connecting to a projector are welcome. As a user I shouldn't have to carry around adapters. Forcing me to bring adapters along is bad design imho.
7411,@rasbt,2021-10-18 21:41:07+00:00,https://twitter.com/rasbt/status/1450215391347843074,"@paul_rietschka @HamelHusain Agree, based on the looks. Looks really meh. Spec-wise, the design is great though considering that normal users shouldn't have to buy dongles for everyday use cases. They made it look ugly, but giving it an HDMI port and SD card slot, they fixed design flaws of the previous gen."
7412,@rasbt,2021-10-18 17:50:25+00:00,https://twitter.com/rasbt/status/1450157333930184720,"@KyleCranmer Sure, just saying you should be good with the new 14 inch and 16 inch ones as they likely have the fixed keyboard, too, even though they didn‚Äôt explicitly mentioned it in the presentation today."
7413,@rasbt,2021-10-18 17:44:03+00:00,https://twitter.com/rasbt/status/1450155731676708867,@KyleCranmer This has been fixed 2 years ago in the 16 inch Pro and last year in the 13 inch M1 already? I am assuming they didn‚Äôt bring back the old crappy butterfly one ü§û
7414,@rasbt,2021-10-18 13:17:07+00:00,https://twitter.com/rasbt/status/1450088554802077704,@aha_irshi @HamelHusain hah hilarious. yes!
7415,@rasbt,2021-10-18 13:16:51+00:00,https://twitter.com/rasbt/status/1450088487613575174,"@HamelHusain * I meant ""fan"" of course üòÖ (and it probably does have fun) :)"
7416,@rasbt,2021-10-18 13:14:17+00:00,https://twitter.com/rasbt/status/1450087841774645258,"@HamelHusain [2/2] That being sad, once in a while, installing libraries can be a bit tricky. Most of it has been ironed out if you  use homebrew and conda-forge. However, e.g., installing nightly builds can be a hassle because you may have to compile from source, which is time consuming."
7417,@rasbt,2021-10-18 13:13:07+00:00,https://twitter.com/rasbt/status/1450087546973790209,"@HamelHusain I had a 2018 15 inch MbPro before, and I must say the M1 Macbook Air is probably the best computer I ever owned. By far the fastest (I see this in both data science and ML projects) and has the longest battery life. Plus, it doesn't have a fun and doesn't get super hot [1/2]"
7418,@rasbt,2021-10-18 13:03:05+00:00,https://twitter.com/rasbt/status/1450085021377777678,"@tunguz @Jeande_d Haha, I don't want to sell anyone on automatic experiment tracking tools. Personally, I don't use them 95% of the time. But as someone who always thought they are not useful, I actually do change my mind a bit recently in a large-scale computing context."
7419,@rasbt,2021-10-18 12:49:29+00:00,https://twitter.com/rasbt/status/1450081600277028867,"@tunguz @Jeande_d 2/2 Above @Jeande_d mentioned that the leaderboard fulfills this purpose. But yeah, I think sth like WandB is still useful if you don't waste resources in the scenario I described above. Plus, it has some nice viz for comparing things."
7420,@rasbt,2021-10-18 12:47:42+00:00,https://twitter.com/rasbt/status/1450081151691984900,"@tunguz @Jeande_d Agreed. For interactive experimentation, where you look at one thing at a time, it is not super useful. I can imagine though that many people on Kaggle do both, starting with interactive exp. and then at some point run brute-force run a lot of configuration. 1/2"
7421,@rasbt,2021-10-18 12:31:34+00:00,https://twitter.com/rasbt/status/1450077093061070855,"@tunguz @Jeande_d [2/2] E.g., say you are running 10,000 jobs and a decent percentage fails (due to HPC quirks) and you have to resubmit. With WandB you can just resubmit and it will figure out which jobs still need to run and which ones already completed so you are not wasting resources"
7422,@rasbt,2021-10-18 12:29:50+00:00,https://twitter.com/rasbt/status/1450076656132046849,"@tunguz @Jeande_d That's what I always thought, too. An experiment tracking tool can make your project substantially more convenient though if you are doing experiments on a large scale. In our current study, convinced my PhD student to try WandB and it's a game changer for productivity 1/2"
7423,@rasbt,2021-10-18 02:31:46+00:00,https://twitter.com/rasbt/status/1449926145827381252,"@CSProfKGD Totally agree. It's also surprising and unfortunate that in 2021, there is still so much focus on these bold numbers (often in absence confidence intervals) instead of a formal testing procedure"
7424,@rasbt,2021-10-17 23:39:03+00:00,https://twitter.com/rasbt/status/1449882681676902404,"@mrigankanath_ @bhutanisanyam1 Good question! Like you suggest via mentioning the recent ResNet paper, my gut feeling also says it's probably mostly due to the attention to detail (no pun intended ;)). I.e., taking care with fine-tuning and employing modern best practices."
7425,@rasbt,2021-10-17 18:13:57+00:00,https://twitter.com/rasbt/status/1449800867750744068,@mrigankanath_ @bhutanisanyam1 [2/2] So the answer is neither? Because (a) Swin Transformer showed that the predictive performance with or without patches is more or less the same (https://t.co/lppc8Lue9z). Now they show pred. perf. with and without the transformer architecture is more or less the same. üòÖü§∑‚Äç‚ôÇÔ∏è
7426,@rasbt,2021-10-17 18:11:42+00:00,https://twitter.com/rasbt/status/1449800302073364482,"@mrigankanath_ @bhutanisanyam1 Nice blogpost and summary of the architecture. I find their abstract raises an interesting question ""Is the performance of ViTs due to the inherently-more-powerful Transformer architecture, or is it at least partly due to using patches as the input representation?"" [1/2]"
7427,@rasbt,2021-10-17 17:17:09+00:00,https://twitter.com/rasbt/status/1449786575466995712,"[5/5] Red lines:
if there is a great paper that achieves state-of-the-art results but uses more training data in the process, thisc an cause issues downstream for future papers, so it's a clear reject."
7428,@rasbt,2021-10-17 17:17:09+00:00,https://twitter.com/rasbt/status/1449786574040932364,"[4/5] More tidbits regarding the decision process

- Some conferences there are acceptance quotas (usually not an issue at CVPR, ICCV)
- Each paper is treated independently by ACs (there is no AC quote); this magically results in 21-25% acceptance rate"
7429,@rasbt,2021-10-17 17:17:09+00:00,https://twitter.com/rasbt/status/1449786572732256261,"[3/5] AC Pro tips shared:

1. Organization is key (e.g., keeping a spreadsheet)
2. Get speedier responses by referring to reviewer by name
3. Pit reviewers against each other
4. Think before you tweet"
7430,@rasbt,2021-10-17 17:17:08+00:00,https://twitter.com/rasbt/status/1449786571297787910,"[2/5]
- Increasing the AC pool is pulling out expert reviewers
- https://t.co/WX6ea2wjat does not exist for CVPR, ICCV"
7431,@rasbt,2021-10-17 17:17:08+00:00,https://twitter.com/rasbt/status/1449786569385287684,"Informative and well appreciated talk by @CSProfKGD on ""Pulling back the AC curtain"" (based CVPR, ICCV experience): https://t.co/RPaSS5cLsd
Interesting tidbits:
- an AC may spend approx. 7 hours when finding reviewers for 27 papers
[1/5]"
7432,@rasbt,2021-10-16 21:15:51+00:00,https://twitter.com/rasbt/status/1449484258045747204,"@NIkronic @roydanroy 2/2 That being said, my personal take is that prospective PhD students don't have to have a ton of expertise before doing a PhD. To me, a person with a ton of expertise probably doesn't even need to do a PhD (beyond that it is piece of paper required to qualify for a certain job)"
7433,@rasbt,2021-10-16 21:15:42+00:00,https://twitter.com/rasbt/status/1449484218225020931,"@NIkronic @roydanroy Just a disclaimer that I was not making recommendations or giving career advice via what I said above üòÖ, it's more like my personal journey and what I personally like doing. 1/2"
7434,@rasbt,2021-10-16 17:34:37+00:00,https://twitter.com/rasbt/status/1449428582938333187,"@hackathorn Thanks, Richard! Btw. here's a sneak peek into the ‚òïÔ∏è‚òïÔ∏è‚òïÔ∏ècollection so far: https://t.co/ftZl6EVXZE"
7435,@rasbt,2021-10-16 16:17:32+00:00,https://twitter.com/rasbt/status/1449409184160788484,"@roydanroy I deeply respect people who stay hyperfocused on an area and become absolute experts. For my part, I just love learning new things too much and usually go by gut feeling, getting into doing what I think I'd enjoy and where I could provide some value after getting good at it."
7436,@rasbt,2021-10-16 16:13:56+00:00,https://twitter.com/rasbt/status/1449408276446199815,"@roydanroy Love jumping around and trying new things. Career so far: Got bored by biology &amp; wet lab work and tried computational bio. Bored using off the shelf tools and got into CS and statistical pattern recognition.Bored by Bayesian methods, got into contemporary machine learning and DL."
7437,@rasbt,2021-10-16 15:08:37+00:00,https://twitter.com/rasbt/status/1449391838150942725,"@soumithchintala @colesbury I am really positively surprised how smart and elegant this approach is. I expected some super complicated approach that I could probably not comprehend. Instead, this description in the article makes total sense to even a Python interpreter layman like me :)"
7438,@rasbt,2021-10-16 14:09:49+00:00,https://twitter.com/rasbt/status/1449377042529726471,"@unsorsodicorda @GaelVaroquaux Nice one! Thanks so much for sharing. I actually also missed the Dror et al 2019 ASO paper (""Deep Dominance - How to Properly Compare Deep Neural Models"") and will put that onto my reading list as it was exactly something I was looking for couple of weeks ago"
7439,@rasbt,2021-10-16 14:06:31+00:00,https://twitter.com/rasbt/status/1449376212304941058,"@dabeaz Let me say it like this: If you like tinkering and hacking things together that then actually work pretty well in practice, getting into ML can be a lot of fun :)"
7440,@rasbt,2021-10-16 14:03:35+00:00,https://twitter.com/rasbt/status/1449375471385382915,"@thomasjpfan I gave it another try, and still get the same issue in Safari 15.0 &amp; Jupyter Lab 3.2. In Firefox and Chrome it looks fine. Maybe it's really some temporary Safari quirk, and I wouldn't worry about it too much. There will probably be an update soon when the new macOS comes out https://t.co/B8BI0l7XkE"
7441,@rasbt,2021-10-15 18:36:09+00:00,https://twitter.com/rasbt/status/1449081678505385985,"@thomasjpfan The latest Safari (v15.0), which has a few issues in general üòÖ"
7442,@rasbt,2021-10-15 18:02:52+00:00,https://twitter.com/rasbt/status/1449073302937477123,"@thomasjpfan Yeah, in the compact view. In the expanded view it looks great: https://t.co/mTr5VCpXrR"
7443,@rasbt,2021-10-15 17:56:33+00:00,https://twitter.com/rasbt/status/1449071714533580800,*apparently doesn't render on GitHub. Nbviewer ftw: https://t.co/15sB2CgQ1P
7444,@rasbt,2021-10-15 17:54:46+00:00,https://twitter.com/rasbt/status/1449071264145068034,Was just taking scitkit-learn's nightly build with the new pipeline visualization feature for a spin and love it. Really neat addition for teaching and also super handy when projects demand substantial preprocessing work. https://t.co/A8kjXFNxkV https://t.co/UIhgp6atLG
7445,@rasbt,2021-10-15 16:09:14+00:00,https://twitter.com/rasbt/status/1449044704864124929,@tomgoldsteincs and maybe spice it up by appending _debug or _temp üòÖ
7446,@rasbt,2021-10-15 14:12:12+00:00,https://twitter.com/rasbt/status/1449015252146872324,"@GoogleAI So, in a nutshell, this is a standardized benchmark suite that includes uncertainty metrics (in addition to the standard predictive metrics)? Sounds super useful! Curious to learn more about how the calibration error is calculated. Is there a reference or write-up for that?"
7447,@rasbt,2021-10-14 19:00:09+00:00,https://twitter.com/rasbt/status/1448725331330936842,"@marb5l @fchollet Could probably be easily fixed by changing the survey responses to sth like 
TensorFlow / tf.keras
Standalone Keras"
7448,@rasbt,2021-10-14 17:24:25+00:00,https://twitter.com/rasbt/status/1448701239475195906,"@AndrewM_Webb @zacharylipton Basically turning them into something like the more affordable Beats Flex, but 3 times as expensive and way worse batter life ü§î"
7449,@rasbt,2021-10-14 17:01:48+00:00,https://twitter.com/rasbt/status/1448695545371967488,"@EmmaBostian @NotionHQ A personal wiki (eg dokuwiki). Not the most elegant maybe, but can be back-upped and will stand the test of time"
7450,@rasbt,2021-10-14 01:29:07+00:00,https://twitter.com/rasbt/status/1448460829431640066,"Machine learning meets communication research. Really enjoyed this productive collaboration with @Kaiping_Chen, @SangJungKim2 &amp; Qiantong Gao, where we studied the use color and brightness in conspiracy content using ML"
7451,@rasbt,2021-10-13 13:10:28+00:00,https://twitter.com/rasbt/status/1448274941699371012,"* Where:
T5-Small 60 million params
T5-Base 220 million params
T5-Large 770 million params
T5-XL 3300 million params
Sure, you prob have the strongest gradients somewhere along the diagonal, but still interesting to focus on training size vs model size for best bang for the buck"
7452,@rasbt,2021-10-13 13:01:24+00:00,https://twitter.com/rasbt/status/1448272661470121987,"""classification [...] tasks benefit so much from additional examples that collecting a few hundred examples is often 'worth' billions of parameters."" (Tried to highlight most notable gradients below. Sure bigger=better but extra training ex go a long way) https://t.co/3SybU3vaHG https://t.co/u7d6nJ7omP"
7453,@rasbt,2021-10-13 01:14:44+00:00,https://twitter.com/rasbt/status/1448094820824752135,"@P_Brugarolas @ViolaLaboratory Asterisk: Nowadays several publishers allow updating the (bio)arxiv version after peer-review, (as long as you don't use the version in the final layout). E.g., Elsevier allows that, and I've seen some other journals/publishers doing that, too: https://t.co/T4DEihDQ8f"
7454,@rasbt,2021-10-13 00:54:56+00:00,https://twitter.com/rasbt/status/1448089840164159503,"@iamtrask Yeah, that's a fair point :)"
7455,@rasbt,2021-10-13 00:52:27+00:00,https://twitter.com/rasbt/status/1448089215900819461,"@iamtrask Of course, the resulting progress is a different kind of progress. But there are some lessons learned, and I think a lot of tooling that makes modern methods possible (just using GPUs in the case of AlexNet back then; and now DeepSpeed) originated from making things bigger?"
7456,@rasbt,2021-10-13 00:49:58+00:00,https://twitter.com/rasbt/status/1448088590207094786,"@iamtrask Never trained a model that big myself but regarding ""anyone can initialise a bunch of parameters"" is largely not true based on what I heard. In the current tool landscape, it req. a competent team &amp; significant efforts (&amp; also ideas to design workarounds) to make that work. No?"
7457,@rasbt,2021-10-12 18:33:09+00:00,https://twitter.com/rasbt/status/1447993759082369039,"@chriswolfvision @dimadamen As much as I complain about the peer review system some times, I really appreciate all the time &amp; energy that volunteers spend on organizing &amp; facilitating it. Want to express my appreciation, and I hope that we find a good way of rewarding and acknowledging these efforts better!"
7458,@rasbt,2021-10-12 17:38:27+00:00,https://twitter.com/rasbt/status/1447979993947164678,@TaliaRinger We need more reviewers like you :)
7459,@rasbt,2021-10-12 17:35:36+00:00,https://twitter.com/rasbt/status/1447979278914801670,"@TaliaRinger *that is, allowing people to be more self-critical about their paper, and not having to shy away from listing limitations and weaknesses without having to worry about getting rejected."
7460,@rasbt,2021-10-12 17:33:26+00:00,https://twitter.com/rasbt/status/1447978730689814537,"@TaliaRinger Maybe if we remove the expectation that something has to be revolutionary or groundbreaking to get accepted, we could address this issue somewhat :)"
7461,@rasbt,2021-10-12 17:23:32+00:00,https://twitter.com/rasbt/status/1447976242142228485,"@TaliaRinger In the meantime, I think just focusing on ""technically &amp; factually correct"" and letting people decide themselves what they find interesting is a better way to go"
7462,@rasbt,2021-10-12 17:23:19+00:00,https://twitter.com/rasbt/status/1447976186190213122,"@TaliaRinger Yeah. Developing a good review system for ML is hard, but I hope we will get there some day. There were many interesting discussions recently on how such a system could look like."
7463,@rasbt,2021-10-12 16:14:38+00:00,https://twitter.com/rasbt/status/1447958900574236679,@TaliaRinger Agreed. Actually I think most people check out papers from arxiv directly based on topic and recommendation vs discovering them at conferences. I‚Äôd say going by Reddit and Twitter discussion and recommendations from colleagues is the way to select papers worthwhile reading imhoüòÖ
7464,@rasbt,2021-10-12 13:48:26+00:00,https://twitter.com/rasbt/status/1447922110748405765,"@christian_unoxx @aureliengeron @AllenDowney I would actually say that matmul is probably more useful in most modern/my use cases (e.g., ML &amp; DL) because it treats a 3D tensor as a stack of matrices via the first dimension: https://t.co/93UpRpWoAs"
7465,@rasbt,2021-10-12 13:35:58+00:00,https://twitter.com/rasbt/status/1447918971005640716,"@christian_unoxx @aureliengeron @AllenDowney I wouldn't say this is necessarily an advantage, but it just behaves differently for arrays with more than 2 dimensions (3D tensors and such). https://t.co/9Rau67SZnx"
7466,@rasbt,2021-10-12 13:27:50+00:00,https://twitter.com/rasbt/status/1447916926194290704,"@aureliengeron Originally, I wondered why this is necessary and disliked the addition of this feature. Especially in the last 2 years, it has really grown on me, and I use f-strings almost everywhere now."
7467,@rasbt,2021-10-12 13:26:43+00:00,https://twitter.com/rasbt/status/1447916642042880009,"@aureliengeron @AllenDowney I always want to use the @ operator more, but then the problem is that in NumPy it performs np.matmul not https://t.co/1EFkAGcwKY. For many cases, the results are the same, but there are some common gotchas if you are used to https://t.co/1EFkAGcwKY."
7468,@rasbt,2021-10-12 13:09:16+00:00,https://twitter.com/rasbt/status/1447912251701272584,"@JustinStrharsky Thanks for the kind mentioned, It's really flattering to hear that I have a positive impact on  growing the community of machine learning practitioners :)"
7469,@rasbt,2021-10-12 01:16:33+00:00,https://twitter.com/rasbt/status/1447732892466024451,"*this is for summer 2022. I know, it sounds like it's super far away, but if you are interested in a summer 2022 internship, now is the time to apply."
7470,@rasbt,2021-10-12 01:14:02+00:00,https://twitter.com/rasbt/status/1447732259059032065,This is great advice for students looking for internships! One little but important detail to add: don't wait and procrastinate on this!!! (I know several industry labs that are already in the midst of their search and some already started interviewing candidates a few weeks ago)
7471,@rasbt,2021-10-12 01:06:33+00:00,https://twitter.com/rasbt/status/1447730373824323584,"@elmanmansimov Nice, thanks for sharing! Will forward it to my students!"
7472,@rasbt,2021-10-11 22:52:24+00:00,https://twitter.com/rasbt/status/1447696613179285514,"@JustinStrharsky Thanks! Actually, I just remembered that iOS has a dictation button on they keyboard I can use for voice-and-text, and it works for any app (including my email-to-self one) üòÖ"
7473,@rasbt,2021-10-11 14:11:02+00:00,https://twitter.com/rasbt/status/1447565408068833281,"@unsorsodicorda Which then becomes interesting in the light of the recent, convincing emprical results showing that GD works just as well. Probably also a nice result for theorists in the context of studying generalization bounds"
7474,@rasbt,2021-10-11 14:05:40+00:00,https://twitter.com/rasbt/status/1447564058039918596,"@unsorsodicorda True re theory. Reminds me that many theory papers e.g. regarding generalization bounds rely on SGD in a non-minibatch sense (but one example at a time, sampled *with* replacement) to make life easier"
7475,@rasbt,2021-10-11 12:51:42+00:00,https://twitter.com/rasbt/status/1447545445375520770,"@michalwols Ah yes, true. Hence the LayerNorm in transformers."
7476,@rasbt,2021-10-11 12:47:51+00:00,https://twitter.com/rasbt/status/1447544474108940292,"@JustinStrharsky @jeremyphoward Interesting, you use a voice to text app or just regular voice recordings you transcribe later? One thing I use my phone for is the ""Note to self"" app to jot down and email myself ideas in the same manner. Looking for an app that could do that with voice though (sending as text)"
7477,@rasbt,2021-10-11 12:46:01+00:00,https://twitter.com/rasbt/status/1447544011351277571,"@GiorgioMantova @jeremyphoward Haha I wish. I still use Anki actually. Not super intensely, but like 10 minutes each day. I started a few times over in the last years. There are always interesting things to add and learn about."
7478,@rasbt,2021-10-11 12:44:17+00:00,https://twitter.com/rasbt/status/1447543576603381761,@michalwols you mean due to forgetting to use the running mean and variance during inference?
7479,@rasbt,2021-10-11 12:29:36+00:00,https://twitter.com/rasbt/status/1447539882117767169,"Looks like very interesting and impressive work! Sure, skip-connections and BatchNorm are probably not essential, but they do make your life easier (for now)."
7480,@rasbt,2021-10-11 02:33:29+00:00,https://twitter.com/rasbt/status/1447389866141097993,"@jeremyphoward * I started using Anki mobile later (I actually think I had it on my computer already), but this was in the period 2008-2011 before I owned a smartphone."
7481,@rasbt,2021-10-11 02:31:36+00:00,https://twitter.com/rasbt/status/1447389391027113990,"@jeremyphoward Fun fact: when I was an undergrad in Germany, I made physical flash cards &amp; took them on walks on hiking trails. Did it mainly because I liked being outside, but I think it actually helped, that is, looking at a concept at the card and thinking about it while wandering around üòÖ"
7482,@rasbt,2021-10-10 20:08:08+00:00,https://twitter.com/rasbt/status/1447292888774332416,"@PCacioppi @ctitusbrown Where is this quote from? What you describe sounds like something that would happen via the ""with"" context manager."
7483,@rasbt,2021-10-10 18:49:33+00:00,https://twitter.com/rasbt/status/1447273111976566785,"@ctitusbrown Yeah, if is possible, having the file auto-closed as a default (without requiring the context manager) would also help with ensuring best practicing. This might be a technical limitation, due to backwards compatibility, or the other use-case is more common than we thinküôÉ"
7484,@rasbt,2021-10-10 18:38:15+00:00,https://twitter.com/rasbt/status/1447270266955046912,"@ctitusbrown Afaik, there is (still?) no good way around using a context manager here if you want a closed file upon encountering an exception. And you can't put the 'with' statement with a list comprehension. You can remove the second indentation via a list comprehension though"
7485,@rasbt,2021-10-10 17:58:58+00:00,https://twitter.com/rasbt/status/1447260380120682501,"@david_macedo [2/2] I am not sure what we gain by having papers ""accepted"" to a conference -- doesn't make those more or less useful. Instead, I think using expert reviewers to fix/weed out technically or factually wrong papers and/or improving related work discussions could be more productive"
7486,@rasbt,2021-10-10 17:56:00+00:00,https://twitter.com/rasbt/status/1447259633693888520,"@david_macedo Yes. Given that we nowadays find and share papers on e.g., Arxiv and have (often expert) discussions on Twitter, reddit, etc. I wonder if ""accepting"" a paper to a conference via the traditional model is even that useful or necessary. [1/2]"
7487,@rasbt,2021-10-10 16:07:57+00:00,https://twitter.com/rasbt/status/1447232445619871747,"@Al_Grigor Oh yeah, German keyboards üòÖ ... I remember I did some coding in Perl back then (bioinformatics stuff) and noticed how inconvenient they were for coding ... when using { } and \. Probably similar issue when writing LaTeX."
7488,@rasbt,2021-10-10 13:53:31+00:00,https://twitter.com/rasbt/status/1447198611150934024,"Also: as the number of submissions grows larger, the probability of looking at the author's response to the reviewers (/rebuttal) approaches zero."
7489,@rasbt,2021-10-10 13:48:57+00:00,https://twitter.com/rasbt/status/1447197463509717002,"@iamtrask Nice one. Agreed, NumPy is one of the main pillars of scientific computing &amp; the first thing to pick up when getting into data sci &amp; ML. Created a similar lecture a few years ago that I published as a blog post last yr, accompanied by recordings if useful: https://t.co/SkStNbFy9u"
7490,@rasbt,2021-10-09 16:07:58+00:00,https://twitter.com/rasbt/status/1446870061319393286,"@ivoflipse5 I avoided the term ""history"" on purpose üòá"
7491,@rasbt,2021-10-09 15:34:26+00:00,https://twitter.com/rasbt/status/1446861620483866629,"Great summary of ML &amp; DL, starting with perceptrons in 1950's.

And in particular, a great summary of the latest developments re architectures for SOTA computer vision: 
CNNs -&gt; visual transformers -&gt; MLPs again without attention or convolutions -&gt; CNNs again (ResNets tuned well)"
7492,@rasbt,2021-10-09 14:31:10+00:00,https://twitter.com/rasbt/status/1446845699946160128,"@ykilcher *anyways, if someone wants to play around with this, these are results from a simple AlexNet trained on Cifar-10 for my DL course last semester (https://t.co/awGZjC3Mcp). I observed this happening with larger architectures (VGG) occasionally as well."
7493,@rasbt,2021-10-09 14:25:14+00:00,https://twitter.com/rasbt/status/1446844204425129985,"@ykilcher In the original double descent paper, they also looked at epochs. Sure, they didn't focus on it extensively, so they probably didn't have some of these extreme cases observed, but still I am not convinced that we have two different phenomena here."
7494,@rasbt,2021-10-09 14:20:29+00:00,https://twitter.com/rasbt/status/1446843009249730561,"@ykilcher Just had a quick look at the paper, and it appears that this was actually what they were looking at ü§¶‚Äç‚ôÇÔ∏èüòÖ. Anyways, to me this looks very similar to double decent (like in the screenshot of my training results above). Double descent in practice is stms different, weird, and subtle"
7495,@rasbt,2021-10-08 18:12:10+00:00,https://twitter.com/rasbt/status/1446538927645642753,@ykilcher or training for less time (and assuming you don't have exploding gradient issues) https://t.co/d1hmRxNOb0
7496,@rasbt,2021-10-08 17:56:16+00:00,https://twitter.com/rasbt/status/1446534926766071816,"@pwang @gvanrossum @ThePSF @PyData Nice! Btw. last month I saw that Python ranked #1 in IEEE Spectrum's ranking, too üéâ (https://t.co/kWo3tnEvne)"
7497,@rasbt,2021-10-08 01:32:29+00:00,https://twitter.com/rasbt/status/1446287348229148672,@ykilcher weight sharing ü§å
7498,@rasbt,2021-10-08 01:24:31+00:00,https://twitter.com/rasbt/status/1446285345226641408,"Yes, totally agree. If we continue down this path and just throw more compute at it, why bother developing new architectures at all and not just use Bayes Optimal Classifiers for everything."
7499,@rasbt,2021-10-08 00:52:56+00:00,https://twitter.com/rasbt/status/1446277396005629952,"@anuragsaharoy @zacharylipton @willcallag Hah, yeah. Why rely on an existing, established, and working system when you can roll your own ü§∑‚Äç‚ôÇÔ∏è. Schools in Germany did the same thing during Corona when they needed course management and video conferencing software"
7500,@rasbt,2021-10-07 21:53:17+00:00,https://twitter.com/rasbt/status/1446232185279746061,"@djpard1s A piece of paper for daily tasks, digital folders for most project data, and OneNote for digital notes and tidbits. https://t.co/3HtDAgjkis"
7501,@rasbt,2021-10-07 21:50:20+00:00,https://twitter.com/rasbt/status/1446231442598596609,"@willcallag @zacharylipton In Germany, you can actually send an email to the post office, and they will print and send it as a traditional, physical letter for you."
7502,@rasbt,2021-10-07 21:44:52+00:00,https://twitter.com/rasbt/status/1446230066912956419,"@vdmbrsv @unsorsodicorda Yeah, I remember the back &amp; forth on this with earlier this summer. Personally, have tried a few architectures, and the perf. didn‚Äôt match gradient boosting via XGBoost and LightGBM. But I also didn‚Äôt invest extensive time into tuning. Looking forward to the empirical comparison!"
7503,@rasbt,2021-10-07 12:35:18+00:00,https://twitter.com/rasbt/status/1446091763354046471,"Continuing the discussion, I just saw the ""Deep Neural Networks and Tabular Data: A Survey"" paper uploaded to arxiv the other day: https://t.co/Qpvpdiv0xt. Useful list of most (/all?) the approaches for classification (left) and data generation (right) so far https://t.co/KqnjadJ08J"
7504,@rasbt,2021-10-06 21:39:38+00:00,https://twitter.com/rasbt/status/1445866363139014656,"@TaliaRinger Nice! Just getting it done is already a big milestone üéâ, and good luck! Fingers crossedü§û"
7505,@rasbt,2021-10-06 21:37:07+00:00,https://twitter.com/rasbt/status/1445865729228558342,"@driscollis Similar argument could be made for for-loops :). I like toying around with new features &amp; likewise I am interested in trying it seriously some time. Maybe 2-3 Python versions down the road due to compat. reasons (similar to f-strings, which I now like to use almost everywhere)."
7506,@rasbt,2021-10-06 19:54:34+00:00,https://twitter.com/rasbt/status/1445839922359947270,"@tymwol Yeah, that's a trade-off. But given that being pythonic is such an important aspect of using Python, I wished that they went for being more familiar in syntax for Python users üòÖ"
7507,@rasbt,2021-10-06 19:37:54+00:00,https://twitter.com/rasbt/status/1445835727942651906,"@mfreib @bernhardsson Yeah, I am not a fan of protein powder. This does looks delicious overall though. Btw try the bananas frozen (you can usually still slice them when they are frozen). It's a real game changer."
7508,@rasbt,2021-10-06 19:33:11+00:00,https://twitter.com/rasbt/status/1445834540748967937,"@tymwol Yeah that makes sense. My main gripe with it is that based on how Python syntax usually works, this would be a 'first_name is not defined' error. In Python, we use the equal sign for variable assignment. I would have also accepted sth involving the walrus operator here."
7509,@rasbt,2021-10-06 18:59:11+00:00,https://twitter.com/rasbt/status/1445825983651581952,"@tymwol Let's say the feature has grown on me since I posted this yesterday. But besides the functionality, I feel like the syntactic implementation is still meh. I.e., I really dislike that this is binding a value to a variable: https://t.co/6stD6eTU64"
7510,@rasbt,2021-10-06 17:25:52+00:00,https://twitter.com/rasbt/status/1445802499265294336,@sukhmeet7 @bernhardsson yeah
7511,@rasbt,2021-10-06 16:18:14+00:00,https://twitter.com/rasbt/status/1445785478452727809,@bernhardsson Oat milk + frozen banana (sliced) + egg + greek yoghurt. Optionally add some peanut butter and throw everything into a mixer. Takes 1-2 minutes and it's super delicious.
7512,@rasbt,2021-10-06 15:58:58+00:00,https://twitter.com/rasbt/status/1445780629652586497,"@le_roux_nicolas @MSFTResearch @susan_dumais Awesome! Congratulations, Nicolas üéâ

Very important topics to work on, and it's great to hear people seriously care about this and invest in working on it!"
7513,@rasbt,2021-10-06 13:05:57+00:00,https://twitter.com/rasbt/status/1445737090499559425,@zacharylipton @sunilmallya @mldcmu There is a fine line between awesome amounts of snow so that you can go cross country skiing in the afternoon vs just enough snow to just make biking and driving inconvenient.
7514,@rasbt,2021-10-06 12:57:38+00:00,https://twitter.com/rasbt/status/1445734998867419136,@GuzaUy I do like this one though: https://t.co/1zTzkXxcZH
7515,@rasbt,2021-10-06 12:53:38+00:00,https://twitter.com/rasbt/status/1445733990330257419,"@GuzaUy [2/2] but for the left match/case example, I feel like it makes sense when I read it, but at the same time I worry about some behavior in edge cases I am not accounting for. The right hand side has a more deterministic logical flow to me, but maybe that's just how my brain works."
7516,@rasbt,2021-10-06 12:52:24+00:00,https://twitter.com/rasbt/status/1445733679926444038,"@GuzaUy That's actually a great article. I can see the utility for some use cases. In general, there seems to be this dislike of if/elif/else statements. I actually do think that even in this case, the code on the right is more verbose but perfectly readable. Maybe I am just to new [1/2] https://t.co/Dg0jOi7sYo"
7517,@rasbt,2021-10-06 02:28:19+00:00,https://twitter.com/rasbt/status/1445576625450483723,"@msjgriffiths Written like that, I actually kind of like it :)"
7518,@rasbt,2021-10-06 00:39:57+00:00,https://twitter.com/rasbt/status/1445549352496209922,"@admercs @yaroslavvb That's actually a good point. Maybe especially attractive for scientific computing contexts as well, where everything serious is jit-based nowadays."
7519,@rasbt,2021-10-06 00:38:45+00:00,https://twitter.com/rasbt/status/1445549053022904322,"@ctnzr @Google Ok, it was (is?) called De-Mail (https://t.co/fpl24yBJmO), and they charged 0.18‚Ç¨ for sending a ""personal"" or ""confidential"" email. https://t.co/R4GwLb7TB6"
7520,@rasbt,2021-10-06 00:29:40+00:00,https://twitter.com/rasbt/status/1445546767005540357,"@ctnzr @Google The German post service actually implements that (https://t.co/1xkpp4VAWK). Ok, they do print your email though and send it via physical mail, so it's not completely the same. I do think though that they had something like pay-to-send-email service a few years ago though."
7521,@rasbt,2021-10-06 00:19:31+00:00,https://twitter.com/rasbt/status/1445544212204720129,"@Le_Dumiebi I see. Given that Python is the old and new cool thing, I can see now why it was added ;)"
7522,@rasbt,2021-10-05 23:59:34+00:00,https://twitter.com/rasbt/status/1445539190477713411,"@kylewadegrove Hm, yeah, maybe. But even considering an example like below, I am not sure I like the fact that it kind of breaks with typically expected Python behavior. Like that this is binding a value to the variable first_name vs using a previously defined first_name variable as a value. https://t.co/D3hCU4UAAg"
7523,@rasbt,2021-10-05 23:49:28+00:00,https://twitter.com/rasbt/status/1445536650277232640,"@miguelalonsojr Yes, sure! Just worried that people adopting it freely will make code less accessible to newcomers though."
7524,@rasbt,2021-10-05 23:37:26+00:00,https://twitter.com/rasbt/status/1445533620681129990,"A maybe not so cool feature ...
I feel like the left case is intuitive. Maybe it's because I used Python for so many years, but I can imagine even people not coding in Python can guess what's going on. The example on the right hand side? Probably not so much. https://t.co/ELBRBRZcHB"
7525,@rasbt,2021-10-05 23:25:28+00:00,https://twitter.com/rasbt/status/1445530610903093256,"""Python 3.10: Cool New Features for You to Try"" (https://t.co/rMfi2EgwuC): Am particularly excited about the improved error msg. Currently helping students with their first HW, and most common problems are subtle things like missing commas or typos, which are now easier to spot https://t.co/MuJQE6ZdHS"
7526,@rasbt,2021-10-05 21:54:51+00:00,https://twitter.com/rasbt/status/1445507806455480322,"@PaulCumbo I use a standing desk from Uplift since grad school (got it ~7 years ago). My Ph.D. advisor did a lot of research into which one to get back then. I liked her's so I got one, too, and I am really happy with it."
7527,@rasbt,2021-10-05 21:37:15+00:00,https://twitter.com/rasbt/status/1445503375169056769,"@ben_j_lindsay Yes, this. I always thought it was just me and my inexperience with Excel. But yeah, this was always driving me nuts."
7528,@rasbt,2021-10-05 13:12:56+00:00,https://twitter.com/rasbt/status/1445376457958641664,"Just noticed scikit-learn added a post-pruning procedure (minimal cost complexity pruning) to decision trees a few versions ago: https://t.co/OGlRFI8EQI

More info about it from the docs:
- https://t.co/IkjQ9skYyU
- https://t.co/YPsW4KzBld"
7529,@rasbt,2021-10-05 12:38:27+00:00,https://twitter.com/rasbt/status/1445367781575245826,"@kevin_zakka @DynamicWebPaige Or just show some appreciation to students who spent that time and hard work on preparing a high quality code accompanying their research paper, which might be useful to others. Because there is currently no real incentive for that in academia."
7530,@rasbt,2021-10-05 12:34:17+00:00,https://twitter.com/rasbt/status/1445366731963346945,"@real_laggy That's how I felt when I started grad school. A few liters of midnight oil later, it all clicked into place and makes sense now :)"
7531,@rasbt,2021-10-05 01:48:38+00:00,https://twitter.com/rasbt/status/1445204251848871937,"@rahuldave @karlhigley @3blue1brown @alfcnz I think @eigensteve had some amazing ones, too!"
7532,@rasbt,2021-10-05 01:45:26+00:00,https://twitter.com/rasbt/status/1445203446177673216,There were ~two moments in my life when I really started to appreciate linear algebra. (Spoiler: it was not solving systems of linear eq). 1: learning computer vision and thinking of linear transformations. 2: Implementing gradient descent and backpropagation efficiently. https://t.co/sfQXi7ksWC
7533,@rasbt,2021-10-04 21:29:28+00:00,https://twitter.com/rasbt/status/1445139030576873484,"[2/2] 
(b) designing pre-text tasks that focus on larger-scale (global vs local) color augmentations (like channel randomization) can be beneficial for certain tasks  (at least fruit irreg. detection) -- so, at least something worthwhile considering. https://t.co/q5nO5XJ7W5"
7534,@rasbt,2021-10-04 21:29:28+00:00,https://twitter.com/rasbt/status/1445139027754110989,"""Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies"" (https://t.co/4RRdGRpcSF)
Interesting take-aways re self-supervised representation learning from this work:
(a) early stopping on the pre-text task benefits the downstream task, too
[1/2]"
7535,@rasbt,2021-10-04 20:44:22+00:00,https://twitter.com/rasbt/status/1445127677653004300,"@AlexGDimakis I wish! I think our university uses ProQuest, and I cannot even find the thesis of my own PhD student there who graduated back in May üòÖ"
7536,@rasbt,2021-10-04 20:14:17+00:00,https://twitter.com/rasbt/status/1445120107555049473,@betatim Discord ftw
7537,@rasbt,2021-10-04 18:26:16+00:00,https://twitter.com/rasbt/status/1445092924291682307,@DimitrisPapail @AlexGDimakis That sounds like good advice. Ideally maybe having at least 2-3 faculty members as good matches for backup purposes :)
7538,@rasbt,2021-10-04 18:18:23+00:00,https://twitter.com/rasbt/status/1445090941681995795,"@AlexGDimakis Yes, that's a good one! The only caveat is that only a fraction of Ph.D. theses are accessible (or discoverable) online."
7539,@rasbt,2021-10-04 17:15:05+00:00,https://twitter.com/rasbt/status/1445075009513328653,"""PASS: An ImageNet replacement for self-supervised pretraining without humans"" (https://t.co/H6Zmcy5AFo). This datasets of 1.4 million images with CC-BY license, and fewer problematic images, seems like a good alternative to ImageNet for pre-training your next CV model."
7540,@rasbt,2021-10-04 17:07:17+00:00,https://twitter.com/rasbt/status/1445073048290349058,"@AlexGDimakis If I had to apply for grad school, I would be more interested in (1) the career paths of students graduated from the different departments and (2) their satisfaction rating and comments about those departments."
7541,@rasbt,2021-10-04 17:02:37+00:00,https://twitter.com/rasbt/status/1445071875621675018,"@roydanroy @AlexGDimakis Strongly agree. Imagine ranking poets by the number of poems they wrote, doctors by the number of patients they saw, etc. ..."
7542,@rasbt,2021-10-04 14:24:58+00:00,https://twitter.com/rasbt/status/1445032199737257986,@adjiboussodieng Congrats! Wishing you lots of success and fun in this amazing new position!
7543,@rasbt,2021-10-04 14:04:19+00:00,https://twitter.com/rasbt/status/1445027003921539077,"@TaliaRinger Same. While I knew that some PhD students have papers towards their end of their PhD, I didn‚Äôt even know that it was expected to produce multiple papers besides the PhD  thesis. Anyways, fortunately our department does not expect students to have papers to be accepted :)"
7544,@rasbt,2021-10-04 13:43:43+00:00,https://twitter.com/rasbt/status/1445021820281933829,"@sameervk10 You mean journal subscriptions? Honestly, I don't have a single subscription myself, so I am maybe not a good person to make a recommendation here :)"
7545,@rasbt,2021-10-04 02:12:36+00:00,https://twitter.com/rasbt/status/1444847892347424777,Great to see my favorite go-to architecture for CV remains relevant :)
7546,@rasbt,2021-10-02 20:53:44+00:00,https://twitter.com/rasbt/status/1444405258462060545,"@maosbot Yeah, exactly! I‚Äôd say if you‚Äôd give the same lecture in person that you could have prerecorded otherwise, this is bad lecture design. However, having gone back to in-person, I do see some value in that format if you plan in pauses for Q&amp;A."
7547,@rasbt,2021-10-02 14:15:39+00:00,https://twitter.com/rasbt/status/1444305078056280067,"@tomgoldsteincs ** but yeah regarding the main point that there is no noticeable difference between predictive performances of SGD vs full batch GD, then it is clear and CIs might be wasteful. :)"
7548,@rasbt,2021-10-02 14:09:45+00:00,https://twitter.com/rasbt/status/1444303595617259526,@tomgoldsteincs *that would be for different random seeds for the initial weights. And optionally for shuffling the dataset after each epoch.
7549,@rasbt,2021-10-02 14:08:25+00:00,https://twitter.com/rasbt/status/1444303261197115392,"@tomgoldsteincs I can imagine it was already a very intensive and expensive study, but confidence intervals would have been really nice here!"
7550,@rasbt,2021-10-01 17:21:37+00:00,https://twitter.com/rasbt/status/1443989490150817801,"@ununth A particular (and very influential) type of convolutional neural network. If you are interested in more details, I have an relatively short explanation here: https://t.co/rT2VJZrO0g and code implementation here: https://t.co/hqEx8g2NNh"
7551,@rasbt,2021-10-01 17:06:35+00:00,https://twitter.com/rasbt/status/1443985707601735681,"""Has the ResNet Hypothesis been debunked?"" -- Once in a while, you can find really good discussions and pointers on reddit (https://t.co/B96xaI23r8)

aka papers that you can (1) train ResNets without shortcuts with good results if you are careful about initialization and [1/2]"
7552,@rasbt,2021-10-01 16:10:53+00:00,https://twitter.com/rasbt/status/1443971690216792075,"@therriaultphd [2/2] and then you tell the story when you downloaded that .xlsx file that couldn't be opened in Excel because it had too many rows, you spent half a day trying various Excel alternatives to open it, &amp; you later discovered that it was actually just a CSV file with an .xlsx ending"
7553,@rasbt,2021-10-01 16:09:24+00:00,https://twitter.com/rasbt/status/1443971319381598208,"@therriaultphd Based on feedback, students also really appreciate it when you tell these real-life stories &amp; lessons learned. E.g., like when talking about using a simple command line tool like head or tail to check how your data is formatted before opening,  ... [1/2]"
7554,@rasbt,2021-10-01 16:05:00+00:00,https://twitter.com/rasbt/status/1443970211493957640,"@therriaultphd I'd also say don't hesitate to spontaneously throw in a related anecdote in here and there. Practiced and professional talks are nice, but the real interesting parts are when speakers occasionally goes off the script"
7555,@rasbt,2021-10-01 13:51:00+00:00,https://twitter.com/rasbt/status/1443936486592765955,"@skoularidou @qu3tzalify I feel the same way. I deeply enjoy my research projects. Actually, the more time I have to be hands-on, the more I enjoy it. Unfortunately, to keep up with the pressures and rates, it seems that one has to become more of a lab manager type to increase the throughput"
7556,@rasbt,2021-10-01 13:38:17+00:00,https://twitter.com/rasbt/status/1443933288297553924,"@skoularidou @qu3tzalify [2/2] she noticed that this was absolutely fine and nothing bad happened. She said that from then on, when she realized that, she enjoyed her job so much more and became much happier."
7557,@rasbt,2021-10-01 13:38:00+00:00,https://twitter.com/rasbt/status/1443933218298814467,"@skoularidou @qu3tzalify My PhD advisor once told me that she had a love-hate relationship with her job due to the pressures related to publications &amp; grants. Then, one year when she worked reasonable hours and stopped pushing herself beyond the reasonable limits for the quest of more publications [1/2]"
7558,@rasbt,2021-10-01 02:53:08+00:00,https://twitter.com/rasbt/status/1443770930447233024,"@rahuldave @unsorsodicorda @alex000kim @anacondainc @code Whoa! I must say I really admire people who can use sed and awk fluently and productively :). It's just that it doesn't really work for me. Every time I was thinking about learning it vs just getting it done in Python, I did the latter üòÖ"
7559,@rasbt,2021-10-01 02:39:23+00:00,https://twitter.com/rasbt/status/1443767470079283203,"@phd_derek @Sergei_Imaging @togelius Yeah, they work pretty well, too. I feel like Word or Google Docs are less clunky for first &amp; early drafts where there are lots of suggestions and changes."
7560,@rasbt,2021-09-30 22:09:20+00:00,https://twitter.com/rasbt/status/1443699511017283590,"@codeFreedomRitr @Jlong5795 @mintiiB Would definitely be super interested in learning more about creating &amp; keeping a dev diary. (Can imagine this could also come in handy for research projects.) I.e., super curious about workflows and tools."
7561,@rasbt,2021-09-30 22:06:52+00:00,https://twitter.com/rasbt/status/1443698890503557124,@MausJens @alex000kim @anacondainc I heard WSL/WSL2 is very popular though ;). Or maybe that's only among that subset of former Linux or macOS users :P
7562,@rasbt,2021-09-30 21:42:52+00:00,https://twitter.com/rasbt/status/1443692848642150401,@TheKreja @pooja_LuvIndia @IAkhil3 @togelius That's why I mentioned OneDrive. I actually recommend just editing in the browser so everyone uses the same version that is constantly synced back.
7563,@rasbt,2021-09-30 18:55:43+00:00,https://twitter.com/rasbt/status/1443650783380221954,"@Sergei_Imaging @togelius Seriously though üôÉ. Actually most of the intros, related work, and abstracts of our collaborative papers were actually written and collaboratively edited in Word (or Google Docs) before moving them to Overleaf later."
7564,@rasbt,2021-09-30 18:11:03+00:00,https://twitter.com/rasbt/status/1443639543471747072,"@unsorsodicorda @alex000kim @anacondainc @code Will take a look at GitLens, thanks! While I mentioned VC Code GUI for Git, I am actually still a git CLI user. But who knows, maybe GitLens is finally the one that makes me want to reconsider ;)"
7565,@rasbt,2021-09-30 18:08:09+00:00,https://twitter.com/rasbt/status/1443638816175235074,"@unsorsodicorda @rahuldave @alex000kim @anacondainc @code I do use bash here and there though. Actually, I use the following for renaming files a lot:

for f in fgh*; do mv ""$f"" ""${f/fgh/xxx}"";done"
7566,@rasbt,2021-09-30 18:06:43+00:00,https://twitter.com/rasbt/status/1443638455515353089,"@unsorsodicorda @rahuldave @alex000kim @anacondainc @code I agree with your disagreement. We learned about various command line tools in a bioinformatics class, but I must say that awk was one of the things that never really clicked with me. I'd rather write a Python or Perl script than trying to do sth in awk and screw things up"
7567,@rasbt,2021-09-30 18:01:30+00:00,https://twitter.com/rasbt/status/1443637142161399816,"@__jrbourbeau__ @CoiledHQ Wow, really that long ago? Time is running so fast! And thanks again!"
7568,@rasbt,2021-09-30 18:00:34+00:00,https://twitter.com/rasbt/status/1443636906504359941,@hazrat_ai Thanks for the note! I am sure @PacktPub would be interested in looking into that ...
7569,@rasbt,2021-09-30 17:51:55+00:00,https://twitter.com/rasbt/status/1443634730751217671,"@togelius Yes, some people still use Word. And it is sufficient for certain things. As much as i dislike Word for many things, I do actually like the comments and tracked changes features. It is super useful for collaborations. But emailing word files? No. In 2021 you can use OneDrive"
7570,@rasbt,2021-09-30 12:55:08+00:00,https://twitter.com/rasbt/status/1443560040217157643,"@unsorsodicorda @alex000kim @anacondainc That's true. But it definitely can replace some things like remote file editing (vs shell + vi), editing and running jupyter notebooks (if using the shell for launching it counts), and working with GitHub through the VS Code GUI."
7571,@rasbt,2021-09-30 12:51:00+00:00,https://twitter.com/rasbt/status/1443559002248556549,"""The need for serverless Python, SciPy 2021"" -- Plot twist: This is actually much more relevant to ML than I thought. Great talk by Stephanie Wang on how using the cloud has evolved over the years, functions as a service, and distributed computing with Ray https://t.co/TvcwVWI6WV https://t.co/pUGB3k5fuR"
7572,@rasbt,2021-09-30 12:29:28+00:00,https://twitter.com/rasbt/status/1443553582087905289,"@alex000kim @anacondainc Whoa! But to be fair, VS Code gives us less and less reasons to. Haha sometimes I feel so old school still using git‚Äôs CLI or starting Jupyter Lab from the shell terminal"
7573,@rasbt,2021-09-30 02:13:30+00:00,https://twitter.com/rasbt/status/1443398568295944192,"@kbash09 @AndrewYNg That's an interesting point! I think it typically goes a bit beyond ""just"" high-quality features. I.e., also focusing on what data points to collect, how data points are labeled, considering labeling uncertainty &amp; inconsistencies etc. Lots of interesting challenges in this realm!"
7574,@rasbt,2021-09-29 22:33:35+00:00,https://twitter.com/rasbt/status/1443343225503223818,"@dustinvtran @roydanroy *Can confirm. Based on a book I read back then, it was called the ' ""groundbreaking"" 5-day-2-day diet'"
7575,@rasbt,2021-09-29 22:26:05+00:00,https://twitter.com/rasbt/status/1443341336900472833,"@dustinvtran @roydanroy Hah true and a lot of it was probably involuntary too ;). On a serious note, I actually did the ‚Äúofficial‚Äù version though, I don‚Äôt recall but I think it was the 5/2 approach or sth like that"
7576,@rasbt,2021-09-29 19:35:11+00:00,https://twitter.com/rasbt/status/1443298329371283461,Amazing resource! Next task is to set up a poll to find out which are the ones most worthwhile picking up in 2021.
7577,@rasbt,2021-09-29 19:16:43+00:00,https://twitter.com/rasbt/status/1443293682933903364,@roydanroy It was a trend back then and I tried it about 10 years ago in grad school for approx 6 months. Extremely socially inconvenient.
7578,@rasbt,2021-09-29 17:30:46+00:00,https://twitter.com/rasbt/status/1443267019462397955,"@ATBasye @AndrewYNg Oh yeah, that's fair! :)"
7579,@rasbt,2021-09-29 17:19:43+00:00,https://twitter.com/rasbt/status/1443264235874684936,"@jeanmarcalkazzi Lesson learned. Since then, I am a bit hesitant giving talks about unpublished work."
7580,@rasbt,2021-09-29 17:18:59+00:00,https://twitter.com/rasbt/status/1443264052478754817,"@jeanmarcalkazzi FWIW I had a case where a colleague from another dep copied an idea from a seminar talk of our unpublished work. I.e., the person didn't copy our method but the main idea behind it, and then published a paper 2 years after our paper claiming that they came up with that idea."
7581,@rasbt,2021-09-29 17:16:47+00:00,https://twitter.com/rasbt/status/1443263499774345217,"@jeanmarcalkazzi Good and valid question! Unfortunately, I don't have a good answer for that. In general, I don't think any conference is immune to that if no public records of the papers and submission details exist."
7582,@rasbt,2021-09-29 16:21:36+00:00,https://twitter.com/rasbt/status/1443249613180375047,@ykilcher *moral of the story and probably also generally a good thing: don't ever submit a paper to a conference without posting an arxiv preprint first.
7583,@rasbt,2021-09-29 16:19:20+00:00,https://twitter.com/rasbt/status/1443249043405148160,"@ykilcher arg, this whole thing about copying and plagiarizing rejected conference papers makes me want to write and submit conference papers even less"
7584,@rasbt,2021-09-29 12:51:07+00:00,https://twitter.com/rasbt/status/1443196641847152647,@david_picard I can also see a top 3 out of 5 or sth like that depending on how reliable methods converge
7585,@rasbt,2021-09-29 12:47:00+00:00,https://twitter.com/rasbt/status/1443195607569637386,@david_picard I like the random seed 0-5 idea :). Previously I have been doing 0-3 but depending on the computational budget &amp; method 0-5 or 0-10 is preferred https://t.co/dvb7v9rhV9
7586,@rasbt,2021-09-29 12:28:29+00:00,https://twitter.com/rasbt/status/1443190948524171266,@iamtrask @ylecun Haha actually happened to us. Thought it is 2021 and we could be honest about titles and people would appreciate new methods that are effective yet simple to use
7587,@rasbt,2021-09-29 01:40:21+00:00,https://twitter.com/rasbt/status/1443027837406138369,@david_picard Depends on who we are talking about :). Those who don't already use error bars might be incentivized to tune the random seed as a hyperparameter üòÖ
7588,@rasbt,2021-09-28 16:56:21+00:00,https://twitter.com/rasbt/status/1442895969482264576,"@AlejandroPiad Yesterday, for example, I learned about autoencoders RNNs. I mean the difference between a regular encoder-decoder RNN and a encoder-decoder autoencoder RNN (never seen or used the latter until someone pointed it out)"
7589,@rasbt,2021-09-28 16:28:17+00:00,https://twitter.com/rasbt/status/1442888904286380032,"@AlejandroPiad Yeah, and I had so many fruitful discussions here helping me learn new things about concepts that I thought I already completely understood. It can be a great way for sharing knowledge and staying up to date"
7590,@rasbt,2021-09-28 16:21:36+00:00,https://twitter.com/rasbt/status/1442887224190775298,"@AlejandroPiad I agree, you cannot learn ML from Twitter threads. But you can learn something about ML from Twitter threads. What I mean is that Twitter is great for sharing and discovering useful tidbits here and there."
7591,@rasbt,2021-09-28 13:15:22+00:00,https://twitter.com/rasbt/status/1442840356467494915,"@jwuphysics Ok that‚Äôs fair! It‚Äôs a general problem with decision trees and decision tree visualization. I‚Äôd also say when a tree becomes so big that it becomes unwieldy, it kind of loses its advantage as an interpretable model and you‚Äôd probably better of with a diff model or model ensemble"
7592,@rasbt,2021-09-28 12:46:20+00:00,https://twitter.com/rasbt/status/1442833049813667847,"Looking for ways to spruce up my decision tree lecture this week &amp; stumbled upon the dtreeviz library compatible with scikit-learn: https://t.co/lxeFfx9pUa. Not sure if I love the pie charts, but the histograms plus split indicator are kind of nice. Also nice viz for regr trees https://t.co/QUgIP70uMr"
7593,@rasbt,2021-09-28 12:33:42+00:00,https://twitter.com/rasbt/status/1442829870975881217,"@srchvrs @SoledadVillar5 @thegautamkamath actually had good experiences with journals so far. The reviews were usually more constructive overall. There was less of an adversarial vibe (""let me find reasons to reject"") and more of a ""what could the authors add to improve the paper"" (not always justified, but stms helpful)"
7594,@rasbt,2021-09-28 01:09:57+00:00,https://twitter.com/rasbt/status/1442657801164165120,"@rjurney @mendeley_com LiquidText is pretty cool (https://t.co/0zdHzU0bp9) if you like annotating papers. Not sure if it works on phones, but on iPad, it's amazing."
7595,@rasbt,2021-09-27 23:03:41+00:00,https://twitter.com/rasbt/status/1442626024861315080,"@paul_rietschka Totally opposite experience :). Since it was released ~2017ish, I used PyTorch pretty consistently and exclusively and found that it made me more productive in my research projects. Maybe also just me, but it works more like my mental model of neural networks and autograd works"
7596,@rasbt,2021-09-27 21:31:43+00:00,https://twitter.com/rasbt/status/1442602881606041604,"@soumithchintala @PyTorch I am not a large open source project, but I think both https://t.co/0zVHS7FpgL or https://t.co/gABGOUBmCG would check all these requirements (and they both have code block and latex math support too)"
7597,@rasbt,2021-09-27 20:57:46+00:00,https://twitter.com/rasbt/status/1442594336579801090,@eigensteve Congrats! This looks awesome!
7598,@rasbt,2021-09-27 20:24:50+00:00,https://twitter.com/rasbt/status/1442586047834214406,@connerver @ezyang Came here to say this.
7599,@rasbt,2021-09-27 19:38:23+00:00,https://twitter.com/rasbt/status/1442574358778560517,@deepwhitman @vboykis Plot twist: and it can be solved without AI
7600,@rasbt,2021-09-27 19:33:35+00:00,https://twitter.com/rasbt/status/1442573149791408139,@annargrs @teemu_roos @ykilcher * with conferences I mean these conferences that people commonly refer to as top tier conferences
7601,@rasbt,2021-09-27 19:32:44+00:00,https://twitter.com/rasbt/status/1442572938528665612,"@annargrs @teemu_roos @ykilcher Not sure. Of course, it depends on how you organize the conference. Right now I think that conferences are too broad in scope anyways. And ideally you want experts who work on related work to review the given work."
7602,@rasbt,2021-09-27 17:15:51+00:00,https://twitter.com/rasbt/status/1442538487257853956,"@themintsv *Of course unless if you really care more about  comparing models than methods. Then, getting error bars / uncertainty estimates by other means (e.g., multiple datasets) might be a better way to evaluate."
7603,@rasbt,2021-09-27 17:14:30+00:00,https://twitter.com/rasbt/status/1442538150681735179,"@themintsv You are right. For the Cifar-10 case it was way more pronounced than the ImageNet case. I agree that it doesn't have to be 500 random seeds, but I think 5 seeds should be a bare minimum though."
7604,@rasbt,2021-09-27 15:58:04+00:00,https://twitter.com/rasbt/status/1442518915469426691,"""torch.manual seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision"" https://t.co/LoQhOzpbVw. Results are actually not as bad as the title makes it seem. But yeah, reporting std dev or CIs should be(come) the default. https://t.co/K2JElhgwCs"
7605,@rasbt,2021-09-27 15:45:54+00:00,https://twitter.com/rasbt/status/1442515852922740738,"@notmisha @ykilcher That's a good question. The default would probably be the same as right now: someone asks someone to review a paper, and there is a combination between a) the person is interested in reading the work and b) the person is not good at saying no :P"
7606,@rasbt,2021-09-27 15:19:42+00:00,https://twitter.com/rasbt/status/1442509258902364160,"@teemu_roos @ykilcher Coincidentally, I just stumbled upon this thread (https://t.co/3Gkr6tGo1U) which is kind of related. I.e., I feel like it might not hurt, to some extend, to involve the community in deciding what work they'd like to see presented at a conference."
7607,@rasbt,2021-09-27 14:52:24+00:00,https://twitter.com/rasbt/status/1442502388691181577,"@teemu_roos @ykilcher [2/2] What I am trying to get at is that there is a distinction between ""rejected because not interesting enough for this conference"" and ""rejected because it has major flaws"""
7608,@rasbt,2021-09-27 14:51:21+00:00,https://twitter.com/rasbt/status/1442502124995104770,"@teemu_roos @ykilcher The current problem with arxiv is that there is no filter for papers that are checked / ""factually correct"" (as per reviewer feedback). The OpenReview approach is helpful, but it basically lists ""rejected"" + a discussion readers would have to sift through [1/2]"
7609,@rasbt,2021-09-27 14:48:29+00:00,https://twitter.com/rasbt/status/1442501401448431617,"@teemu_roos @ykilcher Sure, this is an open question. But I do think it could be an improvement to engage both reviewers and the community to nominate papers that are on topic and relevant for the conference vs just having an AC + 3 reviewers/paper (out of 10000+ submissions) making that decision"
7610,@rasbt,2021-09-27 14:28:11+00:00,https://twitter.com/rasbt/status/1442496295038427144,"@teemu_roos @ykilcher One model is to just let people post their papers to arxiv. Editors &amp; reviewers for conferences then select from the pool on not-yet-peer-reviewed papers and reviews them for that conference. Arxiv papers get a ""checked"" or ""peer reviewed"" badge after passing the review."
7611,@rasbt,2021-09-27 14:25:22+00:00,https://twitter.com/rasbt/status/1442495586775621634,"@teemu_roos @ykilcher Right, maybe the number of submission will go up if there is no limit in terms of how many papers can get accepted. Maybe the incentive for encouraging people to a ""worthwhile"" research paper would be the need for finding qualified reviewers interested in reviewing that paper"
7612,@rasbt,2021-09-27 14:14:36+00:00,https://twitter.com/rasbt/status/1442492876928139273,"@ykilcher [2/2] Just have a curated list or repo of factually correct papers. Then, let readers decide what they find useful and worthwhile reading."
7613,@rasbt,2021-09-27 14:13:42+00:00,https://twitter.com/rasbt/status/1442492650582544387,"@ykilcher I feel like in 2021, we could do better without that concept of ""accepting"" only a fixed number of percentage of papers, which is a bit problematic if not harmful for research and progress. I am all for accepting as long it is on topic and factually correct. [1/2]"
7614,@rasbt,2021-09-27 13:56:26+00:00,https://twitter.com/rasbt/status/1442488303043825669,"@HasanHYurdagul @DynamicWebPaige Ah, I see now! Yeah that makes sense Thanks!"
7615,@rasbt,2021-09-27 13:55:13+00:00,https://twitter.com/rasbt/status/1442487995932680200,"@HasanHYurdagul @DynamicWebPaige I see. But if you learn not in a sequential manner, how is the autoencoder RNN still an RNN? :P. Need to look into some papers they cite for autoencoder RNN I guess"
7616,@rasbt,2021-09-27 13:53:55+00:00,https://twitter.com/rasbt/status/1442487670270152713,@HasanHYurdagul @DynamicWebPaige But you already have that setup in a regular encoder-decoder RNN as well. https://t.co/KTWcjEqtPT
7617,@rasbt,2021-09-27 13:50:31+00:00,https://twitter.com/rasbt/status/1442486816519692289,"@HasanHYurdagul @DynamicWebPaige But that's also what the encoder-decoder RNN architecture does. You can e.g., use that as a word or character RNN to generate new text. I.e. during training you learn to reconstruct the input. During inference, you can sample from the probability distribution"
7618,@rasbt,2021-09-27 13:47:53+00:00,https://twitter.com/rasbt/status/1442486154528391184,"@HasanHYurdagul @DynamicWebPaige *Ah, it seems to be the same thing architecture-wise, but the input-output sequences are different. I.e., in the RNN autoencoder apparently the target sequence is same as the input sequence but reversed. Pls correct me if I'm wrong."
7619,@rasbt,2021-09-27 13:44:53+00:00,https://twitter.com/rasbt/status/1442485395577528324,"@HasanHYurdagul @DynamicWebPaige Honest question, what is the difference between an RNN for many-to-many sequence tasks (featuring the usual encoder-decoder architecture) and a RNN autoencoder?"
7620,@rasbt,2021-09-27 12:35:02+00:00,https://twitter.com/rasbt/status/1442467820986515468,"@unsorsodicorda Would be interested in that as well. Since we are talking about MLE not MAP, it‚Äôd say scipy should suffice? But I am very curious to hear what people recommend, esp wrt to PYMC3"
7621,@rasbt,2021-09-26 13:11:11+00:00,https://twitter.com/rasbt/status/1442114529584836611,"@mjrendas @AndrewYNg Yes. I think it would be very helpful to capture the process of designing, testing, and revising models (from the dataset perspective). Most resources (books and papers) are either too general or only focus on the end product."
7622,@rasbt,2021-09-26 13:07:05+00:00,https://twitter.com/rasbt/status/1442113495017918465,"@mcgillmd921 There are many amazing Python books, which I would recommend, too. However, I would start with an interactive course first, because exercises &amp; tinkering are more rewarding and motivating. Then, I would follow-up and fill in details via books, which have a more thorough coverage"
7623,@rasbt,2021-09-26 13:05:39+00:00,https://twitter.com/rasbt/status/1442113135909822469,"@mcgillmd921 I think that interactive resources that briefly explain some concept but focus on interactive exercises are most helpful for learning programming. That being said, I highly recommend Codecademy (not free though). However, there is a free alternative at https://t.co/jtbXtHjarB"
7624,@rasbt,2021-09-25 17:38:26+00:00,https://twitter.com/rasbt/status/1441819394594656256,"@cabitzaf Based on the abstract, this sounds like something I was/am looking for, indeed! Thanks for sharing!"
7625,@rasbt,2021-09-25 17:35:59+00:00,https://twitter.com/rasbt/status/1441818778661183491,"@DJCordhose @rajiinio 2/2 Haven't seriously worked in industry, but I think that the dataset focus is already implied in the ""applied ML"" context as @rajiinio mentioned. But applied ML could maybe also a bit broader and refer to dev ops and deployment. Overall, I like the term data-centric AI"
7626,@rasbt,2021-09-25 17:34:31+00:00,https://twitter.com/rasbt/status/1441818410099175425,"@DJCordhose @rajiinio Yeah, my understanding is that the emphasis is more on  ""how can we change the dataset"" to improve predictive performance vs ""how can we improve the algorithm""  to improve predictive performance. 1/2"
7627,@rasbt,2021-09-25 17:08:14+00:00,https://twitter.com/rasbt/status/1441811795690364932,"@pooja_LuvIndia @madewithml Thanks for the @madewithml pointer. Didn't know it existed, and it looks like an excellent resource!"
7628,@rasbt,2021-09-25 16:47:39+00:00,https://twitter.com/rasbt/status/1441806614797832198,"[4/4] and the face images of people labeled as ""non-criminal"" were regular images from the internet. Here, DL should probably not have been used in the first place. But in general, to investigate, one could include controls like replacing training labels by dataset labels."
7629,@rasbt,2021-09-25 16:47:38+00:00,https://twitter.com/rasbt/status/1441806613174579201,"[3/4] This was not because it actually worked but because the dataset was flawed: The class label was tied with the data collection process, introducing non-salient information the model could exploit. I.e., in this case the face images of criminals were mugshots,"
7630,@rasbt,2021-09-25 16:47:38+00:00,https://twitter.com/rasbt/status/1441806611899682822,"[2/4] I.e., it is worth asking whether a problem needs to be solved via ML or via an algorithm at all. Btw. turned out the researchers found their model performed well given their metrics. Probably unintentionally."
7631,@rasbt,2021-09-25 16:47:38+00:00,https://twitter.com/rasbt/status/1441806610859442176,"[1/4] Overall, many good examples of what could go wrong are discussed. E.g., discusses a paper where researchers tried to design CNNs to predict ""criminality"" from face images. Probably something that shouldn't even have made it to the algo design stage."
7632,@rasbt,2021-09-25 16:39:13+00:00,https://twitter.com/rasbt/status/1441804494111715328,"[3/3] Personally, I think evaluation doesn't necessarily have to be statistically rigorous. E.g., consistently using k-fold cross validation and reporting the average performance with standard deviation could already be useful in the deep learning field."
7633,@rasbt,2021-09-25 16:39:13+00:00,https://twitter.com/rasbt/status/1441804493037965313,[2/3] There are lots of practical issues (think of all the independence assumption violations) that prevent rigorous analysis in the absence of unlimited resources. People have been trying to put diff. band-aids on it recently. Some betters than others &amp; stms they are misleading.
7634,@rasbt,2021-09-25 16:39:12+00:00,https://twitter.com/rasbt/status/1441804491960078345,"[1/3] One point I may not totally agree with though is the criticism re ""lack of rigorous statistical evaluation."" I 100% agree that things could and should be improved in this direction. However, ""rigorous"" is tricky."
7635,@rasbt,2021-09-25 16:33:27+00:00,https://twitter.com/rasbt/status/1441803042219872256,"There is a good section on quantifying annotator uncertainty. Ties in to of what I have been thinking about lately, i.e., how to encode natural labeling ambiguity and quality for supervised learning algos"
7636,@rasbt,2021-09-25 16:31:22+00:00,https://twitter.com/rasbt/status/1441802520528101378,"Also, interesting thoughts about problems with peer-review (yes, peer review has lots of issues). I.e., ""often means [ML] research is not reviewed by a third party until it is given to peer-reviewers, a point far too late to make meaningful changes to the design ..."""
7637,@rasbt,2021-09-25 16:26:34+00:00,https://twitter.com/rasbt/status/1441801308646739971,"""Pitfalls in ML Research: Reexamining the Dev Cycle"" -- really great article that I can only highly recommend to ML researchers &amp; practitioners: https://t.co/YMcCFh8ldV. (PS: Not to be confused with the also excellent ""How to avoid ML pitfalls""  I shared a few weeks ago) üëá"
7638,@rasbt,2021-09-25 12:27:25+00:00,https://twitter.com/rasbt/status/1441741126399111173,"@svboese @samueljohn_de There shouldn‚Äôt be a problem with that. If the features are ordinal, you can encode them as ordinal values (integers) but you don‚Äôt have to specify them as categorical in the HGradBC"
7639,@rasbt,2021-09-24 22:12:51+00:00,https://twitter.com/rasbt/status/1441526066334498816,@samueljohn_de One thing I liked about it was that it also can handle categorical features (without one hot encoding)
7640,@rasbt,2021-09-24 19:27:21+00:00,https://twitter.com/rasbt/status/1441484416560238602,"@KyleCranmer @Smerity oh, we are doing hardware, too? I'd like to amend my list then and add cooking and kitchen utensils ;)"
7641,@rasbt,2021-09-24 19:16:27+00:00,https://twitter.com/rasbt/status/1441481675138011144,@Smerity LaTeX math and equations
7642,@rasbt,2021-09-24 17:56:49+00:00,https://twitter.com/rasbt/status/1441461634208251904,One of the many highlights here is that the HistGradientBoostingClassifier (the implementation is inspired by LightGBM) is now stable and available for general use! I have been using it in a research project in the past and found that it works great.
7643,@rasbt,2021-09-24 16:55:10+00:00,https://twitter.com/rasbt/status/1441446120371064845,@xamat A bit too young for that one. But I remember that both Californication and By the Way were huge back then when I was a kid in school.
7644,@rasbt,2021-09-24 14:15:52+00:00,https://twitter.com/rasbt/status/1441406031750328336,"@__mharrison__ Ah! Ok, not you, but also a great podcast interviewee! Thanks for sharing!"
7645,@rasbt,2021-09-24 12:34:20+00:00,https://twitter.com/rasbt/status/1441380478108459008,"@__mharrison__ Arg I am blocked and can only see the first part of the URL, not the tweet. In case you have a cool podcast interview out, awesome, congrats! I‚Äôd love to listen! Will dig for the podcast link later!"
7646,@rasbt,2021-09-24 12:20:19+00:00,https://twitter.com/rasbt/status/1441376952598679555,"@zubairahmed_ai @A_K_Nain @AnirudhKoul Not necessarily CV specific, but here are three papers I recently read and liked: https://t.co/8O5ZRDjPOh, https://t.co/OUfbEEihyv, https://t.co/6zFxHffbRK"
7647,@rasbt,2021-09-23 22:04:59+00:00,https://twitter.com/rasbt/status/1441161701945139203,"@unsorsodicorda Good point. It's been many years since I made the switch, but I think it had something to do with running Jupyter notebooks remotely. I think I had issues with that via screen but don't recall. Overall, I think it was also easier to manage environments."
7648,@rasbt,2021-09-23 22:03:49+00:00,https://twitter.com/rasbt/status/1441161406187900933,"@unsorsodicorda @3scorciav @ProjectJupyter @code Oh yes, you can use tmux in a remote SSH-connected Visual Studio code terminal. No problem there"
7649,@rasbt,2021-09-23 21:46:01+00:00,https://twitter.com/rasbt/status/1441156926234980358,"@ItsNeuronal @NYU_CNS @FlatironCCN Awesome! Congrats! Also, what an exciting research direction!"
7650,@rasbt,2021-09-23 18:38:56+00:00,https://twitter.com/rasbt/status/1441109845852114955,"Like here is my implementation of KNN that works just fine. It helps illustrate how the scikit-learn API works &amp; how KNN works. Is it efficient and would I use it in practice? Probably not. Scikit-learn's impl. will probably give you the same results, but it is way more efficient https://t.co/ar6vy994Jq"
7651,@rasbt,2021-09-23 18:36:39+00:00,https://twitter.com/rasbt/status/1441109269584121856,"Was just talking about this in class today. I still recommend impl. ML algos from scratch, because it is fun, you'll learn something, and you'll understand how things work. But sure, for the real-world appl., I would resort to established libraries due to efficiency and security"
7652,@rasbt,2021-09-23 18:22:46+00:00,https://twitter.com/rasbt/status/1441105777117188100,@Castillonis @underwaytrying @AndrewYNg The field or the book?
7653,@rasbt,2021-09-23 16:51:02+00:00,https://twitter.com/rasbt/status/1441082691366146048,"@captainsafia @github Oh nice, didn‚Äôt know it either. Super handy üëç"
7654,@rasbt,2021-09-23 16:09:43+00:00,https://twitter.com/rasbt/status/1441072293367586828,"@unsorsodicorda As a former screen user, I say tmux"
7655,@rasbt,2021-09-23 12:22:02+00:00,https://twitter.com/rasbt/status/1441014997153366017,"@cazencott Yeah, we just have to teach a couple of days per week in spring and fall semester and can just chill and read books the rest of the day. Also that generous long summer vacation ‚Ä¶ üòì"
7656,@rasbt,2021-09-22 23:06:30+00:00,https://twitter.com/rasbt/status/1440814795054190597,@micaleel @infinity911_ Yes! I actually forgot if it supports it by default or required installing an extension: https://t.co/XzjpmZNP5v
7657,@rasbt,2021-09-22 20:20:01+00:00,https://twitter.com/rasbt/status/1440772896683479048,"@TaliaRinger I think it's only the free version of Gmail that may not be FERPA compliant. Some universities (who don't roll their own email) license Microsoft Office/Outlook for email, some Gmail. E.g., We have Outlook, and U of Minnesota email is based on Gmail."
7658,@rasbt,2021-09-22 20:08:02+00:00,https://twitter.com/rasbt/status/1440769879649357830,"@AndrewYNg There are general techniques that apply broadly, but one of the pillars is that good approaches are project-specific. It may sound trivial, but I think that a textbook in this area should absolutely have a curated selection of in-depth case studies rather than general examples."
7659,@rasbt,2021-09-22 18:20:33+00:00,https://twitter.com/rasbt/status/1440742833502121993,"@ducha_aiki @CSProfKGD Haha yeah. Finals week is Dec 17 - 23 this year for us. So there is already plenty of other paperwork / grading to do over Xmas ""break"""
7660,@rasbt,2021-09-22 18:15:42+00:00,https://twitter.com/rasbt/status/1440741611965538305,"@CSProfKGD Be careful what you sign up for üôÉ. In my invitation, they also mentioned reviewing  ""up to 10 papers"" over Christmas and within less than a month üò¨ https://t.co/Pjy0yGAnRt"
7661,@rasbt,2021-09-22 17:30:44+00:00,https://twitter.com/rasbt/status/1440730293082603520,"@peteskomoroch Same with long distance running. I am interested in it, I really enjoy, it and it brings me happiness. Yet, it depletes energy as it is not something you can do all day every day :P"
7662,@rasbt,2021-09-22 17:29:35+00:00,https://twitter.com/rasbt/status/1440730005789495301,"@peteskomoroch Depends on the activity and interest. E.g., I am really interested in advancing my coding skills, and coding, learning, and building things brings me happiness. At the same time, it is depletes energy as you cannot keep high focus for a long period of time."
7663,@rasbt,2021-09-22 15:00:25+00:00,https://twitter.com/rasbt/status/1440692466361901056,"@AI4AvgU @code I am actually liking that too. Lots of cool convenience features (like cell run time). However, I still prefer Jupyter Lab/Nb for the looks :P. I have to look  of there is a pep8/flake8 style checker for notebooks in VS Code -- that'd be a killer feature"
7664,@rasbt,2021-09-22 14:26:18+00:00,https://twitter.com/rasbt/status/1440683880277704704,"Whoa! Yesterday, I literally explained in class how Jupyter Notebook &amp; Lab work as browser apps and how I prefer the latter because it removes clutter (fewer browser tabs). What a timely release :)"
7665,@rasbt,2021-09-22 12:54:13+00:00,https://twitter.com/rasbt/status/1440660709453414407,"@dimadamen @roydanroy This is why I also recommend allowing authors to upload a revised version (with highlighted changes) in addition to the rebuttal. Many journals allow/require this, and I think it is really helpful for reviewers. (Because, in the end, rebuttals can also be just empty promises)."
7666,@rasbt,2021-09-22 12:02:22+00:00,https://twitter.com/rasbt/status/1440647660835278861,"Also, it‚Äôs 2021. Life is too short to try to use any SOTA method that doesn‚Äôt come with relatively easily accessible source code"
7667,@rasbt,2021-09-21 23:54:26+00:00,https://twitter.com/rasbt/status/1440464467045670919,"@rjurney @ruslansv I see :(. I remember I had to compile a few things here and there myself in the beginning. However, basically everything I need is now available via conda-forge or homebrew."
7668,@rasbt,2021-09-21 22:16:39+00:00,https://twitter.com/rasbt/status/1440439862067298306,"@rjurney @ruslansv The 15 inch had 32 Gb of RAM, so I was obviously concerned with the 16 Gb now. But in practice, I don't have any limitations for my typical use cases. I am a relatively organized person though, so I don't really have more than 10 apps open at a time. And yes I use Slack."
7669,@rasbt,2021-09-21 22:15:37+00:00,https://twitter.com/rasbt/status/1440439601160601605,"@rjurney @ruslansv I don't do heavy computations, but all my prior class code (NumPy, scikit-learn) runs faster. PyTorch code I run obviously on a separate GPU cluster anyways. I also did some basic video editing (for my virtual class last year), and I noticed that it was faster than my 15inch too"
7670,@rasbt,2021-09-21 22:14:09+00:00,https://twitter.com/rasbt/status/1440439231520727047,"@rjurney @ruslansv Arg sorry to hear. I continue having a great time with it. I actually use it as my main computer, plugged into a 32inch screen when at home or at the office (super snappy, better than my maxed out 2018 15inch), or as a laptop when teaching and traveling (great battery life!)."
7671,@rasbt,2021-09-21 21:38:47+00:00,https://twitter.com/rasbt/status/1440430329592881167,"@ThomasViehmann @alfcnz I would also say in PyTorch, the normalization is always done outside by default in a sense, i.e., taking the [0, 255] range and squish it into [0., 1.] via torchvision's ToTensor()"
7672,@rasbt,2021-09-21 21:37:13+00:00,https://twitter.com/rasbt/status/1440429935827382279,"@ThomasViehmann @alfcnz Re the normalization in- vs outside q. In practice, I don't notice much of a diff when I standardize the inputs vs leave them in the [0, 1] range. But historically, before modern weight initialization schemes and batchnorm that ""stabilize training"" this did make more of a diff"
7673,@rasbt,2021-09-21 18:09:14+00:00,https://twitter.com/rasbt/status/1440377596043091970,"@TheZachMueller Given that you only have 55 minutes left, maybe install MiniForge instead of Anaconda if you want to save some time. Or even Mamba :P"
7674,@rasbt,2021-09-21 12:59:13+00:00,https://twitter.com/rasbt/status/1440299578662608897,@TheZachMueller Wow that was quick ü§ó
7675,@rasbt,2021-09-21 12:27:01+00:00,https://twitter.com/rasbt/status/1440291473212117004,One of the most expensive architectures meets one of the most expensive search strategies. Plot twist: computational efficiency is improved.
7676,@rasbt,2021-09-21 12:07:13+00:00,https://twitter.com/rasbt/status/1440286493394685956,"@rjurney @marcoarment @OvercastFM Yeah, the search function is not great. However, you can just copy the podcast RSS feed URL directly and it should work (upper right corner ‚Äú+‚Äù and then ‚ÄúAdd URL‚Äù)."
7677,@rasbt,2021-09-20 17:47:43+00:00,https://twitter.com/rasbt/status/1440009791372501003,@unsorsodicorda @zacharylipton Interesting question. Especially with respect to all the self-supervised learning work that goes into modern CV.
7678,@rasbt,2021-09-20 15:15:41+00:00,https://twitter.com/rasbt/status/1439971533007556612,"Earlier this summer, we saw results indicating that transformers don't care about word order such that the distributional hypothesis probably doesn't hold: https://t.co/3HX2OwEgcc. Taking it a step further, researchers now show that those LLMs can be pretrained on nonsense docs: https://t.co/Q5k45Pf12S"
7679,@rasbt,2021-09-20 14:55:32+00:00,https://twitter.com/rasbt/status/1439966463885025282,"@WillingCarol @Mike_Kaminsky @hspter No, sorry, never really looked into good exporting options."
7680,@rasbt,2021-09-20 12:34:51+00:00,https://twitter.com/rasbt/status/1439931057420255240,"@BecomingDataSci 2/2 And as a added benefit, without explicit work, this is a form of networking, and it can lead to opportunities. Like in our case the podcast interview and conference, which I both enjoyed :)"
7681,@rasbt,2021-09-20 12:31:47+00:00,https://twitter.com/rasbt/status/1439930284422664195,"@BecomingDataSci Yes, exactly. I actually don‚Äôt think about networking when I use it. For me it is a wider circle of friends and colleagues that I share things with that I am excited about or chat about sth interesting. 1/2"
7682,@rasbt,2021-09-20 01:53:38+00:00,https://twitter.com/rasbt/status/1439769690969100289,"@Mike_Kaminsky @hspter I do agree with you that it can distract flow sometimes. I do have certain times where I turn on do-not-disturb on my computer, and Slack seems to be a bit disrespectful of that sometimes (at least the message sound). It appears to be a bug no one bothered fixing yet."
7683,@rasbt,2021-09-20 01:52:05+00:00,https://twitter.com/rasbt/status/1439769299942580224,"@Mike_Kaminsky @hspter I found that one of the tricks is to use a channel per project, so you can use the paper-trail of shared resources as a timeline. Sure, you can do that via email, but I find scrolling through emails messier. And once in a while someone accidentally starts a new thread."
7684,@rasbt,2021-09-20 01:50:50+00:00,https://twitter.com/rasbt/status/1439768987118755849,"@Mike_Kaminsky @hspter was never a big fan until we all went from in-person to virtual. It's actually sometimes great for having a quick back-and-forth instead of scheduling a meeting. Or, my favorite: use it as a companion for sharing resources during a meeting (Zoom etc.)"
7685,@rasbt,2021-09-19 23:14:42+00:00,https://twitter.com/rasbt/status/1439729695155703812,"@WalterReade @vimota Yeah, I was thinking particularly in the smartphone space. However, just checking https://t.co/jR7KLX6Mgl and it seems like it hasn't been updated in a while üòÖ"
7686,@rasbt,2021-09-19 23:09:13+00:00,https://twitter.com/rasbt/status/1439728312822206467,"@TheZachMueller @BecomingDataSci yeah, my feeling is that most people in my circles use Twitter because they want to and LinkedIn because they have to"
7687,@rasbt,2021-09-19 20:17:54+00:00,https://twitter.com/rasbt/status/1439685200636690447,"@_brohrer_ Reminds me when I handed out voting sheets with scores 1-10 to survey for project presentation awards (best visualizations, most creative, etc.). There were some very interesting digits on there, and CNN-based assessments didn't work. E.g. I think I guessed the one below was a 4 https://t.co/v1zMDEgKKu"
7688,@rasbt,2021-09-19 19:53:15+00:00,https://twitter.com/rasbt/status/1439678997244354563,"@ammaryh92 Yeah, it's an amazin app/platform. If you ever embedded an ML model into a web application using Flask (no criticism, it is awesome for what it is), then you really learn to appreciate it :)"
7689,@rasbt,2021-09-19 15:13:18+00:00,https://twitter.com/rasbt/status/1439608545901690880,"@kdnuggets Nice article! Makes me think of a slight gotcha when considering Tf-idf's in scikit-learn, where the +1 count is added to the idf instead of the denominator of the df. https://t.co/6NS6sbcv0A"
7690,@rasbt,2021-09-18 12:31:03+00:00,https://twitter.com/rasbt/status/1439205326507610120,"@agrover112 Yes! Btw reminds me I observed double descent even with a relatively small DL model once (AlexNet): https://t.co/awGZjC3Mcp (Note that the y-axis here is accuracy, not error, which is why it appears flipped) https://t.co/smkuwmOCkv"
7691,@rasbt,2021-09-18 12:14:26+00:00,https://twitter.com/rasbt/status/1439201142215430145,"""A Farewell to the Bias-Variance Tradeoff?
An Overview of the Theory of Overparameterized Machine Learning"" (https://t.co/6zFxHeXB0c). Good reference and pointers for updating my model evaluation &amp; bias-variance trade-off intro slides for teaching in a few weeks https://t.co/rEoIQKzIMw"
7692,@rasbt,2021-09-18 02:58:41+00:00,https://twitter.com/rasbt/status/1439061283186282496,@thenamessayan It‚Äôs good but not as good. I actually sometimes draft the first manuscript in gdocs or Word just for the more convenient comment and discussion functionality
7693,@rasbt,2021-09-18 02:46:20+00:00,https://twitter.com/rasbt/status/1439058178143051777,@TreforBazett @alfcnz Yeah this sounds strange. Budget cuts in disguise of sth else?
7694,@rasbt,2021-09-18 02:43:20+00:00,https://twitter.com/rasbt/status/1439057420689477637,@DisQS @MelissaK_Moore This!
7695,@rasbt,2021-09-18 02:41:09+00:00,https://twitter.com/rasbt/status/1439056874104573956,@MelissaK_Moore I must say that I indeed appreciate the review &amp; comment functionality
7696,@rasbt,2021-09-18 02:25:32+00:00,https://twitter.com/rasbt/status/1439052943114883077,@radamihalcea 2/2  It is hard to write this email that feels like you are putting a dent into their research passion and career and I sometimes would think it is easier not to respond. But then I am always surprised that students are just thankful for listening and responding at all
7697,@rasbt,2021-09-18 02:21:23+00:00,https://twitter.com/rasbt/status/1439051896380182528,"@radamihalcea Thanks for sharing! And this really resonates with me. I am always feeling bad about writing the ‚Äú‚Ä¶ Unfortunately, ‚Ä¶‚Äú email. I really do. Because the emails I receive are often from students who are very passionate and put a lot of effort into writing that email  1/2"
7698,@rasbt,2021-09-18 01:09:37+00:00,https://twitter.com/rasbt/status/1439033838467010564,"@TimKietzmann Your suggested 45 min sounds like a great idea. Gives you a short break to relax, refresh, and check the agenda for the next meeting"
7699,@rasbt,2021-09-18 01:08:00+00:00,https://twitter.com/rasbt/status/1439033430751301638,"@TimKietzmann Predominantly 60 min :(. Problem with 60 min is that another convention is to schedule meetings so that they start on the hour (e.g. 9 instead of 9:15 or 9:30). So, if you want to have a day for meetings you have them end-to-end without break or have full 1 h breaks in between"
7700,@rasbt,2021-09-17 23:32:11+00:00,https://twitter.com/rasbt/status/1439009316531490820,"@rjurney The latest update to the UI was so bad that I finally ditched it. I.e., it was really hard to see and keep track of the unplayed episodes of podcasts I subscribed to. I would think this was a key feature, but no. I am now using @marcoarment ‚Äòs @OvercastFM and couldn‚Äôt be happier"
7701,@rasbt,2021-09-17 14:02:12+00:00,https://twitter.com/rasbt/status/1438865876699258880,"@PhDemetri @tylergbyers * by ""it"" I mean most of my projects üôÉ"
7702,@rasbt,2021-09-17 14:01:38+00:00,https://twitter.com/rasbt/status/1438865732054433796,"@PhDemetri @tylergbyers haha, yeah, I usually use it to excuse it as ""this is just a proof of concept"" :P"
7703,@rasbt,2021-09-17 13:34:24+00:00,https://twitter.com/rasbt/status/1438858880092622850,"@PhDemetri makes it sound like scientists &gt; engineers. I dunno, but I don't think of one being better than the other, just different focus areas and problem solving skills."
7704,@rasbt,2021-09-17 13:30:28+00:00,https://twitter.com/rasbt/status/1438857891847495680,@PhDemetri This is a compliment?ü§î
7705,@rasbt,2021-09-17 02:09:48+00:00,https://twitter.com/rasbt/status/1438686596132491265,@sullivancolin it's turtles all the way down
7706,@rasbt,2021-09-17 01:38:27+00:00,https://twitter.com/rasbt/status/1438678705627357186,I guess this plot from the mpire repo (https://t.co/tmFq5oqUVF) answers my question :) https://t.co/BwNZbeU7rE
7707,@rasbt,2021-09-17 01:37:03+00:00,https://twitter.com/rasbt/status/1438678354702606336,"That's what I love about the Python ecosystem &amp; community: Whatever you use, it probably works pretty well already. But there is always another great tool to accomplish something. And people don't hesitate to improve upon the status quo and share it with the world :) https://t.co/jB0HFUxsgx"
7708,@rasbt,2021-09-17 01:05:16+00:00,https://twitter.com/rasbt/status/1438670355040768006,@ben_j_lindsay @SamanthaZeitlin I hear you. Completionist syndrome.
7709,@rasbt,2021-09-16 23:10:37+00:00,https://twitter.com/rasbt/status/1438641500632621060,"@alfcnz @kchonyc Nice! Also, your notes are superb as always. Keep going and you have a textbook right there :)"
7710,@rasbt,2021-09-16 22:32:04+00:00,https://twitter.com/rasbt/status/1438631802869010435,"@Seanhsubps There are different alternatives for dealing with the x&lt;0 data, like leaky ReLU, SELU, etc. but using a different set of weights for those is an interesting approach that I haven't thought about yet"
7711,@rasbt,2021-09-16 19:00:28+00:00,https://twitter.com/rasbt/status/1438578550551072775,"@TheZachMueller It's a iterative process switching between the two. Staring with reading the documentation, then playing with some code, then reading more documentation, followed by playing some more, and so forth :)"
7712,@rasbt,2021-09-16 17:53:43+00:00,https://twitter.com/rasbt/status/1438561749918224388,"Just learned about fastcore, and the parallel submodule  seems like another excellent way for making threading and multiprocessing in Python more accessible: https://t.co/UIPrkjZN9B"
7713,@rasbt,2021-09-16 17:46:51+00:00,https://twitter.com/rasbt/status/1438560022070534146,"@TheCodingProjec @fastdotai Thanks for sharing, I had no idea this existed!"
7714,@rasbt,2021-09-16 17:38:19+00:00,https://twitter.com/rasbt/status/1438557877074022401,"Speaking of joblib, would have been intersting to add it to the plot. Or would it be reasonable to assume the performance doesn't differ substantially compared to multiprocessing? https://t.co/IpLVPZgUKr"
7715,@rasbt,2021-09-16 17:37:20+00:00,https://twitter.com/rasbt/status/1438557627169099777,"""Parallelizing Python Code"" Nice post outlining diff strategies. As someone who primarily uses the stdlib's multiprocessing lib manually, or joblib for the extra convenience, there are some nice tidbits in here. E.g., I didn't know about IPython Parallel! https://t.co/KgNlDIFpcF"
7716,@rasbt,2021-09-16 17:20:46+00:00,https://twitter.com/rasbt/status/1438553458437726215,@alexkyllo I see what you did there ;)
7717,@rasbt,2021-09-16 12:57:37+00:00,https://twitter.com/rasbt/status/1438487237679849476,Another good one to add: https://t.co/wawM6fsULx
7718,@rasbt,2021-09-16 12:42:43+00:00,https://twitter.com/rasbt/status/1438483487279960070,"What is your favorite tool for labeling data? Labelme (for image data) came to mind, but then going down the rabbit hole of this question, I learned that there is an entire ""awesome-"" GitHub repo of data labeling tools: https://t.co/w7ZApH9hT1"
7719,@rasbt,2021-09-16 01:14:53+00:00,https://twitter.com/rasbt/status/1438310387544363009,"@_SubhamKumar @tejasybhakta However, I could see other cases benefiting from it more. Maybe things like our semi-adversarial network method that consists of multiple subnetworks where two out of three remain frozen during training. Or say a GAN where you freeze the discriminator when training the generator."
7720,@rasbt,2021-09-16 01:13:11+00:00,https://twitter.com/rasbt/status/1438309958081302529,"@_SubhamKumar @tejasybhakta Also didn't notice any difference after a quick model run. However, I think this is mostly because my there was relatively simple code in the ""with"" context. 1/2"
7721,@rasbt,2021-09-16 01:03:53+00:00,https://twitter.com/rasbt/status/1438307618024566784,"@aureliengeron 4) if the code snippets are very short throughout the book. Like for most NumPy + scikit-learn code this would be fine. But when it comes to deep learning, it could become a bit too much and I'd prefer 1)."
7722,@rasbt,2021-09-15 23:21:42+00:00,https://twitter.com/rasbt/status/1438281904223047684,"I am pretty excited to take this one for a spin. Find+replacing instances of https://t.co/vGkyQ1kJD9_grad() with torch.inference_mode() for a ""free"" speed-up sounds like like a no_brainer():"
7723,@rasbt,2021-09-15 23:14:20+00:00,https://twitter.com/rasbt/status/1438280051418619909,"If you have approached data science from a dev rather than prod environment perspective, this is an excellent post by @chipro describing what the latter entails: https://t.co/GuKjp9yabm‚Ä¶

(I now consider myself fortunate that I never had to worry about K8s)"
7724,@rasbt,2021-09-15 17:54:41+00:00,https://twitter.com/rasbt/status/1438199606504984583,"@ammaryh92 Shuffling definitely (positively) affects gradient descent based optimization. But it's is not sufficient for making non-i.i.d. data i.i.d. On the other hand, slight dependences between data points usually don't hurt."
7725,@rasbt,2021-09-15 15:23:13+00:00,https://twitter.com/rasbt/status/1438161490511634436,"@ammaryh92 But given that there are many other choices for convex losses, why MSE? MSE falls out naturally for linear regression, because minimizing MSE means maximizing the likelihood if the errors are normal distributed and your data is i.i.d. üôÇ"
7726,@rasbt,2021-09-15 02:40:41+00:00,https://twitter.com/rasbt/status/1437969590705868801,"@__mharrison__ @swyx It's the GWM5610-1 for me because more rugged &amp; solar. (Ok I upgraded to another one last year, also solar, but the old GWM5610-1 is still on my desk as an occasional pomodoro timer)"
7727,@rasbt,2021-09-15 02:37:59+00:00,https://twitter.com/rasbt/status/1437968911752998918,"@swyx I tried it once a few years ago (I think Model 3 in 2017), and yeah, I agree with you. Too many distractions, not enough battery life. I can see the appeal as a tool for certain types of sports though."
7728,@rasbt,2021-09-15 01:58:18+00:00,https://twitter.com/rasbt/status/1437958923726823427,"@CSProfKGD Thanks for the kind words, and I am glad you like it!"
7729,@rasbt,2021-09-15 01:19:42+00:00,https://twitter.com/rasbt/status/1437949211279085569,@jdelaroderie @CSProfKGD *trying to say how bad our intro to programming class was. I was never able to do anything useful in Pascal.
7730,@rasbt,2021-09-15 01:18:26+00:00,https://twitter.com/rasbt/status/1437948893296308227,"@jdelaroderie @CSProfKGD When I was taught Delphi/Pascal, I thought it was a language for implementing sorting algorithms üò¨"
7731,@rasbt,2021-09-15 01:05:13+00:00,https://twitter.com/rasbt/status/1437945565015314443,@CSProfKGD Reminds me of the goode olde times as a grad student when the homework had to be submitted in MATLAB and I was prototyping it in Python because it was so much easier for me üôÉ
7732,@rasbt,2021-09-14 21:25:02+00:00,https://twitter.com/rasbt/status/1437890157554933761,"@kamatsu8 @TaliaRinger As far as I know, they don't. I am teaching since the very first semester I started."
7733,@rasbt,2021-09-14 18:43:31+00:00,https://twitter.com/rasbt/status/1437849508952612875,@iamtrask No model evaluation focused material ü•≤
7734,@rasbt,2021-09-14 12:32:14+00:00,https://twitter.com/rasbt/status/1437756070764683265,"@fchollet Totally agree. Depending on your personality type, you may be frustrated that things don‚Äôt work smoothly &amp; change significantly. But chances are you get a big sense of satisfaction &amp; feeling of accomplishment ‚Äî probably like what mountaineers feel when venturing to new places"
7735,@rasbt,2021-09-14 01:34:50+00:00,https://twitter.com/rasbt/status/1437590633414340609,"@ultrabox8000 @ChrSzegedy Yeah, this one is definitely overkill if you want to go ‚Äòjust‚Äô 200 on the autobahn. And be careful. Even though there are no speed limits on certain segments, it‚Äôs still very dangerous. Ie the speed diff betw middle &amp; left lane since many underestimate speed of cars from behind"
7736,@rasbt,2021-09-13 19:54:22+00:00,https://twitter.com/rasbt/status/1437504951006158849,"@dmort27 True. Ruby is fine, but the package and env management looks like a mess / creates a mess"
7737,@rasbt,2021-09-13 18:55:31+00:00,https://twitter.com/rasbt/status/1437490142516850696,"@dimadamen @roydanroy This is really good advice! One thing I find difficult in practice is noticing these visual queues in Zoom. When I am teaching/giving talks, I am usually immersed on the content I am presenting. Following your advice, it might also be good to have short breaks more frequently."
7738,@rasbt,2021-09-13 17:14:23+00:00,https://twitter.com/rasbt/status/1437464688997150729,"Also interesting to see implementations and support for all these alternative tensors (zero, nested, masked, lazy, finite tensors) ü§Ø"
7739,@rasbt,2021-09-13 17:14:22+00:00,https://twitter.com/rasbt/status/1437464687462031360,"Even though PyTorch may offer enough functionality for many use cases, it's exciting to see what's in the pipeline for future releases. This includes more focus on functorch for better composition, and sharded tensors for intra-layer parallelisms to implement transformers ..."
7740,@rasbt,2021-09-13 16:24:47+00:00,https://twitter.com/rasbt/status/1437452206677053444,"@codeFreedomRitr A physical book stand. I love it. Also doubles as a ""handwritten notes that need to be processed"" inbox pile. https://t.co/RWbWZBJYfr"
7741,@rasbt,2021-09-13 16:09:30+00:00,https://twitter.com/rasbt/status/1437448361280425987,"@EmilWallner @hardmaru haha, good one"
7742,@rasbt,2021-09-12 15:52:48+00:00,https://twitter.com/rasbt/status/1437081768755179524,"@austinvhuang Good points. Thanks for sharing! In addition, I'd say anomaly detection-related problems don't have to always be model/classifier-based"
7743,@rasbt,2021-09-12 15:32:23+00:00,https://twitter.com/rasbt/status/1437076630862712834,"Inspiration for other, more sophisticated techniques to try, can be drawn from the excellent imbalanced-learn library: https://t.co/SiRl3gRXrM"
7744,@rasbt,2021-09-12 15:20:31+00:00,https://twitter.com/rasbt/status/1437073644354740228,"Not panaceas or silver bullets, but sample- and class-weighting are often reasonable defaults to start with and easy to implement across different ML and DL frameworks."
7745,@rasbt,2021-09-12 14:42:50+00:00,https://twitter.com/rasbt/status/1437064164648890370,"@bernhardsson I know what you mean, and I wonder about that sometimes, too. At the same time, I also wonder though how much sense it makes to put a number on it. It is maybe like asking ""what is the average predictive performance of ML models?"" -- it depends on so much context"
7746,@rasbt,2021-09-12 13:59:57+00:00,https://twitter.com/rasbt/status/1437053372029407232,"@ykilcher @gradientpub @GaryMarcus I think these foundation models have already got too much attention (no pun intended üò¨). Every time we use and talk about it, the more likely it will get adopted, which is, like you said, just playing into the cards of this PR stunt"
7747,@rasbt,2021-09-12 13:56:09+00:00,https://twitter.com/rasbt/status/1437052416080453640,"@whiskeyandwry @BlancheMinerva Yes. Not that it really matters in practice, but also all deep learning frameworks I know implement cross correlation instead of convolution."
7748,@rasbt,2021-09-12 13:19:40+00:00,https://twitter.com/rasbt/status/1437043234161807363,@BecomingDataSci This looks really awesome! Big congrats again! üéâüéâüéâüéâü•≥ü•≥ü•≥
7749,@rasbt,2021-09-12 13:17:38+00:00,https://twitter.com/rasbt/status/1437042720711839749,"@BlackHC @davidmbudden @iclr_conf [2/2] That being said, I think ICLR mentioned ""up to 3 papers"" which is somewhat ok. Other conferences are being unreasonable. Eg see screenshot from the CVPR invitation below. The conference probably needs to be split up &amp; distributed over the year, because who has time for that https://t.co/6QRiibAicV"
7750,@rasbt,2021-09-12 13:15:48+00:00,https://twitter.com/rasbt/status/1437042262006018048,"@BlackHC @davidmbudden @iclr_conf I think this is only fair. In my life, I probably reviewed 10 times more papers than I submitted. I like helping with reviews, but the workload and deadlines need to be reasonable and shouldn't be a task that takes a full work week given that we have other primary duties [1/2]"
7751,@rasbt,2021-09-11 14:49:45+00:00,https://twitter.com/rasbt/status/1436703517201272836,"@TaliaRinger @tgamblin @vamchale In a similar vein, real numbers and floats, sets, integers. Symbolic vs automatic differentiation."
7752,@rasbt,2021-09-11 13:57:42+00:00,https://twitter.com/rasbt/status/1436690418889105408,@mervenoyann *Btw shameless plug: I have a GAN lecture online here in case you are interested üòÖ https://t.co/FW7DwopW0P
7753,@rasbt,2021-09-11 13:56:29+00:00,https://twitter.com/rasbt/status/1436690112662880263,"@mervenoyann I see. I actually had a hard time reading the code in the book (not particularly this book but in general, I find it hard to read longer codes in books due to the formatting) and mainly just read the book for the explanations but used the code repo mainly: https://t.co/G6vEAkNrVF"
7754,@rasbt,2021-09-11 13:51:10+00:00,https://twitter.com/rasbt/status/1436688772624756736,"@mervenoyann Wow! Is the full title of the book ""Generative Deep Learning: Teaching Machines to Paint, Write, Compose, and Play""? I actually read that book a few years back but skipped over the GAN parts since I was more interested in applications on music etc."
7755,@rasbt,2021-09-10 21:31:04+00:00,https://twitter.com/rasbt/status/1436442123155410944,"@hugobowne @TaliaRinger Like you said, I think it was definitely appealing that PyTorch's tensor lib was interconvertible with NumPy, which is a powerful, familiar tool for many. You can also see that the community nudged PyTorch dev this way with introducing .shape (vs .size()) etc."
7756,@rasbt,2021-09-10 21:29:19+00:00,https://twitter.com/rasbt/status/1436441681717518339,"@hugobowne @TaliaRinger Yeah. I think the reasons behind wanting it in PyTorch is that 1) many people are already familiar with Python and 2) it lets you leverage the existing scientific Python stack. I mean running a training loop is one thing, but we usually want to customize code, plot results etc."
7757,@rasbt,2021-09-10 21:26:08+00:00,https://twitter.com/rasbt/status/1436440881951920139,"@TaliaRinger *Or in other words, I'd say PyTorch was not directly inspired by TensorFlow. It would have been created either way. Because there was already a large number of people who liked Torch, but they wished they didn't need to learn/use Lua but the more widespread and popular Python"
7758,@rasbt,2021-09-10 21:24:24+00:00,https://twitter.com/rasbt/status/1436440443592581121,"@TaliaRinger [2/2] Torch was a great framework, too, but I remember many people not wanting to adopt it because they didn't want to learn Lua. My guess is that TensorFlow was inspired by Theano's approach. And PyTorch was essentially created because of people wanting Torch in Python, not Lua"
7759,@rasbt,2021-09-10 21:23:55+00:00,https://twitter.com/rasbt/status/1436440322763104272,"@TaliaRinger I was not involved in building the frameworks, but I remember Theano was pretty popular back then &lt; 2015, and the community was partly split between Theano, Torch, and Caffe. Theano was/is great, but as far as I remember, many people loved Theano because of Python [1/2]"
7760,@rasbt,2021-09-10 16:44:44+00:00,https://twitter.com/rasbt/status/1436370066065575955,"@mervenoyann @huggingface Exciting news and big congrats joining such a productive, passionate, and ""transforming"" team :)"
7761,@rasbt,2021-09-10 16:41:25+00:00,https://twitter.com/rasbt/status/1436369230711214109,"@therriaultphd @rklau When I was in Europe recently, I was actually quite worried and embarrassed about that. Everyone waving their app &amp; QR code for entry when I was fumbling my kind of worn out CDC cardboard paper out of my wallet. I was surprised though that it got accepted everywhere without issue"
7762,@rasbt,2021-09-10 12:40:25+00:00,https://twitter.com/rasbt/status/1436308578458087462,"@BlancheMinerva @tuetschek @stanislavfort @verena_rieser @katecrawford Just out of curiosity, what resources (# of GPUs and training time) do you usually use to train a GPT-2 sized model?"
7763,@rasbt,2021-09-10 12:36:36+00:00,https://twitter.com/rasbt/status/1436307620764266531,"@tuetschek @stanislavfort @verena_rieser @katecrawford Especially if you also factor in all the failed attempts, bad architecture choices, and bad hyperparameter settings that were used before getting to the part where you train the GPT-2 model from scratch successfully."
7764,@rasbt,2021-09-10 02:40:40+00:00,https://twitter.com/rasbt/status/1436157646252482565,@thserra @ModernSeinfeld1 And as someone making assignments ... I am also too young to have watched Seinfeld üôÉ
7765,@rasbt,2021-09-10 01:23:18+00:00,https://twitter.com/rasbt/status/1436138179581644801,"@theavalkyrie using the identity operator `is` (instead of equality `==`) for comparisons with built-in constants such as None, True, and False"
7766,@rasbt,2021-09-08 20:04:42+00:00,https://twitter.com/rasbt/status/1435695612398292997,"Having &gt;700 datasets readily available at your finger tips and ready to go (depending on your internet connection) is huge! Great to see that it covers various tasks, sizes, and languages. https://t.co/ZcDoApRh1D"
7767,@rasbt,2021-09-08 18:26:45+00:00,https://twitter.com/rasbt/status/1435670963258015744,"@__mharrison__ I am not sure if that‚Äôs a common thing for those course hosting platforms, but if it was a book, those terms would be weird."
7768,@rasbt,2021-09-08 16:09:20+00:00,https://twitter.com/rasbt/status/1435636381536161792,"@GaelVaroquaux @zacharylipton Yeah, my motto today for preparing lecture slides for tomorrow üòÖ. It's hard."
7769,@rasbt,2021-09-08 14:47:49+00:00,https://twitter.com/rasbt/status/1435615865949589505,"@GaelVaroquaux @zacharylipton @roydanroy Back then, my PhD advisor told me to get rid of all the general intro ""bla bla"" stuff in my thesis and just write 1 page outline of the different chapters. No one missed the generic intro, and I think the professors on my committee actually really appreciated the ommission."
7770,@rasbt,2021-09-08 13:24:05+00:00,https://twitter.com/rasbt/status/1435594792730251268,"After 14 years and 24 'minor' version increments, I am really excited for scikit-learn to go v1.0 ü•≥üéâ 

Release notes here: https://t.co/uAEE3ATlFL"
7771,@rasbt,2021-09-08 13:17:11+00:00,https://twitter.com/rasbt/status/1435593058645684227,@TheZachMueller @PyTorch with torch.set_grad_enabled(False): ... üôÉ
7772,@rasbt,2021-09-07 22:10:38+00:00,https://twitter.com/rasbt/status/1435364915141808129,@pwang @TheZachMueller Thanks a lot for clarifying this!
7773,@rasbt,2021-09-07 01:22:04+00:00,https://twitter.com/rasbt/status/1435050703639228419,"@mark_riedl Nice, finally someone creates a collaborative AI system that is geared towards having humans and deep learning models enhance their respective strengths :P"
7774,@rasbt,2021-09-06 17:57:40+00:00,https://twitter.com/rasbt/status/1434938867732336641,"@Iprogrammerinfo @CatalyzeX @Stanford @nikosvg Glad that you find my deep learning resources useful, and thanks for the shout-out!"
7775,@rasbt,2021-09-06 15:05:16+00:00,https://twitter.com/rasbt/status/1434895482053087242,"@seanmylaw @arnabbiswas1 @stumpy_dev Based on the term ""modern time series analysis"" I expected relatively complicated procedure compared to previous-gen methods, and I was positively surprised that the opposite was the case--the computation is more intensive, but the concepts are actually pretty straight forward :)"
7776,@rasbt,2021-09-06 15:03:26+00:00,https://twitter.com/rasbt/status/1434895020050550787,"@seanmylaw @arnabbiswas1 @stumpy_dev Yeah, and I was surprised to see that matrix profiles in time series analysis are also way more intuitive than I anticipated (but this is probably largely owed to the great presentation and step-by-step walkthrough you provided) üôÇ"
7777,@rasbt,2021-09-06 14:15:43+00:00,https://twitter.com/rasbt/status/1434883011904950272,"""Modern Time Series Analysis with STUMPY"" -- really enjoyed this SciPy2021 talk by @seanmylaw. Great intro to subsequence comparison-based time series analysis and using matrix profiles. Really makes me want to find a time series problem to work on new ü§ó https://t.co/KcWn1Zjt0D https://t.co/QHTuzBULKR"
7778,@rasbt,2021-09-06 13:34:36+00:00,https://twitter.com/rasbt/status/1434872665366581248,"@yoavgo Good point. Seems that the current get of lang models are a huge leap from previous-gen (e.g. RNN-based) models. In certain ways, they come with improved capabilities while suffering from the same issues as previous-gen, yet they get exponentially more hate than the previous gen"
7779,@rasbt,2021-09-06 13:10:40+00:00,https://twitter.com/rasbt/status/1434866641045753862,"@bindureddy That's an interesting idea. Reminds me of the RNN + RL combos being used in the molecule synthesis space, e.g., Olivecrona et al. 2017: ""Molecular De-Novo Design through Deep Reinforcement Learning"" https://t.co/nlJFDnMd2w https://t.co/RQc3pheTh1"
7780,@rasbt,2021-09-06 12:30:18+00:00,https://twitter.com/rasbt/status/1434856484471517188,@unsorsodicorda Yeah that‚Äôs the idea and I agree with your concerns. But I still find that it helps me retain stuff after weeks or months or years. I usually have q like ‚ÄúWhy does the orig transformer use layer norm instead of batch norm‚Äù and spend only maybe 5-10 min a day reviewing it
7781,@rasbt,2021-09-06 01:31:43+00:00,https://twitter.com/rasbt/status/1434690744443408391,"3) Be selective with your time and resources (there is an endless pool of cool and interesting stuff out there. When you reached a certain stage, I recommend skipping the intro material to make sure you get to the next level)
3/3"
7782,@rasbt,2021-09-06 01:31:43+00:00,https://twitter.com/rasbt/status/1434690743294210052,"2) Ask key (and tricky) questions about the material. Review the Q&amp;A's occasionally (I use Anki &amp; spaced repetition for that) -- yes, since I completed college, I am not taking tests anymore, but this has been a useful habit that I still do consistently up to this day 
2/3"
7783,@rasbt,2021-09-06 01:31:42+00:00,https://twitter.com/rasbt/status/1434690742098833408,"Love sharing tips on learning how to learn. My top 3 (that I have been applying since my undergrad 10 years ago) are

1) Take notes in two tiers: (1) quick capture, (2) digitize &amp; reorganize neatly (helps me thinking about the material and is also useful for future reference)
1/3"
7784,@rasbt,2021-09-05 22:55:08+00:00,https://twitter.com/rasbt/status/1434651339850756097,"@BecomingDataSci Hah, not that I know of. The only requirement is that you tell us more about it via either a podcast interview or blog post ;)"
7785,@rasbt,2021-09-05 19:07:01+00:00,https://twitter.com/rasbt/status/1434593933816905730,@BecomingDataSci Congrats on the book and the review üéâüéâ
7786,@rasbt,2021-09-05 17:02:39+00:00,https://twitter.com/rasbt/status/1434562635274588161,"@choldgraf Great question. There must definitely be an effect, but it is probably also related to project size. Like their is a sweet spot where adding more tooling etc can help with accessibility  once the project exceeds a certain size"
7787,@rasbt,2021-09-05 03:25:00+00:00,https://twitter.com/rasbt/status/1434356866717454339,"@bailey_stimac Yeah, technically yes. But I think the main selling point was that it would allow you to use the existing production/serving tools"
7788,@rasbt,2021-09-05 00:51:01+00:00,https://twitter.com/rasbt/status/1434318114423025670,"@bailey_stimac Interesting question. Rapids is a very different approach as it is those algos written for cuda from the ground up. Hummingbird is essentially a tool to convert ML algos into PyTorch, which then can run on GPUs"
7789,@rasbt,2021-09-04 17:39:58+00:00,https://twitter.com/rasbt/status/1434209635301535751,"@kevinschawinski @blattnerma Yeah, but I'd say there is rarely a case where you don't have a specific constraint, and I'd guess that most industry problems are dictated by constraints. Usually in form of the data that is available (# of examples, complexity of the problem, structured vs. unstructured, etc.)"
7790,@rasbt,2021-09-04 12:36:35+00:00,https://twitter.com/rasbt/status/1434133289426722819,"@ducha_aiki @chriswolfvision 2/2 Reviewer response: ""method sounds too simple, it is like a trick"" -- reject."
7791,@rasbt,2021-09-04 12:35:57+00:00,https://twitter.com/rasbt/status/1434133130047332353,"@ducha_aiki @chriswolfvision I agree. Btw on that note, we had a paper that proposed a method for distribution calibration &amp; semi-supervised learning that was improving accuracy by a substantial margin (5-10%). We called it ""simple"" because it was easy to use 1/2"
7792,@rasbt,2021-09-04 02:06:32+00:00,https://twitter.com/rasbt/status/1433974732395798530,@DynamicWebPaige @marissamayer @Google Fascinating fact
7793,@rasbt,2021-09-04 00:13:05+00:00,https://twitter.com/rasbt/status/1433946180606644230,"@rishav_real @MattNiessner Thanks for sharing. That's a bummer, though :("
7794,@rasbt,2021-09-04 00:12:26+00:00,https://twitter.com/rasbt/status/1433946017515413507,"@burkov Agreed! Actually, according to the talks' questions part, text processing pipelines are also exactly those that are a bit challenging to process via hummingbird, though."
7795,@rasbt,2021-09-03 23:39:11+00:00,https://twitter.com/rasbt/status/1433937650008928259,"5/5 Btw, finally, here's a link to the talk :) https://t.co/LDzuujSUtZ"
7796,@rasbt,2021-09-03 23:39:11+00:00,https://twitter.com/rasbt/status/1433937648134074373,"4/5 Nice side-effect is that there is also a speed-up. In the random forest example, there was a 6x speedup converting the scikit-learn model to PyTorch, and then an additional 10x speedup running in on the GPU. https://t.co/3qKWKkAOgH"
7797,@rasbt,2021-09-03 23:39:10+00:00,https://twitter.com/rasbt/status/1433937645005119493,"3/5 Found it super interesting that they essentially take scikit-learn models (like decision trees, random forests, etc.) as input and convert them (in one line of code) to a PyTorch model, which can then benefit from existing serving tools. I really love re-using tools like this"
7798,@rasbt,2021-09-03 23:39:09+00:00,https://twitter.com/rasbt/status/1433937642694103040,"Despite its popularity, traditional ML tends to be a bit neglected when it comes to tools for model serving. Hummingbird is essentially trying to address that 2/5 https://t.co/YXuaDCaZf6"
7799,@rasbt,2021-09-03 23:39:08+00:00,https://twitter.com/rasbt/status/1433937637778280457,"Students in my ""traditional"" ML class tend to ask how much traditional ML is still commonly used vs deep learning. Looks like it's a decent chunk (if not still the majority) acc. to the Kaggle surveys. [Slide is from the hummingbird talk at SciPy 2021; more in the next tweet] https://t.co/RkhBB29AKe"
7800,@rasbt,2021-09-03 22:09:03+00:00,https://twitter.com/rasbt/status/1433914966118182920,@shanselman @DynamicWebPaige @NumWorks This looks really cool. Want one for myself now :)
7801,@rasbt,2021-09-03 17:33:23+00:00,https://twitter.com/rasbt/status/1433845590538997763,"@DynamicWebPaige @code @github Looking at an example, it doesn't render from inline LaTeX directly, but when used in conjunction with the VSCode plugin, I suppose it's still a relatively convenient way to get LaTeX equations into markdown docs for GitHub https://t.co/0P3Mw1k29n"
7802,@rasbt,2021-09-03 17:29:27+00:00,https://twitter.com/rasbt/status/1433844601446612996,"@DynamicWebPaige @code @github Wait what, ""Remotely (with @GitHub's #LaTeX rendering server)""? üò±üò±
GitHub now supports LaTeX equations? That would make my day &amp; more! ü§ó"
7803,@rasbt,2021-09-03 15:55:09+00:00,https://twitter.com/rasbt/status/1433820872834490375,@jo_keo No but C++
7804,@rasbt,2021-09-03 15:44:03+00:00,https://twitter.com/rasbt/status/1433818078484238358,"@MattNiessner That‚Äôs very impressive and awesome indeed. I think that PhD students, given the amount of work they do as research assistants, are notoriously underpaid, and I think a lot of students just barely get by on their salary. Now, the other issue to solve: post-PhD salaries in Germany"
7805,@rasbt,2021-09-03 13:18:19+00:00,https://twitter.com/rasbt/status/1433781403993481217,"Just slightly bummed that the C++ code (https://t.co/izJ6E4J1G3) doesn't have a Python wrapper, yet. Pretty sure that authors would appreciate contributions in case someone is looking for something to toy around with this weekend :)"
7806,@rasbt,2021-09-03 12:50:45+00:00,https://twitter.com/rasbt/status/1433774464899092488,"@pwang @TheZachMueller Thanks, and good question ... üòÖ. (1) The original question was whether any for-profit needs the commercial license. (2) My related question was whether Miniconda / conda via Miniforge are free for commercial use."
7807,@rasbt,2021-09-03 00:07:31+00:00,https://twitter.com/rasbt/status/1433582389985488897,"Getting ready for the semester -&gt; just pushed a new MLxtend release (version 0.19.0) with many changes to keep things compatible with the Python sci-stack, among others: https://t.co/LnZmnOwUH8"
7808,@rasbt,2021-09-02 21:06:42+00:00,https://twitter.com/rasbt/status/1433536888372187139,"@chriswolfvision Also, Kullback-Liebler divergence, Cauchy‚ÄìShwarz inequality, and Minkowsky distance"
7809,@rasbt,2021-09-02 14:49:12+00:00,https://twitter.com/rasbt/status/1433441887894056967,"@TheZachMueller Also wondering if it is just affecting Anaconda or also Miniconda, or even the the conda package manager included in Miniforge. Maybe @pwang has some up to date pointers :)"
7810,@rasbt,2021-09-02 14:48:16+00:00,https://twitter.com/rasbt/status/1433441651221991430,"@TheZachMueller Comment on top of this thread https://t.co/cUyHSmutYg: ""Just to be clear: At this time, there is no prohibition on using Anaconda Individual Edition in a small-scale commercial setting like yours."" But this is already 1 year ago. Not sure what changed since then"
7811,@rasbt,2021-09-02 14:46:48+00:00,https://twitter.com/rasbt/status/1433441282588819459,"@TheZachMueller Re conda, was recently discussing it with someone. I remember I read about it ~1 year ago. Was then searching online to back this up but it seemed they reverted this? It's kind of unclear to me what the current status is, and if you have any pointers, I would appreciate it!"
7812,@rasbt,2021-09-02 14:31:12+00:00,https://twitter.com/rasbt/status/1433437356107894784,"MAD(D)NESS: ""Multiplying Matrices Without Multiplying"". An approximation method for 100x speedups compared to the exact method from the authors of Bolt (https://t.co/GQJTqgyD8y).  Paper here: https://t.co/OUfbEEzSX5 https://t.co/6ZyhljFQyI"
7813,@rasbt,2021-09-02 14:04:54+00:00,https://twitter.com/rasbt/status/1433430736573403142,"@mblondel_ml Phew, for a sec I thought they now removed the (deprecated?) RandomState in the most recent version"
7814,@rasbt,2021-09-02 12:39:53+00:00,https://twitter.com/rasbt/status/1433409343639199751,"@capeandcode Nice thread! In case you are looking for a code implementation, https://t.co/yrKXXH8NCL :)"
7815,@rasbt,2021-09-02 12:37:00+00:00,https://twitter.com/rasbt/status/1433408619010269186,"@roydanroy Not sure about shipping, but I just returned from a trip from Europe and N95 masks (called FFP2 there) are readily available in pharmacies &amp; stores. For those 'proper' ones without ear lobe, you can definitely order them (e.g. 3M sells them there in the EU equivalents of Target)."
7816,@rasbt,2021-09-02 00:05:51+00:00,https://twitter.com/rasbt/status/1433219582785949700,@stephlabou @seanmylaw Happy to share! Screenshot below is a screenshot of a local GitHub clone of an ongoing project. This is based on a cookiecutter template I have on GitHub here: https://t.co/h81R1eMfnx (this is in turn heavily based on the data science cookiecutter linked in the repo) https://t.co/k8V5LPvCDG
7817,@rasbt,2021-08-31 21:43:43+00:00,https://twitter.com/rasbt/status/1432821428039061504,@Kaiping_Chen @NSF Congratulations üéâ
7818,@rasbt,2021-08-31 20:01:52+00:00,https://twitter.com/rasbt/status/1432795794403479556,"@skoularidou Awesome news, congrats on the new position!"
7819,@rasbt,2021-08-31 19:57:03+00:00,https://twitter.com/rasbt/status/1432794585802186755,"PS: Due to an invalid python&gt;=3.6 for the conda-forge noarch setting, biopandas on conda-forge was stuck in 0.2.7. Should be fixed now and BioPandas 0.2.9 should install fine (https://t.co/GtHYqVLP9I)"
7820,@rasbt,2021-08-31 19:56:49+00:00,https://twitter.com/rasbt/status/1432794523776733184,"Every time I work on a conda-forge feedstock, I am very impressed by the great tooling and setup of conda-forge (https://t.co/Fp5H31u3n7). The conda-forge project and its developers and contributors are really üëåüëå"
7821,@rasbt,2021-08-31 19:51:34+00:00,https://twitter.com/rasbt/status/1432793204269752320,"""Top Programming Languages 2021 
Python dominates as the de facto platform for new technologies"" (https://t.co/kWo3tnEvne). Not a big fan of rankings, but not a bad headline considering that I am starting to teach a Python-based ML course next week üòÖ"
7822,@rasbt,2021-08-31 19:42:50+00:00,https://twitter.com/rasbt/status/1432791004533428226,"@burkov Yeah. Colleague recently emailed to schedule a meeting. I said I am flexible that day except 9-10 am, which is when I‚Äôll have another meeting. Colleague: ok great, let‚Äôs meet 10-11 am. ü§¶‚Äç‚ôÇÔ∏è"
7823,@rasbt,2021-08-31 18:50:48+00:00,https://twitter.com/rasbt/status/1432777913594753024,@tunguz Oops üò¨
7824,@rasbt,2021-08-31 17:49:28+00:00,https://twitter.com/rasbt/status/1432762474877661186,"@JFPuget @michael_nielsen @Delta Sorry to hear :(, losing a laptop, even if you have backups, is one of the biggest hassles. On that note, I didn't even know that you could put laptops in checked bags because of the battery fire hazard."
7825,@rasbt,2021-08-31 17:29:57+00:00,https://twitter.com/rasbt/status/1432757565398687744,"@Swayson Yeah, every time a non-tech person asks me what I do and I say ""I do deep learning research"" they think I work on developing new pedagogical / learning activities for students. PS: I think 'Machine Learning' is not a great name either."
7826,@rasbt,2021-08-31 15:08:58+00:00,https://twitter.com/rasbt/status/1432722086619922437,"Actually, since 2013 or so, there has already been a growing divide when people started calling multilayer perceptrons with 1 hidden layer a ""deep neural network"" üôÉ"
7827,@rasbt,2021-08-31 00:39:17+00:00,https://twitter.com/rasbt/status/1432503220446842881,"@JamesABednar @anacondainc Awesome, congrats! Will be excited to see what comes out of this collaboration!"
7828,@rasbt,2021-08-29 12:42:54+00:00,https://twitter.com/rasbt/status/1431960549336752128,"@zzznah @shaohua0116 @tim_sainburg Also ""Initialization is critical for preserving global data structure in both t-SNE and UMAP"" https://t.co/33CYPhSio5"
7829,@rasbt,2021-08-29 12:00:44+00:00,https://twitter.com/rasbt/status/1431949940461297670,"@D4t4Waves Looks pretty good! But yeah, relatively similar to t-SNE (left) &amp; UMAP (right). Based on a single dataset, it's hard to tell which one is preferable. https://t.co/ha29pNACRa"
7830,@rasbt,2021-08-29 11:37:08+00:00,https://twitter.com/rasbt/status/1431943999665885187,@valentyn_bez Agreed. The way t-SNE is useful is for EDA
7831,@rasbt,2021-08-29 11:36:07+00:00,https://twitter.com/rasbt/status/1431943743544963072,"Encouraging people not to use t-SNE &amp; UMAP is a bit harsh though. Of course, it's not a silver bullet; otherwise, we could e.g., solve all problem with t-SNE + a linear classifier. Important to keep in mind its limitation wrt to local &amp; global relationships"
7832,@rasbt,2021-08-29 10:53:25+00:00,https://twitter.com/rasbt/status/1431932997868167169,"Yeah, t-SNE &amp; UMAP are tricky in practice. Results don't show anything interesting? Rinse and repeat with different hyperparameters until something interesting pops up, but it is hard to differentiate between meaningful and arbitrary correlations &amp; structures."
7833,@rasbt,2021-08-27 18:46:15+00:00,https://twitter.com/rasbt/status/1431327213526388737,@sarahookr Really sorry to hear. Traveling overseas without issues is already super stressful if everything goes smoothly. This is a really horrible thing to happen. Hoping that this gets resolved soon!
7834,@rasbt,2021-08-27 07:10:59+00:00,https://twitter.com/rasbt/status/1431152247455551490,"Teaching for 2 1/2 years, Jupyter has been indispensable for my machine &amp; deep learning courses. Moreover, Jupyter Notebooks form the organizational backbone of my books. I am very grateful that the Jupyter project exists &amp; that it received this well deserved honorable highlight"
7835,@rasbt,2021-08-27 06:36:03+00:00,https://twitter.com/rasbt/status/1431143455078690819,@randal_olson MiniForge!
7836,@rasbt,2021-08-26 09:55:31+00:00,https://twitter.com/rasbt/status/1430831264999804929,"@aiexplorations To be honest, most ML research is also not that interesting. Many papers are essentially exploring hyperparameter options. Interesting  ones are those that stand the test of time &amp; eventually become defaults in tutorials &amp; software libs, which are the more impactful contributions"
7837,@rasbt,2021-08-26 09:38:48+00:00,https://twitter.com/rasbt/status/1430827058746232835,"About 8 years ago, I stopped trying to read it all. Now, we have probably reached the point where even skimming the titles has become infeasible"
7838,@rasbt,2021-08-26 09:33:10+00:00,https://twitter.com/rasbt/status/1430825639507075075,"@BlackHC What are the options? Change programs, suck it up, quit? If you feel like you are more than 50% done, I‚Äôd probably stay and try to finish. Would probably help to find a fun side project as a hobby during that time."
7839,@rasbt,2021-08-25 13:28:29+00:00,https://twitter.com/rasbt/status/1430522470709170186,"@michael_nielsen Margin notes can be nice if you read it on a large screen and you have at least 2-3 of them per page. In other cases, it‚Äôs causing too much wasted space and screen estate"
7840,@rasbt,2021-08-25 08:30:15+00:00,https://twitter.com/rasbt/status/1430447416466149377,@glouppe @xamat Good and bad news. It's a bummer that most academic committees still don't seem to appreciate software ü§î
7841,@rasbt,2021-08-25 08:19:34+00:00,https://twitter.com/rasbt/status/1430444727892119556,@xamat Just checking my Google Scholar profile. My book seems to be the most cited one by far. Probably not indexed by certain academic databases so it has zero impact academically. But its still the project I am most proud of due to its real world impact.
7842,@rasbt,2021-08-25 08:18:11+00:00,https://twitter.com/rasbt/status/1430444379559403520,"@xamat That's quite a milestone, and nice that these numbers are now kind of meaningless to you (in a good way) üôÇ"
7843,@rasbt,2021-08-23 20:36:27+00:00,https://twitter.com/rasbt/status/1429905395729018882,"@alfcnz Awesome, finally!!! RE tidbit: according someone who does speak German‚Ä¶I think the ""eigen"" corresponds to the German word that translates to ""own"""
7844,@rasbt,2021-08-23 18:43:06+00:00,https://twitter.com/rasbt/status/1429876871257337861,@AdrianEisenmei2 @hackathorn Have to take a look at reticulate!
7845,@rasbt,2021-08-22 17:23:46+00:00,https://twitter.com/rasbt/status/1429494519792381957,@TheZachMueller Ghost in the Wires (fun and action packed autobiography of a famous hacker); Masters of Doom (the origin story behind id software); Kerry Fisher‚Äôs autobiographies; iWoz
7846,@rasbt,2021-08-22 10:07:41+00:00,https://twitter.com/rasbt/status/1429384772577542153,Neat visualization of one of my GitHub repos via @hackathorn. The interactive version (https://t.co/JrtdVHWxOP) is actually pretty useful for exploring a repo and seeing things at a glance. Link to this great visualization tool by Amelia Wattenberger: https://t.co/fVR59vwG2j https://t.co/W796IuhjC8
7847,@rasbt,2021-08-21 07:23:06+00:00,https://twitter.com/rasbt/status/1428980967457366018,"@michael_nielsen @AlexKontorovich Feeling the same way. Can‚Äôt put my finger on it, but there is something about this that annoys me. Btw I sometimes do suggest other referees if they come to mind spontaneously, but I usually don‚Äôt when I have to think too hard about it."
7848,@rasbt,2021-08-20 11:45:20+00:00,https://twitter.com/rasbt/status/1428684573668425735,"@MrHenHan @capeandcode It depends what type of preprocessing we are talking about. If it doesn‚Äôt involve any parameters that depend on the split, then it doesn‚Äôt matter. If you are doing a Fahrenheit -&gt; Celsius transform, it doesn‚Äôt matter; and it is more efficient to do it once beforehand"
7849,@rasbt,2021-08-20 11:11:53+00:00,https://twitter.com/rasbt/status/1428676154421137411,@dvtswe @weights_biases It‚Äôs getting there. We are now using it for almost all our recent projects :)
7850,@rasbt,2021-08-20 10:41:10+00:00,https://twitter.com/rasbt/status/1428668424532680708,"@svpino @capeandcode Ha yeah, it looks very subtle, but I remember paying very special attention to this when making this chart üôÉ"
7851,@rasbt,2021-08-19 18:23:20+00:00,https://twitter.com/rasbt/status/1428422343467077635,"@MrHenHan For the self-driving car, you maybe want to change the dataset to include disproportionally many examples of tricky edge cases. For the spam filter, you probably don't care much etc."
7852,@rasbt,2021-08-19 18:21:03+00:00,https://twitter.com/rasbt/status/1428421772379054094,"@MrHenHan *As someone focused on the technical aspects and developing general purpose methods, it's a bit hard to make a general judgement call. It's really something that needs to be tailored to the case at hand. Like designing a spam filter vs a self-driving car. Very different."
7853,@rasbt,2021-08-19 18:16:35+00:00,https://twitter.com/rasbt/status/1428420646292365312,"@MrHenHan Yeah making certain alterations to the training data is, I guess*, something that has to be discussed and developed together with domain experts &amp; customers using the model for a particular application"
7854,@rasbt,2021-08-19 16:21:21+00:00,https://twitter.com/rasbt/status/1428391646148841476,@tunguz Might actually be useful because it will make it easier to spot the fake products that their website is flooded with
7855,@rasbt,2021-08-19 16:16:09+00:00,https://twitter.com/rasbt/status/1428390337882595328,"@MrHenHan Anyways, hot topic on MLOps these days https://t.co/4DNUROEWaG)"
7856,@rasbt,2021-08-19 16:15:58+00:00,https://twitter.com/rasbt/status/1428390291514576897,"@MrHenHan Not exactly sure what sort of checks and activities the term 'auditing' encompasses, but from a predictive performance perspective, taking a data-centric approach can often actually be more effective and cheaper than improving model performance by other means"
7857,@rasbt,2021-08-19 16:09:23+00:00,https://twitter.com/rasbt/status/1428388637360730121,@F_Vaggi @soashworth @lastpositivist @talyarkoni There need to be harsher consequences. Like banning offenders from submitting to any conference or journal if there was an obvious case of an malicious attempt. There should probably also be criminal charges similar to tax fraud.
7858,@rasbt,2021-08-19 16:06:00+00:00,https://twitter.com/rasbt/status/1428387785724121092,"@F_Vaggi @soashworth @lastpositivist @talyarkoni There is almost zero consequences in academia for that stuff. If someone gets caught, worst case scenario is 'potential' paper retraction, which is basically the same outcome as not submitting a paper in the first place. The setup is almost like ""it's worth a try"""
7859,@rasbt,2021-08-19 15:24:55+00:00,https://twitter.com/rasbt/status/1428377444210331652,"@yureq @PhDemetri I remember that those by Timothy Zahn were actually pretty good. But yeah, I read them when I was like 13. Not sure how well they held up"
7860,@rasbt,2021-08-19 15:22:50+00:00,https://twitter.com/rasbt/status/1428376921671405574,@alfcnz @ProcessingOrg Amazing stuff!
7861,@rasbt,2021-08-18 21:01:02+00:00,https://twitter.com/rasbt/status/1428099643859165185,"@BlackHC Hah, I remember that from the old days pre 1.x where a version update improved numerical stability of software or logsoftmax that I used in my custom loss func ‚Ä¶ didn‚Äôt seem like a big diff at first and hard to catch in unit tests, but in backprop over 100s of epochs it shows ü§î"
7862,@rasbt,2021-08-18 11:34:15+00:00,https://twitter.com/rasbt/status/1427957009744281607,@glyph This insightful thread would be great content for a blog article :)
7863,@rasbt,2021-08-18 08:43:31+00:00,https://twitter.com/rasbt/status/1427914043126333442,"@BlancheMinerva Anyways, thanks so much for sharing. I am looking forward to a more in-depth read when I am back home!"
7864,@rasbt,2021-08-18 08:42:09+00:00,https://twitter.com/rasbt/status/1427913698119663627,"""Pitfalls in Machine Learning Research: Reexamining the Development Cycle"" -- Nice write-up by Stella Biderman &amp; Walter Scheirer on improving your methodological ML practices, incl (1) algorithm design/choice, (2) data collection, and (3) model evaluation: https://t.co/YMcCFhpWCv"
7865,@rasbt,2021-08-18 08:39:02+00:00,https://twitter.com/rasbt/status/1427912914497847300,"@BlancheMinerva Based on what I remember about the other paper and from what I got from skimming through  your paper, there might be common points, but both seem to be useful. The other paper seems more like a how-to ML for students whereas yours is aiming towards improving the state of research"
7866,@rasbt,2021-08-18 08:35:36+00:00,https://twitter.com/rasbt/status/1427912047166214152,"@BlancheMinerva Thanks for sharing. Currently traveling and don't have time to do 1-by-1 comparison, but yeah, at first glance, both papers seem to touch on similar topics that one encounters in ML projects, i.e., (1) Algorithm design/choice, (2) Data collection, (3) Model evaluation"
7867,@rasbt,2021-08-18 05:40:53+00:00,https://twitter.com/rasbt/status/1427868081049804801,"@JisunAn 2/2 It‚Äôs probably more efficient to focus just on the planning and supervising aspects, but I am enjoying the hands on parts too much üôÉ"
7868,@rasbt,2021-08-18 05:39:24+00:00,https://twitter.com/rasbt/status/1427867707135963144,"@JisunAn On a more serious note, I see this as part of supervising. Am trying to split my time evenly between planning projects &amp; involve students and staying hands on and work on parts of the project (incl running experiments) myself 1/2"
7869,@rasbt,2021-08-18 05:35:52+00:00,https://twitter.com/rasbt/status/1427866816928485377,@JisunAn Usually during my coffeeüòÖ
7870,@rasbt,2021-08-16 14:57:37+00:00,https://twitter.com/rasbt/status/1427283409123127297,@BEBischof @weights_biases Awesome! Congrats! üçæ
7871,@rasbt,2021-08-16 12:19:13+00:00,https://twitter.com/rasbt/status/1427243548383096832,"Good comment looking at this from the other side: ""Then one night within 1 hour your inbox explodes with 24 emails with authors commenting on all 6 papers to all 4 reviewers each. Now you have 6 papers you don't quite remember, 3 additional reviews ..."" https://t.co/3HNaqyK2Cj"
7872,@rasbt,2021-08-16 02:45:55+00:00,https://twitter.com/rasbt/status/1427099271124422658,*Would have been interesting to have EfficientNetv2 in the plot. Another little surprise there is that the top-1 acc they report is 5% or so lower than for than for EfficientNetv1 (at least in the EfficientNet papers)
7873,@rasbt,2021-08-16 02:45:54+00:00,https://twitter.com/rasbt/status/1427099269614510081,"""Mobile-Former: Bridging MobileNet and Transformer"". Combines the depthwise and pointwise convolutions of MobileNet with cross-attention to capture global feats.  Not SOTA, but great performance for this relatively small computational footprint. https://t.co/QdEaUqAC87 https://t.co/fOhhIn9wuh"
7874,@rasbt,2021-08-15 20:05:05+00:00,https://twitter.com/rasbt/status/1426998397970550790,"@GuggerSylvain @A_K_Nain Awesome, thanks a lot! will bookmark this for future reference, too!"
7875,@rasbt,2021-08-15 17:32:04+00:00,https://twitter.com/rasbt/status/1426959892984877062,@A_K_Nain Maybe @GuggerSylvain has a tutorial for that :)
7876,@rasbt,2021-08-15 17:30:41+00:00,https://twitter.com/rasbt/status/1426959545646161925,"@A_K_Nain The only difference is that you train and save your own pre-trained model. Then for the fine-tuning for downstream tasks, you load from your locally saved pre-trained model instead from the huggingface repo. Steps 2-4 you list above should be the same as usual."
7877,@rasbt,2021-08-15 17:29:32+00:00,https://twitter.com/rasbt/status/1426959252992708615,"@A_K_Nain Oh I see, that's clear now :). Don't have a tutorial at hand, but what you do is basically using BertForMaskedLM instead of eg BertForSequenceClassification. Then you train it as usual. Once pre-trained, you save and load it into egBertForSequenceClassification.from_pretrained"
7878,@rasbt,2021-08-15 17:17:24+00:00,https://twitter.com/rasbt/status/1426956198981640200,"@A_K_Nain *In other words, not sure if anyone ever successfully trained a transformer for the downstream tasks from scratch directly skipping the pre-training"
7879,@rasbt,2021-08-15 17:15:18+00:00,https://twitter.com/rasbt/status/1426955671573041157,"@A_K_Nain 2/2 The from scratch training is naturally for the bidirectional, masked LM task, but the tasks you describe are fine-tuning tasks. So I am not sure whether I am misunderstanding the question. If I do, pls ignore my answer above"
7880,@rasbt,2021-08-15 17:14:50+00:00,https://twitter.com/rasbt/status/1426955553327263751,"@A_K_Nain Yeah, the models they provided are more for fine-tuning since that's the more common task. If you want to train from scratch, e.g., for BERT you can use 
config = BertConfig.from_pretrained('bert-base-uncased')
model = BertForMaskedLM(config)
1/2"
7881,@rasbt,2021-08-15 16:09:32+00:00,https://twitter.com/rasbt/status/1426939122317500422,@PierreAblin I like that they also added some color to Table 1 -- for those who don't have deuteranopia (red-green blindness) https://t.co/HUJNkAh7Qm
7882,@rasbt,2021-08-15 13:18:01+00:00,https://twitter.com/rasbt/status/1426895957099220999,@philipvollet Enjoy the well earned time off! And looking forward to hearing about the said adventures!
7883,@rasbt,2021-08-15 12:50:05+00:00,https://twitter.com/rasbt/status/1426888929576357894,@rjurney Haha I wishüòÖ. That would be lovely
7884,@rasbt,2021-08-14 21:42:31+00:00,https://twitter.com/rasbt/status/1426660530194952196,"@rjurney Not trying to be sarcastic, but audiobooks make/help me fall asleep. For most things I usually prefer reading physical books, but yeah, audio books can be nice when doing household chores etc"
7885,@rasbt,2021-08-14 14:57:04+00:00,https://twitter.com/rasbt/status/1426558495973953536,"@S3Y3D_com @arxiv Oops, not sure how that happened!"
7886,@rasbt,2021-08-14 14:49:10+00:00,https://twitter.com/rasbt/status/1426556508414820353,Happy birthday @arxiv_org! It's been such an immensely important platform for science. Can't imagine where we would be without it.
7887,@rasbt,2021-08-13 22:49:07+00:00,https://twitter.com/rasbt/status/1426314903955070978,"@burkov I am using OneDrive since 2018, because it comes included with Office 365. It worked flawlessly for me since then. Also has all the nice features like selective sync."
7888,@rasbt,2021-08-13 18:43:47+00:00,https://twitter.com/rasbt/status/1426253162235809801,@bookauthority Wow thanks!
7889,@rasbt,2021-08-13 12:52:24+00:00,https://twitter.com/rasbt/status/1426164733665849344,"This is a really great NLP Transformer survey, indeed! Also, I like that they included a section focusing on the three main ways to utilize a pre-trained transformer (assuming most of us don't have the infrastructure to train them from scratch): https://t.co/lGULN6vCwV https://t.co/UEHL0MSPwo"
7890,@rasbt,2021-08-12 16:26:57+00:00,https://twitter.com/rasbt/status/1425856339926994945,"@shayanjm @burkov yeah, that's a viable alternative for good reasons. But like you said, your mileage may probably vary depending on the task. For some tasks, I imagine it's hard to avoid hand-labeled examples."
7891,@rasbt,2021-08-12 14:07:01+00:00,https://twitter.com/rasbt/status/1425821124248616960,An interesting point is how (&amp; whether it is worthwhile) to formally approach Tip 2 and 3 using metrics. One approach that comes to mind is Krippendorf alpha (https://t.co/84mq4J1zSP). Any other approaches that you recommend or are already successfully used in practice? @AndrewNg
7892,@rasbt,2021-08-12 14:03:30+00:00,https://twitter.com/rasbt/status/1425820240080953344,"Some interesting takeways and insights from the data-centric AI talks and panel discussion. Among others, @AndrewYNg shared some useful tips (see screenshots below) centered around improving datasets to improve model performance 1/2 https://t.co/BAlR11ya7f"
7893,@rasbt,2021-08-12 12:29:11+00:00,https://twitter.com/rasbt/status/1425796507102597124,@hammad_khan23 Glad to hear the videos helped! And best of luck for your final!
7894,@rasbt,2021-08-12 01:50:55+00:00,https://twitter.com/rasbt/status/1425635878806900737,"* as a nice bonus, the talk also included some interesting insights into speeding up Numba's jit: https://t.co/DRajeJnRid"
7895,@rasbt,2021-08-12 01:49:18+00:00,https://twitter.com/rasbt/status/1425635473108709379,"2/2 Cutting to the chase, GitHub repository can be found here: https://t.co/O5My7CSKNk. Nice that it works as a drop-in replacement for scikit-learn's KNeighborsTransformer (below), so it could be used for other NN-based algos like Isomap, DBScan, KNeighborsClassifier etc ... https://t.co/QM8Q84wRCJ"
7896,@rasbt,2021-08-12 01:49:17+00:00,https://twitter.com/rasbt/status/1425635468914446341,"Another great SciPy 2021 talk (https://t.co/fEaj7fxsKr) introduced me to PyNNDescent, a library for fast approximate neighbor search with NumBa (by @leland_mcinnes). Instead of space tree structures, takes a graph-based approach for finding neighbors &amp; scales incredibly well 1/2"
7897,@rasbt,2021-08-11 20:38:20+00:00,https://twitter.com/rasbt/status/1425557216535404547,"@JFPuget @soumithchintala despite all this complaining on a satirical level, matplotlib is still both my favorite and my go-to plotting library ‚ô•Ô∏è"
7898,@rasbt,2021-08-11 17:59:42+00:00,https://twitter.com/rasbt/status/1425517296559271938,@soumithchintala Hah same. But the more often you use it the better you‚Äôll get ‚Ä¶ in the sense of growing a large repertoire of projects and plots you can copy from üòÖ
7899,@rasbt,2021-08-11 16:10:37+00:00,https://twitter.com/rasbt/status/1425489844407517184,"2/2 That's including sources of variance such as data sampling, data augmentation, initial model weights, shuffling order in SGD etc. Also, we should be doing more OOB bootstrapping vs k-fold cross validation."
7900,@rasbt,2021-08-11 16:10:37+00:00,https://twitter.com/rasbt/status/1425489842826326020,"Finally got around reading this excellent paper by Bouthillier et al: ""Accounting for Variance in Machine Learning Benchmarks"" (https://t.co/0V4sgskvin). Takeways: letting sources of variance vary (randomizing those by not seeding random seeds) is not too bad 1/2"
7901,@rasbt,2021-08-11 13:51:38+00:00,https://twitter.com/rasbt/status/1425454865342414848,@naivebayesian *edited :)
7902,@rasbt,2021-08-11 13:49:20+00:00,https://twitter.com/rasbt/status/1425454289191899140,@naivebayesian Looks like it is a textbook accompanying the Coursera course series/specialization of the same name?
7903,@rasbt,2021-08-11 13:33:00+00:00,https://twitter.com/rasbt/status/1425450176165122048,"""How can I learn machine learning as a beginner? What are some recommended books and channels?"" -- remember having written about that beforeü§î. Either way, as more &amp; more resources are avail. these days, it was time to compile a more contemporary answer: üôÉhttps://t.co/tkYnUCH7X2"
7904,@rasbt,2021-08-11 12:34:59+00:00,https://twitter.com/rasbt/status/1425435576640188417,@justinrwlynn @AlexIrrthum Glad to hear you like it. Btw the closed captioning was done by a deep learning model (https://t.co/kwV225HhFj). They may not be perfect but magnitudes better than the ones auto generated by YouTube
7905,@rasbt,2021-08-11 00:58:17+00:00,https://twitter.com/rasbt/status/1425260248206651394,"@burkov Ha, yeah, that's a tricky one. Maybe you could provide detailed rules for labeling, and then in successive rounds with multiple people involved refine them until you get a Krippendorf alpha=1 (https://t.co/JNMJemdxUV) üòÖ"
7906,@rasbt,2021-08-10 21:03:32+00:00,https://twitter.com/rasbt/status/1425201170751053826,"@ezyang *mostly not entirely because for many tools you still need a dedicated team of experts developing it. Say OneDrive was open source. No one may pull out the rug under you in that sense, but it also wouldn't help with keeping it working in new OS's if the team stops maintaining it"
7907,@rasbt,2021-08-10 21:00:49+00:00,https://twitter.com/rasbt/status/1425200488228737037,"@ezyang This was one of my main concerns a few years back. Nowadays, when using non-open source tools, I am actually even more concerned about security and privacy. But to answer your question, it mostly (but not entirely) would üòÖ"
7908,@rasbt,2021-08-10 17:56:33+00:00,https://twitter.com/rasbt/status/1425154113881395220,"@xamat Same. However, investing in/supporting a company that does actually something immensely useful doesn't sound like a bad thing"
7909,@rasbt,2021-08-10 17:44:33+00:00,https://twitter.com/rasbt/status/1425151094028701699,@langlijundaisy Oh I probably should have added that info to the figure to make it more clear: each row would be one node (atom).
7910,@rasbt,2021-08-10 15:51:50+00:00,https://twitter.com/rasbt/status/1425122726470094854,"@GiorgioMantova Thanks üôè for the kind words! Making figures can sometimes be a lot of work, so I am glad to hear that they go a long way in terms of clarifying and explaining the concepts!"
7911,@rasbt,2021-08-10 14:31:45+00:00,https://twitter.com/rasbt/status/1425102575217561603,"@aborges_alex haha but it is R! üôÉ (I think the selling point behind this approach is that it interfaces well with HuggingFace's Transformers library, Spacy, etc.)"
7912,@rasbt,2021-08-10 14:28:11+00:00,https://twitter.com/rasbt/status/1425101675170312204,@jakevdp The venus flytrap dataset in the making
7913,@rasbt,2021-08-10 14:16:49+00:00,https://twitter.com/rasbt/status/1425098814961094668,@mikibarros @GiorgioMantova Good question üòÖ Roughly fall (autumn)
7914,@rasbt,2021-08-10 14:09:34+00:00,https://twitter.com/rasbt/status/1425096993488183304,**Btw. here is the link to the talk: https://t.co/XFeXowwYA8
7915,@rasbt,2021-08-10 14:09:34+00:00,https://twitter.com/rasbt/status/1425096991672000521,"*Kind of similar to what I tried to do with BioPandas and working with molecular structures. Got a lot of useful pointers out of the talk, like that I should probably check out the ExtensionArray class some time!"
7916,@rasbt,2021-08-10 14:09:33+00:00,https://twitter.com/rasbt/status/1425096988232720389,Was just watching this excellent SciPy 2021 talk on Natural Language Processing With Pandas DataFrames. I really support the idea of using a general purpose tool for analysis vs. reinventing the wheel. Check out their text extensions toolkit:  https://t.co/zuQmJiDdO6 https://t.co/BW4tSJGGIy
7917,@rasbt,2021-08-10 12:29:35+00:00,https://twitter.com/rasbt/status/1425071830092627984,"@GiorgioMantova Yes, the new edition will be based on PyTorch :)"
7918,@rasbt,2021-08-10 11:49:22+00:00,https://twitter.com/rasbt/status/1425061707211284493,@TheShubhanshu Oh this was just PowerPoint
7919,@rasbt,2021-08-10 11:48:21+00:00,https://twitter.com/rasbt/status/1425061451346157581,"@RichmanRonald Thanks for your interest! It‚Äôs still a few months away though, will let you know :)"
7920,@rasbt,2021-08-10 11:45:52+00:00,https://twitter.com/rasbt/status/1425060829372760064,@unsorsodicorda The latter üòÖ
7921,@rasbt,2021-08-10 11:44:58+00:00,https://twitter.com/rasbt/status/1425060599973699584,"@JohnCLangford Most compelling were those that encouraged or at least included interaction in groups or with the speaker. There needs to be sth to make it worthwhile to tune in at a specific time that is probably not perfect for most, and to justify why not just watching a recording later"
7922,@rasbt,2021-08-10 01:43:36+00:00,https://twitter.com/rasbt/status/1424909262267076613,"@HiramCoriaRodr1 @juanleitonm There will be an overhauled edition of my current book, with new chapters. It may be a while until then though. Planning with some time in Fall"
7923,@rasbt,2021-08-10 01:29:02+00:00,https://twitter.com/rasbt/status/1424905598513078280,"And another chapter done! Similar to the new transformer chapter, I am pretty excited about this one ü§ó https://t.co/rNM5neNb97"
7924,@rasbt,2021-08-10 00:16:15+00:00,https://twitter.com/rasbt/status/1424887278749601794,"""What to do when you botch a release on PyPI"": https://t.co/sAqXOIGnlV
Bookmarked! My go-to was usually to be angry with myself for skipping  TestPyPI (https://t.co/kgj2zIFuFt) &amp; stressing to make the next release asap.
The ""Yank"" option and post specs seem better alternatives ;)"
7925,@rasbt,2021-08-09 21:34:46+00:00,https://twitter.com/rasbt/status/1424846643631951876,"@ChrSzegedy @pranaysaryal @fchollet Huh, that's interesting. Maybe the other words were not legible enough to the model, or maybe they only index based on a certain keyword vocabulary"
7926,@rasbt,2021-08-09 21:22:21+00:00,https://twitter.com/rasbt/status/1424843515461263361,"@ChrSzegedy @pranaysaryal @fchollet Interesting! Maybe they are doing sth different. But with it being quite expensive, I have to disagree. Shouldn't take more than a sec to apply OCR to a pic. Evernote has been doing that since 2010 or so. Did a quick search &amp; seems Google Photos does OCR: https://t.co/Bm1PZCIszJ"
7927,@rasbt,2021-08-09 15:19:52+00:00,https://twitter.com/rasbt/status/1424752296571936771,"@georgebaptista More of the latter. That is, collecting more data, figuring out which data to label, and how to combine data from different modalities."
7928,@rasbt,2021-08-09 15:01:27+00:00,https://twitter.com/rasbt/status/1424747662142808064,"In recent collaborations, I've learned that taking a more data-centric approach can go a long way. 

Love to hear other people's experiences &amp; this looks like it is going to be a worthwhile webinar on Wednesday:"
7929,@rasbt,2021-08-09 14:23:33+00:00,https://twitter.com/rasbt/status/1424738122185773064,"@vykthur Unfortunately, I have to agree."
7930,@rasbt,2021-08-09 13:42:43+00:00,https://twitter.com/rasbt/status/1424727845683748869,"Tianshou: a new, elegant PyTorch library for reinforcement learning (both model-based &amp; model-free): https://t.co/QJrCyU0eEo

Glad that people are trying to make RL fun (again). Sth that like is exactly needed to lower the barrier to entry.
GH repository: https://t.co/HC7uZnC6B9"
7931,@rasbt,2021-08-09 13:24:27+00:00,https://twitter.com/rasbt/status/1424723250400088071,"@ChrSzegedy @pranaysaryal @fchollet Don't have an Android device and also don't know the details, but my bet is that it's probably even ""simpler"" than that. It's probably just doing OCR to search for text (https://t.co/FfmLFpNfiq), and it probably just so happens that the card contains the word ""vaccine"" somewhere"
7932,@rasbt,2021-08-09 12:58:14+00:00,https://twitter.com/rasbt/status/1424716650503409664,"@mark_riedl One of the creepy parts is ‚Äúeven with hands on the wheel, there was no way I could stop or turn as it entered a gravel-covered area‚Äù üôÅ"
7933,@rasbt,2021-08-09 00:42:30+00:00,https://twitter.com/rasbt/status/1424531499488059397,@alfcnz Sounds intense Exploding head ... But I would take this a thousand times over making TikZ figures for Beamer
7934,@rasbt,2021-08-09 00:07:48+00:00,https://twitter.com/rasbt/status/1424522768054472709,"@xamat Was only able to watch a tiny fraction of it, but yeah, I agree it was a very nice event. There were many disciplines I didn't even know existed like the 1-vs-1 track cycling sprints, which were super interesting and fun."
7935,@rasbt,2021-08-08 15:59:16+00:00,https://twitter.com/rasbt/status/1424399824716238849,"Some people asked about the recording of the ""Transformer from the Ground Up"" talk, looks like it's now up on the PyData channel :) https://t.co/ZNQyEzjNBU"
7936,@rasbt,2021-08-08 15:55:19+00:00,https://twitter.com/rasbt/status/1424398829655310338,@PyDataJeddah Oh I am really sorry about that! Didn't notice I had it still set to private. It should work now!
7937,@rasbt,2021-08-08 14:28:28+00:00,https://twitter.com/rasbt/status/1424376970322788355,@unsorsodicorda @labmlai @PyTorchLightnin @weights_biases @PyTorch Unfortunately I don‚Äôt :(
7938,@rasbt,2021-08-08 13:26:40+00:00,https://twitter.com/rasbt/status/1424361419403939847,Annotated PyTorch implementations by @labmlai. This website contains lots of tutorials explaining technical deep learning concepts and algorithms with PyTorch code side-by-side. What a treasure trove. https://t.co/Yga2Vuoc6R
7939,@rasbt,2021-08-08 13:22:16+00:00,https://twitter.com/rasbt/status/1424360313147863044,"@labmlai @vpj Wow, awesome, thanks so much!"
7940,@rasbt,2021-08-07 19:51:36+00:00,https://twitter.com/rasbt/status/1424095904928309251,"@dabeaz Whoa, have been using Big Sur since release. First on Intel, and since ~Feb on an ARM Mac, and I didn't have that happen even once. Also, I often use the Amphetamine app to keep the computer running for days and didn't have that happen."
7941,@rasbt,2021-08-07 19:14:33+00:00,https://twitter.com/rasbt/status/1424086578658414605,"@kwiatkowskazz Totally agree. The classic ""is ML really necessary?"" question many people often avoid (to either justify their job or funding) ;)"
7942,@rasbt,2021-08-07 18:45:51+00:00,https://twitter.com/rasbt/status/1424079358331863042,"One important question is ""Why do you want to build an ML model?"" In my classes, when grading project proposals, this part is often a bit neglected. It's good to encourage students to justify why using ML (beyond the learning experience) could be useful for a given problem."
7943,@rasbt,2021-08-07 14:39:42+00:00,https://twitter.com/rasbt/status/1424017412157026309,"""How to avoid machine learning pitfalls: a guide for academic researchers"" (https://t.co/U7bodRs5ie). This is a really good summary of the main Dos &amp; Don'ts when approaching an ML project. Bookmarked as a useful resource to recommend to people starting out in ML"
7944,@rasbt,2021-08-06 21:39:39+00:00,https://twitter.com/rasbt/status/1423760706814554120,"@mochacat6 not wrong, but what I had in mind was something that connects with the code lines (or cells)"
7945,@rasbt,2021-08-06 21:14:42+00:00,https://twitter.com/rasbt/status/1423754428331532294,"@ricardoanderegg @jeremyphoward Thanks for sharing, looks like a rabbit hole to go down some time -- might come in handy for teaching in Fall"
7946,@rasbt,2021-08-06 21:12:57+00:00,https://twitter.com/rasbt/status/1423753989540270084,"@m__vaisakh @PyTorch @labmlai @GoogleColab Nice, that's actually not too bad. Is the text on a cell-by-cell basis?"
7947,@rasbt,2021-08-06 21:09:57+00:00,https://twitter.com/rasbt/status/1423753233105924096,"@mark_riedl Same boat, and it's two large classes for me"
7948,@rasbt,2021-08-06 12:01:55+00:00,https://twitter.com/rasbt/status/1423615316865716225,@xamat Awesome. It‚Äôs one of the most useful platforms out there and I am glad they are caring about making it sustainable
7949,@rasbt,2021-08-05 19:52:07+00:00,https://twitter.com/rasbt/status/1423371257932832770,@leland_mcinnes @datametrician @wesmckinn @ApacheArrow Awesome! Congrats! Sounds like exciting times ahead!
7950,@rasbt,2021-08-05 13:11:06+00:00,https://twitter.com/rasbt/status/1423270339723898881,*preferably without dark mode üòÖ
7951,@rasbt,2021-08-05 13:10:25+00:00,https://twitter.com/rasbt/status/1423270168327868421,"Stumbled upon this neat implementation &amp; explanation of graph attention nets: https://t.co/tFUZjsztPI
...and was thinking: wouldn't it be great to have a Jupyter Lab plugin to enable rich comment and code cells side-by-side. Or maybe there is one already I don't know of (please)? https://t.co/Kttuj1M5ZQ"
7952,@rasbt,2021-08-04 12:54:15+00:00,https://twitter.com/rasbt/status/1422903709365846017,"@therriaultphd Browsing this thread a second time ... now for inspiration. Haha our CSA share luckily only came with 4 ears of corn to experiment with, but what are your recommendations? https://t.co/82QzZQtBTQ"
7953,@rasbt,2021-08-04 12:47:36+00:00,https://twitter.com/rasbt/status/1422902038569136137,"@KyleCranmer Awesome! Too bad I missed the talk, but I hope it went well! And I hope they make the right choice! :) PS: How long are you staying in Madison? In case you have time and you'd like to grab a coffee on Fri or the weekend, pls let me know"
7954,@rasbt,2021-08-03 17:23:38+00:00,https://twitter.com/rasbt/status/1422609115931725837,"@reuvenmlerner @ManningBooks Nice one! As someone who has used Pandas for ~10 years and developed a routine of mostly only resorting to the basics, I wouldn't mind a workout to expand my skillset :)"
7955,@rasbt,2021-08-03 16:47:02+00:00,https://twitter.com/rasbt/status/1422599905974050823,"@adnancagri @ocelma @kj_analytics @ColeKroncke haha right, on my computer, I usually don't. I usually also don't use Google Forms, and this CSV file was auto-generated from exporting the form &amp; was too lazy to rename :P"
7956,@rasbt,2021-08-03 16:25:37+00:00,https://twitter.com/rasbt/status/1422594515387523075,@ColeKroncke looks like you have private DM's disabled. Please let me know how to reach you
7957,@rasbt,2021-08-03 16:21:22+00:00,https://twitter.com/rasbt/status/1422593444166443009,"Wow, there were 1203 responses! I wish I had found a larger box with more books!
The 3 people are @ocelma, @kj_analytics, @colekroncke. I will reach out to you via DM regarding shipping. https://t.co/t8UnMQuguJ"
7958,@rasbt,2021-08-03 13:05:05+00:00,https://twitter.com/rasbt/status/1422544047508439042,"@alec_helbling @manim_community @3blue1brown Looks really neat! And yeah, DTs are the main engine of modern ML, as building block for random forests and gradient boosting. ML courses should start (or include) decision trees :)"
7959,@rasbt,2021-08-02 23:22:11+00:00,https://twitter.com/rasbt/status/1422336960509644807,"@SeanOCo07854298 Yeah, you are correct, it doesn't cover information storage and storage allocation-related topics"
7960,@rasbt,2021-08-02 17:35:08+00:00,https://twitter.com/rasbt/status/1422249621317947392,"@GharibiHadi @PyDataJeddah Fine-tuning a pre-trained BERT model; and yeah, a demo using HF."
7961,@rasbt,2021-08-02 16:23:28+00:00,https://twitter.com/rasbt/status/1422231584204378113,"@TylerJBurch hah, wow, I had no idea either"
7962,@rasbt,2021-08-02 15:34:23+00:00,https://twitter.com/rasbt/status/1422219234633998336,"@jackclarkSF Glad to hear, and I really appreciate it that you continue putting it together every week! Likewise, I am always looking forward to accompany my Monday morning coffee break with the current Import AI newsletter"
7963,@rasbt,2021-08-02 14:53:32+00:00,https://twitter.com/rasbt/status/1422208954394894337,"2/2
No further info required. I will then randomly pick &amp; announce 3 people in 24h and follow up with via Twitter DM regarding their shipping addresses.

Caveat: due to shipping costs and hassle, I will only ship to US addresses.

https://t.co/rx7ibBUdGJ"
7964,@rasbt,2021-08-02 14:53:31+00:00,https://twitter.com/rasbt/status/1422208950439645189,"Found a box with 3 copies of Python Machine Learning when I was moving last month and am happy to set up a little free signed book giveawayü§ó

For the lack of a better idea, I set up a Google Form (below) where you can enter your Twitter handle if you are interested. 

1/2 https://t.co/uqww3eUwnO"
7965,@rasbt,2021-08-02 01:48:23+00:00,https://twitter.com/rasbt/status/1422011362876723201,"@johnseesuyang @CSProfKGD Yes, exactly!"
7966,@rasbt,2021-08-01 20:52:23+00:00,https://twitter.com/rasbt/status/1421936875057594373,"@abby621 Yes, it is. Solutions? Limit the number of papers each author can submit. Eg 1-2 max. Or, my preferred one, extend the review period. 3-4 weeks per paper sounds reasonable to me."
7967,@rasbt,2021-07-30 15:52:20+00:00,https://twitter.com/rasbt/status/1421136587606331404,"@FabianGroger I try to make sure that the project and process is enjoyable. I think good organization goes a long way to prevent feeling overwhelmed or getting frustrated due to chaos. I try to structure the project into ideas and things to try, and every so often, I stop and restructure."
7968,@rasbt,2021-07-30 13:42:09+00:00,https://twitter.com/rasbt/status/1421103824949948421,"@ctitusbrown Since ~2018 almost exclusively Visual Studio Code. There are several different ways to use it for editing files remotely. E.g., pair it with Forklift (https://t.co/445VdbMaw3) or consider extensions (https://t.co/UMtkhg7Npa)"
7969,@rasbt,2021-07-30 03:16:37+00:00,https://twitter.com/rasbt/status/1420946403451445248,"@therriaultphd fine, let's save this idea for the pounds of kale you are getting next week"
7970,@rasbt,2021-07-30 01:32:50+00:00,https://twitter.com/rasbt/status/1420920285667205124,"@therriaultphd Given that Oatly is such a hit, I wonder if one could do sth like that with cornü§îüòÖ"
7971,@rasbt,2021-07-30 00:48:37+00:00,https://twitter.com/rasbt/status/1420909157813784579,"Happy to share a preprint of my ""Deeper Learning By Doing: Integrating Hands-On Research Projects Into an ML Course"" paper accepted to the Teaching ML Workshop at ECML 2021. Am hoping that the materials are useful for planning the upcoming Fall semester :) https://t.co/HLJzYQNS7b"
7972,@rasbt,2021-07-29 16:06:16+00:00,https://twitter.com/rasbt/status/1420777705990234124,"One of the things I am particularly excited about after getting back home is catching up with SciPy 2021's @scipyconf talks &amp; tutorials ü§ó

Tutorials playlist: https://t.co/b2OyLeA10Y

Scientific applications of machine learning and data science playlist: https://t.co/OhRsYZYiZC"
7973,@rasbt,2021-07-29 15:57:53+00:00,https://twitter.com/rasbt/status/1420775594808258562,@angstroms Interesting. Thanks for sharing. Didn't know!
7974,@rasbt,2021-07-29 12:51:10+00:00,https://twitter.com/rasbt/status/1420728608138596357,Asking about the best language for data science is so 2010 :). The more interesting question is which (Python) library offers the best JIT &amp; GPU support for peak performance of your neural nets ;). Impressive effort by OpenAI releasing Triton: https://t.co/BYYFNfnSdg https://t.co/3sf6i0nnhJ
7975,@rasbt,2021-07-29 00:53:12+00:00,https://twitter.com/rasbt/status/1420547924472340480,"@dabeaz Writing a book is a big undertaking. Like a good long hike or run, it is mostly a fun process but will leave you exhausted afterwards. Hope you can enjoy it in the upcoming days and weeks! Congrats on getting it done, this is awesome! ü•≥"
7976,@rasbt,2021-07-28 00:56:18+00:00,https://twitter.com/rasbt/status/1420186316411711488,"@robert_mchardy @fhuszar @tunguz @roydanroy 2/2 However, in contrast to Jax it is not a drop-in replacement (e.g., because torch.tensor() &amp; np.array() etc are spelled differently ;P). However, functionality is close enough, and I don't think it needs to be a drop in replacement. It's fine as it is."
7977,@rasbt,2021-07-28 00:55:28+00:00,https://twitter.com/rasbt/status/1420186107229134851,"@robert_mchardy @fhuszar @tunguz @roydanroy It has become more and more similar to NumPy over the years. E.g., it also supports .reshape() in addition to .view(), .shape instead of size(), etc. 1/2"
7978,@rasbt,2021-07-27 13:03:27+00:00,https://twitter.com/rasbt/status/1420006923135553559,@RichmanRonald Awesome work! Bookmarked for reading when I get back home
7979,@rasbt,2021-07-27 00:40:08+00:00,https://twitter.com/rasbt/status/1419819862122135552,"@cgarciae88 @tunguz Yeah Haiku and Flax are the ones I looked at. They are nice, but for my typical use cases there wasn‚Äôt any advantage over the more mature PyTorch"
7980,@rasbt,2021-07-26 19:00:45+00:00,https://twitter.com/rasbt/status/1419734450712170560,"@AllesistKode @tunguz Only looked at Haiku &amp; Flax. But yeah the fact that there are many multiple APIs that may or may not be continued in a few months or years, &amp; that PyTorch comes with more batteries included would make me hesitant to switch, esp since there is no gain in functionality for my uses"
7981,@rasbt,2021-07-26 14:51:33+00:00,https://twitter.com/rasbt/status/1419671740645580802,@tunguz *external libs/libraries
7982,@rasbt,2021-07-26 14:43:54+00:00,https://twitter.com/rasbt/status/1419669813069238273,"@tunguz Have toyed a round with it a bit, and it looks very nice. For my typical use cases (deep learning mostly), it‚Äôs too basic/low-level for me so that code would end up too verbose compared to PyTorch, or I‚Äôd have to rely too much on external links. Gonna stick to PyTorch"
7983,@rasbt,2021-07-23 01:27:04+00:00,https://twitter.com/rasbt/status/1418382120020439049,"If you can use your university's or company's supercomputer, yeah, it's a prepaid buffet. Otherwise, it's more of a pay-by-weight type of situationü§î"
7984,@rasbt,2021-07-23 00:02:34+00:00,https://twitter.com/rasbt/status/1418360857004707843,"Booked a place in the Rocky Mountains for our vacation and national park trips this year, and it turned out we didn't have any sort of internet unless we drive 30 min into the next village. Feels weird but kind of relaxing. Side-effect: the transformer chapter is almost done :) https://t.co/XKPoTWCkpN"
7985,@rasbt,2021-07-19 19:07:31+00:00,https://twitter.com/rasbt/status/1417199438989348866,"@RichmanRonald @JFPuget @sarahookr Journal of Machine Learning Research (https://t.co/q6X7M7UW38), Pattern Recognition (https://t.co/UUG1if4wUJ), and Machine Intelligence (https://t.co/ZVqZ22c94F) are good, general ML journals I can recommend based on positive experiences as a reviewer."
7986,@rasbt,2021-07-19 18:06:42+00:00,https://twitter.com/rasbt/status/1417184136461172737,"@burkov Yeah, generally, I agree, I think it was worth considering; it is a proven an intuitive setup after all"
7987,@rasbt,2021-07-19 17:20:30+00:00,https://twitter.com/rasbt/status/1417172508302794755,@Edit0r_At_Large @KouMurayama Probably the senior author from a large lab who hasn't seen the paper before ;)
7988,@rasbt,2021-07-19 17:16:34+00:00,https://twitter.com/rasbt/status/1417171518581264389,"@burkov What I mean is during inference, when you have inputs consisting of multiple sentences, the model has seen it before during training. With the siamese setup, I suppose you mean only feeding 1 sentence per network copy? So 1 network never sees more than 1 sentence"
7989,@rasbt,2021-07-19 17:11:06+00:00,https://twitter.com/rasbt/status/1417170143789076481,@burkov Like would the siamese setup work/help during inference?
7990,@rasbt,2021-07-19 17:09:42+00:00,https://twitter.com/rasbt/status/1417169790800703495,"@burkov Because it doesn't have the next-word prediction task like GPT, there is no notion of text order in the model (besides the positional encoding). If you only have 1 instead of 2 sentences in the input, there is no ordering dependence between the sentences."
7991,@rasbt,2021-07-19 16:55:58+00:00,https://twitter.com/rasbt/status/1417166334702538759,"@burkov I suppose it (a) was probably the first setup that came to mind and it worked well; (b) probably helps with the unidirectional aspect of parsing text ; (c) keeps things simple because NSP is only done during training, and this setup doesn't require any coding changes."
7992,@rasbt,2021-07-19 16:30:00+00:00,https://twitter.com/rasbt/status/1417159798425063430,"@vykthur @SpeenDoctor_ yeah, looks like they are extremely stingy and want to hire a single person to do the job of a team :P"
7993,@rasbt,2021-07-19 15:24:10+00:00,https://twitter.com/rasbt/status/1417143232140562444,"@hugobowne Traditionally, generative models are models modeling the input distribution p(x). But in most deep learning contexts, we now mean by generative model anything that can produce structured outputs"
7994,@rasbt,2021-07-18 16:53:14+00:00,https://twitter.com/rasbt/status/1416803259843555335,"@DynamicWebPaige What's impressive (unless that was intended üòÖ) is that it mapped ""einz: one"" from the context given that the correct spelling is ""eins"" not ""einz"""
7995,@rasbt,2021-07-18 14:29:40+00:00,https://twitter.com/rasbt/status/1416767129588752388,"""Data vs classifiers, who wins?"" (https://t.co/KmX2b3U5MX) -- on using item response theory to evaluate OpenML-CC18 benchmark for its capability to evaluate machine learning algorithms. Only ~10% of the datasets are rated as difficult. https://t.co/7nsaOTokY0"
7996,@rasbt,2021-07-18 13:15:08+00:00,https://twitter.com/rasbt/status/1416748372585852928,"@slashML @hardmaru I am sure most agree, and most also agree that this ship has sailed. We should better focus on things we can still change, like coming up for better terms for self-supervised learning :P"
7997,@rasbt,2021-07-18 12:20:00+00:00,https://twitter.com/rasbt/status/1416734496288804872,"@wittmannfm 2/2 If you search for Elman vs. Jordan networks, there might potentially be some explanations (e.g., https://t.co/OHOdX5Brdu). Reg. Keras' SimpleRNN, it could purely be for historical reasons."
7998,@rasbt,2021-07-18 12:19:11+00:00,https://twitter.com/rasbt/status/1416734293137793029,"@wittmannfm Regarding your question, why the SimpleRNN in Keras uses output recurrence rather than hidden recurrence, I am actually not sure. In the book, this was more noted as a observation. In PyTorch, it's hidden recurrence btw: https://t.co/fXe6uoFx5a  1/2"
7999,@rasbt,2021-07-17 13:25:06+00:00,https://twitter.com/rasbt/status/1416388490556755977,"@TheZachMueller Yes, I think that would be it. I mean this is basically also what Pillow (as a fork of PIL) did. You can see they still have a PIL submodule etc."
8000,@rasbt,2021-07-17 13:24:14+00:00,https://twitter.com/rasbt/status/1416388273312829446,@TheZachMueller Tbh I don't think any major changes are required then. I think you just need to use the appropriate submodule and file names (matching the original ones) and/or change the names in the __init__.py files.
8001,@rasbt,2021-07-16 13:38:31+00:00,https://twitter.com/rasbt/status/1416029481152753665,@pnatarajanmd @harvardmed Congrats!
8002,@rasbt,2021-07-16 12:41:17+00:00,https://twitter.com/rasbt/status/1416015077728309249,"""The Benchmark Lottery"" -- on the challenges of the machine learning method comparison process. This manuscript comes with a handy checklist in the appendix, which could be a nice complement to the reproducibility checklist https://t.co/ImABAYACHk https://t.co/2oLBwWk8lX"
8003,@rasbt,2021-07-16 12:23:31+00:00,https://twitter.com/rasbt/status/1416010608747630592,"Yes to that. And to make extra sure, I find that adding small technical mistakes &amp; gotchas as adversarial ex. for spaced repetition to Anki gives me an extra peace/piece of mind, things like

a = float('nan')
if a == float('nan'):
    print('A is nan')
else:
    print('Oh oh')"
8004,@rasbt,2021-07-16 02:48:09+00:00,https://twitter.com/rasbt/status/1415865811185639428,@chrisalbon @therriaultphd @seanjtaylor @sarahcat21 and my hair doesn't look like that anymore dammit üòÇ
8005,@rasbt,2021-07-14 23:13:39+00:00,https://twitter.com/rasbt/status/1415449440924708866,"@__mharrison__ Nice, that's exciting. Looking forward to the end product ü§ó. I am a devote and regular pandas user, but I feel like with a tool like pandas, it's always good to see how other people use it, because there are so many neat little (more efficient or elegant) tricks to discover :)"
8006,@rasbt,2021-07-14 20:44:11+00:00,https://twitter.com/rasbt/status/1415411829472387072,@DynamicWebPaige Same!
8007,@rasbt,2021-07-14 12:48:16+00:00,https://twitter.com/rasbt/status/1415292059888541702,@python_engineer @jeffheaton Miniforge is great. Have been using it to get a M1-supporting Python version back then and kept it as a default.
8008,@rasbt,2021-07-13 20:32:06+00:00,https://twitter.com/rasbt/status/1415046400988131329,"@anki_xyz hah, Re ""sound completely different and mean actually the same thing"", I have a slide for at least some of them ... (there are many, many more, take negative log likelihood and cross entropy etc.) https://t.co/uzANKawyQS"
8009,@rasbt,2021-07-13 17:21:07+00:00,https://twitter.com/rasbt/status/1414998338265550850,"""PonderNet: Learning to Ponder"" -- love the title but also the focus on methods that find compromises between computational cost/feasibility and generalization (esp. in an AutoML context) https://t.co/nXAKBeLdxV"
8010,@rasbt,2021-07-13 17:15:24+00:00,https://twitter.com/rasbt/status/1414996897564172295,"@gunsonjack @DeepLearningAI_ @AndrewYNg Also, what I like is that this is nothing beyond reach. It doesn't necessarily require acquiring additional resources and switching platforms etc.; just caring a little bit more about the problem at hand and communicating with stakeholders"
8011,@rasbt,2021-07-13 15:20:09+00:00,https://twitter.com/rasbt/status/1414967892504944644,"@ylecun Me: ""Method X is non convex, has no generalization bounds, and is wildly over-parameterized. It is fun to work with performs really well!"""
8012,@rasbt,2021-07-13 12:11:33+00:00,https://twitter.com/rasbt/status/1414920432084467713,"@hackathorn Thanks so much for the compliments, Richard!"
8013,@rasbt,2021-07-12 11:31:22+00:00,https://twitter.com/rasbt/status/1414547932192387075,@amaarora @jejjohnson Expl. is I think in this video: https://t.co/FexZD11uSA
8014,@rasbt,2021-07-12 11:29:55+00:00,https://twitter.com/rasbt/status/1414547564398055425,"@amaarora @jejjohnson Slides 34 - 42 :)
https://t.co/d8aTp9Qe1r https://t.co/vGAbz3mxYM"
8015,@rasbt,2021-07-12 02:33:42+00:00,https://twitter.com/rasbt/status/1414412623521714176,"@ben_j_lindsay @Shreeyak_S @dgelemi @rjurney @huggingface have the 16 gb one. Coming from a 32 Gb, I was a bit skeptical whether the 8 Gb was enough. But based on @Shreeyak_S it seems that this one is fine too."
8016,@rasbt,2021-07-11 23:28:40+00:00,https://twitter.com/rasbt/status/1414366056555163651,"@Shreeyak_S @dgelemi @rjurney @huggingface Not using Chrome but Slack, and it's been fine too ü§ó"
8017,@rasbt,2021-07-11 22:26:27+00:00,https://twitter.com/rasbt/status/1414350398681493516,"@rjurney @dgelemi @huggingface Haven't really had to use it, yet, but it installs fine via pip."
8018,@rasbt,2021-07-11 22:11:25+00:00,https://twitter.com/rasbt/status/1414346618434895876,"@michael_nielsen At this point, Doodle is the Skype of online meetings"
8019,@rasbt,2021-07-11 22:10:43+00:00,https://twitter.com/rasbt/status/1414346439786778626,"@michael_nielsen Yes, either https://t.co/kOr8dxrCUb or https://t.co/HrgnCiiAC1. Quicker and more convenient for both people who have to set it up and people who are responding"
8020,@rasbt,2021-07-11 12:31:40+00:00,https://twitter.com/rasbt/status/1414200718265921545,"@dgelemi @rjurney @huggingface Good question, coming from a 32Gb one, I was initially concerned about it as well. I installed the stats indicator for the menubar (https://t.co/IveBiSKars) and kept an eye on it in the beginning (and use it still). Usually, RAM usage is around 50-70% for my use cases so its fine"
8021,@rasbt,2021-07-11 11:16:02+00:00,https://twitter.com/rasbt/status/1414181682882691077,"@rjurney @huggingface 2/2 Back to the original question: given that the M1 is also magnitudes cheaper and has much better battery life, I‚Äôd say this is a much better machine for prototyping. I actually sold my Intel MacBook back in March and haven‚Äôt regretted it"
8022,@rasbt,2021-07-11 11:13:57+00:00,https://twitter.com/rasbt/status/1414181162319327234,"@rjurney @huggingface It may only be using the CPU cores not GPU cores. But even then it blows away the intel CPU MacBooks. Haven‚Äôt benchmarked against PyTorch on AMD cards, but my 6-core 15 inch MacBook CPU was magnitudes slower than the M1 for PyTorch 1/2"
8023,@rasbt,2021-07-11 02:51:11+00:00,https://twitter.com/rasbt/status/1414054635103473665,"@rjurney @huggingface Why can't it use the cores on the M1? It's actually super fast. MLPs and smaller convolutional nets like LeNet (for teaching purposes) actually train faster than on my desktop + GPU (1080Ti). For PyTorch, it's probably 100-times faster than Intel CPUs"
8024,@rasbt,2021-07-11 00:26:54+00:00,https://twitter.com/rasbt/status/1414018323835203586,"@rjurney @huggingface I'd definitely go for the M1, it's not too hard to compile it from source. Here are some tips based on my experience: https://t.co/5mxUp0xbPJ. Or, nowadays you can just install M1 binaries from conda-forge, too"
8025,@rasbt,2021-07-10 17:31:53+00:00,https://twitter.com/rasbt/status/1413913881936859136,"@hkontweet Nice, really glad to hear. Congrats!"
8026,@rasbt,2021-07-10 17:29:19+00:00,https://twitter.com/rasbt/status/1413913237108793350,"@LizaPincsak Hah, awesome! Thanks so much ü§óü§óü§ó"
8027,@rasbt,2021-07-10 03:01:34+00:00,https://twitter.com/rasbt/status/1413694859760787457,"@hkontweet Nice, that's great to hear! Hope the interviews went all well :)"
8028,@rasbt,2021-07-09 22:02:10+00:00,https://twitter.com/rasbt/status/1413619512713302021,@unsorsodicorda still big WIP üòÖ
8029,@rasbt,2021-07-09 22:01:41+00:00,https://twitter.com/rasbt/status/1413619392965971968,"@RileenSinha I wouldn't say the academic version is super terrible, because I agree that it offers an explanation. However, it actually took me some time to figure out what they wanted to say. My point is that I feel like academic writing could benefit from using/adding some plain words :)"
8030,@rasbt,2021-07-09 18:42:44+00:00,https://twitter.com/rasbt/status/1413569323541614592,@saurabhkankriya yes :)
8031,@rasbt,2021-07-09 17:25:39+00:00,https://twitter.com/rasbt/status/1413549925217013763,"""Introduction to Deep Learning -- 170 Video Lectures from ùêÄdaptive Linear Neurons to ùêôero-shot Classification with Transformers"" 
Just organized all DL-related videos I recorded in 2021. Hoping it might be useful for one or the other person out there:
https://t.co/8FhMfL6v3N"
8032,@rasbt,2021-07-08 22:23:01+00:00,https://twitter.com/rasbt/status/1413262371393581057,@michael_nielsen I like that idea. It's a bit similar to writing the abstract after finishing a first draft of a paper. Or preparing a presentation/talk based on a paper.
8033,@rasbt,2021-07-08 21:17:32+00:00,https://twitter.com/rasbt/status/1413245891843170304,@DynamicWebPaige Awesome! And I hope GitHub follows suit :)
8034,@rasbt,2021-07-08 13:28:00+00:00,https://twitter.com/rasbt/status/1413127732423270403,"Academic writing: ""At first sight the inner disk in the center may appear larger in area than the outer ring, but the two have the same area: (5¬≤‚àí4¬≤)œÄ=3¬≤œÄ"" 

Real world: ""the two white areas are equal"""
8035,@rasbt,2021-07-08 11:46:29+00:00,https://twitter.com/rasbt/status/1413102185802522628,"Succinct summary of the fine differences between latent variables, embeddings, and representations in DL contexts (Source: https://t.co/hXxhRPRCaO) https://t.co/0gyKYkFh6W"
8036,@rasbt,2021-07-08 11:12:08+00:00,https://twitter.com/rasbt/status/1413093541404979205,@fchollet @hardmaru ... and comparing the architectures via nested or k-fold cross-validation instead of a single test set :)
8037,@rasbt,2021-07-08 02:40:22+00:00,https://twitter.com/rasbt/status/1412964750657523713,"2/2 But an interesting detail at first glance, when I see correctly, fine-tuning GPT-3 did not work well, so they based that model on regular GPT (with GPT-3 tokenizer)."
8038,@rasbt,2021-07-08 02:40:22+00:00,https://twitter.com/rasbt/status/1412964749655126016,"Just see that the paper on the model (Codex) underlying Copilot just went live: "" Evaluating Large Language Models Trained on Code"" (https://t.co/7Lw9KX3rRz). Calling it a day, but looking forward to go through the details tomorrow. 1/2"
8039,@rasbt,2021-07-07 21:43:13+00:00,https://twitter.com/rasbt/status/1412889967378980876,"@DynamicWebPaige and, of course https://t.co/Rh7M9u7iT0"
8040,@rasbt,2021-07-07 21:42:04+00:00,https://twitter.com/rasbt/status/1412889679423328265,"@DynamicWebPaige true, numbers don't lie but words can: you can make statistics say anything you want"
8041,@rasbt,2021-07-07 21:38:46+00:00,https://twitter.com/rasbt/status/1412888847453757453,@DynamicWebPaige The data never lies
8042,@rasbt,2021-07-07 14:47:42+00:00,https://twitter.com/rasbt/status/1412785400117182468,"@karlrohe @ylecun Sure, probably an excerpt from the ""CNNs with PyTorch Cookbook"""
8043,@rasbt,2021-07-06 19:56:13+00:00,https://twitter.com/rasbt/status/1412500652127932422,"@CSProfKGD When I remember correctly (from a talk by @ylecun ) the company who held the patent most of the time didn't even know what a CNN was. And, luckily, the patent expired in 2007 :)"
8044,@rasbt,2021-07-06 12:43:17+00:00,https://twitter.com/rasbt/status/1412391700631375873,"@KouMurayama On a more serious note: yes, you can use ""laufen"" in different contexts. Usually clear from the context, though. In those contexts where it is not clear, you use ""rennen"" (running)"" or ""gehen"" (walking) instead of ""laufen."""
8045,@rasbt,2021-07-06 12:40:17+00:00,https://twitter.com/rasbt/status/1412390948647149569,"@KouMurayama How about ""I am going to the store"" where ""go"" = walk, run, bike, drive, ... ;)"
8046,@rasbt,2021-07-05 20:25:02+00:00,https://twitter.com/rasbt/status/1412145516209651717,@TheZachMueller @DynamicWebPaige @github @OpenAI @Microsoft Perhaps we could :). What are the RAM requirements for EleutherAI GPT-Neo-2.7B? üò¨
8047,@rasbt,2021-07-05 20:11:23+00:00,https://twitter.com/rasbt/status/1412142084274933771,"@DynamicWebPaige @github @OpenAI @Microsoft Just catching up with the world, and this is super cool. Any plans to fine-tune it on https://t.co/V3J5QTFtDO projects to facilitate Python 2 to 3 migration? Not sure how good 2to3 is these days, but I think that'd be cool :)"
8048,@rasbt,2021-07-05 19:54:22+00:00,https://twitter.com/rasbt/status/1412137798346346496,"@JFPuget Also, this whole discussion has ""Will AutoML replace data scientists?"" vibes"
8049,@rasbt,2021-07-05 19:51:06+00:00,https://twitter.com/rasbt/status/1412136976770387969,@seanmylaw This is the way!
8050,@rasbt,2021-07-05 16:44:12+00:00,https://twitter.com/rasbt/status/1412089941455167491,"@kjelljorner Yes, it requires active effort to prepare a presentation-ready notebook. Just like someone needs to edit the first draft of a manuscript couple of times (back in the day, painfully retyping it on a typewriter)"
8051,@rasbt,2021-07-05 14:44:50+00:00,https://twitter.com/rasbt/status/1412059905071198212,"This. But I'd say there is nothing wrong with using Jupyter Notebooks in a project. Similar to writing an academic paper, there is nothing wrong with collecting notes in a physical notebook, OneNote etc. Yeah, N[n]otebooks can be cluttered coz they are a process not an endproduct"
8052,@rasbt,2021-06-28 03:19:29+00:00,https://twitter.com/rasbt/status/1409350715961708547,"@CSProfKGD Maybe not the most efficient way, but I would recommend using a basic mobile-friendly template you like (layout-wise) and then go from there, tweaking the CSS to give it a more unique look so that it looks less like template (so, that's what I did personally üòÖ)"
8053,@rasbt,2021-06-26 03:02:34+00:00,https://twitter.com/rasbt/status/1408621680247836672,"Wow, youngification GANs have really come a long way. Really impressive."
8054,@rasbt,2021-06-26 02:58:29+00:00,https://twitter.com/rasbt/status/1408620655436836867,@jithendrabsy @u6yuvi @omarsar0 Glad to hear you are liking them :)
8055,@rasbt,2021-06-25 00:11:24+00:00,https://twitter.com/rasbt/status/1408216219136802817,"@fchollet yeah, this is a sad attitude. academic elitism at its best :("
8056,@rasbt,2021-06-25 00:00:19+00:00,https://twitter.com/rasbt/status/1408213428670455819,"@hsyed @hannahsheahan Yes and no. Sure, there are different levels of code review. One of them could be peer reviewing code in context of a paper review. You might regard that code as throw away but it generated some experimental results, and those should ideally be checked"
8057,@rasbt,2021-06-24 02:58:26+00:00,https://twitter.com/rasbt/status/1407895864899772416,@mdreid @mat_kelcey not possible
8058,@rasbt,2021-06-23 16:27:50+00:00,https://twitter.com/rasbt/status/1407737171184865286,"@paul_rietschka Actually, above, I was using HistGradientBoostingClassifier because it was easier than compiling LightGBM for my ARM chip. As I understand, it's a reimplementation of LightGBM."
8059,@rasbt,2021-06-23 16:24:57+00:00,https://twitter.com/rasbt/status/1407736445561942024,@xamat Nice! And Happy Birthday! PS: Are those Aftershokz? Love them.
8060,@rasbt,2021-06-23 14:48:55+00:00,https://twitter.com/rasbt/status/1407712276770082817,"@paul_rietschka Yeah, sure. Reg LGBM and XGB, I got slightly better results with the former. Probably because I had some categorical features (tried one-hot and frequency encoding for XGBoost)"
8061,@rasbt,2021-06-23 14:01:27+00:00,https://twitter.com/rasbt/status/1407700330641596417,"@paul_rietschka I was working on a project with a 2000-example dataset the other week, including running xgboost, lightgbm and some of the neural nets. Training completed in seconds on my laptop on the CPU"
8062,@rasbt,2021-06-23 03:03:20+00:00,https://twitter.com/rasbt/status/1407534712978030592,@rezar good oneüòÇ
8063,@rasbt,2021-06-23 02:52:53+00:00,https://twitter.com/rasbt/status/1407532080377077760,@david_macedo @jrzaurin This was yesterday :). Uploaded today: https://t.co/hqorAVCnD9
8064,@rasbt,2021-06-22 13:44:30+00:00,https://twitter.com/rasbt/status/1407333676896112647,"@huyhcmut1997 @mattredlon don't know papers in this regard, but sounds interesting. Can see how unsupervised pre-training/self-supervised learning can be used to generate embeddings for GBMs. But the problem with tabular data is often that it's not very unstructured &amp; that there is not much unlabeled data"
8065,@rasbt,2021-06-22 12:34:59+00:00,https://twitter.com/rasbt/status/1407316184794533890,"For reference, other recent discussions:

""Tabular Data: Deep Learning is Not All You Need"": https://t.co/7LZVrwrJA9

""Deep learning for tabular data IV: Deep Learning vs LightGBM"": https://t.co/ivQNYOWpAG"
8066,@rasbt,2021-06-22 12:33:30+00:00,https://twitter.com/rasbt/status/1407315809584697344,Another one on XGBoost vs deep learning on tabular data. Half-time match result 2:1.
8067,@rasbt,2021-06-22 12:30:49+00:00,https://twitter.com/rasbt/status/1407315135056723968,@k_saifullaah @giffmana What I find interesting is more the standard regularized MLP vs specialized DL architecture.
8068,@rasbt,2021-06-22 12:27:45+00:00,https://twitter.com/rasbt/status/1407314362935742467,"@k_saifullaah @giffmana Skimmed through this paper yesterday and wanted to share it today after announcement but someone was faster :). Didn't read it in detail, but it looked good at first glance. Of course, it's missing confidence intervals, though"
8069,@rasbt,2021-06-21 16:48:15+00:00,https://twitter.com/rasbt/status/1407017530347110409,@josueortc @adjiboussodieng @CosyneMeeting Oh interesting! Do you know if it worked well and what the takeaways from this experiment were?
8070,@rasbt,2021-06-21 13:55:14+00:00,https://twitter.com/rasbt/status/1406973992691458049,"@adjiboussodieng Agreed. If speaking slots are limited due to time and space constraints at physical venues, I wouldn‚Äôt mind lottery-based selections. As long as the papers are on topic of course."
8071,@rasbt,2021-06-21 04:33:08+00:00,https://twitter.com/rasbt/status/1406832532188958720,@adjiboussodieng One potential model &amp; way forward: 1) Share articles (eg via arxiv) + code to reproduce results. 2) Community votes for papers they'd like to see featured at conferences. 3) Reach out to/hire reviewers to professionally eval these articles for correctness &amp; reproducibility
8072,@rasbt,2021-06-21 04:14:40+00:00,https://twitter.com/rasbt/status/1406827885743296512,"@ylecun @adjiboussodieng Would be great &amp; very valuable to hear your major ""what worked &amp; what didn't work"" viewpoints from a 10-years later perspective"
8073,@rasbt,2021-06-21 04:07:49+00:00,https://twitter.com/rasbt/status/1406826163239112711,"@adjiboussodieng Totally agree with you. I feel like we shouldn't hold on to these traditional systems just for the sake of traditions. Given the current state of publishing (and conference reviewers &amp; organizers admitting that they are overwhelmed), it'd be nice to try something new."
8074,@rasbt,2021-06-18 04:08:05+00:00,https://twitter.com/rasbt/status/1405739066247696387,"@mrocklin @DrJosephHardin Yap. Have been a Mac Mini advocate since 2012. There have been ups an downs, but with this generation, which literally has the same chip, it's worthwhile considering it if you plug it into a monitor most of the time anyways."
8075,@rasbt,2021-06-18 04:05:51+00:00,https://twitter.com/rasbt/status/1405738506476003330,"@DrewFustin @mrocklin Very nice! As someone who is due for a monitor upgrade at one point, how are you liking the curved displays? I heard weird arguments that doing image editing (the alignment aspect) or looking at tables can be annoying. Fact or fiction?"
8076,@rasbt,2021-06-18 02:29:10+00:00,https://twitter.com/rasbt/status/1405714172722270209,"@ruchowdh little add-on :)  in an ML context, bootstrapping is usually used for eval. &amp; creating confidence intervals (e.g., instead of k-fold CV; if you are interested: https://t.co/e24yFnHfuT). Synthetic data generation techniques are usually used for resolving class imbalance issues."
8077,@rasbt,2021-06-18 02:26:22+00:00,https://twitter.com/rasbt/status/1405713468670496768,@ruchowdh Thanks so much for the kind words üòä
8078,@rasbt,2021-06-18 02:15:04+00:00,https://twitter.com/rasbt/status/1405710626488524800,"@ruchowdh In a nutshell: typically, bootstrapping has a specific meaning, i.e., think of it as sampling with replacement. Synthetic data usually involves interpolation."
8079,@rasbt,2021-06-18 02:13:24+00:00,https://twitter.com/rasbt/status/1405710203971059713,"@jwuphysics True, that's an interesting point. I do like general-purpose methods though because it allows for comparing what different models learn. There is also the difference between global &amp; local methods, and methods for explaining specific predictions vs methods explaining feature imp"
8080,@rasbt,2021-06-18 02:11:25+00:00,https://twitter.com/rasbt/status/1405709707625566213,"@PhilippBayer Top of my head, most methods I recently saw were CNN/computer vision specific. For the general SHAP/LIME realm, contenders are LEAP, LORE, PALEX, and some other ones I can't recall -- really lost track there. Like you, I prefer SHAP/LIME."
8081,@rasbt,2021-06-18 02:04:07+00:00,https://twitter.com/rasbt/status/1405707868846837764,2/2 I feel like Grad-CAM (vs guided backprop) and SHAP (vs LIME) are just at the threshold. They work better but become harder to explain itself. I find that recent newer techniques are becoming more complicated so that I feel like it hurts the utility
8082,@rasbt,2021-06-18 02:02:00+00:00,https://twitter.com/rasbt/status/1405707338351316993,"There are different uses cases, one is diagnosis &amp; debugging and one is presentation &amp; communication. For the latter, I think it is more helpful if the explanation system itself is explainable to non-experts. Feature permutation importance, LIME, guided backprop are good ones 1/2"
8083,@rasbt,2021-06-18 01:59:50+00:00,https://twitter.com/rasbt/status/1405706791921532932,"Yes, this! Glancing over recent papers, I feel like the explanation techniques recently became more complicated than the models they try to explain."
8084,@rasbt,2021-06-17 16:30:31+00:00,https://twitter.com/rasbt/status/1405563517521088516,"@thejonullman In the real world, many conferences have this over-competitive, almost hostile, vibe. Having seen a large # of conference paper reviews, often the reviewer default mode at conferences seems ""I want to reject this paper, now let's read the paper and look for reasons to justify it"""
8085,@rasbt,2021-06-17 04:22:46+00:00,https://twitter.com/rasbt/status/1405380375824773124,"@alfcnz @GoodNotesApp Nice! Among other advantages, for someone like me who is bad at math, it is so much more convenient to work out problems digitally. Particularly, the aspect about having unlimited, perfect erasing capabilities"
8086,@rasbt,2021-06-17 04:15:09+00:00,https://twitter.com/rasbt/status/1405378457605971973,"@alfcnz Wow, this is really fascinating. (And also the fact that you didn't use an eraser or correction type in a year!)"
8087,@rasbt,2021-06-16 20:12:43+00:00,https://twitter.com/rasbt/status/1405257050817536004,"@rahuldave Yes, I agree. Especially if you have categorical variables with high cardinality and sufficient data to learn the embeddings. In addition to learning them in a supervised fashion or via autoencoder on unlabeled data, you can also consider learning them in self-supervised fashion"
8088,@rasbt,2021-06-16 17:46:26+00:00,https://twitter.com/rasbt/status/1405220234395631621,"@rahuldave Yeah, it especially makes sense if you have raw data to work with. Like text or images etc. In many tabular datasets/real-world problems, you are already given extracted features."
8089,@rasbt,2021-06-16 17:23:49+00:00,https://twitter.com/rasbt/status/1405214542947311617,"New benchmark paper on comparing optimizers. Of course no single optimizer is superior across tasks. Also, Adam remains a viable (and my go-to) option. And ""tuning helps about as much as trying other optimizers."" https://t.co/w49XWq0a26"
8090,@rasbt,2021-06-16 14:48:42+00:00,https://twitter.com/rasbt/status/1405175506178281474,"@david_macedo Maybe, maybe not. The advantage usually lies in the automatic feature extraction from raw data. You don't have that in many cases of tabular datasets."
8091,@rasbt,2021-06-16 14:30:23+00:00,https://twitter.com/rasbt/status/1405170899859427331,"Deep learning for tabular data IV: Deep Learning vs LightGBM -- ""If we focused only in performance metrics and running time the only possible conclusion is that DL models for tabular data are still no competition for GBMs in real-world environments."" https://t.co/gAWECsH81l"
8092,@rasbt,2021-06-16 03:36:27+00:00,https://twitter.com/rasbt/status/1405006328729382917,"@alfcnz @KyleCranmer @psteinb_ @dhpmrou @mackelab @robamler @Sca_DS Alright, I am in. Let's do this üí™üî•"
8093,@rasbt,2021-06-16 03:27:12+00:00,https://twitter.com/rasbt/status/1405004000479657987,"""GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)"" https://t.co/5StpYCzKQr. Don't even need to read the abstract. Title already tells me it's a fun read &amp; defines the scope. Love it."
8094,@rasbt,2021-06-16 02:18:19+00:00,https://twitter.com/rasbt/status/1404986667547729920,Writing a conference paper and exceeding the page limit 1 hour before the submission deadline
8095,@rasbt,2021-06-15 22:56:23+00:00,https://twitter.com/rasbt/status/1404935850341904387,"@alfcnz @KyleCranmer @psteinb_ @dhpmrou @mackelab @robamler @Sca_DS Thanks for forwarding. Sounds like a good opportunity to share what I've learned about teaching in the last couple of years, and I'd enjoy writing it. Summer is busier than I had hoped, but I hope I can contribute."
8096,@rasbt,2021-06-14 03:52:21+00:00,https://twitter.com/rasbt/status/1404285554687098883,"@xamat If you are referring to the paper I am thinking of, it's a perfect case study of lurking variables."
8097,@rasbt,2021-06-14 02:16:35+00:00,https://twitter.com/rasbt/status/1404261456330334212,"@F_Vaggi @michael_nielsen ""more people, more resources, more facilities"" probably sounds nice in an industry context. In a scientific context, I'd say this means you probably get stretched even more thin. It's great if you are more of a manager person but probably not great if you like being hands-on"
8098,@rasbt,2021-06-12 17:08:20+00:00,https://twitter.com/rasbt/status/1403761095370813446,"@roydanroy Yeah, maybe. I would just put the RAM meter from iStat into your menubar and keep an eye on it when the computer feels slow to see if it coincides with maxed out memory use. Maybe you have some rogue program or malware using up resources, or maybe there is a hardware issue even"
8099,@rasbt,2021-06-12 16:48:48+00:00,https://twitter.com/rasbt/status/1403756181986988036,@FSoudan @roydanroy I am using the ARM-version of Miniforge and it works great (https://t.co/OKx3RDLEst). Basically miniconda with conda-forge as default channel. Some things I compiled myself: https://t.co/1iMYYKSEbH
8100,@rasbt,2021-06-12 16:04:56+00:00,https://twitter.com/rasbt/status/1403745138602655745,"@roydanroy That being said, it's crazy how much RAM ""simple"" office apps take these days: https://t.co/MDfN1CzWMe"
8101,@rasbt,2021-06-12 16:02:13+00:00,https://twitter.com/rasbt/status/1403744457263091728,"@roydanroy I use the machine quite heavily for everything, web browsing, image &amp; video editing, lecture recording, Slack, Texpad, etc. and have usually many apps open. If you use the 8 GB for say just web browsing, I don't think you should be having a RAM bottleneck"
8102,@rasbt,2021-06-12 15:59:02+00:00,https://twitter.com/rasbt/status/1403743656176197633,@roydanroy 16 GB. Was coming from a 32 GB machine and was actually worried about that because it usually used &gt;60%. On the 16 GB it's still the same usage percentage; I think modern OSes are quite good with memory allocation
8103,@rasbt,2021-06-12 15:38:22+00:00,https://twitter.com/rasbt/status/1403738453523718146,"@omarsar0 It makes it look messy at first glance, but I really like the branching. I think it's spot on. If you want to add one more thing: Autoencoders &amp; GANs (probably as a branch of 6. &amp; 7., CNNs."
8104,@rasbt,2021-06-12 03:56:42+00:00,https://twitter.com/rasbt/status/1403561875892224002,"@roydanroy @KDziugaite Wow! This sounds like a really fun tradition, and this looks amazing!"
8105,@rasbt,2021-06-11 03:31:52+00:00,https://twitter.com/rasbt/status/1403193237704171524,"@KountayDwivedi wow, that's very flattering! I can't promise when I will get to it but I bookmarked it. The drawings look really engaging and effective"
8106,@rasbt,2021-06-11 03:25:46+00:00,https://twitter.com/rasbt/status/1403191701112508416,"@RileenSinha yes and no, you will see ;)"
8107,@rasbt,2021-06-11 03:20:06+00:00,https://twitter.com/rasbt/status/1403190276370350081,"It's been (just?) 6 year since the first edition, but it feels like ages ago when reading what I wrote back then. I am really enjoying the process of revisiting old topics and thinking about how I can present certain concepts more clearly https://t.co/sQw5CN1dQ9"
8108,@rasbt,2021-06-10 21:21:00+00:00,https://twitter.com/rasbt/status/1403099906051563528,"@__mharrison__ @xamat True, when I see pictures of your setup, I must say that this is a prime example of ""professional"" video conferencing"
8109,@rasbt,2021-06-10 21:08:59+00:00,https://twitter.com/rasbt/status/1403096881488662536,"@xamat Zoom what? Chatting via Zoom, teaching via Zoom, peer programming via Zoom?"
8110,@rasbt,2021-06-09 21:05:55+00:00,https://twitter.com/rasbt/status/1402733720088596481,"@xamat @anithakan @katariya_namit Awesome, congrats to you all! :)"
8111,@rasbt,2021-06-09 16:15:57+00:00,https://twitter.com/rasbt/status/1402660750049546246,"@ducha_aiki wow, haven't noticed that one yet"
8112,@rasbt,2021-06-08 23:03:26+00:00,https://twitter.com/rasbt/status/1402400907397144579,"@eggie5 Good q. They used it in the ""Simple Ensemble"" in that paper. The hyperparam search looks as extensive as the one for XGBoost. My guess is that XGBoost outperformed CatBoost in their experiments, which is why they went with XGBoost for the DNN comparison. But I am just speculating"
8113,@rasbt,2021-06-08 22:11:41+00:00,https://twitter.com/rasbt/status/1402387886499110913,"@MaxEpstein5 @JFPuget Nice, gonna try this next time."
8114,@rasbt,2021-06-08 20:13:14+00:00,https://twitter.com/rasbt/status/1402358077442064384,"@jmschreiber91 @balazskegl Yap, nope, sorry. Bold does not make it significant. You only get proper significance with 1 to 3 asterisks."
8115,@rasbt,2021-06-08 20:08:40+00:00,https://twitter.com/rasbt/status/1402356928127377410,"@tom_gxt Ah sorry, that was for the MLP. The 1D-CNN etc. are a tad slower. Same dataset, 0.2 min / epoch on CPU. Still relatively fast but not nearly as fast as e.g., XGBoost. I can run 1000 hyperopt iterations with XGBoost in like 1-2 min."
8116,@rasbt,2021-06-08 20:06:34+00:00,https://twitter.com/rasbt/status/1402356400244891648,@balazskegl Totally with you with that. Probably wouldn't call it old school though -- rather the opposite. Requiring uncertainty scores is a more recent development in DL. And I am usually also very picky about that.
8117,@rasbt,2021-06-08 17:53:17+00:00,https://twitter.com/rasbt/status/1402322855296176131,"@chanansh It depends on the dataset. Sometimes it makes sense to extract features manually (incl. domain knowledge) vs using automatic feature extraction vs DNNs. Both methods have their place, imho"
8118,@rasbt,2021-06-08 17:51:14+00:00,https://twitter.com/rasbt/status/1402322341686923269,"@chanansh I see. It depends. I mean take the Iris dataset as a classic example. The features are flower width and height. Sure, you can apply a CNN to raw(er) data formats (i.e., images). But then you'll need a larger dataset of course."
8119,@rasbt,2021-06-08 17:49:00+00:00,https://twitter.com/rasbt/status/1402321778530258953,"@tom_gxt Depends on the dataset of course, but in most cases, I assume it's almost negligible. Was just trying different methods on a 1000 example + 6 column dataset, and 300 epochs for a MLP take like 2-3 seconds on CPU (ARM chip)."
8120,@rasbt,2021-06-08 17:47:09+00:00,https://twitter.com/rasbt/status/1402321310890573828,"@chanansh I haven't looked into the datasets used in this particular comparison. But for tabular datasets in general, you assume that rows are independent (order doesn't matter). Same for columns."
8121,@rasbt,2021-06-08 16:55:13+00:00,https://twitter.com/rasbt/status/1402308241787392003,"@JFPuget yeah, even made sure it's encoded according to their instructions. Fitting went fine but I couldn't predict on this dataset. https://t.co/m7IZuEy5Pr"
8122,@rasbt,2021-06-08 16:36:15+00:00,https://twitter.com/rasbt/status/1402303469088919553,"@JFPuget Interesting! Btw based on the 2nd-place solution, the non blended 1D-CNN performs really well by itself too! https://t.co/ZcBQwtkoCx https://t.co/4KnxgcTyA2"
8123,@rasbt,2021-06-08 16:34:45+00:00,https://twitter.com/rasbt/status/1402303091949674498,"@JFPuget @alexip Re XGBoost. Yes, they have added experimental support for categorical data but didn't work for me. Re LightGBM, I think HistGradientBoostingClassifier, I think it's a re-implementation of LightGBM"
8124,@rasbt,2021-06-08 16:20:53+00:00,https://twitter.com/rasbt/status/1402299601164681222,"@JFPuget * HistGradientBoostingClassifier because it is easier to set up and use for beginners. Btw., I was recently trying XGBoost on a dataset with categorical data and had problems running it at all on this and had to use one-hot encoding for categorical features"
8125,@rasbt,2021-06-08 16:19:38+00:00,https://twitter.com/rasbt/status/1402299288873537537,@JFPuget 2/2 But seems that DNNs have won competitions on tabular data recently: https://t.co/yMXwFOcRtL.
8126,@rasbt,2021-06-08 16:19:25+00:00,https://twitter.com/rasbt/status/1402299234737704960,"@JFPuget Not a Kaggler but this is totally in line with what I would have thought. Also, XGBoost is my go-to recommendation (along with scikit-learn's HistGradientBoostingClassifier) for tabular data these days 1/2"
8127,@rasbt,2021-06-08 16:14:41+00:00,https://twitter.com/rasbt/status/1402298042288644103,"@latticepolys Yeah, I can imagine. However, given the recent promises in these other papers, I think it was worth taking a look at these methods. XGBoost seems better, but it's not a very clear winner imho. In any case, what it has going for itself is that it also requires less tuning: https://t.co/zSJHLIrnoD"
8128,@rasbt,2021-06-08 16:01:02+00:00,https://twitter.com/rasbt/status/1402294608231636997,"@latticepolys Yes and no, some of these DNNs were pretty recent, specialized architectures, incl. ones that won Kaggle competitions recently (https://t.co/yMXwFOcRtL)."
8129,@rasbt,2021-06-08 15:56:50+00:00,https://twitter.com/rasbt/status/1402293551925542916,@mohomran * Small correction: I just see they did include TabNet
8130,@rasbt,2021-06-08 15:56:05+00:00,https://twitter.com/rasbt/status/1402293361755701248,"@mohomran How do you mean? The SAINT authors included XGBoost in their tables. Would have been nice though if the SAINT authors also included other deep neural networks (like NODE, DNF-Net, TabNet, and the 1D-CNN by Baosenguo et al.)"
8131,@rasbt,2021-06-08 15:48:36+00:00,https://twitter.com/rasbt/status/1402291479461171203,Also no surprise here: XGBoost requires less hyperparameter tuning (x-axis shows the number of iterations in hyperopt): https://t.co/zSzOCLgmIZ
8132,@rasbt,2021-06-08 15:44:28+00:00,https://twitter.com/rasbt/status/1402290438803951628,Tabular Data: Deep Learning is Not All You Need. Nice comparison betw XGBoost &amp; recent DNNs for tabular data. Surprise?! XGboost comes out on top for most datasets (esp. those not incl in the DNN papers). What's even better? An ensemble of XGBoost &amp; DNNs https://t.co/GOeH3XxqV4 https://t.co/kCNAJPggon
8133,@rasbt,2021-06-08 14:34:30+00:00,https://twitter.com/rasbt/status/1402272830172143620,"@AndreasBenderUK @kjelljorner @rguha Yeah, I have had similar experiences in my projects. Esp. if the dataset is relatively small, the learning curves are somewhat noisy, and it is hard to extrapolate from that reliably. But you may get a rough ballpark estimate"
8134,@rasbt,2021-06-08 03:02:51+00:00,https://twitter.com/rasbt/status/1402098769861255176,"@DynamicWebPaige Hah, that's the glass is half full perspective, but true, too üôÉ"
8135,@rasbt,2021-06-08 03:02:11+00:00,https://twitter.com/rasbt/status/1402098605234737153,@DynamicWebPaige That's a great summary! Love it!
8136,@rasbt,2021-06-07 06:59:50+00:00,https://twitter.com/rasbt/status/1401796021739573248,@aerinykim @ylecun et al.
8137,@rasbt,2021-06-06 22:59:33+00:00,https://twitter.com/rasbt/status/1401675154787344386,"Learning curves: once part of ML intro courses I feel like they fell out of fashion in the last decade. In my last three collabs (ML on small datasets), they were super valuable to discover predictive performance bottlenecks and justify spending a few hours on getting more data"
8138,@rasbt,2021-06-06 21:35:36+00:00,https://twitter.com/rasbt/status/1401654026375213057,"@unsorsodicorda @jazzcoffeestuff Reminds me, a long long time ago I did some quick &amp; dirty benchmarks. Even for something non-scientific computing related (bubblesort &amp; classic for-loops), and my naive implementation, I got a ~300 speedup when using Cython. https://t.co/ZlUmqngD1X https://t.co/WhsHHZgGJa"
8139,@rasbt,2021-06-06 20:19:19+00:00,https://twitter.com/rasbt/status/1401634831885348865,"@BatesDmbates Thanks for reminding me and offering your help with this, really appreciate it! Unfortunately, I have to postpone this a bit longer due to taking on too many other projects this summer (and keeping up with the recent transformer research)"
8140,@rasbt,2021-06-06 20:05:32+00:00,https://twitter.com/rasbt/status/1401631360498999298,@Rubenia_Borge @fchollet Same boat. Doesn't help that it's usually around Finals' week and life is already stressful enough
8141,@rasbt,2021-06-06 20:04:16+00:00,https://twitter.com/rasbt/status/1401631044328173571,"@unsorsodicorda There are more and more solutions to this problem, Numba, Cython, and maybe even Rust: https://t.co/bOFa1WzCJ5"
8142,@rasbt,2021-06-06 20:03:04+00:00,https://twitter.com/rasbt/status/1401630740836651011,"@unsorsodicorda I agree with all you've said. Edu around analyzing code could definitely be improved. Might be worthwhile to get a first prototype up and running in Python, then replace/upgrade performance critical parts"
8143,@rasbt,2021-06-06 19:50:40+00:00,https://twitter.com/rasbt/status/1401627620480016390,"@chae_yeun_park To me, the solution here is to improve education around Python, teaching to identify bottlenecks via profilers etc. Maybe learning to considering utilizing Numba or Cython for performance critical aspects etc."
8144,@rasbt,2021-06-06 19:49:16+00:00,https://twitter.com/rasbt/status/1401627270754799618,"@chae_yeun_park 1/2 One option is to (require to) use another language, but how many people would be left behind? I learned C++ in college and was even quite good at it. But if I had to use C++ day to day, many projects probably wouldn't have gotten done at all"
8145,@rasbt,2021-06-06 19:47:07+00:00,https://twitter.com/rasbt/status/1401626727844139014,"@chae_yeun_park I get your point, but one might argue this is due to increased accessibility; i.e., more people are able to do computation in an HPC environment because Python makes these implementations easier. 1/2"
8146,@rasbt,2021-06-05 00:38:36+00:00,https://twitter.com/rasbt/status/1400975307641917442,"The more important question: How can we make computing environmentally more friendly? Instead of switching to Fortran, how about by teaching Python well? By showing how to replace for-loops with vectorized implementations and utilize scientific libraries"
8147,@rasbt,2021-06-05 00:35:44+00:00,https://twitter.com/rasbt/status/1400974584678076425,"And if this little overhead really matters, well maybe we should also get rid of GUIs then, installing Debian headless on our laptops."
8148,@rasbt,2021-06-05 00:33:02+00:00,https://twitter.com/rasbt/status/1400973907184820232,"Looking at this manuscript, the author seems bitter and probably doesn't know that almost no one implements scientific code in vanilla Python -- those who do are doing it for educational purposes or debugging. E.g. for DL, Python's overhead (vs pure C++/CUDA) is less than 10%"
8149,@rasbt,2021-06-04 12:55:50+00:00,https://twitter.com/rasbt/status/1400798447180070914,"@vinnuvinay008 Wow thanks for the kind words, and that‚Äôs very very motivating to hear!"
8150,@rasbt,2021-06-03 05:13:20+00:00,https://twitter.com/rasbt/status/1400319667684753409,@ChrSzegedy @seanjtaylor @chappaquack SELUs (https://t.co/fkd9pAZzk0)? Have to admit that I always admired the idea but never really read up on it ... because life &amp; 100 pages.
8151,@rasbt,2021-06-03 05:06:33+00:00,https://twitter.com/rasbt/status/1400317962893119491,"""Never have I found a community that is so loving and considerate. The people are not snobby to newbies, and give the feeling of actually being excited about seeing them develop.""  (via https://t.co/y1UR9oOJel‚Ä¶). Happy to be part of this community. Let's keep it like this :)"
8152,@rasbt,2021-06-03 03:01:00+00:00,https://twitter.com/rasbt/status/1400286368094425090,"The process of revisiting &amp; refining educational material is oddly satisfying. I am not trying to produce eye-candy, but I am trying to incoporate feedback from the ""a few years later perspective"" -- asking myself how I can provide more info to anticipate potential questions :) https://t.co/tXzkHMdQNo"
8153,@rasbt,2021-06-02 03:36:21+00:00,https://twitter.com/rasbt/status/1399932873860341761,"@LuciaScience @anthonygitter @GreeneScientist @wildtypeMC @biodataguy @evan_cofer @jcveritas @alxndrkalinin @FertigLab @siminaboca @1AlexanderTitus I remember we actually started this project under the ""Ten simple rules for deep learning in biology"" title but the journal asked us to change it. But we hope the recommendations didn't get that much more complicated in the process ;)"
8154,@rasbt,2021-06-02 02:09:01+00:00,https://twitter.com/rasbt/status/1399910896877637633,4/4 It's short and concise and an enjoyable read. Found myself reading and nodding: Turns out Radek really captured the essence of all of it. It's a hard recommend! I believe this is the official link to the book in case you are interested: https://t.co/oMsc9fbSaO
8155,@rasbt,2021-06-02 02:09:01+00:00,https://twitter.com/rasbt/status/1399910894818242562,3/4 It's an eventful summer &amp; I just wanted to check it out ... thought it might be something that I could recommend to students. I looked at the TOC and could help but checking out all these topics -- really curious to hear what someone would write about these https://t.co/hLakD2pRaq
8156,@rasbt,2021-06-02 02:08:59+00:00,https://twitter.com/rasbt/status/1399910888015028227,"""Meta Learning -- How To Learn Deep Learning And Thrive In the Digital Work!""
If you are starting out in deep learning, this is the book! It distills what I perceived as my own hard-won experience from being on the ML internet since 2012-ish into a pocketable 80 pages. 1/4"
8157,@rasbt,2021-06-01 15:50:06+00:00,https://twitter.com/rasbt/status/1399755141188919298,"@philipvollet This ProteinBERT approach reminds me of ProtBert (https://t.co/gUMtlHUHqL, from https://t.co/KNh1EZKyDN). Dataset and tasks seem similar. Seems like the main diff is that ProteinBERT has an additional GO recovery task during pre-training."
8158,@rasbt,2021-05-31 21:03:53+00:00,https://twitter.com/rasbt/status/1399471721443381252,@suzatweet @huggingface Wow big congrats! That sounds amazing! Wishing you all the best in your new role!
8159,@rasbt,2021-05-31 21:02:18+00:00,https://twitter.com/rasbt/status/1399471322372231172,"@wightmanr @ylecun to be fair, there's PyTorch itself"
8160,@rasbt,2021-05-31 19:33:33+00:00,https://twitter.com/rasbt/status/1399448986256355328,"@cmarschner @chriswolfvision Yes and no. There have been so many specialized architectures in recent years. I.e., Artificial Neural Network may get fewer searches today, but you have to factor in all the searchers related to BERT, GPT, Transformer etc. that didn't exist &gt;2 years ago."
8161,@rasbt,2021-05-31 18:25:15+00:00,https://twitter.com/rasbt/status/1399431798183108608,"@_amirrahnama @chriswolfvision As a relatively junior person, I haven't submitted to many venues, but I have reviewed for quite a few. Based on my reviewer experience, both JMLR and Nature Machine Intelligence stood out positively"
8162,@rasbt,2021-05-31 18:08:25+00:00,https://twitter.com/rasbt/status/1399427561269174276,"@chriswolfvision Nah, people are just getting fed up with conference reviews and submit elsewhere üôÉ. Will only believe in the peak if the total number of ML/DL papers uploaded on Arxiv at the end of 2021 will be &lt;= 2020 ;)"
8163,@rasbt,2021-05-31 17:56:27+00:00,https://twitter.com/rasbt/status/1399424551365251076,"@roydanroy @mlittmancs Is there a large intersection between offenders and people in charge, perhaps?"
8164,@rasbt,2021-05-31 17:55:11+00:00,https://twitter.com/rasbt/status/1399424230182297600,"@roydanroy @mlittmancs we had discussions about why paper writing is broken, excuses like ""But everyone is doing it"" for years. Yet, nothing ever seems to have change. For conference organizers: Keep a public list of offenders. Ban offenders from future conference participation. Why is that so hard?"
8165,@rasbt,2021-05-31 04:55:51+00:00,https://twitter.com/rasbt/status/1399228107576512518,"@seanjtaylor @klakhani Yeah, as long as I remember, when your order from their website, you get a recycle back for free (a bag you can drop off at ups for free that gets shipped back to them for recycling)"
8166,@rasbt,2021-05-31 02:13:13+00:00,https://twitter.com/rasbt/status/1399187177339240453,"@zacharylipton If it comes across like gatekeeping, it‚Äôs probably gatekeeping"
8167,@rasbt,2021-05-31 02:10:30+00:00,https://twitter.com/rasbt/status/1399186494582034439,"@jamie_maguire1 So many different workflows, there is a unique one for everyone"
8168,@rasbt,2021-05-31 02:07:31+00:00,https://twitter.com/rasbt/status/1399185745299054598,"@semiDL @MatharyCharles @zacharylipton Yeah, maybe the hard to understand aspect is due to space constraints or just brevity for the sake of efficiency. It‚Äôs maybe a necessity sometimes but I don‚Äôt see how this is something to be particularly proud of"
8169,@rasbt,2021-05-29 00:13:12+00:00,https://twitter.com/rasbt/status/1398432201012809740,@kjbird15 Thanks a lot for the kind and motivating words!
8170,@rasbt,2021-05-28 03:11:02+00:00,https://twitter.com/rasbt/status/1398114566391877635,"@roydanroy @leonpalafox And as a result, there was all talk and zero consequences, and this pisses me off, and this has to change."
8171,@rasbt,2021-05-28 03:06:55+00:00,https://twitter.com/rasbt/status/1398113526267404289,"@roydanroy @leonpalafox As an international student, I did care about these things. Wasn't sexual but another form of misconduct in academia reg. my advisor. Went to the research integrity officer etc. Same overall exp: people tried sweeping things under the rug. Back then, thought it was an MSU thing"
8172,@rasbt,2021-05-28 02:29:38+00:00,https://twitter.com/rasbt/status/1398104143684907008,@roydanroy Wasn't aware of this. Thanks for resurfacing. It's painful to read into this and related posts. But I think it is important to read about and share in hope that something like this never ever happens again.
8173,@rasbt,2021-05-28 01:06:53+00:00,https://twitter.com/rasbt/status/1398083319938654210,"@thetowerofcell 4 as in the ""4th edition"" or ""May the 'Forth' be with you""  :P"
8174,@rasbt,2021-05-28 00:41:42+00:00,https://twitter.com/rasbt/status/1398076985310650370,"Really excited about the projects I lined up for this summer. One of them involves PyTorch, transformers, graph neural nets, and the number 4"
8175,@rasbt,2021-05-27 18:18:55+00:00,https://twitter.com/rasbt/status/1397980652696387592,"@WillHighSci Hm, 'categorical label learning' and 'continuous label learning' are definitely a bit unwieldy ü§î"
8176,@rasbt,2021-05-27 01:33:54+00:00,https://twitter.com/rasbt/status/1397727732843356163,Every time I explain the terms ‚Äúsupervised‚Äù and ‚Äúunsupervised‚Äù learning to students it makes me feel like a dinosaur. I am in favor of just calling it ‚Äúlabel-learning‚Äù &amp; ‚Äúpattern discovery‚Äù ‚Ä¶ or sth like that
8177,@rasbt,2021-05-27 01:16:29+00:00,https://twitter.com/rasbt/status/1397723348696809472,"@xamat And sometimes when you get asked to give a talk for free, you are actually getting a good deal there"
8178,@rasbt,2021-05-25 17:32:38+00:00,https://twitter.com/rasbt/status/1397244229852745744,@mjcavaretta @AndrewYNg The Data Cascades paper maybe captures the general sentiment nicely: https://t.co/gp5iUop8i5
8179,@rasbt,2021-05-25 17:27:17+00:00,https://twitter.com/rasbt/status/1397242884781400065,@mjcavaretta @AndrewYNg 2/2 I think even something simple as a learning curve plot could probably convince collaborators with small datasets to reconsider regarding the dataset as a fixed asset.
8180,@rasbt,2021-05-25 17:26:46+00:00,https://twitter.com/rasbt/status/1397242753407406085,"@mjcavaretta @AndrewYNg Interestingly, we all learned about ""learning curves"" at some point from intro ML classes or books. Yet, I don't think we often see them in practice. 1/2"
8181,@rasbt,2021-05-25 17:24:28+00:00,https://twitter.com/rasbt/status/1397242175826583552,"@unsorsodicorda @__mharrison__ I did! 2 or 3 times in the last last 10 years. I don't follow it  100% but overall there are many useful aspects in there. Overall, I would really recommend it."
8182,@rasbt,2021-05-25 17:22:37+00:00,https://twitter.com/rasbt/status/1397241707977232393,"@mjcavaretta @AndrewYNg I don't think there are (m)any concrete counter-arguments. Data work is just perceived as ""more uncool"" is my guess. It's mostly: ""We have this dataset and tried the following methods, and results are not good. What are the latest ML methods that can improve the results?"""
8183,@rasbt,2021-05-25 16:57:24+00:00,https://twitter.com/rasbt/status/1397235364029517836,@neurobongo But the survey said customers want bigger batteries ...
8184,@rasbt,2021-05-25 16:03:54+00:00,https://twitter.com/rasbt/status/1397221898044456962,"@__mharrison__ Every evening, write down a daily schedule for the next day and try to stick to it as best as possible"
8185,@rasbt,2021-05-25 15:37:48+00:00,https://twitter.com/rasbt/status/1397215330808864772,@mjcavaretta @AndrewYNg Probably needs experiments &amp; results to be more convincing
8186,@rasbt,2021-05-25 14:27:06+00:00,https://twitter.com/rasbt/status/1397197540362268698,@uguralikaplan @QVagabond @AndrewYNg I read it as incentive for people to test their architectures/models on more diverse datasets (instead of just Cifar-10 &amp; ImageNet) and make sure they perform well under different scenarios etc.
8187,@rasbt,2021-05-25 14:06:30+00:00,https://twitter.com/rasbt/status/1397192354512179201,"@MilesCranmer Quick glance at the screenshot: ADAM and occasionally just momentum (SGD+momentum?) seem to be fine most of the time. Good, not missing out on anything exciting then :)"
8188,@rasbt,2021-05-25 13:45:28+00:00,https://twitter.com/rasbt/status/1397187062072283146,"@AndrewYNg Great and refreshing idea. Often when i am asked how to improve results in a project and I bring up data centric approaches, people seem to be uninterested. Your idea would not only be good exercise but also result in references &amp; success stories for convincing collaborators :)"
8189,@rasbt,2021-05-25 02:01:58+00:00,https://twitter.com/rasbt/status/1397010019351150592,"@TheZachMueller Very nice! And yeah, very unexpected. That's definitely more ""car"" than Jeep :)"
8190,@rasbt,2021-05-25 01:08:36+00:00,https://twitter.com/rasbt/status/1396996588002758656,"@TheZachMueller Oh I see. Haven't been on a Bronco, but yeah, I can see that; it's probably more like a Rubicon."
8191,@rasbt,2021-05-25 01:03:48+00:00,https://twitter.com/rasbt/status/1396995380223545344,"@TheZachMueller I think AWD is more comfortable for longer trips &amp; highways, but you will probably appreciate the 4WD for rock climbing. PS: Yeah, the CrossTrek is a bit small, but the Outback is quite large, in fact you can put a mattress in the back if you fold the back seats over :D"
8192,@rasbt,2021-05-25 01:01:45+00:00,https://twitter.com/rasbt/status/1396994867423809538,"@TheZachMueller I don't think it's overkill to have either 4WD or AWD when you live in a snowy state, rather the safe &amp; sane thing :). I think both should handle snow well with appropriate tires."
8193,@rasbt,2021-05-24 22:27:02+00:00,https://twitter.com/rasbt/status/1396955931032924163,@daniela_witten One way this could maybe be justified is to charge speakers so that it can be completely free for student attendees. Still expenses like paying for giving talk don‚Äôt sound right. Do conference organizers also have to pay to help organizing the conference?
8194,@rasbt,2021-05-24 22:10:14+00:00,https://twitter.com/rasbt/status/1396951702876602372,@daniela_witten Next: charge reviewers for reviewing papers
8195,@rasbt,2021-05-24 17:19:28+00:00,https://twitter.com/rasbt/status/1396878526389833733,"@ykilcher Haha, awesome. This wins the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2021."
8196,@rasbt,2021-05-24 17:03:49+00:00,https://twitter.com/rasbt/status/1396874588995432450,@JimEntwood @roydanroy Thanks &amp; no worries!
8197,@rasbt,2021-05-24 14:41:58+00:00,https://twitter.com/rasbt/status/1396838892930846727,"@mblondel_ml @roydanroy Checking that submissions meet minimum quality standards and are submitted with the correct subject categories. Short summary here: https://t.co/UjutmIvwRU
PS: this list of moderators by subject area seems more up to date: https://t.co/zIVFLdWmNW"
8198,@rasbt,2021-05-24 14:36:35+00:00,https://twitter.com/rasbt/status/1396837538132893698,@roydanroy Bummer that this list seems out of date. Have been an active moderator for cs.LG since 2019.
8199,@rasbt,2021-05-24 04:46:47+00:00,https://twitter.com/rasbt/status/1396689110451081217,"@burkov Yeah, that‚Äôs what I meant. Of course you will still have to keep your hands on the wheel during regular operation, but you‚Äôll be able to watch an entire Harry Potter movie while you wait and it‚Äôs charging"
8200,@rasbt,2021-05-24 04:34:00+00:00,https://twitter.com/rasbt/status/1396685890626408449,"@burkov According to latest rumors, pretrained cars are going to be for sale in 2025"
8201,@rasbt,2021-05-22 20:05:03+00:00,https://twitter.com/rasbt/status/1396195420687282181,@srchvrs @iamtrask @lemire video literally looks bad on paper ;)
8202,@rasbt,2021-05-22 20:00:41+00:00,https://twitter.com/rasbt/status/1396194323172057088,"@srchvrs @iamtrask @lemire Yeah agree. To many reviewers, things would look fishy if researchers used a non-standard dataset"
8203,@rasbt,2021-05-22 17:31:33+00:00,https://twitter.com/rasbt/status/1396156794825740296,"@iamtrask We have seen something like this on a smaller scale with the 1000+ projects that predict COVID from chest X-rays. Overall, not sure this was helpful. Some of them were genuine, well-meaning efforts of course. But overall, all the noise gave this whole research direction a bad rep"
8204,@rasbt,2021-05-22 17:27:52+00:00,https://twitter.com/rasbt/status/1396155865036726277,"@iamtrask On one hand, I totally agree. On the other, I think one alternative scenario is someone comes up with a MNIST-like dataset related to cancer diagnosis. After a few rounds, people start getting &gt;95% acc. Some people, esp. popular media, will claim we solved cancer. Not good either"
8205,@rasbt,2021-05-22 15:15:44+00:00,https://twitter.com/rasbt/status/1396122613731180546,"@icymi_py And since all good things come in threes ;)
- ""GPT-v1: Generative Pre-Trained Transformer"" (https://t.co/oUuaZzC0J3)
- ""GPT-v3: Language Models are Few-Shot Learners"" (https://t.co/RkqxKHiUSe)"
8206,@rasbt,2021-05-22 15:01:00+00:00,https://twitter.com/rasbt/status/1396118906281070595,"@vlad_flore @fchollet Nice, learned something new!"
8207,@rasbt,2021-05-22 03:00:58+00:00,https://twitter.com/rasbt/status/1395937702047096834,@mat_kelcey @fchollet Not sure why but this one I never got used to using it most of the time. It's probably due to old muscle memory and having a list of all options at one glance.
8208,@rasbt,2021-05-22 02:47:54+00:00,https://twitter.com/rasbt/status/1395934417416302598,@michaelaye @fchollet I think at this point it is just habit and muscle memory. I do use zsh but don't have auto history activated.
8209,@rasbt,2021-05-22 02:02:31+00:00,https://twitter.com/rasbt/status/1395922994111909896,"@fchollet yeah or
1. history 100 | grep 2_to_3_letters
2. mouse select &amp; cmd+c
3. cmd+v"
8210,@rasbt,2021-05-22 01:57:25+00:00,https://twitter.com/rasbt/status/1395921712089284610,"@hugobowne Yeah, tried to use it in a molecule design &amp; optim context. (we reviewed some of the related literature here https://t.co/TNUNWPh4F5 if you are interested; pg 105). Kind of tried it for related work in a molecule context but didn't work so well compared to backprop-based methods"
8211,@rasbt,2021-05-21 15:56:46+00:00,https://twitter.com/rasbt/status/1395770553089286145,"@MisalRaj_ @TheZachMueller @alfcnz @omarsar0 Wow, awesome, I had no idea :)"
8212,@rasbt,2021-05-21 15:22:29+00:00,https://twitter.com/rasbt/status/1395761924424482818,"@hugobowne negative reinforcement, couldn't get it to work well several times"
8213,@rasbt,2021-05-21 02:39:26+00:00,https://twitter.com/rasbt/status/1395569898542219264,@yoavgo Gating Is Also What You Need! https://t.co/YMDx5uEfaH
8214,@rasbt,2021-05-21 01:41:43+00:00,https://twitter.com/rasbt/status/1395555371180335105,"@sid_fury @jmschreiber91 Nah, last week, we concluded it's good for DL. Rabbit holes here:
https://t.co/IpyRRAlDAj

https://t.co/I3UeNd1UaV https://t.co/nrxPiWvMXm"
8215,@rasbt,2021-05-21 00:35:34+00:00,https://twitter.com/rasbt/status/1395538726244212738,"@TheZachMueller @alfcnz @omarsar0 CS231 by Bill Punch at MSU. That was a decade ago though, and I don't think there is an online version. He has a great textbook though (The Practice of Computing Using Python)"
8216,@rasbt,2021-05-21 00:26:07+00:00,https://twitter.com/rasbt/status/1395536347436224513,"@TheZachMueller @alfcnz @omarsar0 To be honest, given that Python is primarily object-oriented, you could consider any Python course that is worth its salt. Not a course but an excellent book: Fluent Python by Lucio Ramalho"
8217,@rasbt,2021-05-20 23:05:02+00:00,https://twitter.com/rasbt/status/1395515939672690693,"@jmschreiber91 Hah, the glass is half-full perspective: DL practitioners use cross-validation ;)"
8218,@rasbt,2021-05-20 22:57:16+00:00,https://twitter.com/rasbt/status/1395513986603528195,"@wightmanr 2/2 the smaller size

1) can make all the difference betw. being able to run it on your hardware or not

2) allows you to explore more hyperparam options for the same budget

3) for the same budget, you can have an ensemble of 10 ENets, which would probably outperform the SOTA"
8219,@rasbt,2021-05-20 22:56:51+00:00,https://twitter.com/rasbt/status/1395513881771053059,"@wightmanr Yeah, with the EfficientNetV2-M version only being like 2 percent points worse but 10x smaller than say ViT-H/14, it  is very appealing from a user perspective

1/2"
8220,@rasbt,2021-05-20 22:30:22+00:00,https://twitter.com/rasbt/status/1395507215587553290,"Awesome news. I almost dismissed the EfficientNetv2 paper as an April Fool's joke last month, but it turned out to be one of the more exciting convolutional network-related papers I read this year. Looking forward to taking the PyTorch version for a spin now!"
8221,@rasbt,2021-05-19 20:33:06+00:00,https://twitter.com/rasbt/status/1395115317882458119,@roydanroy Includes some basic training assessment and evaluation without any major dependencies. All you need to do is changing the dataset and adjusting the number of output layers. https://t.co/FhxatDEeCh
8222,@rasbt,2021-05-19 20:28:11+00:00,https://twitter.com/rasbt/status/1395114080504061960,"@roydanroy Have some implementations here: https://t.co/armA3X7hOt. Incl. ResNet etc. But I recommend going to the mobilenet notebook (https://t.co/LUe3Rar3sO) and just replace ""mobilenet_v2"" with one of the following: 'resnet101',
 'resnet152',
 'resnet18',
 'resnet34',
 'resnet50' https://t.co/z90Iwf1Rjt"
8223,@rasbt,2021-05-19 17:32:53+00:00,https://twitter.com/rasbt/status/1395069967033327628,"@roydanroy @jefrankle It's not terrible. But I feel like if they insist on double-column format, then there should also be line numbers on both sides"
8224,@rasbt,2021-05-19 15:36:51+00:00,https://twitter.com/rasbt/status/1395040765542338564,"Just looking at the ""Enhancing Photorealism Enhancement"" paper, and (owning a Switch) I had no idea video games already look so realistic to begin with. But yeah, the enhanced version is quite something (https://t.co/mnUcel4SRO) https://t.co/BLtteWo7r1 https://t.co/DEUbEy6DXr"
8225,@rasbt,2021-05-19 15:06:02+00:00,https://twitter.com/rasbt/status/1395033007715725316,@zacharylipton I think it's called trading :P
8226,@rasbt,2021-05-19 14:24:53+00:00,https://twitter.com/rasbt/status/1395022654478983169,"@rishabh16_ It's yet another hyperparam. Personally, I notice only little differences, but in theory, weight init choice should depend on e.g., activiation function. Most recommend TanH &amp; Xavier, ReLU &amp; Kaiming, etc. You could also use the nonlinearity param to adjust for leaky vs relu etc: https://t.co/gCBmoF6zTd"
8227,@rasbt,2021-05-19 14:19:49+00:00,https://twitter.com/rasbt/status/1395021378903019522,@rishabh16_ I think they had a heuristic similar to Xavier. I think it was Xavier without fan_out. Now it's now defaulting to Kaiming He init in both linear and conv layers: https://t.co/DQxJdEX3KI &amp; https://t.co/ocVKfOEpWJ https://t.co/Cdqr2hnFRt
8228,@rasbt,2021-05-19 13:22:25+00:00,https://twitter.com/rasbt/status/1395006933216681990,"@mark_riedl This is only half the story. Have fun when you get to to the bundler and gem files parts. Also don‚Äôt bother with taking notes and writing done how you got it to work. Next time you have to install it and follow these steps, it won‚Äôt work. Have been there."
8229,@rasbt,2021-05-19 01:46:09+00:00,https://twitter.com/rasbt/status/1394831712207704069,"@hmason Phyto(plankto)n, got it. :)"
8230,@rasbt,2021-05-19 01:25:15+00:00,https://twitter.com/rasbt/status/1394826450528837633,"@HugoSchmutz2 @JFPuget @jeremyphoward 2/2 At the same time, after evaluation, unless you have a super unstable model, I still recommend fitting the model on all data. Like in the scenario depicted below, I would fit a model on all data https://t.co/kdVBKI4n9V"
8231,@rasbt,2021-05-19 01:22:44+00:00,https://twitter.com/rasbt/status/1394825818963124226,"@HugoSchmutz2 @JFPuget @jeremyphoward Not shown in the figure above, but you can of course add an approximated CI via cross-validation or nested CV (as they suggest in the paper). I would always recommend showing CIs or some measure of stability for perf. eval  1/2"
8232,@rasbt,2021-05-15 15:13:00+00:00,https://twitter.com/rasbt/status/1393585209715707904,@zacharylipton Which is located next to the compute facility where they use matrix multiply operations
8233,@rasbt,2021-05-15 14:24:52+00:00,https://twitter.com/rasbt/status/1393573095680659460,@Brotherluii Danke fuer die netten Worte!
8234,@rasbt,2021-05-15 14:24:32+00:00,https://twitter.com/rasbt/status/1393573015514984452,"@DJCordhose Yeah, I use an iPad + Pencil. This is a setup I am using back for in person teaching as well."
8235,@rasbt,2021-05-15 14:23:26+00:00,https://twitter.com/rasbt/status/1393572735171940354,"@DJCordhose Hah, thanks! :)"
8236,@rasbt,2021-05-15 04:44:14+00:00,https://twitter.com/rasbt/status/1393426975600021504,@ChrSzegedy ThreadBERT ;)
8237,@rasbt,2021-05-15 04:31:02+00:00,https://twitter.com/rasbt/status/1393423655070220289,@ChrSzegedy This would probably get a lot of attention
8238,@rasbt,2021-05-14 21:35:26+00:00,https://twitter.com/rasbt/status/1393319063968010244,"GPT-v2: https://t.co/3wqYSXdubV
GPT-v3: https://t.co/NQsV9Xz6DJ
BART: https://t.co/r4iZbSNh73
Closing words on lang models: https://t.co/C73lm8YuRB
Fine-tuning DistilBert in PyTorch: https://t.co/2T9hrPPprE"
8239,@rasbt,2021-05-14 21:35:25+00:00,https://twitter.com/rasbt/status/1393319062856511492,"Didn't want to end the last lecture with just the vanilla Transformer, so I made some optional post-semester content to wrap it up
Transformer: https://t.co/LkJU33WMBV
Other models overview: https://t.co/MWEkK6RxDx
GPT-v1: https://t.co/QtRpVac0fI
BERT: https://t.co/tDase8ziMU
..."
8240,@rasbt,2021-05-14 14:53:26+00:00,https://twitter.com/rasbt/status/1393217897259016192,"@GaelVaroquaux @JFPuget @apachaves @jeremyphoward So, when I understand correctly, you mean that if the researchers had used CV in the papers reporting these performances, then in the meta study (plots above), it would be closer to x=y? That would seem reasonable."
8241,@rasbt,2021-05-14 14:37:21+00:00,https://twitter.com/rasbt/status/1393213852393820162,"@GaelVaroquaux @JFPuget @apachaves @jeremyphoward &gt; 2) That line is not at x=y. Correlation is not equality. 

Sure, but this doesn't matter for model selection at all. If you are interested in the best model, then ranking is sufficient. To evaluate the model, you use an independent test set."
8242,@rasbt,2021-05-14 14:33:32+00:00,https://twitter.com/rasbt/status/1393212890098851842,"@GaelVaroquaux @JFPuget @apachaves @jeremyphoward I am absolutely certain that most if not all of them have been optimized for the original CIFAR-10 and ImageNet test sets. The original test set performances have a positive bias, but I am surprised that they are biased by the same amount."
8243,@rasbt,2021-05-14 14:29:31+00:00,https://twitter.com/rasbt/status/1393211879313510404,"@JFPuget @GaelVaroquaux @apachaves @jeremyphoward * I.e., it seems that you can select the fitting procedure without doing CV, just with a validation (and even test set) if that dataset is large; afterwards you would evaluate on an independent test set of course"
8244,@rasbt,2021-05-14 14:28:39+00:00,https://twitter.com/rasbt/status/1393211663793463296,"@JFPuget @GaelVaroquaux @apachaves @jeremyphoward &gt; rank correlation is useful to rank models, but not to evaluate model performance on new data.

Of course. I suggested multiple independent test sets for evaluation earlier. The plot was just to show that using a test set seems not that bad for model selection though"
8245,@rasbt,2021-05-14 04:04:12+00:00,https://twitter.com/rasbt/status/1393054514152890369,@anthonypjshaw I think @ykilcher has some special glasses for recording that might do the tricküôÉ
8246,@rasbt,2021-05-13 21:16:07+00:00,https://twitter.com/rasbt/status/1392951814996254724,Article source: https://t.co/YllFs194mI https://t.co/zDf8ybH44a
8247,@rasbt,2021-05-13 21:12:13+00:00,https://twitter.com/rasbt/status/1392950832992301057,"Creative approaches by both professors and students here. Co-evolution at work. Overall, I am glad that I replaced the final exam by more weight on project-based work, though. https://t.co/Ku7DyG0s97"
8248,@rasbt,2021-05-13 19:50:20+00:00,https://twitter.com/rasbt/status/1392930228398403584,"@RichmanRonald https://t.co/aYvW168wLF . PS: @JFPuget ""This repeated holdout procedure, sometimes also called Monte Carlo Cross-Validation, ..."" üôÉ"
8249,@rasbt,2021-05-13 19:37:25+00:00,https://twitter.com/rasbt/status/1392926979805036551,"@JFPuget @WalterReade @jeremyphoward Then using multiple test sets is more for evaluating the best model you got, which you may want to deploy or use in practice, or compare against some other ""best model"" you had before."
8250,@rasbt,2021-05-13 19:36:41+00:00,https://twitter.com/rasbt/status/1392926794798575619,"@JFPuget @WalterReade @jeremyphoward There is also the point that CV measures instability, which can be good for algorithm and modeling procedure comparisons (answering the question: how much do I have to fiddle with this model to get good and consistent performance)"
8251,@rasbt,2021-05-13 19:35:17+00:00,https://twitter.com/rasbt/status/1392926441000652803,"@JFPuget @WalterReade @jeremyphoward Thanks :). Yeah so my main point was that it is good to have multiple validation sets and multiple independent test sets, but it doesn't have to be strictly cross-validation in DL due to computational budgets"
8252,@rasbt,2021-05-13 18:38:53+00:00,https://twitter.com/rasbt/status/1392912247903686656,"@JFPuget @WalterReade @jeremyphoward Oh ok, then we have been on the same page all along. I always interpreted CV as involving rotating training and validation sets, hence the word ""cross"". And in the special case of k-fold, doing it k-times without &amp; sampling test folds w/o replacement."
8253,@rasbt,2021-05-13 16:45:40+00:00,https://twitter.com/rasbt/status/1392883753421246467,@DanevskiyD @JFPuget @thienan496 @jeremyphoward Ok fair :). Then let's take a CNN trained with all but the object-of-interest's pixels set to 0 values. Or an LSTM vs an LSTM with packed sequences
8254,@rasbt,2021-05-13 16:40:26+00:00,https://twitter.com/rasbt/status/1392882439400398850,"@HugoSchmutz2 @JFPuget @jeremyphoward 2/2 Sure, but in which practical scenario does it matter? If you have a learning curve pointing upwards for the test acc (like the one below), wouldn't you care more about using these 1500+ data points assuming it might improve the model vs having a theoretically accurate CI? https://t.co/mnC16gpsR6"
8255,@rasbt,2021-05-13 16:38:30+00:00,https://twitter.com/rasbt/status/1392881952101912583,"@HugoSchmutz2 @JFPuget @jeremyphoward You mean if you retrain your model on the whole dataset, the CI for the model trained on the training set is invalidated? 1/2"
8256,@rasbt,2021-05-13 16:29:55+00:00,https://twitter.com/rasbt/status/1392879790068322308,"@JFPuget @GaelVaroquaux @apachaves @jeremyphoward It's not that I don't think CV could be valuable for DL. But given computational budgets, I am not sure if it is that essential for model comparison &amp; selection. E.g. there is a near-perfect rank correlation in papers like ""Do Cifar-10/ImageNet classifiers generalize to ..."" https://t.co/iGxm7sIbpS"
8257,@rasbt,2021-05-13 16:24:08+00:00,https://twitter.com/rasbt/status/1392878337001930757,"@JFPuget @thienan496 @jeremyphoward Issues related to the curse of dimensionality do also translate to DL in my experience. I.e., try to fit a smallish model like LeNet-5 or AlexNet on images size 300x300 and then compare the classification performance to the same images downsized to ~70x70"
8258,@rasbt,2021-05-13 01:47:36+00:00,https://twitter.com/rasbt/status/1392657749905969152,"@JFPuget @jeremyphoward If you have a standard benchmark set, you can also subdivide your dataset so that you can use one portion to check progress periodically and an independent portion for the final estimate (but I guess no one would do this in practice for a paper as opposed to using the union)"
8259,@rasbt,2021-05-13 01:43:51+00:00,https://twitter.com/rasbt/status/1392656807039021062,"@JFPuget @jeremyphoward E.g., currently working on a project where we collected a new test set every two weeks to assess the model on an independent dataset to see whether we made real progress or just overfit (data leakage from re-evaluating on the same test set)"
8260,@rasbt,2021-05-12 22:55:47+00:00,https://twitter.com/rasbt/status/1392614510163374085,"@WalterReade @JFPuget @jeremyphoward Hah, I see. But if it's not too stressful, don't hesitate to reach out, maybe we could grab a coffee or so"
8261,@rasbt,2021-05-12 22:54:47+00:00,https://twitter.com/rasbt/status/1392614260677689346,"@JFPuget @jeremyphoward or for evaluating a particular model (say GPT-v3), having that 1 single training set (but several different tasks and tests sets) convincing enough. (Ok, grain of salt is that they didn't/couldn't(?) really make sure there is no overlap between train and test sets)"
8262,@rasbt,2021-05-12 22:53:27+00:00,https://twitter.com/rasbt/status/1392613922604191747,"@JFPuget @jeremyphoward depends on the domain, but if you are developing e.g. general purpose models for vision or language modeling, you could use different datasets to compare architectures"
8263,@rasbt,2021-05-12 22:44:59+00:00,https://twitter.com/rasbt/status/1392611792078127109,"@WalterReade @JFPuget @jeremyphoward Wow, that's great! Let me know when you are here &amp; settled"
8264,@rasbt,2021-05-12 22:38:06+00:00,https://twitter.com/rasbt/status/1392610062435246082,@WalterReade @JFPuget @jeremyphoward What I usually do is just running it multiple times but using a random seed for splitting off the validation set portion from the training set. Kind of easier than doing the rotation in cross-validation when using PyTorch data loaders.
8265,@rasbt,2021-05-12 22:32:09+00:00,https://twitter.com/rasbt/status/1392608561574854663,"@haltakov re jargon, my new favorite is ""matrix multiply"", as in ""we use a mixture of model parallelism within each matrix multiply"""
8266,@rasbt,2021-05-12 21:48:04+00:00,https://twitter.com/rasbt/status/1392597468748128260,"@JFPuget @jeremyphoward 3/3 I think it is more productive to train and tune the 1 model you care about, evaluate it on validation set(s) along the way, and when you are done evaluate it on multiple test sets instead of cross-validation."
8267,@rasbt,2021-05-12 21:47:30+00:00,https://twitter.com/rasbt/status/1392597324455632905,"@JFPuget @jeremyphoward 2/3 Given the nature of DL models, in addition to being computationally expensive, I don't see how it is useful to evaluate multiple models to get a performance estimate and then train a final model again on the whole training set."
8268,@rasbt,2021-05-12 21:46:51+00:00,https://twitter.com/rasbt/status/1392597161037152256,"@JFPuget @jeremyphoward In the deep learning context, I actually agree with @jeremyphoward 's answer re cross-validation. I recommend using multiple validation sets and test sets, but I don't necessarily see how cross-validation is useful 1/3"
8269,@rasbt,2021-05-12 19:08:20+00:00,https://twitter.com/rasbt/status/1392557270412709891,"@roydanroy Nowadays, the best way to get in is to accept an invitation as a speaker"
8270,@rasbt,2021-05-12 19:04:08+00:00,https://twitter.com/rasbt/status/1392556214677086215,"@jeremyphoward Intriguing answers :). I feel like it is all in the ""it depends"" realm. Like are we talking about traditional ML on small structured datasets or DL on large, unstructured, unlabeled+labeled data etc. One-hot encoding for features vs labels, etc."
8271,@rasbt,2021-05-12 18:35:48+00:00,https://twitter.com/rasbt/status/1392549083328483335,"@burkov Sounds intriguing; I am curious, do they have a new BERT model in the pipeline or did they switch over to GPT-v3 üôÉ"
8272,@rasbt,2021-05-10 22:25:29+00:00,https://twitter.com/rasbt/status/1391882109673955333,@Thalesdisciple @katemath Experience
8273,@rasbt,2021-05-10 20:16:43+00:00,https://twitter.com/rasbt/status/1391849706322632709,"@tallinzen @zehavoc So, when I understand correctly, ""performances"" is correct if you refer to the comparison of computational and predictive performance[s], but it is incorrect when referring to the comparison of the predictive performance of two models?"
8274,@rasbt,2021-05-10 20:11:51+00:00,https://twitter.com/rasbt/status/1391848480101093382,@tallinzen üî•üî•üî•
8275,@rasbt,2021-05-10 20:08:59+00:00,https://twitter.com/rasbt/status/1391847758177488906,"@tallinzen and ""maths"" üò¨"
8276,@rasbt,2021-05-10 19:52:18+00:00,https://twitter.com/rasbt/status/1391843557955280898,"@ylecun hm, next, it would be nice if someone could also look into this wrt vision transformers :)"
8277,@rasbt,2021-05-10 17:39:32+00:00,https://twitter.com/rasbt/status/1391810149984129024,"@jmschreiber91 @seanmylaw Hah. There are nice examples though where it is not super confusing to have an extra dimension, like @alfcnz et al.'s https://t.co/EBIs58q5kd"
8278,@rasbt,2021-05-10 17:34:55+00:00,https://twitter.com/rasbt/status/1391808984512925701,"@jmschreiber91 @seanmylaw This! Depending on what you want to show, I (sometimes) like using the scatterpoint diameter as a way to add information in an additional dimension. I think that's called Bubble Chart."
8279,@rasbt,2021-05-10 14:30:15+00:00,https://twitter.com/rasbt/status/1391762514896211968,"@HamelHusain @driscollis Yeah, back in the day I found both were having a similar feature set. I think Jekyll used to be more popular than Hugo, which is why I went with the former. For collaborative work or Python coding-related content, the things you list above could make Hugo more appealing"
8280,@rasbt,2021-05-10 13:26:31+00:00,https://twitter.com/rasbt/status/1391746472308248576,"@driscollis Has been a while since I thought about it, but I‚Äôd still go with Jekyll. Easy to use and lots of tutorials, info, and help available on the web."
8281,@rasbt,2021-05-10 00:42:52+00:00,https://twitter.com/rasbt/status/1391554295066148868,"@zakaria_DataSci Thanks for the note. Yeah, due to problems like this in the past I placed local copies next to the notebooks https://t.co/j5k5CluXgu"
8282,@rasbt,2021-05-09 20:05:25+00:00,https://twitter.com/rasbt/status/1391484471048871942,@hardmaru @ylecun @PyTorch Totally agree. Talked about this paper in my stuff-in-the-news videos couple of months ago and thought expressing this method via a short pseudo-pytorch code snippet was super cool https://t.co/Wag3BZF02k
8283,@rasbt,2021-05-08 18:33:56+00:00,https://twitter.com/rasbt/status/1391099064025075715,@burkov The answer is probably energy-based models
8284,@rasbt,2021-05-08 14:22:13+00:00,https://twitter.com/rasbt/status/1391035714473766915,@zacharylipton Ok boomer
8285,@rasbt,2021-05-07 19:50:31+00:00,https://twitter.com/rasbt/status/1390755947249819655,"@jeremyphoward Thanks a lot for sharing! Really interesting to learn about the cultural differences in these two industry &amp; start-up worlds. Shaping that rough diamond sounds like a big adventure. Good luck! Lastly, the planned full-stack start-up creation course is super exciting news!"
8286,@rasbt,2021-05-07 19:08:16+00:00,https://twitter.com/rasbt/status/1390745315029004288,"@DynamicWebPaige I am not familiar with the details and may be wrong here, but didn't the recent AlphaFold model employ transformer modules and is end-to-end differentiable? I.e., no reinforcement learning?"
8287,@rasbt,2021-05-07 16:53:22+00:00,https://twitter.com/rasbt/status/1390711364335947779,"@peteskomoroch @JeffBargmann 2/2 Tangent: Sure, it's comparing apples with oranges, but in Germany, I don't think calculus was part of the admission, and once enrolled, universities offered free prep courses to take in summer. I feel like this system wasn't so bad."
8288,@rasbt,2021-05-07 16:52:47+00:00,https://twitter.com/rasbt/status/1390711219758280711,"@peteskomoroch @JeffBargmann Devil's advocate: not everyone is interested studying STEM in college, and stats and data science will also be useful for future journalists etc. 1/2"
8289,@rasbt,2021-05-07 14:11:49+00:00,https://twitter.com/rasbt/status/1390670712671817740,"@AlexGDimakis @zacharylipton Yeah, agreed, it's a bimodal distribution."
8290,@rasbt,2021-05-07 14:04:49+00:00,https://twitter.com/rasbt/status/1390668950858616836,"@yoavgo Reproducibility checklist: ""Computing confidence intervals is somewhat compute-intensive as it requires running experiments multiple times. This might impose a negative impact on the carbon footprint. Reporting the acc. from a single test set might help alleviate the concerns."""
8291,@rasbt,2021-05-07 02:30:57+00:00,https://twitter.com/rasbt/status/1390494330067034112,@iamtrask AI can interpolate between database records
8292,@rasbt,2021-05-07 01:02:45+00:00,https://twitter.com/rasbt/status/1390472137375371269,"@hugobowne Coincidentally, this was discussed here the other day: https://t.co/uRX3hGiJbJ. Most upvoted answer: ""In my experience, these sorts of attacks are mostly academic and the methods break down quickly when you get to real world settings."""
8293,@rasbt,2021-05-07 00:43:19+00:00,https://twitter.com/rasbt/status/1390467245290270725,@talyarkoni @JoshuaGrubbsPhD i'd take doggycoin if I were you. Could be worth twice as much tomorrow (... or not)
8294,@rasbt,2021-05-07 00:36:51+00:00,https://twitter.com/rasbt/status/1390465619515039747,"""A Panda? No, It's a Sloth."" TIL that there is a type of adversarial attack targeting the energy efficiency of DNNs. Fascinating. I.e. adding noise to a deep neural net could increase energy consumption of e.g. VGG by up to 79%. https://t.co/qcEZdgR8d4 &amp;  https://t.co/zZghDycxuF"
8295,@rasbt,2021-05-06 21:18:58+00:00,https://twitter.com/rasbt/status/1390415816592695298,"@kimalderman Yeah, it's a bummer that it has to be one or the other. My guess it's a ""the day has only so many hours / the semester only has so many days"" kind of issue. But yeah, it would be great if there was greater flexibility wrt electives or so."
8296,@rasbt,2021-05-06 17:55:05+00:00,https://twitter.com/rasbt/status/1390364509466943488,"@peteskomoroch Agree, this is bad. Not sure what the solution is. It feels that‚Äôs stats and data science are ever so important to navigating everyday life and even already indispensable for just keeping up with the news. Would be great to add it to the curriculum somehow without a big cost"
8297,@rasbt,2021-05-06 17:36:25+00:00,https://twitter.com/rasbt/status/1390359812114898956,"@_anantmital Agree. On the other hand, how can someone stay informed about important topics in the world, from COVID, to misinformation, to elections."
8298,@rasbt,2021-05-06 17:33:57+00:00,https://twitter.com/rasbt/status/1390359190917558282,"@jmschreiber91 @Adrowitzer Yeah, the bummer is that they have to pick one over the other since both are important and useful. But yeah stats and data science has already become so essential for just keeping up with the news and just navigating everyday life."
8299,@rasbt,2021-05-06 17:15:04+00:00,https://twitter.com/rasbt/status/1390354441132515337,@allensirolly I honestly can‚Äôt recall if we had stats in school. What I can recall though is that I thought the same about programming ‚Ä¶ ‚Äúbubble sort? Why do I need this? that‚Äôs not how video games work‚Äù
8300,@rasbt,2021-05-06 17:11:28+00:00,https://twitter.com/rasbt/status/1390353535011860484,@peteskomoroch I see. Yeah that might turn out problematic for some. Still I think stats and data science will be more useful to most. I have to admit that I have no idea how the US school system works but it seems that offering calculus classes for those who are interested might be good
8301,@rasbt,2021-05-06 17:05:53+00:00,https://twitter.com/rasbt/status/1390352127890010114,@Adrowitzer They teach neural nets and SVMs in Highschool these days?! üò≥
8302,@rasbt,2021-05-06 17:04:10+00:00,https://twitter.com/rasbt/status/1390351695163633666,"2/2 and maybe students will get interested in calculus naturally once they get into data science competitions and are trying to improve their predictive models, and want to understand how XGboost etc work"
8303,@rasbt,2021-05-06 17:02:03+00:00,https://twitter.com/rasbt/status/1390351163782991878,"Sure, calculus is important, too, but probably more later in life. Personally, I paid zero attention to calculus in school because it was just so boring and I couldn‚Äôt see why it‚Äôs useful. I think with data science, it‚Äôs easier to keep students engaged. 1/2"
8304,@rasbt,2021-05-06 16:58:48+00:00,https://twitter.com/rasbt/status/1390350343746301957,"Probably unpopular opinion, but I think it‚Äôs great. Basic stats and data science is probably more broadly relevant than calculus these days. Plus it sounds refreshing, and if done well, it will make school much more fun and help with data literacy :)"
8305,@rasbt,2021-05-05 16:48:27+00:00,https://twitter.com/rasbt/status/1389985354275565574,@zacharylipton Let me also go on the contrary here: I think the writing is mostly really good. Actually too good. The research behind the writing is usually what's a bit thin. Good writing makes many these things fly
8306,@rasbt,2021-05-05 13:39:35+00:00,https://twitter.com/rasbt/status/1389937822283538433,@unsorsodicorda @yoavgo Saw it in the announcements yesterday but haven‚Äôt had a chance to read it yet. Looking forward to find out how they made MLPs work so well for CV
8307,@rasbt,2021-05-05 04:16:30+00:00,https://twitter.com/rasbt/status/1389796119891296256,@roydanroy Could also be that the target audience of most ML confs is just too vague. It‚Äôs big mish mash of topics. And I don‚Äôt mean this only in the ML topic sense but things like advertising the latest model that could be useful in the next software product vs sth. invariance theorems
8308,@rasbt,2021-05-04 23:57:48+00:00,https://twitter.com/rasbt/status/1389731012859633666,@roydanroy The Stephen King-type of papers
8309,@rasbt,2021-05-04 23:29:15+00:00,https://twitter.com/rasbt/status/1389723830088839173,"@karpathy Also every day last month in the left column (""What's News"" column): 
print(f""{random.choice(index_fund_set)} to close at record""). 
Ok, maybe except today &amp; tomorrow üò¨"
8310,@rasbt,2021-05-04 22:28:03+00:00,https://twitter.com/rasbt/status/1389708428155699205,@RichmanRonald @yoavgo And it's more than a nightmare to implement. Not to speak of (pre-)training it from scratch (in case you are interested in working with something that is not an English NLP model)
8311,@rasbt,2021-05-04 22:15:48+00:00,https://twitter.com/rasbt/status/1389705347317735424,"@unsorsodicorda @yoavgo Yeah, time will tell. At least when it comes to classification performance &amp; efficiency, CNNs come out ahead for the time being. DINO does look like an impressive effort though. https://t.co/eg4EF1rj1Z"
8312,@rasbt,2021-05-04 18:34:51+00:00,https://twitter.com/rasbt/status/1389649742058213377,"@yoavgo This. Just spent the last week reading through recent transformer literature for putting together the last lecture for this semester, and it feels like I am acquiring a new set of hacking skills. Kind of a bummer that they work so well and may also overtake computer vision :P"
8313,@rasbt,2021-05-04 13:30:49+00:00,https://twitter.com/rasbt/status/1389573227723300868,@tunguz üî•üî•üî•
8314,@rasbt,2021-05-04 00:39:29+00:00,https://twitter.com/rasbt/status/1389379117439758339,"Great stuff! This looks like a really valuable companion for a Deep Learning course. I found that building custom data loaders, and saving &amp; loading models is one of the major friction points for students. Great to have additional supporting material and examples for this."
8315,@rasbt,2021-05-03 14:10:07+00:00,https://twitter.com/rasbt/status/1389220730034921472,@compbiologist @NSF Congrats!
8316,@rasbt,2021-05-03 13:46:18+00:00,https://twitter.com/rasbt/status/1389214738547097601,@ylecun @tdietterich @murtazamoin @RichardSocher @Google I agree with it being better than search engines prior to it. But it would be more interesting to compare it to other contemporary search engines. I have been using Bing on mobile for a few years and it seems pretty decent
8317,@rasbt,2021-05-03 13:39:28+00:00,https://twitter.com/rasbt/status/1389213019192844288,"@suzatweet That sounds really fun, looking forward to it!"
8318,@rasbt,2021-05-01 20:03:05+00:00,https://twitter.com/rasbt/status/1388584782821564419,"@ido87 @shoyer @KyleCranmer just want to highlight though that I think the decoupling is good, but the current state of journal publications in other fields are of course not without flaw. So the system shouldn't be adopted 1-to-1 of course"
8319,@rasbt,2021-05-01 20:02:09+00:00,https://twitter.com/rasbt/status/1388584547969818625,"@ido87 @shoyer @KyleCranmer Yes, that's right! Coming from comp bio, this is how this (and other) fields work. I remember that the ML conference-publication was praised in other fields &amp; was something to strive for, but now it seems that decoupling publication and communication doesn't seem so bad after all"
8320,@rasbt,2021-05-01 17:09:55+00:00,https://twitter.com/rasbt/status/1388541204221120514,"@pbloemesquire @KyleCranmer Yes. In general, was trying to say that there could be value in a professional service organizing and facilitating paper writing and publishing rather than having researchers have to spend research time for conference management but yeah in its current state that's not the case"
8321,@rasbt,2021-05-01 16:56:04+00:00,https://twitter.com/rasbt/status/1388537718439825414,"@pbloemesquire @KyleCranmer 2/2 of course one doesn't need publishers for that, but sometimes you might want an expert helping with the process, like when you sometimes consider paying a financial advisor, real-estate agent, tax-preparer etc. for a service instead of doing all of it all by yourself"
8322,@rasbt,2021-05-01 16:54:10+00:00,https://twitter.com/rasbt/status/1388537240901521409,"@pbloemesquire @KyleCranmer I agree with the criticism against publishers, but I can also see them being useful &amp; relevant with a few tweaks: for a reasonable fee, provide feedback and help with editing, organize format guidelines, organize reviewers, hosting, organize conferences &amp; events etc.  1/2"
8323,@rasbt,2021-05-01 16:48:03+00:00,https://twitter.com/rasbt/status/1388535702200139779,"@pbloemesquire @KyleCranmer That's a very thoughtful thread. Yeah, and impact is already automatically evaluated by the community via an existing incentive system (i.e., citations)"
8324,@rasbt,2021-05-01 16:26:16+00:00,https://twitter.com/rasbt/status/1388530217744994307,"@KyleCranmer Yeah, I like that idea. Works could be chosen by a mix of editor-based choices and community-voting among attendees"
8325,@rasbt,2021-05-01 15:55:45+00:00,https://twitter.com/rasbt/status/1388522539840901120,"@KyleCranmer 2/2 I dunno, maybe holding the conference multiple times a year (e.g., starting with Winter / Summer editions) to spread out submissions more &amp; help with reviewer bottlenecks? Or perhaps splitting by subarea? Or both?"
8326,@rasbt,2021-05-01 15:53:59+00:00,https://twitter.com/rasbt/status/1388522095508869120,"@KyleCranmer Yes, totally share this view. For the last few years, I have been helping out as a reviewer for the three big conferences, and submitting to these conferences seems like a frustrating, sometimes perhaps even soul-crushing experience. What are some ideas to fix/improve this? 1/2"
8327,@rasbt,2021-04-29 19:23:52+00:00,https://twitter.com/rasbt/status/1387850137041506308,@HenryWolfAI @__mharrison__ The Apple Bluetooth keyboard
8328,@rasbt,2021-04-29 17:56:50+00:00,https://twitter.com/rasbt/status/1387828235266928642,"@__mharrison__ Only the typing sound, not the vibration, but very very subtle like mouse clicks"
8329,@rasbt,2021-04-29 15:22:42+00:00,https://twitter.com/rasbt/status/1387789445114568709,"@iamtrask You might be interested in books by Ursula LeGuin. Like The Left Hand of Darkness or The Dispossessed. Especially the latter aged very well, and even though it's been written like 50 years ago it feels like something one would write today."
8330,@rasbt,2021-04-29 14:14:52+00:00,https://twitter.com/rasbt/status/1387772376667103232,"@hardmaru Nice list. If there is one more to add: ""Working in my field is not as much fun as it used to be so let me write a critique"""
8331,@rasbt,2021-04-29 01:41:24+00:00,https://twitter.com/rasbt/status/1387582759502286851,"@burkov Worse than Amazon? I mean it sounds like at least they have a customer service that responds :P. But joking aside, sorry to hear, this sounds frustrating. With counterfeit, you mean someone e.g., prints copies based on the eBook version?"
8332,@rasbt,2021-04-28 00:08:56+00:00,https://twitter.com/rasbt/status/1387197101243834375,"Continuing the talk about data quality &amp; model performance: Just helping a student debug a class project &amp; found a great little tool for fixing image-size-&amp;-crop related issues manually but quickly. Open source, installs via pip, and works on macOS, too:  https://t.co/K4fYDNHXTx https://t.co/8VAgSBkveT"
8333,@rasbt,2021-04-27 21:13:36+00:00,https://twitter.com/rasbt/status/1387152975857074180,"@rjurney 3/3 You can give it a try e.g., by cloning this project, cd'ing into the docs folder, and running make_api.py: https://t.co/PQAkgvfcou. It will create the following folder structure, and the extracted docstrings in markdown look as follows: https://t.co/Wy1FbrCPD4"
8334,@rasbt,2021-04-27 21:13:12+00:00,https://twitter.com/rasbt/status/1387152878394093568,"@rjurney 2/3 Since I am not a reStructuredText person, I wrote my own to convert docstrings to markdown (not perfect though). E.g. the docs of mlxtend, biopandas etc are build using it."
8335,@rasbt,2021-04-27 21:13:03+00:00,https://twitter.com/rasbt/status/1387152838476935169,"@rjurney You mean for extracting info from docstrings for the documentation? Yeah, there is Sphinx-autodoc: https://t.co/WJkKTnHzwu. 1/3"
8336,@rasbt,2021-04-26 19:06:07+00:00,https://twitter.com/rasbt/status/1386758507538624516,@randal_olson @IAmAru @SciPyConf Same. Also with online seminars. And I really really tried.
8337,@rasbt,2021-04-26 16:07:32+00:00,https://twitter.com/rasbt/status/1386713565105692676,"@savage_saini The library seems to be compatible with visual transformers, yes"
8338,@rasbt,2021-04-26 15:18:12+00:00,https://twitter.com/rasbt/status/1386701149131223040,@zacharylipton @Wikipedia This. Lots of exciting things to catch up with. Can't wait for more commuting again.
8339,@rasbt,2021-04-26 14:54:07+00:00,https://twitter.com/rasbt/status/1386695089498595331,@DrewFustin Data cascades here we go
8340,@rasbt,2021-04-26 14:48:41+00:00,https://twitter.com/rasbt/status/1386693723552092160,"Nice open source project on different class activation map (CAM) methods for CNNs. When developing CNNs in PyTorch, this seems user-friendly enough to make it part of the standard diagnostic pipeline (next to loss plots and confusion matrices). https://t.co/4ppAPlPdwV https://t.co/voBH9Xu4YS"
8341,@rasbt,2021-04-26 13:43:14+00:00,https://twitter.com/rasbt/status/1386677249269805056,"@dimadamen Coming from Europe, found it ""wrong"" at first. But got used to it over the years and now really appreciate it as a reviewer &amp; reader:  keeps things more manageable. Also, as author I see the appeal since it lowers the barrier to writing &amp; editing, + easier to collect feedback"
8342,@rasbt,2021-04-25 16:12:55+00:00,https://twitter.com/rasbt/status/1386352532558172160,"@dehati_aadmi Not yet, it will probably be a couple of weeks until it will become available online"
8343,@rasbt,2021-04-23 14:30:58+00:00,https://twitter.com/rasbt/status/1385602100755943426,"@denfromufa Not yet, but the thesis will be uploaded at some point :)"
8344,@rasbt,2021-04-23 00:43:54+00:00,https://twitter.com/rasbt/status/1385393961997590531,"Zhongjie was my first grad student, and it makes me realize how fast time went by!! It is already almost 3 years since I joined @UWMadisonSTATS  :)"
8345,@rasbt,2021-04-23 00:43:54+00:00,https://twitter.com/rasbt/status/1385393961163010053,"Exciting day: Zhongjie Yu just passed his Ph.D. defense today (Topic: ""Few-Shot Learning: Contributions to Deep Learning With Limited Data""). Congratulations to Dr. Zhongjie Yu for a successful defense! Really proud of him!ü•≥"
8346,@rasbt,2021-04-22 14:22:21+00:00,https://twitter.com/rasbt/status/1385237541931175941,"@sameervk10 For performance metrics, you could construct confidence interval, e.g., via binomial approximation or bootstrapping. For individual predictions, I think this is still an open research problem. I have seen people using dropout for this but I don't know what the best practice is."
8347,@rasbt,2021-04-22 00:56:41+00:00,https://twitter.com/rasbt/status/1385034788940177414,"@iamtrask @biobenkj Yes, indeed. Was hard to motivate the VAE example after that üòÖ"
8348,@rasbt,2021-04-22 00:55:54+00:00,https://twitter.com/rasbt/status/1385034595305984003,"@biobenkj @iamtrask It actually is, using it for all my lecture vids because it is much less flaky than the Canvas video player. The particular video the images are from was a coding video: https://t.co/Z40T7XHeWM"
8349,@rasbt,2021-04-22 00:39:53+00:00,https://twitter.com/rasbt/status/1385030563657027584,@iamtrask @biobenkj 3/3 Same now in latent space: https://t.co/r6lM99cYGo
8350,@rasbt,2021-04-22 00:39:00+00:00,https://twitter.com/rasbt/status/1385030342214660097,@iamtrask @biobenkj 2/3 Left column is the original. Top row is adding the average image of smiling persons -- results look quite reasonable imho. Bottom row is subtracting the average image of smiling persons. https://t.co/IFVbEVrXga
8351,@rasbt,2021-04-22 00:37:31+00:00,https://twitter.com/rasbt/status/1385029966891474951,"@iamtrask @biobenkj Coincidentally was just teaching a class on VAEs the other day where we did some latent space arithmetic with image data. Similar to what you said above, you can also manipulate images in the original space to some extend without having it look completely nonsensical 1/2"
8352,@rasbt,2021-04-22 00:12:47+00:00,https://twitter.com/rasbt/status/1385023743416745984,"@biobenkj Ask them if they know principal component analysis. If yes, say it is essentially a non-linear version of that using deep neural networks (just assuming this is in a DNN context here üòÖ)"
8353,@rasbt,2021-04-17 19:58:36+00:00,https://twitter.com/rasbt/status/1383510222682017795,@goldstein_aa @wirtzdan probably because they are really good movies :P
8354,@rasbt,2021-04-17 19:56:17+00:00,https://twitter.com/rasbt/status/1383509639375904772,"@wirtzdan Only watched 4 movies in 2021, coincidentally, those two were among them. Great movies &amp; great acting. Watched Another Round first and then found The Hunt. The latter is a great movie but very disturbing at the same time -- not sure I can recommend it"
8355,@rasbt,2021-04-17 19:10:22+00:00,https://twitter.com/rasbt/status/1383498085339254789,@ArtificialGene2 Or myabe the models are so samrt taht they are able to udesnntard you dtesipe suffhling
8356,@rasbt,2021-04-17 19:05:40+00:00,https://twitter.com/rasbt/status/1383496904433037312,"@akanshajainn @ceobillionaire So technically the following two could look the same to the model if the natural order is not used:
The movie my friend has not seen is good
The movie my friend has seen is not good"
8357,@rasbt,2021-04-17 19:03:10+00:00,https://twitter.com/rasbt/status/1383496274750570502,"@akanshajainn @ceobillionaire Yeah, for the original sentences. But if they are used with the shuffled sentences, then they are not preserving the original (unshuffled) order but some random/unnatural order. So this may indicate that the original order really doesn't matter as much"
8358,@rasbt,2021-04-17 17:12:21+00:00,https://twitter.com/rasbt/status/1383468384294084609,@eggie5 ü§ó
8359,@rasbt,2021-04-17 17:05:58+00:00,https://twitter.com/rasbt/status/1383466780983578625,@Read_The_Dung Language models like BERT etc. that use self-supervised learning methods involving masking words and predicting those https://t.co/Nct5v3MSaW
8360,@rasbt,2021-04-17 15:36:28+00:00,https://twitter.com/rasbt/status/1383444255536914443,"@zacharylipton @Miles_Brundage @hardmaru Based on personal experience, the latter is definitely a thing. I've asked/invited people to write about certain methods who then talked to their employee, and they responded that it wasn't in the best interest of the company to publish formally due to the time commitment."
8361,@rasbt,2021-04-17 15:33:36+00:00,https://twitter.com/rasbt/status/1383443533231624203,"@zacharylipton @Miles_Brundage @hardmaru I'd say it's not the ""doing research"" but ""publishing"" part that is surprising &amp; interesting. For many companies, traditionally keeping trade secrets &gt; visibility from publishing. Also, can be tricky to justify the ""why did you spend 40+ hours writing about this"" time commitment."
8362,@rasbt,2021-04-16 21:18:15+00:00,https://twitter.com/rasbt/status/1383167881765064705,"@zacharylipton Never heard of this term except that I get my eggs from the Yuppie Hill Poultry Farm (Burlington, WI), and they are amazing"
8363,@rasbt,2021-04-16 14:05:38+00:00,https://twitter.com/rasbt/status/1383059009620602882,"@waynemystir @seanjtaylor Probably a mix of the two reasons you mentioned above. I have seen successful applications of RL for related problems. I may be too inexperienced in RL to use it effectively. Overall, I found it is frustrating and I don't enjoy working on/with RL"
8364,@rasbt,2021-04-16 00:50:13+00:00,https://twitter.com/rasbt/status/1382858836760006658,"@waynemystir @seanjtaylor Yes, every time I tried and wanted to use RL for something serious (in my case molecule work), I found it too frustrating and gave up after a few days/weeks"
8365,@rasbt,2021-04-16 00:48:43+00:00,https://twitter.com/rasbt/status/1382858458668666882,"--&gt; "" we demonstrated that standard optimizers, without any layer-wise normalization techniques, can match or exceed the large batch size results used to justify LARS and LAMB. Our results did not require specialized ‚Äúlarge batch optimizers‚Äù or any new techniques whatsoever"""
8366,@rasbt,2021-04-16 00:48:13+00:00,https://twitter.com/rasbt/status/1382858334399819779,"Glad that  I am not missing out on anything interesting when I still stubbornly default to ADAM: ""A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes"" (https://t.co/P7DsR48hYZ) https://t.co/A1Xm10rsoy"
8367,@rasbt,2021-04-16 00:35:59+00:00,https://twitter.com/rasbt/status/1382855254983725063,@seanjtaylor Basically everything that involved reinforcement learning
8368,@rasbt,2021-04-15 14:46:02+00:00,https://twitter.com/rasbt/status/1382706790601736193,@alfcnz @ykilcher And I always thought neural network implementations in LISP look super complicated üòÇ
8369,@rasbt,2021-04-15 02:24:19+00:00,https://twitter.com/rasbt/status/1382520129867616258,"@LeapingLlamas yes, totally agree."
8370,@rasbt,2021-04-15 01:45:51+00:00,https://twitter.com/rasbt/status/1382510448302514183,@LeapingLlamas I think you refer to the fact that it's overselling the idea behind the problem? I agree. I think this paper is more meant as an internal whitepaper highlighting issues. I just liked the title :)
8371,@rasbt,2021-04-15 01:44:46+00:00,https://twitter.com/rasbt/status/1382510175018491907,"@LeapingLlamas 2/2 But if someone decides to use that for ML later, it can lead to nasty-&amp;-hard-to-detect cases of overfitting"
8372,@rasbt,2021-04-15 01:44:32+00:00,https://twitter.com/rasbt/status/1382510118382804992,"@LeapingLlamas Yeah, I think such problems can particularly easily arise if ML model engineers are not involved in the collection. Like a little spec of dust in the lower-left corner probably doesn't mean much to someone taking pictures of construction sites. 1/2"
8373,@rasbt,2021-04-15 00:28:55+00:00,https://twitter.com/rasbt/status/1382491088112467972,@hardmaru @nvidia More or fewer spatulas than last year? :) https://t.co/IARjjcRCLo
8374,@rasbt,2021-04-15 00:25:26+00:00,https://twitter.com/rasbt/status/1382490211276427264,"Data Cascades‚Äîcompounding events causing negative, downstream effects from data issues‚Äîtriggered by conventional AI/ML practices that undervalue data quality: https://t.co/tanHE5bEeW"
8375,@rasbt,2021-04-15 00:22:55+00:00,https://twitter.com/rasbt/status/1382489579194880001,"Recently, there's been more and more talk about data-centric vs model centric approaches. Interesting paper highlighting the issue in practice --&gt; ' ‚ÄúEveryone wants to do the model work, not the data work‚Äù: Data Cascades in High-Stakes AI ' https://t.co/tpAO2qHVDH"
8376,@rasbt,2021-04-15 00:19:45+00:00,https://twitter.com/rasbt/status/1382488783187238915,It's gonna be a big year for somewhat-self-driving cars! https://t.co/IIYwtoCJJR
8377,@rasbt,2021-04-14 13:36:20+00:00,https://twitter.com/rasbt/status/1382326859220848641,@adi_myth @seanjtaylor @karpathy @pabbeel @AndrewYNg Yes yes! And I too talked about that @AndrewYNg and @karpathy talked about it :). 2 days before this excellent write-up went live. https://t.co/79c4E6gMJA
8378,@rasbt,2021-04-14 03:42:01+00:00,https://twitter.com/rasbt/status/1382177293695655937,@amuellerml @scikit_learn @sklearn_inria This is amazing!
8379,@rasbt,2021-04-14 00:58:49+00:00,https://twitter.com/rasbt/status/1382136225809756162,"@HamelHusain Trax, Flax, Haiku, ... wow, the number of APIs is growing fast"
8380,@rasbt,2021-04-14 00:51:25+00:00,https://twitter.com/rasbt/status/1382134361844244493,"@mmcquade_ai_u @huggingface @jrhunt Hah, just started listening today and am not there yet :P. But I really appreciate it!"
8381,@rasbt,2021-04-14 00:26:11+00:00,https://twitter.com/rasbt/status/1382128012884344835,"Recently started listening to podcasts again and just discovered this new machine learning podcast by @mmcquade_ai_u -- AI &amp; U. First episode is a conversation about NLP &amp; Transformers, with Joe Davidson from @huggingface. Awesome stuff! https://t.co/wxWaR0OLPw"
8382,@rasbt,2021-04-14 00:19:43+00:00,https://twitter.com/rasbt/status/1382126384672301056,"@powerpig @seanjtaylor @karpathy @pabbeel that goes under ""traditional methods"" :P"
8383,@rasbt,2021-04-13 21:13:49+00:00,https://twitter.com/rasbt/status/1382079603632713734,"@seanjtaylor @karpathy Oh yes. They really stood the test of time so far for the ""Model-Centric Approach""! 
Looking forward to see @karpathy's recipe for the ""Data-Centric Approach"" he talked about in the recent podcast episode with @pabbeel :)"
8384,@rasbt,2021-04-13 00:24:55+00:00,https://twitter.com/rasbt/status/1381765303932178432,"Arg, thanks.
Was just checking all my projects. Phew, guess I am lucky that I always used minimalist Dataset classes. But that sounds annoying, indeed.
Maybe not a bug, but surely a big coding ""gotcha""."
8385,@rasbt,2021-04-07 02:21:34+00:00,https://twitter.com/rasbt/status/1379620336560451584,@AndrewYNg @Analyticsindiam Great! Remember you discussing this in previous talks/newsletters &amp; was mentioning this paradigm shift in two talks this week‚Äîcrediting you as the source of course :). Nice to have this write-up/reference next time for people who are interested in more detailed follow-up info :)
8386,@rasbt,2021-04-07 00:55:52+00:00,https://twitter.com/rasbt/status/1379598767704395778,"@chrisalbon Hah, yeah! Instead of (a) doing conv arithmetic or (b) implementing a forward hook, I just recommend good olde print statements in class today, for finding out the output size of all-conv net block in PyTorch. Because we can, and because it works :) https://t.co/9nI06XQoxG"
8387,@rasbt,2021-04-06 18:47:06+00:00,https://twitter.com/rasbt/status/1379505962151768064,"@alexrives Big congrats! Read the biorxiv version recently, and that‚Äôs a great piece of work! Glad to see that it‚Äôs now officially published :)"
8388,@rasbt,2021-04-06 12:47:34+00:00,https://twitter.com/rasbt/status/1379415485280817155,"@fulhack All 4, where the 4th is editing .py files on a host directly. Approximately same proportions but it varies by project. Local Jupyter Nb for simpler analyses and teaching, and on the host for deep learning. .py files for most research projects and writing supporting code for Nbs"
8389,@rasbt,2021-04-05 15:45:44+00:00,https://twitter.com/rasbt/status/1379097932624973825,"@srchvrs wouldn't it be fun if we adopted tech jargon and used ""disrupting"""
8390,@rasbt,2021-04-05 01:49:38+00:00,https://twitter.com/rasbt/status/1378887523678760962,@nelslindahl Thanks for the feedback and kind words!
8391,@rasbt,2021-04-05 01:45:41+00:00,https://twitter.com/rasbt/status/1378886529834233858,"@_brohrer_ Or: 
How satisfied is the user? -Ordinal regression"
8392,@rasbt,2021-04-05 01:44:02+00:00,https://twitter.com/rasbt/status/1378886111884419076,"@_brohrer_ Good list! Maybe:
Is this suspicious behavior? -Anomaly detection"
8393,@rasbt,2021-04-03 18:39:48+00:00,https://twitter.com/rasbt/status/1378416962766770180,"Deep Learning News #10 (April 3rd). This week discussing a paper evaluating 7 methods for mitigating bias in deep learning models + a new dataset for assessment: Bias MNIST. Also, a refreshing break from visual transformers: discussing EfficientNet-V2. https://t.co/yW2dpmYjQR"
8394,@rasbt,2021-04-01 14:59:08+00:00,https://twitter.com/rasbt/status/1377636654354198529,"@alfcnz @BhagwatBond Not a course, but Practical Statistics for Data Scientists by Bruce &amp; Bruce is a nice and concise book"
8395,@rasbt,2021-04-01 14:42:05+00:00,https://twitter.com/rasbt/status/1377632363413397510,"Excited to share our latest work on causal representation learning. Our CAR net paper just got accepted and just submitted a preprint to arxivü•≥. If you can't wait, just uploaded a version here: https://t.co/R6QPgvUQTW https://t.co/Q1TmnSJYcN"
8396,@rasbt,2021-03-31 19:57:55+00:00,https://twitter.com/rasbt/status/1377349460120981505,@elizabeth_dlha @odsc Thanks! Glad to hear you liked in and that there was something informative in there :)
8397,@rasbt,2021-03-31 19:19:57+00:00,https://twitter.com/rasbt/status/1377339905576083456,https://t.co/UVdGlBHK1c
8398,@rasbt,2021-03-31 12:48:08+00:00,https://twitter.com/rasbt/status/1377241301213720576,"@NicoloMarchesi @alfcnz Same. Also, multiple tabs. What also helps me sometimes is making a copy of the code files and trimming them to the essentials. Like only keeping function names with input and output descriptions"
8399,@rasbt,2021-03-30 21:21:10+00:00,https://twitter.com/rasbt/status/1377008021512019972,"And yes, thanks to that name I also totally took a glance at my calendar to double check whether it‚Äôs April 1st yet"
8400,@rasbt,2021-03-30 21:10:46+00:00,https://twitter.com/rasbt/status/1377005402810937345,"I remember sharing ‚Äúanother week, another optimizer‚Äù tweets last year. After a few quiet weeks, here we go again :). Btw. this looks like a really good one! Worth checking out in more detail"
8401,@rasbt,2021-03-29 01:43:07+00:00,https://twitter.com/rasbt/status/1376349165647769604,"@SketcherRami @roydanroy @burkov Yes, agree. The decoupling from the batch size is what I had in mind with making learning rate tuning easier"
8402,@rasbt,2021-03-29 00:52:53+00:00,https://twitter.com/rasbt/status/1376336525466726409,"@PrasoonPratham But overall, I agree with you, it's essentially an appl. of the chain rule :). Personally, I like that you can draw it as a computation graph and work through it in a divide-and-conquer approach. One step at a time. I must say though that I don't blame people if they find it hard"
8403,@rasbt,2021-03-29 00:49:03+00:00,https://twitter.com/rasbt/status/1376335559711457282,"@PrasoonPratham And again, this is just softmax (multi-class logistic) regression, the simplest model. Conceptually, MLPs and CNNs are not that different, same basic concepts, but I find that writing down concise vectorized versions is not that easy"
8404,@rasbt,2021-03-29 00:46:44+00:00,https://twitter.com/rasbt/status/1376334976623476736,"@PrasoonPratham 2/2 not so obvious how to arrive at that, and it's just for 1 weight. Then, if you also consider multiple inputs, it takes some hard thinking to arrive at the vectorized version. At least for me. I find matrix calculus still very hard and really need to be well rested for that :P https://t.co/lC9XNNhIYL"
8405,@rasbt,2021-03-29 00:44:37+00:00,https://twitter.com/rasbt/status/1376334445897256961,"@PrasoonPratham the tricky part in ML is that is goes beyond just the regular chain rule for univariate functions. Even for something simple like softmax regression, we have to (1) combine things via the multivariable chain rule and (2) usually have to vectorize that, and matrix calculus is hard"
8406,@rasbt,2021-03-29 00:32:32+00:00,https://twitter.com/rasbt/status/1376331406612250632,"@burkov As someone who uses both as well, yeah, in a class-context usually go ahead and explain that I have them there just for convenience. The 2nd one is really just aesthetics but the first one makes learning rate tuning and thus real-world work more convenient though"
8407,@rasbt,2021-03-28 16:57:57+00:00,https://twitter.com/rasbt/status/1376217005523603457,"@DJCordhose Yeah, stabilizing the learning by bringing the learning rate down once no improvement is being made. https://t.co/jIfvVujo7S_scheduler.ReduceLROnPlateau (https://t.co/NeRGnGnep5)"
8408,@rasbt,2021-03-28 16:20:02+00:00,https://twitter.com/rasbt/status/1376207464354418689,"@zubairahmed_ai Hi there. Sorry, I don't have a ResearchGate account but I have all my papers on my website (I mean the paywalled ones)"
8409,@rasbt,2021-03-28 16:15:31+00:00,https://twitter.com/rasbt/status/1376206325894504451,"@DJCordhose Yeah, I recently found also that I get better results with SGD than Adam, but have to add momentum and a simple scheduler"
8410,@rasbt,2021-03-27 21:52:19+00:00,https://twitter.com/rasbt/status/1375928697262387206,"@roydanroy @CsabaSzepesvari @peter_richtarik or like what some people call and upload as ""technical report."" I.e., giving more formal recognition to these works."
8411,@rasbt,2021-03-27 20:56:12+00:00,https://twitter.com/rasbt/status/1375914572834570240,"Deep Learning News #9 (Mar 27 edition). This week with a simple yet effective self-supervised learning technique for redundancy reduction, a workshop focused on detecting hateful memes, and several tools (annotation, profiling, and model comparison) https://t.co/RBfWkz9eUu"
8412,@rasbt,2021-03-25 22:06:25+00:00,https://twitter.com/rasbt/status/1375207467794231303,"Oh this is great. No kidding, just spent hours yesterday trying to find bottlenecks manually (in my case, I had a couple of wasteful extra iterations over the train &amp; validation set for each performance metric during each epoch)"
8413,@rasbt,2021-03-24 00:54:13+00:00,https://twitter.com/rasbt/status/1374524921947119616,"For reference, the cover of the 1st edition https://t.co/OzAupAfQDz"
8414,@rasbt,2021-03-24 00:53:26+00:00,https://twitter.com/rasbt/status/1374524726861656066,"All good things come in threes! Again, I really enjoy the cover design of the Korean version."
8415,@rasbt,2021-03-24 00:50:06+00:00,https://twitter.com/rasbt/status/1374523886033723392,@MarkusM99098101 Happy birthday! And I hope you'll like the book!
8416,@rasbt,2021-03-22 20:34:50+00:00,https://twitter.com/rasbt/status/1374097259512598533,"@rjurney Yeah, we have something like that back in 2018L https://t.co/ON5vBbgxcG https://t.co/c2XbGChFqo"
8417,@rasbt,2021-03-22 17:00:29+00:00,https://twitter.com/rasbt/status/1374043317323902976,@tymwol Sounds normal to me
8418,@rasbt,2021-03-22 16:58:21+00:00,https://twitter.com/rasbt/status/1374042779446312962,@hardmaru @openreviewnet I.e. OptionallyOpenReview
8419,@rasbt,2021-03-22 14:16:22+00:00,https://twitter.com/rasbt/status/1374002013273477122,"Regarding conference submissions, I think it‚Äôs reasonable to be a bit more forgiving, especially given deadlines and strict page limits. Given that many journals charge submission fees, it might be reasonable to expect technical editors to take care of minor language issues"
8420,@rasbt,2021-03-22 14:11:08+00:00,https://twitter.com/rasbt/status/1374000695741984775,"And based on 6 semesters of conference-pape-style class project grading where everyone uses the same template, I think that a moderate amount of grammar errors doesn't really affect readability and clarity much."
8421,@rasbt,2021-03-22 14:11:07+00:00,https://twitter.com/rasbt/status/1374000694122971142,"Regarding clarity, when reviewing papers, I find that big-picture aspects such as how they divide a paper into sections and augment text with figures matters most."
8422,@rasbt,2021-03-22 01:41:02+00:00,https://twitter.com/rasbt/status/1373811928573825024,"@MDJDPathology @iamtrask Yes, I think hit the nail on the head. Most research was promised to be relevant for clinical use, but it looked like it was done without consulting with an actual domain expert. Or didn't even ask what clinicians even need."
8423,@rasbt,2021-03-22 01:07:22+00:00,https://twitter.com/rasbt/status/1373803454502739973,"@iamtrask There was one well-executed one (as far as I can tell as a non-domain expert wrt COVID-19). I.e,. working with clinicians to predict the severity and potential oxygen requirement from x-ray based diagnosis, which can be useful for resource allocation: https://t.co/IKV2rXCTTG"
8424,@rasbt,2021-03-22 01:05:29+00:00,https://twitter.com/rasbt/status/1373802979988545538,"@iamtrask Oh yeah, totally. Also most didn't even try to think very hard about the application &amp; were mostly about: can we predict COVID-19 from chest x-rays. Not because it was more useful or practical than conventional COVID-19 tests but bcoz chest x-ray datasets were readily available."
8425,@rasbt,2021-03-22 00:39:51+00:00,https://twitter.com/rasbt/status/1373796532684783616,"@iamtrask 3/3 Some were so bad that we had to even reject them from arxiv. I haven't specifically looked at any that passed peer review, but I'd wager that the failure here was not necessarily just due to an immature state of ML/DL but more likely due to poor science"
8426,@rasbt,2021-03-22 00:37:41+00:00,https://twitter.com/rasbt/status/1373795983507779590,"@iamtrask 2/3 they were just opportunistic and wanted to among the first with a COVID-19 related preprint to grab citations. In any case, most of what I've seen was half-baked. Mostly overfitting to the same small dataset. Most often not even basic confidence intervals."
8427,@rasbt,2021-03-22 00:37:32+00:00,https://twitter.com/rasbt/status/1373795945872261122,"@iamtrask Haven't read this meta-paper, yet, but yeah, that's what I expected, unfortunately. As arxiv machine learning moderator, I've seen a bunch of stuff since the pandemic. Not sure if people really just wanted to rush it out to have a positive impact asap, or 1/3"
8428,@rasbt,2021-03-21 23:07:20+00:00,https://twitter.com/rasbt/status/1373773248777883649,@theshawwn Just let it rerun in without momentum (left) and with momentum but without learning rate schedule (right) and in both cases no double descent. Both cases slightly better generalization performance too https://t.co/tP4icOIVuh
8429,@rasbt,2021-03-21 14:59:53+00:00,https://twitter.com/rasbt/status/1373650578115559424,@nelslindahl Thanks for the kind words &amp; sharing!
8430,@rasbt,2021-03-21 14:20:03+00:00,https://twitter.com/rasbt/status/1373640551787028484,"@theshawwn no, I used a scheduler (https://t.co/hbr62rmjA3). I.e., every time the validation accuracy plateaus for a few epochs, the learning rate is divided by 10"
8431,@rasbt,2021-03-20 19:48:02+00:00,https://twitter.com/rasbt/status/1373360706930806789,"@DCasBol yeah, based on the times I used it it either makes no difference or makes things worse"
8432,@rasbt,2021-03-20 18:56:33+00:00,https://twitter.com/rasbt/status/1373347748171419653,"Deep Learning News #8 Mar 20 2021. This week with a math benchmark set probing the capabilities of GPT-3, an interesting approach to data augmentation, and repurposing GANs for semantic part segmentation: https://t.co/aloMHXutYB"
8433,@rasbt,2021-03-20 18:06:18+00:00,https://twitter.com/rasbt/status/1373335102898462724,"@DCasBol Yeah, same! Could be due to using momentum maybe."
8434,@rasbt,2021-03-20 14:36:34+00:00,https://twitter.com/rasbt/status/1373282320623529987,"@SapkotaTsuman usually yes, in the original paper they also talked about the epoch-wise phenomenon too though"
8435,@rasbt,2021-03-20 13:50:24+00:00,https://twitter.com/rasbt/status/1373270702699245570,"Well, this was unexpected. I guess I am not a double-descent skeptic anymore then ...  https://t.co/awGZjC3Mcp https://t.co/fPXzp32KHj"
8436,@rasbt,2021-03-19 00:50:02+00:00,https://twitter.com/rasbt/status/1372711930457157634,Had a great time at the International Summer School of Deep Learning in Poland 2 years ago. It's now back via a virtual format. Am exciting to be part of it with a lecture on generative adversarial nets this summer! They just relased the full schedule here https://t.co/Mx9x5Sl1oD
8437,@rasbt,2021-03-19 00:21:01+00:00,https://twitter.com/rasbt/status/1372704627943215109,@jmschreiber91 @ericmjl @roydanroy Your Naming Strategy is Secretly an Energy Based Method and You Should Treat It Like One
8438,@rasbt,2021-03-19 00:16:07+00:00,https://twitter.com/rasbt/status/1372703396541689860,@ericmjl @roydanroy Good names and where to find them
8439,@rasbt,2021-03-19 00:07:59+00:00,https://twitter.com/rasbt/status/1372701347984912387,@roydanroy The Unreasonable Effectiveness of Naming Your Work
8440,@rasbt,2021-03-18 00:36:53+00:00,https://twitter.com/rasbt/status/1372346234166476810,"@zacharylipton writing reviews is now basically like writing recommendation letters. You put a lot of effort into writing a nice letter, then when you submit you find that it's all about filling out their multiple choice questionnaires and your text is actually just a supplementary attachment"
8441,@rasbt,2021-03-17 22:25:48+00:00,https://twitter.com/rasbt/status/1372313244023586821,@khumie__ Thanks so much for the kind words! That's really really motivating to hear!
8442,@rasbt,2021-03-17 22:24:57+00:00,https://twitter.com/rasbt/status/1372313032269905921,"@Preservelives @sama @ilyasut I think it used to be 6 days / week ~80 years ago or so. But yeah, in the more relevant time-frame (say from the 1980s to today where computers became standard), I don't feel much has changed. On the contrary, people now also engage with work ""after work"" (e.g., answering emails)"
8443,@rasbt,2021-03-17 00:44:30+00:00,https://twitter.com/rasbt/status/1371985760648359938,"@Isinlor @sama @ilyasut Yeah, people spend less of the 40h/week on actual work but on AI-facilitated distractions on the internet (and email) ;). I don't think time that could be freed up is spent on additional time with family but rather with our devices :P"
8444,@rasbt,2021-03-16 20:22:25+00:00,https://twitter.com/rasbt/status/1371919806019014668,"@sama @ilyasut ""As AI produces most of the world‚Äôs basic goods and services, people will be freed up to spend more time with people they care about ..."" -&gt; I don't think so. Didn't we say the same about computers and the introduction of other tech?"
8445,@rasbt,2021-03-16 03:14:14+00:00,https://twitter.com/rasbt/status/1371661054518890498,@Queensland_AI @jeremyphoward @fastdotai April 1st is such a fun day for a Q&amp;A :)
8446,@rasbt,2021-03-15 00:53:29+00:00,https://twitter.com/rasbt/status/1371263245915414531,"@roydanroy Oh I misunderstood ""repost"" then. No, they didn't edit anything. On top of it, they even kindly suggested that we join each other's group meetings to share our ideas in the future because we had similar research interestsüò§"
8447,@rasbt,2021-03-15 00:30:23+00:00,https://twitter.com/rasbt/status/1371257434141044738,@roydanroy Yup. It's published and has 3 times more citations as ours.
8448,@rasbt,2021-03-14 23:25:37+00:00,https://twitter.com/rasbt/status/1371241135545450496,"@roydanroy ** In most cases, I would assume these are honest mistakes. And I would say this is partly owed to the fast pace with conference deadlines etc. On the other hand, I do think this is an important issue and training and peer review needs to be improved to catch these things."
8449,@rasbt,2021-03-14 23:22:07+00:00,https://twitter.com/rasbt/status/1371240252879306753,"@roydanroy *It was definitely weird because the person attended seminars where we presented the work-in-progress and included in the apology that he forgot/wasn't aware. I didn't pursue this further because life goes on, but yeah, as a young grad student I was very frustrated back then."
8450,@rasbt,2021-03-14 23:19:08+00:00,https://twitter.com/rasbt/status/1371239504472899587,"@roydanroy Arg, reading your thread and sorry to hear. Been there, and it is very frustrating. In our case, the person shared the scooped work via our department's mailing list (prev. institution). Person apologized, but still not clear whether it was an accident or purposeful scoop."
8451,@rasbt,2021-03-14 03:43:01+00:00,https://twitter.com/rasbt/status/1370943521327345665,"@justlukeing Thanks for the kind words! Sorry, I don't have any particular recommendation there. That's a bit outside of what papers I usually read."
8452,@rasbt,2021-03-14 03:42:05+00:00,https://twitter.com/rasbt/status/1370943289445265408,@3scorciav @will_price_94 @_willfalcon @edgarriba Haven't thought about this template structure too hard. I started organizing my projects more as well. Have a slightly different structure. The template looks good though. I think it is specifically so that it works well in a Hydra context
8453,@rasbt,2021-03-14 03:39:42+00:00,https://twitter.com/rasbt/status/1370942689861103618,@aerinykim :) https://t.co/sK3aeEvydG
8454,@rasbt,2021-03-13 20:14:01+00:00,https://twitter.com/rasbt/status/1370830527809396737,"Deep Learning News #7 Mar 13th, 2021. This week with a GAN textbox generator, more self-supervised learning, Facebook's deep learning fairness challenges, and adversarial laser beams. https://t.co/99ae1HbSjm"
8455,@rasbt,2021-03-13 19:51:01+00:00,https://twitter.com/rasbt/status/1370824742148714499,Wow. That‚Äôs ‚Äúthe art‚Äù of education. Very impressive!
8456,@rasbt,2021-03-13 15:19:05+00:00,https://twitter.com/rasbt/status/1370756306827681794,"ConSelfSTransDRLIB: Contrastive Self-supervised Transformers for Disentangled Representation Learning with Inductive Biases is All you need, and where to find them.

The current state of deep learning research summarized in one sentence.

(Credit: https://t.co/RTuht7Lkj0)"
8457,@rasbt,2021-03-13 01:01:10+00:00,https://twitter.com/rasbt/status/1370540406476308481,@hugobowne @RoamResearch I use a personal wiki (DokuWiki) but t looks interesting for someone who wants to start a knowledge base. Basically a modern version of that. I do wonder why it is &gt; 2x as expensive as a yearly Office 365 subscription that includes OneNote and 1 Tb of cloud storage on the side.
8458,@rasbt,2021-03-13 00:54:29+00:00,https://twitter.com/rasbt/status/1370538723755098112,@Swayson @unitandvector @adjiboussodieng @ylecun thanks for clarifying!
8459,@rasbt,2021-03-12 21:43:18+00:00,https://twitter.com/rasbt/status/1370490609748881408,"@iamtrask If you want to make things more clear and easier to explain, I think you'll have to get rid of the term ""supervised learning"" altogether and call it ""label learning."" And self-supervised learning can be called ""ancillary label learning"""
8460,@rasbt,2021-03-12 01:01:46+00:00,https://twitter.com/rasbt/status/1370178166032101382,"@adjiboussodieng @ylecun Hah, haven't seen the ""."" in a long time and was just wondering the other day whether it is still necessary or just something we old school twitter users still use. Good to know that it still is :)"
8461,@rasbt,2021-03-11 00:20:03+00:00,https://twitter.com/rasbt/status/1369805283321593856,"@rekil_prashanth @TheZachMueller There are many concepts that are related but I didn't want to clutter things up too much. In this case, they are kind of strongly related &amp; wanted to highlight it. I.e., in this case self-supervised + transfer learning would be kind of weight initialization schemes for a model"
8462,@rasbt,2021-03-11 00:07:35+00:00,https://twitter.com/rasbt/status/1369802145172750337,@PyTorch This is amazing!! (PS: Also love the sparkle effect in the editor btw. What VS Code plugin is that?)
8463,@rasbt,2021-03-11 00:05:05+00:00,https://twitter.com/rasbt/status/1369801514210983940,Looking forward to this! Gathered many interesting thoughts and observations over the last couple of months that I am excited to share and discuss!
8464,@rasbt,2021-03-10 21:35:27+00:00,https://twitter.com/rasbt/status/1369763859695865859,@alfcnz wow that looks amazing!
8465,@rasbt,2021-03-10 21:21:28+00:00,https://twitter.com/rasbt/status/1369760340762914816,"@ManuelHrokr @goldstein_aa @RoamResearch All GitHub repos should have a Wiki option as far as I know. Not sure how good it is, never really used that. If it helps, personally I am using DokuWiki. Super easy to set up and maintain. Only thing is you need a webserver for that. But you can already rent those for 1.99/month"
8466,@rasbt,2021-03-10 14:35:12+00:00,https://twitter.com/rasbt/status/1369658100488241155,@LKrukrubo Thanks for the kind words!
8467,@rasbt,2021-03-10 04:05:58+00:00,https://twitter.com/rasbt/status/1369499749267673090,"Oh, and if someone's interested, here is the narrated version I made yesterday. Again, very spontaneous &amp; I tried to keep it succinct. https://t.co/skRmx8E6qs"
8468,@rasbt,2021-03-10 01:17:48+00:00,https://twitter.com/rasbt/status/1369457425183629314,"@goldstein_aa @ManuelHrokr @RoamResearch The other one in that vein is Notion, I think. At least I hear people often recommending it. If I were to start a new knowledge base today, I would probably consider trying one or the other."
8469,@rasbt,2021-03-10 01:12:23+00:00,https://twitter.com/rasbt/status/1369456065230864384,"@goldstein_aa @ManuelHrokr @RoamResearch Thanks for the recommendation. I do keep a personal wiki alongside my mindmap for more detailed notes and connecting ""nodes."" It seems a bit like Roam in that sense. The wiki works well for me and is so large that I don't want to migrate at this point. (Plus it is free :P)"
8470,@rasbt,2021-03-10 00:53:17+00:00,https://twitter.com/rasbt/status/1369451255148515331,"Thanks for the feedback, everyone! Below is a slightly extended version based on all the awesome responses I received. Will probably extend it some time with more concrete methods for some of the categories some time later this semester :) https://t.co/p3budoESWB"
8471,@rasbt,2021-03-10 00:47:53+00:00,https://twitter.com/rasbt/status/1369449898014347266,"@DrGroftehauge @chrisalbon Could be. But then it probably wouldn't work so well in ""inference"" mode."
8472,@rasbt,2021-03-10 00:46:47+00:00,https://twitter.com/rasbt/status/1369449621399998469,"@BenH343 Thanks! Haven't really read this reference, but a computational concept related to this might be DropConnect (essentially dropout but dropping weight connections)"
8473,@rasbt,2021-03-10 00:44:45+00:00,https://twitter.com/rasbt/status/1369449109808181252,"@kaixhin @sytelus Oh yeah, I agree. Thanks!"
8474,@rasbt,2021-03-10 00:44:07+00:00,https://twitter.com/rasbt/status/1369448951099883522,"@ManuelHrokr I also get a lot out of reorganizing the mindmap as I am adding new topics. It's very satisfying, kind of like building with Lego bricks"
8475,@rasbt,2021-03-10 00:41:49+00:00,https://twitter.com/rasbt/status/1369448371988164611,@datenzauberai Thanks! Just recently saw that more and more people seem to use GANs for that (in the image domain). Haven't tried that myself yet but it seems worth mentioning
8476,@rasbt,2021-03-10 00:31:59+00:00,https://twitter.com/rasbt/status/1369445895813660678,@Cedias_ Hm yeah. Just thinking where this would fit. One example is multi-task learning. Another example would be dropout (if you think of it as a model ensemble approx. the geometric average of the predicted label proba)
8477,@rasbt,2021-03-10 00:29:19+00:00,https://twitter.com/rasbt/status/1369445226994163715,@Hobbit_hodor oh yes! One of the things that sound good in theory but something only very few people use in practice https://t.co/IfaTNb8oYp
8478,@rasbt,2021-03-10 00:26:24+00:00,https://twitter.com/rasbt/status/1369444490423992322,"@DJCordhose In practice, I have mixed experiences with that though; sometimes, choosing a simpler model indeed helps (versus a more complex model + regularization); but that's extremely anecdotal :P"
8479,@rasbt,2021-03-10 00:25:19+00:00,https://twitter.com/rasbt/status/1369444219681652745,"@DJCordhose Regarding simpler model, I remember the original dropout recommendation: if your model doesn't overfit, increase it's size until it does and then apply dropout to mitigate overfitting. Overall, this model will then perform better than the smaller (/simpler) model"
8480,@rasbt,2021-03-10 00:24:12+00:00,https://twitter.com/rasbt/status/1369443939862929409,"@DJCordhose Good recommendations! In practice, I was never really that lucky with plain SGD (usually Adam or SGD+momentum+LR scheduler) always beat SGD in terms of generalization performances in my use cases so far."
8481,@rasbt,2021-03-10 00:21:59+00:00,https://twitter.com/rasbt/status/1369443381282299907,@DrGroftehauge @chrisalbon good ones
8482,@rasbt,2021-03-10 00:18:31+00:00,https://twitter.com/rasbt/status/1369442507847794689,"@JPSabini I tried to summarize the most useful ones as ""adaptive learning rate"" but yeah, this can be extended to more general optimizer and scheduler categories"
8483,@rasbt,2021-03-10 00:16:58+00:00,https://twitter.com/rasbt/status/1369442117861470210,"@AwokeKnowing Yeah, I agree with that, it's a form of weight initialization"
8484,@rasbt,2021-03-10 00:15:45+00:00,https://twitter.com/rasbt/status/1369441813350776834,"@DrGroftehauge @darius_morawiec 2/2 loss function: ""(torch.log(torch.sigmoid(logits))*levels + torch.log(1 - torch.sigmoid(logits))*(1-levels)"". Would work most of the time but then fail. Reformulating it to the equivalent ""(F.logsigmoid(logits)*levels + (F.logsigmoid(logits) - logits)*(1-levels))"" fixed it"
8485,@rasbt,2021-03-10 00:14:54+00:00,https://twitter.com/rasbt/status/1369441599005003776,"@DrGroftehauge @darius_morawiec Yeah, what works on paper doesn't necessarily work well in practice if it is just coded up directly without stability considerations. E.g., we had this issue in a research project with the following 1/2"
8486,@rasbt,2021-03-09 21:51:42+00:00,https://twitter.com/rasbt/status/1369405558466506764,@manojlds @ManuelHrokr That‚Äôs MindNode
8487,@rasbt,2021-03-09 21:51:19+00:00,https://twitter.com/rasbt/status/1369405465650733058,"@anki_xyz 2/2 but when I think about it like shown in the lower part, it‚Äôs really hard for me to tell what effect strides and padding have on the output size. For that, it‚Äôs really much easier to tell from the viz on the top. But maybe that‚Äôs just how my brain works."
8488,@rasbt,2021-03-09 21:47:16+00:00,https://twitter.com/rasbt/status/1369404443729465351,"@anki_xyz Thanks for the kind words! Yeah, I had to search really hard to find the above illustration. There are 1000 visualizations of the bottom one on the web. 1/2"
8489,@rasbt,2021-03-09 21:45:31+00:00,https://twitter.com/rasbt/status/1369404003122110475,"@AwokeKnowing 2/2 E.g., consider predicting toxicity levels of molecules, self-supervised learning could be (pre)training the model to predict molecular weight. Could be done on the same dataset or on a larger, unlabelled dataset."
8490,@rasbt,2021-03-09 21:45:12+00:00,https://twitter.com/rasbt/status/1369403922977325057,"@AwokeKnowing Maybe we mean different things. With self-supervised learning, I mean training the model on a pre-text task; could be on the same dataset or on a larger unlabeled dataset 1/2"
8491,@rasbt,2021-03-09 15:32:39+00:00,https://twitter.com/rasbt/status/1369310167414824963,"@AwokeKnowing Yeah that could be done in a different organization. Currently I prefer ""Datasets"" because it highlights that it's about collecting additional or related data, augment the data, or create additional labels (like for the pretext task in self-supervised learning)"
8492,@rasbt,2021-03-09 15:30:36+00:00,https://twitter.com/rasbt/status/1369309654434672650,@rekil_prashanth Hm maybe. Ensembling usually always helps. Dropout can be seen as a technique for making ensembles more feasible.
8493,@rasbt,2021-03-09 15:29:28+00:00,https://twitter.com/rasbt/status/1369309367883993090,@TalKachman MindNode
8494,@rasbt,2021-03-09 00:04:42+00:00,https://twitter.com/rasbt/status/1369076644682596352,"@ducha_aiki Oh yeah, so true. And if you have a tendency to go onto tangents, make it 7-10 ;)"
8495,@rasbt,2021-03-08 23:54:27+00:00,https://twitter.com/rasbt/status/1369074062685798402,"@sandstep1 No, sry doesn‚Äôt exist yet :P"
8496,@rasbt,2021-03-08 23:42:34+00:00,https://twitter.com/rasbt/status/1369071071362703362,@ManuelHrokr Same (except different software)! Started doing that last semester and it is very satisfying to see the mind map grow!
8497,@rasbt,2021-03-08 23:41:31+00:00,https://twitter.com/rasbt/status/1369070809495597060,"@yanniknoc Oh interesting, the only context where I ever used it was GAN training. It might extend to general classification settings, good point"
8498,@rasbt,2021-03-08 23:18:30+00:00,https://twitter.com/rasbt/status/1369065015861510146,@AwokeKnowing With ‚Äúdataset‚Äù i meant methods that do something with the dataset (eg working with additional features and/or labels)
8499,@rasbt,2021-03-08 22:54:50+00:00,https://twitter.com/rasbt/status/1369059058318270465,@pbloemesquire Interesting. Dropout and bagging are actually quite similar except that in dropout the ensemble is implicit for efficiency reasons
8500,@rasbt,2021-03-08 22:42:01+00:00,https://twitter.com/rasbt/status/1369055835427594243,@0xhexhex Probably under architecture setup. The structuring was very spontaneous and there may be better ways to organize these topics
8501,@rasbt,2021-03-08 22:41:15+00:00,https://twitter.com/rasbt/status/1369055641394937858,@mpsterling MindNode
8502,@rasbt,2021-03-08 22:40:53+00:00,https://twitter.com/rasbt/status/1369055548348456962,@PMinervini Yeah in ML the term seems to be used very loosely. Funny enough someone added a note about that on Wikipedia recently. While i agree with you the whole diagram would then essentially be called regularization techniques :P https://t.co/idekcMXis2
8503,@rasbt,2021-03-08 22:02:49+00:00,https://twitter.com/rasbt/status/1369045968738476035,Mapping out lectures and did a spontaneous brain dump of techniques for improving generalization performance of deep neural nets. What did I forget? (Only focusing on common and rel. widely used methods here) https://t.co/SsmlE1r05w
8504,@rasbt,2021-03-08 21:58:57+00:00,https://twitter.com/rasbt/status/1369044997467738113,@savvyRL @ml_collective @jasonyo @seb_ruder @thisismyhat @_whatcode @Mitchnw Yeah it looks great; didn‚Äôt know it was still restricted and hope it will open up soon. And I hope it won‚Äôt require invites ;)
8505,@rasbt,2021-03-08 21:48:24+00:00,https://twitter.com/rasbt/status/1369042343345741827,@savvyRL @ml_collective @jasonyo @seb_ruder @thisismyhat @_whatcode @Mitchnw Oh I see. That makes sense then.
8506,@rasbt,2021-03-08 21:31:12+00:00,https://twitter.com/rasbt/status/1369038013200744453,"@ml_collective @jasonyo @seb_ruder @thisismyhat @_whatcode @Mitchnw @savvyRL * i.e. if you hear about an event here anyways, it makes it is easier to join and participate. There might be other downsides, but it looked pretty user friendly and inclusive to me"
8507,@rasbt,2021-03-08 21:23:01+00:00,https://twitter.com/rasbt/status/1369035952790925312,"@ml_collective @jasonyo @seb_ruder @thisismyhat @_whatcode @Mitchnw @savvyRL Was just wondering since so many have cool audio chat events happening on other platforms and share these happenings on Twitter, has anyone used Twitter Spaces for this, yet? Haven't had a chance to fully try it yet but it looks like a good alternative that is more direct"
8508,@rasbt,2021-03-08 20:07:21+00:00,https://twitter.com/rasbt/status/1369016913242816525,"@pablopargui @ampanmdagaba @__mharrison__ For my use cases, I am actually with you on that. Generally, I am trying to move away from dense one liners and also don‚Äôt always favor the most efficient way if it not as readable. I don‚Äôt write production code so I try to err more on the side of readability"
8509,@rasbt,2021-03-08 18:39:01+00:00,https://twitter.com/rasbt/status/1368994682668265472,@rahuldave @alfcnz @harsh_ris Yeah I don‚Äôt really use sidecar. In another more notation heavy (no slides) statistics course last semester I used Microsoft OneNote on the iPad and plugged it into my Mac to have the iPad screen in a QuickTime window on my Mac for recording.
8510,@rasbt,2021-03-08 18:25:37+00:00,https://twitter.com/rasbt/status/1368991309797748736,@ampanmdagaba I may have seen the warning you mentioned and also couldn‚Äôt figure out why. Thought it was unwarranted and maybe a bug so I ignored it. But yeah would also be curious about the other ones in practice
8511,@rasbt,2021-03-08 18:24:18+00:00,https://twitter.com/rasbt/status/1368990977868849152,@rahuldave @alfcnz @harsh_ris Right now I use it with Apple Keynote which has a native annotation mode via iPad as a remote device ‚Äî that‚Äôs basically what I have been using in class pre-pandemic. Only difference now is that I am doing a screen recording
8512,@rasbt,2021-03-08 18:08:43+00:00,https://twitter.com/rasbt/status/1368987055263518728,@ampanmdagaba * Like you can do multiplication with addition and for-loops doesn‚Äôt mean implementing the multiplication operator is a bad choice
8513,@rasbt,2021-03-08 18:07:41+00:00,https://twitter.com/rasbt/status/1368986797548638212,@ampanmdagaba I like and usually always use the first one. Looks most readable and intuitive for me and my use cases. Regarding why other solutions exist: I dunno but it maybe just happens that you can mimic/achieve this behavior but their real use case is different
8514,@rasbt,2021-03-08 17:34:21+00:00,https://twitter.com/rasbt/status/1368978409402081280,"@wahyuguntaraa True! But in practice most people call it transposed convolution afaik. Like Conv2dTranspose in Pytorch, and similar Keras etc"
8515,@rasbt,2021-03-08 16:57:32+00:00,https://twitter.com/rasbt/status/1368969144281014283,"Looking for good visualizations of transposed convolution (""deconvolution""), I mostly find the emulated version (using regular convolution that is used in CNNs) -- lower subpanel. I wonder why, because isn't that super unintuitive regarding strides compared to the upper subpanel? https://t.co/piXfQRjqmw"
8516,@rasbt,2021-03-08 02:42:50+00:00,https://twitter.com/rasbt/status/1368754050662100992,@bradpwyble Twin Peaks
8517,@rasbt,2021-03-08 01:50:24+00:00,https://twitter.com/rasbt/status/1368740854223998983,@alfcnz Nice! Have to check whether that's included in our institutions subscription. Makes me reconsider installing Adobe's CS (I find all the cloud sync requirement a bit obnoxious intrusive to be honest but maybe I can do that on a second user account)
8518,@rasbt,2021-03-08 01:47:24+00:00,https://twitter.com/rasbt/status/1368740099102507008,"@burkov @xamat Oh, same ;)"
8519,@rasbt,2021-03-08 01:45:18+00:00,https://twitter.com/rasbt/status/1368739572708966401,@alfcnz that looks super neat. It's done in post-processing? Btw. what app/tool do you use for such post-processing?
8520,@rasbt,2021-03-08 01:36:58+00:00,https://twitter.com/rasbt/status/1368737474982330369,"@alfcnz @sharoha136 @karpathy depends on the browser, I usually like to search in Safari +  private window"
8521,@rasbt,2021-03-08 01:36:01+00:00,https://twitter.com/rasbt/status/1368737234611023873,@alfcnz @harsh_ris You might be right. I think I used the drawing mode and it was drawing on top of the screen rather than in the app. But you can probably use it as a cursor for drawing.
8522,@rasbt,2021-03-08 01:25:43+00:00,https://twitter.com/rasbt/status/1368734642317254661,@alfcnz @sharoha136 @karpathy thanks! only downside is it requires login and doesn't work in private modeüò¨
8523,@rasbt,2021-03-08 00:26:18+00:00,https://twitter.com/rasbt/status/1368719690449698816,"@alfcnz @sharoha136 @karpathy It recommends typing ""-site: example . com"" (which would be a lot of hassle each time if you have &gt; 1 domain). I do see on that page that there is a firefox extension for that though."
8524,@rasbt,2021-03-08 00:24:05+00:00,https://twitter.com/rasbt/status/1368719131525214208,"@harsh_ris @alfcnz 2/2 You can do the iPad as a pointer device only if you connect it via Sidecar, but then you can only use the drawing mode on a virtual layer on top of the screen as far as I know. More common use of the iPad is to use it as a drawing device via secondary screen."
8525,@rasbt,2021-03-08 00:22:28+00:00,https://twitter.com/rasbt/status/1368718727408156673,"@harsh_ris @alfcnz If you mean the drawing tablet, you can think of it as a pointing device like your mouse. You can essentially interact with your computer as if it were a mouse. 1/2"
8526,@rasbt,2021-03-08 00:18:00+00:00,https://twitter.com/rasbt/status/1368717603187884035,@alfcnz @sharoha136 @karpathy Thanks! Doesn't seem to catch the medium-derivatives like towardsdatascience etc. but that's at least an improvement. Have to look whether there's a browser extension for that.
8527,@rasbt,2021-03-08 00:06:03+00:00,https://twitter.com/rasbt/status/1368714594454286337,"@sandhya_ai @tdietterich @arxiv Oh that's frustrating to hear and probably was maybe due to miscommunication in the arxiv docs. They should still be able to submit. Usually if it is an application of ML and there is no other category for the application area, we take it into cs.LG 1/2"
8528,@rasbt,2021-03-07 19:04:34+00:00,https://twitter.com/rasbt/status/1368638724670709761,"Deep Learning News #6, Mar 7 2021! This week covering the new PyTorch 1.8 release and a few tips and some practical advice for training neural nets https://t.co/NNAGGHZWUy"
8529,@rasbt,2021-03-05 22:24:22+00:00,https://twitter.com/rasbt/status/1367964229563789315,"@AnthonyAGatti @katnoria1 Yes, that's right. I don't intend to run anything serious on this machine but I use it to debug code before running it on my GPU machines. What I particularly like about this machine is that it is fast and quiet (doesn't have a fan) but I don't want to unnecessarily stress it ;)"
8530,@rasbt,2021-03-05 14:33:11+00:00,https://twitter.com/rasbt/status/1367845651304824834,"@thusinutz sounds like it, if they have enough ram"
8531,@rasbt,2021-03-05 14:31:55+00:00,https://twitter.com/rasbt/status/1367845335352176640,"@katnoria1 speaking of the M1 one, I compiled PyTorch for the ARM chip and ran a simple LeNet on Cifar 10 for fun and it was only 2 times slower than a GTX 1080 Ti, whereas running things on the 2018er CPU was not even in the same ballpark (like 20 times slower)"
8532,@rasbt,2021-03-05 14:30:21+00:00,https://twitter.com/rasbt/status/1367844938692648966,"@katnoria1 Yes, I think though. I recently sold 2018 one and got an M1 one though. In any case, the 2018er got pretty hot anyways under use (e.g., video export) so I probably wouldn't have run neural net training on it :P."
8533,@rasbt,2021-03-05 05:41:47+00:00,https://twitter.com/rasbt/status/1367711919226970113,"@CompulsorySNAP @SarvagyaGupta @TheZachMueller yeah but as I understand compiling it was a bit of a hassle. Now, the binaries make things easier I hope."
8534,@rasbt,2021-03-05 04:18:10+00:00,https://twitter.com/rasbt/status/1367690877754355713,"@SarvagyaGupta @TheZachMueller Depends on what you mean with at the same time. The cuda and ROCm would be installed as two separate PyTorch versions. So if you do that via different virtual environment, I assume you could train two models at the same time but not one model distributed over the two cards."
8535,@rasbt,2021-03-05 01:38:05+00:00,https://twitter.com/rasbt/status/1367650591728676869,"That's a great release! 
- AMD GPU support via ROCm (binaries available directly from the installer menu)
- Now possible to fit large models onto GPUs w/o external libraries: pipeline and model parallelism
- determinants &amp; eigenvalues via torch.linalg w/o switching to NumPy"
8536,@rasbt,2021-03-04 21:58:21+00:00,https://twitter.com/rasbt/status/1367595295865892865,@alfcnz @AICoffeeBreak @wacom @zoom_us @powerpoint @Microsoft @MicrosoftEDU @Office @BillGates Maybe CC @satyanadella instead :)
8537,@rasbt,2021-03-04 21:56:52+00:00,https://twitter.com/rasbt/status/1367594920345755650,"@alfcnz @wacom @zoom_us @powerpoint Ah yes, next to latex support, this is one of the reasons why I decided to use Keynote back then. Keynote has other issues though (undo button but no erase ;), and no options for pen width or saving annotations). Anyways, surprised that PowerPoint hasn't fixed anything, yet"
8538,@rasbt,2021-03-04 14:57:21+00:00,https://twitter.com/rasbt/status/1367489345784066055,"@JonathanSumDL It may. They are using something called "" bipartite attention"" instead of self-attention. Apparently this scales linearly rather than quadratically."
8539,@rasbt,2021-03-04 01:56:00+00:00,https://twitter.com/rasbt/status/1367292711930331142,"@rjurney Theoretically, I can't see why it shouldn't work if it still goes through the same router. On the other hand, I can imagine that this is likely the culprit for that issue."
8540,@rasbt,2021-03-04 01:52:15+00:00,https://twitter.com/rasbt/status/1367291769659019267,"@rjurney 2/2 Hm, before going that route maybe check that your phone is connected to the same wifi. And if you don't do it over wifi, make sure that the cellular upload option is checked for the Photos app on the phone."
8541,@rasbt,2021-03-04 01:49:30+00:00,https://twitter.com/rasbt/status/1367291079100301317,"@rjurney Ah sorry I misread your tweet, I thought you had the ""old"" setup pushing your photos to your Mac and then uploading to iCloud. In any case, never have problems with it and transfer photos to my Mac quite regularly 1/2"
8542,@rasbt,2021-03-04 01:17:52+00:00,https://twitter.com/rasbt/status/1367283115559944192,"@rjurney Why so complicated? I have my phone upload directly to iCloud, and the Mac fetches from there (I think?). Those are the full resolution ones apparently. This way, a photo usually shows up on my Mac Photos app only seconds after taking it via phone. https://t.co/lShff0ThDZ"
8543,@rasbt,2021-03-04 01:14:46+00:00,https://twitter.com/rasbt/status/1367282336736415748,"@alfcnz Also, in case you use it for teaching and slide annotation, another advantage (compared to an iPad) is that you can maintain eye contact with the camera mounted above your monitor."
8544,@rasbt,2021-03-04 01:13:20+00:00,https://twitter.com/rasbt/status/1367281974432399360,"@alfcnz nice! Tried one back in 2018 and sent it back because I was lacking eye-hand coordination with this. However, I should have given it more time! Know a lecturer who used it for online teaching last semester. Was pretty choppy in the early weeks but became super smooth with time"
8545,@rasbt,2021-03-03 22:35:07+00:00,https://twitter.com/rasbt/status/1367242157115904003,"TransGAN, GANsformer ... all good things come in threes; I guess someone should be working on TransGANsformer now ;)"
8546,@rasbt,2021-03-03 22:31:30+00:00,https://twitter.com/rasbt/status/1367241250806632452,"GANsformer: 2 weeks later, the second methods on GANs with Transformers just went live: https://t.co/633UsBfzz8. Wow, their generated images look better than anything I was ever able to generate with existing GANs https://t.co/ktGULNAhN5"
8547,@rasbt,2021-03-02 01:03:39+00:00,https://twitter.com/rasbt/status/1366554762053885952,"@darius_morawiec I am curious too, my guess is that the computation time of the function itself is really negligible. However, I can see other activation functions requiring more epochs"
8548,@rasbt,2021-03-02 01:01:03+00:00,https://twitter.com/rasbt/status/1366554109684416513,"@vasusingla71 Nice, thanks for sharing! Will mention this in my lecture on regularization approaches next week"
8549,@rasbt,2021-03-01 20:10:00+00:00,https://twitter.com/rasbt/status/1366480865237348354,"Working through papers I bookmarked last year to update my slides. Re-stumbled upon this interesting paper: ""Smooth Adversarial Training"" https://t.co/ksuVd91ebb
If adversarial robustness is relevant for your application, trying those activation funcs sounds like a no-brainer: https://t.co/AjTuGuwJup"
8550,@rasbt,2021-03-01 00:34:36+00:00,https://twitter.com/rasbt/status/1366185064938274820,"@svpino @itsmeseba @mrdbourke Yeah. I think traditionally this was done in a way similar to video classification (combining CNN + RNN). Actually, I remember seeing BERT being used for that now as well, aptly named ActionBERT :) https://t.co/8wUVBLGGhi"
8551,@rasbt,2021-02-28 17:44:36+00:00,https://twitter.com/rasbt/status/1366081882904006658,@StasBekman @GuggerSylvain @mariaKhalusova @huggingface That's a really nice write-up! Thanks for sharing
8552,@rasbt,2021-02-27 22:46:49+00:00,https://twitter.com/rasbt/status/1365795553293049857,"@BerbaFan @fchollet @PyImageSearch @aureliengeron Big congrats! This is awesome news! I hope you do something fun to reward yourself at the end of this journey :). Also thanks for the kind acknowledgements, I am honored that my little writing had some positive impact :)."
8553,@rasbt,2021-02-27 22:45:35+00:00,https://twitter.com/rasbt/status/1365795239676551172,"Deep Learning News #5, Feb 27 2021. This week I am covering Apple's on-device federated learning approach, ML and differentiable privacy, bias and dataset diversity, model search, and several methods for facilitating model training on single GPUs https://t.co/eiGYqeU1S1"
8554,@rasbt,2021-02-27 14:42:20+00:00,https://twitter.com/rasbt/status/1365673627186843650,Just stumbled upon this nice repo listing challenges and contests suitable for applying machine learning/deep learning. 33 challenges CVPR 2021-related challenges were just added. Something interesting to consider for student projects/homeworks  https://t.co/KPviKe22Db
8555,@rasbt,2021-02-27 00:20:58+00:00,https://twitter.com/rasbt/status/1365456858694180871,@Hoodi_hastam @svpino That's actually a pretty good analogy. Basically my thoughts for every new project where data is limited. Always like: I can see how this could be useful but let's stick to the current framework and maybe just use some semi-supervised learning or imbalanced data methods instead
8556,@rasbt,2021-02-27 00:16:18+00:00,https://twitter.com/rasbt/status/1365455684779786243,"@A_K_Nain @svpino Interesting! You mean in the image domain (like self-supervised learning for an CNN-based GAN)? Otherwise, for text, you have BART (based on BERT) etc. that work quite successfully on different tasks"
8557,@rasbt,2021-02-26 15:12:08+00:00,https://twitter.com/rasbt/status/1365318737616846848,@svpino Self-supervised vs semi-supervised learning is the new Python vs R
8558,@rasbt,2021-02-26 02:16:17+00:00,https://twitter.com/rasbt/status/1365123488407764992,"@GuggerSylvain @mariaKhalusova @huggingface Awesome, thanks for the pointers. Esp. FairScale looks like it hits the sweet spot for me in terms of having something cleaner than my hacks and being easy enough to just give it a try :)"
8559,@rasbt,2021-02-26 02:13:15+00:00,https://twitter.com/rasbt/status/1365122727158435855,"@seanmylaw @mariaKhalusova @huggingface @GuggerSylvain Coincidentally, I also saw this post the other day ... I am basically doing a form of step 4: https://t.co/jrYRT3b1IA"
8560,@rasbt,2021-02-26 02:12:51+00:00,https://twitter.com/rasbt/status/1365122625685647360,"@seanmylaw @mariaKhalusova @huggingface @GuggerSylvain No, not a specific approach. More like a mix between some experience and some form of grid/random search. Experience in terms of what to consider tuning and then depending on the size running either grid or randomized search"
8561,@rasbt,2021-02-26 02:10:39+00:00,https://twitter.com/rasbt/status/1365122071966191625,"@GuggerSylvain @mariaKhalusova @huggingface I see. Do you have any favorite tutorials for model and pipeline parallelism in PyTorch? The one time I used model parallelism I hacked it together by using to Sequential subnetworks, putting those onto different GPUs. Is there now more specific tooling for that?"
8562,@rasbt,2021-02-26 01:46:00+00:00,https://twitter.com/rasbt/status/1365115870675169289,@saidpertuz Yes :) https://t.co/eGm9KBnaH4
8563,@rasbt,2021-02-26 01:44:26+00:00,https://twitter.com/rasbt/status/1365115476028882946,"@mariaKhalusova @huggingface @GuggerSylvain PS: In the list above, model parallelism and pipeline parallelism mean using multiple GPUs if you cannot use any of the other tricks to fit the model training onto a single GPU?"
8564,@rasbt,2021-02-26 01:41:57+00:00,https://twitter.com/rasbt/status/1365114851522187264,"@mariaKhalusova @huggingface @GuggerSylvain That's a nice list! Personally, even if I have multiple GPUs available, I am still a practitioner of what I call hyperparameter parallelism: running one model per GPU with a different hyperparameter setting (to find good learning rates etc.) üòÖ"
8565,@rasbt,2021-02-25 03:12:24+00:00,https://twitter.com/rasbt/status/1364775225443942402,Code example to show that this actually works ;) https://t.co/Ep2GOCwIU3
8566,@rasbt,2021-02-25 03:11:39+00:00,https://twitter.com/rasbt/status/1364775034523439106,"Sketched out the loss gradient for softmax regr in class today, remining me of how nicely multi-category cross entropy deriv. play with softmax deriv., resulting in a super simple learning rule, w -= (p-y)*x, making this such a nice combination for multi-layer perceptrons as well https://t.co/AF6kSKNubv"
8567,@rasbt,2021-02-24 01:48:09+00:00,https://twitter.com/rasbt/status/1364391636319547397,"@fperez_org @KyleCranmer I share your opinion regarding these tools. Imho I think this can only be justified if the university sends each student a dedicated test-taking device. Cheating is also a problem though. While not a silver bullet, I ended up redesigning &amp; reweighting course assignments"
8568,@rasbt,2021-02-24 00:45:51+00:00,https://twitter.com/rasbt/status/1364375954429255681,"@hugobowne @pwang @teoliphant @ulysseas @joinClubhouse These topics get more and more interesting. At this rate, I will probably have to ask someone for an invite link eventually"
8569,@rasbt,2021-02-24 00:42:45+00:00,https://twitter.com/rasbt/status/1364375177094643715,"@svpino @alfcnz no worries, it's just a US/Canada thing"
8570,@rasbt,2021-02-23 21:27:54+00:00,https://twitter.com/rasbt/status/1364326138592518145,@roydanroy More like Tesla + autopilot. It automagically works very well and feels great when it does. Most of the time. But be aware of edge cases.
8571,@rasbt,2021-02-19 23:46:01+00:00,https://twitter.com/rasbt/status/1362911347030298625,"@BFGHDF @__mharrison__ Yeah. For ML/DL contexts, there is also MLFlow which has lots of useful stuff for monitoring"
8572,@rasbt,2021-02-18 20:15:40+00:00,https://twitter.com/rasbt/status/1362496023302705156,"@MelMitchell1 *Self-supervised learning because it is conducive to learning general representations for various downstream tasks related to various prediction and synthesis tasks, etc. Recent interesting example is Protrans (https://t.co/KNh1EZKyDN)."
8573,@rasbt,2021-02-18 20:13:28+00:00,https://twitter.com/rasbt/status/1362495469147090947,@MelMitchell1 I think of recent advances related to skill-transfer for RL and meta-learning for FSL still as narrow AI. But it's moving into the rough direction in terms of becoming broader within the task domain. Pre-text tasks via self-supervised learning are maybe also worth mentioning.
8574,@rasbt,2021-02-18 19:25:38+00:00,https://twitter.com/rasbt/status/1362483433470107654,"@__mharrison__ In a research context, Jupyter Nbs are great for prototyping but don't scale well. Ultimately, you probably want to run your code on multiple GPUs via a job scheduler or at least via the command line; with Jupyter Nbs this can be a hassle."
8575,@rasbt,2021-02-18 19:23:49+00:00,https://twitter.com/rasbt/status/1362482974613245953,"@__mharrison__ It's mainly because I feel like .py scripts and module imports are better suited for more involved deep learning models. Easier to debug via VSCode / PyCharm too. I love Jupyter Nbs for teaching and data analysis, but for research/project work, .py scripts are better imho."
8576,@rasbt,2021-02-18 17:01:32+00:00,https://twitter.com/rasbt/status/1362447165856047114,"@_MRogers ""how did you determine..."" -&gt; I think this was by manual tweaking and a rather arbitrary choice.

""can i plot 4 and 15 features"" -&gt; technically, yes. You need to extend the filler_feature_values={} and *_ranges dictionaries with those feature indices."
8577,@rasbt,2021-02-18 16:57:51+00:00,https://twitter.com/rasbt/status/1362446240357748736,"As I am planning to move away from Jupyter Nbs to .py scripts for HWs later this semester (when implementing more complex deep learning models), I am happy to announce that thanks to the latest refactoring, watermark also runs in regular Python envs now!
https://t.co/mcWXveqldQ https://t.co/qAxGwhDCBV"
8578,@rasbt,2021-02-18 15:12:12+00:00,https://twitter.com/rasbt/status/1362419651691634695,Short and sweet intro to Transformers with pointers to relevant literature and from-scratch implementations:
8579,@rasbt,2021-02-18 15:08:44+00:00,https://twitter.com/rasbt/status/1362418782271111176,@TheShubhanshu @joelgrus I thought jupyter notebooks were not allowed üò¨üòÖ
8580,@rasbt,2021-02-18 15:07:32+00:00,https://twitter.com/rasbt/status/1362418480553803777,"@roydanroy *I do think though it takes ~2-4 years from a patent application to an actual patent, so I wouldn't be surprised if a transformer patent was already filed a few years ago"
8581,@rasbt,2021-02-18 15:06:34+00:00,https://twitter.com/rasbt/status/1362418234574700546,"@roydanroy Dropout and BatchNorm for sure. In both cases Google if I remember correctly. I recall there is also a CNN patent by Google, just dug up the discussion here: https://t.co/m8VsKxz78W. As far as I remember, there was also an LSTM-related one. Transformers though I don't know yet"
8582,@rasbt,2021-02-18 03:17:00+00:00,https://twitter.com/rasbt/status/1362239665236017152,"@ledell @open_ml Oh yes, that's a really nice one. Have seen and used it before! Not sure how it could slip through the cracks. Thanks for the note, just added it!"
8583,@rasbt,2021-02-18 02:57:15+00:00,https://twitter.com/rasbt/status/1362234695392583685,"@joelgrus oops, my bad, I missed the ""static"" part. Maybe knitpy (https://t.co/4yrpoCkMpV‚Ä¶) and stitch (https://t.co/liMynUeTXz) fill this niche? Basically both Rmarkdown and knitr clones &amp; two things on my cool-things-to-check out list that I never had a chance to try."
8584,@rasbt,2021-02-18 02:47:51+00:00,https://twitter.com/rasbt/status/1362232332451741696,"@joelgrus I know what you mean, but a collaborator recently started using streamlit, and I am really impressed. Basically like R Shiny but for Python: https://t.co/cmHESGJHmW"
8585,@rasbt,2021-02-17 22:34:58+00:00,https://twitter.com/rasbt/status/1362168691622838273,"@gdequeiroz That's a nice one, thanks! Just added it :)"
8586,@rasbt,2021-02-17 00:58:55+00:00,https://twitter.com/rasbt/status/1361842531072438274,@alexrives @ylecun Thanks for clarifying!
8587,@rasbt,2021-02-17 00:55:26+00:00,https://twitter.com/rasbt/status/1361841651031941126,"After seeing an increased used of transformers for computer vision in terms of classification and object detection, there is also a transformer GAN now. These results from this (first?) transformer-only GAN are actually kind of impressive: https://t.co/v4QbPEvjZv https://t.co/8IXxBRUCMY"
8588,@rasbt,2021-02-17 00:34:25+00:00,https://twitter.com/rasbt/status/1361836364728270851,"@ylecun @alexrives Interesting! The MSA is only used for training? Or, for prediction on new sequences, does it require to (a) know a set of evolutionary related proteins and (b) the structure of these evolutionary related proteins?"
8589,@rasbt,2021-02-16 19:26:00+00:00,https://twitter.com/rasbt/status/1361758748667236355,"@doomsuckle @randal_olson yap! That being said, my folder naming scheme was always based on the (abbrev.) international format :) https://t.co/xKorW8U2EY"
8590,@rasbt,2021-02-16 15:34:14+00:00,https://twitter.com/rasbt/status/1361700421434228737,"@randal_olson Hah, if you date your project folder names and keep a subfolder for each year, the American format is actually preferable over the European one."
8591,@rasbt,2021-02-16 14:04:55+00:00,https://twitter.com/rasbt/status/1361677944524005379,"Finished ""Ready Player Two"" and it was actually quite okay. Not great and of course not as good as the first back then. But the same way the first one criticizes virtual reality headsets, I like the points it makes about Neuralink and artificial general intelligence"
8592,@rasbt,2021-02-15 22:23:12+00:00,https://twitter.com/rasbt/status/1361440954142588928,@chrisalbon I have had really good experience with Ippodo Tea (https://t.co/rDKT9p4cJR) in recent years. They do have a getting started guide as well as good and detailed descriptions on their product pages
8593,@rasbt,2021-02-15 17:44:21+00:00,https://twitter.com/rasbt/status/1361370780693647360,"@pwang @vboykis Maybe it's not just the synchronousness. Some other audio-only things that don't work well: audiobook versions of machine learning textbooks, technical conference talks without slides, or seminars without whiteboards"
8594,@rasbt,2021-02-15 16:27:40+00:00,https://twitter.com/rasbt/status/1361351482189217797,"@zubairahmed_ai @KishavanBhola @zaidalyafeai @karpathy @jcjohnss Otherwise it's like gatekeeping to promote a particular brand. Kind of sad because we made a lot of progress in the past couple of years, even the traditionally closed venues like for-profit publishers (both papers &amp; books) allow nowadays to host a copy on your personal website"
8595,@rasbt,2021-02-15 16:25:07+00:00,https://twitter.com/rasbt/status/1361350839454093318,"@zubairahmed_ai @KishavanBhola @zaidalyafeai @karpathy @jcjohnss I see. I can understand if people like to have conversations not being saved/recorded and shared; kind of like the appeal behind Snapchat. But I feel like with everyone's permission, it should be okay."
8596,@rasbt,2021-02-15 14:42:34+00:00,https://twitter.com/rasbt/status/1361325030827827204,"@alfcnz @Typora @NotionHQ @drawio @PyTorch @ProjectJupyter Nice one! As always, really awesome lecture design üçø"
8597,@rasbt,2021-02-15 14:05:52+00:00,https://twitter.com/rasbt/status/1361315795113017345,"@roydanroy Yes! Noticed, that some EU-based companies recently started doing that. Double opt-in is not a GDPR requirement as far as I know but a nice thing to do, isn't complicated, and probably also has a positive psychological effect on new customers."
8598,@rasbt,2021-02-15 01:18:44+00:00,https://twitter.com/rasbt/status/1361122741412372480,"@rekil_prashanth @TheZachMueller Yes, you are right. I think it's not an ideal measure though because some images contain multiple obj. E.g. below, using top-1 accuracy, a system that predicts cow, barn etc. would be wrong. There have been re-labeling efforts recently to mitigate that: https://t.co/l6HN9UJNpK. https://t.co/6W6euD5T6q"
8599,@rasbt,2021-02-15 00:39:00+00:00,https://twitter.com/rasbt/status/1361112740169977859,"@svpino @ampanmdagaba @__MLT__ @drob yeah, also to be fair, often AI and reinforcement learning are used interchangeably. E.g,. see https://t.co/qypml6z5bL. On arxiv, ""cs. AI"" and ""cs.LG"" (machine learning) are strictly distinct categories, and reinfocement learning is strictly ""cs .LG"" not ""cs. AI"""
8600,@rasbt,2021-02-15 00:08:22+00:00,https://twitter.com/rasbt/status/1361105033346039808,@svpino @ampanmdagaba @__MLT__ @drob Basically everything that is based on reinforcement learning.
8601,@rasbt,2021-02-14 23:51:32+00:00,https://twitter.com/rasbt/status/1361100798055317505,"@svpino @ampanmdagaba @__MLT__ @drob Agreed. I do think though that more and more are ML-based. As you notice, I am a bit on the fence about the saying ""Machine learning produces predictions"" because you can equally say it produces ""actions"" :)"
8602,@rasbt,2021-02-14 23:46:13+00:00,https://twitter.com/rasbt/status/1361099459992711170,"@svpino @ampanmdagaba @__MLT__ @drob yeah, but what would be an ex. of a current one. Obviously we don't have artificial general intelligence, but even for ""impressive"" narrow AI, all examples, like self-driving cars, AlphaGo, AlphaStar, AlphaFold, object-detection, BERT, GPT-3 ... they all rely on machine learning."
8603,@rasbt,2021-02-14 23:42:23+00:00,https://twitter.com/rasbt/status/1361098492740046859,"@ampanmdagaba @svpino @__MLT__ @drob Oh yeah good point. When I explain AlphaStar, a common student question is: how is it different from the in-game AI."
8604,@rasbt,2021-02-14 23:40:52+00:00,https://twitter.com/rasbt/status/1361098110068551684,"@ampanmdagaba @svpino @__MLT__ @drob meta-learning is actually already pretty common in ML, in a few-shot learning context (https://t.co/4cCU6x8eF2). Another meta-learning context is training an ML algo on meta data (https://t.co/3jSVVwihMr). It's an overloaded term, unfortunately"
8605,@rasbt,2021-02-14 23:05:13+00:00,https://twitter.com/rasbt/status/1361089139484065798,"@ampanmdagaba @svpino @__MLT__ @drob Yeah, totally agree. Still wondering what is mean by AI produces actions. If you consider RL as AI and not ML, that's weird."
8606,@rasbt,2021-02-14 23:00:07+00:00,https://twitter.com/rasbt/status/1361087857767636992,"@burkov Hm yeah that's odd. I do think though that many algorithms still use dense arrays under the hood. I.e., if you pass it a sparse array, it will convert it to dense under the hood anyway. So it doesn't really matter memory-usage-wise https://t.co/AgO7xoeBzx"
8607,@rasbt,2021-02-14 20:53:49+00:00,https://twitter.com/rasbt/status/1361056071071244290,"@svpino @__MLT__ @drob Interesting. Serious question: What would be a modern application of artificial intelligence that is not machine learning? (Always looking for examples for illustrations in class, and it is hard to think of modern AI systems that are not ML)"
8608,@rasbt,2021-02-14 20:45:28+00:00,https://twitter.com/rasbt/status/1361053971104763908,"mljar-supervised: Pretty cool-looking new Python package for AutoML. Also includes preprocessing steps (e.g. like TPOT), which is super important. https://t.co/YMDC6aUJ7X. Table on the right compares it to other AutoML tools on the percentile rank of private Kaggle leaderboards https://t.co/CvI2lvqcZ3"
8609,@rasbt,2021-02-14 19:16:50+00:00,https://twitter.com/rasbt/status/1361031667687845891,"@zubairahmed_ai @KishavanBhola @zaidalyafeai @karpathy @jcjohnss yeah, you shouldn't be recording without asking &amp; getting permission by all participants"
8610,@rasbt,2021-02-14 18:47:15+00:00,https://twitter.com/rasbt/status/1361024222173270017,"@KishavanBhola @zubairahmed_ai @zaidalyafeai @karpathy @jcjohnss just out of curiosity, does the app not have a recording feature like Zoom? If not, I can imagine there might be a way to capture (e.g., Quicktime lets you record by plugging an iPhone via Lightning port into a Mac; I use that for recording on ipadOS for some lectures)"
8611,@rasbt,2021-02-14 15:30:44+00:00,https://twitter.com/rasbt/status/1360974766975438852,"@Muenchner_Junge @JSEllenberg Not aware of such a list :(. I think if it did, someone would have implemented it in code (versus autoML and NAS). I do remember a simple but useful list that I shared with students last year, which can come in handy for newcomers: https://t.co/m3WXaZyH7Z"
8612,@rasbt,2021-02-14 15:21:49+00:00,https://twitter.com/rasbt/status/1360972522045534208,"@mosko_mule @wgrathwohl hah, cool, didn't know it was added either"
8613,@rasbt,2021-02-14 15:20:57+00:00,https://twitter.com/rasbt/status/1360972303161565185,"@_rdm_8 Yeah, number of random starts and number of epochs would be two additional dimensions that would matter in practice."
8614,@rasbt,2021-02-13 18:54:15+00:00,https://twitter.com/rasbt/status/1360663594212487169,@jasondeanlee @tomgoldsteincs Nice! This PyTorch-implementation will be useful for my class-context later this semester as well. Thanks for sharing!
8615,@rasbt,2021-02-13 18:09:27+00:00,https://twitter.com/rasbt/status/1360652320334352393,"Deep Learning News #3, Feb 13 2021 -- After talking a lot about language models last week, there is a refreshing number of computer vision news this week, from new BatchNorm-free image classification SOTAs to estimating the price of your handbags: https://t.co/jsw89u0rde"
8616,@rasbt,2021-02-13 18:04:44+00:00,https://twitter.com/rasbt/status/1360651134160019464,"@JSEllenberg More serious answer: usually it comes down to patience &amp; experience. For each proj., there are lots of things to explore to get good results. There is no ""if you do this, you will good results"" but rather a ""these are the things you should try to see whether they also work here"""
8617,@rasbt,2021-02-13 17:59:56+00:00,https://twitter.com/rasbt/status/1360649925168680964,@JSEllenberg Not BatchNorm ;) https://t.co/O44XVsI3Kw
8618,@rasbt,2021-02-13 17:51:16+00:00,https://twitter.com/rasbt/status/1360647742704517122,"@paul_rietschka hah, yeah. Am in the same boat with that recommendation. I occasionally use SGD with 0.9 momentum but it needs more patience with learning parameter tuning and scheduler tuning. And I am lazy :P"
8619,@rasbt,2021-02-13 17:49:38+00:00,https://twitter.com/rasbt/status/1360647334674243585,Here the accompanying references: https://t.co/EYqfD8rRVd
8620,@rasbt,2021-02-12 18:40:07+00:00,https://twitter.com/rasbt/status/1360297651049218048,@denfromufa probably to highlight that these differences are tiny
8621,@rasbt,2021-02-12 17:47:56+00:00,https://twitter.com/rasbt/status/1360284518003986433,@A_K_Nain That would be around minute 22:00. The tests are on CIFAR-10 and VGG-13.
8622,@rasbt,2021-02-12 17:39:27+00:00,https://twitter.com/rasbt/status/1360282384650948611,"Regarding generalization in neural nets, one of the ""Things that don't matter very much: The optimizer""

(via Tom Goldstein's talk, ""An empirical look at generalization in neural nets"" https://t.co/CqLeHLte3H) https://t.co/uzrvDCirrl"
8623,@rasbt,2021-02-12 04:43:59+00:00,https://twitter.com/rasbt/status/1360087228815446016,@lostthenumbers My first computer had a black-and-white monitor
8624,@rasbt,2021-02-12 00:09:08+00:00,https://twitter.com/rasbt/status/1360018060854386692,@DynamicWebPaige @Microsoft @code @github Congrats! That's awesome news! Best of success in your new job and role :)
8625,@rasbt,2021-02-11 21:23:40+00:00,https://twitter.com/rasbt/status/1359976422127853573,"""Datasets for Machine Learning and Deep Learning -- Some of the Best Places to Explore"" I just put together a list of all the dataset repositories we discussed on Twitter last month: https://t.co/tiwSj76kEz"
8626,@rasbt,2021-02-10 02:21:07+00:00,https://twitter.com/rasbt/status/1359326501704003585,@hardmaru confidence intervals! :)
8627,@rasbt,2021-02-10 01:36:09+00:00,https://twitter.com/rasbt/status/1359315184561569797,"@abhayspawar @xamat It's all empirical, but I recall from several class projects that students who tuned various DT parameters in random forests extensively only had negligible gains in the best case."
8628,@rasbt,2021-02-10 01:26:04+00:00,https://twitter.com/rasbt/status/1359312648563806210,"@abhayspawar @xamat Technically, you are right. In practice, I am not sure if it is worthwhile tuning those. I think playing around with the number of features is usually sufficient to get strong individual trees (on training data) but also somewhat decor-relate the trees."
8629,@rasbt,2021-02-10 01:22:57+00:00,https://twitter.com/rasbt/status/1359311860688965632,"(8) consider Nvidia Apex's fused batchnorm and optimizers
(9) consider checkpointing to trade off memory for 'compute' to train with larger batch sizes
(10) fuse pointwise operations into single cuda kernels with the @torch.jit.script decorator

4/4"
8630,@rasbt,2021-02-10 01:22:56+00:00,https://twitter.com/rasbt/status/1359311859049000966,"(6) increase batch size and consider optimizers designed for large batch training
(7) even on a single node use DistributedDataParallel (vs simple or no DataParallel)

3/4"
8631,@rasbt,2021-02-10 01:22:56+00:00,https://twitter.com/rasbt/status/1359311858004602881,"(3) choose better default algos / enbable autotuning via torch.backends.cudnn.benchmark = True
(4) disable redundant bias in convolutional layers if they are followed by BatchNorm2d
(5) zero out gradients with param.grad = None instead of https://t.co/4JDztCD7Rt_grad()

2/4"
8632,@rasbt,2021-02-10 01:22:56+00:00,https://twitter.com/rasbt/status/1359311856616243200,"Really enjoyed Szymon Migacz's talk on optimizing PyTorch's comp. performance deep learning applications:
https://t.co/byRaqRICRo

Summarizing the main points:
(1) parallel data processing via num_workers &gt; 0
(2) better memory GPU utilization via  pin_memory = True

1/4"
8633,@rasbt,2021-02-09 18:34:22+00:00,https://twitter.com/rasbt/status/1359209040757329923,"@uwcdis @UWMadisonLS Thanks for the mention &amp; shoutout! For those who are interested in the topics covered in this course, I have a more detailed course overview here: https://t.co/YeN3eZMkbl"
8634,@rasbt,2021-02-09 16:08:42+00:00,https://twitter.com/rasbt/status/1359172381420445703,"@xamat Let him run the random forest as a baseline. Easier to get going and no hyperparams to worry about. Then, let's see if and by how much a properly tuned XGBoost model can improve the result wrt to that baseline"
8635,@rasbt,2021-02-09 15:12:41+00:00,https://twitter.com/rasbt/status/1359158282473078784,"@seanmylaw @stumpy_dev If you meant ""organizing by topic"" I think this is indeed tricky because there is no tagging feature inside discussions yet as far as I know. But it's still better than mailing lists, which have the same issue :)"
8636,@rasbt,2021-02-09 02:09:25+00:00,https://twitter.com/rasbt/status/1358961170451988481,"@seanmylaw @stumpy_dev Agreed :). There is also a feature where you can bulk-convert Issues with a specific tag (e.g., Questions) to entries in the discussion section. Apparently, if you have Issue templates setup, future Issues with that tag will then also get converted. Super neat!"
8637,@rasbt,2021-02-08 16:28:17+00:00,https://twitter.com/rasbt/status/1358814923451740161,"@canyon289 Depends on the genre. If you are into autobiographies &amp; suspense, you might like ""Ghost In The Wires: My Adventures as the World's Most Wanted Hacker"" https://t.co/NBhlXprF7G"
8638,@rasbt,2021-02-08 15:30:14+00:00,https://twitter.com/rasbt/status/1358800313621356548,"I know many people were worried when GitHub joined Microsoft not too long ago, but I must say I am really amazed about all the improvements and enhancement has been making since then"
8639,@rasbt,2021-02-08 15:28:41+00:00,https://twitter.com/rasbt/status/1358799921869180930,Just learning about the new GitHub discussion feature (see scikit-learn ex. below). Looks amazing and will lower the barrier to community building and Q&amp;A esp. for smaller projects; more organized &amp; easier to set up than mailing lists or Google Groups: https://t.co/nJt36zgGKk https://t.co/hY7Os5GG94
8640,@rasbt,2021-02-08 00:05:07+00:00,https://twitter.com/rasbt/status/1358567498749267973,"The bigger goodies are forward mode autodiff, which can come in handy outside deep learning for general-purpose stuff, and second order gradients: https://t.co/Mm1gunbs4e"
8641,@rasbt,2021-02-08 00:03:49+00:00,https://twitter.com/rasbt/status/1358567170947612684,"This is nice! I didn't know about this autograd refresh via the new functional API. So, among other things, you can now compute partial derivatives / gradients from Python function as opposed to Python variables. Beyond the performance improvements, good for code organization. https://t.co/cIRk0D7puk"
8642,@rasbt,2021-02-07 15:18:40+00:00,https://twitter.com/rasbt/status/1358435015646928897,"@bjg @nitishjoshi_ Yeah, I don't really need Rust (my tasks are usually related to DL) but I am tempted to learn it just for the fun of it. I heard so many good things around the language and it seems like it is a joy to work with it :)"
8643,@rasbt,2021-02-07 15:16:47+00:00,https://twitter.com/rasbt/status/1358434540692393989,"@sjm2404 Sorry, they may exist but I don't know any. Will be talking about PyTorch more in my deep learning class this semester, including coding portions here and there. https://t.co/9RIzs6NGfj"
8644,@rasbt,2021-02-07 15:14:01+00:00,https://twitter.com/rasbt/status/1358433841933742081,@RavitJain I use R occasionally; you can find certain specialized analyses in there that are not implemented elsewhere yet.  I think the reason it's not on the list is that it is hard to search for (similar reason C  is not on that list). R would probably among the top 10 otherwise I guess.
8645,@rasbt,2021-02-06 19:20:52+00:00,https://twitter.com/rasbt/status/1358133579058991107,"Deep Learning News #2, Feb 6 2021 
https://t.co/eBc1HFdwAt"
8646,@rasbt,2021-02-06 18:01:11+00:00,https://twitter.com/rasbt/status/1358113523935633408,"@ocramanatnof Yeah, wondered about it too. Possible reasons: (a) hard to assess because ""R"" (/R lang) doesn't work well as a search term. (b) low popularity and didn't make it into the ranking (c) not considered a general-purpose programming language in this context. I think probably (a)"
8647,@rasbt,2021-02-06 16:49:49+00:00,https://twitter.com/rasbt/status/1358095565423341568,@martingoodson @xamat üî•This tweet wins Twitter today.
8648,@rasbt,2021-02-06 15:54:06+00:00,https://twitter.com/rasbt/status/1358081543755997185,"@xamat Well said. In addition to what you said, and maybe I am wrong, but it seems like switching to fully functional paradigms is a purely academic thing."
8649,@rasbt,2021-02-06 15:45:42+00:00,https://twitter.com/rasbt/status/1358079428388130817,"@robert_monpolli @TheZachMueller @imridhasankar @fastdotai I am not involved / not planning to get involved, but there is probably a bigger discussion to be had to sort things out."
8650,@rasbt,2021-02-06 15:43:05+00:00,https://twitter.com/rasbt/status/1358078772831023106,@robert_monpolli @TheZachMueller @imridhasankar @fastdotai thanks for the update
8651,@rasbt,2021-02-06 15:42:20+00:00,https://twitter.com/rasbt/status/1358078581616893954,"@eng_saqib Hm, I thought PySpark was even before that and most people then switch(ed) to Dask &amp; @CoiledHQ for these types of workflows"
8652,@rasbt,2021-02-06 15:36:06+00:00,https://twitter.com/rasbt/status/1358077014142558209,What happened to Scala? I remember it was the hot new thing for data science and machine learning when I was in grad school (/not too long ago). https://t.co/59gMKDP0kk https://t.co/vL7VSs9dyK
8653,@rasbt,2021-02-06 15:14:03+00:00,https://twitter.com/rasbt/status/1358071462855286789,"""CMU Researchers Explore ‚ÄòCrazy Idea‚Äô of Automating AI Paper Reviews"" -- Yes, crazy idea. But I like the list of the most frequently mentioned qualities of a good review. Will probably adopt it as rubric for assessing peer reviews in class this semester https://t.co/zQI73FXRYn https://t.co/SW2W9AWqnJ"
8654,@rasbt,2021-02-06 00:45:26+00:00,https://twitter.com/rasbt/status/1357852869777620997,"@joelgrus @xamat jap, exactly!"
8655,@rasbt,2021-02-06 00:33:19+00:00,https://twitter.com/rasbt/status/1357849820392796160,@tunguz *so the sticky notes have more sticky stuff on them and in the worst case scenario act as a regular paper bookmark that they are still somewhat adhesive and don't fall out too easily
8656,@rasbt,2021-02-06 00:28:33+00:00,https://twitter.com/rasbt/status/1357848621161545728,@joelgrus @xamat aka conference calls as an afterwork hobby? :P
8657,@rasbt,2021-02-06 00:25:48+00:00,https://twitter.com/rasbt/status/1357847928258392066,@tunguz whoa. will probably last you a lifetime
8658,@rasbt,2021-02-05 23:56:10+00:00,https://twitter.com/rasbt/status/1357840471276544005,@tunguz Always been a big fan of post-it notes for this purpose; harder to lose them (and more importantly the place) when throwing books into a bag
8659,@rasbt,2021-02-05 00:43:14+00:00,https://twitter.com/rasbt/status/1357489927030726657,"@TheZachMueller @imridhasankar @fastdotai E.g., similar to how PyTorch is inspired by and based on Torch 7 and Chainer. It's not like it would be a better library if it would hide this connection. ü§î"
8660,@rasbt,2021-02-05 00:41:37+00:00,https://twitter.com/rasbt/status/1357489521915547649,"@TheZachMueller @imridhasankar @fastdotai Oh wow. This is all very weird, I mean implementing something based on / inspired by someone else's open source code but then not admitting it / claiming credit for it. I can't see what the upside is. E.g., admitting/crediting is not like making things less useful."
8661,@rasbt,2021-02-05 00:25:50+00:00,https://twitter.com/rasbt/status/1357485549397958657,@imridhasankar @fastdotai Just seeing there is a thread discussing this: https://t.co/CFJ9MiA2DJ
8662,@rasbt,2021-02-04 23:37:00+00:00,https://twitter.com/rasbt/status/1357473260833804293,"@imridhasankar @fastdotai Yeah, I agree. There's some similarity."
8663,@rasbt,2021-02-04 21:04:47+00:00,https://twitter.com/rasbt/status/1357434954284687361,"@EthanFetaya @icmlconf @NeurIPSConf @iclr_conf Yes! Also useful for journal clubs! I like to print papers that I am planning to read thoroughly. Each time, I have to add the page labels manually to be able to tell which page I am referring to during the discussion"
8664,@rasbt,2021-02-04 20:36:23+00:00,https://twitter.com/rasbt/status/1357427804875423746,The open source community is really amazing
8665,@rasbt,2021-02-04 17:09:27+00:00,https://twitter.com/rasbt/status/1357375727872671745,"@zacharylipton Now, the big question, into which category does the extreme learning machine (ELM) fall?"
8666,@rasbt,2021-02-03 02:10:15+00:00,https://twitter.com/rasbt/status/1356787049664241666,"@michael_nielsen Emojis to some extent. Not a huge leap, but a nice 2.0 (or 1.1) update to the written for of language, adding another dimension to it. 

Major leap-wise, I am thinking of the .ONI files from Ready Player Two, which are a one-day-maybe thing."
8667,@rasbt,2021-02-02 21:37:57+00:00,https://twitter.com/rasbt/status/1356718525822480384,@mzakaria @radekosmulski Thanks for the kind words and offer! Here is to hoping that things return to normal in the not so distant future!
8668,@rasbt,2021-02-02 18:36:24+00:00,https://twitter.com/rasbt/status/1356672837956874244,"@ogrisel @scikit_learn Yeah, going through deprecation cycles don't sound fun but in this case I think it will be well worth it because t-SNE is so ubiquitous across many scientific disciplines nowadays. Looks like there is already an open issue: https://t.co/gqm2jiEdeL"
8669,@rasbt,2021-02-02 18:29:01+00:00,https://twitter.com/rasbt/status/1356670979162976258,@leland_mcinnes @seanmylaw @scikit_learn @NikolayOskolkov Thanks! Collecting so many good resources today! All bookmarked for my ML class next semester :)
8670,@rasbt,2021-02-02 15:38:47+00:00,https://twitter.com/rasbt/status/1356628135266164749,"@hippopedoid @scikit_learn Thanks, that's a good summary! Until then, I added it to my ""best practices"" note collection :)"
8671,@rasbt,2021-02-02 14:40:11+00:00,https://twitter.com/rasbt/status/1356613391444500487,"Oops, looks like we have been using t-SNE all wrong üòÖ. Maybe time to change the default in @scikit_learn :) https://t.co/4XmqRyth6q"
8672,@rasbt,2021-02-02 14:24:34+00:00,https://twitter.com/rasbt/status/1356609458437296134,@radekosmulski Thanks for the kind words! Glad to share my experience in hope it's helpful to others :)
8673,@rasbt,2021-02-02 00:32:38+00:00,https://twitter.com/rasbt/status/1356400097492398085,"@rroobbiinn Regarding dependence as the default outcome for FC networks, spontaneously, I can't think of a single example. It's obvious for Iris, but even take something like MNIST images, it doesn't matter whether all pixels are shuffled or not, you'd still get the same prediction outcome"
8674,@rasbt,2021-02-02 00:09:41+00:00,https://twitter.com/rasbt/status/1356394320824270848,"@rroobbiinn 2/2 If we think of extreme cases, then we also can't say CNNs have locality as an inductive bias, because that doesn't apply to 1x1 feature maps etc."
8675,@rasbt,2021-02-02 00:08:24+00:00,https://twitter.com/rasbt/status/1356393997477040131,"@rroobbiinn I think that's overthinking it. To me the figure still works as a nice summary. In practice, MLPs still have unordered features as inductive rel. bias even if in theory approximating any computation is possible. 1/2"
8676,@rasbt,2021-02-01 15:52:21+00:00,https://twitter.com/rasbt/status/1356269162084052992,"@_brohrer_ @E2eMl Yeah, I love teaching it as well! And there are potentially many different HW's you can design on top of a base implementation. Like adding KD tree or Ball tree data structures to speed things up: https://t.co/nYEDt7TyA1 https://t.co/I7jE7hREia"
8677,@rasbt,2021-02-01 14:40:31+00:00,https://twitter.com/rasbt/status/1356251084906516481,@rroobbiinn Regarding the equivariance prior i agree
8678,@rasbt,2021-02-01 14:39:38+00:00,https://twitter.com/rasbt/status/1356250862339895298,"@rroobbiinn The features are still assumed to be independent in the MLP (upper left). I.e., you can shuffle the feature columns in training set (before training) and it shouldn't matter. Or is there is an order, it is not position dependent."
8679,@rasbt,2021-02-01 04:16:00+00:00,https://twitter.com/rasbt/status/1356093922741800962,"@beeonaposy That sounds awesome, fun, and useful! Excited to share it with my students!"
8680,@rasbt,2021-02-01 00:53:01+00:00,https://twitter.com/rasbt/status/1356042838157496321,@roydanroy SGD with lr=0.1 and momentum=0.9
8681,@rasbt,2021-02-01 00:41:49+00:00,https://twitter.com/rasbt/status/1356040019379675136,@__mharrison__ How to Fizz the Buzz and Avoid Wookie Mistakes
8682,@rasbt,2021-01-31 19:30:15+00:00,https://twitter.com/rasbt/status/1355961613136908298,"@iamBT16 Thanks, glad to hear it was useful!"
8683,@rasbt,2021-01-31 19:22:01+00:00,https://twitter.com/rasbt/status/1355959541096189954,"Putting together material for my lectures next week, I stumbled upon this great figure summarizing the different design decisions / inductive biases of common neural net architectures (from: https://t.co/iHDYK4V98w) https://t.co/JAcqZ3Bz6O"
8684,@rasbt,2021-01-31 18:58:58+00:00,https://twitter.com/rasbt/status/1355953740390555657,@jonykarki @svpino thanks for the kind words!
8685,@rasbt,2021-01-30 15:30:50+00:00,https://twitter.com/rasbt/status/1355538973272252417,"@LorenaABarba Nice setup! Am curious, besides teaching, are you using part of the equipment for conference calls, too? I could use some better setup (like earbuds) to reduce speaker feedback &amp; was wondering if the mics in the Jabra are sufficient, or do you use the condenser mic for calls too?"
8686,@rasbt,2021-01-30 00:41:13+00:00,https://twitter.com/rasbt/status/1355315092670263303,@alfcnz @ajpizzuto @mr_ubik nice. bookmarked!
8687,@rasbt,2021-01-29 23:57:06+00:00,https://twitter.com/rasbt/status/1355303992868397056,Really nice and succinct essay on message passing (aka graph convolutions in deep learning) including practical aspects like batched padded matrix multiplication: https://t.co/AYX13f2NRt https://t.co/e7K8cuU9MG
8688,@rasbt,2021-01-29 20:09:03+00:00,https://twitter.com/rasbt/status/1355246598587092997,@ajpizzuto I could offer a list of literature on GNNs: https://t.co/bNxVIOp6R6. You will see they are actually all very similar under the hood :P
8689,@rasbt,2021-01-29 20:07:42+00:00,https://twitter.com/rasbt/status/1355246260417159168,"@ajpizzuto little spoiler/teaser: A future edition of my book will include a chapter on graph neural nets ;). For now, I don't know great resources off the top of my head, and there are many GNN methods out there; but it's essentially all based on message passing between nodes."
8690,@rasbt,2021-01-29 15:02:33+00:00,https://twitter.com/rasbt/status/1355169468264177665,@mundt_martin Probably should have said manual feature extraction or sth. like that :). What I meant was getting rid of the need to create structured data from unstructured data. Like having a human measuring sepal and petal lengths and widths with a ruler compared to providing images as input
8691,@rasbt,2021-01-29 00:36:20+00:00,https://twitter.com/rasbt/status/1354951476217589763,"@stuartandersonn @FlorianGallwitz @Twitter Didn't do it for me, but rebooting fixed it :)"
8692,@rasbt,2021-01-29 00:34:32+00:00,https://twitter.com/rasbt/status/1354951023895449600,"The field of ML-&gt;DL actually made great progress (*no sarcasm*). Thinking about it, we made all our least favorite tasks more or less obsolete, including feature engineering, architecture fiddling, and the worst of all: hand-labeling more training data"
8693,@rasbt,2021-01-29 00:15:13+00:00,https://twitter.com/rasbt/status/1354946160767729667,"@cynicalgrrl @Ted_Underwood @Twitter Hm, I am on the latest version, restarted safari, cleared the cache etc. Maybe it's time for a system reboot (just have to wait 45 more min until after office hours :P)"
8694,@rasbt,2021-01-28 18:26:23+00:00,https://twitter.com/rasbt/status/1354858377340399616,"As a fun thing to do this semester, I am reviving my ""Stuff in the News"" section -- an informal discussion of news related to deep learning at the beginning (or end) of each lecture week. In case someone is interested: https://t.co/1BVVG2RUu7"
8695,@rasbt,2021-01-28 00:53:54+00:00,https://twitter.com/rasbt/status/1354593509429424128,"@chrisalbon Fun fact: I wrote Gini ""Index"" in the first 1st edition of Python Machine Learning (fixed in a reprint) that resulted in lots of errata email üòÖ. Apparently, Gini Index is some term from economics ... who would have thunk (https://t.co/rpKuq39QQv)"
8696,@rasbt,2021-01-28 00:49:17+00:00,https://twitter.com/rasbt/status/1354592348345393152,"@AnnaWeese2 @chrisalbon as far as I know, the motivation is that Gini impurity is just simpler to compute (p^2 instead of p log p) while having the same properties (concave function). Given that CART was invented in 1984 when computers were a tad slower, these little tricks probably made some difference"
8697,@rasbt,2021-01-27 20:35:05+00:00,https://twitter.com/rasbt/status/1354528377596760076,@wicds_official That's a very interesting selection of topics and very enjoyable articles! Congrats to the winners!
8698,@rasbt,2021-01-27 19:41:43+00:00,https://twitter.com/rasbt/status/1354514945057173504,"@AndrewYNg Taking a step back and improving AI related education to better understand implications and limitations of AI-powered tech in the real world. And to lower entry barriers, to allow more people to help work on limitations of AI and problems like climate change and online harassment"
8699,@rasbt,2021-01-27 19:10:36+00:00,https://twitter.com/rasbt/status/1354507115805728771,@BFGHDF @packt Thanks so much for the compliment! :)
8700,@rasbt,2021-01-26 20:26:00+00:00,https://twitter.com/rasbt/status/1354163701520232450,"@abursuc I actually have 3 accounts now üòÖ (old institution, current institution, personal email). It's kind of unfortunate that the  ""merging/linking"" doesn't do much besides allowing you to circle between the accounts. I feel like there should be a ""view all"" or ""list all"" option"
8701,@rasbt,2021-01-26 16:31:44+00:00,https://twitter.com/rasbt/status/1354104746513207302,@zacharylipton Kaffeeklau
8702,@rasbt,2021-01-26 16:24:21+00:00,https://twitter.com/rasbt/status/1354102888654655491,"@abursuc The remaining issue/complaint from my side is that I get reviewer invites to both my private and .edu address. I merged these accounts on CMT via the merging feature, but somehow merging doesn't help with having one profile, and I still have to switch between profiles constantly."
8703,@rasbt,2021-01-26 01:29:57+00:00,https://twitter.com/rasbt/status/1353877807009509376,"This looks like a really handy tool for finding the published journal and conference versions of arXiv preprints. Also as recommendation to arXiv users, you can retrospectively add the DOI and journal references with a few clicks in 10 sec (see screenshots below) https://t.co/Gbmu0C8HHW"
8704,@rasbt,2021-01-26 01:10:34+00:00,https://twitter.com/rasbt/status/1353872926282575872,@rubenoliveros @isaacfab00 thanks for the kind words!
8705,@rasbt,2021-01-25 19:18:45+00:00,https://twitter.com/rasbt/status/1353784390082560000,"@JPSabini Oh, I thought you were asking whether I add some TF2 models to this repo. Regarding the book code, it's all on GitHub in separate repo, organized by chapter. I hope that's useful :) https://t.co/AvmasMevp3"
8706,@rasbt,2021-01-25 19:13:49+00:00,https://twitter.com/rasbt/status/1353783149407449088,@biobenkj Project management and organizing resources &amp; related work
8707,@rasbt,2021-01-25 19:12:48+00:00,https://twitter.com/rasbt/status/1353782894536388610,"@JPSabini Oh yeah, the repository could be updated some time :). Not sure when I get to it though, just started into the new semester today, teaching Intro to Deep Learning"
8708,@rasbt,2021-01-22 14:22:17+00:00,https://twitter.com/rasbt/status/1352622620773113856,"@naivebayesian @jeremyphoward @radekosmulski @goodfellow_ian @karpathy @ylecun Yes, this is of course a bit exaggerated :)"
8709,@rasbt,2021-01-22 01:11:55+00:00,https://twitter.com/rasbt/status/1352423714852368393,"@roydanroy *Ooops, over-aggressive editing to fit everything into the Twitter word count limit. I meant ""took a JavaScript course"" above"
8710,@rasbt,2021-01-22 01:10:09+00:00,https://twitter.com/rasbt/status/1352423270717546496,@roydanroy Java should be up way higher ;)
8711,@rasbt,2021-01-22 01:05:50+00:00,https://twitter.com/rasbt/status/1352422187219693575,"@roydanroy Pokemon at &gt; 33% üòú!?  Believe it or not, it may be more conducive to learning JavaScript than Java. My partner took a JavaScript that used Pokemon examples throughout when implementing classes, methods etc. She said it was all super confusing because she didn't know Pokemon."
8712,@rasbt,2021-01-21 16:57:40+00:00,https://twitter.com/rasbt/status/1352299333761298433,"@abursuc I like that idea. I think Nature's ""Scientific Reports"" does that in a basic form already, i.e., the editor can select a rating wrt to how useful the reviewer text was."
8713,@rasbt,2021-01-21 15:49:15+00:00,https://twitter.com/rasbt/status/1352282117758197760,"@DimitrisPapail Awesome! Big congrats, Dimitris!"
8714,@rasbt,2021-01-21 15:14:24+00:00,https://twitter.com/rasbt/status/1352273345857937409,"@radekosmulski @goodfellow_ian @karpathy @ylecun @jeremyphoward haha no worries, there was zero risk of confusion: I am really not a math aficionado"
8715,@rasbt,2021-01-21 15:11:30+00:00,https://twitter.com/rasbt/status/1352272616506220551,@mhajabri @jeremyphoward It looks interesting and I want to check it out as well :). Have to get through my existing pile of books first though ...
8716,@rasbt,2021-01-21 15:09:15+00:00,https://twitter.com/rasbt/status/1352272050455502849,"@MiguelCRomao Maybe it is easier to learn it from the book, because it is  more organized than the online tutorials. On the other hand, if you already have a significant deep learning background, then it's maybe too basic and you could learn it faster from the examples on the website"
8717,@rasbt,2021-01-21 14:59:13+00:00,https://twitter.com/rasbt/status/1352269526520524805,"@radekosmulski @goodfellow_ian @karpathy @ylecun Yeah. I remember Geoff Hinton saying that he usually comes up with the idea, implements it and sees how it works in practice, and lastly math is added later on to formalize it for the paper. I think this was either in the Talking Nets or Architects of Intelligence book."
8718,@rasbt,2021-01-21 14:55:15+00:00,https://twitter.com/rasbt/status/1352268528137736195,"For those who were interested to hear more, I wrote up my more detailed thoughts here: https://t.co/oyzJt3bTs7"
8719,@rasbt,2021-01-21 14:53:45+00:00,https://twitter.com/rasbt/status/1352268151254343680,"As promised last week, here are my thoughts on the Deep Learning with PyTorch book. ""Book Review: Deep Learning With PyTorch -- A Practical Deep Learning Guide With a Computer Vision Focus and an Interesting Structure"" https://t.co/oyzJt3bTs7"
8720,@rasbt,2021-01-21 02:43:26+00:00,https://twitter.com/rasbt/status/1352084360397266948,@dicksonlab That sounds fun too! https://t.co/uraQA9czHb
8721,@rasbt,2021-01-21 02:14:01+00:00,https://twitter.com/rasbt/status/1352076955462606849,scikit-earn üôÉ
8722,@rasbt,2021-01-21 01:46:49+00:00,https://twitter.com/rasbt/status/1352070112078139394,"@dicksonlab After discovering cross country skiing, I must say that winter is now my favorite season, and those sunny snow days are the best!"
8723,@rasbt,2021-01-20 16:35:04+00:00,https://twitter.com/rasbt/status/1351931259841368065,@arielcedola @packt Glad you like it! :)
8724,@rasbt,2021-01-20 15:34:18+00:00,https://twitter.com/rasbt/status/1351915964674224128,"Some people asked me if it is possible to get a discount on Python Machine Learning (3rd Ed) for the new semester. I don't have any codes myself, but @Packt added it to the New Year New Skills Sale on Amazon with 20% off until Monday: https://t.co/INNwcatbcX"
8725,@rasbt,2021-01-20 01:29:59+00:00,https://twitter.com/rasbt/status/1351703486791090178,@Al_Grigor @kaggle It could well be :)
8726,@rasbt,2021-01-19 22:55:05+00:00,https://twitter.com/rasbt/status/1351664506787811332,"@Al_Grigor @kaggle &gt; Want to win a @kaggle competition? Use XGBoost

Not an active Kaggler, but if you are into gradient boosting, why not LightGBM? Based on research class projects, my students had all positive experiences. Slightly better accuracy and faster to train."
8727,@rasbt,2021-01-19 18:52:24+00:00,https://twitter.com/rasbt/status/1351603433921507338,"@daniela_witten at least, I hope they waive the publication fees for you üò¨"
8728,@rasbt,2021-01-19 18:50:24+00:00,https://twitter.com/rasbt/status/1351602927429935106,@daniela_witten üòû
8729,@rasbt,2021-01-19 15:42:19+00:00,https://twitter.com/rasbt/status/1351555594352779268,"@DynamicWebPaige been there, it's tough ;). Stay strong!"
8730,@rasbt,2021-01-19 14:39:40+00:00,https://twitter.com/rasbt/status/1351539829943758849,"Finally an interesting new CNN architecture. After ""Exploring Randomly Wired Neural Networks for Image Recognition"" (https://t.co/FPRsVu9Ozo), I thought things might get boring. This arch. is also refreshingly straightforward (at least during 'inference'): https://t.co/JHlODUUheb"
8731,@rasbt,2021-01-19 14:32:03+00:00,https://twitter.com/rasbt/status/1351537912349929479,"@austingovella People recommended Linea Sketch to me. I use it occasionally but prefer drawing on my computer or on paper. Maybe it's my generation, but I am not a tablet person."
8732,@rasbt,2021-01-19 14:30:18+00:00,https://twitter.com/rasbt/status/1351537473688629260,"@rjurney @ogrisel Another reason why I use conda is MKL and speed. Maybe it has changed, but the PyPI versions of NumPy used to be 50% slower on my machines because they were not build with MKL."
8733,@rasbt,2021-01-19 14:28:16+00:00,https://twitter.com/rasbt/status/1351536961203425280,"@rjurney @ogrisel If you use conda, I would install packages from conda/conda-forge when you can. Based on my teaching experience, most problems from students are when they use conda but then sometimes install things via pip, things get garbled and dependencies are not met and things break."
8734,@rasbt,2021-01-19 02:45:29+00:00,https://twitter.com/rasbt/status/1351360101425274880,"@terrible_coder @deliprao Same. The main difference I see is that it allows you to define derivatives of python functions as opposed to a computation graph. For my current use cases either one is fine so I currently don't have a use case for JAX yet, but I keep it in mind."
8735,@rasbt,2021-01-18 23:39:56+00:00,https://twitter.com/rasbt/status/1351313404653395972,@WonderMicky @DeepMind That's awesome! Congrats!
8736,@rasbt,2021-01-18 20:36:32+00:00,https://twitter.com/rasbt/status/1351267248976109568,"@rjurney Regarding compatibility with the scientific computing ecosystem in general, I heard Docker recently released an ARM version, and homebrew can also be patched. But beyond that, no clue how well it works in practice or whether it's stable"
8737,@rasbt,2021-01-18 20:34:57+00:00,https://twitter.com/rasbt/status/1351266850089431040,"@rjurney For data science, I've always been a big Intel fan due to Intel's MKL and it's performance advantage. Personally, I am not in the market for a new machine for the next ~3 years, however, the M1 Mac Mini does seem appealing as a quiet all-purpose desktop machine."
8738,@rasbt,2021-01-18 15:17:41+00:00,https://twitter.com/rasbt/status/1351187009306566659,"@imohitmayank @fchollet Yeah it can be a chicken-egg problem. Like you think it would have been better to have focused on topic area X more a few years ago, but without that exploration you wouldn't have been stumbled upon it in the first place ;)"
8739,@rasbt,2021-01-18 15:16:28+00:00,https://twitter.com/rasbt/status/1351186701025161216,"@KinasRemek @fchollet Agreed. I usually try to combine the two, like drawing the knowledge / building the foundation I need for my projects from books."
8740,@rasbt,2021-01-18 02:15:56+00:00,https://twitter.com/rasbt/status/1350990274437275655,"@JMM019 @fchollet True. In the curriculum, I would leave room for new things as well via placeholders. Personally, I usually err on the side of jumping around too much ..."
8741,@rasbt,2021-01-18 02:02:07+00:00,https://twitter.com/rasbt/status/1350986796474249216,"@beeonaposy @fchollet I agree! However it becomes easier over time. I abandoned planning with when to complete a given book and went to I try to read ~60 min each day (excluding project related papers) no matter how far I get, no pressure."
8742,@rasbt,2021-01-18 01:52:25+00:00,https://twitter.com/rasbt/status/1350984358681784321,"@fchollet Planning out a curriculum of books &amp; papers to read in the next 5-10 years and committing to that, as opposed to reading what book or paper I stumbled upon on the internet last week and looks interesting at the given moment."
8743,@rasbt,2021-01-15 14:12:01+00:00,https://twitter.com/rasbt/status/1350083318277152770,"@roydanroy **However, I am sure there are other platforms to share solutions and collaborate. So my thinking is the best way to deal with this situation is to re-weight tasks where group work is not an issue (and even encouraged) like projects"
8744,@rasbt,2021-01-15 14:10:38+00:00,https://twitter.com/rasbt/status/1350082972549062658,@roydanroy * A colleague of mine had incidents where students posted/shared midterm solutions on Cheqq. Said colleague contacted Cheqq to release the account information of students who accessed the solutions. Apparently that deterred students from posting solutions on Cheqq for the final
8745,@rasbt,2021-01-15 14:08:51+00:00,https://twitter.com/rasbt/status/1350082523452354562,"@roydanroy 2/2 After going open-book for the exam last semester (different types of questions), I am planning to get rid of the final exam this semester and re-weight the other portions of the class. I don't see a good way for dealing with exams online."
8746,@rasbt,2021-01-15 14:07:28+00:00,https://twitter.com/rasbt/status/1350082176755314688,"@roydanroy I also heard about the Zoom approach, but the asynchronousness this semester and students being in vastly different time zones would make finding a common denominator for day &amp; time a bit difficult if you have a large class 1/2"
8747,@rasbt,2021-01-14 15:09:06+00:00,https://twitter.com/rasbt/status/1349735298754756609,@radekosmulski @bhutanisanyam1 @karpathy interesting. looks nice indeed. thanks for sharing!
8748,@rasbt,2021-01-14 00:39:43+00:00,https://twitter.com/rasbt/status/1349516508439973888,@arielcedola 3/3 At some point I grew so frustrated that I just deleted it :P
8749,@rasbt,2021-01-14 00:39:25+00:00,https://twitter.com/rasbt/status/1349516435165478912,"@arielcedola 2/2 However, there were some parts I found clunky. Eg I almost always had to log in every time I opened it. And I couldn't figure out how to undo a subfolder (I usually keep a folder for each project, and sometimes I accidentally dragged a folder wrong so it became a subfolder)"
8750,@rasbt,2021-01-14 00:37:03+00:00,https://twitter.com/rasbt/status/1349515838907420674,"@arielcedola oh yeah, have used that one in the past. Among the different options, it was my favorite because it had a folder hierarchy for the PDFs (compared to sqlite databases like Zotero) which allowed for easy syncing via e.g., OneDrive. However 1/2"
8751,@rasbt,2021-01-13 22:40:02+00:00,https://twitter.com/rasbt/status/1349486391730851840,@AngeBassa Congrats!
8752,@rasbt,2021-01-13 21:20:08+00:00,https://twitter.com/rasbt/status/1349466282178056193,"@ComeOnROY 2/2 to further explain b): inside gridsearch when you do e.g., 5-fold cv, the each model is trained on 4/5th of the training data. When grid search is completed, the best model is refit to all the training data before computing the test accuracy"
8753,@rasbt,2021-01-13 21:18:58+00:00,https://twitter.com/rasbt/status/1349465990007037952,@ComeOnROY It is rare but yes. Especially if the dataset is relatively small. Could be (a) due to noise (b) the fact that your model hasn't reached its full capacity and can benefit a lot from more data 1/2
8754,@rasbt,2021-01-13 14:46:10+00:00,https://twitter.com/rasbt/status/1349367136804868099,@ankur310794 @TensorFlow This looks like great work as well! Thanks for sharing!
8755,@rasbt,2021-01-13 14:21:27+00:00,https://twitter.com/rasbt/status/1349360920284291074,"This is really is a great tutorial/example for implementing a transformer from scratch, https://t.co/lU9EeIA15b https://t.co/NoSTauAN86"
8756,@rasbt,2021-01-13 14:03:02+00:00,https://twitter.com/rasbt/status/1349356282432675843,"@amArunava wow that sounds like a lot. Personally, as machine learning moderator on arxiv who is seeing submissions on a regular basis, I would have also guessed higher. Out of the ~100-200 submissions each day, there are at least 5-10 transformer papers."
8757,@rasbt,2021-01-13 13:59:50+00:00,https://twitter.com/rasbt/status/1349355480318140419,"@zwacke2 Yeah it seems like throwing out convolutions completely and having the transformers learn that inductive bias completely from scratch from large amounts of data sounds a bit extreme. Or, at least it would be out of reach for me / someone with less than a dozen GPUs"
8758,@rasbt,2021-01-13 13:58:30+00:00,https://twitter.com/rasbt/status/1349355143293251585,"@zwacke2 Nice, I just see it was accepted as a Spotlight paper: https://t.co/mHlVtAZGKi"
8759,@rasbt,2021-01-13 03:54:01+00:00,https://twitter.com/rasbt/status/1349203020115038208,"@themintsv Yeah, I think that's the data-efficient image transformer (DeiT) https://t.co/MINwIjPOYv -- to be fair, they mentioned it in the survey"
8760,@rasbt,2021-01-13 03:21:26+00:00,https://twitter.com/rasbt/status/1349194820099698692,"3/3 Btw ""small"" caveat: yes, they are expensive to train! E.g., the Vision Transformer (ViT) considers ImageNet as too small, so it is pre-trained (supervised or self-supervised) on a much large dataset before fine-tuning to ImageNet. üò¨"
8761,@rasbt,2021-01-13 03:21:26+00:00,https://twitter.com/rasbt/status/1349194819189534721,"2/3 Long story short, the number of applications where transformers have already been tried in CV is impressive. I had no idea. Image recognition, object detection, segmentation, image generation, image enhancement, multi-modal w. text, video, low-shot, clustering, 3D data"
8762,@rasbt,2021-01-13 03:21:25+00:00,https://twitter.com/rasbt/status/1349194817583149063,"Have had this recent transformer in vision survey on my desk for almost a week and was excited to read it. As someone primarily using goode olde CNNs for computer vision, I was pretty excited about this... ""Transformers in Vision: A Survey"" https://t.co/fhWW7r7jdP ... 1/3 https://t.co/WnOCn9RWMk"
8763,@rasbt,2021-01-13 01:38:40+00:00,https://twitter.com/rasbt/status/1349168956486135809,"@tunguz When I taught DL last spring, there were some students wanting to work with tabular datasets for their class projects. Compared to other types of data, the architecture design part was usually a bit boring. Will keep this in mind for future semesters, as a pointer for experiments"
8764,@rasbt,2021-01-13 01:37:41+00:00,https://twitter.com/rasbt/status/1349168711945625600,"@tunguz Thanks. This ""ColumnTransformer""-like approach looks like something that is actually interesting to play with"
8765,@rasbt,2021-01-13 01:25:49+00:00,https://twitter.com/rasbt/status/1349165725508894722,@tunguz Basically like MLPs with 1-2 hidden layers?
8766,@rasbt,2021-01-13 01:20:42+00:00,https://twitter.com/rasbt/status/1349164435928182784,"@tunguz Saw the first tweet, which got me pretty excited. Thought this could maybe a resource with practical tips to get DL models to work better on said data (compared to say LightGBM). Well, maybe not, good to know. Thanks for sharing!"
8767,@rasbt,2021-01-13 01:16:50+00:00,https://twitter.com/rasbt/status/1349163463306838017,"@fkratzert Arg, sorry to hear this :(. Have heard from others that the conference process has become way messier over the years. Probably due to overload (too many papers, not enough time, not enough personnel). I hope you can submit it to another venue soon, maybe a journal like JMLR."
8768,@rasbt,2021-01-12 19:14:54+00:00,https://twitter.com/rasbt/status/1349072378664525826,@BerbaFan I was planning to add a few sentences about it ;)
8769,@rasbt,2021-01-12 19:13:58+00:00,https://twitter.com/rasbt/status/1349072143712202752,"@gerhhellstern My thoughts are going to be more about the book :P. Regarding Tf vs PyTorch, as someone who used both pretty extensively for research (Tf since 2015, PyTorch since 2017), they kind of converged and are pretty much interchangeable today in terms of feature sets"
8770,@rasbt,2021-01-11 20:37:18+00:00,https://twitter.com/rasbt/status/1348730729828646914,"@BiohazZzZard Good q. Haven't watched the TV show. (Personally, I was wondering the opposite: is it worth watching the show after reading the book, and I think the consensus is a yes :))"
8771,@rasbt,2021-01-11 18:48:05+00:00,https://twitter.com/rasbt/status/1348703242574819333,@bhutanisanyam1 @radekosmulski Awesome! Personal impact of the community: (1) The feedback kept me motivated to learn and write more; (2) trying to explain better helped me learn better; (3) and the feedback about content itself (including errata) was also a super useful experience to fill in knowledge gaps
8772,@rasbt,2021-01-11 18:44:08+00:00,https://twitter.com/rasbt/status/1348702249799847940,"@radekosmulski @_brohrer_ haven't watched the TV show but the book is excellent. It's kind of an action-packed mystery thriller in space. Also, there are shifting perspectives (switching to a diff. character each chapter) a la Game of Thrones -- but only 2 characters so it is way way easier to keep track"
8773,@rasbt,2021-01-11 18:41:30+00:00,https://twitter.com/rasbt/status/1348701584667123718,@RichmanRonald @paulapivat üòÇ
8774,@rasbt,2021-01-11 17:26:47+00:00,https://twitter.com/rasbt/status/1348682781631668225,@RandianJustice Haven't watched the TV show but heard good things about it. Maybe I'll watch it after I am a few more books in
8775,@rasbt,2021-01-11 17:26:15+00:00,https://twitter.com/rasbt/status/1348682649791987714,"@paulapivat actually not too far fetched, both are about artificial intelligence in some sense ;)"
8776,@rasbt,2021-01-11 17:25:25+00:00,https://twitter.com/rasbt/status/1348682440823480329,"@eliaswalyba Same: Had it on my desk since Aug. But this winter seemed like a good time for an easy going text book to get the productivity going again. Also, am teaching my DL class again in Spring and was wondering if it could work as companion. Details will follow in the blog post then ;)"
8777,@rasbt,2021-01-11 17:18:56+00:00,https://twitter.com/rasbt/status/1348680806487760897,"After a short break from social media last week, I finished reading these two below. Both were fun &amp; surprisingly easy-going &amp; quick reads. If someone's interested in hearing more about the DL one, I am happy to put down some of my thoughts in a blog post later this week :) https://t.co/JsVyzQ1has"
8778,@rasbt,2021-01-11 14:50:13+00:00,https://twitter.com/rasbt/status/1348643383766622208,"@unsorsodicorda @set92 @Typora @alfcnz Based on toying around with it this morning, it's been great so far. Super smooth editing. So far, I actually like it even a tiny tad better than Typora :)"
8779,@rasbt,2021-01-10 15:58:58+00:00,https://twitter.com/rasbt/status/1348298293655302144,"@set92 @unsorsodicorda @Typora @alfcnz awesome, thanks for sharing"
8780,@rasbt,2021-01-10 15:52:42+00:00,https://twitter.com/rasbt/status/1348296720472563715,"@unsorsodicorda @Typora @alfcnz Yeah, it's a great tool that I think is very underappreciated. I actually used it to draft all my lecture notes, blog posts, and even papers in recent years (before converting to LaTeX)."
8781,@rasbt,2021-01-10 15:49:44+00:00,https://twitter.com/rasbt/status/1348295971868987392,"@adjiboussodieng 2/3 It is hard, but sometimes omitting details if they are too tangential helps too. Sometimes, I want to talk about this latest &amp; greatest research in a certain subtopic, but sometimes it is better to omit unnecessary details to focus on the bigger picture first."
8782,@rasbt,2021-01-10 15:48:36+00:00,https://twitter.com/rasbt/status/1348295686551445506,"@adjiboussodieng Personally, I think it is organization and communication; students will be busy with absorbing all the material that you explain and share. Having a clear organization of the topics (the order they are presented but also the motivation) makes things smoother 1/3"
8783,@rasbt,2021-01-06 14:36:32+00:00,https://twitter.com/rasbt/status/1346827998884978691,"@rjurney I use VS Code ~80% of the time when I am writing Python code (.py files), but when working with Jupyter notebooks, I think Jupyter Lab is still the way to go. I dunno, but working with Jupyter notebooks outside Jupyter Notebook/Lab always felt limiting or buggy."
8784,@rasbt,2021-01-06 01:40:28+00:00,https://twitter.com/rasbt/status/1346632696592814080,"@nlpnyc @zacharylipton Hah, watched those :). Other than that, I like Tarantino movies and the two Bladerunner movies. I am currently reading Leviathan Wakes (~halfway through) -- heard there is also a TV show; may check it out afterwards out of curiosity if it is good."
8785,@rasbt,2021-01-06 00:20:12+00:00,https://twitter.com/rasbt/status/1346612496388517890,"Just reading through the recent ""[A] Survey on Neural Network Interpretability"" (https://t.co/NXhHOBErAM) and there is this really cool interactive figure summarizing the respective literature in a 3D scatterplot (link to the interactive version: https://t.co/mXEJYw2X2l‚Ä¶) https://t.co/feGAmdas4i"
8786,@rasbt,2021-01-05 23:35:35+00:00,https://twitter.com/rasbt/status/1346601268169613314,"@nlpnyc @zacharylipton Thanks for the recommendations. Will add those to a someday-maybe list for when I am in the mood for this genre again. Movie-wise, haven't been able to find anything that piqued my interest lately; only thing I (re)watched in recent month was Fargo. Am more into books lately."
8787,@rasbt,2021-01-05 17:09:56+00:00,https://twitter.com/rasbt/status/1346504216165175302,This is great. I am especially thrilled about the visual debugger. https://t.co/wtSdVIj60X
8788,@rasbt,2021-01-05 17:01:48+00:00,https://twitter.com/rasbt/status/1346502169986560003,@randal_olson My first open source project was a progress bar for Python: https://t.co/Xnp4uRgOH8. 8 years later I am wowed. Progress bars have come a long way. It's essentially the same stuff under the hood but look at all that eye candy (kind of the same as with the evolution of movies) :)
8789,@rasbt,2021-01-05 15:44:59+00:00,https://twitter.com/rasbt/status/1346482835251752961,"@CharlieYouAI @burkov Interesting! Coincidentally, I just saw ""Transformers in Vision: A Survey"" on arxiv yesterday and added it to my reading pile :) https://t.co/fhWW7r7jdP"""
8790,@rasbt,2021-01-05 15:43:53+00:00,https://twitter.com/rasbt/status/1346482559878901760,@burkov graph neural networks?
8791,@rasbt,2021-01-05 15:42:53+00:00,https://twitter.com/rasbt/status/1346482307146780674,"@zacharylipton Yeah. Can't speak for others, but my personal interest already declined pretty rapidly since ~2015ish. The last good ones were Nolan's Batman movies. Didn't even try to watch a superhero movie since 2016 or so since the genre became really meh for me."
8792,@rasbt,2021-01-04 18:12:58+00:00,https://twitter.com/rasbt/status/1346157688984653824,"@thoughtsofaphd Same! Also, I find that I can deal with email (reading, answering, archiving etc.) way more efficiently when I am on my computer, so I deleted the mail client for my phone ~last year or so and never looked back :)"
8793,@rasbt,2021-01-04 16:41:09+00:00,https://twitter.com/rasbt/status/1346134583524401152,"@zacharylipton deja vu, or did we have this discussion ~6 months ago ;) https://t.co/rsueYyOUky"
8794,@rasbt,2021-01-04 14:50:48+00:00,https://twitter.com/rasbt/status/1346106811875790850,"@rhenry_herrera ah yes, good catch!"
8795,@rasbt,2021-01-04 14:49:18+00:00,https://twitter.com/rasbt/status/1346106435831271424,"@ddnukeit Yeah, I do :). It's a simple wooden stand that I got for $10 years ago. Simple but sufficient. https://t.co/3kNVMH9zWw"
8796,@rasbt,2021-01-04 03:10:34+00:00,https://twitter.com/rasbt/status/1345930594438569985,"@_psuryan Yeah, it may be antiquated compared to other tools (Notion, Roam), but it's an established tool that has been around for long and that I don't think will go away soon. It's basically like a personal wikipedia"
8797,@rasbt,2021-01-04 02:54:32+00:00,https://twitter.com/rasbt/status/1345926560512139269,"@jwuphysics I am using last name of first author, last name of last author (if applicable), year, and short title. Downside is it doesn't allow for sorting by year though but there is always a little tradeoff. E.g., bau-torralba_2020_role-of-units.pdf"
8798,@rasbt,2021-01-04 02:29:45+00:00,https://twitter.com/rasbt/status/1345920322655158275,cc @alfcnz @unsorsodicorda @adnancagri
8799,@rasbt,2021-01-04 02:29:45+00:00,https://twitter.com/rasbt/status/1345920321585635329,"""How I Keep My Projects Organized"" -- After exchanging notes on project management approaches with friends and colleagues privately &amp; on Twitter today, I just wrote a quick blog post outlining my approach, which may or may not be useful to others :)  https://t.co/3HtDAgjkis"
8800,@rasbt,2021-01-04 02:29:07+00:00,https://twitter.com/rasbt/status/1345920164919971846,@_psuryan This is nice! I used TiddlyWiki way back before I switched to DokuWiki :)
8801,@rasbt,2021-01-03 23:38:54+00:00,https://twitter.com/rasbt/status/1345877324709953537,"@adnancagri @alfcnz @anthonysamir @unsorsodicorda I don't think there is a one-size-fits-all tool or approach, and it's good to stay flexible if that's required by a given project. What's important though is to find a comfortable approach and stick with it versus wasting time on the quest of the ideal tool that doesn't exist"
8802,@rasbt,2021-01-03 23:37:23+00:00,https://twitter.com/rasbt/status/1345876946362707969,"@adnancagri @alfcnz @anthonysamir @unsorsodicorda I recently also adopted OneNote for certain research projects where I can do a fast copy&amp;paste and annotation of screenshot augmented with notes and scribbles. When I archive a project, I would export the pages as PDFs and put it into the folder for future reference."
8803,@rasbt,2021-01-03 23:36:22+00:00,https://twitter.com/rasbt/status/1345876690095001601,"@adnancagri @alfcnz @anthonysamir @unsorsodicorda Also, I am not 100% strict about having all files in that folder. E.g., I collaborate on papers using Overleaf. I just put a weblink into that folder. However, when the project is finished, I download the Overleaf files and put them into the folder for archival purposes."
8804,@rasbt,2021-01-03 23:34:31+00:00,https://twitter.com/rasbt/status/1345876222287486983,"@adnancagri @alfcnz @anthonysamir @unsorsodicorda This prob. doesn't work for everyone, but I kind of like this approach because it doesn't require specific apps and is OS agnostic. I do use some specialized apps for certain parts of each proj. (dep. on what the proj. requires) but other than that it's (subscription) free ;)"
8805,@rasbt,2021-01-03 23:32:03+00:00,https://twitter.com/rasbt/status/1345875603862532097,"@adnancagri @alfcnz @anthonysamir @unsorsodicorda Each evening, I make a time-blocking-style todo list/schedule from my weekly todos. When a project is completed, I move the folder into a project-archive folder that is dated. I sync this across computers with OneDrive. And that's basically it. https://t.co/PAmLYtOTwo"
8806,@rasbt,2021-01-03 23:29:45+00:00,https://twitter.com/rasbt/status/1345875021898670080,"@adnancagri @alfcnz @anthonysamir @unsorsodicorda In essence, I have a project-data folder where I keep all my active projects. Each project is a separate folder. In each folder, I have files associated with that project. Also, each folder has a separate todo list. Each week I compile a weekly todo from these lists. https://t.co/DEKCQr55dT"
8807,@rasbt,2021-01-03 23:26:14+00:00,https://twitter.com/rasbt/status/1345874138754375680,"@adnancagri @alfcnz @anthonysamir @unsorsodicorda I posted about it on twitter a few times but never really wrote about it, because it is a subjective workflow that works well for me (but may not for others). I think ultimately there is a journey for everyone, finding what works for a particular job &amp; life situation"
8808,@rasbt,2021-01-03 23:11:40+00:00,https://twitter.com/rasbt/status/1345870471208841216,@neurobongo they kind of make household chores more bearable
8809,@rasbt,2021-01-03 23:09:01+00:00,https://twitter.com/rasbt/status/1345869805505703937,"@alfcnz @akhtarmubashara also, I really liked his ""Digital Minimalism"" one"
8810,@rasbt,2021-01-03 22:56:48+00:00,https://twitter.com/rasbt/status/1345866731273773059,@alfcnz @anthonysamir @unsorsodicorda I tried a lot of apps in the past. I basically went back to plain lists for projects because thinking about which tool to use was kind of a distraction itself. I add deadlines to my calendar. It's a simple setup but works well. Have been doing this for years now.
8811,@rasbt,2021-01-03 19:54:12+00:00,https://twitter.com/rasbt/status/1345820780471451649,"@anthonysamir @unsorsodicorda @alfcnz oh yeah, I used Omnifocus in grad school"
8812,@rasbt,2021-01-03 18:46:45+00:00,https://twitter.com/rasbt/status/1345803806051880964,"@unsorsodicorda @alfcnz Yeah, it's not mentioned because it goes partly against GTD in the sense that you don't pick tasks based on energy level but you do particular things at a particular time (which helps with planning your day). Here is a pic of how it can look like: https://t.co/MZ6eReQKKT"
8813,@rasbt,2021-01-03 16:52:42+00:00,https://twitter.com/rasbt/status/1345775101879398401,@kjelljorner @alfcnz *so this daily list is based on a weekly list I make from my project lists every Sunday. This weekly list I make digitally but print out every week. Also for scribbling on it.
8814,@rasbt,2021-01-03 16:50:54+00:00,https://twitter.com/rasbt/status/1345774651767717894,"@kjelljorner @alfcnz piece of paper. My main/project todo lists are all digital, but for this daily one I prefer paper -- somehow increases my focus if I can do it on my desk without staring at the computer. Also, I usually do it before going to bed and this way I don't have to stare at a screen"
8815,@rasbt,2021-01-03 15:55:04+00:00,https://twitter.com/rasbt/status/1345760598815092737,@themintsv wow that's a good one. I clicked on the link expecting a dozen links and found more than 1000. Wow.
8816,@rasbt,2021-01-03 15:51:44+00:00,https://twitter.com/rasbt/status/1345759761418100736,"@TalDaniel8 Very cool, thanks! That's actually very helpful because working on computer vision is usually what I recommend for beginners in DL"
8817,@rasbt,2021-01-03 15:49:51+00:00,https://twitter.com/rasbt/status/1345759285360386050,"@mihail_eric @kaggle @GoogleAI Awesome, thanks!"
8818,@rasbt,2021-01-03 15:49:01+00:00,https://twitter.com/rasbt/status/1345759077012561920,"@alfcnz *before time blocking, I always ended up with too many little projects on my daily todo lists -- more that can be accomplished in a day. This was often frustrating and tiring in the long run, and it made me sometimes focus on the wrong things (little todos for immediate rewards)"
8819,@rasbt,2021-01-03 15:47:13+00:00,https://twitter.com/rasbt/status/1345758623520219137,"@alfcnz I like to combine GTD with time blocking to manage my day &amp; energy. Every evening, I would plot out what I'll do when next day to have a rough idea of what I can accomplish that day. I use GTD for my master todo-lists, but time blocking helps with keeping things realistic"
8820,@rasbt,2021-01-02 20:31:02+00:00,https://twitter.com/rasbt/status/1345467658997800960,"@PawarBI Interesting. Thanks for sharing! At first glance, it looks a bit like a mix between Evernote and OneNote to me."
8821,@rasbt,2021-01-02 20:27:33+00:00,https://twitter.com/rasbt/status/1345466783646560257,"@ryanpholbrook Yeah, good point, that's been the go-to place for most students in previous semesters."
8822,@rasbt,2021-01-02 20:23:01+00:00,https://twitter.com/rasbt/status/1345465644477788162,"@ryanpholbrook Thanks! Was actually recently wondering where to publish datasets, haven't heard of Data in Brief before and it looks useful for that purpose!"
8823,@rasbt,2021-01-02 20:21:18+00:00,https://twitter.com/rasbt/status/1345465210199543810,@PawarBI Thanks for both! My collection keeps growing :)
8824,@rasbt,2021-01-02 20:20:21+00:00,https://twitter.com/rasbt/status/1345464971556245504,"@hackalog Interesting repo &amp; workflow. There is definitely some barrier of entry (extra effort), esp. compared to just having a folder of labeled images for which you e.g. create a PyTorch dataset class but I can see how it can be useful for reproducible research. Thanks for sharing!"
8825,@rasbt,2021-01-02 19:02:55+00:00,https://twitter.com/rasbt/status/1345445484744290305,Thanks everyone for the additional recommendations! I am currently collecting these additional resources and will share a list in a few weeks when I got the class's GitHub repo set up! https://t.co/llDeVXlhYT
8826,@rasbt,2021-01-02 19:01:13+00:00,https://twitter.com/rasbt/status/1345445057923575809,"@IgorBrigadir Whoa, that's a super comprehensive one, thanks!"
8827,@rasbt,2021-01-02 19:00:14+00:00,https://twitter.com/rasbt/status/1345444810111520770,@josephofiowa Will add this! Thanks a lot for sharing!
8828,@rasbt,2021-01-02 18:59:37+00:00,https://twitter.com/rasbt/status/1345444656465793026,"@_lewtun Awesome, bookedmarked and added to the list!"
8829,@rasbt,2021-01-02 18:59:24+00:00,https://twitter.com/rasbt/status/1345444598202724352,@crude2refined That's a really nice one! Thanks a lot!
8830,@rasbt,2021-01-02 18:57:35+00:00,https://twitter.com/rasbt/status/1345444144102203397,"@judywawira it will be and ""Intro to deep learning"" course this semester. Yes, I think I am going to share it :)"
8831,@rasbt,2021-01-02 18:56:35+00:00,https://twitter.com/rasbt/status/1345443890074169344,@VeitSchiele This looks nice! Thanks for sharing!
8832,@rasbt,2021-01-02 16:31:47+00:00,https://twitter.com/rasbt/status/1345407451865243648,"Compiling some resources for students next semester. Useful places for ML datasets:

Tabular &amp; cleaned:
https://t.co/kcsoxPUYQG

By domain:
https://t.co/fQ4KCuQuTZ

By application:
https://t.co/veUoWTTu0O

Search engine:
https://t.co/3ycpIQx71p

Community:
https://t.co/Oa9miTVQYX"
8833,@rasbt,2021-01-01 23:37:04+00:00,https://twitter.com/rasbt/status/1345152088112771075,"@MisterFreire Reg 3), it's basically about asking yourself why you are reading a paper. E.g., if I read a paper to explain a given method in a lecture, I read it differently compared to a paper that I read because I want to compare their results to my results when I am writing a paper"
8834,@rasbt,2021-01-01 23:35:08+00:00,https://twitter.com/rasbt/status/1345151603553271808,"@MisterFreire Reg 2), I avoid specific apps. They all have their quirks &amp; I am perfectly fine with just having PDFs on my computer. I keep general notes on my personal wiki, and project specific notes in a simple document for a given project (lecture or research) that the paper is relevant for"
8835,@rasbt,2021-01-01 23:31:51+00:00,https://twitter.com/rasbt/status/1345150774985240576,"@SaranAhluwalia Yeah, I really think it depends on what you are going for. If you are more interested in the implementation details, focusing more on the methods and appendix makes more sense."
8836,@rasbt,2021-01-01 16:25:04+00:00,https://twitter.com/rasbt/status/1345043374370385922,"@SaranAhluwalia After reading the abstract, mostly from start to end while taking notes on parts that are relevant to my project(s). Although, I occasionally try to do the usually recom. process: Reading conclusions, looking at the figs, then skimming it, &amp; then reading it from beginning to end."
8837,@rasbt,2021-01-01 16:17:28+00:00,https://twitter.com/rasbt/status/1345041461306392576,"3/3 Also, what I find really helpful is to create a paper reading/to read list for each individual research project and area (next to having one main document or list)."
8838,@rasbt,2021-01-01 16:17:28+00:00,https://twitter.com/rasbt/status/1345041460329144320,"2/3 ""keeps track of papers that I‚Äôve read ‚Äì every time I read a new paper, I add it into the doc, along with a short summary of my takeaways. The document is now over fifty pages"" Taking a similar approach as well. It really motivates one to read more to keep one's list growing"
8839,@rasbt,2021-01-01 15:28:05+00:00,https://twitter.com/rasbt/status/1345029030769287168,"@burkov My guess is something bidirectional transformer-based. I remember xfspell (https://t.co/fYAHO52nuc) from the ""The Unreasonable Effectiveness of the Transformer Spell Checker"" earlier this year. Beyond this tutorial, there are probably more advanced ones"
8840,@rasbt,2021-01-01 15:17:54+00:00,https://twitter.com/rasbt/status/1345026470025043968,"@KwasiRansom Good question. Personally, I am one of the machine learning moderators on arxiv so I get to skim through the titles 2 days a week and discover interesting articles this way. Also, I sometimes find interesting articles via social media. Other than that, I use Google Scholar."
